@inproceedings{10.1145/3696230.3696248,
author = {Asmawi, Adelina and Alam, Md. Saiful},
title = {Understanding the Digital Epistemologies of Chat GPT: Towards a Decolonial Language Pedagogy},
year = {2024},
isbn = {9798400717574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696230.3696248},
doi = {10.1145/3696230.3696248},
abstract = {Since its emergence, research around Chat GPT and language teaching has trended into an asymmetry of opportunities and challenges from both utopian and dystopian perspectives. Chat GPT has Western data-based inherent coloniality and thus carries invisible colonial perpetuation when used in language education. However, Chat GPT has context-awareness and personalization capacity and is open to user control. Therefore, rather than decolonizing Chat GPT itself, decolonizing by Chat GPT can be a flipped approach to materialize decolonial persuasion in language pedagogy. Grounded in Santos's epistemology of the south, this paper attempts to conceptualize Chat GPT-assisted decolonial pedagogy. Using the authors’ constructivist ideation, the study employed simulated text data generated through a series of Chat GPT-author conversations. The collected data were analyzed by applying the educational data mining (EDM) method to support the primary conceptualization of the proposed decolonial pedagogy. The findings serve as a breakthrough with a novelty discovered in Chat GPT-facilitated decolonization of language pedagogy empowering decolonially charged educators working in the global south.},
booktitle = {Proceedings of the 2024 8th International Conference on Digital Technology in Education (ICDTE)},
pages = {277–283},
numpages = {7},
keywords = {AI, Chat GPT, Chat GPT Epistemology, Decolonizing ELT, Decolonizing Education},
location = {
},
series = {ICDTE '24}
}

@inproceedings{10.1145/3626253.3633409,
author = {Hazzan, Orit and Erez, Yael},
title = {Generative AI in Computer Science Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633409},
doi = {10.1145/3626253.3633409},
abstract = {Generative AI has the potential to become disruptive technology for computer science education. Therefore, computer science educators must be familiar with the threats they should deal with and with the opportunities that generative-AI opens for the computer science education community. In the workshop, we explore the integration of several generative-AI tools and applications in computer science education. Activities include lesson design, code development, test design and assessment. We address the students' and the educators' perspectives. In addition, we explore computer science practices and soft skills to be applied with these tools as well as immediate and future applications and implications for computer science education and for the society. AT the end of the workshop, the participants will be able to use these generative AI tools in their daily educational computer science activities and beyond.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1899},
numpages = {1},
keywords = {ai, assessment, computer science education, curriculum design, disruptive technology, generative ai, skills},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3685680,
author = {Annapureddy, Ravinithesh and Fornaroli, Alessandro and Gatica-Perez, Daniel},
title = {Generative AI Literacy: Twelve Defining Competencies},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
url = {https://doi.org/10.1145/3685680},
doi = {10.1145/3685680},
abstract = {This article introduces a competency-based model for generative artificial intelligence (AI) literacy covering essential skills and knowledge areas necessary to interact with generative AI. The competencies range from foundational AI literacy to prompt engineering and programming skills, including ethical and legal considerations. These 12 competencies offer a framework for individuals, policymakers, government officials, and educators looking to navigate and take advantage of the potential of generative AI responsibly. Embedding these competencies into educational programs and professional training initiatives can equip individuals to become responsible and informed users and creators of generative AI. The competencies follow a logical progression and serve as a roadmap for individuals seeking to become familiar with generative AI and for researchers and policymakers to develop assessments, educational programs, guidelines, and regulations.},
journal = {Digit. Gov.: Res. Pract.},
month = feb,
articleno = {13},
numpages = {21},
keywords = {Generative AI literacy, AI literacy, data literacy, generative AI, prompt engineering, AI competencies, AI skills}
}

@inproceedings{10.1145/3702212.3702223,
author = {Petrovska, Olga and Pearsall, Rebecca and Clift, Lee},
title = {Assessing Software Engineering Students' Analytical Skills in the Era of Generative AI},
year = {2025},
isbn = {9798400711725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702212.3702223},
doi = {10.1145/3702212.3702223},
abstract = {This poster showcases an assessment designed to develop and evaluate software engineering students’ code analysis skills. We demonstrate how students approached code analysis tasks when given multiple code samples created by a human and various AI tools.},
booktitle = {Proceedings of the 9th Conference on Computing Education Practice},
pages = {34},
numpages = {1},
keywords = {generative AI, software engineering, education, apprenticeship},
location = {
},
series = {CEP '25}
}

@article{10.1145/3652154,
author = {Russo, Daniel},
title = {Navigating the Complexity of Generative AI Adoption in Software Engineering},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3652154},
doi = {10.1145/3652154},
abstract = {This article explores the adoption of Generative Artificial Intelligence (AI) tools within the domain of software engineering, focusing on the influencing factors at the individual, technological, and social levels. We applied a convergent mixed-methods approach to offer a comprehensive understanding of AI adoption dynamics. We initially conducted a questionnaire survey with 100 software engineers, drawing upon the Technology Acceptance Model, the Diffusion of Innovation Theory, and the Social Cognitive Theory as guiding theoretical frameworks. Employing the Gioia methodology, we derived a theoretical model of AI adoption in software engineering: the Human-AI Collaboration and Adaptation Framework. This model was then validated using Partial Least Squares–Structural Equation Modeling based on data from 183 software engineers. Findings indicate that at this early stage of AI integration, the compatibility of AI tools within existing development workflows predominantly drives their adoption, challenging conventional technology acceptance theories. The impact of perceived usefulness, social factors, and personal innovativeness seems less pronounced than expected. The study provides crucial insights for future AI tool design and offers a framework for developing effective organizational implementation strategies.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {135},
numpages = {50},
keywords = {Generative AI, large language models, technology adaption, empirical software engineering}
}

@inproceedings{10.1145/3702163.3702188,
author = {Schefer-Wenzl, Sigrid and Vogl, Christoph and Peiris, Sahani and Miladinovic, Igor},
title = {Exploring the Adoption of Generative AI Tools in Computer Science Education: A Student Survey},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702188},
doi = {10.1145/3702163.3702188},
abstract = {The integration of generative AI tools into education has the potential to revolutionize learning experiences, particularly in computer science. This paper explores the adoption and utilization of generative AI tools among computer science students at the University of Applied Sciences Campus Vienna in Austria through a comprehensive survey. The study aims to understand the extent to which AI tools like ChatGPT are integrated into students' academic routines, their perceptions of these tools, and the challenges and opportunities they present. The survey results indicate a high level of acceptance and frequent use of AI tools for tasks such as programming, exam preparation, and generating simplified explanations. However, concerns about the accuracy of AI-generated content and the potential impact on critical thinking skills were also highlighted. The findings underscore the need for clear institutional guidelines and ethical considerations in the use of AI tools in education. This paper contributes to the growing body of literature on AI in education and provides insights for educators and policymakers to enhance the responsible integration of AI technologies in computer science curricula.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {173–178},
numpages = {6},
keywords = {Artificial Intelligence, Computer Science Education, Generative AI Tools, Higher Education},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3706599.3707213,
author = {Muller, Michael and Chilton, Lydia B and Maher, Mary Lou and Martin, Charles Patrick and Choi, Minsik and Walsh, Greg and Kantosalo, Anna},
title = {GenAICHI 2025: Generative AI and HCI at CHI 2025},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3707213},
doi = {10.1145/3706599.3707213},
abstract = {This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI), and - among other approaches - particularly to Large Language Models (LLMs) and Foundation Models (FMs). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together.Following successful workshops in 2022–2024, we convene the interdisciplinary research domain of generative AI and HCI. Participation is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {782},
numpages = {9},
keywords = {HCI, HCAI, Generative AI, Design, Uncertainty, Large language models, Bias, Ethics.},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3597503.3639201,
author = {Choudhuri, Rudrajit and Liu, Dylan and Steinmacher, Igor and Gerosa, Marco and Sarma, Anita},
title = {How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639201},
doi = {10.1145/3597503.3639201},
abstract = {Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {184},
numpages = {13},
keywords = {empirical study, software engineering, generative AI, ChatGPT},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3641555.3705107,
author = {Fox, Armando and Fern\'{a}ndez, Pablo and Leinonen, Juho and Parejo Maestre, Jos\'{e} Antonio},
title = {Using Generative AI to Scaffold the Teaching of Software Engineering Team Skills},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705107},
doi = {10.1145/3641555.3705107},
abstract = {Most of the attention on GenAI in computing education has focused on programming-centric tasks, such as code generation, giving feedback on code, or providing synthetic programming partners. Yet in advanced software engineering and project courses, interpersonal skills such as team meetings or customer interviews are equally important but difficult and instructor-intensive to teach realistically. GenAI presents the possibility of scaffolding the teaching of some of these practices by enabling exercises in which students develop the ability to investigate a topic by iteratively asking questions to find a solution. The goal is to create scenarios in which students train to interact with humans in real-world situations, simulating these interactions in a controlled, guided environment. These simulations could help students practice and refine ''soft skills,'' such as teamwork and interviewing, by mimicking the types of exchanges and problem-solving they would encounter in professional environments. This approach allows learners to engage in realistic communication exercises, improving their ability to handle complex, interpersonal tasks through repeated practice with AI-guided feedback. As an example, we envision examples that include requirements elicitation with customers, development team meetings, and discussion with potential investors, to name just a few.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1719},
numpages = {1},
keywords = {computing education, empirical studies, experimentation, generative artificial intelligence, large language models, natural language generation, requirements analysis, requirements elicitation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701823,
author = {Ali, Areej and Collier, Aayushi Hingle and Dewan, Umama and McDonald, Nora and Johri, Aditya},
title = {Analysis of Generative AI Policies in Computing Course Syllabi},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701823},
doi = {10.1145/3641554.3701823},
abstract = {Since the release of ChatGPT in 2022, Generative AI (GenAI) is increasingly being used in higher education computing classrooms across the United States. While scholars have looked at overall institutional guidance for the use of GenAI and reports have documented the response from schools in the form of broad guidance to instructors, we do not know what policies and practices instructors are actually adopting and how they are being communicated to students through course syllabi. To study instructors' policy guidance, we collected 98 computing course syllabi from 54 R1 institutions in the U.S. and studied the GenAI policies they adopted and the surrounding discourse. Our analysis shows that 1) most instructions related to GenAI use were as part of the academic integrity policy for the course and 2) most syllabi prohibited or restricted GenAI use, often warning students about the broader implications of using GenAI, e.g. lack of veracity, privacy risks, and hindering learning. Beyond this, there was wide variation in how instructors approached GenAI including a focus on how to cite GenAI use, conceptualizing GenAI as an assistant, often in an anthropomorphic manner, and mentioning specific GenAI tools for use. We discuss the implications of our findings and conclude with current best practices for instructors.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {18–24},
numpages = {7},
keywords = {course syllabi, generative ai, policy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3633053.3633057,
author = {Petrovska, Olga and Clift, Lee and Moller, Faron and Pearsall, Rebecca},
title = {Incorporating Generative AI into Software Development Education},
year = {2024},
isbn = {9798400709326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633053.3633057},
doi = {10.1145/3633053.3633057},
abstract = {This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools “doing the homework”.},
booktitle = {Proceedings of the 8th Conference on Computing Education Practice},
pages = {37–40},
numpages = {4},
keywords = {apprenticeship, assessment, education, generative AI, software engineering},
location = {Durham, United Kingdom},
series = {CEP '24}
}

@inproceedings{10.1145/3708359.3712125,
author = {Wang, Xingyi and Wang, Xiaozheng and Park, Sunyup and Yao, Yaxing},
title = {Mental Models of Generative AI Chatbot Ecosystems},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712125},
doi = {10.1145/3708359.3712125},
abstract = {The capability of GenAI-based chatbots, such as ChatGPT and Gemini, has expanded quickly in recent years, turning them into GenAI Chatbot Ecosystems. Yet, users’ understanding of how such ecosystems work remains unknown. In this paper, we investigate users’ mental models of how GenAI Chatbot Ecosystems work. This is an important question because users’ mental models guide their behaviors, including making decisions that impact their privacy. Through 21 semi-structured interviews, we uncovered users’ four mental models towards first-party (e.g., Google Gemini) and third-party (e.g., ChatGPT) GenAI Chatbot Ecosystems. These mental models centered around the role of the chatbot in the entire ecosystem. We further found that participants held a more consistent and simpler mental model towards third-party ecosystems than the first-party ones, resulting in higher trust and fewer concerns towards the third-party ecosystems. We discuss the design and policy implications based on our results.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {1016–1031},
numpages = {16},
keywords = {Mental Models, Generative AI Chatbots, Privacy and Security, Human Computer Interaction},
location = {
},
series = {IUI '25}
}

@article{10.5555/3729857.3729868,
author = {Bandi, Ajay},
title = {Pedagogical Evaluation of Generative AI Course for Technologists},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {6},
issn = {1937-4771},
abstract = {Generative AI is a transformative technology that impacts various fields, including software development, data analytics, and cybersecurity. To address this, we have designed and developed a Generative AI course for technologists, integrating foundational knowledge of various Gen AI architecture models with hands-on practical experience using Python libraries, including HuggingFace. This paper discusses the detailed course structure and assessments. A pedagogical evaluation approach is followed to identify the challenges encountered in the course and how to overcome them. The results demonstrate that the Generative AI Course for Technologists effectively equips students with technical expertise and critical thinking skills through a balanced combination of theoretical concepts and practical exercises, such as chatbot development and prompt engineering. The course addresses challenges like hardware limitations and API integration by proposing future improvements, including a dedicated Python module and access to cloud-based GPU tools, ensuring learners are well-prepared to navigate and ethically apply Generative AI in real-world contexts.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {99–110},
numpages = {12}
}

@inproceedings{10.1145/3706599.3706734,
author = {Glazko, Kate S and Huh, Mina and Johnson, Jazette and Pavel, Amy and Mankoff, Jennifer},
title = {Generative AI and Accessibility Workshop: Surfacing Opportunities and Risks},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706734},
doi = {10.1145/3706599.3706734},
abstract = {The increasing use of generative AI (GAI) as an accessibility tool offers transformative opportunities, but it also introduces significant risks and barriers that remain unaddressed. This workshop explores the multi-faceted nature of GAI use for accessibility, focusing on its potential to create access solutions where none exist while surfacing the risks of bias, inaccessibility, and misinformation. Our goal is to establish best practices for inclusive GAI design that centers disabled people’s agency, addressing key questions such as how to ensure GAI tools are accessible by default and how to mitigate risks without undermining autonomy. By bringing together experts in accessibility, AI, human-computer interaction (HCI), and disability studies, this workshop aims to develop design guidelines, recommendations, and practices that will influence future GAI systems. Participants will collaboratively define an agenda for creating GAI tools that advance equity, minimize harm, and embrace the diverse needs of the disability community.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {783},
numpages = {6},
keywords = {Generative AI, Accessibility, Accessibility technologies},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706599.3719844,
author = {Ma, Qianou and Jain, Anika and Kim, Jini and Chai, Megan and Kaufman, Geoff},
title = {ImaginAItion: Promoting Generative AI Literacy Through Game-Based Learning},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719844},
doi = {10.1145/3706599.3719844},
abstract = {The rapid adoption of Generative AI (GenAI) in our society and everyday life demonstrates the need for greater AI literacy of its potential biases and harms. Although there have been attempts to bring AI literacy to children, commonly via game-based learning, there is still a lack of instruction that aims to encourage a more nuanced understanding of the utility and harm of GenAI systems to a broader audience. To address the gap, we developed the educational game ImaginAItion, inspired by existing popular party game mechanisms such as Telestrations and Caution Signs. In particular, our game targets adults who do not have a deep understanding of GenAI. Leveraging persuasive strategies grounded in psychological theories, we seek to encourage deeper reflection on players’ GenAI prompting behaviors and their understanding of its capabilities and limitations.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {331},
numpages = {9},
keywords = {AI literacy, game-based learning, Generative AI},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3635636.3664263,
author = {Kawakami, Reishiro and Venkatagiri, Sukrit},
title = {The Impact of Generative AI on Artists},
year = {2024},
isbn = {9798400704857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635636.3664263},
doi = {10.1145/3635636.3664263},
abstract = {Generative AI has the potential to augment artists’ creative expression, while simultaneously harming their professions through unethical data collection practices and replacement of human labor. We conducted a thematic analysis of social media posts to understand artists’ perceptions and experiences of the direct and indirect impact of generative AI on their profession. Our findings also highlight growing public distrust toward artists amidst the rise of generative AI, with accusations of using AI tools leading to stress and fear of unemployment. Our study provides valuable insights into the complex interplay between artists, generative AI, and the public. We discuss potential protective measures for artists, including regulatory interventions and opt-in/out data collection, and explore future impacts of generative AI on artists’ creative processes.},
booktitle = {Proceedings of the 16th Conference on Creativity &amp; Cognition},
pages = {79–82},
numpages = {4},
keywords = {AI art, Artists, Generative AI, artwork, creative professions},
location = {Chicago, IL, USA},
series = {C&amp;C '24}
}

@inproceedings{10.1145/3641554.3701853,
author = {Filcik, Daniel and Sobiesk, Edward and Matthews, Suzanne J.},
title = {Fostering Creativity: Student-Generative AI Teaming in an Open-Ended CS0 Assignment},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701853},
doi = {10.1145/3641554.3701853},
abstract = {The increasing ubiquity of web-based generative artificial intelligence technologies necessitates that all students experience teaming with such technologies -- exploring their strengths and limitations and learning how to create synergy with them. To aid in this effort, we designed an open-ended generative AI project for the freshmen taking our general-education introduction to computing course. Students were required to team with generative AI to create something beyond what they alone (or the AI alone) could accomplish. Upon completion, students submitted a short written critical analysis documenting their experiences and presented a three-minute demonstration of their project in class. Despite limited course coverage of AI and generative AI prior to this project, we were impressed by the creativity and sophistication of the submitted final products as well as the breadth of generative AI tools explored. Student reflections on the experience illustrated numerous insights into the strengths and limitations of the tools they employed. Our results underscore that students can learn about the benefits and limitations of generative AI in as little as a single assignment and that covering such topics need not require extensive amounts of course time and resources.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {339–345},
numpages = {7},
keywords = {computing education, cs0, final project, freshmen, generative artificial intelligence, human-ai teaming},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705038,
author = {Dzhumaliev, Mirbek and Musaev, Aibek and Pu, Calton},
title = {Leveraging Generative AI for Personalized Learning Experiences},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705038},
doi = {10.1145/3641555.3705038},
abstract = {This demo presents KimBilet.com, an educational platform that utilizes generative AI to create personalized educational content on demand. Catering to high-school and college students, instructors, job seekers, and lifelong learners, the system generates customized courses based on user prompts, covering any topic of interest. Each course may include a sequence of AI-created lessons and quizzes, providing detailed feedback for every quiz option to enhance understanding. The platform supports intuitive navigation through keyboard shortcuts and allows users to jump between course items seamlessly. It also maintains a history of completed quizzes to help users track their learning progress. Future enhancements include topic suggestions based on past interests, support for coding exercises, and multilingual support. This demo will showcase how KimBilet.com leverages AI to offer adaptive learning experiences, engage attendees through interactive exploration, and discuss its potential applications in educational settings. Participants will gain insights into integrating AI-driven tools into teaching and learning processes to address diverse educational needs.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1732},
numpages = {1},
keywords = {AI in education, e-learning tools, educational technology, generative AI, personalized learning},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3638529.3663650,
author = {Walsh, Toby},
title = {Generative AI: why all the fuss?},
year = {2024},
isbn = {9798400704949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638529.3663650},
doi = {10.1145/3638529.3663650},
abstract = {ChatGPT burst into people's lives at the end of 2022, heralding the arrival of large language models in particular, and generative AI in general. How best to see this moment in the development of AI. What is generative AI actually good for? And what are its limitations? And how might we tackle them? In this talk, I'll explore how to understand recent breakthroughs in AI, and discuss what might come next.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {3},
numpages = {1},
keywords = {artificial intelligence, generative AI, large language models, machine learning, knowledge representation},
location = {Melbourne, VIC, Australia},
series = {GECCO '24}
}

@inproceedings{10.1145/3571884.3603756,
author = {Fischer, Joel E},
title = {Generative AI Considered Harmful},
year = {2023},
isbn = {9798400700149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571884.3603756},
doi = {10.1145/3571884.3603756},
abstract = {The recent months have seen an explosion of interest, hype, and concern about generative AI, driven by the release of ChatGPT. In this article I seek to explicate some potential and actual harms of the engineering and use of generative AI such as ChatGPT. With this I also suggest a reframing for researchers with an interest in interaction. With this reframing I seek to provoke researchers to consider studying the settings of ChatGPT development and use as active sites of production. Research should focus on the organisational, technological and interactional practices and contexts in and through which generative AI and its outputs—harmful and otherwise—are produced, by whom, to what end, and with what consequences on societies.},
booktitle = {Proceedings of the 5th International Conference on Conversational User Interfaces},
articleno = {7},
numpages = {5},
keywords = {ChatGPT, GPT-3, GPT-4, LLM, Large Language Models, NLG, NLP, generative AI, natural language, text generation},
location = {Eindhoven, Netherlands},
series = {CUI '23}
}

@inproceedings{10.1145/3677389.3702596,
author = {Chen, Yinlin and Xie, Zhiwu and Yang, Le},
title = {JCDL 2024 Workshop: Generative AI for Resource Discovery in Libraries},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702596},
doi = {10.1145/3677389.3702596},
abstract = {This workshop delves into the transformative role of Generative AI technologies in digital libraries, emphasizing advancements in resource discovery and user engagement. Participants will explore how cutting-edge large language models such as GPT-4 and Llama are leveraged to deliver highly personalized resource recommendations and improve the efficiency and precision of information retrieval processes. Through showcases of capstone projects developed as part of the AI Incubator Program, hands-on sessions, and collaborative discussions, attendees will gain practical insights into deploying AI-driven solutions that streamline library operations and elevate user experience.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {125},
numpages = {2},
keywords = {generative AI, large language model, retrieval-augmented generation},
location = {Hong Kong, China},
series = {JCDL '24}
}

@inbook{10.5555/3716662.3716722,
author = {Kay, Jackie and Kasirzadeh, Atoosa and Mohamed, Shakir},
title = {Epistemic Injustice in Generative AI},
year = {2025},
publisher = {AAAI Press},
abstract = {This paper investigates how generative AI can potentially undermine the integrity of collective knowledge and the processes we rely on to acquire, assess, and trust information, posing a significant threat to our knowledge ecosystem and democratic discourse. Grounded in social and political philosophy, we introduce the concept of generative algorithmic epistemic injustice. We identify four key dimensions of this phenomenon: amplified and manipulative testimonial injustice, along with hermeneutical ignorance and access injustice. We illustrate each dimension with real-world examples that reveal how generative AI can produce or amplify misinformation, perpetuate representational harm, and create epistemic inequities, particularly in multilingual contexts. By highlighting these injustices, we aim to inform the development of epistemically just generative AI systems, proposing strategies for resistance, system design principles, and two approaches that leverage generative AI to foster a more equitable information ecosystem, thereby safeguarding democratic values and the integrity of knowledge production.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {684–697},
numpages = {14}
}

@inproceedings{10.1145/3641032.3641055,
author = {Faccia, Alessio and Ridon, Manjeet and Beebeejaun, Zeenat and Mosteanu, Narcisa Mosteanu Roxana},
title = {Advancements and Challenges of Generative AI in Higher Educational Content Creation A Technical Perspective},
year = {2024},
isbn = {9798400709173},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641032.3641055},
doi = {10.1145/3641032.3641055},
abstract = {Generative Artificial Intelligence (AI) has witnessed remarkable advancements, igniting interest in various domains, including Higher Education. This research paper explores the impacts and challenges of integrating Generative AI in content creation within Higher Education. We utilise a literature review and case study approach to gain insights into the potential benefits and complexities of implementing Generative AI in educational settings. Specific research questions are formulated to investigate the influence of Generative AI on content creation efficiency, productivity, quality, and adaptability. The paper also highlights ethical considerations and the evolving role of educators in the AI-driven educational landscape. Furthermore, the research paper examines the practical applications of Generative AI tools such as OpenAI GPT, GPT-Neo, Hugging Face's Transformers Library, Cognii, MosaChat-AI, TeacherMatic, and OpenAI Codex in Higher Education content creation. This comprehensive analysis aims to provide educators, instructional designers, and policymakers with valuable insights and concrete examples of how Generative AI can be leveraged to create personalised learning materials, improve assessment strategies, and enhance the overall educational experience for students pursuing advanced technical subjects. The culmination of this research presents a vision for a future where Generative AI, thoughtfully implemented and ethically managed, empowers educational institutions to meet the diverse and evolving needs of learners in the digital era.},
booktitle = {Proceedings of the 2023 8th International Conference on Information Systems Engineering},
pages = {48–54},
numpages = {7},
keywords = {Applications, Chat GPT, Generative AI, Higher Education},
location = {Bangkok, Thailand},
series = {ICISE '23}
}

@article{10.5555/3665464.3665476,
author = {Alrifai, Rad},
title = {Using Generative AI to Design Programming Assignments in Introduction to Computer Science},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {Programming stands as an essential requisite in computer science education. Recognizing the challenges students face in learning programming effectively, the proposed assignment aims to integrate generative artificial intelligence (AI) tools to teach students introductory programming constructs. Generative AI has gained an increasing popularity in recent years. Several available Generative AI implementations can now help students learn programming essentials and debugging skills.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {103–106},
numpages = {4}
}

@inproceedings{10.1145/3641555.3705272,
author = {Hooper, Kerrie and Lunn, Stephanie Jill},
title = {Traversing New Horizons: An Exploration of Educational Policies on Generative AI},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705272},
doi = {10.1145/3641555.3705272},
abstract = {Understanding how tertiary academic institutions approach the integration of generative AI (GAI) into their course policies is crucial since AI technologies are rapidly transforming society. AI is being used and applied across sectors and industries, and it is important to do so with regard to ethics. This exploratory study sought to examine how GAI policies were discussed across academic institutions. The policies were analyzed using NLP techniques and utilized existing publicly available datasets, which consisted of a collection of over 100 university policies and syllabi policies. Unsupervised clustering techniques were applied to analyze patterns in how different institutions may express their policies and best practices. These findings illuminate how universities and colleges may approach topics and challenges around AI, and specifically GAI.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1479–1480},
numpages = {2},
keywords = {NLP analysis, academic policies, generative AI},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3685235.3685237,
author = {Deng, Xuefei (Nancy) and Joshi, K.D.},
title = {Promoting Ethical Use of Generative AI in Education},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {3},
issn = {0095-0033},
url = {https://doi.org/10.1145/3685235.3685237},
doi = {10.1145/3685235.3685237},
abstract = {Generative artificial intelligence (AI) represents a crucial subset of AI models characterized by their ability to generate new content based on user input, showing vast potential to transform learning and teaching. However, educators have raised ethical concerns, particularly regarding the adverse effect on students' learning if students simply parrot generative AI-generated content without engaging in critical analysis or original thought. Moreover, there exists the potential of generative AI to perpetuate existing biases in training data. This editorial discusses three major concerns in generative AI use in education and proposes questions (on task-AI fit and people-AI fit) and approaches to address the ethical considerations by adopting five principles of AI ethics. The editorial also discusses developing a classroom AI use policy as one governance mechanism for promoting ethical use of AI. As generative AI technology continues to evolve, so must our educational practices. The editorial ends with a call for readers (educators) to collaboratively define the terms of engagement with generative AI in educational settings and to begin this discourse by sharing insights and experiences with promoting ethical use of generative AI.},
journal = {SIGMIS Database},
month = jul,
pages = {6–11},
numpages = {6},
keywords = {ai ethics, ai use policy, biases, ethical use of ai, generative ai, higher education, normalization of mediocrity, plagiarism, prompt engineering}
}

@article{10.1145/3718098,
author = {Shi, Wenda and Wong, Waikeung and Zou, Xingxing},
title = {Generative AI in Fashion: Overview},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3718098},
doi = {10.1145/3718098},
abstract = {Generative Artificial Intelligence (GenAI) has recently gained immense popularity by offering various applications for generating high-quality and aesthetically pleasing content of image, 3D, and video data format. The innovative GenAI solutions have shifted paradigms across various design-related industries, particularly fashion. In this paper, we explore the incorporation of GenAI into fashion-related tasks and applications. Our examination encompasses a thorough review of more than 470 research papers and an in-depth analysis of over 300 applications, focusing on their contributions to the field. These contributions are identified as 13 tasks within four categories: multi-modal fashion understanding, and fashion synthesis of image, 3D, and dynamic (video and animatable 3D) formats We delve into these methods, recognizing their potential to propel future endeavours toward achieving state-of-the-art (SOTA) performance. Furthermore, we present a comprehensive overview of 53 publicly available datasets suitable for training and benchmarking fashion-centric models, accompanied by the relevant evaluation metrics. Finally, we review real-world applications, unveiling existing challenges and future directions. With comprehensive investigation and in-depth analysis, this paper is targeted to serve as a useful resource for understanding the current landscape of GenAI in fashion, paving the way for future innovations in this dynamic field. Papers discussed in this paper, along with public code and datasets links are available at: .},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = feb
}

@inproceedings{10.1145/3708557.3716363,
author = {Withanage Don, Daksitha Senel and Kiderle, Thomas and Mertes, Silvan and Schiller, Dominik and Ritschel, Hannes and Andr\'{e}, Elisabeth},
title = {MeLaX: Conversations with Generative AI in Socially Interactive Agents},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716363},
doi = {10.1145/3708557.3716363},
abstract = {In this demo paper, we present name, a real-time platform for integrating generative AI technologies within interactive virtual photorealistic agents. The system enables responsive interactions through a modular pipeline, including speech recognition, natural language processing, text-to-speech, and behavior generation, all working in sync to deliver dynamic and emotion-aware agent responses. With its no-code graphical user interface (GUI), name offers an accessible environment for researchers to explore and evaluate advanced human-agent interactions. Supporting diverse model configurations and seamless integration, the platform serves as a comprehensive testbed to advance natural and context-sensitive interactive intelligent virtual agents. Software and further details are available at https://daksitha.github.io/projects/melax/index.html.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {163–166},
numpages = {4},
keywords = {Generative AI, Socially Interactive Agents, Real-Time Systems},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3649405.3659534,
author = {Prather, James and Leinonen, Juho and Kiesler, Natalie and Benario, Jamie Gorson and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Virginia and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and Smith, David H. and Strickroth, Sven and Zingaro, Daniel},
title = {How Instructors Incorporate Generative AI into Teaching Computing},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659534},
doi = {10.1145/3649405.3659534},
abstract = {Generative AI (GenAI) has seen great advancements in the past two years and the conversation around adoption is increasing. Widely available GenAI tools are disrupting classroom practices as they can write and explain code with minimal student prompting. While most acknowledge that there is no way to stop students from using such tools, a consensus has yet to form on how students should use them if they choose to do so. At the same time, researchers have begun to introduce new pedagogical tools that integrate GenAI into computing curricula. These new tools offer students personalized help or attempt to teach prompting skills without undercutting code comprehension. This working group aims to detail the current landscape of education-focused GenAI tools and teaching approaches, present gaps where new tools or approaches could appear, identify good practice-examples, and provide a guide for instructors to utilize GenAI as they continue to adapt to this new era.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {771–772},
numpages = {2},
keywords = {artificial intelligence, generative AI, large language models, pedagogical practices, teaching computing},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3641555.3705121,
author = {Harrington, Brian and Alnoor, Ahmad Zubair and Haqiqi, Pedram and Hoseininia, Zahra and Lin, Kai and Lodi, Maliha and Mirza, Asad and Wolfe, Leah and Zhang, Kevin},
title = {A Systematic Literature Mapping of Early Generative AI Research is CS Education},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705121},
doi = {10.1145/3641555.3705121},
abstract = {The widespread release of generative AI tools has led to a rapid rise in publications evaluating their impact on CS education. While there is no doubt that the area is new and rapidly evolving, it is important to begin to catalogue and map the literature at this early stage. In this work, we systematically search and map 82 papers evaluating the impact of generative AI tools on CS education. We then build a literature map of these papers using the axes of population, use of generative AI, and method of evaluation. This work will serve as both a snapshot of the first generation of generative AI papers in the field, and a road-map for further classification and literature review as the field develops.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1467–1468},
numpages = {2},
keywords = {gen ai, generative ai, large language models, literature map, llm},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706599.3720160,
author = {Xu, Ningning and Liu, Yu and Chen, Yifei and Jiang, Zheyuan and Ren, Yuwei and Zhang, Zhichao and Jia, Bin and Yu, Lingyun},
title = {ArtifactShow: Incorporating Generative AI into Narrative Visualization for Interactive Cultural Experience},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720160},
doi = {10.1145/3706599.3720160},
abstract = {We propose ArtifactShow, an interactive system that engages users in cultural experiences through a series of digital shows powered by generative AI. Current cultural digitization processes rely heavily on labor-intensive efforts to create complex multimedia scenes from vast amounts of cultural data. To address this challenge, we integrate generative AI into narrative visualization, enhancing public understanding of historical and cultural narratives through navigation, exploration, and visual analysis. To evaluate the effectiveness of our system, we conducted user studies with three domain experts and seven volunteers. Our findings suggest that ArtifactShow has significant potential to enhance public knowledge and interest in cultural heritage. Through our exploration, we developed a workflow and design guidelines for using generative AI to construct narrative visualizations for cultural heritage.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {78},
numpages = {8},
keywords = {Cultural Heritage, Data Visualization, Generative AI},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641308.3677393,
author = {Rege, Akshay and Kim, Euiyoung and Kim, Soyeon and Sirkin, David and Currano, Rebecca},
title = {Designing Generative AI User Interfaces for Automobiles},
year = {2024},
isbn = {9798400705205},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641308.3677393},
doi = {10.1145/3641308.3677393},
abstract = {As the development of Generative AI technology continues to progress, the opportunity for innovation with AI in the form of user interfaces, products and services within vehicles is expanding. Furthermore, automobiles are undergoing major transformations in design due to changes in the underlying technology resulting in evolved user needs, behaviors, activities and aspirations. This workshop is aimed at providing the participants hands-on experience of designing novel Generative AI interfaces for vehicles. While working on the design challenge as the connecting thread, we will introduce and weave together modules of knowledge domains focusing on Human-centered design, Ethical and Responsible behavior, and Autonomy in vehicles. Participants will learn about and engage collaboratively in employing design methods such as Co-creation using Activity Canvases, Enactment, Wizard of Oz, Bodystorming and inter-group discussion. As the outcome, we aim to publish participant’s design concepts as a booklet and a research paper, and seek new research collaborations.},
booktitle = {Adjunct Proceedings of the 16th International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
pages = {264–267},
numpages = {4},
keywords = {Automotive User Interfaces, Design Methods for AI, Generative AI, Human-AI Interaction},
location = {Stanford, CA, USA},
series = {AutomotiveUI '24 Adjunct}
}

@inproceedings{10.1145/3613904.3642466,
author = {Weisz, Justin D. and He, Jessica and Muller, Michael and Hoefer, Gabriela and Miles, Rachel and Geyer, Werner},
title = {Design Principles for Generative AI Applications},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642466},
doi = {10.1145/3613904.3642466},
abstract = {Generative AI applications present unique design challenges. As generative AI technologies are increasingly being incorporated into mainstream applications, there is an urgent need for guidance on how to design user experiences that foster effective and safe use. We present six principles for the design of generative AI applications that address unique characteristics of generative AI UX and offer new interpretations and extensions of known issues in the design of AI applications. Each principle is coupled with a set of design strategies for implementing that principle via UX capabilities or through the design process. The principles and strategies were developed through an iterative process involving literature review, feedback from design practitioners, validation against real-world generative AI applications, and incorporation into the design process of two generative AI applications. We anticipate the principles to usefully inform the design of generative AI applications by driving actionable design recommendations.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {378},
numpages = {22},
keywords = {Generative AI, design principles, foundation models, human-centered AI},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3672608.3707992,
author = {Michel, Shira},
title = {Generative AI in Rural High Schools: Challenges and Opportunities},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707992},
doi = {10.1145/3672608.3707992},
abstract = {Recent advancements in Artificial Intelligence (AI) and more recently, Generative AI (GenAI) approaches have introduced both new challenges and opportunities in educational settings; yet, its effect on rural schools, which already face educational inequities, remains unclear. This study employs a mixed-methods approach using surveys and interviews to explore the current and potential roles of GenAI in rural high school classrooms across three U.S. regions. Preliminary findings reveal mixed perceptions: rural teachers value GenAI's ability to personalize learning but worry about encountering misinformation and feel unprepared to mitigate these risks due to their current level of AI literacy. While GenAI offers potential to enhance students' tech skills and reduce resource disparities, barriers like unreliable internet access and a lack of students owning personal devices still hinder its effectiveness, leaving both teachers and students under-supported in fully leveraging the technology. Overall, this study aims to explore rural teachers' experiences with GenAI to help develop strategies for fair and effective integration that address their unique challenges.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {106–108},
numpages = {3},
keywords = {generative AI, K-9-12 education, artificial intelligence},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3706598.3713934,
author = {Chen, Liuqing and Cheang, Wengteng and Jiang, Zhaojun and Xu, Yuan and Cai, Zebin and Sun, Lingyun and Childs, Peter and Han, Ji and Hansen, Preben and Zuo, Haoyu},
title = {I-Card: A Generative AI-Supported Intelligent Design Method Card Deck},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713934},
doi = {10.1145/3706598.3713934},
abstract = {A design method card deck helps designers understand and provoke thinking by presenting each method in a simple format and allow designers to switch between methods seamlessly by maintaining the same simple format across the deck. However, recent observations have shown designers hesitate to use a card deck due to the lack of support, while other tools have provided identified support with generative AI. Through a formative study, we identified the specific support designers need when applying the design method cards and intentions in integrating generative AI. Accordingly, we developed the intelligent design method card deck, I-Card, which integrates generative AI to provide applicable design methods, design knowledge and data support, and interactive and dynamic support. A user study demonstrates that I-Card improved the design efficiency and applicability by offering personalized guidance, enhanced decision-making with comprehensive data generation and provided more design inspiration via interactive support.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {426},
numpages = {22},
keywords = {Design method, design method cards, design cards, generative AI, design support tool},
location = {
},
series = {CHI '25}
}

@article{10.1145/3672277,
author = {Antony, Victor Nikhil and Huang, Chien-Ming},
title = {ID.8: Co-Creating Visual Stories with Generative AI},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {2160-6455},
url = {https://doi.org/10.1145/3672277},
doi = {10.1145/3672277},
abstract = {Storytelling is an integral part of human culture and significantly impacts cognitive and socio-emotional development and connection. Despite the importance of interactive visual storytelling, the process of creating such content requires specialized skills and is labor-intensive. This article introduces ID.8, an open-source system designed for the co-creation of visual stories with generative AI. We focus on enabling an inclusive storytelling experience by simplifying the content creation process and allowing for customization. Our user evaluation confirms a generally positive user experience in domains such as enjoyment and exploration while highlighting areas for improvement, particularly in immersiveness, alignment, and partnership between the user and the AI system. Overall, our findings indicate promising possibilities for empowering people to create visual stories with generative AI. This work contributes a novel content authoring system, ID.8, and insights into the challenges and potential of using generative AI for multimedia content creation.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = aug,
articleno = {20},
numpages = {29},
keywords = {Storytelling, generative AI, creativity}
}

@inproceedings{10.1145/3706599.3719841,
author = {Qu, Xiaodong and Sherwood, Joshua and Liu, Peiyan and Aleisa, Nawwaf},
title = {Generative AI Tools in Higher Education: A Meta-Analysis of Cognitive Impact},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719841},
doi = {10.1145/3706599.3719841},
abstract = {This meta-analysis examines the cognitive impact of Generative Artificial Intelligence (GenAI) tools on college students, focusing on various levels of Bloom’s taxonomy. As GenAI integration in higher education grows, understanding its influence on critical thinking, problem-solving, and creativity is essential. Using a mixed-effects model, we synthesized data from quantitative studies to explore two moderators: cognitive skill level (e.g., understanding, applying, analyzing) and instructional context (instructed vs. unguided use). Our findings indicate that GenAI tools significantly enhance lower-order cognitive outcomes, particularly in understanding and applying concepts, with instructed use producing stronger positive effects than unguided use. However, their impact on higher-order cognitive skills, such as creating and evaluating, was minimal. These results highlight the importance of tailoring GenAI integration to task complexity and underscore the value of guided instruction in maximizing its educational benefits. Educators should prioritize instructional strategies that encourage active engagement with GenAI tools, particularly for fostering critical thinking and creativity.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {302},
numpages = {9},
keywords = {Generative AI, GenAI in education, Bloom’s taxonomy, Education, Meta-analysis},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706598.3713827,
author = {Wagman, Kelly B. and Dearing, Matthew T. and Chetty, Marshini},
title = {Generative AI Uses and Risks for Knowledge Workers in a Science Organization},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713827},
doi = {10.1145/3706598.3713827},
abstract = {Generative AI could enhance scientific discovery by supporting knowledge workers in science organizations. However, the real-world applications and perceived concerns of generative AI use in these organizations are uncertain. In this paper, we report on a collaborative study with a US national laboratory with employees spanning Science and Operations about their use of generative AI tools. We surveyed 66 employees, interviewed a subset (N=22), and measured early adoption of an internal generative AI interface called Argo lab-wide. We have four findings: (1) Argo usage data shows small but increasing use by Science and Operations employees; Common current and envisioned use cases for generative AI in this context conceptually fall into either a (2) copilot or (3) workflow agent modality; and (4) Concerns include sensitive data security, academic publishing, and job impacts. Based on our findings, we make recommendations for generative AI use in science and other organizations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1199},
numpages = {17},
keywords = {generative AI, genAI, artificial intelligence, large language models, LLMs, copilot, workflow agent, agents, future of work, enterprise AI, AI for science, knowledge work, responsible AI, security},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714146,
author = {Prasad, Prajish and Balse, Rishabh and Balchandani, Dhwani},
title = {Exploring Multimodal Generative AI for Education through Co-design Workshops with Students},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714146},
doi = {10.1145/3706598.3714146},
abstract = {Multimodal large language models (MLLMs) are Generative AI models that take different modalities such as text, audio, and video as input and generate appropriate multimodal output. Since such models will be integrated into future educational tools, a human-centered design approach that takes students’ perspectives into account is essential while designing such applications.This paper describes two co-design workshops which were conducted with 79 student groups to examine how they design and prototype future educational tools integrated with MLLMs. Through various activities in the workshops, students discussed relevant educational problems, created journey maps, storyboards and low fidelity prototypes for their applications, and evaluated their applications based on relevant design principles. We found that students’ applications used MLLMs for important learning environment design features such as multimodal content creation, personalization, and feedback. Based on these findings, we discuss future research directions for the design of multimodality in generative AI educational applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {139},
numpages = {17},
keywords = {artificial intelligence, generative AI, large language models, multimodality, co-design, design principles, learning environment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3649405.3659517,
author = {Glassey, Richard and Baltatzis, Alexander},
title = {Active Repos: Integrating Generative AI Workflows into GitHub},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659517},
doi = {10.1145/3649405.3659517},
abstract = {The aim of this work is to describe a simple and cost effective way to integrate generative AI into GitHub to support course specific scenarios. We are motivated by helping teachers realise their creative AI use cases in spite of technical barriers and also to ensure that students have a blessed and fair way to access AI services without needing to sign-up, prompt or pay. First we will describe a scenario that we have implemented for our own CS1 course, then we will describe the technical requirements for implementation. We finish off with our early thoughts on where these types of scenarios might be heading in terms of supporting computing education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {777–778},
numpages = {2},
keywords = {CS1, GitHub actions, automation, generative AI},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3706598.3713504,
author = {G\'{o}mez Ortega, Alejandra and Morales Ornelas, Hosana and Gen\c{c}, U\u{g}ur},
title = {Surrendering to Powerlesness: Governing Personal Data Flows in Generative AI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713504},
doi = {10.1145/3706598.3713504},
abstract = {Personal data flows across digital technologies integrated into people’s lives and relationships. Increasingly, these technologies include Generative AI. (How) should personal data flow into and out of GenAI models? We investigate how people experience personal data collection in GenAI ecosystems and unpack the enablers and barriers to governing their data. We focus on personal data collection by Meta, specifically Instagram, in line with their recent policy update on processing user data to train GenAI models. We conducted semi-structured interviews with 20 Latin American Instagram users, based in Europe and Latin America. We discussed the acceptability of their data flowing in and out of GenAI models through different scenarios. Our results interrogate power dynamics in data collection, the (inter)personal nature of data, and the multiple unknowns concerning data and their algorithmic derivatives. We pose provocations around feelings of powerlessness, reframing (inter)personal data, and encountering unknown data and algorithms through design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {232},
numpages = {18},
keywords = {Personal Data; Sensitive Data; Privacy; Data Governance; Generative AI; Social Media;},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3654777.3676451,
author = {Zhang, Lei and Pan, Jin and Gettig, Jacob and Oney, Steve and Guo, Anhong},
title = {VRCopilot: Authoring 3D Layouts with Generative AI Models in VR},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676451},
doi = {10.1145/3654777.3676451},
abstract = {Immersive authoring provides an intuitive medium for users to create 3D scenes via direct manipulation in Virtual Reality (VR). Recent advances in generative AI have enabled the automatic creation of realistic 3D layouts. However, it is unclear how capabilities of generative AI can be used in immersive authoring to support fluid interactions, user agency, and creativity. We introduce VRCopilot, a mixed-initiative system that integrates pre-trained generative AI models into immersive authoring to facilitate human-AI co-creation in VR. VRCopilot presents multimodal interactions to support rapid prototyping and iterations with AI, and intermediate representations such as wireframes to augment user controllability over the created content. Through a series of user studies, we evaluated the potential and challenges in manual, scaffolded, and automatic creation in immersive authoring. We found that scaffolded creation using wireframes enhanced the user agency compared to automatic creation. We also found that manual creation via multimodal specification offers the highest sense of creativity and agency.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {96},
numpages = {13},
keywords = {Generative AI, Human-AI Co-creation, Virtual Reality},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@article{10.1145/3713075,
author = {El Saddik, Abdulmotaleb and Ahmad, Jamil and Khan, Mustaqeem and Abouzahir, Saad and Gueaieb, Wail},
title = {Unleashing Creativity in the Metaverse: Generative AI and Multimodal Content},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3713075},
doi = {10.1145/3713075},
abstract = {The Metaverse presents an emerging creative expression and collaboration frontier where generative artificial intelligence (GenAI) can play a pivotal role with its ability to generate multimodal content from simple prompts. These prompts allow the metaverse to interact with GenAI, where context information, instructions, input data, or even output indications constituting the prompt can come from within the metaverse. However, their integration poses challenges regarding interoperability, lack of standards, scalability, and maintaining a high-quality user experience. This paper explores how GenAI can productively assist in enhancing creativity within the contexts of the Metaverse and unlock new opportunities. We provide a technical, in-depth overview of the different generative models for image, video, audio, and 3D content within the Metaverse environments. We also explore the bottlenecks, opportunities, and innovative applications of GenAI from the perspectives of end users, developers, service providers, and AI researchers. This survey commences by highlighting the potential of GenAI for enhancing the Metaverse experience through dynamic content generation to populate massive virtual worlds. Subsequently, we shed light on the ongoing research practices and trends in multimodal content generation, enhancing realism and creativity and alleviating bottlenecks related to standardization, computational cost, privacy, and safety. Lastly, we share insights into promising research directions toward the integration of GenAI with the Metaverse for creative enhancement, improved immersion, and innovative interactive applications.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = jan,
keywords = {Generative AI, Metaverse, Diffusion Models, Generative Adversarial Networks, Multimodal, Content Generation}
}

@inproceedings{10.1145/3657604.3664657,
author = {Chen, Xiuyu and Feng, Shihui},
title = {Analyzing Students' Information Behavior in Generative AI-Supported Small Group Discussions},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664657},
doi = {10.1145/3657604.3664657},
abstract = {Generative artificial intelligence (AI) tools utilize machine learning models to create new content in response to human-provided prompts, which can automate the creation of large amounts of content in a short time. This study analyzed students' information behavior in small group discussions where the students were encouraged to use generative AI tools. Descriptive and lag sequential analysis methods were employed to examine the characteristics and patterns of students' information behavior according to Ellis' model of information seeking. The results indicated that although students frequently used generative AI tools as primary information sources, they also sought additional resources to satisfy their informational needs. Additionally, students sometimes copied and pasted useful information from generative AI tools into group documents to share with their group members. Lag sequential analysis revealed that students typically began their information seeking process with generative AI tools, followed by exploring additional information sources.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {325–329},
numpages = {5},
keywords = {chatgpt, ellis model, generative ai, information seeking},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3706598.3713799,
author = {Kyi, Lin and Mahuli, Amruta and Silberman, M. Six and Binns, Reuben and Zhao, Jun and Biega, Asia J.},
title = {Governance of Generative AI in Creative Work: Consent, Credit, Compensation, and Beyond},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713799},
doi = {10.1145/3706598.3713799},
abstract = {Since the emergence of generative AI, creative workers have spoken up about the career-based harms they have experienced arising from this new technology. A common theme in these accounts of harm is that generative AI models are trained on workers’ creative output without their consent and without giving credit or compensation to the original creators.This paper reports findings from 20 interviews with creative workers in three domains: visual art and design, writing, and programming. We investigate the gaps between current AI governance strategies, what creative workers want out of generative AI governance, and the nuanced role of creative workers’ consent, compensation and credit for training AI models on their work. Finally, we make recommendations for how generative AI can be governed and how operators of generative AI systems might more ethically train models on creative output in the future.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {197},
numpages = {16},
keywords = {3 Cs (Consent, Credit, and Compensation), AI governance, AI regulation, Generative AI, Creative work, Knowledge work},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714286,
author = {Wang, Yimeng and Wang, Yinzhou and Crace, Kelly and Zhang, Yixuan},
title = {Understanding Attitudes and Trust of Generative AI Chatbots for Social Anxiety Support},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714286},
doi = {10.1145/3706598.3714286},
abstract = {Social anxiety (SA) has become increasingly prevalent. Traditional coping strategies often face accessibility challenges. Generative AI (GenAI), known for their knowledgeable and conversational capabilities, are emerging as alternative tools for mental well-being. With the increased integration of GenAI, it is important to examine individuals’ attitudes and trust in GenAI chatbots’ support for SA. Through a mixed-method approach that involved surveys (n = 159) and interviews (n = 17), we found that individuals with severe symptoms tended to trust and embrace GenAI chatbots more readily, valuing their non-judgmental support and perceived emotional comprehension. However, those with milder symptoms prioritized technical reliability. We identified factors influencing trust, such as GenAI chatbots’ ability to generate empathetic responses and its context-sensitive limitations, which were particularly important among individuals with SA. We also discuss the design implications and use of GenAI chatbots in fostering cognitive and emotional trust, with practical and design considerations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1123},
numpages = {21},
keywords = {social anxiety, generative AI, trust, mixed methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706599.3720135,
author = {Fabre, \'{E}milie and Seaborn, Katie and Koiwai, Shuta and Watanabe, Mizuki and Riesch, Paul},
title = {More-than-Human Storytelling: Designing Longitudinal Narrative Engagements with Generative AI},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720135},
doi = {10.1145/3706599.3720135},
abstract = {Longitudinal engagement with generative AI (GenAI) storytelling agents is a timely but less charted domain. We explored multi-generational experiences with “Dreamsmithy,” a daily dream-crafting app, where participants (N = 28) co-created stories with AI narrator “Makoto” every day. Reflections and interactions were captured through a two-week diary study. Reflexive thematic analysis revealed themes likes “oscillating ambivalence” and “socio-chronological bonding,” highlighting the complex dynamics that emerged between individuals and the AI narrator over time. Findings suggest that while people appreciated the personal notes, opportunities for reflection, and AI creativity, limitations in narrative coherence and control occasionally caused frustration. The results underscore the potential of GenAI for longitudinal storytelling, but also raise critical questions about user agency and ethics. We contribute initial empirical insights and design considerations for developing adaptive, more-than-human storytelling systems.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {405},
numpages = {10},
keywords = {Generative AI, Large Language Models, ChatGPT, Storytelling, Longitudinal Study, Field Study, Voice Agent, User Experience},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3613905.3636294,
author = {Muller, Michael and Kantosalo, Anna and Maher, Mary Lou and Martin, Charles Patrick and Walsh, Greg},
title = {GenAICHI 2024: Generative AI and HCI at CHI 2024},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636294},
doi = {10.1145/3613905.3636294},
abstract = {This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI), and - among other approaches - particularly to Large Language Models (LLMs) and Foundation Models (FMs). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together. Following successful workshops in 2022 and 2023, we convene the interdisciplinary research domain of generative AI and HCI. Participation in this invitational workshop is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {470},
numpages = {7},
keywords = {Bias, Design, Generative AI, Uncertainty.},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3663384.3663393,
author = {Feldman, Molly Q and Anderson, Carolyn Jane},
title = {Non-Expert Programmers in the Generative AI Future},
year = {2024},
isbn = {9798400710179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663384.3663393},
doi = {10.1145/3663384.3663393},
abstract = {Generative AI is rapidly transforming the practice of programming. At the same time, our understanding of who writes programs, for what purposes, and how they program, has been evolving. By facilitating natural-language-to-code interactions, large language models for code have the potential to open up programming work to a broader range of workers. While existing work finds productivity benefits for expert programmers, interactions with non-experts are less well-studied. In this paper, we consider the future of programming for non-experts through a controlled study of 67 non-programmers. Our study reveals multiple barriers to effective use of large language models of code for non-experts, including several aspects of technical communication. Comparing our results to a prior study of beginning programmers illuminates the ways in which a traditional introductory programming class does and does not equip students to effectively work with generative AI. Drawing on our empirical findings, we lay out a vision for how to empower non-expert programmers to leverage generative AI for a more equitable future of programming.},
booktitle = {Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {15},
numpages = {19},
keywords = {CS1, Code LLMs, Generative AI, mixed methods, non-experts},
location = {Newcastle upon Tyne, United Kingdom},
series = {CHIWORK '24}
}

@article{10.5555/3711988.3711989,
author = {Tham, Jason},
title = {Teaching UX: Amid the Hype of Generative AI},
year = {2025},
issue_date = {November 2024},
publisher = {Usability Professionals' Association},
address = {Bloomingdale, IL},
volume = {20},
number = {1},
issn = {1931-3357},
abstract = {I am a faculty member in a technical communication program at a comprehensive research university. Recently, I have been inundated with questions, concerns, and critiques about the rise of augmentation technologies in writing and design processes, particularly generative artificial intelligence (AI) tools that support chat-based text generation and text-to-image production. I'm sure many UX researchers and designers face similar issues in their work. It remains unclear how generative AI should fit into existing workflow or design processes. Common questions include these:• How does AI work? What can it do? Is it free?• Is it cheating if I use AI to produce content?• Who is responsible for the quality of AI-generated content?• To what extent can I outsource my routine work to AI? In other words, what's an acceptable threshold for using AI before it is considered too much?Specific to UX is the value (cost and labor versus gains and effects) of generative AI in the research and design of user-centered products. Students in my UX courses are increasingly worried about the presence of AI and, consequently, the relevance of their developing skill sets in UX. Educators are growing wary about the presence of AI in the context of teaching and learning; many form partially informed decisions on academic policies for AI usage.},
journal = {J. User Exper.},
month = feb,
pages = {1–8},
numpages = {8}
}

@inproceedings{10.1145/3649409.3691073,
author = {Barendsen, Erik and Lonati, Violetta and Quille, Keith and Altin, Rukiye and Divitini, Monica and Hooshangi, Sara and Karnalim, Oscar and Kiesler, Natalie and Melton, Madison and Suero Montero, Calkin and Morpurgo, Anna},
title = {AI in and for K-12 Informatics Education. Life after Generative AI.},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691073},
doi = {10.1145/3649409.3691073},
abstract = {The use and adoption of Generative AI (GenAI) has revolutionised various sectors, including computing education. However, this narrow focus comes at a cost to the wider AI in and for educational research. This working group aims to explore current trends and explore multiple sources of information to identify areas of AI research in K-12 informatics education that are being underserved but needed in the post-GenAI AI era. Our research focuses on three areas: curriculum, teacher-professional learning and policy. The denouement of this aims to identify trends and shortfalls for AI in and for K-12 informatics education. We will systematically review the current literature to identify themes and emerging trends in AI education at K-12. This will be done under two facets, curricula and teacher-professional learning. In addition, we will conduct interviews and surveys with educators and AI experts. Next, we will examine the current policy (such as the European AI Act, and European Commission guidelines on the use of AI and data in education and training as well as international counterparts). Policies are often developed by both educators and experts in the domain, thus providing a source of topics or areas that may be added to our findings. Finally, by synthesising insights from educators, AI experts, and policymakers, as well as the literature and policy, our working group seeks to highlight possible future trends and shortfalls.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {279–280},
numpages = {2},
keywords = {AI, GenAI, K-12, curricula, generative AI, informatics},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3643834.3661614,
author = {Capel, Tara and Ploderer, Bernd and Bircanin, Filip and Hanmer, Simon and Yates, Jamie Paige and Wang, Jiaxuan and Khor, Kai Ling and Leong, Tuck Wah and Wadley, Greg and Newcomb, Michelle},
title = {Studying Self-Care with Generative AI Tools: Lessons for Design},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661614},
doi = {10.1145/3643834.3661614},
abstract = {The rise of generative AI presents new opportunities for the understanding and practice of self-care through its capability to generate varied content, including self-care suggestions via text and images, and engage in dialogue with users over time. However, there are also concerns about accuracy and trustworthiness of self-care advice provided via AI. This paper reports our findings from workshops, diaries, and interviews with five researchers and 24 participants to explore their experiences and use of generative AI for self-care. We analyze our findings to present a framework for the use of generative AI to support five types of self-care, – advice seeking, mentorship, resource creation, social simulation, and therapeutic self-expression – mapped across two dimensions – expertise and modality. We discuss how these practices shift the role of technologies for self-care from merely offering information to offering personalized advice and supporting creativity for reflection, and we offer suggestions for using the framework to investigate new self-care designs.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {1620–1637},
numpages = {18},
keywords = {Self-care, generative AI, human-AI interaction},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3686397.3686407,
author = {Islam, Mohammad Shafiqul and Sutton, Sara and Rafiq, Rahat Ibn},
title = {A Generative AI Powered Approach to Cyberbullying Detection},
year = {2024},
isbn = {9798400717345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686397.3686407},
doi = {10.1145/3686397.3686407},
booktitle = {Proceedings of the 2024 8th International Conference on Information System and Data Mining},
pages = {57–63},
numpages = {7},
keywords = {Cyberbullying, Generative AI, Large Language Model},
location = {
},
series = {ICISDM '24}
}

@inproceedings{10.1145/3641554.3701785,
author = {Ramirez Osorio, Valeria and Zavaleta Bernuy, Angela and Simion, Bogdan and Liut, Michael},
title = {Understanding the Impact of Using Generative AI Tools in a Database Course},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701785},
doi = {10.1145/3641554.3701785},
abstract = {Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) have led to changes in educational practices by creating opportunities for personalized learning and immediate support. Computer science student perceptions and behaviors towards GenAI tools have been studied, but the effects of such tools on student learning have yet to be determined conclusively. We investigate the impact of GenAI tools on computing students' performance in a database course and aim to understand why students use GenAI tools in assignments. Our mixed-methods study (N=226) asked students to self-report whether they used a GenAI tool to complete a part of an assignment and why. Our results reveal that students utilizing GenAI tools performed better on the assignment part in which LLMs were permitted but did worse in other parts of the assignment and in the course overall. Also, those who did not use GenAI tools viewed more discussion board posts and participated more than those who used ChatGPT. This suggests that using GenAI tools may not lead to better skill development or mental models, at least not if the use of such tools is unsupervised, and that engagement with official course help supports may be affected. Further, our thematic analysis of reasons for using or not using GenAI tools, helps understand why students are drawn to these tools. Shedding light into such aspects empowers instructors to be proactive in how to encourage, supervise, and handle the use or integration of GenAI into courses, fostering good learning habits.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {959–965},
numpages = {7},
keywords = {computing education, databases, generative artificial intelligence, large language models, student behavior, student performance},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3636517.3636522,
author = {Crandall, Aaron S. and Sprint, Gina and Fischer, Bryan},
title = {Generative Pre-Trained Transformer (GPT) Models as a Code Review Feedback Tool in Computer Science Programs},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {1},
issn = {1937-4771},
abstract = {Undergraduate computer science and software engineering students benefit significantly from in-depth reviews of their code early and often in their courses. Performing these reviews is time-consuming for teaching assistants and professors to complete, consequently impacting the timeliness and consistency of the provided feedback. When code feedback is not delivered close to the time of authorship, the utility of the review for students is diminished. Prior work with Automatic Static Analysis Tools has shown promise at using artificial intelligence to automate code reviews, with some success integrating them into classroom environments. To leverage new advances in Generative Pre-Trained Transformer (GPT) models, this work reports on an Automatic Review Tool (ART) to provide timely, automatically generated code reviews. ART was evaluated in a second-semester computer science course by integrating ART into the course's Github-based assignment submission system. A cohort of student volunteers (N = 74) read the ART reviews and provided feedback using a survey spanning two of their course assignments. The results of this pilot study show that students perceived ART was successful at detecting defects and offering style-based suggestions, and students were receptive to receiving future automated reviews of their work.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {38–47},
numpages = {10}
}

@inproceedings{10.1145/3716895.3716985,
author = {Li, Ping and Li, Yue and Yin, Xiyang},
title = {Generative AI in Auto Driving Dilemmas: The Discrepancies of AI and Human in Moral Judgments},
year = {2025},
isbn = {9798400718007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716895.3716985},
doi = {10.1145/3716895.3716985},
abstract = {This current research aimed to investigate the discrepancies in moral judgments between generative AI chatbots and humans in the context of auto driving dilemmas. Through experiments, the study compares the moral judgments and purchase intentions of humans and chatbots regarding auto driving behaviors. The data show that the behavioral orientation of auto vehicles has a significant impact. Compared to deontological-oriented auto vehicles, participants give lower moral blame to utilitarian-oriented ones, consider them to have a smaller degree of wrong, and have a higher level of acceptance. At the same time, the moral blame and wrong ratings received by AI in both utilitarian and deontological scenarios are significantly lower than those of adults, while the moral acceptance rating it obtains is significantly higher. However, in terms of purchase intention, there is no significant difference in the willingness to purchase auto vehicles with either utilitarian or deontological orientations. The findings of this study are of great significance for the design of the decision-making system of auto vehicles, understanding the public's expectations, and promoting the development and application of auto driving technology.},
booktitle = {Proceedings of the 5th International Conference on Artificial Intelligence and Computer Engineering},
pages = {506–509},
numpages = {4},
keywords = {Auto Driving, Computational Social Psychology, Generative AI, Moral Dilemmas},
location = {
},
series = {ICAICE '24}
}

@inproceedings{10.1145/3674912.3674922,
author = {Weerakoon, Oshani and Lepp\"{a}nen, Ville and M\"{a}kil\"{a}, Tuomas},
title = {Enhancing Pedagogy with Generative AI: Video Production from Course Descriptions},
year = {2024},
isbn = {9798400716843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674912.3674922},
doi = {10.1145/3674912.3674922},
abstract = {This paper explores a novel workflow that integrates Generative AI tools, ChatGPT and DALL·E, into educational use, aiming to improve the traditional teaching methods in university education. Our workflow is focused on creating short introductory videos for university courses, using primary course descriptions available in the university’s study guide with the idea of introducing courses visually. This approach was deliberately selected for experimentation, and we believe that it could be further enhanced to generate course videos on specific course topics. This will minimize the efforts of teachers who are required to produce detailed course videos as a part of their teaching. As the first part of our workflow, we present a tool that utilizes ChatGPT-4 and DALL·E 2 to autonomously generate a script and background graphics for videos, using primary course descriptions extracted through a given course web URL. As the second part of the workflow, we combine those generated artefacts into videos using Narakeet, a Text-to-Speech software service that is available online. To analyze the feasibility of this workflow, we then conducted a field survey where university teachers participated in reviewing introductory course videos of their courses generated through our workflow. We employed only engineering courses that are English-taught in this field survey. The results demonstrate the potential of AI-generated content to increase the efficiency of teachers when creating video materials. However, challenges such as the uncanny valley effect in text-to-speech narration and the propensity for AI-generated misinformation highlight the need for careful review by humans on such content before setting it for wider use. This paper argues for the strategic integration of AI in university education, focusing on the benefits, while acknowledging the limitations owned by generative AI tools.},
booktitle = {Proceedings of the International Conference on Computer Systems and Technologies 2024},
pages = {249–255},
numpages = {7},
keywords = {AI in Education, ChatGPT, DALL·E, Generative AI, Pedagogical Tools},
location = {Ruse, Bulgaria},
series = {CompSysTech '24}
}

@inproceedings{10.1145/3706599.3719991,
author = {Anderson, Torin and Niu, Shuo},
title = {Making AI-Enhanced Videos: Analyzing Generative AI Use Cases in YouTube Content Creation},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719991},
doi = {10.1145/3706599.3719991},
abstract = {Generative AI (GenAI) tools enhance social media video creation by streamlining tasks such as scriptwriting, visual and audio generation, and editing. These tools enable the creation of new content, including text, images, audio, and video, with platforms like ChatGPT and MidJourney becoming increasingly popular among YouTube creators. Despite their growing adoption, knowledge of their specific use cases across the video production process remains limited. This study analyzes 274 YouTube how-to videos to explore GenAI’s role in planning, production, editing, and uploading. The findings reveal that YouTubers use GenAI to identify topics, generate scripts, create prompts, and produce visual and audio materials. Additionally, GenAI supports editing tasks like upscaling visuals and reformatting content while also suggesting titles and subtitles. Based on these findings, we discuss future directions for incorporating GenAI to support various video creation tasks.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {388},
numpages = {7},
keywords = {Generative AI; YouTube; video; content creator},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706468.3706531,
author = {Thomas, Danielle R and Borchers, Conrad and Kakarla, Sanjit and Lin, Jionghao and Bhushan, Shambhavi and Guo, Boyuan and Gatz, Erin and Koedinger, Kenneth R},
title = {Do Tutors Learn from Equity Training and Can Generative AI Assess It?},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706531},
doi = {10.1145/3706468.3706531},
abstract = {Equity is a core concern of learning analytics. However, applications that teach and assess equity skills, particularly at scale are lacking, often due to barriers in evaluating language. Advances in generative AI via large language models (LLMs) are being used in a wide range of applications, with this present work assessing its use in the equity domain. We evaluate tutor performance within an online lesson on enhancing tutors’ skills when responding to students in potentially inequitable situations. We apply a mixed-method approach to analyze the performance of 81 undergraduate remote tutors. We find marginally significant learning gains with increases in tutors’ self-reported confidence in their knowledge in responding to middle school students experiencing possible inequities from pretest to posttest. Both GPT-4o and GPT-4-turbo demonstrate proficiency in assessing tutors ability to predict and explain the best approach. Balancing performance, efficiency, and cost, we determine that few-shot learning using GPT-4o is the preferred model. This work makes available a dataset of lesson log data, tutor responses, rubrics for human annotation, and generative AI prompts. Future work involves leveling the difficulty among scenarios and enhancing LLM prompts for large-scale grading and assessment.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {505–515},
numpages = {11},
keywords = {Tutor Training, Generative AI, Large Language Models, Assessment, Equity},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3613905.3636273,
author = {Grudin, Jonathan and Brinkman, Donald},
title = {HCI History and the Trajectory to Generative AI},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636273},
doi = {10.1145/3613905.3636273},
abstract = {This course examines HCI history broadly, then conversational AI history from ELIZA to generative AI. A study of an LLM predecessor illuminates possibilities. With rapid change comes rising uncertainty. Not all history is relevant, but unchanging human nature abides. Some digital dreams become digital nightmares. Social media can deliver disinformation, malware, negative self-image, and polarization that undermines communities. Generative AI provides value but raises employment and career questions, education challenges, and empowers bad actors. We benefit from understanding the forces, the trajectories that brought us here, and how unanticipated consequences arose. Past events that shaped the present have become evident.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {597},
numpages = {3},
keywords = {Conversational Agents, Design, Future, Generative AI, HCI, History, Human Factors, Information Science, Information Systems},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@article{10.5555/3715622.3715630,
author = {Lindoo, Ed and Lotfy, Mohamed},
title = {Generative AI and its Impact on the CS Classroom and Programmers},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {2},
issn = {1937-4771},
abstract = {As the integration of generative artificial intelligence (AI) in educational settings becomes more widespread, students, teachers, and educational institutions face the challenge of utilizing these technologies in a responsible manner. The responsible use of generative AI can help CS and IT students develop critical thinking, enhance their learning experience, facilitate the learning process, can assist in understanding code concepts, programming skills, and/or enhancing the programming knowledge. The aim of this investigation is on how students might utilize, and potentially abuse, generative AI. In this paper we provide examples of how generative AI can be used to generate code modules. We discuss the use of generative AI in programming classes as well as its impact on the future of programming and programmers.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {35–50},
numpages = {16}
}

@inproceedings{10.1145/3706598.3713397,
author = {Lin, David Chuan-En and Kang, Hyeonsu B. and Martelaro, Nikolas and Kittur, Aniket and Chen, Yan-Ying and Hong, Matthew K.},
title = {Inkspire: Supporting Design Exploration with Generative AI through Analogical Sketching},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713397},
doi = {10.1145/3706598.3713397},
abstract = {With recent advancements in the capabilities of Text-to-Image (T2I) AI models, product designers have begun experimenting with them in their work. However, T2I models struggle to interpret abstract language and the current user experience of T2I tools can induce design fixation rather than a more iterative, exploratory process. To address these challenges, we developed Inkspire, a sketch-driven tool that supports designers in prototyping product design concepts with analogical inspirations and a complete sketch-to-design-to-sketch feedback loop. To inform the design of Inkspire, we conducted an exchange session with designers and distilled design goals for improving T2I interactions. In a within-subjects study comparing Inkspire to ControlNet, we found that Inkspire supported designers with more inspiration and exploration of design ideas, and improved aspects of the co-creative process by allowing designers to effectively grasp the current state of the AI to guide it towards novel design intentions.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {427},
numpages = {18},
keywords = {generative AI, sketching, iterative design, co-creative design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3658619.3658627,
author = {Kharrufa, Ahmed and Johnson, Ian},
title = {The Potential and Implications of Generative AI on HCI Education},
year = {2024},
isbn = {9798400716591},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658619.3658627},
doi = {10.1145/3658619.3658627},
abstract = {Generative AI (GAI) is impacting teaching and learning directly or indirectly across a range of subjects and disciplines. As educators, we need to understand the potential and limitations of AI in HCI education and ensure our graduating HCI students are aware of the potential and limitations of AI in HCI. In this paper, we report on the main pedagogical insights gained from the inclusion of generative AI into a 10-week undergraduate module. We designed the module to encourage student experimentation with GAI models as part of the design brief requirement and planned practical sessions and discussions. Our insights are based on replies to a survey sent out to the students after completing the module. Our key findings, for HCI educators, report on the use of AI as a persona for developing project ideas and creating resources for design, and AI as a mirror for reflecting students’ understanding of key concepts and ideas and highlighting knowledge gaps. We also discuss potential pitfalls that should be considered and the need to assess students’ literacies and assumptions of GAIs as pedagogical tools. Finally, we put forward the case for educators to take the opportunities GAI presents as an educational tool and be experimental, creative, and courageous in their practice. We end with a discussion of our findings in relation to the TPACK framework in HCI.},
booktitle = {Proceedings of the 6th Annual Symposium on HCI Education},
articleno = {10},
numpages = {8},
keywords = {GAI, Gen AI, Generative AI, HCI Education, Pedagogy, TPACK},
location = {New York, NY, USA},
series = {EduCHI '24}
}

@inproceedings{10.1145/3641554.3701859,
author = {Gorson Benario, Jamie and Marroquin, Jenn and Chan, Monica M. and Holmes, Ernest D.V. and Mejia, Daniel},
title = {Unlocking Potential with Generative AI Instruction: Investigating Mid-level Software Development Student Perceptions, Behavior, and Adoption},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701859},
doi = {10.1145/3641554.3701859},
abstract = {Generative AI tools are rapidly evolving and impacting many domains, including programming. Computer Science (CS) instructors must address student access to these tools. While some advocate to ban the tools entirely, others suggest embracing them so that students develop the skills for utilizing the tools safely and responsibly. Studies indicate positive impacts, as well as cautions, on student outcomes when these tools are integrated into courses. We studied the impact of incorporating instruction on industry-standard generative AI tools into a mid-level software development course with students from 16 Minority Serving Institutions. 89% of student participants used generative AI tools prior to the course without any formal instruction. After formal instruction, students most frequently used generative AI tools for explaining concepts and learning new things. Students generally reported positive viewpoints on their ability to learn to program and learn problem-solving skills while using generative AI tools. Finally, we found that students: reported to understand their code when they work with generative AI tools, are critical about the outputs that generative AI tools provide, and check outputs of generative AI tools to ensure accuracy.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {395–401},
numpages = {7},
keywords = {cs education, generative ai, llms in cs education, minority serving institutions},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3630106.3658987,
author = {Wolfe, Robert and Mitra, Tanushree},
title = {The Impact and Opportunities of Generative AI in Fact-Checking},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658987},
doi = {10.1145/3630106.3658987},
abstract = {Generative AI appears poised to transform white collar professions, with more than 90% of Fortune 500 companies using OpenAI’s flagship GPT models, which have been characterized as “general purpose technologies” capable of effecting epochal changes in the economy. But how will such technologies impact organizations whose job is to verify and report factual information, and to ensure the health of the information ecosystem? To investigate this question, we conducted 30 interviews with N=38 participants working at 29 fact-checking organizations across six continents, asking about how they use generative AI and the opportunities and challenges they see in the technology. We found that uses of generative AI envisioned by fact-checkers differ based on organizational infrastructure, with applications for quality assurance in Editing, for trend analysis in Investigation, and for information literacy in Advocacy. We used the TOE framework to describe participant concerns ranging from the Technological (lack of transparency), to the Organizational (resource constraints), to the Environmental (uncertain and evolving policy). Building on the insights of our participants, we describe value tensions between fact-checking and generative AI, and propose a novel Verification dimension to the design space of generative models for information verification work. Finally, we outline an agenda for fairness, accountability, and transparency research to support the responsible use of generative AI in fact-checking. Throughout, we highlight the importance of human infrastructure and labor in producing verified information in collaboration with AI. We expect that this work will inform not only the scientific literature on fact-checking, but also contribute to understanding of organizational adaptation to a powerful but unreliable new technology.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1531–1543},
numpages = {13},
keywords = {Design, Fact-Checking, Generative AI, Sociotechnical Infrastructure, Transparency},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3641555.3705076,
author = {Chen, Matt},
title = {Early Adoption of Custom Generative AI Bots in Online Forums for CS Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705076},
doi = {10.1145/3641555.3705076},
abstract = {This lightning talk presents insights from a pilot program in an IT Faculty, where custom generative AI bots were integrated into online forums across 20 courses over two semesters in 2024. The AI bots were trained on specific course content and past student questions to provide tailored responses to student inquiries, with all responses reviewed by teaching staff before being released to students.This approach, distinct from the direct use of large language models (LLMs) like ChatGPT or Claude, offers targeted information aligned with course material and ensures accuracy while preventing the disclosure of assignment answers. The mechanism is designed to support large computer science courses, including first-year courses with over 1,000 students, where timely and comprehensive staff responses can be challenging.This talk will explore the benefits and drawbacks of using generative AI bots in the CS context. It will also examine the factors influencing staff acceptance and trust in chatbot responses and how AI impacts the types and quality of student questions in forums. Key lessons learned and challenges encountered during the program's implementation will also be shared.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1739},
numpages = {1},
keywords = {custom AI integration, generative AI bots},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3658619.3658628,
author = {Maceli, Monica and Smith, Nancy and Bhakta, Gatha},
title = {Incorporating Unanticipated Uses of Generative AI into HCI Education},
year = {2024},
isbn = {9798400716591},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658619.3658628},
doi = {10.1145/3658619.3658628},
abstract = {The list of generative AI tools is ever-expanding, as is the hype around such systems. Many such tools are oriented towards augmenting or complementing the existing work of designers. Tools such as Midjourney and others provide features that easily fit into the long-standing processes, research, and creative work currently done by interface designers. For example, generative AI tools may speed the process of developing and iterating on interface prototypes. However, as happens with all technologies when acquiring broader use, these systems are being creatively repurposed.Of interest to the EduCHI community are those unanticipated uses that serve to contribute to user experience design and research in novel, unexpected ways. This position paper provides an overview of existing generative AI tools, their intended purpose, and their unanticipated uses within the design and research process, as evidenced by a brief review of related literature and selected classroom examples. This position paper aims to pose questions relevant to CHI educators, namely how can these possibilities be woven into existing courses? How might our students contribute to these creative approaches and at what level of maturity shall these tools and techniques be presented alongside more traditional methods? Lastly, we raise ethical questions about the use of these tools and highlight the challenges of using them in the context of design.},
booktitle = {Proceedings of the 6th Annual Symposium on HCI Education},
articleno = {5},
numpages = {7},
keywords = {Human-computer interaction education, artificial intelligence, generative ai},
location = {New York, NY, USA},
series = {EduCHI '24}
}

@article{10.1145/3689372,
author = {Jaidka, Kokil and Chen, Tsuhan and Chesterman, Simon and Hsu, Wynne and Kan, Min-Yen and Kankanhalli, Mohan and Lee, Mong Li and Seres, Gyula and Sim, Terence and Taeihagh, Araz and Tung, Anthony and Xiao, Xiaokui and Yue, Audrey},
title = {Misinformation, Disinformation, and Generative AI: Implications for Perception and Policy},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
url = {https://doi.org/10.1145/3689372},
doi = {10.1145/3689372},
abstract = {The emergence of generative artificial intelligence (GenAI) has exacerbated the challenges of misinformation, disinformation, and mal-information (MDM) within digital ecosystems. These multi-faceted challenges demand a re-evaluation of the digital information lifecycle and a deep understanding of its social impact. An interdisciplinary strategy integrating insights from technology, social sciences, and policy analysis is crucial to address these issues effectively. This article introduces a three-tiered framework to scrutinize the lifecycle of GenAI-driven content from creation to consumption, emphasizing the consumer perspective. We examine the dynamics of consumer behavior that drive interactions with MDM, pinpoints vulnerabilities in the information dissemination process, and advocates for adaptive, evidence-based policies. Our interdisciplinary methodology aims to bolster information integrity and fortify public trust, equipping digital societies to manage the complexities of GenAI and proactively address the evolving challenges of digital misinformation. We conclude by discussing how GenAI can be leveraged to combat MDM, thereby creating a reflective cycle of technological advancement and mitigation.},
journal = {Digit. Gov.: Res. Pract.},
month = feb,
articleno = {11},
numpages = {15},
keywords = {Misinformation, disinformation, trust, resilience, generative AI, social media}
}

@inproceedings{10.1145/3723010.3723012,
author = {Borghoff, Uwe M. and Minas, Mark and Schopp, Jannis},
title = {Generative AI in Student Software Development Projects: A User Study on Experiences and Self-Assessment},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723012},
doi = {10.1145/3723010.3723012},
abstract = {The way software is developed is changing rapidly due to the general availability of generative AI tools. As a result, the software engineering education that is part of every computer science program needs to change. Especially in software engineering courses, such AI tools need to be used and practiced in a meaningful and useful way. The programming project is one such course at our university, and the curriculum will be expanded accordingly in the future. In this paper we describe our approach and a user study among the participants of the last programming project, in which we collected experiences with the use of current AI tools, in particular highlighting their usefulness and limitations. Our study focuses on identifying which aspects of the course students used AI tools for, evaluating successful applications, and uncovering remaining challenges.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {161–170},
numpages = {10},
keywords = {software development project course, software engineering education, AI support, AI-based tutoring, experiments},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3722237.3722403,
author = {Mei, Beiyun and Zhu, He},
title = {The Ethical Dilemma and Governance Path of Generative AI in Cultural Communication},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722403},
doi = {10.1145/3722237.3722403},
abstract = {Generative AI, as a new media form, promotes the revolution of culture in production, dissemination and consumption, and despite its text generation, visual art and personalised recommendation to accelerate the breadth and depth of cultural dissemination, its ethical misconduct performance, which cannot be ignored, has triggered the attention of academics and all walks of life. Through case studies and literature review, this paper reveals the problems of cultural appropriation, privacy leakage, and algorithmic bias that generative AI may lead to in the process of cultural creation and dissemination, and based on in-depth analyses of these ethical challenges, it proposes a series of governance paths in terms of strengthening ethical review, promoting algorithmic transparency, and establishing a platform for cross-border cooperation.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {969–974},
numpages = {6},
keywords = {Cultural Communication, Ethical Dilemma, Generative AI},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3722237.3722260,
author = {Wu, Yanan and Zeng, Xiaoping and Lin, Qibei},
title = {Generative AI Integrated Educational Model for User-Centered Design},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722260},
doi = {10.1145/3722237.3722260},
abstract = {The advent of artificial intelligence (AI) has profoundly transformed the educational landscape. Many educators are exploring how AI tools can enhance learning instructional programs. However, there is less focus on how its application within design education—particularly when teaching user-centered design. This study developed an educational model utilizing AI for user-centered design curriculum. Based on design thinking theory, this model integrates ChatGPT and Midjourney into the divergent and convergent design phases to facilitate the workflow. The empirical research showed that educational model can foster students’ creativity and problem-solving skills. The findings highlight the efficacy of AI integration in curricula design and instructional practices.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {129–135},
numpages = {7},
keywords = {Generative AI, design education, design thinking, instructional design, user-centered design},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3677045.3685439,
author = {R\"{o}nnberg, Niklas and B\"{o}r\"{u}tecene, Ahmet},
title = {Use of Generative AI for Fictional Field Studies in Design Courses},
year = {2024},
isbn = {9798400709654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677045.3685439},
doi = {10.1145/3677045.3685439},
abstract = {In this paper, we present how we used generative AI (GenAI) as a pedagogical tool for students taking a course in tangible interaction design. In this course, the students design different physical-digital objects (PDOs) to learn designing, sketching and prototyping with code and hardware. However, due to the short course duration these PDOs are not evaluated or explored with any kind of field or user study. Therefore we gave the students the exercise of doing user interviews with GenAI to explore their design ideas further. With this paper, we contribute a description and the outcomes of this approach, and highlight the pedagogical implications for student learning.},
booktitle = {Adjunct Proceedings of the 2024 Nordic Conference on Human-Computer Interaction},
articleno = {23},
numpages = {5},
keywords = {Design, Education, Field study, Generative AI, User interview},
location = {Uppsala, Sweden},
series = {NordiCHI '24 Adjunct}
}

@inproceedings{10.1145/3706599.3721349,
author = {Lee, Chaeyeon and Lee, Chungnyeong and Kim, Sangyong and Choi, Yongsoon and Kim, Jusub},
title = {StorageChat Timeline: A Generative AI-Based Art Appreciation System for Enhancing Immersion and Exploratory Experience},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3721349},
doi = {10.1145/3706599.3721349},
abstract = {This video showcases StorageChat Timeline, an AI-powered system utilizing a Large Language Model (LLM) and generative AI technologies (e.g., style transfer, image-to-video) for art appreciation education. By offering real-time interactive question-and-answer experiences, the system enables users to construct the meaning of artworks based on their knowledge and experiences. It also provides immersive generative animations reflecting the artworks’ styles and multimodal features, including text-to-speech and dynamic visuals, to enhance emotional engagement. Through this design, the system aims to enhance immersion, learning motivation, and visual literacy, fostering active participation in art appreciation. This innovative approach enhances accessibility to art and proposes a generative AI-driven methodology for art education. The video demonstrates how the system’s key features—AI conversational interface, immersive animations, and multimodal integration—create an engaging and visually interactive experience, showcasing its potential to transform art appreciation.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {921},
numpages = {2},
keywords = {Generative AI, Large Language Models (LLM), Museum Education, Immersive Learning},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3613904.3642902,
author = {Tankelevitch, Lev and Kewenig, Viktor and Simkute, Auste and Scott, Ava Elizabeth and Sarkar, Advait and Sellen, Abigail and Rintel, Sean},
title = {The Metacognitive Demands and Opportunities of Generative AI},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642902},
doi = {10.1145/3613904.3642902},
abstract = {Generative AI (GenAI) systems offer unprecedented opportunities for transforming professional and personal work, yet present challenges around prompting, evaluating and relying on outputs, and optimizing workflows. We argue that metacognition—the psychological ability to monitor and control one’s thoughts and behavior—offers a valuable lens to understand and design for these usability challenges. Drawing on research in psychology and cognitive science, and recent GenAI user studies, we illustrate how GenAI systems impose metacognitive demands on users, requiring a high degree of metacognitive monitoring and control. We propose these demands could be addressed by integrating metacognitive support strategies into GenAI systems, and by designing GenAI systems to reduce their metacognitive demand by targeting explainability and customizability. Metacognition offers a coherent framework for understanding the usability challenges posed by GenAI, and provides novel research and design directions to advance human-AI interaction.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {680},
numpages = {24},
keywords = {Generative AI, Human-AI interaction, Metacognition, System Usability, User Experience Design},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3637864,
author = {Felten, Ed and Raj, Manav and Seamans, Rob},
title = {Generative AI Requires Broad Labor Policy Considerations},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {8},
issn = {0001-0782},
url = {https://doi.org/10.1145/3637864},
doi = {10.1145/3637864},
abstract = {Considering how generative artificial intelligence might affect occupations.},
journal = {Commun. ACM},
month = aug,
pages = {29–32},
numpages = {4}
}

@inproceedings{10.1145/3711542.3711583,
author = {Tan, Tee Hean},
title = {Rule-Based vs. AI-Driven: Comparing PolyAQG Framework and Generative AI Models},
year = {2025},
isbn = {9798400717383},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711542.3711583},
doi = {10.1145/3711542.3711583},
abstract = {This comparative analysis examines the PolyAQG framework and Generative AI models (e.g., ChatGPT, Gemini) across ten key criteria for question generation. The PolyAQG framework, a rule-based approach, is well-suited for structured content and excels in generating consistent questions for educational purposes. However, it may be limited in creativity and depth. Generative AI models, while capable of covering broader topics and interpreting complex contexts, require more computational resources and may introduce inaccuracies in specialized domains. The PolyAQG framework offers scalability within specific domains and predictable error handling. Generative AI models, although scalable across topics, may require fine-tuning for accuracy. Furthermore, Generative AI enables dynamic user interaction and fosters critical thinking, while the PolyAQG framework provides a more limited user interface. The choice between PolyAQG and generative AI depends on application needs. PolyAQG is ideal for structured questions and consistency, while generative AI excels in creativity, adaptability, and user interaction.},
booktitle = {Proceedings of the 2024 8th International Conference on Natural Language Processing and Information Retrieval},
pages = {298–303},
numpages = {6},
keywords = {Generative AI model, PolyAQG framework, contextual understanding, domain-specific, questions generation, rule-based, scalability},
location = {
},
series = {NLPIR '24}
}

@inproceedings{10.1145/3657604.3664699,
author = {Hutt, Stephen and Hieb, Grayson},
title = {Scaling Up Mastery Learning with Generative AI: Exploring How Generative AI Can Assist in the Generation and Evaluation of Mastery Quiz Questions},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664699},
doi = {10.1145/3657604.3664699},
abstract = {Generative AI has the potential to scale a number of educational practices, previously limited by resources. One such instructional approach is mastery learning, a pedagogy emphasizing proficiency before progression that is highly resource (teacher time, materials) intensive. The rise of computer-based instruction offered partial solutions, tailoring student progression and automating some facets of the mastery learning process. This work in progress considers the application of large language models for content generation tailored to mastery learning. We present a paired framework for analyzing and evaluating the generated content relative to rubrics designed by the teacher. Recognizing the potential of large language models, we critically assess the potential of improving mastery-based instruction. We close our discussion by considering the applications and limitations of this approach.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {310–314},
numpages = {5},
keywords = {content evaluation, content generation, generative ai, large language models, mastery learning},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3641235.3664438,
author = {Kicklighter, Caleb and Seo, Jinsil Hwaryoung and Andreassen, Mayet and Bujnoch, Emily},
title = {Empowering Creativity with Generative AI in Digital Art Education},
year = {2024},
isbn = {9798400705175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641235.3664438},
doi = {10.1145/3641235.3664438},
abstract = {Artificial intelligence is dramatically changing the creative process for many practices. We see this as an opportunity to enrich student projects within our classroom. We created educational materials and conducted an initial study in the Fall of 2023. The study focuses on the impact that image-based generative AI tools could have on the creative process for students in the 3D Animation classroom. We found that, within our class, most students found AI useful for their productivity, but further work was needed to educate students and to create a safe space for students to explore how these tools can enhance their creative work.},
booktitle = {ACM SIGGRAPH 2024 Educator's Forum},
articleno = {13},
numpages = {2},
keywords = {3D Animation Education, Concept Development, Creativity, Generative AI, Iteration, Undergraduate Digital Art Education},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{10.1145/3613904.3641971,
author = {Rajcic, Nina and Llano Rodriguez, Maria Teresa and McCormack, Jon},
title = {Towards a Diffractive Analysis of Prompt-Based Generative AI},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641971},
doi = {10.1145/3613904.3641971},
abstract = {Recent developments in prompt-based generative AI has given rise to discourse surrounding the perceived ethical concerns, economic implications, and consequences for the future of cultural production. As generative imagery becomes pervasive in mainstream society, dominated primarily by emerging industry leaders, we encourage that the role of the CHI community be one of inquiry; to investigate the numerous ways in which generative AI has the potential to, and already is, augmenting human creativity. In this paper, we conducted a diffractive analysis exploring the potential role of prompt-based interfaces in artists’ creative practice. Over a two week period, seven visual artists were given access to a personalised instance of Stable Diffusion, fine-tuned on a dataset of their work. In the following diffractive analysis, we identified two dominant modes adopted by participants, AI for ideation, and AI for production. We furthermore present a number of ethical design considerations for the future development of generative AI interfaces.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {844},
numpages = {15},
keywords = {Creative AI, Diffractive Analysis, Diffusion, Generative AI},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3714334.3714362,
author = {Tian, Yusen and Tu, Binghao},
title = {A Systematic Literature Review on the Feasibility of Dialogue Learning Based on Generative AI},
year = {2025},
isbn = {9798400711237},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3714334.3714362},
doi = {10.1145/3714334.3714362},
abstract = {This study systematically reviews the feasibility of dialogue learning based on generative AI. Research on mixed reality and generative AI in enhancing teaching effectiveness is increasingly in-depth both domestically and internationally. The development and application of mixed reality and generative AI are accelerating, evolving classroom structures and methods. In the context of rapid social, economic, and technological development, students require more personalized and innovative education, which dialogue learning interventions based on generative AI can effectively address. Through a systematic literature review method, 128 relevant studies from the past decade were systematically analyzed to explore the feasibility of dialogue learning in the context of generative AI. The study finds that the application of generative AI in dialogue learning not only enhances learning outcomes but also excels in personalized learning and timely feedback. However, the diversity and operability of technological implementation and application scenarios require further exploration. This research provides references and insights for future studies by related scholars.},
booktitle = {Proceedings of the 2024 2nd International Conference on Artificial Intelligence, Systems and Network Security},
pages = {160–164},
numpages = {5},
keywords = {AIGC, Dialogue Learning, Generative AI},
location = {
},
series = {AISNS '24}
}

@inproceedings{10.1145/3626252.3630842,
author = {Amoozadeh, Matin and Daniels, David and Nam, Daye and Kumar, Aayush and Chen, Stella and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Mohammad Amin},
title = {Trust in Generative AI among Students: An exploratory study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630842},
doi = {10.1145/3626252.3630842},
abstract = {Generative Artificial Intelligence (GenAI) systems have experienced exponential growth in the last couple of years. These systems offer exciting capabilities for CS Education (CSEd), such as generating programs, that students can well utilize for their learning. Among the many dimensions that might affect the effective adoption of GenAI for CSEd, in this paper, we investigate students' trust. Trust in GenAI influences the extent to which students adopt GenAI, in turn affecting their learning. In this paper, we present results from a survey of 253 students at two large universities to understand how much they trust GenAI tools and their feedback on how GenAI impacts their performance in CS courses. Our results show that students have different levels of trust in GenAI. We also observe different levels of confidence and motivation, highlighting the need for further understanding of factors impacting trust.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {67–73},
numpages = {7},
keywords = {generative ai, novice programmers, trust},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3582515.3609555,
author = {Baldassarre, Maria Teresa and Caivano, Danilo and Fernandez Nieto, Berenice and Gigante, Domenico and Ragone, Azzurra},
title = {The Social Impact of Generative AI: An Analysis on ChatGPT},
year = {2023},
isbn = {9798400701160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582515.3609555},
doi = {10.1145/3582515.3609555},
abstract = {In recent months, the impact of Artificial Intelligence (AI) on citizens’ lives has gained considerable public interest, driven by the emergence of Generative AI models, ChatGPT in particular. The rapid development of these models has sparked heated discussions regarding their benefits, limitations, and associated risks. Generative models hold immense promise across multiple domains, such as healthcare, finance, and education, to cite a few, presenting diverse practical applications. Nevertheless, concerns about potential adverse effects have elicited divergent perspectives, ranging from privacy risks to escalating social inequality. This paper adopts a methodology to delve into the societal implications of Generative AI tools, focusing primarily on the case of ChatGPT. It evaluates the potential impact on several social sectors and illustrates the findings of a comprehensive literature review of both positive and negative effects, emerging trends, and areas of opportunity of Generative AI models. This analysis aims to facilitate an in-depth discussion by providing insights that can inspire policy, regulation, and responsible development practices to foster a citizen-centric AI.},
booktitle = {Proceedings of the 2023 ACM Conference on Information Technology for Social Good},
pages = {363–373},
numpages = {11},
keywords = {Citizen-centric AI, Generative AI Social Impact, Trustable AI},
location = {Lisbon, Portugal},
series = {GoodIT '23}
}

@inproceedings{10.1145/3688828.3699656,
author = {Yu, Yaman},
title = {Safeguarding Children in Generative AI: Risk Frameworks and Parental Control Tools},
year = {2025},
isbn = {9798400711879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3688828.3699656},
doi = {10.1145/3688828.3699656},
abstract = {Generative AI (GAI) systems are increasingly integrated into children’s digital experiences, raising concerns about safety, privacy, and appropriate interactions. My research explores the specific risks children encounter when interacting with GAI, with a focus on identifying harmful interactions and their potential impacts. By examining parent-child perceptions of GAI safety, I aim to develop a comprehensive framework and database of risky interactions to guide the creation of effective parental control tools and educational resources. The ultimate goal is to provide parents with practical solutions to actively mitigate risks and create safer AI environments for children.},
booktitle = {Companion Proceedings of the 2025 ACM International Conference on Supporting Group Work},
pages = {121–123},
numpages = {3},
keywords = {AI Ethics, Children Safety, Family-Centered Design, Generative AI, Human-Computer Interaction, Parental Control, Risk Mitigation},
location = {Hilton Head, New Jersey, USA},
series = {GROUP '25}
}

@inproceedings{10.1145/3706598.3713166,
author = {Subramonyam, Hari and Thakkar, Divy and Ku, Andrew and Dieber, Juergen and Sinha, Anoop K.},
title = {Prototyping with Prompts: Emerging Approaches and Challenges in Generative AI Design for Collaborative Software Teams},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713166},
doi = {10.1145/3706598.3713166},
abstract = {Generative AI models are increasingly being integrated into human task workflows, enabling the production of expressive content across a wide range of contexts. Unlike traditional human-AI design methods, the new approach to designing generative capabilities focuses heavily on prompt engineering strategies. This shift requires a deeper understanding of how collaborative software teams establish and apply design guidelines, iteratively prototype prompts, and evaluate them to achieve specific outcomes. To explore these dynamics, we conducted design studies with 39 industry professionals, including UX designers, AI engineers, and product managers. Our findings highlight emerging practices and role shifts in AI system prototyping among multistakeholder teams. We observe various prompting and prototyping strategies, highlighting the pivotal role of to-be-generated content characteristics in enabling rapid, iterative prototyping with generative AI. By identifying associated challenges, such as the limited model interpretability and overfitting the design to specific example content, we outline considerations for generative AI prototyping.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {882},
numpages = {22},
keywords = {Generative AI, Prompt Engineering, Human-Centered AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3491101.3503719,
author = {Muller, Michael and Chilton, Lydia B and Kantosalo, Anna and Martin, Charles Patrick and Walsh, Greg},
title = {GenAICHI: Generative AI and HCI},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3503719},
doi = {10.1145/3491101.3503719},
abstract = {This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together. It is time to convene the interdisciplinary research domain of generative AI and HCI. Participation in this invitational workshop is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {110},
numpages = {7},
keywords = {Bias, Design, Generative AI, Uncertainty.},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@inproceedings{10.1145/3636243.3636248,
author = {Hou, Irene and Mettille, Sophia and Man, Owen and Li, Zhuo and Zastudil, Cynthia and MacNeil, Stephen},
title = {The Effects of Generative AI on Computing Students’ Help-Seeking Preferences},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636248},
doi = {10.1145/3636243.3636248},
abstract = {Help-seeking is a critical way that students learn new concepts, acquire new skills, and get unstuck when problem-solving in their computing courses. The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand. However, it is unclear how this new resource compares to existing help-seeking resources along dimensions of perceived quality, latency, and trustworthiness. In this paper, we investigate the help-seeking preferences and experiences of computing students now that generative AI tools are available to them. We collected survey data (n=47) and conducted interviews (n=8) with computing students. Our results suggest that although these models are being rapidly adopted, they have not yet fully eclipsed traditional help resources. The help-seeking resources that students rely on continue to vary depending on the task and other factors. Finally, we observed preliminary evidence about how help-seeking with generative AI is a skill that needs to be developed, with disproportionate benefits for those who are better able to harness the capabilities of LLMs. We discuss potential implications for integrating generative AI into computing classrooms and the future of help-seeking in the era of generative AI.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {39–48},
numpages = {10},
keywords = {ChatGPT, Generative AI, computing education, help-seeking},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@article{10.1145/3743133,
author = {Stalnaker, Trevor and Wintersgill, Nathan and Chaparro, Oscar and Heymann, Laura A. and Di Penta, Massimiliano and German, Daniel M and Poshyvanyk, Denys},
title = {Developer Perspectives on Licensing and Copyright Issues Arising from Generative AI for Software Development},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3743133},
doi = {10.1145/3743133},
abstract = {Despite the utility that Generative AI (GenAI) tools provide for tasks such as writing code, the use of these tools raises important legal questions and potential risks, particularly those associated with copyright law. As lawmakers and regulators respond to these questions, the views of users can offer relevant perspectives. In this paper, we provide: (1) a survey of 574 developers on the licensing and copyright aspects of GenAI for coding, as well as follow-up interviews; (2) a snapshot of developers’ views at a time when GenAI and perceptions of it were rapidly evolving; and (3) an analysis of developers’ perspectives, yielding insights and recommendations that can inform future regulatory decisions in this evolving field. Our results show the benefits developers derive from GenAI, how they view the use of AI-generated code as similar to using other existing code, the varied opinions they have on who should own or be compensated for such code, that they are concerned about data leakage via GenAI, and other findings, providing organizations and policymakers with valuable insights into how the technology is being used and the concerns that stakeholders believe warrant attention.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
keywords = {open-source software, generative ai, machine learning, large language models, qualitative research}
}

@article{10.1145/3655727.3655736,
author = {Woods, Charles and Johnson, Gavin P.},
title = {(Re)Designing Privacy Literacy in the Age of Generative AI},
year = {2025},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
url = {https://doi.org/10.1145/3655727.3655736},
doi = {10.1145/3655727.3655736},
abstract = {In this article, we propose (re)designing privacy literacy as an essential component of our digital lives in an age of Generative Artificial Intelligence (genAI). Our study emphasizes the layered digital, technical, rhetorical, and algorithmic literacies associated with design thinking and genAI to support theorizing privacy literacy. We introduce Design as an analytical element complementary to Woods and Wason's (2021) multi-pronged framework for analyzing Terms of Service (ToS) documents. Using a cluster of Adobe Generative AI ToS, we illustrate the necessity of including Design, which allows those invested in Communication Design (CD) and Technical and Professional Communication (TPC) to interrogate how or if design supports or undermines values related to user privacy, data ownership, and informed consent. We conclude by detailing how collective surveillance apathy regarding emergent data infrastructures signal a Post-Surveillance era in our global society and digital lives.},
journal = {Commun. Des. Q. Rev},
month = jan,
pages = {86–97},
numpages = {12},
keywords = {artificial intelligence, design, digital privacy, post-surveillance, terms of service}
}

@inproceedings{10.1145/3632620.3671116,
author = {Prather, James and Reeves, Brent N and Leinonen, Juho and MacNeil, Stephen and Randrianasolo, Arisoa S and Becker, Brett A. and Kimmel, Bailey and Wright, Jared and Briggs, Ben},
title = {The Widening Gap: The Benefits and Harms of Generative AI for Novice Programmers},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671116},
doi = {10.1145/3632620.3671116},
abstract = {Novice programmers often struggle through programming problem solving due to a lack of metacognitive awareness and strategies. Previous research has shown that novices can encounter multiple metacognitive difficulties while programming, such as forming incorrect conceptual models of the problem or having a false sense of progress after testing their solution. Novices are typically unaware of how these difficulties are hindering their progress. Meanwhile, many novices are now programming with generative AI (GenAI), which can provide complete solutions to most introductory programming problems, code suggestions, hints for next steps when stuck, and explain cryptic error messages. Its impact on novice metacognition has only started to be explored. Here we replicate a previous study that examined novice programming problem solving behavior and extend it by incorporating GenAI tools. Through 21 lab sessions consisting of participant observation, interview, and eye tracking, we explore how novices are coding with GenAI tools. Although 20 of 21 students completed the assigned programming problem, our findings show an unfortunate divide in the use of GenAI tools between students who did and did not struggle. Some students who did not struggle were able to use GenAI to accelerate, creating code they already intended to make, and were able to ignore unhelpful or incorrect inline code suggestions. But for students who struggled, our findings indicate that previously known metacognitive difficulties persist, and that GenAI unfortunately can compound them and even introduce new metacognitive difficulties. Furthermore, struggling students often expressed cognitive dissonance about their problem solving ability, thought they performed better than they did, and finished with an illusion of competence. Based on our observations from both groups, we propose ways to scaffold the novice GenAI experience and make suggestions for future work.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {469–486},
numpages = {18},
keywords = {CS1, ChatGPT, Copilot, generative AI, large language models, metacognition},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3706599.3720145,
author = {Park, Minseo and Lim, Youn-kyung},
title = {Exploring the Potential of Generative AI for Supporting Middle-Aged Individuals in Retirement Transitions},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720145},
doi = {10.1145/3706599.3720145},
abstract = {The widespread adoption of Generative AI (GenAI) has fueled research exploring applications across diverse age groups and domains. However, its potential to support individuals in retirement transitions remains underexplored. This study aims to uncover the potential of GenAI in this context by examining its current and anticipated roles through semi-structured interviews with 10 middle-aged individuals navigating retirement transitions. The findings highlight three key roles of GenAI as an identity navigator, self-actualization facilitator, and connection catalyst. Building on the findings, the study identifies novel design opportunities for GenAI-based systems that assist an integrated journey from self-discovery to self-actualization, and support both direct and indirect connection to the world. The research aims to inspire the HCI community to further investigate these new design possibilities and attract attention to the unique context of retirement transition.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {271},
numpages = {7},
keywords = {generative AI, retirement transitions, middle-aged people, design opportunities},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3632620.3671103,
author = {Logacheva, Evanfiya and Hellas, Arto and Prather, James and Sarsa, Sami and Leinonen, Juho},
title = {Evaluating Contextually Personalized Programming Exercises Created with Generative AI},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671103},
doi = {10.1145/3632620.3671103},
abstract = {Programming skills are typically developed through completing various hands-on exercises. Such programming problems can be contextualized to students’ interests and cultural backgrounds. Prior research in educational psychology has demonstrated that context personalization of exercises stimulates learners’ situational interests and positively affects their engagement. However, creating a varied and comprehensive set of programming exercises for students to practice on is a time-consuming and laborious task for computer science educators. Previous studies have shown that large language models can generate conceptually and contextually relevant programming exercises. Thus, they offer a possibility to automatically produce personalized programming problems to fit students’ interests and needs. This article reports on a user study conducted in an elective introductory programming course that included contextually personalized programming exercises created with GPT-4. The quality of the exercises was evaluated by both the students and the authors. Additionally, this work investigated student attitudes towards the created exercises and their engagement with the system. The results demonstrate that the quality of exercises generated with GPT-4 was generally high. What is more, the course participants found them engaging and useful. This suggests that AI-generated programming problems can be a worthwhile addition to introductory programming courses, as they provide students with a practically unlimited pool of practice material tailored to their personal interests and educational needs.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {95–113},
numpages = {19},
keywords = {automatic exercise generation, context personalization, generative AI, large language models},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@article{10.1145/3632523,
author = {Johnson, Maggie},
title = {Generative AI and CS Education},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {4},
issn = {0001-0782},
url = {https://doi.org/10.1145/3632523},
doi = {10.1145/3632523},
abstract = {Increasing knowledge sharing between industry and academia.},
journal = {Commun. ACM},
month = mar,
pages = {23–24},
numpages = {2}
}

@inproceedings{10.1145/3626252.3630938,
author = {Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.},
title = {Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630938},
doi = {10.1145/3626252.3630938},
abstract = {In Summer 2023, we developed and integrated a suite of AI-based software tools into CS50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial AI software such as ChatGPT, GitHub Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-to-student ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had "a personal tutor.'' Our findings suggest that integrating AI thoughtfully into educational settings enhances the learning experience by providing continuous, customized support and enabling human educators to address more complex pedagogical issues. In this paper, we detail how AI tools have augmented teaching and learning in CS50, specifically in explaining code snippets, improving code style, and accurately responding to curricular and administrative queries on the course's discussion forum. Additionally, we present our methodological approach, implementation details, and guidance for those considering using these tools or AI generally in education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {750–756},
numpages = {7},
keywords = {ai, artificial intelligence, generative ai, large language models, llms},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3702163.3702177,
author = {Ito, Yuki and Ma, Qiang},
title = {Supporting student self-learning using generative AI},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702177},
doi = {10.1145/3702163.3702177},
abstract = {With recent advancements in language-generating AI, students increasingly depend on AI for problem-solving in their coursework. However, over-reliance on AI risks depriving students of opportunities for self-learning, which is essential in education. One of the considerable reasons students turn to AI is their inability to solve problems independently due to a lack of understanding. To address this, we propose an interactive system that guides students struggling with problem-solving by giving them hints. When the system gets students’ answers, it assesses the answer by breaking down problems into small parts, then evaluating each part, and finally, explaining the grading rationale. Based on this assessment, the system offers targeted suggestions for improvement generated by language generation AI with pre-prepared templates. These hints guide students without providing direct answers, fostering class understanding and problem-solving skills.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {97–103},
numpages = {7},
keywords = {Interactive System, Large Language Model},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3689050.3704798,
author = {Thalhammer, Philipp Tim},
title = {Generative AI Meets Accessibility: Deformable Interfaces and Multimodal Solutions},
year = {2025},
isbn = {9798400711978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689050.3704798},
doi = {10.1145/3689050.3704798},
abstract = {Artificial intelligence (AI), especially large language models (LLMs), has evolved into one of the most influential technologies of our century. Yet, human interaction with AI is dominated by chat-based input windows. Although there have been some developments regarding wearable AI interfaces, the field remains largely unexplored. AI has the potential to revolutionize the way we approach accessibility by automating tasks that previously required human assistance. However, most AI tools are at least partly inaccessible to people who use assistive technologies to interact with computers. The goal of my Ph.D. research is to investigate how generative AI and LLMs can be made more accessible for people with disabilities and be utilized to create new accessibility tools through the use of multimodal interactions. I approach this problem using an iterative research through design (RTD) approach focused on close engagement with the target demographic.},
booktitle = {Proceedings of the Nineteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {126},
numpages = {5},
keywords = {Accessibility, AI, Bio-Materials, Deformable Interfaces},
location = {
},
series = {TEI '25}
}

@inproceedings{10.1145/3649165.3690111,
author = {Poitras, Eric and Crane, Brent and Siegel, Angela},
title = {Generative AI in Introductory Programming Instruction: Examining the Assistance Dilemma with LLM-Based Code Generators},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690111},
doi = {10.1145/3649165.3690111},
abstract = {Problem decomposition is an important skill in programming, allowing learners to break down complex tasks into manageable subgoals. However, translating these subgoals into executable code poses a significant challenge for novice programmers. In this study conducted in an introductory programming course, learners received instruction in stepwise refinement and integration of AI-generated code within their assignments. Throughout the course, learners were permitted to rely on AI code generators, following opportunities to receive feedback on their ability to read and write code without AI assistance.  Our findings show that learners frequently relied on AI-generated code when working on assignments outside the classroom, but that the frequency of reliance varied from one assignment to another. The reliance on AI-generated code was not correlated with the learners' year in their degree, nor whether they were enrolled in a CS degree or not. Instead, it was associated with their prior knowledge, as learners who were less proficient in reading and writing code were more likely to seek AI assistance.  AI tools were primarily used to translate subgoals into code, fix errors, and explain algorithmic concepts. Few learners encountered difficulties in understanding or integrating AI generated code into their solutions. Overall, learner performance in meeting assignment requirements was relatively high, regardless of their prior knowledge or reliance on AI code generators. We conclude that leveraging the capabilities of generative AI can effectively bridge the gap between problem-solving and implementation, enabling learners to engage in skills that might otherwise be beyond their reach.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {186–192},
numpages = {7},
keywords = {ai coding assistants, ai-assisted pair programming, chatgpt, generative ai, gpt-3.5, introductory programming, large language models},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3649217.3653602,
author = {Mahon, Joyce and Mac Namee, Brian and Becker, Brett A.},
title = {Guidelines for the Evolving Role of Generative AI in Introductory Programming Based on Emerging Practice},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653602},
doi = {10.1145/3649217.3653602},
abstract = {In the rapidly evolving Generative AI (GenAI) landscape, source code and natural language are being mixed and used in new ways. This presents opportunities for rethinking teaching practice in Introductory Programming (CS1) courses that includes, but goes beyond, assessment. In this paper we examine the reasons why and how instructors who are early adopters of GenAI are using it in their teaching, and why others are not. We also explore the changes and adaptations that are currently being made to practice. This is achieved by synthesizing insights from several recent studies that have collected primary data from introductory programming instructors who are teaching with, considering teaching with, or actively not teaching with GenAI.Due to the fast pace of GenAI development and adoption, the fixed-pace and cyclical nature of education, and the relatively slow pace of research (including ethical approvals) and publication cycles, research with primary data from instructors is only being published relatively recently. In computing education, there is not yet enough published research with primary data from CS1 instructors to warrant a systematic literature review, although in the next year this will likely be possible. Based on an analysis of the nascent research that has been published, we propose emerging and flexible guidelines on how CS1 instructors could adapt their practice based on what others have done so far. These guidelines highlight important factors to consider when integrating GenAI in CS1 courses, which for many is only beginning.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {10–16},
numpages = {7},
keywords = {CS1, LLM, artificial intelligence, automated/assisted code generation, chatgpt, computing education, copilot, generative AI, introductory programming, k-12, large language model, machine learning, novice programmer, school},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3641554.3701946,
author = {Li, Nero and Broner, Shahar and Kim, Yubin and Mizuo, Katrina and Sauder, Elijah and To, Claire and Wang, Albert and Gila, Ofek and Shindler, Michael},
title = {Investigating the Capabilities of Generative AI in Solving Data Structures, Algorithms, and Computability Problems},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701946},
doi = {10.1145/3641554.3701946},
abstract = {There is both great hope and concern about the future of Computer Science practice and education concerning the recent advent of large language models (LLMs).We present the first study to extensively evaluate the ability of such a model to solve problems in Computer Science Theory. Specifically, we tested 165 exam-level problems across 16 specific topics related to computer science theory, ranging from preliminary data structures to algorithm design paradigms to theory of computation (automata and complexity). Our results use the recent popular models (GPT-4 and GPT-4o). This is a rapidly evolving field, with model performance continuously improving. We present our results primarily as an indication of what they can already achieve-equivalently how they can already be useful-today, fully expecting them to improve even further in the near future. Our results show that what was very recently a state-of-the-art model (GPT-4) can solve 77% of free-response problems in data structures and algorithms with little to no guidance. The latest model, GPT-4o, can solve around 46% of the Theory of Computation problems we posed, with predictable categories for which problems it could not solve. When broken down by topic, the model can solve 80% of problems in 4 out of the 15 topics and at least half in 8 other topics. Other problems, namely more visual problems, either require more substantial coaching or seem to still be beyond the capabilities of the language model--for now. By understanding the strengths and limitations of these models for solving theory problems, we can open the door to future work, ranging from human educational assessment on the topic to automated tutors for learners of the subject.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {659–665},
numpages = {7},
keywords = {algorithm design techniques, chatgpt, computational thinking, computer-assisted instruction, data structures, generative ai, gpt-4, gpt-4o, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3664647.3687170,
author = {Huang, Zi Helen and Chen, Phoebe and Yan, Shuicheng},
title = {Generative AI in Multimedia: Challenges and Opportunities for Academic and Industrial Impact},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3687170},
doi = {10.1145/3664647.3687170},
abstract = {Generative AI has revolutionized multimedia, leading to groundbreaking developments in content creation, interactive experiences, and personalized media. This panel delves into the transformative potential of generative AI in academic and industrial sectors, exploring its future applications and connections to emerging techniques. Additionally, the panel will address newly identified opportunities and challenges from both technical and ethical perspectives, highlighting the importance of responsible AI development. Bringing together leading experts from universities, research institutions, and industry, this panel aims to foster discussion and debate among participants. We invite everyone to join and contribute to this critical and promising area of research in the multimedia community.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {11123–11124},
numpages = {2},
keywords = {generative ai, large foundation model, multimedia},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3654777.3676326,
author = {Rajaram, Shwetha and Numan, Nels and Kumaravel, Balasaravanan Thoravi and Marquardt, Nicolai and Wilson, Andrew D},
title = {BlendScape: Enabling End-User Customization of Video-Conferencing Environments through Generative AI},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676326},
doi = {10.1145/3654777.3676326},
abstract = {Today’s video-conferencing tools support a rich range of professional and social activities, but their generic meeting environments cannot be dynamically adapted to align with distributed collaborators’ needs. To enable end-user customization, we developed BlendScape, a rendering and composition system for video-conferencing participants to tailor environments to their meeting context by leveraging AI image generation techniques. BlendScape supports flexible representations of task spaces by blending users’ physical or digital backgrounds into unified environments and implements multimodal interaction techniques to steer the generation. Through an exploratory study with 15 end-users, we investigated whether and how they would find value in using generative AI to customize video-conferencing environments. Participants envisioned using a system like BlendScape to facilitate collaborative activities in the future, but required further controls to mitigate distracting or unrealistic visual elements. We implemented scenarios to demonstrate BlendScape’s expressiveness for supporting environment design strategies from prior work and propose composition techniques to improve the quality of environments.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {40},
numpages = {19},
keywords = {end-user customization, generative AI, video-conferencing},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@article{10.1145/3700140,
author = {Bright, Jonathan and Enock, Florence and Esnaashari, Saba and Francis, John and Hashem, Youmna and Morgan, Deborah},
title = {Generative AI is already widespread in the public sector: evidence from a survey of UK public sector professionals},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
url = {https://doi.org/10.1145/3700140},
doi = {10.1145/3700140},
abstract = {Generative AI has the potential to transform how public services are delivered by enhancing productivity and reducing time spent on bureaucracy. But to what extent is the technology already in use? Our survey of UK public service professionals (in education, health, social work, and emergency services) seeks to answer this question. We find that use of generative AI is widespread: 45% of respondents were aware of colleagues using generative AI, while 22% use it themselves. Respondents were positive about its potential to enhance their efficiency and reduce their bureaucratic workload. For example, those working in the health service thought that time spent on bureaucracy could drop by the equivalent of one day per week, an enormous potential impact. Our survey also found a high amount of trust (61%) in generative AI and a low fear of replacement (16%). However, only a minority of respondents (32%) felt like there was clear guidance on generative AI usage in their workplaces. In other words, it is clear that generative AI is already coming into the public sector, but uptake is happening in a disorganised fashion without clear guidelines. The UK’s public sector urgently needs to develop more systematic methods for taking advantage of the technology.},
journal = {Digit. Gov.: Res. Pract.},
month = feb,
articleno = {2},
numpages = {13},
keywords = {Generative AI, Public Sector, Productivity, Bureaucracy}
}

@inproceedings{10.1145/3583780.3615317,
author = {Shah, Chirag},
title = {Generative AI and the Future of Information Access},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615317},
doi = {10.1145/3583780.3615317},
abstract = {The prominent model of retrieving, evaluating, and using relevant information from databases, collections, and the web is going through a significant transformation. This is largely due to wide-scale availability of various generative AI systems that can take in natural language inputs and generate highly customized natural language text, images, audio, and videos. This transformation in how people seek and access information will have profound impacts on users, developers, and policymakers. It is already changing many sectors including education, health, and commerce. But the hopes and hypes of generative AI are often not clear as we get swept up by either the current capabilities and limitations of this technology in the short term or fear from speculative future in the long term. Instead, I believe we need to approach this area pragmatically and with scientific curiosity, scholarly rigor, and societal responsibility. In this talk, I will highlight some of the opportunities and challenges for information access stemming from recent advancements in generative AI. For instance, there are new possibilities now for addressing accessibility, low-resource domains, and bias in training data using generative AI tools. On the other hand, there are new challenges concerning hallucination, toxicity, and information provenance. It is clear that we want to benefit from what AI systems are capable of, but how do we do that while curbing some of these problems? I will argue that the solution is multifaceted and complex -- some will require technical advancements and others will call for policy changes. We will need to not only build information systems with fairness, transparency, and accountability in mind, but also train a new generation of developers, policymakers, and of course the users. The goal here is to cut through both hype and fear and think pragmatically about the future of information access.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {3},
numpages = {1},
keywords = {generative AI, information access},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3613905.3650900,
author = {Yazici, Aybars and Mejia-Domenzain, Paola and Frej, Jibril and K\"{a}ser, Tanja},
title = {GELEX: Generative AI-Hybrid System for Example-Based Learning},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650900},
doi = {10.1145/3613905.3650900},
abstract = {Traditional example-based learning methods are often limited by static, expert-created content. Hence, they face challenges in scalability, engagement, and effectiveness, as some learners might struggle to relate to the examples or find them relevant. To address these challenges, we introduce GELEX (GEnerative-AI Learning through EXamples), a hybrid Artificial Intelligence (AI) system enhancing example-based learning by using large language models (LLMs). Our hybrid system incorporates mechanisms to control and evaluate the AI output, acknowledging and addressing the potential factual inaccuracies of LLMs. We instantiate our system in the cooking domain. Our approach utilizes association rule mining on a large database of recipes to identify key patterns. When learners submit a recipe for feedback, a LLM enriches it by integrating these patterns. Then, learners are prompted to actively process the example by highlighting the changes and critically assessing the modifications. This strategy transforms traditional example-based learning into a dynamic, scalable, interactive educational tool.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {171},
numpages = {10},
keywords = {Example-based Learning, Generative AI, Procedural Writing},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3689187.3709614,
author = {Prather, James and Leinonen, Juho and Kiesler, Natalie and Gorson Benario, Jamie and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Vee and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and Smith, David H. and Strickroth, Sven and Zingaro, Daniel},
title = {Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709614},
doi = {10.1145/3689187.3709614},
abstract = {Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report aims to summarize and explain what is happening on the ground in computing classrooms. We provide a systematic literature review; a survey of educators and industry professionals; and interviews with educators using GenAI in their courses, educators studying GenAI, and researchers who create GenAI tools to support computing education. The triangulation of these methods and data sources expands the understanding of GenAI usage and perceptions at this critical moment for our community.},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {300–338},
numpages = {39},
keywords = {artificial intelligence, computing education, genai, generative ai, large language models, pedagogical practices, teaching computing},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3613904.3642700,
author = {Woodruff, Allison and Shelby, Renee and Kelley, Patrick Gage and Rousso-Schindler, Steven and Smith-Loud, Jamila and Wilcox, Lauren},
title = {How Knowledge Workers Think Generative AI Will (Not) Transform Their Industries},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642700},
doi = {10.1145/3613904.3642700},
abstract = {Generative AI is expected to have transformative effects in multiple knowledge industries. To better understand how knowledge workers expect generative AI may affect their industries in the future, we conducted participatory research workshops for seven different industries, with a total of 54 participants across three US cities. We describe participants’ expectations of generative AI’s impact, including a dominant narrative that cut across the groups’ discourse: participants largely envision generative AI as a tool to perform menial work, under human review. Participants do not generally anticipate the disruptive changes to knowledge industries currently projected in common media and academic narratives. Participants do however envision generative AI may amplify four social forces currently shaping their industries: deskilling, dehumanization, disconnection, and disinformation. We describe these forces, and then we provide additional detail regarding attitudes in specific knowledge industries. We conclude with a discussion of implications and research challenges for the HCI community.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {641},
numpages = {26},
keywords = {generative AI, industries, knowledge work},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3686803,
author = {Li, Jialong and Zhang, Mingyue and Li, Nianyu and Weyns, Danny and Jin, Zhi and Tei, Kenji},
title = {Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1556-4665},
url = {https://doi.org/10.1145/3686803},
doi = {10.1145/3686803},
abstract = {Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this article aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI’s within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.†},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = sep,
articleno = {13},
numpages = {60},
keywords = {Self-Adaptive Systems, MAPE, Generative AI, Large Language Model, diffusion model, survey}
}

@inproceedings{10.1145/3628516.3659392,
author = {Kim, David Y.J. and Ravi, Prerna and Williams, Randi and Yoo, Daeun},
title = {App Planner: Utilizing Generative AI in K-12 Mobile App Development Education},
year = {2024},
isbn = {9798400704420},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628516.3659392},
doi = {10.1145/3628516.3659392},
abstract = {App Planner is an interactive support tool for K-12 students, designed to assist in creating mobile applications. By utilizing generative AI, App Planner helps students articulate the problem and solution through guided conversations via a chat-based interface. It assists them in brainstorming and formulating new ideas for applications, provides feedback on those ideas, and stimulates creative thinking. Here we report usability tests from our preliminary study with high-school students who appreciated App Planner for aiding the app design process and providing new viewpoints on human aspects especially the potential negative impact of their creation.},
booktitle = {Proceedings of the 23rd Annual ACM Interaction Design and Children Conference},
pages = {770–775},
numpages = {6},
keywords = {Education Technology, Generative AI, Mobile Application},
location = {Delft, Netherlands},
series = {IDC '24}
}

@inproceedings{10.1145/3706599.3719819,
author = {W\"{o}hler, Leslie and Son, Takubon and Ikehata, Satoshi and Aizawa, Kiyoharu},
title = {Analyzing Viewer Perception of Generative AI-Based Editing in 360° Images Across Display Modalities},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719819},
doi = {10.1145/3706599.3719819},
abstract = {Recent advances in automatic AI-based media generation as well as immersive viewing technologies raise questions on how viewers are maliciously manipulated by content pretending to represent the real world and whether the display modality affects the perception of viewers. Therefore, we investigate the perception of image edits performed using generative AI in 360° images viewed on regular screen as well as on head-mounted display (HMD). We use the think aloud protocol to have participants freely describe image elements they suspect to be edited and provide the reasons for their suspicions. In our experiments, participants were able to recognize around 35% of edits and provided more descriptive information for stimuli viewed on a regular screen. Furthermore, we analyze and code the free answers finding that especially an unnatural impression, knowledge of the scene as well as context clues are used to correctly identify edited image regions.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {71},
numpages = {7},
keywords = {image manipulation, human perception, VR, generative AI},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706599.3716302,
author = {Jiang, Harry H. and Agnew, William and Friedlander, Tim and Yang, Zhuolin and Fox, Sarah E and Bernstein, Michael S. and Passananti, Josephine Charlie and Ogata, Megumi and Ortiz, Karla},
title = {Forging an HCI Research Agenda with Artists Impacted by Generative AI},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3716302},
doi = {10.1145/3706599.3716302},
abstract = {Alongside the proliferation of commercial generative AI products in the past two years, HCI research focused on the usage of such tools has been conducted at a remarkable volume. This new area of study has been critical to various degrees of the systems which create and uphold these technologies. However, as the deployment of generative AI products has engendered many observable harms, HCI work in this area is now more relevant than ever. While thoughtful research can uncover and promote symbiotic applications of AI technologies, uncritical work can contribute to normalization of harmful uses, skew public perception of technologies, or serve to advance business interests.The aim of this panel is to revisit the attitudes the HCI community holds towards generative AI and provide a forum to interact with an industry that has seen the first upheavals caused by this technology, the creative arts.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {760},
numpages = {4},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3613904.3642919,
author = {Wadinambiarachchi, Samangi and Kelly, Ryan M. and Pareek, Saumya and Zhou, Qiushi and Velloso, Eduardo},
title = {The Effects of Generative AI on Design Fixation and Divergent Thinking},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642919},
doi = {10.1145/3613904.3642919},
abstract = {Generative AI systems have been heralded as tools for augmenting human creativity and inspiring divergent thinking, though with little empirical evidence for these claims. This paper explores the effects of exposure to AI-generated images on measures of design fixation and divergent thinking in a visual ideation task. Through a between-participants experiment (N=60), we found that support from an AI image generator during ideation leads to higher fixation on an initial example. Participants who used AI produced fewer ideas, with less variety and lower originality compared to a baseline. Our qualitative analysis suggests that the effectiveness of co-ideation with AI rests on participants’ chosen approach to prompt creation and on the strategies used by participants to generate ideas in response to the AI’s suggestions. We discuss opportunities for designing generative AI systems for ideation support and incorporating these AI tools into ideation workflows.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {380},
numpages = {18},
keywords = {Creativity support tools, Design fixation, Generative-AI},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3653666.3656065,
author = {Smith, Julie M.},
title = {"I'm Sorry, but I Can't Assist": Bias in Generative AI},
year = {2024},
isbn = {9798400706264},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653666.3656065},
doi = {10.1145/3653666.3656065},
abstract = {Research Questions: (1) Is there a pattern of racial bias in student advising recommendations made by generative AI? (2) What safeguards can promote equity when using generative AI in high-stakes decision-making? Methodology: Using lists of names associated with various ethnic/racial groups, we asked ChatGPT and Claude AI for recommendations for colleges and majors for each student. Results: ChatGPT was more likely to recommend STEM majors to some student groups. ChatGPT did not show systematic bias in various metrics of school quality, but Claude AI did. There were also overall differences in the colleges recommended by Claude AI and ChatGPT. Implications: We provide cautions and recommendations for using generative AI in high-stakes tasks.},
booktitle = {Proceedings of the 2024 on RESPECT Annual Conference},
pages = {75–80},
numpages = {6},
keywords = {artificial intelligence, generative ai, large language models, quity, racism, student advising},
location = {Atlanta, GA, USA},
series = {RESPECT 2024}
}

@inproceedings{10.1145/3706468.3706533,
author = {Ortega-Arranz, Alejandro and Topali, Paraskevi and Molenaar, Inge},
title = {Configuring and Monitoring Students' Interactions with Generative AI Tools: Supporting Teacher Autonomy},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706533},
doi = {10.1145/3706468.3706533},
abstract = {The widespread use of Generative Artificial Intelligence (GenAI) tools, such as ChatGPT, has come along with multiple benefits in education (e.g., 24h teacher, augmenting student monitoring). However, at the same time, these tools hinder teachers’ autonomy, limiting the capacity and freedom to exert control over students’ actions and their learning process. Additionally, the generic character of the GenAI output usually lacks contextualization (e.g., course curriculum, students’ age), thus hampering the successful attainment of the course goals. To address these issues, this paper proposes the development of a system mediating between the GenAI interfaces and their back-ends. This system allows teachers to monitor the students’ interactions and align the given answers with the course learning objectives and teaching methods. This research follows the Systems Development Research methodology, and within the first iteration, we developed a system prototype that was evaluated with 8 secondary-school teachers. Results showed a high perceived usefulness of the system for monitoring students’ interactions; for alerting the teachers to take specific actions (e.g., suspicious copy-paste behaviours), and for having control over the GenAI outputs. Additionally, while most teachers perceived a higher autonomy level within the given scenarios, some teachers did not. The evaluation also served to collect further requirements and usability features to keep improving the tool in the next methodological iterations.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {895–902},
numpages = {8},
keywords = {Generative AI, Learning Analytics, GenAI Analytics, Human-Centred Design, Teachers},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3678884.3689133,
author = {Brubaker, Jed R. and Fiesler, Casey and Madaio, Michael and Tang, John and Wong, Richmond Y.},
title = {Generative AI Going Awry: Enabling Designers to Proactively Avoid It in CSCW Applications},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678884.3689133},
doi = {10.1145/3678884.3689133},
abstract = {The rapid development and deployment of generative AI technologies creates a design challenge of how to proactively understand the implications of productizing and deploying these new technologies, especially with regard to negative design implications. This is especially concerning in CSCW applications, where AI agents can introduce misunderstandings or even misdirections with the people interacting with the agent. In this panel, researchers from academia and industry will reflect on their experiences with ideas, methods, and processes to enable designers to proactively shape the responsible design of genAI in collaborative applications. The panelists represent a range of different approaches, including speculative fiction, design activities, design toolkits, and process guides. We hope that the panel encourages a discussion in the CSCW community around techniques we can put into practice today to enable the responsible design of genAI.},
booktitle = {Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
pages = {125–127},
numpages = {3},
keywords = {design, generative ai, redteaming},
location = {San Jose, Costa Rica},
series = {CSCW Companion '24}
}

@inproceedings{10.1145/3708036.3708178,
author = {Niu, Hailong and Gong, Xinlu},
title = {The Role of Generative AI in Higher Education: A Decade of Current Status and Future Prospects},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708178},
doi = {10.1145/3708036.3708178},
abstract = {With the rapid development of Generative AI technology, particularly large language models like ChatGPT. Generative AI has brought profound transformations to teaching methods, learning experiences, and assessment models, but it also presents challenges related to academic integrity and educational equity. The purpose of this study is to analyze the current state of Generative AI applications in higher education over the past decade and its future development trends using a comprehensive bibliometric and scientometric approach. The study selects 620 papers from the Web of Science database, published between 2014 and 2024, related to Generative AI and higher education, and employs VOSviewer and CiteSpace software for data analysis and visualization. The results show a significant increase in research on the application of Generative AI in higher education since 2018, with a particular focus on personalized learning, teaching assessment, and interdisciplinary education, which have garnered widespread attention. Through network analyses of collaboration among authors, institutions. This study not only provides researchers with insights into the current status and development trends of Generative AI in higher education but also lays the foundation for deeper discussions on issues such as educational equity and academic integrity.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {848–852},
numpages = {5},
keywords = {generative AI, higher education, large language models},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3702212.3702214,
author = {Clift, Lee and Petrovska, Olga},
title = {Learning without Limits: Analysing the Usage of Generative AI in a Summative Assessment},
year = {2025},
isbn = {9798400711725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702212.3702214},
doi = {10.1145/3702212.3702214},
abstract = {This paper explores how Generative AI (GenAI) can be introduced within summative assessment components in software engineering education. We present an example of an assessment which allows learners to use GenAI in a freeform, constructionist manner, as part of a large, software development project. This work is inspired by previously executed AI-focused assessments and surveys, which explicitly indicate that learners on an Applied Software Engineering Degree Apprenticeship Programme want to formally learn how to use GenAI tools when programming and their employers want to see these skills from graduates. The learning outcome of the assignment was for learners to explore a typical developmental pipeline as a solo developer, moving from design to development to finished product. Learners were marked exclusively on their end product and understanding of application components, not the written code itself, resulting in an assessment where the end product and project were prioritised over foundational code (which was adequately assessed in other components). The results show that all learners used GenAI to some extent during their project, and in all cases, they found it beneficial for large programming tasks. Learners were generally able to produce a larger, more comprehensive and more ambitious project, compared to previous years. It is proposed that removing the barrier to GenAI - and demystifying it - can encourage a constructionist approach to its use, and normalise it as a potential tool for programming.},
booktitle = {Proceedings of the 9th Conference on Computing Education Practice},
pages = {5–8},
numpages = {4},
keywords = {GenAI, software engineering, education, apprenticeship},
location = {
},
series = {CEP '25}
}

@inproceedings{10.1145/3626253.3635595,
author = {Hamerski, Patti C.},
title = {Generative AI as a Resource for Creativity in Computational Physics},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635595},
doi = {10.1145/3626253.3635595},
abstract = {Generative artificial intelligence (gen-AI) has become ubiquitous in daily life, including classroom environments where students are using it to assist them on their coursework. Given the widespread use of this tool and the lack of knowledge over how it can support learning, there is a need for educators to have a framework for using it in the classroom and teaching their students usage strategies that are beneficial for learning. One pathway forward is through creativity, a process crucial for learning and also connected to the act of using gen-AI. This poster demonstrates the results of a study designed to provide an in-depth view on how creativity intersects with gen-AI usage in a computational physics course. In the course, students learn about computing tools during group-based, open-ended computational physics activities. Students are often tasked with using gen-AI to explore and help make decisions. The findings demonstrate a connection between using gen-AI and engaging in creative processes, and the implications point to strategies for supporting student usage of gen-AI.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1666–1667},
numpages = {2},
keywords = {computational science, creativity, curriculum design, generative ai},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1613/jair.1.15278,
author = {Franceschelli, Giorgio and Musolesi, Mirco},
title = {Reinforcement Learning for Generative AI: State of the Art, Opportunities and Open Research Challenges},
year = {2024},
issue_date = {Apr 2024},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {79},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.15278},
doi = {10.1613/jair.1.15278},
abstract = {Generative Artificial Intelligence (AI) is one of the most exciting developments in Computer Science of the last decade. At the same time, Reinforcement Learning (RL) has emerged as a very successful paradigm for a variety of machine learning tasks. In this survey, we discuss the state of the art, opportunities and open research questions in applying RL to generative AI. In particular, we will discuss three types of applications, namely, RL as an alternative way for generation without specified objectives; as a way for generating outputs while concurrently maximizing an objective function; and, finally, as a way of embedding desired characteristics, which cannot be easily captured by means of an objective function, into the generative process. We conclude the survey with an in-depth discussion of the opportunities and challenges in this fascinating emerging area.},
journal = {J. Artif. Int. Res.},
month = apr,
numpages = {30}
}

@inproceedings{10.1145/3623762.3633499,
author = {Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir},
title = {The Robots Are Here: Navigating the Generative AI Revolution in Computing Education},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633499},
doi = {10.1145/3623762.3633499},
abstract = {Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {108–159},
numpages = {52},
keywords = {ai, artificial intelligence, chatgpt, code generation, codex, computer programming, copilot, cs1, curriculum, generative ai, github, gpt, gpt-3, gpt-4, large language models, llm, llms, novice programming, openai, pedagogical practices, programming},
location = {Turku, Finland},
series = {ITiCSE-WGR '23}
}

@inproceedings{10.1145/3729605.3729638,
author = {Wang, Xuna},
title = {Generative AI Based on Deep Knowledge Tracing for Academic Insight and Intelligent Learning Strategy Optimization},
year = {2025},
isbn = {9798400714405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3729605.3729638},
doi = {10.1145/3729605.3729638},
abstract = {The advancement of educational technology and the need for diverse development of students have jointly promoted personalized learning to become the core concern of the current education field. However, how to track students' mastery of knowledge in real time and optimize teaching strategies have become the key links of personalized learning. Based on the sequential data of students' learning process, this paper constructs a deep knowledge tracking model to predict students' mastery of knowledge points. According to students' knowledge acquisition, the use of generative AI is further proposed to optimize the corresponding teaching strategies. It is found that the deep knowledge tracking model can effectively evaluate students' knowledge grasp, and the teaching strategy combined with generative AI can be more targeted to improve students' learning effect.},
booktitle = {Proceedings of the 2025 International Conference on Big Data and Informatization Education},
pages = {184–189},
numpages = {6},
keywords = {deep knowledge tracking, generative AI, personalized learning},
location = {
},
series = {ICBDIE '25}
}

@inproceedings{10.1145/3706598.3713829,
author = {Zeng, Yuhan and Shi, Yingxuan and Huang, Xuehan and Nah, Fiona and LC, RAY},
title = {"Ronaldo's a poser!": How the Use of Generative AI Shapes Debates in Online Forums},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713829},
doi = {10.1145/3706598.3713829},
abstract = {Online debates can enhance critical thinking but may escalate into hostile attacks. As humans are increasingly reliant on Generative AI (GenAI) in writing tasks, we need to understand how people utilize GenAI in online debates. To examine the patterns of writing behavior while making arguments with GenAI, we created an online forum for soccer fans to engage in turn-based and free debates in a post format with the assistance of ChatGPT, arguing on the topic of "Messi vs Ronaldo". After 13 sessions of two-part study and semi-structured interviews with 39 participants, we conducted content and thematic analyses to integrate insights from interview transcripts, ChatGPT records, and forum posts. We found that participants prompted ChatGPT for aggressive responses, created posts with similar content and logical fallacies, and sacrificed the use of ChatGPT for better human-human communication. This work uncovers how polarized forum members work with GenAI to engage in debates online.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {158},
numpages = {22},
keywords = {Co-Writing, AI-Mediated Communication, Human-AI Collaboration, Online Debate, Remote Collaboration, Generative AI, Large Language Models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3544549.3573794,
author = {Muller, Michael and Chilton, Lydia B and Kantosalo, Anna and Liao, Q. Vera and Maher, Mary Lou and Martin, Charles Patrick and Walsh, Greg},
title = {GenAICHI 2023: Generative AI and HCI at CHI 2023},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3573794},
doi = {10.1145/3544549.3573794},
abstract = {This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together. Following a successful workshop in 2022, we convene the interdisciplinary research domain of generative AI and HCI. Participation in this invitational workshop is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {350},
numpages = {7},
keywords = {Bias, Design, Generative AI, Uncertainty.},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@inproceedings{10.1145/3588430.3597250,
author = {Vincent, Brent and Ayyar, Kartik},
title = {Roblox Generative AI in action},
year = {2023},
isbn = {9798400701580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588430.3597250},
doi = {10.1145/3588430.3597250},
abstract = {Roblox is investing in generative AI techniques to revolutionize the creation process on its platform. By leveraging natural language and other intuitive expressions of intent, creators can build interactive objects and scenes without complex modeling or coding. The use of AI image generation services and large language models aim to make creation faster and easier for every user on the platform.},
booktitle = {ACM SIGGRAPH 2023 Real-Time Live!},
articleno = {9},
numpages = {2},
keywords = {Education, Games, Lighting, Metaverse, Modeling, Pipeline, Real-Time Rendering},
location = {Los Angeles, CA, USA},
series = {SIGGRAPH '23}
}

@inproceedings{10.1145/3706599.3719972,
author = {Lin, Xin and Han, Xiaonan and Qiu, Junqiao},
title = {Generative AI in Special Education: Teachers' Insights on Instructional Enrichment vs. Accommodations},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719972},
doi = {10.1145/3706599.3719972},
abstract = {Generative Artificial Intelligence (GAI) holds significant potential for transforming education, yet its adoption in special education remains underexplored. It is important to investigate how special education teachers perceive and use GAI for two distinct instructional tasks: instructional enrichment and accommodations. Although the Technology Acceptance Model (TAM) has been extensively used to study technology adoption, its application to GAI in special education is underrepresented. This gap is critical as special education teachers must address diverse needs of students with multiple disabilities. Moreover, limited research had examined how TAM dimensions vary across different tasks. This late-breaking study revealed that teachers consistently rated GAI lower for accommodations across all TAM dimensions, with particularly differences in Intention to Use and Actual Use. The results highlighted the complexities of adopting GAI for distinct instructional purposes. Although GAI demonstrated potential for supporting instructional enrichment, its inability to generate individualized recommendations limited its effectiveness for accommodations.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {304},
numpages = {6},
keywords = {Generative Artificial Intelligence, Special Education, Technology Acceptance Model, Instructional Enrichment, Instructional Accommodations},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3613905.3647967,
author = {Kimmel, Bailey and Geisert, Austin Lee and Yaro, Lily and Gipson, Brendan and Hotchkiss, Ronald Taylor and Osae-Asante, Sidney Kwame and Vaught, Hunter and Wininger, Grant and Yamaguchi, Chase},
title = {Enhancing Programming Error Messages in Real Time with Generative AI},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3647967},
doi = {10.1145/3613905.3647967},
abstract = {Generative AI is changing the way that many disciplines are taught, including computer science. Researchers have shown that generative AI tools are capable of solving programming problems, writing extensive blocks of code, and explaining complex code in simple terms. Particular promise has been shown in using generative AI to enhance programming error messages. Both students and instructors have complained for decades that these messages are often cryptic and difficult to understand. Yet recent work has shown that students make fewer repeated errors when enhanced via GPT-4. We extend this work by implementing feedback from ChatGPT for all programs submitted to our automated assessment tool, Athene, providing help for compiler, run-time, and logic errors. Our results indicate that adding generative AI to an automated assessment tool does not necessarily make it better and that design of the interface matters greatly to the usability of the feedback that GPT-4 provided.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {608},
numpages = {7},
keywords = {AI, Artificial Intelligence, Automatic Code Generation, CS1, ChatGPT, Codex, Copilot, GPT-4, GitHub, HCI, Introductory Programming, LLM, Large Language Models, Novice Programming, OpenAI},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3636555.3636866,
author = {Cheng, Yixin and Lyons, Kayley and Chen, Guanliang and Ga\v{s}evi\'{c}, Dragan and Swiecki, Zachari},
title = {Evidence-centered Assessment for Writing with Generative AI},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636866},
doi = {10.1145/3636555.3636866},
abstract = {We propose a learning analytics-based methodology for assessing the collaborative writing of humans and generative artificial intelligence. Framed by the evidence-centered design, we used elements of knowledge-telling, knowledge transformation, and cognitive presence to identify assessment claims; we used data collected from the CoAuthor writing tool as potential evidence for these claims; and we used epistemic network analysis to make inferences from the data about the claims. Our findings revealed significant differences in the writing processes of different groups of CoAuthor users, suggesting that our method is a plausible approach to assessing human-AI collaborative writing.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {178–188},
numpages = {11},
keywords = {Assessment, Epistemic Network Analysis, Evidence-centered Design, Generative Artificial Intelligence},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3723420.3723428,
author = {Qiu, Xiaoming and Zhang, Shu},
title = {Application analysis of generative artificial intelligence in basic education},
year = {2025},
isbn = {9798400712876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723420.3723428},
doi = {10.1145/3723420.3723428},
abstract = {This paper makes a detailed analysis of the application of Generative ARTIFICIAL intelligence in the field of basic education, and clarifies the existing problems, including the alienation of teaching process, the adaptation of teachers and students to new technologies, and the accuracy of content generation. And the empirical research is carried out on its specific application in the field of basic education, including questionnaire survey, data analysis and so on. By evaluating the changes in learning interest, learning performance and learning interaction between the control group and the experimental group, the potential and problems of generative AI application in the field of basic education are clarified. On this basis, this research draws the conclusion that the application of generative AI in the field of basic education also requires teachers to strengthen the emotional input, strengthen the technical training for teachers and students, and improve the accuracy of high content of education, so as to better cope with the challenges brought by technological change.},
booktitle = {Proceedings of the 2024 7th International Conference on E-Business, Information Management and Computer Science},
pages = {41–46},
numpages = {6},
keywords = {basic education, educational development, generative artificial intelligence, problem, suggestion},
location = {
},
series = {EBIMCS '24}
}

@inproceedings{10.1145/3658271.3658337,
author = {Santos, Patricia de Oliveira and Figueiredo, Allan Chamon and Nuno Moura, Pedro and Diirr, Bruna and Alvim, Adriana C. F. and Santos, Rodrigo Pereira Dos},
title = {Impacts of the Usage of Generative Artificial Intelligence on Software Development Process},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658271.3658337},
doi = {10.1145/3658271.3658337},
abstract = {Context: Over the years, tools have been created to improve the execution of development process activities. The emergence of generative Artificial Intelligence (AI) and, more recently, the launch and dissemination of Copilot, ChatGPT-3 and other generative tools, have broadened the discussion about the possibility of using conversational generative AI tools in diverse development tasks. Problem: There is still a lack of secondary studies to map the literature about how software development process activities can be affected by the usage of generative AI tools. Solution: This study aims to identify in which activities of the software development process Natural Language (NL) generative AI tools have been used and how they can impact requirements specification, design/architecture, development and testing activities. IS Theory: The study was developed under the aegis of the Task Technology Fit theory. Method: This work presents the results of a Systematic Mapping Review (SMR) carried out to collect research results that investigate the application of generative AI tools in the software development process. Results: Results indicate that the main activities affected are development and testing and that, although there are still some issues to be addressed, there are benefits in using AI generative tools compared to using more traditional methods like human-human pair programming and code testing made by software engineering professionals. Contribution: It was possible to collect studies to identify in which activities of the software development process generative AI tools can be applied and what are the impacts of using this technology.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {65},
numpages = {9},
keywords = {ChatGPT, Copilot, Generative AI, Software Engineering, Software Process},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

@inproceedings{10.1145/3706598.3714212,
author = {Liu, Yujia and Zha, Siyu and Zhang, Yuewen and Wang, Yanjin and Zhang, Yangming and Xin, Qi and Nie, Lun Yiu and Zhang, Chao and Xu, Yingqing},
title = {BrickSmart: Leveraging Generative AI to Support Children's Spatial Language Learning in Family Block Play},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714212},
doi = {10.1145/3706598.3714212},
abstract = {Block-building activities are crucial for developing children’s spatial reasoning and mathematical skills, yet parents often lack the expertise to guide these activities effectively. BrickSmart, a pioneering system, addresses this gap by providing spatial language guidance through a structured three-step process: Discovery &amp; Design, Build &amp; Learn, and Explore &amp; Expand. This system uniquely supports parents in 1) generating personalized block-building instructions, 2) guiding parents to teach spatial language during building and interactive play, and 3) tracking children’s learning progress, altogether enhancing children’s engagement and cognitive development. In a comparative study involving 12 parent-child pairs children aged 6-8 years) for both experimental and control groups, BrickSmart demonstrated improvements in supportiveness, efficiency, and innovation, with a significant increase in children’s use of spatial vocabularies during block play, thereby offering an effective framework for fostering spatial language skills in children.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {645},
numpages = {19},
keywords = {AI Agent, Parent-child, Spatial Language, Block Play, Large Language Model, Generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3689535.3689553,
author = {Stone, Irene},
title = {Exploring Human-Centered Approaches in Generative AI and Introductory Programming Research: A Scoping Review},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689553},
doi = {10.1145/3689535.3689553},
abstract = {Recent advancements in generative artificial intelligence are poised to reshape introductory programming education, challenging conventional teaching methodologies. This paper presents a scoping review that explores the current understanding of integrating generative artificial intelligence tools in the learning of introductory programming. Through an analysis of 28 selected studies, this review provides a snapshot of the landscape in mid-2024, presenting benefits, concerns, and recommendations surrounding the use of generative artificial intelligence within programming education. It finds insufficient guidance on how to implement recommended pedagogical strategies, limited consideration of student perceptions and experiences, and a predominance of short study time frames. Additionally, there is a significant research gap in second-level education, particularly in the United Kingdom and Ireland. The paper discusses how these gaps signal a need for more human-centered approaches in the current research. The paper concludes with recommendations for future research, aiming to inspire further inquiry and advance the understanding of generative artificial intelligence’s role in programming education from a human-centered perspective.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {4},
numpages = {7},
keywords = {AI, CS1, ChatGPT, LLMs, artificial intelligence, code generation, generative AI, human-centered, learner perspectives, novice programming, pedagogical practices, programming, python, student-centered},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3614419.3644014,
author = {Wu, Chuhao and Wang, Xinyu and Carroll, John and Rajtmajer, Sarah},
title = {Reacting to Generative AI: Insights from Student and Faculty Discussions on Reddit},
year = {2024},
isbn = {9798400703348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614419.3644014},
doi = {10.1145/3614419.3644014},
abstract = {Generative Artificial intelligence (GenAI) such as ChatGPT has elicited strong reactions from almost all stakeholders across the education system. Education-oriented and academic social media communities provide an important venue for these stakeholders to share experiences and exchange ideas about GenAI, which is constructive for developing human-centered policies. This study examines early user reactions to GenAI, consisting of 725 Reddit threads between 06/2022 and 05/2023. Through natural language processing (NLP) and content analysis, we observe an increasingly negative sentiment in the discussion and identify six main categories of student and faculty experiences of GenAI in education. These experiences reflect concerns about academic integrity and AI’s negative impact on the values of traditional education. Our analysis also highlights the tension and burden imposed by new technologies. Our findings suggest that dialogue between stakeholders in the education community is critical and can mitigate sources of tension between students and faculty.},
booktitle = {Proceedings of the 16th ACM Web Science Conference},
pages = {103–113},
numpages = {11},
keywords = {Generative AI, Higher Education, Social Media, Topic Modeling},
location = {Stuttgart, Germany},
series = {WEBSCI '24}
}

@inproceedings{10.1145/3678884.3681895,
author = {Romero Lauro, Quentin and Bigham, Jeffrey P and Kotturi, Yasmine},
title = {Exploring the Role of Social Support When Integrating Generative AI in Small Business Workflows},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678884.3681895},
doi = {10.1145/3678884.3681895},
abstract = {Small business owners stand to benefit from generative AI technologies due to limited resources, yet they must navigate increasing legal and ethical risks. In this paper, we interview 11 entrepreneurs and support personnel to investigate existing practices of how entrepreneurs integrate generative AI technologies into their business workflows. Specifically, we build on scholarship in HCI which emphasizes the role of small, offline networks in supporting entrepreneurs' technology maintenance. We detail how entrepreneurs resourcefully leveraged their local networks to discover new use-cases of generative AI (e.g., by sharing accounts), assuage heightened techno-anxieties (e.g., by recruiting trusted confidants), overcome barriers to sustained use (e.g., by receiving wrap-around support), and establish boundaries of use. Further, we suggest how generative AI platforms may be redesigned to better support entrepreneurs, such as by taking into account the benefits and tensions of use in a social context.},
booktitle = {Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
pages = {485–492},
numpages = {8},
keywords = {entrepreneurship, generative ai, lean economies, social support},
location = {San Jose, Costa Rica},
series = {CSCW Companion '24}
}

@inproceedings{10.1145/3706598.3713804,
author = {Kiskola, Joel and Rydenfelt, Henrik and Olsson, Thomas and Haapanen, Lauri and V\"{a}nttinen, Noora and Nelimarkka, Matti and Vigren, Minna and Laaksonen, Salla-Maaria and Lehtiniemi, Tuukka},
title = {Generative AI and News Consumption: Design Fictions and Critical Analysis},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713804},
doi = {10.1145/3706598.3713804},
abstract = {The emergence of Generative AI features in news applications may radically change news consumption and challenge journalistic practices. To explore the future potentials and risks of this understudied area, we created six design fictions depicting scenarios such as virtual companions delivering news summaries to the user, AI providing context to news topics, and content being transformed into other formats on demand. The fictions, discussed with a multi-disciplinary group of experts, enabled a critical examination of the diverse ethical, societal, and journalistic implications of AI shaping this everyday activity. The discussions raised several concerns, suggesting that such consumer-oriented AI applications can clash with journalistic values and processes. These include fears that neither consumers nor AI could successfully balance engagement, objectivity, and truth, leading to growing detachment from shared understanding. We offer critical insights into the potential long-term effects to guide design efforts in this emerging application area of GenAI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {250},
numpages = {18},
keywords = {Design fiction, artificial intelligence, journalism, online news, speculative design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713233,
author = {Naqvi, Syeda Masooma and He, Ruichen and Kaur, Harmanpreet},
title = {Catalyst for Creativity or a Hollow Trend?: A Cross-Level Perspective on The Role of Generative AI in Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713233},
doi = {10.1145/3706598.3713233},
abstract = {Generative AI image creation tools have the potential to transform design education and practice, but raise critical concerns for creativity and ownership. We leverage the 2022 launch of tools like Midjourney and DALL.E as a point dividing design enthusiasts into pre- and post-tool learners. In this paper, we conduct 28 artifact-based interviews with designers at varying levels of tool introduction, to understand how they perceive and use generative AI in their design roles. Our results indicate a rift in the value system of designers, with experienced designers being more circumspect about the loss of traditional creativity and foundational design skills. On the practical side, there exists a tension between the growing marketability of AI-related skills for design vs. the limited affordances of these tools for achieving meaningful designs. We discuss implications for the shifting definitions of design as a field, creativity and ownership, and AI in the design curriculum.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {194},
numpages = {16},
keywords = {Generative AI, Design, Creativity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713393,
author = {Adnin, Rudaiba and Pandkar, Atharva and Yao, Bingsheng and Wang, Dakuo and Das, Maitraye},
title = {Examining Student and Teacher Perspectives on Undisclosed Use of Generative AI in Academic Work},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713393},
doi = {10.1145/3706598.3713393},
abstract = {With the widespread adoption of Generative Artificial Intelligence (GenAI) tools, ethical issues are being raised around the disclosure of their use in publishing, journalism, or artwork. Recent research has found that college students are increasingly using GenAI tools; however, we know less about when, why, and how they choose to hide or disclose their use of GenAI in academic work. To address this gap, we conducted an online survey (n=97) and interviews with fifteen college students followed by interviews with nine teachers who had experience with students’ undisclosed use of GenAI. Our findings elucidate the strategies students employ to hide their GenAI use and their justifications for doing so, alongside the strategies teachers follow to manage such non-disclosure. We unpack students’ non-disclosure of GenAI through the lens of cognitive dissonance and discuss practical considerations for teachers and students regarding ways to promote transparency in GenAI use in higher education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1071},
numpages = {17},
keywords = {Generative AI, undisclosed use, college students, AI in education},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3723178.3723268,
author = {Sadat Shanto, Shakib and Ahmed, Zishan and Jony, Akinul Islam},
title = {Generative AI for Programming Education: Can ChatGPT Facilitate the Acquisition of Fundamental Programming Skills for Novices?},
year = {2025},
isbn = {9798400713828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723178.3723268},
doi = {10.1145/3723178.3723268},
abstract = {Modern Generative AI (GAI) systems like ChatGPT have sparked much interest in their potential to revolutionize programming education, especially for beginners. However, the existing empirical data regarding the effectiveness of technologies like ChatGPT as autonomous programming tutors is presently limited. The present study investigates the capacity of ChatGPT to facilitate the acquisition of fundamental programming skills for novice programmers without human assistance. This study puts forth a conceptual framework (APEC - Adaptive Programming Education via ChatGPT) that integrates both bottom-up and top-down approaches, incorporating ChatGPT as the principal instructor for the study of programming. An empirical study was undertaken to assess the usefulness of ChatGPT as a tool for teaching novice programmers a new programming language. This empirical study was conducted on 20 undergraduate students. To provide an expert assessment of the quality of the responses, a survey was conducted with three programming experts proficient in Python. The survey findings indicate that ChatGPT is proficient in explaining core principles such as variables, data types, and control statements through conversational exchanges, adopting an intelligent and logical methodology. Nevertheless, certain constraints arise when dealing with increasingly complex topics.},
booktitle = {Proceedings of the 3rd International Conference on Computing Advancements},
pages = {685–692},
numpages = {8},
keywords = {Generative AI, ChatGPT, Programming Education, Educational Technology, Higher Education},
location = {
},
series = {ICCA '24}
}

@inproceedings{10.1145/3627217.3631585,
author = {Amresh, Ashish},
title = {Leveling Up Education: Harnessing Generative AI for Game-Based Learning},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3631585},
doi = {10.1145/3627217.3631585},
abstract = {Generative AI has exploded in popularity over the past few years and is showing no signs of slowing down. There is skepticism among educators and institutions on the best ways to harness its power without ignoring ethical and equitable challenges that arise with its use. One area where there is emerging consensus is in building personalized learning solutions that can provide equitable access to a wide range of learners without compromising on ethical challenges. Simultaneously game-based learning has proven to be a viable paradigm to engage learners and the ability of games to be able to adapt to the player/learner provides significant opportunities to build equitable and accessible personalized learning solutions. In this talk, we will discuss ways in which game-based learning and generative AI can synergistically be combined to take advantage of each other’s capabilities and create educational interventions that can be offered at scale. By combining the interactive and motivational aspects of games with the adaptability and intelligence of generative AI, educators can unlock new opportunities to cater to individual learning needs and cultivate a more effective and enjoyable learning process. In this keynote, we will look at experimental software frameworks that can drive and level up education in multiple contexts and showcase some exemplars that demonstrate the promise that this integration provides.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {4},
numpages = {1},
keywords = {Game-based Learning, Generative AI, Software Systems},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@inproceedings{10.1145/3627673.3680117,
author = {Xu, Anbang and Yu, Tan and Du, Min and Gundecha, Pritam and Guo, Yufan and Zhu, Xinliang and Wang, May and Li, Ping and Chen, Xinyun},
title = {Generative AI and Retrieval-Augmented Generation (RAG) Systems for Enterprise},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680117},
doi = {10.1145/3627673.3680117},
abstract = {This workshop introduces generative AI applications for enterprise, with a focus on retrieval-augmented generation (RAG) systems. Generative AI is a field of artificial intelligence that can create new content and solve complex problems. RAG systems are a novel generative AI technique that combines information retrieval with text generation to generate rich and diverse responses. RAG systems can leverage enterprise data, which is often specific, structured, and dynamic, to provide customized solutions for various domains. However, enterprise data also poses challenges such as scalability, security, and data quality. This workshop convenes researchers and practitioners to explore RAG and other generative AI systems in real-world enterprise scenarios, fostering knowledge exchange, collaboration, and identification of future directions. Relevant to the CIKM community, the workshop intersects with core areas of data science and machine learning, offering potential benefits across various domains.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5599–5602},
numpages = {4},
keywords = {enterprise application, generation, rag, retrieval},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3711006,
author = {He, Zhiting and Su, Jiayi and Chen, Li and Wang, Tianqi and Lc, Ray},
title = { 'I Recall the Past': Exploring How People Collaborate with Generative AI to Create Cultural Heritage Narratives},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711006},
doi = {10.1145/3711006},
abstract = {Visitors to cultural heritage sites often encounter official information, while local people's unofficial stories remain invisible. To explore expression of local narratives, we conducted a workshop with 20 participants utilizing Generative AI (GenAI) to support visual narratives, asking them to use Stable Diffusion to create images of familiar cultural heritage sites, as well as images of unfamiliar ones for comparison. The results revealed three narrative strategies and highlighted GenAI's strengths in illuminating, amplifying, and reinterpreting personal narratives. However, GenAI showed limitations in meeting detailed requirements, portraying cultural features, and avoiding bias, which were particularly pronounced with unfamiliar sites due to participants' lack of local knowledge. To address these challenges, we recommend providing detailed explanations, prompt engineering, and fine-tuning AI models to reduce uncertainties, using objective references to mitigate inaccuracies from participants' inability to recognize errors or misconceptions, and curating datasets to train AI models capable of accurately portraying cultural features.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW108},
numpages = {30},
keywords = {cultural heritage, familiarity, generative ai, narrative}
}

@inproceedings{10.1145/3678884.3681897,
author = {Yang, Simin and Tsui, Yuk Hang and Wang, Xian and Alhilal, Ahmad and Hadi Mogavi, Reza and Wang, Xuetong and Hui, Pan},
title = {From Prompt to Metaverse: User Perceptions of Personalized Spaces Crafted by Generative AI},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678884.3681897},
doi = {10.1145/3678884.3681897},
abstract = {Generative artificial intelligence (AI) has revolutionized content creation. In parallel, the Metaverse has emerged to transcend the constraints of our physical reality. While Generative AI has a multitude of exciting applications for the fields of writing, coding, and graphic design, its usage to personalize our virtual space has not yet been explored. In this paper, we investigate the application of Artificial Intelligence Generated Content (AIGC) to personalize our virtual spaces and enhance the metaverse experience. To this end, we present a pipeline to enable users to customize their virtual spaces. Moreover, we explore the hardware resources and latency required for personalized spaces, as well as user acceptance of the AI-generated spaces. Comprehensive user studies follow extensive system experiments. Our research evaluates users' perceptions of two generated spaces: panoramic images and 3D virtual spaces. According to our findings, users have shown a great interest in 3D personalized spaces, and the practicality and immersion of 3D space generation tools surpass panoramic space generation tools.},
booktitle = {Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
pages = {497–504},
numpages = {8},
keywords = {ai-generated content, generative artificial intelligence, hci, metaverse, personalization, virtual reality, virtual spaces},
location = {San Jose, Costa Rica},
series = {CSCW Companion '24}
}

@inproceedings{10.1145/3706598.3713946,
author = {Schecter, Aaron and Richardson, Benjamin},
title = {How the Role of Generative AI Shapes Perceptions of Value in Human-AI Collaborative Work},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713946},
doi = {10.1145/3706598.3713946},
abstract = {As artificial intelligence (AI) continues to transform the modern workplace, generative AI (GenAI) has emerged as a prominent tool capable of augmenting work processes. Defined by its ability to create or modify content, GenAI differs significantly from traditional machine learning models that classify, recognize, or predict patterns from existing data. This study explores the role of GenAI in shaping perceptions of AI's contribution and how these perceptions influence both creators’ internal assessments of their work and their anticipation of external evaluators’ assessments. Our research develops and empirically tests a structural model through a between-subjects experiment, revealing that the role GenAI plays in the work process significantly impacts perceived enhancements in work quality and effort relative to human input. Additionally, we identify a critical trade-off between fostering worker assessments of creativity and managing perceived external assessments of the work's value.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {530},
numpages = {15},
keywords = {Human-AI collaboration, creative work, generative AI, lab experiments},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3613904.3642160,
author = {Sun, Yuan and Jang, Eunchae and Ma, Fenglong and Wang, Ting},
title = {Generative AI in the Wild: Prospects, Challenges, and Strategies},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642160},
doi = {10.1145/3613904.3642160},
abstract = {Propelled by their remarkable capabilities to generate novel and engaging content, Generative Artificial Intelligence (GenAI) technologies are disrupting traditional workflows in many industries. While prior research has examined GenAI from a techno-centric perspective, there is still a lack of understanding about how users perceive and utilize GenAI in real-world scenarios. To bridge this gap, we conducted semi-structured interviews with (N = 18) GenAI users in creative industries, investigating the human-GenAI co-creation process within a holistic LUA (Learning, Using and Assessing) framework. Our study uncovered an intriguingly complex landscape: Prospects – GenAI greatly fosters the co-creation between human expertise and GenAI capabilities, profoundly transforming creative workflows; Challenges – Meanwhile, users face substantial uncertainties and complexities arising from resource availability, tool usability, and regulatory compliance; Strategies – In response, users actively devise various strategies to overcome many of such challenges. Our study reveals key implications for the design of future GenAI tools.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {747},
numpages = {16},
keywords = {Generative AI, Human-AI Collaboration, Transparency, User Agency},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3703619.3706049,
author = {Casas, Llogari and Mitchell, Kenny},
title = {Structured Teaching Prompt Articulation for Generative-AI Role Embodiment with Augmented Mirror Video Displays},
year = {2025},
isbn = {9798400713484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703619.3706049},
doi = {10.1145/3703619.3706049},
abstract = {We present a classroom enhanced with augmented reality video display in which students adopt snapshots of their corresponding virtual personas according to their teacher’s live articulated spoken educational theme, linearly, such as historical figures, famous scientists, cultural icons, and laterally according to archetypal categories such as world dance styles. We define a structure of generative AI prompt guidance to assist teachers with focused specified visual role embodiment stylization. By leveraging role-based immersive embodiment, our proposed approach enriches pedagogical practices that prioritize experiential learning.},
booktitle = {Proceedings of the 19th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry},
articleno = {15},
numpages = {7},
keywords = {Artificial Intelligence, Generative AI, Human-Computer Interaction, Virtual Reality},
location = {Nanjing, Guangdong Province, China},
series = {VRCAI '24}
}

@inproceedings{10.1145/3726010.3726029,
author = {Liu, Baiqiang},
title = {Network Security Issues Caused by Generative Artificial Intelligence},
year = {2025},
isbn = {9798400712845},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726010.3726029},
doi = {10.1145/3726010.3726029},
abstract = {It has recently emerged that generative Artificial Intelligence (AI) has been significantly developed and can create realistic speech, images, and video. Although such innovations provide many advantages, they pose major threats to the network's security. The research question of the study will, therefore, be the role and effects of generative artificial intelligence on network security, especially deepfake, artificial intelligence-driven phishing, and multimedia content manipulation. This research uses a case study analysis of real-life experiences of security threats in networked systems to show how generative AI can be misused. The findings reveal that: 1. Generative AI can create highly developed cyberattacks such as deepfake social engineering and AI-supplemented phishing, which use visually and audibly persuasive appeals to manipulate users. 2. The problem with this kind of security threat highlighted by AI is that most traditional security solutions lack awareness of such threats since they are incapable of effective real-time user authentication, over-dependence on visual and biometric verification, and lack of AI-awareness training. 3. There are significant gaps in cybersecurity policies and training. Many organizations lack formal protocols for addressing AI-related security risks, and often, organizations are applying generative AI technologies. In addressing the aforementioned vulnerabilities, the study recommends an improved security model that incorporates deepfake detection, more secure authentication, and even advanced anomaly detection systems. In furtherance, there should be improvements in policy that aim at commanding the AI media, ensuring comprehensive training of the employees on cybersecurity matters, and drives that aim at educating the public on how to enhance the strength for discouraging AI cybercrimes.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence, Digital Media Technology and Interaction Design},
pages = {132–136},
numpages = {5},
keywords = {Deepfakes, Generative AI, Manipulation of Multimedia Content, Network Security},
location = {
},
series = {ICADI '24}
}

@inproceedings{10.1145/3652620.3687773,
author = {Bucchiarone, Antonio and Cicchetti, Antonio and V\'{a}zquez-Ingelmo, Andrea and Adami, Filippo and Schiavo, Gianluca and Garc\'{\i}a-Holgado, Alicia and Garc\'{\i}a-Pe\~{n}alvo, Francisco Jos\'{e}},
title = {Designing and Generating Lesson Plans combining Open Educational Content and Generative AI},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687773},
doi = {10.1145/3652620.3687773},
abstract = {In this paper, we propose an approach for assisting educators in deriving lesson plans for complex learning subjects like Model-Driven Engineering (MDE) from existing educational materials, leveraging generative AI techniques. Our method focuses on guiding teachers in defining learning objectives and suggesting concrete learning activities for students. Central to our approach is the development of a metamodel that characterizes the methodology and serves as the foundation for implementing supporting tools. By utilizing available Open Educational Resources (OERs) and incorporating them into specific learning activities, our method provides a general framework for supporting educators in designing lesson plans. We present the methodology to generate lesson plans, the metamodel conceptualizing plans ingredients, and demonstrate their application through supporting tools, illustrating the potential of our approach in facilitating the development of MDE teaching materials.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {78–86},
numpages = {9},
keywords = {open educational resources, OERs, model-driven engineering, MDE, generative AI, educational paradigms, tailored learning activities, customizable learning content},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3691621.3694955,
author = {Qin, Xue and Weaver, Garrett},
title = {Utilizing Generative AI for VR Exploration Testing: A Case Study},
year = {2024},
isbn = {9798400712494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691621.3694955},
doi = {10.1145/3691621.3694955},
abstract = {As the virtual reality (VR) industry expands, the need for automated GUI testing for applications is growing rapidly. With its long-term memory and ability to process mixed data, including images and text, Generative AI (GenAI) shows the potential to understand complex user interfaces. In this paper, we conduct a case study to investigate the potential of using GenAI for field of view (FOV) analysis in VR exploration testing. Specifically, we examine how the model can assist in test entity selection and test action suggestions. Our experiments demonstrate that while GPT-4o achieves a 63% accuracy rate in object identification within an arbitrary FOV, it struggles with object organization and localization. We also identify critical contexts that can improve the accuracy of suggested actions across multiple FOVs. Finally, we discuss the limitations found during the experiment and offer insights into future research directions.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering Workshops},
pages = {228–232},
numpages = {5},
keywords = {virtual reality, GUI exploration testing, case study},
location = {Sacramento, CA, USA},
series = {ASEW '24}
}

@inproceedings{10.1145/3613904.3642438,
author = {Han, Ariel and Zhou, Xiaofei and Cai, Zhenyao and Han, Shenshen and Ko, Richard and Corrigan, Seth and Peppler, Kylie A},
title = {Teachers, Parents, and Students' perspectives on Integrating Generative AI into Elementary Literacy Education},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642438},
doi = {10.1145/3613904.3642438},
abstract = {The viral launch of new generative AI (GAI) systems, such as ChatGPT and Text-to-Image (TTL) generators, sparked questions about how they can be effectively incorporated into writing education. However, it is still unclear how teachers, parents, and students perceive and suspect GAI systems in elementary school settings. We conducted a workshop with twelve families (parent-child dyads) with children ages 8-12 and interviewed sixteen teachers in order to understand each stakeholder’s perspectives and opinions on GAI systems for learning and teaching writing. We found that the GAI systems could be beneficial in generating adaptable teaching materials for teachers, enhancing ideation, and providing students with personalized, timely feedback. However, there are concerns over authorship, students’ agency in learning, and uncertainty concerning bias and misinformation. In this article, we discuss design strategies to mitigate these constraints by implementing an adults-oversight system, balancing AI-role allocation, and facilitating customization to enhance students’ agency over writing projects.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {678},
numpages = {17},
keywords = {Artificial Intelligence, Generative AI, K-12 Education},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642800,
author = {Jin, Yucheng and Cai, Wanling and Chen, Li and Zhang, Yizhe and Doherty, Gavin and Jiang, Tonglin},
title = {Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642800},
doi = {10.1145/3613904.3642800},
abstract = {Music-based reminiscence has the potential to positively impact the psychological well-being of older adults. However, the aging process and physiological changes, such as memory decline and limited verbal communication, may impede the ability of older adults to recall their memories and life experiences. Given the advanced capabilities of generative artificial intelligence (AI) systems, such as generated conversations and images, and their potential to facilitate the reminiscing process, this study aims to explore the design of generative AI to support music-based reminiscence in older adults. This study follows a user-centered design approach incorporating various stages, including detailed interviews with two social workers and two design workshops (involving ten older adults). Our work contributes to an in-depth understanding of older adults’ attitudes toward utilizing generative AI for supporting music-based reminiscence and identifies concrete design considerations for the future design of generative AI to enhance the reminiscence experience of older adults.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1012},
numpages = {17},
keywords = {Generative AI, Human-AI Interaction, Music-based Reminiscence, Older Adults, Reminiscence},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3735513,
author = {Chun, Soon Ae and Noveck, Beth Simone},
title = {Introduction to the Special Issue on ChatGPT and other Generative AI Commentaries Part 2:  GenAI Augmented Government 4.0},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3735513},
doi = {10.1145/3735513},
abstract = {This special issue, part 2, continues the discussion from the previous issue on GenAI and other AI-augmented Government 4.0. It shows the current adoption and potential of GenAI-based transformation in the public sector. It also highlights risks and challenges of GenAI from different perspectives. The duality of GenAI as a creative and productive assistant in the public administration and service delivery, and as a structured analytical tool for decision-making support can make GenAI a favorite tool of trade and a catalyst for public sector transformation. However, rigorous testing and empirical findings are required for the sustainability of the GenAI Augmented Transformation in the public sector.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = may,
keywords = {Generative AI, Public Domain Innovations, ChatGPT, Large Language Models}
}

@inproceedings{10.1145/3641555.3705064,
author = {Erez, Yael and Ayali, Lilach and Hazzan, Orit},
title = {Evolution of Students' Attitudes Towards the Use of Generative AI Tools in a CS1 Course: Implications for Instructors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705064},
doi = {10.1145/3641555.3705064},
abstract = {Recent advancements in large language model-based generative artificial intelligence (GenAI) tools have transformed computer science education, presenting both opportunities and challenges. A study investigating students' attitudes toward these tools was conducted during an Introduction to Computer Science course. The target of the study was to gauge students' evolving attitudes toward using GenAI tools in the course, before, during and after ChatGPT was gradually assimilated into homework assignments. The study refers to three phases: preliminary phase, assimilation phase, and calibration stage, which currently takes place. Findings show that, in the preliminary phase, students appreciated the efficiency of GenAI tools offered but were concerned about developing a dependency on these tools and about ''cheating''. Findings from the assimilation phase indicate that consistent, guided exposure to GenAI tools positively shifted students' views, alleviating initial concerns and promoting a positive attitude toward using GenAI tools in the course. The targets of the calibration phase are: a) to examine how to leverage independent learning by formulating clear guidelines that can build trust in the technology and help overcome concerns regarding reliability and credibility; b) to check how GenAI can help students in a Introduction to Computer Science course acquire skills such as critical thinking and code comprehension. The study offers insights for educators on the integration of GenAI tools into computer science courses to enhance learning while maintaining academic integrity.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1740},
numpages = {1},
keywords = {critical thinking, cs1, generative ai, introduction to computer science, mixed methods, program comprehension, skills, students' attitudes},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3568812.3603476,
author = {Phung, Tung and P\u{a}durean, Victor-Alexandru and Cambronero, Jos\'{e} and Gulwani, Sumit and Kohn, Tobias and Majumdar, Rupak and Singla, Adish and Soares, Gustavo},
title = {Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603476},
doi = {10.1145/3568812.3603476},
abstract = {Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies. State-of-the-art models like OpenAI’s ChatGPT&nbsp;[8] and GPT-4&nbsp;[9] could enhance programming education in various roles, e.g., by acting as a personalized digital tutor for a student, a digital assistant for an educator, and a digital peer for collaborative learning&nbsp;[1, 2, 7]. In our work, we seek to comprehensively evaluate and benchmark state-of-the-art large language models for various scenarios in programming education. Recent works have evaluated several large language models in the context of programming education&nbsp;[4, 6, 10, 11, 12]. However, these works are limited for several reasons: they have typically focused on evaluating a specific model for a specific education scenario (e.g., generating explanations), or have considered models that are already outdated (e.g., OpenAI’s Codex&nbsp;[3] is no longer publicly available since March 2023). Consequently, there is a lack of systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios in programming education. These scenarios are designed to capture distinct roles these models could play, namely digital tutors, assistants, and peers, as discussed above. More concretely, we consider the following six scenarios: (1) program repair, i.e., fixing a student’s buggy program; (2) hint generation, i.e., providing a natural language hint to the student to help resolve current issues; (3) grading feedback, i.e., grading a student’s program w.r.t. a given rubric; (4) peer programming, i.e., completing a partially written program or generating a sketch for the solution program; (5) task creation, i.e., generating new tasks that exercise specific types of concepts or bugs; (6) contextualized explanation, i.e., explaining specific concepts or functions in the context of a given program. Our study uses a mix of quantitative and qualitative evaluation to compare the performance of these models with the performance of human tutors. We conduct our evaluation based on 5 introductory Python programming problems with a diverse set of input/output specifications. For each of these problems, we consider 5 buggy programs based on publicly accessible submissions from geeksforgeeks.org &nbsp;[5] (see Figure&nbsp;1); these buggy programs are picked to capture different types of bugs for each problem. We will provide a detailed analysis of the data and results in a longer version of this poster. Our preliminary results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors’ performance for several scenarios.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {41–42},
numpages = {2},
keywords = {ChatGPT, generative AI, introductory programming education, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@article{10.1145/3624732,
author = {Burtch, Gordon and Lee, Dokyun and Chen, Zhichen},
title = {Generative AI Degrades Online Communities},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/3624732},
doi = {10.1145/3624732},
abstract = {How large language models are influencing online communities.},
journal = {Commun. ACM},
month = feb,
pages = {40–42},
numpages = {3}
}

@inproceedings{10.1145/3628516.3659404,
author = {Baines, Alexander and Gruia, Lidia and Collyer-Hoar, Gail and Rubegni, Elisa},
title = {Playgrounds and Prejudices: Exploring Biases in Generative AI For Children.},
year = {2024},
isbn = {9798400704420},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628516.3659404},
doi = {10.1145/3628516.3659404},
abstract = {The influence of generative Artificial Intelligence (AI) on the propagation and amplification of societal biases, particularly in the context of children’s content creation, is a growing concern. By developing and testing a prototype tool designed to assist children in Digital Storytelling (DST), our research aimed to explore and mitigate the propagation of stereotypes through the use of a character-generating AI tool utilising Stable Diffusion. Despite initial aspirations, the tool demonstrated significant biases inherent in the underlying AI model, leading to the decision against its use by children. The findings we discovered contribute to a broader discourse on the development of ethical AI and its use, advocating for a more responsible and inclusive approach to technological innovation in the context of children’s digital media consumption and creation.},
booktitle = {Proceedings of the 23rd Annual ACM Interaction Design and Children Conference},
pages = {839–843},
numpages = {5},
keywords = {Artificial Intelligence, Bias, Child-Computer Interaction, Digital Story Telling, Ethics, Generative AI},
location = {Delft, Netherlands},
series = {IDC '24}
}

@inproceedings{10.1145/3643834.3661547,
author = {Aghel Manesh, Setareh and Zhang, Tianyi and Onishi, Yuki and Hara, Kotaro and Bateman, Scott and Li, Jiannan and Tang, Anthony},
title = {How People Prompt Generative AI to Create Interactive VR Scenes},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661547},
doi = {10.1145/3643834.3661547},
abstract = {Generative AI tools can provide people with the ability to create virtual environments and scenes with natural language prompts. Yet, how people will formulate such prompts is unclear—particularly when they inhabit the environment that they are designing. For instance, it is likely that a person might say, “Put a chair here,” while pointing at a location. If such linguistic and embodied features are common to people’s prompts, we need to tune models to accommodate them. In this work, we present a Wizard of Oz elicitation study with 22 participants, where we studied people’s implicit expectations when verbally prompting such programming agents to create interactive VR scenes. Our findings show when people prompted the agent, they had several implicit expectations of these agents: (1) they should have an embodied knowledge of the environment; (2) they should understand embodied prompts by users; (3) they should recall previous states of the scene and the conversation, and that (4) they should have a commonsense understanding of objects in the scene. Further, we found that participants prompted differently when they were prompting in situ (i.e. within the VR environment) versus ex situ (i.e. viewing the VR environment from the outside). To explore how these lessons could be applied, we designed and built Ostaad, a conversational programming agent that allows non-programmers to design interactive VR experiences that they inhabit. Based on these explorations, we outline new opportunities and challenges for conversational programming agents that create VR environments.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {2319–2340},
numpages = {22},
keywords = {embodied interaction, embodied prompting, generative ai, interactive virtual reality, multi-modal, prompting, virtual reality},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3716640.3716658,
author = {Feng, Tony Haoran and Luxton-Reilly, Andrew and W\"{u}nsche, Burkhard C and Denny, Paul},
title = {From Automation to Cognition: Redefining the Roles of Educators and Generative AI in Computing Education},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716658},
doi = {10.1145/3716640.3716658},
abstract = {Generative Artificial Intelligence (GenAI) offers numerous opportunities to revolutionise teaching and learning in Computing Education (CE). However, educators have expressed concerns that students may over-rely on GenAI and use these tools to generate solutions without engaging in the learning process. While substantial research has explored GenAI use in CE, and many Computer Science (CS) educators have expressed their opinions and suggestions on the subject, there remains little consensus on implementing curricula and assessment changes.In this paper, we describe our experiences with using GenAI in CS-focused educational settings and the changes we have implemented accordingly in our teaching in recent years since the popularisation of GenAI. From our experiences, we propose two primary actions for the CE community: 1) redesign take-home assignments to incorporate GenAI use and assess students on their process of using GenAI to solve a task rather than simply on the final product; 2) redefine the role of educators to emphasise metacognitive aspects of learning, such as critical thinking and self-evaluation. This paper presents and discusses these stances and outlines several practical methods to implement these strategies in CS classrooms. Then, we advocate for more research addressing the concrete impacts of GenAI on CE, especially those evaluating the validity and effectiveness of new teaching practices.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {164–171},
numpages = {8},
keywords = {Generative Artificial Intelligence, GenAI, Strategy, Assignments, Metacognition, Assessments},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3626252.3630854,
author = {Neyem, Andres and Sandoval Alcocer, Juan Pablo and Mendoza, Marcelo and Centellas-Claros, Leonardo and Gonzalez, Luis A. and Paredes-Robles, Carlos},
title = {Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630854},
doi = {10.1145/3626252.3630854},
abstract = {StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {951–957},
numpages = {7},
keywords = {capstone courses, chatgpt, generative ai, large language models, software engineering education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3689050.3705984,
author = {Tumedei, Gianni and Ceccarini, Chiara and Prandi, Catia},
title = {How are you, Mar Menor? Fostering Awareness About an Ecological Crisis through Children's Art and Conversational Generative AI},
year = {2025},
isbn = {9798400711978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689050.3705984},
doi = {10.1145/3689050.3705984},
abstract = {Educating children and teenagers on environmental issues is crucial, as they not only internalize the importance of ecological preservation but can also share this knowledge at home, spreading awareness within their families and communities about these delicate matters. In this work, we introduce an innovative approach to raising awareness of environmental challenges faced by the Mar Menor lagoon by blending children’s art with conversational artificial intelligence. We built an interactive narrative visualization where users can learn about the ecosystem while exploring related drawings created by children and engaging in voice conversations with a chatbot powered by generative AI. To validate our approach, we conducted a preliminary evaluation of the prototype during the European Researchers’ Night 2024 where we gathered positive feedback through user tests and questionnaires, proving the potential of combining children’s creativity and AI technology to foster environmental stewardship and raise awareness about fragile ecosystems.},
booktitle = {Proceedings of the Nineteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {65},
numpages = {7},
keywords = {Interactive Narrative Visualization, Generative AI, Large Language Model, Conversational User Interface, Children’s Art, Environmental Awareness, Education},
location = {
},
series = {TEI '25}
}

@inproceedings{10.1145/3658321.3658367,
author = {Santos, Patricia de Oliveira and Figueiredo, Allan Chamon and Nuno Moura, Pedro and Diirr, Bruna and Alvim, Adriana C. F. and Santos, Rodrigo Pereira Dos},
title = {How Do Information Technology Professionals Use Generative Artificial Intelligence?},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658321.3658367},
doi = {10.1145/3658321.3658367},
abstract = {Context: The emergence of generative Artificial Intelligence (AI) and, more recently, the dissemination of Copilot, ChatGPT-3 and similar tools have broadened the discussion about the possibility of using generative AI tools in many professional segments such as health, education, and technological area. Problem: Although some studies explore the potential of generative AI tools to assist Information Technology (IT) professionals in executing specific tasks, they do not delve into the professionals’ characteristics or collect information about multiple generative AI tools usage. Solution: Considering the possibilities brought by generative AI, this study aims to shed light on the perception of IT professionals about generative AI tools and characterize these professionals’ profiles. IS Theory: This research is based on the Technology Acceptance Model. Method: A survey research was carried out with IT professionals so as to identify how these professionals are using generative AI and gather information about these professionals’ profiles. Results: Results show that 70,5% (43 out of 61) of the respondents use some generative AI tool, the majority of whom are software development professionals, and, despite the problems faced when using these tools, 86% of these professionals recommend using them. Contribution: In this study the profile of the IT professionals using generative AI was identified, it was then possible to evaluate the acceptance of such tools among these professionals and identify the main reasons why some of them are not yet using generative AI.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {56},
numpages = {9},
keywords = {Generative AI, IT Professional, Survey},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

@inproceedings{10.1145/3699538.3699546,
author = {Keuning, Hieke and Alpizar-Chacon, Isaac and Lykourentzou, Ioanna and Beehler, Lauren and K\"{o}ppe, Christian and de Jong, Imke and Sosnovsky, Sergey},
title = {Students' Perceptions and Use of Generative AI Tools for Programming Across Different Computing Courses},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699546},
doi = {10.1145/3699538.3699546},
abstract = {Investigation of students’ perceptions and opinions on the use of generative artificial intelligence (GenAI) in education is a topic gaining much interest. Studies addressing this are typically conducted with large heterogeneous groups, at one moment in time. However, how students perceive and use GenAI tools can potentially depend on many factors, including their background knowledge, familiarity with the tools, and the learning goals and policies of the courses they are taking. In this study we explore how students following computing courses use GenAI for programming-related tasks across different programs and courses: Bachelor and Master, in courses in which learning programming is the learning goal, courses that require programming as a means to achieve another goal, and in courses in which programming is optional, but can be useful. We are also interested in changes over time, since GenAI capabilities are changing at a fast pace, and users are adopting GenAI increasingly. We conducted three consecutive surveys (fall ‘23, winter ‘23, and spring ‘24) among students of all computing programs of a large European research university. We asked questions on the use in education, ethics, and job prospects, and we included specific questions on the (dis)allowed use of GenAI tools in the courses they were taking at the time. We received 264 responses, which we quantitatively and qualitatively analyzed, to find out how students have employed GenAI tools across 59 different computing courses, and whether the opinion of an average student about these tools evolves over time. Our study contributes to the emerging discussion of how to differentiate GenAI use across different courses, and how to align its use with the learning goals of a computing course.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {14},
numpages = {12},
keywords = {Generative AI, Large Language Models, Computing Education, Programming Courses},
location = {
},
series = {Koli Calling '24}
}

@article{10.1145/3674847,
author = {Howison, Mark and Ensor, William O. and Maharjan, Suraj and Parikh, Rahil and Sengamedu, Srinivasan H. and Daniels, Paul and Gaither, Amber and Yeats, Carrie and Reddy, Chandan K. and Hastings, Justine S.},
title = {Extracting Structured Labor Market Information from Job Postings with Generative AI},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
url = {https://doi.org/10.1145/3674847},
doi = {10.1145/3674847},
abstract = {Labor market information is an important input to labor, workforce, education, and macroeconomic policy. However, granular and real-time data on labor market trends are lacking; publicly available data from survey samples are released with significant lags and miss critical information such as skills and benefits. We use generative Artificial Intelligence to automatically extract structured labor market information from unstructured online job postings for the entire U.S. labor market. To demonstrate our methodology, we construct a sample of 6,800 job postings stratified by 68 major occupational groups, extract structured information on educational requirements, remote-work flexibility, full-time availability, and benefits, and show how these job characteristics vary across occupations. As a validation, we compare frequencies of educational requirements by occupation from our sample to survey data and find no statistically significant difference. Finally, we discuss the scalability to collections of millions of job postings. Our results establish the feasibility of measuring labor market trends at scale from online job postings thanks to advances in generative AI techniques. Improved access to such insights at scale and in real-time could transform the ability of policy leaders, including federal and state agencies and education providers, to make data-informed decisions that better support the American workforce.},
journal = {Digit. Gov.: Res. Pract.},
month = feb,
articleno = {9},
numpages = {12},
keywords = {Workforce, education, policy, large language models, Amazon Bedrock}
}

@article{10.1145/3592981,
author = {Denning, Peter J.},
title = {Can Generative AI Bots Be Trusted?},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/3592981},
doi = {10.1145/3592981},
abstract = {It will be a long road to learning how to use generative AI wisely.},
journal = {Commun. ACM},
month = may,
pages = {24–27},
numpages = {4}
}

@inproceedings{10.1145/3649217.3653527,
author = {Martini, Simone},
title = {Teaching Programming in the Age of Generative AI},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653527},
doi = {10.1145/3649217.3653527},
abstract = {Programming has been considered the "essence of informatics" since the beginning of computing as a discipline. But programming in the fifties was very different from what we know today, and one of the goals (or dreams) throughout the history of programming language technology, has been "automatic programming''---the ability to automatically generate computer code starting from a high(er)-level description of the specification of that code. What this meant changed over the years, from punching paper tape, to compiling high-level programming languages, to program synthesis.Today, however, the availability of machine learning artefacts that produce high-level code from natural language specifications has completely changed the traditional meaning. To the extent that some computer scientists have begun to question the received wisdom that the core of their discipline is deeply rooted in programming.If programming and programming languages are no longer the essence of computer science, this changes the epistemology of the discipline itself. Moreover, if we are at the end of programming, we should also change the curriculum, where programming, algorithms and programming languages play a major role. Several recent papers reviewed the performance of code generators based on large language models on typical CS1 problems (e.g., from the many possible citations and how machine learning impacts K-12 teaching.Starting from this data, I will argue for the role of programming in the curriculum, distinguishing between programming taught as part of a holistic curriculum (as in some non-technical high schools) or as a vocational tool. I will use Simondon's notion of (closed and open) technical object as an interpretive lens, together with Calvino's reflections on the availability of writing machines capable of replacing the poet and the author.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {1–2},
numpages = {2},
keywords = {epistemology, large language models, programming},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3610969.3610982,
author = {Mahon, Joyce and Mac Namee, Brian and Becker, Brett A.},
title = {No More Pencils No More Books: Capabilities of Generative AI on Irish and UK Computer Science School Leaving Examinations},
year = {2023},
isbn = {9798400708763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610969.3610982},
doi = {10.1145/3610969.3610982},
abstract = {We investigate the capabilities of ChatGPT (GPT-4) on second-level (high-school) computer science examinations: the UK A-Level and Irish Leaving Certificate. Both are national, government-set / approved, and centrally assessed examinations. We also evaluate performance differences in exams made publicly available before and after the ChatGPT knowledge cutoff date, and investigate what types of question ChatGPT struggles with. We find that ChatGPT is capable of achieving very high marks on both exams and that the performance difference before and after the knowledge cutoff date are minimal. We also observe that ChatGPT struggles with questions involving symbols or images, which can be mitigated when in-text information ‘fills in the gaps’. Additionally, GPT-4 performance can be negatively impacted when an initial inaccurate answer leads to further inaccuracies in subsequent parts of the same question. Finally, the element of choice on the Leaving Certificate is a significant advantage in achieving a high grade. Notably, there are minimal occurrences of hallucinations in answers and few errors in solutions not involving images. These results reveal several strengths and weaknesses of these exams in terms of how generative AI performs on them and have implications for exam design, the construction of marking schemes, and could also shift the focus of what is examined and how.},
booktitle = {Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {2},
numpages = {7},
keywords = {A-Level, Artificial Intelligence, ChatGPT, GPT-4, Generative AI, Ireland, K-12, LCCS, Leaving Certificate, UK, examinations, high school, school, second-level},
location = {Swansea, Wales Uk},
series = {UKICER '23}
}

@inproceedings{10.1145/3640794.3665542,
author = {Ouaazki, Abdessalam and Bergram, Kristoffer and Farah, Juan Carlos and Gillet, Denis and Holzer, Adrian},
title = {Generative AI-Enabled Conversational Interaction to Support Self-Directed Learning Experiences in Transversal Computational Thinking},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640794.3665542},
doi = {10.1145/3640794.3665542},
abstract = {As computational thinking (CT) becomes increasingly acknowledged as an important skill in education, self-directed learning (SDL) emerges as a key strategy for developing this capability. The advent of generative AI (GenAI) conversational agents has disrupted the landscape of SDL. However, many questions still arise about several user experience aspects of these agents. This paper focuses on two of these questions: personalization and long-term support. As such, the first part of this study explores the effectiveness of personalizing GenAI through prompt-tuning using a CT-based prompt for solving programming challenges. The second part focuses on identifying the strengths and weaknesses of a GenAI model in a semester-long programming project. Our findings indicate that while prompt-tuning could hinder ease of use and perceived learning assistance, it might lead to higher learning outcomes. Results from a thematic analysis also indicate that GenAI is useful for programming and debugging, but it presents challenges such as over-reliance and diminishing utility over time.},
booktitle = {Proceedings of the 6th ACM Conference on Conversational User Interfaces},
articleno = {13},
numpages = {12},
keywords = {ChatGPT, Chatbots, Education, Generative AI, Programming, Student Perceptions},
location = {Luxembourg, Luxembourg},
series = {CUI '24}
}

@inproceedings{10.1145/3657054.3657125,
author = {Beltran, Marco Antonio and Ruiz Mondragon, Marina Ivette and Han, Seung Hun},
title = {Comparative Analysis of Generative AI Risks in the Public Sector},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657125},
doi = {10.1145/3657054.3657125},
abstract = {The landscape of artificial intelligence (AI) has experienced a monumental shift with the emerging of Generative AI (GenAI), which has demonstrated to be a transformative tool across diverse sectors. GenAI outputs can span various digital formats, including text, images, videos, and audio, generating particular interest in the public sector. The growing interest of governments in integrating GenAI technologies in public sector operations is marked by the creation of emerging governance instruments and the formulation of soft laws, like standards, principles, and guidelines. This study aims to delve into the intricacies and potential risks associated with the deployment of GenAI within government. Through a qualitative content analysis, the research meticulously examines GenAI usage guidelines issued by Australia, Canada, New Zealand, the United Kingdom, and South Korea. The objective is to discern the risks acknowledged by these countries' soft laws and compare them with the risks identified by scholars in the field. The performed comparative analysis across countries suggest that the use of GenAI in the public sector raises common risks such as information leakage, data privacy, security, and concerns over public trust. By elucidating the varied risk perceptions across different national contexts, this study provides theoretical and practical implications related to the risks of GenAI within the public sector. Moreover, it sets a foundation for future research and policy development, ensuring that generative AI is used as a force for good in public governance.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {610–617},
numpages = {8},
keywords = {GenAI, GenAI Policy and Regulation, Public sector, Risks},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

@inproceedings{10.1145/3626253.3635427,
author = {Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.},
title = {Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635427},
doi = {10.1145/3626253.3635427},
abstract = {CS50.ai is an AI-based educational tool developed and integrated into CS50 at Harvard University using large language models (LLMs), supporting both in-person and online learners. CS50.ai encapsulates a variety of AI-based tools designed to enhance students' learning by approximating a 1:1 teacher-to-student ratio. We showcase: "Explain Highlighted Code," a Visual Studio (VS) Code extension that provides just-in-time explanations of code snippets; style50, a VS Code extension that offers formatting suggestions and explanations thereof; and our "CS50 Duck," an AI-based chatbot for course-related questions, implemented both as a VS Code extension and as a standalone web application. We also demonstrate the integration of our tools into Ed, the course's discussion forum. This demo will illustrate the functionality and effectiveness of these tools as well as the pedagogical "guardrails" that we put in place to ensure secure and fair usage of these tools, while sharing insights from our own experience therewith this past summer and fall.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1927},
numpages = {1},
keywords = {ai, artificial intelligence, generative ai, large language models, llms},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3699538.3699580,
author = {Kiesler, Natalie and Scholz, Ingo and Albrecht, Jens and Stappert, Friedhelm and Wienkop, Uwe},
title = {Novice Learners of Programming and Generative AI - Prior Knowledge Matters},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699580},
doi = {10.1145/3699538.3699580},
abstract = {With the broad availability of Generative AI (GenAI), introductory programming education is starting to change. At Nuremberg Tech, we observed the doubling of failure rates to approximately 50% in the first semester course “Procedural Programming” across students of all study programs. Due to these exam results in winter 2023/24, we conducted a pilot study to gather students’ use of GenAI tools, their exam results, and prior programming education and experience. The results imply significant differences of students’ use of GenAI tools depending on their prior programming education. We will therefore extend the investigation in winter term 2024/25.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {51},
numpages = {2},
keywords = {GenAI, student success, programming education, introductory programming, use pattern},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3581783.3612704,
author = {Xu, Danni and Fan, Shaojing and Kankanhalli, Mohan},
title = {Combating Misinformation in the Era of Generative AI Models},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612704},
doi = {10.1145/3581783.3612704},
abstract = {Misinformation has been a persistent and harmful phenomenon affecting our society in various ways, including individuals' physical health and economic stability. With the rise of short video platforms and related applications, the spread of multi-modal misinformation, encompassing images, texts, audios, and videos have exacerbated these concerns. The introduction of generative AI models like ChatGPT and Stable Diffusion has further complicated matters, giving rise to Artificial Intelligence Generated Content (AIGC) and presenting new challenges in detecting and mitigating misinformation. Consequently, traditional approaches to misinformation detection and intervention have become inadequate in this evolving landscape. This paper explores the challenges posed by AIGC in the context of misinformation. It examines the issue from psychological and societal perspectives, and explores the subtle manipulation traces found in AIGC at signal, perceptual, semantic, and human levels. By scrutinizing manipulation traces such as signal manipulation, semantic inconsistencies, logical incoherence, and psychological strategies, our objective is to tackle AI-generated misinformation and provide a conceptual design of systematic explainable solution. Ultimately, we aim for this paper to contribute valuable insights into combating misinformation, particularly in the era of AIGC.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {9291–9298},
numpages = {8},
keywords = {aigc, generative ai models, misinformation detection, multimodal},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3706598.3713906,
author = {Tao, Hongyi and Vyas, Dhaval},
title = {"Housing Diversity Means Diverse Housing": Blending Generative AI into Speculative Design in Rural Co-Housing Communities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713906},
doi = {10.1145/3706598.3713906},
abstract = {In response to various environmental and societal challenges, co-housing has emerged to support social cohesion, grassroots innovation and ecological regeneration. Co-housing communities typically have smaller personal spaces, closer neighbourly relationships, and engage in more mutually supportive sustainable practices. To understand such communities’ motivations and visions, we developed a speculative design tool that harnesses Generative Artificial Intelligence (GenAI) to facilitate the envisioning of alternative future scenarios that challenge prevailing values, beliefs, lifestyles, and ways of knowing in contemporary society. Within the context of co-housing communities, we conducted a participatory design study with participants in co-creating their future communities. This paper unpacks implications and also reflects on the co-design approach employing GenAI. Our main findings highlight that GenAI, as a catalyst for imagination, empowers individuals to create visualisations that pose questions through a plural and situated speculative discourse.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {527},
numpages = {17},
keywords = {Generative AI, speculative design, co-housing, sustainability},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714035,
author = {Varanasi, Rama Adithya and Wiesenfeld, Batia Mishan and Nov, Oded},
title = {AI Rivalry as a Craft: How Resisting and Embracing Generative AI Are Reshaping the Writing Profession},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714035},
doi = {10.1145/3706598.3714035},
abstract = {Generative AI (GAI) technologies are disrupting professional writing, challenging traditional practices. Recent studies explore GAI adoption experiences of creative practitioners, but we know little about how these experiences evolve into established practices and how GAI resistance alters these practices. To address this gap, we conducted 25 semi-structured interviews with writing professionals who adopted and/or resisted GAI. Using the theoretical lens of Job Crafting, we identify four strategies professionals employ to reshape their roles. Writing professionals employed GAI resisting strategies to maximize human potential, reinforce professional identity, carve out a professional niche, and preserve credibility within their networks. In contrast, GAI-enabled strategies allowed writers who embraced GAI to enhance desirable workflows, minimize mundane tasks, and engage in new AI-managerial labor. These strategies amplified their collaborations with GAI while reducing their reliance on other people. We conclude by discussing implications of GAI practices on writers’ identity and practices as well as crafting theory.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1198},
numpages = {19},
keywords = {Generative AI, genAI, writer, writing professional, author, chatGPT, job, job crafting, labor, work transformation, productivity, invisible work, rivalry},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3654777.3676399,
author = {Zhang, Hongbo and Chen, Pei and Xie, Xuelong and Lin, Chaoyi and Liu, Lianyan and Li, Zhuoshu and You, Weitao and Sun, Lingyun},
title = {ProtoDreamer: A Mixed-prototype Tool Combining Physical Model and Generative AI to Support Conceptual Design},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676399},
doi = {10.1145/3654777.3676399},
abstract = {Prototyping serves as a critical phase in the industrial conceptual design process, enabling exploration of problem space and identification of solutions. Recent advancements in large-scale generative models have enabled AI to become a co-creator in this process. However, designers often consider generative AI challenging due to the necessity to follow computer-centered interaction rules, diverging from their familiar design materials and languages. Physical prototype is a commonly used design method, offering unique benefits in prototype process, such as intuitive understanding and tangible testing. In this study, we propose ProtoDreamer, a mixed-prototype tool that synergizes generative AI with physical prototype to support conceptual design. ProtoDreamer allows designers to construct preliminary prototypes using physical materials, while AI recognizes these forms and vocal inputs to generate diverse design alternatives. This tool empowers designers to tangibly interact with prototypes, intuitively convey design intentions to AI, and continuously draw inspiration from the generated artifacts. An evaluation study confirms ProtoDreamer’s utility and strengths in time efficiency, creativity support, defects exposure, and detailed thinking facilitation.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {97},
numpages = {18},
keywords = {creativity support, generative AI, large-scale model, prototype},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3722237.3722266,
author = {Yang, Ye and Wen, Xiong and Maidin, Siti Sarah},
title = {Generative AI Tools in Higher Education Emerging Research: A Bibliometric analysis of co-citation and co-word analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722266},
doi = {10.1145/3722237.3722266},
abstract = {Artificial Intelligence (AI) is positively grasped as promising to disrupt the higher education system but it also poses a number of challenges. Although so many studies attempt to explore the matching of the possibility of this growing technology with the higher education system, ample research needs to be conducted to solve the challenges facing the renovation of higher education. With this in mind, our aim of bibliometric studies is to conduct a deep investigation into the increasingly developing scenario of Generative AI tools in higher education. We extracted data from the Web of Science database that is up-to-date till July 2024, comprising 934 relevant articles. Co-citation and co-word analyses revealed three main research clusters: advanced computationable methods, AI application in higher education, and user technology and adoption. The findings illustrated rapid diffusion of generative AI technologies with prominent emphasis on large-language models in pedagogical practices. Other critical themes center around developing AI-facilitated learning interventions, ethical challenges, and usage impact on learning outcomes. The results show that the field is inherently interdisciplinary, using ideas from educational technology, cognitive science, and AI. In addition, a rising trend is noted for the focus on academic honesty and users' involvement with AI devices. The results indicate the important implications of this study for teachers and policymakers alongside contributions to teaching and research that offer a guide to sustainable improvement across education. Future research would benefit from longitudinal studies drawing on an interdisciplinary approach to realize the long-term implications and address complex issues surrounding the integration of AI within universities.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {166–174},
numpages = {9},
keywords = {Generative AI, artificial intelligence, bibliometric, educational technology, higher education},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3706598.3714157,
author = {Zhao, Shuo and Huang, Yifei and He, Xiaoyang and Tong, Xin and Li, Xin and Wu, Dan},
title = {Reviving Mural Art through Generative AI: A Comparative Study of AI-Generated and Hand-Crafted Recreations},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714157},
doi = {10.1145/3706598.3714157},
abstract = {Virtual reality (VR) provides an immersive and interactive platform for presenting ancient murals, enhancing users’ understanding and appreciation of these invaluable culture treasures. However, traditional hand-crafted methods for recreating murals in VR are labor-intensive, time-consuming, and require significant expertise, limiting their scalability for large-scale mural scenes. To address these challenges, we propose a comprehensive pipeline that leverages generative AI to automate the mural recreation process. This pipeline is validated by the reconstruction of Foguang Temple scene in Dunhuang Murals. A user study comparing the AI-generated scene with a hand-crafted one reveals no significant differences in presence, authenticity, engagement and enjoyment, and emotion. Additionally, our findings identify areas for improvement in AI-generated recreations, such as enhancing historical fidelity and offering customization. This work paves the way for more scalable, efficient, and accessible methods of revitalizing cultural heritage in VR, offering new opportunities for mural preservation, demonstration, and dissemination using VR.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {662},
numpages = {20},
keywords = {virtual reality, culture heritage, mural recreation, generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3613904.3641889,
author = {Boucher, Josiah D and Smith, Gillian and Telliel, Yunus Do\u{g}an},
title = {Is Resistance Futile?: Early Career Game Developers, Generative AI, and Ethical Skepticism},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641889},
doi = {10.1145/3613904.3641889},
abstract = {This paper presents a study that examines developer perceptions and usage of generative AI (GAI) in a summer professional development program for game development interns focused on mobile game design. GAI applications are in common usage worldwide, yet the impacts of this technology in game development remain relatively underexplored. Through a qualitative study using ethnographic interviews and participatory observation, this paper explores how GAI impacted the workflows, creative processes, and professional identities of early career game developers. We present a case of GAI integration that was not a straightforward adoption. Focusing on the interns’ resistance, negotiation, and reimagining, we show that the interns were actively developing a new professional culture both with and against generative AI. For the interns, their ethical commitments to fellow game developers and the future of their profession were as important as their practical concerns about usability, utility, and efficacy of GAI tools.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {173},
numpages = {13},
keywords = {Creativity Support, Future of GAI, Games/Play, Generative AI, Professional Communities, Programming/Development Support, Qualitative Methods},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.5555/3709347.3744085,
author = {Crista, V\'{\i}tor and Martinho, Diogo and Marreiros, Goreti},
title = {Chat4Elderly: A Multi-Agent System for Personalized Wellness Using Generative AI and Wearable Technology},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {This demo presents Chat4Elderly, a Multi-Agent System (MAS) designed to support the well-being of elderly users through personalized and proactive interactions. The system combines Large Language Models (LLMs) with smartwatch sensor data to provide real-time, context-aware responses that address both mental and physical health needs. By analyzing conversational patterns and physical activity levels, it adapts to user preferences, offering personalized assistance and engagement. Over time, the system improves its interactions using stored knowledge, increasing personalization and supporting long-term well-being. This approach helps reduce loneliness and enhance quality of life (QoL), creating a more supportive and engaging experience for elderly users.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {3041–3043},
numpages = {3},
keywords = {conversation system, generative ai, multi-agent systems, wearable technology},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3610978.3640559,
author = {Verhelst, Eva and Janssens, Ruben and Demeester, Thomas and Belpaeme, Tony},
title = {Adaptive Second Language Tutoring Using Generative AI and a Social Robot},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3640559},
doi = {10.1145/3610978.3640559},
abstract = {The most effective second language learning occurs through extensive interpersonal interaction and tutoring. However, limited funding and a lack of language teachers often prevent students from engaging in individualised practice, a lack which can be addressed using AI and social robots. We present a system that leverages generative AI to provide customized educational content in real-time, adapting to students' skills through an engaging, visually-grounded game played alongside a social robot. To test effectiveness, we conducted a study in which Dutch high school students learned Spanish vocabulary either with or without the robot present. Results showed significant vocabulary gains regardless of robot presence, indicating the game itself, not the social embodiment, drove learning. While further refinements are needed, these findings highlight the potential for generative AI to deliver personalized language tutoring and circumvent the constraints posed by limited resources and staffing in schools. Ongoing work aims to enhance social presence and better align generative content with individuals' abilities and pacing.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1080–1084},
numpages = {5},
keywords = {generative AI, natural language processing, robot-assisted language learning, social robots},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3706598.3714103,
author = {Qiao, Han and Vermeulen, Jo and Fitzmaurice, George and Matejka, Justin},
title = {To Use or Not to Use: Impatience and Overreliance When Using Generative AI Productivity Support Tools},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714103},
doi = {10.1145/3706598.3714103},
abstract = {Generative AI has the potential to assist people with completing various tasks, but increased productivity is not guaranteed due to challenges such as uncertainty in output quality and unclear processing time. Through an online crowdsourced experiment (N=508), leveraging a “paint by numbers” task to simulate properties of GenAI assistance, we explore how, and how well, users make decisions on whether to use or not use automation to maximize their productivity given varying waiting times and output quality. We observed gaps between user’s actual choices and their optimal choices and characterized these gaps as the “gulf of impatience” and the “gulf of overreliance”. We also distilled strategies that participants adopted when making their decisions. We discuss design considerations in supporting users to make more informed decisions when interacting with GenAI tools and make these tools more useful for improving users’ task performance, productivity and satisfaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1122},
numpages = {18},
keywords = {generative AI, decision-making, productivity, reliance, AI, automation, controlled experiment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3633083.3633085,
author = {Soudi, Marwa and Ali, Esraa and Bali, Maha and Mabrouk, Nihal},
title = {Generative AI-Based Tutoring System for Upper Egypt Community Schools},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633085},
doi = {10.1145/3633083.3633085},
abstract = {This work introduces design for a Generative AI (Gen-AI) based tutoring system customized for Egyptian community schools needs. Community schools are managed by NGOs as an alternative education to unprivileged students who missed the formal government education. Our research involved working with an Egyptian NGO and a community school in upper Egypt from March 2023 to September 2023. Several workshops were conducted with involved stakeholders and end users to collect the requirements for such a system. The proposed design reflects the views of management, teachers and student parents.It also adhere to Haman-Centered AI (HCAI) principles which prioritize human values and experiences. This paper lists the outcomes of this process and surveys potential tools that can be used in this system. The findings emphasize the need for Gen-AI to act as a teacher’s assistant rather than a replacement, it also highlights the need for localization as well as the need for an end-to-end solution rather than developing an isolated AI-based module. The proposed Gen-AI tutoring system integrates Generative AI, a Learning Management System (LMS), and comprehensive reporting dashboards. This design aims to meet the technical and pedagogical requirements of community school environments and produces a trusted tutoring system that empowers teachers and students.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {16–21},
numpages = {6},
keywords = {Generative AI, Human Centered AI, Intelligent Tutoring Systems},
location = {Dublin, Ireland},
series = {HCAIep '23}
}

@inproceedings{10.1145/3628096.3629066,
author = {Okolo, Chinasa T.},
title = {The Promise and Perils of Generative AI: Case Studies in an African Context},
year = {2024},
isbn = {9798400708879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628096.3629066},
doi = {10.1145/3628096.3629066},
abstract = {As generative AI applications such as ChatGPT, Midjourney, DALL·E, Bard, and others increase in ubiquity, concerns about the negative implications of these technologies are becoming more present in public discourse. However, little research has examined the impact that generative AI stands to have on African consumers and users who may be affected by its application in various fields such as education, healthcare, and social media. This work presents an early look into the implications of using generative AI within African contexts, exploring case studies of current generative AI use within Africa. These case studies examine the use of generative AI in marketing and for image and text generation. While the potential for generative AI in Africa is growing, this preliminary work aims to set a foundation for highlighting risks associated with generative AI while exploring how generative AI can be responsibly developed and used within African contexts.},
booktitle = {Proceedings of the 4th African Human Computer Interaction Conference},
pages = {266–270},
numpages = {5},
keywords = {Africa, algorithmic bias, generative AI, large language models, responsible AI},
location = {East London, South Africa},
series = {AfriCHI '23}
}

@inproceedings{10.1145/3677045.3685445,
author = {Akverdi, Cansu and Baykal, G\"{o}k\c{c}e Elif},
title = {Generative AI Tools in Design Fields: Opportunities and Challenges in the Ideation Process},
year = {2024},
isbn = {9798400709654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677045.3685445},
doi = {10.1145/3677045.3685445},
abstract = {The utilization of artificial intelligence (AI) tools in the arts and design is gaining increasing attention within the creative industries. This paper explores the growing integration of artificial intelligence (AI) tools in arts and design, focusing on the collaboration between designers and AI during the ideation process. Drawing insights from interviews with academics and graduate students from design-related departments at \"{O}zye\u{g}in University, this study compares the ideation processes using generative AI design tools versus non-AI tools. The findings reveal that designers perceive generative AI tools as more efficient during brainstorming stages. Key themes emerged, including the use of chatbots, the importance of accurate verbal prompts, collaborative AI tools, and the acceleration of the creative process. However, concerns regarding the predictability of AI advancement were also expressed. These findings illuminate the evolving role of AI design tools in communication design academia, underscoring their collaborative impact on ideation processes in the digital era.},
booktitle = {Adjunct Proceedings of the 2024 Nordic Conference on Human-Computer Interaction},
articleno = {29},
numpages = {5},
keywords = {Artificial Intelligence (AI), Designer-AI Collaboration, Generative AI Tools, Ideation Process},
location = {Uppsala, Sweden},
series = {NordiCHI '24 Adjunct}
}

@inproceedings{10.1145/3722237.3722354,
author = {Han, Xue and Li, Zhixiang and Zhang, Wenchuan and Fan, Wentao},
title = {Generative AI in Education: Developing Personalized Learning Experiences with Hyperspherical Variational Self-Attention Autoencoder},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722354},
doi = {10.1145/3722237.3722354},
abstract = {With the advancement of artificial intelligence (AI) technology, content generation has sparked a transformative revolution in the field of education. In traditional education, teachers often spend a lot of time preparing lessons, because students have varying levels of proficiency, teachers need to consider whether the teaching content is suitable for everyone. Generative AI provides an effective solution to this problem by automatically generating personalized, high-quality educational content, which not only alleviates the burden on teachers but also enhances students' learning outcomes. This study focuses on a novel deep generative model—a framework based on Variational Autoencoders (VAE) and the self-attention mechanism (Transformer). We propose a model called the Hyperspherical Variational Self-Attention Autoencoder (HVSAE), which aims to generate personalized learning content based on students' learning situations, thereby reducing the burden on teachers and improving learning outcomes. The experimental results indicate that the model can generate high-quality educational resources, providing important support for achieving more personalized and efficient education.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {670–674},
numpages = {5},
keywords = {Generative artificial intelligence, HVSAE, Personalized education, Self-attention mechanism, VAE},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3613904.3641989,
author = {Choi, Dasom and Lee, Sunok and Kim, Sung-In and Lee, Kyungah and Yoo, Hee Jeong and Lee, Sangsu and Hong, Hwajung},
title = {Unlock Life with a Chat(GPT): Integrating Conversational AI with Large Language Models into Everyday Lives of Autistic Individuals},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641989},
doi = {10.1145/3613904.3641989},
abstract = {Autistic individuals often draw on insights from their supportive networks to develop self-help life strategies ranging from everyday chores to social activities. However, human resources may not always be immediately available. Recently emerging conversational agents (CAs) that leverage large language models (LLMs) have the potential to serve as powerful information-seeking tools, facilitating autistic individuals to tackle daily concerns independently. This study explored the opportunities and challenges of LLM-driven CAs in empowering autistic individuals through focus group interviews and workshops (N=14). We found that autistic individuals expected LLM-driven CAs to offer a non-judgmental space, encouraging them to approach day-to-day issues proactively. However, they raised issues regarding critically digesting the CA responses and disclosing their autistic characteristics. Based on these findings, we propose approaches that place autistic individuals at the center of shaping the meaning and role of LLM-driven CAs in their lives, while preserving their unique needs and characteristics.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {72},
numpages = {17},
keywords = {autism, conversational agent, large language model, participatory design workshop},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3711403.3711436,
author = {Jiang, Ruishuang and He, Xiangchun and Zhang, Shaojun and Zhou, Yaxin and Han, Yuqi},
title = {Generative Artificial Intelligence Enables Multiple Learning Environments and Implementation Paths},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711436},
doi = {10.1145/3711403.3711436},
abstract = {This paper explores the application of generative artificial intelligence in the field of education and its potential to enhance multiple learning environments. Generative AI is a powerful tool capable of simulating human creativity and imagination, and has demonstrated its potential across various fields. In the realm of education, generative AI can offer personalized learning support to students, addressing issues associated with traditional teaching models and unequal resource distribution. This paper delves into the specific application pathways and optimization strategies for generative AI in physical, resource-based, technical, and emotional learning environments. Additionally, it proposes policy recommendations, teacher training initiatives, student experience design considerations, and corporate responsibility measures aimed at implementing generative AI to enable diverse learning environments. These efforts are intended to ensure that the application of generative AI in education fully realizes its potential while addressing ethical, equity-related, and sustainability concerns.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {187–193},
numpages = {7},
keywords = {Generative artificial intelligence, Learning environment, Technology enabling},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3715669.3725868,
author = {Mohamed, Suad and Ismail, Najma and Amaya Hernandez, Kimberly and Parvin, Abdullah and Oliver, Michael and Parra, Esteban},
title = {Design of An Eye-Tracking Study Towards Assessing the Impact of Generative AI Use on Code Summarization},
year = {2025},
isbn = {9798400714870},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715669.3725868},
doi = {10.1145/3715669.3725868},
abstract = {As large language models (LLMs) become more integrated into software engineering and computer science education, it is crucial to understand their impact on student learning. While recent research has explored student perceptions of generative AI, little is known about how these tools influence students’ cognitive processes during programming tasks, such as code comprehension, a valuable skill in software development and maintenance. This paper presents the design of a study that aims to investigate how computer science students interact with LLMs, such as Google’s Gemini, in the context of code summarization using eye-tracking. This study will examine differences in visual attention, fixation behaviors, and performance of students engaged in code summarization with and without AI assistance across varying experience levels.},
booktitle = {Proceedings of the 2025 Symposium on Eye Tracking Research and Applications},
articleno = {80},
numpages = {8},
keywords = {Code Summarization, Eye tracking, empirical study, code comprehension, Large Language Models, AI4SE},
location = {
},
series = {ETRA '25}
}

@article{10.1145/3716859,
author = {Chun, Soon Ae and Noveck, Beth S.},
title = {Introduction to the Special Issue on ChatGPT and other Generative AI Commentaries: AI Augmentation in Government 4.0: AI Augmentation in Government 4.0},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
url = {https://doi.org/10.1145/3716859},
doi = {10.1145/3716859},
abstract = {This special issue is for providing a forum for rapid sharing of current and potential transformations and disruptions that may be enabled by GenAI in the government domain. The main objectives of the Special Issue are: to gauge the potential impact of powerful GenAI tools, such as ChatGPT, Gemini, Co-Pilot, and MetaAI, for the future government and democracy, including negative and positive effects; to assess the role of the Government in the face of proliferation of GenAI tools as a potential facilitator of innovations towards a better society or as regulator to harness the new generation of AI and to mitigate risks; and lastly, to envision how the public sector workplace may need to adapt to the changes, identifying top priority requirements and strategies for the new governing models.},
journal = {Digit. Gov.: Res. Pract.},
month = mar,
articleno = {1},
numpages = {8},
keywords = {Generative AI, Public Domain Innovations, ChatGPT, Large Language Models}
}

@inproceedings{10.1145/3626252.3630909,
author = {Denny, Paul and Leinonen, Juho and Prather, James and Luxton-Reilly, Andrew and Amarouche, Thezyrie and Becker, Brett A. and Reeves, Brent N.},
title = {Prompt Problems: A New Programming Exercise for the Generative AI Era},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630909},
doi = {10.1145/3626252.3630909},
abstract = {Large language models (LLMs) are revolutionizing the field of computing education with their powerful code-generating capabilities. Traditional pedagogical practices have focused on code writing tasks, but there is now a shift in importance towards reading, comprehending and evaluating LLM-generated code. Alongside this shift, an important new skill is emerging -- the ability to solve programming tasks by constructing good prompts for code-generating models. In this work we introduce a new type of programming exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are designed to help students learn how to write effective prompts for AI code generators. A student solves a Prompt Problem by crafting a natural language prompt which, when provided as input to an LLM, outputs code that successfully solves a specified programming task. We also present a new web-based tool called Promptly which hosts a repository of Prompt Problems and supports the automated evaluation of prompt-generated code. We deploy Promptly in one CS1 and one CS2 course and describe our experiences, which include student perceptions of this new type of activity and their interactions with the tool. We find that students are enthusiastic about Prompt Problems, and appreciate how the problems engage their computational thinking skills and expose them to new programming constructs. We discuss ideas for the future development of new variations of Prompt Problems, and the need to carefully study their integration into classroom practice.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {296–302},
numpages = {7},
keywords = {ai code generation, artificial intelligence, generative ai, large language models, llms, prompt engineering, prompt problems},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3701198,
author = {Wang, Tianjia and Wu, Tong and Liu, Huayi and Brown, Chris and Chen, Yan},
title = {Generative Co-Learners: Enhancing Cognitive and Social Presence of Students in Asynchronous Learning with Generative AI},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
url = {https://doi.org/10.1145/3701198},
doi = {10.1145/3701198},
abstract = {Cognitive presence and social presence are crucial for a comprehensive learning experience. Despite the flexibility of asynchronous learning environments to accommodate individual schedules, the inherent constraints of asynchronous environments make augmenting cognitive and social presence particularly challenging. Students often face challenges such as a lack of timely feedback and support, an absence of non-verbal cues in communication, and a sense of isolation. To address this challenge, this paper introduces Generative Co-Learners, a system designed to leverage generative AI-powered agents, simulating co-learners supporting multimodal interactions, to improve cognitive and social presence in asynchronous learning environments. We conducted a study involving 12 student participants who used our system to engage with online programming tutorials to assess the system's effectiveness. The results show that by implementing features to support textual and visual communication and simulate an interactive learning environment with generative agents, our system enhances the cognitive and social presence in the asynchronous learning environment. These results suggest the potential to use generative AI to support student learning and transform asynchronous learning into a more inclusive, engaging, and efficacious educational approach.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jan,
articleno = {GROUP19},
numpages = {24},
keywords = {asynchronous learning, cognitive presence, generative AI, multimodal generative agent, social presence}
}

@inproceedings{10.1145/3706599.3720283,
author = {Wang, Nicole C.},
title = {Scaffolding Creativity: Integrating Generative AI Tools and Real-World Experiences in Business Education},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720283},
doi = {10.1145/3706599.3720283},
abstract = {This exploratory study investigates the intersection of Generative AI tools and experiential learning in business education. Through a case study of an innovative undergraduate course, we examine how students interact with and adapt to various AI modalities—from text-based tools to image generation—alongside real-world experiences. Our findings reveal how this integrated approach enables novice users to overcome creative barriers, accelerates skill acquisition, and creates a dynamic interplay between AI-generated insights and real-world validation. We identify critical interaction challenges, including prompt engineering patterns and the need for more intuitive AI interfaces in educational contexts. These insights inform the design of future AI tools for creative learning and contribute to broader HCI discussions about human-AI collaboration in educational settings.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {468},
numpages = {9},
keywords = {AI-assisted learning, Artificial Intelligence in Education (AIEd), Higher Education, Experiential learning, ChatGPT, Midjourney},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3610969.3611132,
author = {Petrovska, Olga and Clift, Lee and Moller, Faron},
title = {Generative AI in Software Development Education: Insights from a Degree Apprenticeship Programme},
year = {2023},
isbn = {9798400708763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610969.3611132},
doi = {10.1145/3610969.3611132},
abstract = {We describe insights gained from incorporating ChatGPT into assignments for our Software Engineering Degree Apprenticeship programme, including attitudes expressed by the learners and their employers regarding our approach.},
booktitle = {Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {19},
numpages = {1},
keywords = {Apprenticeships, Education, Generative AI, Software Engineering},
location = {Swansea, Wales Uk},
series = {UKICER '23}
}

@inproceedings{10.1145/3706370.3731650,
author = {Wang, Huan and Matviienko, Andrii},
title = {Experiencing Art Museum with a Generative Artificial Intelligence Chatbot},
year = {2025},
isbn = {9798400713910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706370.3731650},
doi = {10.1145/3706370.3731650},
abstract = {Generative Artificial Intelligence (GenAI) chatbots start changing experiences with art for museum visitors by making them more interactive and engaging. However, it remains underexplored how GenAI chatbots influence visitors’ in-field experience and interaction at art museums regarding finding information, engagement, and enjoyment compared to existing museum tour-guide applications. In this paper, we contribute the design and implementation of a smartphone-based chatbot that detects artwork, generates textual and auditory information, and interactively answers visitors’ questions. To explore visitors’ experience with it, we conducted a field experiment (N=30) at the National Art Museum, comparing it to the existing museum application. Our results indicate that visitors showed higher artwork engagement with the chatbot than the museum application. Moreover, they enjoyed an interactive experience using the chatbot to learn about the art collection and have equally preferred textual and auditory information representation.},
booktitle = {Proceedings of the 2025 ACM International Conference on Interactive Media Experiences},
pages = {430–436},
numpages = {7},
keywords = {Museum experience, Chatbot, Tour guide, Generative AI},
location = {
},
series = {IMX '25}
}

@inproceedings{10.1145/3626253.3635369,
author = {MacNeil, Stephen and Leinonen, Juho and Denny, Paul and Kiesler, Natalie and Hellas, Arto and Prather, James and Becker, Brett A. and Wermelinger, Michel and Reid, Karen},
title = {Discussing the Changing Landscape of Generative AI in Computing Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635369},
doi = {10.1145/3626253.3635369},
abstract = {In a previous Birds of a Feather discussion, we delved into the nascent applications of generative AI, contemplating its potential and speculating on future trajectories. Since then, the landscape has continued to evolve revealing the capabilities and limitations of these models. Despite this progress, the computing education research community still faces uncertainty around pivotal aspects such as (1) academic integrity and assessments, (2) curricular adaptations, (3) pedagogical strategies, and (4) the competencies students require to instill responsible use of these tools. The goal of this Birds of a Feather discussion is to unravel these pressing and persistent issues with computing educators and researchers, fostering a collaborative exploration of strategies to navigate the educational implications of advancing generative AI technologies. Aligned with this goal of building an inclusive learning community, our BoF is led by globally distributed leaders to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of LLMs in CS education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1916},
numpages = {1},
keywords = {academic integrity, assessment, computing education, curriculum, large language models, pedagogy},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3660650.3660657,
author = {Roberts, Jordan and Mohamed, Abdallah},
title = {Generative AI in CS Education: Literature Review through a SWOT Lens},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660657},
doi = {10.1145/3660650.3660657},
abstract = {The rapid growth of generative artificial intelligence (AI) models introduced challenges for educators, students and administrators across the academic sphere related to how to manage and regulate these tools. While some oppose their use, many researchers have begun to approach the topic of educational AI use from a different perspective. Despite being in its early stages; this field of research has produced notable insights into the capabilities and limitations of models like ChatGPT. This paper utilizes a SWOT analysis framework to analyze and consolidate existing literature, with a specific focus on Computer Science education. Through the analysis of this literature, we have created a set of use cases and guidelines to aid in the future development of strategies and tools within this field. Our findings indicate that while some concerns are valid, such as AI's ability to generate plagiarized work, we identified several promising avenues and opportunities for careful integration of this technology into education.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {10},
numpages = {6},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@article{10.1145/3677102,
author = {Ling, Long and Chen, Xinyi and Wen, Ruoyu and Li, Toby Jia-Jun and LC, RAY},
title = {Sketchar: Supporting Character Design and Illustration Prototyping Using Generative AI},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CHI PLAY},
url = {https://doi.org/10.1145/3677102},
doi = {10.1145/3677102},
abstract = {Character design in games involves interdisciplinary collaborations, typically between designers who create the narrative content, and illustrators who realize the design vision. However, traditional workflows face challenges in communication due to the differing backgrounds of illustrators and designers, the latter with limited artistic abilities. To overcome these challenges, we created Sketchar, a Generative AI (GenAI) tool that allows designers to prototype game characters and generate images based on conceptual input, providing visual outcomes that can give immediate feedback and enhance communication with illustrators' next step in the design cycle. We conducted a mixed-method study to evaluate the interaction between game designers and Sketchar. We showed that the reference images generated in co-creating with Sketchar fostered refinement of design details and can be incorporated into real-world workflows. Moreover, designers without artistic backgrounds found the Sketchar workflow to be more expressive and worthwhile. This research demonstrates the potential of GenAI in enhancing interdisciplinary collaboration in the game industry, enabling designers to interact beyond their own limited expertise.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {337},
numpages = {28},
keywords = {collaboration, creativity support}
}

@inproceedings{10.1145/3706599.3720203,
author = {Tang, Xiaohang and Wong, Sam and Huynh, Marcus and He, Zicheng and Yang, Yalong and Chen, Yan},
title = {SPHERE: Supporting Personalized Feedback at Scale in Programming Classrooms with Structured Review of Generative AI Outputs},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720203},
doi = {10.1145/3706599.3720203},
abstract = {This paper introduces SPHERE, a system that enables instructors to effectively create and review personalized feedback for in-class coding activities. Comprehensive personalized feedback is crucial for programming learning. However, providing such feedback in large programming classrooms poses significant challenges for instructors. While Large Language Models (LLMs) offer potential assistance, how to efficiently ensure the quality of LLM-generated feedback remains an open question. SPHERE guides instructors’ attention to critical students’ issues, empowers them with guided control over LLM-generated feedback, and provides visual scaffolding to facilitate verification of feedback quality. Our between-subject study with 20 participants demonstrates SPHERE’s effectiveness in creating more high-quality feedback while not increasing the time spent on the overall review process compared to a baseline system. This work contributes a synergistic approach to scaling personalized feedback in programming education, addressing the challenges of real-time response, issue prioritization, and large-scale personalization.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {467},
numpages = {17},
keywords = {Generative AI, Large Language Model, Programming Education at Scale, Feedback, Computing Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706598.3714061,
author = {Wang, Ke and Lin, Lehao and Abdallah, Maha and Cai, Wei},
title = {Where is the Boundary? Understanding How People Recognize and Evaluate Generative AI-extended Videos},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714061},
doi = {10.1145/3706598.3714061},
abstract = {The rise of video generative models that produce high-quality content has made it increasingly difficult to discern video authenticity. AI-extended videos, which mix real-world footage with generative content, pose new challenges in distinguishing real from manipulated segments. AI-extended videos might be utilized to deceive humans, but they also have the capacity to assist video creators and offer people novel video experiences. Despite these concerns, research on how people recognize and evaluate AI-extended videos remains limited. To address this, we conducted a user study where participants interacted with AI-extended videos on a web-based system, identifying boundaries between raw and generated content, followed by a survey and one-on-one interviews. Our quantitative and qualitative analyses revealed how individuals perceive these videos, the factors influencing their perception, evaluations and attitudes. We believe that these insights will aid the future development of AI-extended video technologies and ecosystems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1144},
numpages = {19},
keywords = {Human Perception, AI-generated Videos, AI-extended Videos, Video Extension, Generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706599.3706745,
author = {Tankelevitch, Lev and Glassman, Elena L. and He, Jessica and Kazemitabaar, Majeed and Kittur, Aniket and Lee, Mina and Palani, Srishti and Sarkar, Advait and Ramos, Gonzalo and Rogers, Yvonne and Subramonyam, Hari},
title = {Tools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706745},
doi = {10.1145/3706599.3706745},
abstract = {We invite researchers, designers, practitioners, and provocateurs to explore what it means to understand and shape the impact of Generative AI (GenAI) on human cognition. GenAI radically widens the scope and capability of automation for work, learning, and creativity. While impactful, it also changes workflows and the quality of thinking involved, raising questions about its effects on cognition, including critical thinking and learning. Yet, GenAI also offers opportunities for designing tools for thought that protect and augment cognition. Such systems provoke critical thinking, provide personalized tutoring, or enable novel ways of sensemaking, among other approaches. How does GenAI change workflows and human cognition? What are opportunities and challenges for designing GenAI systems that protect and augment human cognition? Which theories, perspectives, and methods are relevant? This workshop aims to develop a multidisciplinary community interested in exploring these questions to protect against the erosion, and fuel the augmentation, of human cognition using GenAI.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {804},
numpages = {8},
keywords = {generative AI, artificial intelligence, critical thinking, reasoning, cognition, metacognition, learning, diversity, creativity, sensemaking, autonomy, augmentation, intentionality, reflection, social science, research, design, workshop},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3613904.3642191,
author = {Kotturi, Yasmine and Anderson, Angel and Ford, Glenn and Skirpan, Michael and Bigham, Jeffrey P},
title = {Deconstructing the Veneer of Simplicity: Co-Designing Introductory Generative AI Workshops with Local Entrepreneurs},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642191},
doi = {10.1145/3613904.3642191},
abstract = {Generative AI platforms and features are permeating many aspects of work. Entrepreneurs from lean economies in particular are well positioned to outsource tasks to generative AI given limited resources. In this paper, we work to address a growing disparity in use of these technologies by building on a four-year partnership with a local entrepreneurial hub dedicated to equity in tech and entrepreneurship. Together, we co-designed an interactive workshops series aimed to onboard local entrepreneurs to generative AI platforms. Alongside four community-driven and iterative workshops with entrepreneurs across five months, we conducted interviews with 15 local entrepreneurs and community providers. We detail the importance of communal and supportive exposure to generative AI tools for local entrepreneurs, scaffolding actionable use (and supporting non-use), demystifying generative AI technologies by emphasizing entrepreneurial power, while simultaneously deconstructing the veneer of simplicity to address the many operational skills needed for successful application.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1014},
numpages = {16},
keywords = {community-based research, entrepreneurship, generative artificial intelligence},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.5555/3712729.3712990,
author = {Leathrum, James F. and Shen, Yuzhong and Sosonkina, Masha},
title = {Investigating the Use of Generative AI in M&amp;S Education},
year = {2025},
isbn = {9798331534202},
publisher = {IEEE Press},
abstract = {Large Language Models (LLMs) are rapidly creating a place for themselves in society. There are numerous reports, both good and bad, of their use in business, academia, government and society. While some organizations are trying to limit, or eliminate, their use, it appears that it is inevitable they will become a common "tool". In education, there is a fear that students will not acquire critical thinking in the future, but we argue that LLMs will become a tool to assist students with critical thinking, giving guidance, feedback, and assessment. This paper investigates how the current state of LLMs can be integrated into modeling and simulation (M&amp;S) education. Example cases for modeling and simulation development are presented showing how an LLM can assist M&amp;S design and education in anticipation of LLMs becoming a common tool for M&amp;S practitioners. Current limitations are also highlighted, and where possible, short-term solutions are proposed.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {3142–3153},
numpages = {12},
location = {Orlando, Florida, USA},
series = {WSC '24}
}

@inproceedings{10.1145/3613905.3643977,
author = {Elagroudy, Passant and Li, Jie and V\"{a}\"{a}n\"{a}nen, Kaisa and Lukowicz, Paul and Ishii, Hiroshi and Mackay, Wendy E. and Churchill, Elizabeth F and Peters, Anicia and Oulasvirta, Antti and Prada, Rui and Diening, Alexandra and Barbareschi, Giulia and Gruenerbl, Agnes and Kawaguchi, Midori and El Ali, Abdallah and Draxler, Fiona and Welsch, Robin and Schmidt, Albrecht},
title = {Transforming HCI Research Cycles using Generative AI and “Large Whatever Models” (LWMs)},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3643977},
doi = {10.1145/3613905.3643977},
abstract = {This Special Interest Group (SIG) explores the transformative impact of Generative Artificial Intelligence (GenAI) on Human-Computer Interaction (HCI) research processes. The theme here is to answer “question zero”: when to use and when to refrain from using AI tools during the research cycle? The discussion is guided by five research phases commonly used in HCI: research planning, prototyping, data collection, analysis and synthesis, and dissemination and communication. We investigate how GenAI accelerates project cycles, enhances reproducibility, and influences inclusivity in research. We also address the challenging ethical considerations about the ownership of generated content. Our goal is to build a community of HCI enthusiasts to harness the early advantages of the recent groundbreaking technology and foresee challenges arising from its prevalence in the scientific community.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {584},
numpages = {5},
keywords = {ChatGPT, Generative AI, HCI research, Large Language Models, Large Multimodal Models, research processes, science},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3613904.3642625,
author = {Li, Zhuoyan and Liang, Chen and Peng, Jing and Yin, Ming},
title = {The Value, Benefits, and Concerns of Generative AI-Powered Assistance in Writing},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642625},
doi = {10.1145/3613904.3642625},
abstract = {Recent advances in generative AI technologies like large language models raise both excitement and concerns about the future of human-AI co-creation in writing. To unpack people’s attitude towards and experience with generative AI-powered writing assistants, in this paper, we conduct an experiment to understand whether and how much value people attach to AI assistance, and how the incorporation of AI assistance in writing workflows changes people’s writing perceptions and performance. Our results suggest that people are willing to forgo financial payments to receive writing assistance from AI, especially if AI can provide direct content generation assistance and the writing task is highly creative. Generative AI-powered assistance is found to offer benefits in increasing people’s productivity and confidence in writing. However, direct content generation assistance offered by AI also comes with risks, including decreasing people’s sense of accountability and diversity in writing. We conclude by discussing the implications of our findings.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1048},
numpages = {25},
keywords = {AI writing assistant, Human-AI co-creation, Large language model},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3706598.3714227,
author = {Inie, Nanna and Falk, Jeanette and Selvan, Raghavendra},
title = {How CO2STLY Is CHI? The Carbon Footprint of Generative AI in HCI Research and What We Should Do About It},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714227},
doi = {10.1145/3706598.3714227},
abstract = {The energy cost of developing and deploying Generative AI (GenAI) models has exploded with their mass adoption, as has the ensuing carbon emissions. The climate impact of this is currently unknown. In Human-Computer Interaction, GenAI models are rarely trained but often used. Based on detailed review of 282 papers, we estimate this footprint from energy consumption of the total use of GenAI for CHI 2024 research as between 10,769.63 and 10,925.12 kg CO2e — equal to driving a car for more than 100,000 km. We show that in CHI research, GenAI is most often used for Prototyping, Evaluation &amp; User studies, and that Data Collection and Fine-tuning models incurs the highest CO2st.1 We find that CHI submissions are unlikely to report GenAI use transparently, which makes precise calculations difficult. By measuring the usage of a subset of the papers on local hardware, we obtain estimations of the energy consumption and carbon footprint. Based on this evidence, we discuss and demonstrate ways to mitigate the issues of GenAI carbon footprint and lack of transparency.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {206},
numpages = {29},
keywords = {carbon footprint, energy consumption, Environmental Sustainability, Generative AI, AI Hype},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3678717.3691269,
author = {Kanza, Yaron and Krishnamurthy, Balachander and Srivastava, Divesh},
title = {A Geospatial Perspective on Data Ownership, the Right to be Forgotten, Copyrights, and Plagiarism in Generative AI},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678717.3691269},
doi = {10.1145/3678717.3691269},
abstract = {Ethical use of data in generative AI is a growing concern. Large generative AI models are trained on pervasive data sets from a variety of sources, where the data records are fused into the models and become inseparable from them. This raises questions regarding data ownership and the use of personal data, artwork, and copyrighted content in generative AI models. Should people and businesses be allowed to request the removal of their data from a model, even if the data were collected in public places? Should the use of data in generative AI vary across different places based on local copyright laws? How should local laws and regulations regarding data misuse and harmful content be enforced? Can people and organizations verify that their data records have been removed from models or are being used properly? In this paper we discuss the geospatial aspects of data ownership in large generative AI models. We present a vision of generative AI applications that are aware of data ownership and location provenance, based on spatio-temporal features of the data and the usage. These aspects of location-aware AI governance could mitigate some of the risks associated with generative AI and support ethical use of it, in both local and global applications.},
booktitle = {Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
pages = {477–480},
numpages = {4},
keywords = {Generative AI, copyright, the right to be forgotten, unlearning},
location = {Atlanta, GA, USA},
series = {SIGSPATIAL '24}
}

@inproceedings{10.1145/3582269.3615596,
author = {Cai, Alice and Rick, Steven R and Heyman, Jennifer L and Zhang, Yanxia and Filipowicz, Alexandre and Hong, Matthew and Klenk, Matt and Malone, Thomas},
title = {DesignAID: Using Generative AI and Semantic Diversity for Design Inspiration},
year = {2023},
isbn = {9798400701139},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582269.3615596},
doi = {10.1145/3582269.3615596},
abstract = {Designers often struggle to sufficiently explore large design spaces, which can lead to design fixation and suboptimal outcomes. Here we introduce DesignAID, a generative AI tool that supports broader design space exploration by first using large language models to produce a range of diverse ideas expressed in words, and then using image generation software to create images from these words. This innovative combination of AI-based capabilities allows human-computer pairs to rapidly create a diverse set of visual concepts without time-consuming drawing. In a study with 87 crowd-sourced designers, we found that designers rated the automatic generation of images from words as significantly more inspirational, enjoyable, and useful than a conventional baseline condition of image search using Pinterest. Surprisingly, however, we found that automatically generating highly diverse ideas had less value. For image generation, the high diversity condition was somewhat better in inspiration but no better in the other dimensions, and for image search it was significantly worse in all dimensions.},
booktitle = {Proceedings of The ACM Collective Intelligence Conference},
pages = {1–11},
numpages = {11},
keywords = {AI assistance, creativity support, generative AI, human AI collaboration, human-computer collaboration, machine learning},
location = {Delft, Netherlands},
series = {CI '23}
}

@inproceedings{10.1145/3706598.3714298,
author = {Choi, Youjin and Moon, JaeYoung and Yoo, JinYoung and Hong, Jin-Hyuk},
title = {Exploring the Potential of Music Generative AI for Music-Making by Deaf and Hard of Hearing People},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714298},
doi = {10.1145/3706598.3714298},
abstract = {Recent advancements in text-to-music generative AI (GenAI) have significantly expanded access to music creation. However, deaf and hard of hearing (DHH) individuals remain largely excluded from these developments. This study explores how music GenAI could enhance the music-making experience of DHH individuals, who often rely on hearing people to translate sounds and music. We developed a multimodal music-making assistive tool informed by focus group interviews. This tool enables DHH users to create and edit music independently through language interaction with music GenAI, supported by integrated visual and tactile feedback. Our findings from the music-making study revealed that the system empowers them to engage in independent and proactive music-making activities, increasing their confidence, fostering musical expression, and positively shifting their attitudes toward music. Contributing to inclusive art by preserving the unique sensory characteristics of DHH individuals, this study demonstrates how music GenAI can benefit a marginalized community, fostering independent creative expression.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {762},
numpages = {20},
keywords = {Deaf and Hard-of-Hearing (DHH) people, Music generative AI, Music-sensory substitution system, Music-making},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3708359.3712146,
author = {Hung, Yu-Kai and Huang, Yun-Chien and Su, Ting-Yu and Lin, Yen-Ting and Cheng, Lung-Pan and Wang, Bryan and Sun, Shao-Hua},
title = {SimTube: Simulating Audience Feedback on Videos using Generative AI and User Personas},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712146},
doi = {10.1145/3708359.3712146},
abstract = {Audience feedback is crucial for refining video content, yet it typically comes after publication, limiting creators’ ability to make timely adjustments. To bridge this gap, we introduce SimTube, a generative AI system designed to simulate audience feedback in the form of video comments before a video’s release. SimTube features a computational pipeline that integrates multimodal data from the video—such as visuals, audio, and metadata—with user personas derived from a broad and diverse corpus of audience demographics, generating varied and contextually relevant feedback. Furthermore, the system’s UI allows creators to explore and customize the simulated comments. Through a comprehensive evaluation—comprising quantitative analysis, crowd-sourced assessments, and qualitative user studies—we show that SimTube’s generated comments are not only relevant, believable, and diverse but often more detailed and informative than actual audience comments, highlighting its potential to help creators refine their content before release.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {1256–1271},
numpages = {16},
keywords = {Feedback Tool, Vision Language Model, Comment Generation},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3649217.3653596,
author = {Apiola, Mikko and Vartiainen, Henriikka and Tedre, Matti},
title = {First Year CS Students Exploring And Identifying Biases and Social Injustices in Text-to-Image Generative AI},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653596},
doi = {10.1145/3649217.3653596},
abstract = {Generative AI is a recent breakthrough in AI. While it has become a hot topic in computing education research (CER), much of the recent research has focused on e.g. issues of plagiarism or academic integrity. One problem spot with Generative AI is its susceptibility to various kinds of algorithmic bias. In this study, we collected data from an introductory computing course, where students experimented with text-to-image generative models and reflected on their generated image sets, in terms of biases, related harms, and possible fixes. Data were collected in Fall 2023 (pilot data in Fall 2022). Data included reports from 163 students. The results show (1) a variety of bias types observed by students related to gender, ethnicity, age, as well as a variety of bias types not observed by students, (2) two major types of attributions for the source of bias: bias caused by biases in the society and bias caused by data or algorithms, and (3) a number of potential harms associated with the biases, as well as attributions of those harms in specific contexts and use cases.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {485–491},
numpages = {7},
keywords = {bias, critical computing education, generative ai, social injustice},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3657054.3664243,
author = {Yang, Alan and Yang, T. Andrew},
title = {Social Dangers of Generative Artificial Intelligence: Review and Guidelines},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3664243},
doi = {10.1145/3657054.3664243},
abstract = {In this paper, we provide a detailed survey of generative artificial intelligence (GAI) and examine the perceived social problems, including those that are currently apparent and those that can potentially be caused by the technology. After the introduction, we discuss initiatives proposed by governmental and professional entities to curtail the risks posed by adopting AI technologies without consideration of the associated risks. A brief survey of published research in AI security and related risks is then presented along with a discussion of findings and recommendations in the form of guidelines for future adoption of generative AI across a variety of contexts.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {654–658},
numpages = {5},
keywords = {Digital Governance, Generative AI, Regulations and Standards, Risks},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

@inproceedings{10.1145/3706468.3706494,
author = {Jansen, Thorben and Horbach, Andrea and Meyer, Jennifer},
title = {Feedback from Generative AI: Correlates of Student Engagement in Text Revision from 655 Classes from Primary and Secondary School},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706494},
doi = {10.1145/3706468.3706494},
abstract = {Writing is fundamental in knowledge-based societies, and engaging students in text revision through feedback is critical for developing students’ writing skills. Automated feedback offers a promising solution to teachers’ time constraints creating feedback. However, prior research indicates that 20 to 71 percent of students receiving feedback do not engage in any text revision. Despite these concerning figures, students’ non-engagement has not received widespread attention, likely due to fragmented evidence from a few grade levels and writing tasks disconnected from regular teaching. Further, whether the issue persists when generative AI generates the feedback is unclear. The present study investigates what percentage of students behaviorally engage with feedback from generative AI in authentic classroom learning contexts. We analyzed data from an educational technology company, including 655 teacher-generated writing tasks involving 14,236 students across grades 1-12. Our findings show that around half of the students did not revise a single character in the text after receiving feedback. The percentage was similar across grade levels, task types, or feedback characteristics. We discuss the importance of including the percentage of engaged students as an additional metric in feedback research to achieve the goal that no student is left behind.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {831–836},
numpages = {6},
keywords = {student engagement, automated feedback, writing, generative AI},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3678726.3678778,
author = {Li, Zhi-Fang and zhao, Shuo and Zhang, Ya-Chen},
title = {Research on the Transformation of Music Education Model under the Background of Generative Artificial Intelligence},
year = {2024},
isbn = {9798400717611},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678726.3678778},
doi = {10.1145/3678726.3678778},
abstract = {Since 2022, the rapid development of generative artificial intelligence systems represented by Chat-GPT has profoundly influenced various fields. This article briefly introduces the development process of generative artificial intelligence models in recent years, explains the benefits of applying generative artificial intelligence in music education, and discusses the direction of transformation for music education models in the context of the development of generative artificial intelligence. It also reflects and summarizes the challenges faced by the current application of generative artificial intelligence in the field of music education.},
booktitle = {Proceedings of the 2024 8th International Conference on Education and Multimedia Technology},
pages = {60–64},
numpages = {5},
keywords = {Keywords—Generative AI, Music education, Research on Transformation Models},
location = {Tokyo, Japan},
series = {ICEMT '24}
}

@inproceedings{10.1145/3706598.3713634,
author = {Perera, Minoli and Ananthanarayan, Swamy and Goncu, Cagatay and Marriott, Kim},
title = {The Sky is the Limit: Understanding How Generative AI can Enhance Screen Reader Users' Experience with Productivity Applications},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713634},
doi = {10.1145/3706598.3713634},
abstract = {Productivity applications including word processors, spreadsheets, and presentation tools are crucial in work, education, and personal settings. Blind users typically access these tools via screen readers (SRs) and face significant accessibility and usability challenges. Recent advancements in Generative AI (GenAI) may address these challenges by enabling natural language interactions and contextual task understanding. However, there is limited understanding of SR users’ needs and attitudes toward GenAI assistance in these applications. We surveyed 99 SR users to gain a holistic understanding of the challenges they face when using productivity applications, the impact of these challenges on their productivity and independence, and their initial perceptions of AI assistance. Driven by their enthusiasm, we conducted interviews with 16 SR users to explore their attitudes toward GenAI and its potential usefulness in productivity applications. Our findings highlight its need to support existing SR workflows and the importance of enabling customization and task verification.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1165},
numpages = {17},
keywords = {blind, accessibility, productivity applications, assistive technology, screen readers, AI assistants, Generative AI, virtual assistants},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3626253.3635522,
author = {Ruiz, Pati and Rangel, Alessandra and Coenraad, Merijke},
title = {Using Generative AI to Support PK-12 Teaching and Learning: Developing Sample Lessons and More},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635522},
doi = {10.1145/3626253.3635522},
abstract = {North Salem Central School District (North Salem) has worked with researchers as part of a larger Research Practice Partnership (RPP) to design and implement an inclusive PK-12 computing pathway in their district. This poster describes how teachers used Generative AI (GenAI) tools in three areas: (1) the development of sample computational thinking (CT) lesson plans; (2) initial brainstorming; and (3) professional learning.As North Salem reflected on their use of GenAI tools, they named two AI tools specifically: OpenAI's ChatGPT-4 and Bing's Image Creator. Teachers also describe ethical dilemmas that they faced when integrating GenAI tools as well as other concerns that will be described below. This work builds on the growing literature on the use of Generative AI tools to support the day-to-day work of teachers.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1800–1801},
numpages = {2},
keywords = {K-12 computer science education, ducational equity, formative assessment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3603287.3651196,
author = {Ustymenko, Stanislav and Phadke, Abhishek},
title = {Promise and Challenges of Generative AI in Healthcare Information Systems},
year = {2024},
isbn = {9798400702372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603287.3651196},
doi = {10.1145/3603287.3651196},
abstract = {Large Language Models (LLMs) based on pretrained transformer architectures, such as Generative Pretrained Transformer 4 (GPT-4) from OpenAI, are on the cutting age of artificial intelligence research. Along with generating abundant academic literature, these models are the basis of numerous practical systems widely utilized by end users and organizations. In healthcare information systems, there are many case studies and research prototypes demonstrating the promise of applying GPT-like programs to numerous practical natural language processing tasks. At the same time, current limitations of LLMs prevent their safe deployments in professional environments. In this study, we give an overview of capabilities, limitations, and risks associated with current iterations of LLMs. We provide an overview of literature on using LLMs in healthcare context. Finally, we present a framework of generic healthcare IT system utilizing LLMs, and discuss avenues for future research.},
booktitle = {Proceedings of the 2024 ACM Southeast Conference},
pages = {223–228},
numpages = {6},
keywords = {GPT, Healthcare IT, Large Language Models, Software Engineering},
location = {Marietta, GA, USA},
series = {ACMSE '24}
}

@inproceedings{10.1145/3663548.3675631,
author = {Adnin, Rudaiba and Das, Maitraye},
title = {"I look at it as the king of knowledge": How Blind People Use and Understand Generative AI Tools},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3675631},
doi = {10.1145/3663548.3675631},
abstract = {The proliferation of Generative Artificial Intelligence (GenAI) tools has brought a critical shift in how people approach information retrieval and content creation in diverse contexts. Yet, we have limited understanding of how blind people use and make sense of GenAI systems. To bridge this gap, we report findings from interviews with 19 blind individuals who incorporate mainstream GenAI tools like ChatGPT and Be My AI in their everyday practices. Our findings reveal how blind users navigate accessibility issues, inaccuracies, hallucinations, and idiosyncracies associated with GenAI and develop interesting (but often flawed) mental models of how these tools work. We discuss key considerations for rethinking access and information verification in GenAI tools, unpacking erroneous mental models among blind users, and reconciling harms and benefits of GenAI from an accessibility perspective.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {64},
numpages = {14},
keywords = {Accessibility, ChatGPT, Generative AI, blind, visual impairment},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@inproceedings{10.1145/3704289.3704300,
author = {Xiong, Xiao-Gang and Zeng, Meng-Ting},
title = {Research hotspots and path evolution of generative AI development--A Bibliometric Analysis Based on CiteSpace},
year = {2025},
isbn = {9798400716980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704289.3704300},
doi = {10.1145/3704289.3704300},
booktitle = {Proceedings of the 2024 7th International Conference on Big Data and Education},
pages = {22–28},
numpages = {7},
keywords = {Citespace, bibliometrics, generative AI},
location = {
},
series = {ICBDE '24}
}

@inproceedings{10.1145/3626252.3630828,
author = {Prasad, Prajish and Sane, Aamod},
title = {A Self-Regulated Learning Framework using Generative AI and its Application in CS Educational Intervention Design},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630828},
doi = {10.1145/3626252.3630828},
abstract = {Self-regulation refers to the ability to plan, monitor, control and reflect on one's problem-solving process. Prior research has shown that self-regulated learning (SRL) strategies help improve novice performance in solving programming problems. However, with the advent of LLM tools like ChatGPT, novices can generate fairly accurate code by just providing the problem prompt, and hence may forego applying essential self-regulation strategies such as planning and reflection to solve the problem. In this position paper, we discuss challenges and opportunities that generative AI technologies pose for novices' self-regulation strategies in the context of programming problem solving. We believe that the key challenge facing educators is that such technologies may hamper novices' ability to regulate their programming problem solving process.On the other hand, these technologies also open up the possibility to design new interventions that promote better SRL strategies in learners. We draw on generic and domain-specific self-regulated learning theories as the basis of our work, and propose an SRL framework that incorporates use of generative AI tools in programming problem solving. We illustrate how the proposed framework guides exploration of the design space of interventions that integrate generative AI in CS education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1070–1076},
numpages = {7},
keywords = {chatgpt, generative ai, llm, metacognition, pair programming, pair thinking, self-regulated learning, self-regulation, srl},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3706598.3713281,
author = {Tao, Ye and Fu, Xiaohui and Wu, Jiaying and Bian, Ze and Zhu, Aiyu and Bao, Qi and Zheng, Weiyue and Wang, Yubo and Zhu, Bin and Yang, Cheng and Zhou, Chuyi},
title = {AIFiligree: A Generative AI Framework for Designing Exquisite Filigree Artworks},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713281},
doi = {10.1145/3706598.3713281},
abstract = {Filigree art, which represents typical intricate metalwork, has been captivating audiences worldwide with its delicate lace-like patterns and interwoven metal wires’ refined aesthetics. Particularly, Chinese Intangible Cultural Heritage filigree craftsmanship has a unique aesthetic value in fine patterns and complex three-dimensional shapes. However, designing and creating filigree artworks is a labor-intensive and technically complex task and often requires extensive training and a deep understanding of the craft, which limits its design aesthetic and cultural continuity. Aiming to overcome these challenges, this study proposes an artificial intelligence (AI) -aided method that uses AI-generated content (AIGC) technology to accelerate the visualization process of this time-consuming and intricate craft by investigating the role of AI in craft design. First, a comprehensive study of filigree art culture is conducted to identify more than ten historic filigree techniques to obtain AI opportunities. Then, an AI-powered framework called AIFiligree is developed by optimizing culture-based labels and training parameters, enabling the generation of highly authentic fine filigree structures. Further, user workflows are introduced to support diverse design scenarios. Through user studies involving 22 filigree experts and 16 designers, we finally gained insights into AI’s opportunities and challenges in cultural learning, expression, and design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {658},
numpages = {18},
keywords = {Filigree, AIGC, AI design tools, Cultural intangible culture heritage},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706599.3721208,
author = {Wang, Amy and Ruparel, Roma and Iurchenko, Anna and Jhun, Paul and S\'{e}guin, Julie Anne and Strachan, Patricia and Wong, Renee and Karthikesalingam, Alan and Matias, Yossi and Hassidim, Avinatan and Webster, Dale and Semturs, Christopher and Krause, Jonathan and Schaekermann, Mike},
title = {Generative AI for medical education: Insights from a case study with medical students and an AI tutor for clinical reasoning},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3721208},
doi = {10.1145/3706599.3721208},
abstract = {Generative Artificial Intelligence (AI), particularly Large Language Models (LLMs), have demonstrated significant potential in clinical reasoning skills such as history-taking and differential diagnosis generation—critical aspects of medical education. This work explores how LLMs can augment medical curricula through interactive learning. We conducted a participatory design process with medical students, residents and medical education experts to co-create an AI-powered tutor prototype for clinical reasoning. As part of the co-design process, we conducted a qualitative user study, investigating learning needs and practices via interviews, and conducting concept evaluations through interactions with the prototype. Findings highlight the challenges learners face in transitioning from theoretical knowledge to practical application, and how an AI tutor can provide personalized practice and feedback. We conclude with design considerations, emphasizing the importance of context-specific knowledge and emulating positive preceptor traits, to guide the development of AI tools for medical education.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {303},
numpages = {8},
keywords = {Education, Medicine, Generative AI, Large Language Models},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3675812.3675874,
author = {Liu, Liyuan and Mendoza, Ruben A. and Martin, Thomas R. and Miori, Virginia M.},
title = {Generative AI-Powered Educational Alignment: A Framework for Matching Syllabus Course Topics with Web Description},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675874},
doi = {10.1145/3675812.3675874},
abstract = {The application of generative artificial intelligence (GAI) in the educational sector is increasingly gaining attention from researchers. This study explores the congruence between online course descriptions and actual course syllabi to improve course preparation and consistency for instructors. Alignment between course catalog descriptions and actual course content as detailed in the syllabus can lead to learning improvements, student satisfaction, and academic alignment in a program. Our research introduces a novel framework utilizing GAI to systematically evaluates and identifies mismatches and suggests content to close the gap between online course descriptions and syllabus content. We used OpenAI’s ChatGPT to extract key topics from course syllabi and assessed the congruence between results and course description content with embedding methods such as BERT, GPT-2, RoBERTa, and DistilBERT, coupled with cosine similarity metrics. Our framework also integrates an outlier detection algorithm to identify courses with significant misalignments and use GAI applications to refine and enhance course catalog descriptions. This approach helps higher education institutions update course offerings with cutting-edge technology and contributes to curriculum development, helping improve student learning efficiency and course design.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {340–346},
numpages = {7},
keywords = {AI in education, ChatGPT, Curriculum alignment, Curriculum development, Generative AI, Syllabus analysis},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@article{10.1145/3715977,
author = {Rashedi, Roxanne N.},
title = {From Academia to UX: Embodied Cognition, Creativity, and Generative AI},
year = {2025},
issue_date = {March - April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {2},
issn = {1072-5520},
url = {https://doi.org/10.1145/3715977},
doi = {10.1145/3715977},
abstract = {The Interactions website (interactions.acm.org) hosts a stable of bloggers who share insights and observations on HCI, often challenging current practices. Each issue we'll publish selected posts from some of the leading and emerging voices in the field.},
journal = {Interactions},
month = feb,
pages = {7–8},
numpages = {2}
}

@article{10.5555/3636988.3636996,
author = {Carter, Karla},
title = {"I, ChatBot": Co-Teaching Cybersecurity Courses With Generative AI},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {3},
issn = {1937-4771},
abstract = {This tutorial is for computing science faculty who are intrigued by the notion that generative AI, such as OpenAI's ChatGPT or Google's Bard, can enhance the way we teach and students learn cybersecurity. Rather than questioning if faculty and students should use generative AI in the classroom, you're asking how faculty and students can use generative AI appropriately and responsibly in the classroom. Our students deserve to understand the tools shaping their future; generative AI is not going away and we need to prepare our students for a future where not knowing how to write generative AI prompts isn't an option.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {27–28},
numpages = {2}
}

@inproceedings{10.1145/3632621.3671424,
author = {Mozgovoy, Maxim and Suero Montero, Calkin},
title = {Exploring Students Solutions to Concurrent and Parallel Programming Exercises – Impact of Generative AI},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671424},
doi = {10.1145/3632621.3671424},
abstract = {Background. Concurrent and parallel programming is difficult to teach and learn as the understanding of complex and abstract concepts such as nondeterminism, semaphore, and rare conditions, among others, is required [1, 2, 9], having as a core issue the synchronisation of processes to achieve a common goal [4]. It is well-acknowledged that concurrent and parallel programming skills are fundamental since, nowadays, computing is increasingly handled in a parallel manner [7].Problem and Motivation. Therefore, identifying students’ pitfalls and successes when solving practical concurrent and parallel programming exercises could shed light on the best approaches and strategies that they use [3]. In addition, the advent of large language models, and generative AI applications such as ChatGPT, has prompted intensive research on their use in several areas including programming teaching and learning [8]. Yet, the studies in the literature have focused on issues related to learning to program by novice students in introductory courses (e.g., CS1, CS2) [6]. Less work, however, has been presented on the impact of generative AI tools in advanced programming practices such as concurrent and parallel programming.Methodology. To investigate whether generative AI has had an impact on the submitted concurrent and parallel programming exercises solutions at the University of Aizu, Japan, we performed a comparison analysis of the students’ submissions over 2020–2023. The analysis included five different exercises covering the basis of concurrency through various tasks and scenarios where the implementation of parallel processes is needed as solution. For instance, exercises 2.3 and 2.4 required to create parallel processes and perform independent computations; exercises 3.2 and 3.3, required synchronisation of the parallel processes; and in exercise 3.5 a code template was given for modification. We analysed the submissions of 72 undergraduate 3rd year students (avg. 18 students/year) and labelled the solutions using the following nomenclature: OK, indicating a good solution; OKFeat, a good solution but with unusual features; AdvLib, use of unnecessary advanced library or functionality; BadTool, use of an inappropriate tool when the task definition explicitly required a different tool; CodeErr, general coding error; SyncErr, concurrent programming specific error; N/A, solution not submitted or incomplete.Results and Analysis. Results show a substantial increase in the incidence of use of advance libraries (AdvLib) and the wrong tools (BadTool) among students in 2023 for three out of the five analysed exercises. At the same time the concurrency programming-specific errors (SyncErr) also see a reduction in all the exercises. (Figure 1). This coincides with the availability of generative AI tools such as ChatGPT [5], which warrants further investigations to understand how students, teachers and instructors could harness the affordances of large language models in their concurrent programming learning, teaching, and practice.Contribution and Impact. This paper presents an initial step towards investigating the impact of generative AI on advanced programming topics. This research will continue to uncover strategies for the lecturers and instructors to identify the affordances and use of generative AI and to design exercises that harness these affordances to support students learning of difficult programming concepts.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {533–534},
numpages = {2},
keywords = {Evaluation of students’ exercises, Large language models in advanced programming},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3711403.3711435,
author = {Yang, Qi},
title = {A Review of the Role and Impact of Generative Artificial Intelligence on Education},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711435},
doi = {10.1145/3711403.3711435},
abstract = {In order to ensure quality development in the age of intelligence, it is crucial to integrate intelligent technology with education. Artificial Intelligence (AI) and Generative Artificial Intelligence (GAI) are disruptive technologies in the area of education. While online education brings significant advantages in enhancing educational quality, promoting educational equity, and improving educational efficiency, it has also raised concerns among scholars around the world regarding students' moral ethics, cultivation of emotional values, technological dependence, thinking deprivation, privacy, and policy making. Using Cite Space software to analyze more than 50 articles from core journals in the field of educational technology at home and abroad, this paper comprehensively summarizes the role and impact of generative AI in education up to 2023, suggests the limitations of generative AI in empowering education at present, and predicts the direction scholars will tend to research in this field in the future.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {121–127},
numpages = {7},
keywords = {ChatGPT, Education informatization, Generative artificial intelligence},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3706598.3713897,
author = {Kadoma, Kowe and Metaxa, Dana\'{e} and Naaman, Mor},
title = {Generative AI and Perceptual Harms: Who's Suspected of using LLMs?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713897},
doi = {10.1145/3706598.3713897},
abstract = {Large language models (LLMs) are increasingly integrated into a variety of writing tasks. While these tools can help people by generating ideas or producing higher quality work, like many other AI tools, they may risk causing a variety of harms, potentially disproportionately burdening historically marginalized groups. In this work, we introduce and evaluate perceptual harms, a term for the harms caused to users when others perceive or suspect them of using AI. We examined perceptual harms in three online experiments, each of which entailed participants evaluating write-ups from mock freelance writers. We asked participants to state whether they suspected the freelancers of using AI, to rank the quality of their writing, and to evaluate whether they should be hired. We found some support for perceptual harms against certain demographic groups. At the same time, perceptions of AI use negatively impacted writing evaluations and hiring outcomes across the board.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {861},
numpages = {17},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3600211.3604716,
author = {Khosrowi, Donal and Finn, Finola and Clark, Elinor},
title = {Diffusing the Creator: Attributing Credit for Generative AI Outputs},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604716},
doi = {10.1145/3600211.3604716},
abstract = {The recent wave of generative AI (GAI) systems like Stable Diffusion that can produce images from human prompts raises controversial issues about creatorship, originality, creativity and copyright. This paper focuses on creatorship: who creates and should be credited with the outputs made with the help of GAI? Existing views on creatorship are mixed: some insist that GAI systems are mere tools, and human prompters are creators proper; others are more open to acknowledging more significant roles for GAI, but most conceive of creatorship in an all-or-nothing fashion. We develop a novel view, called CCC (collective-centered creation), that improves on these existing positions. On CCC, GAI outputs are created by collectives in the first instance. Claims to creatorship come in degrees and depend on the nature and significance of individual contributions made by the various agents and entities involved, including users, GAI systems, developers, producers of training data and others. Importantly, CCC maintains that GAI systems can sometimes be part of a co-creating collective. We detail how CCC can advance existing debates and resolve controversies around creatorship involving GAI.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {890–900},
numpages = {11},
keywords = {Generative AI, collective-centered, copyright, creatorship, credit attribution, ethics, image synthesis},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

@inproceedings{10.1145/3632634.3655868,
author = {Sumner, Mary and Van Slyke, Craig and Niederman, Fred and Galletta, Dennis},
title = {Panel: Using Generative AI in Teaching and Learning.},
year = {2024},
isbn = {9798400704772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632634.3655868},
doi = {10.1145/3632634.3655868},
booktitle = {Proceedings of the 2024 Computers and People Research Conference},
articleno = {37},
numpages = {2},
location = {Murfreesboro, TN, USA},
series = {SIGMIS-CPR '24}
}

@inproceedings{10.1145/3656650.3656725,
author = {Nakamura, Hiroaki and Nakazato, Hiroyuki and Tobita, Hiroaki},
title = {LingoAI: Language Learning System Integrating Generative AI with 3D Virtual Character},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3656725},
doi = {10.1145/3656650.3656725},
abstract = {In this study, we developed LingoAI with the aim of solving the limitations that have arisen in chatbot language learning. The proposed method automatically generates natural responses in real time according to the learner’s inputs (i.e., voice and text), and a 3D character with facial expression changes and lip-sync is output as voice. This paper presents a functional overview and implementation of the LingoAI system.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {77},
numpages = {2},
keywords = {3D Virtual character, Generative AI, Language Learning},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}

@inproceedings{10.1145/3605468.3609775,
author = {Philbin, Carrie Anne},
title = {Impact of Generative AI on K-12 Students’ Perceptions of Computing: A Research Proposal},
year = {2023},
isbn = {9798400708510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605468.3609775},
doi = {10.1145/3605468.3609775},
abstract = {The rapid progress of generative artificial intelligence (AI) is fundamentally reshaping traditional perspectives on knowledge and skills, with profound implications for computing education. This necessitates a thorough examination of the relevance and timeliness of computing as a subject, especially for K-12 students who are making critical decisions about their future qualifications. This abstract proposes an empirical research study that aims to explore the effects of integrating generative AI in the creation of digital artefacts on K-12 students’ perceptions of the value of computing, as well as their understanding of ownership and achievement. Constructive discussions regarding the outlined approach are encouraged.},
booktitle = {Proceedings of the 18th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {28},
numpages = {2},
keywords = {Artificial Intelligence education, Creative computing, Generative AI, K-12 education, Student perceptions},
location = {Cambridge, United Kingdom},
series = {WiPSCE '23}
}

@inproceedings{10.1145/3643834.3661594,
author = {Liu, Yimeng and Sra, Misha},
title = {DanceGen: Supporting Choreography Ideation and Prototyping with Generative AI},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661594},
doi = {10.1145/3643834.3661594},
abstract = {Choreography creation requires high proficiency in artistic and technical skills. Choreographers typically go through four stages to create a dance piece: preparation, studio, performance, and reflection. This process is often individualized, complicated, and challenging due to multiple constraints at each stage. To assist choreographers, most prior work has focused on designing digital tools to support the last three stages of the choreography process, with the preparation stage being the least explored. To address this research gap, we introduce an AI-based approach to assist the preparation stage by supporting ideation, creating choreographic prototypes, and documenting creative attempts and outcomes. We address the limitations of existing AI-based motion generation methods for ideation by allowing generated sequences to be edited and modified in an interactive web interface. This capability is motivated by insights from a formative study we conducted with seven choreographers. We evaluated our system’s functionality, benefits, and limitations with six expert choreographers. Results highlight the usability of our system, with users reporting increased efficiency, expanded creative possibilities, and an enhanced iterative process. We also identified areas for improvement, such as the relationship between user intent and AI outcome, intuitive and flexible user interaction design, and integration with existing physical choreography prototyping workflows. By reflecting on the evaluation results, we present three insights that aim to inform the development of future AI systems that can empower choreographers.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {920–938},
numpages = {19},
keywords = {AI-supported choreography, choreography ideation, formative study, interactive AI, motion generation, system usability evaluation},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3613905.3651057,
author = {Lyu, Yao and Zhang, He and Niu, Shuo and Cai, Jie},
title = {A Preliminary Exploration of YouTubers' Use of Generative-AI in Content Creation},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3651057},
doi = {10.1145/3613905.3651057},
abstract = {Content creators increasingly utilize generative artificial intelligence (Gen-AI) on platforms such as YouTube, TikTok, Instagram, and various blogging sites to produce imaginative images, AI-generated videos, and articles using Large Language Models (LLMs). Despite its growing popularity, there remains an underexplored area concerning the specific domains where AI-generated content is being applied, and the methodologies content creators employ with Gen-AI tools during the creation process. This study initially explores this emerging area through a qualitative analysis of 68 YouTube videos demonstrating Gen-AI usage. Our research focuses on identifying the content domains, the variety of tools used, the activities performed, and the nature of the final products generated by Gen-AI in the context of user-generated content.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {20},
numpages = {7},
keywords = {Affiliated Marketing, Artificial Intelligence, Content Creation, Content Creator, Generative AI, Professional Development, User-generated Content, YouTube},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3643834.3660677,
author = {Benjamin, Jesse Josua and Lindley, Joseph and Edwards, Elizabeth and Rubegni, Elisa and Korjakow, Tim and Grist, David and Sharkey, Rhiannon},
title = {Responding to Generative AI Technologies with Research-through-Design: The Ryelands AI Lab as an Exploratory Study},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3660677},
doi = {10.1145/3643834.3660677},
abstract = {Generative AI technologies demand new practical and critical competencies, which call on design to respond to and foster these. We present an exploratory study guided by Research-through-Design, in which we partnered with a primary school to develop a constructionist curriculum centered on students interacting with a generative AI technology. We provide a detailed account of the design of and outputs from the curriculum and learning materials, finding centrally that the reflexive and prolonged ‘hands-on’ approach led to a co-development of students’ practical and critical competencies. From the study, we contribute guidance for designing constructionist approaches to generative AI technology education; further arguing to do so with ‘critical responsivity.’ We then discuss how HCI researchers may leverage constructionist strategies in designing interactions with generative AI technologies; and suggest that Research-through-Design can play an important role as a ‘rapid response methodology’ capable of reacting to fast-evolving, disruptive technologies such as generative AI.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {1823–1841},
numpages = {19},
keywords = {HCI education, generative AI, research-through-design},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3663433.3663456,
author = {Sinha, Ravi and Solola, Idris and Nguyen, Ha and Swanson, Hillary and Lawrence, LuEttaMae},
title = {The Role of Generative AI in Qualitative Research: GPT-4's Contributions to a Grounded Theory Analysis},
year = {2024},
isbn = {9798400717222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663433.3663456},
doi = {10.1145/3663433.3663456},
abstract = {We present reflections on our experience using a generative AI model in qualitative research, to illuminate the AI's contributions to our analytic process. Our analytic focus was a segment of classroom transcript, which captured a teacher introducing scientific theory-building practices to middle school students. We used a grounded theory approach to produce a fine-grained characterization of the teacher's talk moves during the lesson implementation. Our eventual goal is to build a more nuanced conceptualization of responsive teaching in the context of theory-building activities. We involved GPT-4 during the initial exploratory and later focused coding stages. For our analysis of GPT-4’s contributions to the analytic process, we analyzed our notes and analytic memos, along with video recordings of meetings where we discussed insights in response to GPT-4’s input. We present vignettes to illustrate pivotal moments where AI contributed to the coding process, including code generation, comparison, and refinement. The paper presents our experiences of conducting qualitative research in partnership with generative AI, underscoring the role that emerging technologies can play in the analysis of data and the development of grounded theory.},
booktitle = {Proceedings of the 2024 Symposium on Learning, Design and Technology},
pages = {17–25},
numpages = {9},
keywords = {Generative AI, Grounded theory, Qualitative methodologies, Responsive teaching},
location = {Delft, Netherlands},
series = {LDT '24}
}

@inproceedings{10.1145/3706468.3706545,
author = {Jin, Yueqiao and Yang, Kaixun and Yan, Lixiang and Echeverria, Vanessa and Zhao, Linxuan and Alfredo, Riordan and Milesi, Mikaela and Fan, Jie Xiang and Li, Xinyu and Gasevic, Dragan and Martinez-Maldonado, Roberto},
title = {Chatting with a Learning Analytics Dashboard: The Role of Generative AI Literacy on Learner Interaction with Conventional and Scaffolding Chatbots},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706545},
doi = {10.1145/3706468.3706545},
abstract = {Learning analytics dashboards (LADs) simplify complex learner data into accessible visualisations, providing actionable insights for educators and students. However, their educational effectiveness has not always matched the sophistication of the technology behind them. Explanatory and interactive LADs, enhanced by generative AI (GenAI) chatbots, hold promise by enabling dynamic, dialogue-based interactions with data visualisations and offering personalised feedback through text. Yet, the effectiveness of these tools may be limited by learners’ varying levels of GenAI literacy, a factor that remains underexplored in current research. This study investigates the role of GenAI literacy in learner interactions with conventional (reactive) versus scaffolding (proactive) chatbot-assisted LADs. Through a comparative analysis of 81 participants, we examine how GenAI literacy is associated with learners’ ability to interpret complex visualisations and their cognitive processes during interactions with chatbot-assisted LADs. Results show that while both chatbots significantly improved learner comprehension, those with higher GenAI literacy benefited the most, particularly with conventional chatbots, demonstrating diverse prompting strategies. Findings highlight the importance of considering learners’ GenAI literacy when integrating GenAI chatbots in LADs and educational technologies. Incorporating scaffolding techniques within GenAI chatbots can be an effective strategy, offering a more guided experience that reduces reliance on learners’ GenAI literacy.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {579–590},
numpages = {12},
keywords = {learning analytics dashboard, generative AI literacy, generative AI chatbots, data visualisation},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3706599.3720120,
author = {Zhang, He and Zha, Siyu and Cai, Jie and Wohn, Donghee Yvette and Carroll, John M.},
title = {Generative AI in Virtual Reality Communities: A Preliminary Analysis of the VRChat Discord Community},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720120},
doi = {10.1145/3706599.3720120},
abstract = {As immersive social platforms like VRChat increasingly adopt generative AI (GenAI) technologies, it becomes critical to understand how community members perceive, negotiate, and utilize these tools. In this preliminary study, we conducted a qualitative analysis of VRChat-related Discord discussions, employing a deductive coding framework to identify key themes related to AI-assisted content creation, intellectual property disputes, and evolving community norms. Our findings offer preliminary insights into the complex interplay between the community’s enthusiasm for AI-driven creativity and deep-rooted ethical and legal concerns. Users weigh issues of fair use, data ethics, intellectual property, and the role of community governance in establishing trust. By highlighting the tensions and trade-offs as users embrace new creative opportunities while seeking transparency, fair attribution, and equitable policies, this research offers valuable insights for designers, platform administrators, and policymakers aiming to foster responsible, inclusive, and ethically sound AI integration in future immersive virtual environments.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {305},
numpages = {11},
keywords = {Human-ai collaboration, AI assistant, user experience, online community},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706599.3719787,
author = {Ly, Carina and Peng, Eleanor and Liu, Katie and Qin, Anthony and Howe, Grace and Cheng, Alan Y. and Cuadra, Andrea},
title = {Museum in the Classroom: Engaging Students with Augmented Reality Museum Artifacts and Generative AI},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719787},
doi = {10.1145/3706599.3719787},
abstract = {Museum field trips provide a rich learning experience for children. However, they are complex and expensive for teachers to organize. Fortunately, digitization of museum artifacts makes it possible to use museum resources within the classroom. Museum in the Classroom (MITC) explores how augmented reality (AR) and generative artificial intelligence (AI) can create an interactive learning experience around museum artifacts. This iPad app allows educators to select historical topics from a curated artifact library, generating AR-based exhibits that students can explore. MITC engages students through interactive AR artifacts, AI-driven chatbots, and AI-generated quiz questions, based on a real exhibition at the Cantor Arts Center at Stanford University. A formative study with middle schoolers (N = 20) demonstrated that the app increased engagement compared to traditional learning methods. MITC also fostered a playful and comfortable environment to interact with museum artifacts. Our findings suggest that combining AR and AI has the potential to enrich classroom learning and offer a scalable alternative to traditional museum visits.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {409},
numpages = {8},
keywords = {Education/Learning; Children/Parents; Artifact or System},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3613904.3642393,
author = {Leong, Joanne and Pataranutaporn, Pat and Danry, Valdemar and Perteneder, Florian and Mao, Yaoli and Maes, Pattie},
title = {Putting Things into Context: Generative AI-Enabled Context Personalization for Vocabulary Learning Improves Learning Motivation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642393},
doi = {10.1145/3613904.3642393},
abstract = {Fostering students’ interests in learning is considered to have many positive downstream effects. Large language models have opened up new horizons for generating content tuned to one’s interests, yet it is unclear in what ways and to what extent this customization could have positive effects on learning. To explore this novel dimension, we conducted a between-subjects online study (n=272) featuring different variations of a generative AI vocabulary learning app that enables users to personalize their learning examples. Participants were randomly assigned to control (sentence sourced from pre-existing text) or experimental conditions (generated sentence or short story based on users’ text input). While we did not observe a difference in learning performance between the conditions, the analysis revealed that generative AI-driven context personalization positively affected learning motivation. We discuss how these results relate to previous findings and underscore their significance for the emerging field of using generative AI for personalized&nbsp;learning.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {677},
numpages = {15},
keywords = {education, generative artificial intelligence, learning, vocabulary},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3624720,
author = {Denny, Paul and Prather, James and Becker, Brett A. and Finnie-Ansley, James and Hellas, Arto and Leinonen, Juho and Luxton-Reilly, Andrew and Reeves, Brent N. and Santos, Eddie Antonio and Sarsa, Sami},
title = {Computing Education in the Era of Generative AI},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3624720},
doi = {10.1145/3624720},
abstract = {Challenges and opportunities faced by computing educators and students adapting to LLMs capable of generating accurate source code from natural-language problem descriptions.},
journal = {Commun. ACM},
month = jan,
pages = {56–67},
numpages = {12}
}

@inproceedings{10.1145/3641237.3691660,
author = {Albrecht-Crane, Christa and Comi, Dana and Flanagan, Suzan and Weech, Shelton},
title = {Situated AI Usage: A Methodological Approach to Generative AI User Research},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691660},
doi = {10.1145/3641237.3691660},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {123–127},
numpages = {5},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@inproceedings{10.1145/3600100.3626262,
author = {Berger, Markus and Ploennigs, Joern},
title = {ArchiGuesser – Teaching Architecture Styles using Generative AI},
year = {2023},
isbn = {9798400702303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600100.3626262},
doi = {10.1145/3600100.3626262},
abstract = {Generative AIs are opening new possibilities to create content from text, speech, and images based on simple input prompts. Users use this to improve their productivity when summarizing knowledge, templating communication, and inspiring their creativity. But, can it also be used to teach, e.g. about our architectural history? With this demo we are exploring this question. We created an educational game that combines various AI technologies from large language models and image generation to computer vision, in order to serve a single purpose: Teach users about architecture in an entertaining way. We wanted to enable students to explore and learn the diversity of our architectural history in a playful and exploratory way and at the same time experience and understand what current AI technologies can achieve.},
booktitle = {Proceedings of the 10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {284–285},
numpages = {2},
location = {Istanbul, Turkey},
series = {BuildSys '23}
}

@inproceedings{10.1145/3658549.3658566,
author = {Ho, Chia-Ling and Liu, Xin-Ying and Qiu, Yu-Wei and Yang, Shih-Yang},
title = {Research on Innovative Applications and Impacts of Using Generative AI for User Interface Design in Programming Courses},
year = {2024},
isbn = {9798400709180},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658549.3658566},
doi = {10.1145/3658549.3658566},
abstract = {Generative Artificial Intelligence (GAI) has become a hot topic nowadays, as its powerful content generation models enable users to instantly create everything from digital media products to coding examples through simple text queries, providing more possibilities in the field of education. This study aims to investigate the impact of Generative AI intervention in teaching App Inventor programming courses, analyzing the differences between UI materials designed by traditional teachers based on their professional knowledge and experience, and UI materials created by Generative AI in classroom teaching. The study also evaluates the impact of Generative AI on students' learning outcomes and motivation through satisfaction and Technology Acceptance Model (TAM) questionnaires. The results indicate that UI materials produced through Generative AI effectively enhance students' satisfaction with the course and their acceptance of new technologies. Compared to traditional teaching methods, Generative AI significantly saves teachers' time and effort in designing materials while simultaneously improving teaching efficiency and quality.},
booktitle = {Proceedings of the 2024 International Conference on Information Technology, Data Science, and Optimization},
pages = {68–72},
numpages = {5},
keywords = {Generative artificial intelligence, Intelligent assistant, Learning effectiveness, Programming course, User interface design},
location = {Taipei, Taiwan},
series = {I-DO '24}
}

@inproceedings{10.1145/3657604.3662046,
author = {Chen, Binglin and Lewis, Colleen M. and West, Matthew and Zilles, Craig},
title = {Plagiarism in the Age of Generative AI: Cheating Method Change and Learning Loss in an Intro to CS Course},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662046},
doi = {10.1145/3657604.3662046},
abstract = {Background: ChatGPT became widespread in early 2023 and enabled the broader public to use powerful generative AI, creating a new means for students to complete course assessments.  Purpose: In this paper, we explored the degree to which generative AI impacted the frequency and nature of cheating in a large introductory programming course. We also estimate the learning impact of students choosing to submit plagiarized work rather than their own work.  Methods: We identified a collection of markers that we believe are indicative of plagiarism in this course. We compare the estimated prevalence of cheating in the semesters before and during which ChatGPT became widely available. We use linear regression to estimate the impact of students' patterns of cheating on their final exam performance. Findings: The patterns associated with these plagiarism markers suggest that the quantity of plagiarism increased with the advent of generative AI, and we see evidence of a shift from online plagiarism hubs (e.g., Chegg, CourseHero) to ChatGPT. In addition, we observe statistically significant learning losses proportional to the amount of presumed plagiarism, but there is no statistical difference on the proportionality between semesters.  Implications: Our findings suggest that unproctored exams become increasingly insecure and care needs to be taken to ensure the validity of summative assessments. More importantly, our results suggest that generative AI can be detrimental to students' learning. It seems necessary for educators to reduce the benefit of students using generative AI for counterproductive purposes.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {75–85},
numpages = {11},
keywords = {cheating, cs 1, generative ai, llm, plagiarism detection},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3630106.3659023,
author = {Dotan, Ravit and Parker, Lisa S. and Radzilowicz, John},
title = {Responsible Adoption of Generative AI in Higher Education: Developing a “Points to Consider” Approach Based on Faculty Perspectives},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3659023},
doi = {10.1145/3630106.3659023},
abstract = {This paper proposes an approach to the responsible adoption of generative AI in higher education, employing a “points to consider” approach that is sensitive to the goals, values, and structural features of higher education. Higher education's ethos of collaborative faculty governance, pedagogical and research goals, and embrace of academic freedom conflict, the paper argues, with centralized top-down approaches to governing AI that are common in the private sector. The paper is based on a semester-long effort at the University of Pittsburgh which gathered and organized perspectives on generative AI in higher education through a collaborative, iterative, interdisciplinary process that included recurring group discussions, three standalone focus groups, and an informal survey. The paper presents insights drawn from this effort—that give rise to the “points to consider” approach the paper develops. These insights include the benefits and risks of potential uses of generative AI In higher education, as well as barriers to its adoption, and culminate in the six normative points to consider when adopting and governing generative AI in institutions of higher education.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {2033–2046},
numpages = {14},
keywords = {generative AI, higher education, points to consider, policy making},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3706599.3719923,
author = {Williams, Aneka and Fox, Grace and Amon, Mary Jean and Tanni, Tangila Islam and Solihin, Yan},
title = {The GenAI networked privacy problem at work- How privacy knowledge and perceptions predict Generative AI disclosure in professional contexts},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719923},
doi = {10.1145/3706599.3719923},
abstract = {This paper explores the GenAI networked privacy problem in the professional use context. Utilizing a survey of GenAI users, our study demonstrates the importance of disclosure comfort, shaped by privacy perceptions related to control and fairness, and knowledge of GenAI privacy controls in driving professional information disclosure. Our findings provide initial evidence of the GenAI networked privacy problem and the need for both (i) further research to deepen our understanding and (ii) efforts from organizations to educate and empower their employees to engage in behaviors which lead to better networked privacy management in this context.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {519},
numpages = {9},
keywords = {Generative AI, Networked Privacy, Privacy-Perceptions, Privacy-Knowledge, Data Disclosure},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3643834.3661624,
author = {Uusitalo, Severi and Salovaara, Antti and Jokela, Tero and Salmimaa, Marja},
title = {”Clay to Play With”: Generative AI Tools in UX and Industrial Design Practice},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661624},
doi = {10.1145/3643834.3661624},
abstract = {Generative artificial intelligence (GAI) is transforming numerous professions, not least various fields intimately relying on creativity, such as design. To explore GAI’s adoption and appropriation in design, an interview-based study probed 10 specialists in user experience and industrial design, with varying tenure and GAI experience, for their adoption/application of GAI tools, reasons for not using them, problems with ownership and agency, speculations about the future of creative work, and GAI tools’ roles in design sensemaking. Insight from reflexive thematic analysis revealed wide variation in attitudes toward GAI tools – from threat-oriented negative appraisals to identification of empowerment opportunities – which depended on the sense of agency and perceived control. The paper examines this finding in light of the Coping Model of User Adaptation and discusses designers’ metacognitive skills as possible underpinnings for their attitudes. Avenues for further research are identified accordingly.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {1566–1578},
numpages = {13},
keywords = {UX design, coping model of user adaptation, design, generative AI, industrial design, metacognition},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3613905.3644054,
author = {Liu, Pinyao and Kitson, Alexandra and Picard-Deland, Claudia and Carr, Michelle and Liu, Sijia and Lc, Ray and Zhu-Tian, Chen},
title = {Virtual Dream Reliving: Exploring Generative AI in Immersive Environment for Dream Re-experiencing},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3644054},
doi = {10.1145/3613905.3644054},
abstract = {Dreaming is a fundamental component of the human experience. Modern-day psychologists and neuroscientists use “dreamwork” to describe a variety of strategies that deepen and engage with dreams. Re-experiencing the dream as if reliving the memory, feelings, and bodily sensations from the dream is a key element shared by many dreamwork practices. In this paper, we propose the concept of "dreamwork engineering" by creating a system enabling dream re-experiencing in a virtual reality environment through generative AI. Through an autoethnographic study, the first author documented his own dreams and relived his dream experiences for two weeks. Based on our results, we propose a technology-aided dreamwork framework, where technology could potentially augment traditional dreamwork methods through spatiality and movement, interactivity and abstract anchor. We further highlight the collaborative role of technology in dreamwork and advocate that the scientific community could also benefit from dreaming and dreamwork for scientific creativity.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {569},
numpages = {11},
keywords = {Dream Re-experiencing, Dreamwork Engineering, Generative AI, Personal Insight, Scientific Creativity, Virtual Reality},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3544549.3585657,
author = {Inie, Nanna and Falk, Jeanette and Tanimoto, Steve},
title = {Designing Participatory AI: Creative Professionals’ Worries and Expectations about Generative AI},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585657},
doi = {10.1145/3544549.3585657},
abstract = {Generative AI, i.e., the group of technologies that automatically generate visual or written content based on text prompts, has undergone a leap in complexity and become widely available within just a few years. Such technologies potentially introduce a massive disruption to creative fields. This paper presents the results of a qualitative survey (N = 23) investigating how creative professionals think about generative AI. The results show that the advancement of these AI models prompts important reflections on what defines creativity and how creatives imagine using AI to support their workflows. Based on these reflections, we discuss how we might design participatory AI in the domain of creative expertise with the goal of empowering creative professionals in their present and future coexistence with AI.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {82},
numpages = {8},
keywords = {creative professionals, creativity support, generative AI, participatory AI, participatory design},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@inproceedings{10.1145/3681756.3697970,
author = {Heng, Yuyao and Chen, Yingman and Gao, Zihan},
title = {Echoes of Antiquity: An Interactive Installation for Guqin Culture Heritage Using Mid-Air interaction and Generative AI},
year = {2024},
isbn = {9798400711381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3681756.3697970},
doi = {10.1145/3681756.3697970},
abstract = {With the development of mid-air interaction, the digital preservation and interactive learning of intangible cultural heritage (ICH) have become increasingly significant. However, the intrinsic significance of the cultural symbols embedded within numerous ICH remains largely obscure to the general public. This paper introduces "Echoes of Antiquity", an interactive installation that utilizes Leap Motion for gesture recognition and generative AI for image processing to vividly illustrate the symbolic elements of Guqin culture, thus bridge the existing chasm in public understanding and appreciation of Guqin’s rich cultural heritage. Specially, our system utilizes Leap Motion to capture gestures and deliver AI-generated images as feedback, thereby enhancing the understanding and retention of the Guqin’s cultural heritage through the seamless integration of motion and visual cues.},
booktitle = {SIGGRAPH Asia 2024 Posters},
articleno = {22},
numpages = {2},
keywords = {Guqin Art, Mid-air interaction, Generative AI, Cultural Preservation, Interactive Design},
location = {
},
series = {SA '24}
}

@inproceedings{10.1145/3678392.3678405,
author = {Qi, Yuanyi and Wang, Lamei},
title = {Learning Assessment for Open Education Learners in the Era of Generative Artificial Intelligence},
year = {2024},
isbn = {9798400717123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678392.3678405},
doi = {10.1145/3678392.3678405},
abstract = {Generative Artificial Intelligence (AI) tools are now used by students to do their learning assessment, thus impairing the value of such learning assessment. For open education learners who aim to just obtain adult education diplomas, particularly, the cost of learning assessment is becoming increasingly low due to the use of generative AI. How to instructional design and assessment for open education learners in the era of generative AI becomes therefore an issue requiring urgent solutions. From such perspectives as the advantages and disadvantages of generative AI, the learning needs and characteristics of open education learners, and the new characteristics of learning assessment with the use of generative AI, this paper examines the dilemma of instructional design and assessment during the age of generative AI, puts forward the ideas and models for the design of homework for open education learners, and makes learning assessment design proposals with respect to renewing the methods of learning assessment, improving the AI literacy of both teachers and students, etc., with a view to offering some insight for the design of homework in the era of generative AI.},
booktitle = {Proceedings of the 2024 10th International Conference on Frontiers of Educational Technologies},
pages = {38–44},
numpages = {7},
keywords = {Generative AI, Learning assessment, Open education learners},
location = {Malacca, Malaysia},
series = {ICFET '24}
}

@inproceedings{10.1145/3593013.3594067,
author = {Hacker, Philipp and Engel, Andreas and Mauer, Marco},
title = {Regulating ChatGPT and other Large Generative AI Models},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3594067},
doi = {10.1145/3593013.3594067},
abstract = {Large generative AI models (LGAIMs), such as ChatGPT, GPT-4 or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create. However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs. This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities. After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals. It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output. We tailor regulatory duties to these different actors along the value chain and suggest strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of society at large. Rules in the AI Act and other direct regulation must match the specificities of pre-trained models. The paper argues for three layers of obligations concerning LGAIMs (minimum standards for all LGAIMs; high-risk obligations for high-risk use cases; collaborations along the AI value chain). In general, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency and (ii) risk management. Non-discrimination provisions (iii) may, however, apply to LGAIM developers. Lastly, (iv) the core of the DSA's content moderation rules should be expanded to cover LGAIMs. This includes notice and action mechanisms, and trusted flaggers.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1112–1123},
numpages = {12},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

@inproceedings{10.1145/3630106.3659005,
author = {Liesenfeld, Andreas and Dingemanse, Mark},
title = {Rethinking open source generative AI: open-washing and the EU AI Act},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3659005},
doi = {10.1145/3630106.3659005},
abstract = {The past year has seen a steep rise in generative AI systems that claim to be open. But how open are they really? The question of what counts as open source in generative AI is poised to take on particular importance in light of the upcoming EU AI Act that regulates open source systems differently, creating an urgent need for practical openness assessment. Here we use an evidence-based framework that distinguishes 14 dimensions of openness, from training datasets to scientific and technical documentation and from licensing to access methods. Surveying over 45 generative AI systems (both text and text-to-image), we find that while the term open source is widely used, many models are ‘open weight’ at best and many providers seek to evade scientific, legal and regulatory scrutiny by withholding information on training and fine-tuning data. We argue that openness in generative AI is necessarily composite (consisting of multiple elements) and gradient (coming in degrees), and point out the risk of relying on single features like access or licensing to declare models open or not. Evidence-based openness assessment can help foster a generative AI landscape in which models can be effectively regulated, model providers can be held accountable, scientists can scrutinise generative AI, and end users can make informed decisions.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1774–1787},
numpages = {14},
keywords = {Technology assessment, large language models, text generators, text-to-image generators},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3663548.3688506,
author = {Li, Mixuan and Aflatoony, Leila},
title = {Exploring the Potential of Generative AI in DIY Assistive Technology Design by Occupational Therapists},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3688506},
doi = {10.1145/3663548.3688506},
abstract = {This paper examines the potential integration of generative AI into the assistive technology (AT) making and adaptation process, with Occupational Therapists (OTs) as the primary beneficiaries, as they are often involved in designing ‘do-it-yourself assistive technology’ (DIY AT) to support independent living for individuals with disabilities. We initiated the study by considering the traditional AT-making processes performed by OTs and prototyped a web interface that incorporates generative AI to support these processes. Through a series of user studies, we collected OTs' preliminary insights on how generative AI could bridge the gap between clinical reasoning and technical design, potentially streamlining the AT creation and adaptation process while maintaining the crucial element of personalized AT solutions. The study's findings highlight several key benefits of generative AI in OT practice: 1) customization of AT solutions tailored to individual client needs, 2) improved visualization capabilities for client communication, 3) inspiration for new AT design ideas, and 4) potential for rapid prototyping and practice. However, key drawbacks were noted, including limitations in inputting measurements, which can lead to inaccurate outputs and necessitate substantial modifications to the created AT, along with challenges associated with the current state of generative AI.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {109},
numpages = {6},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@article{10.1145/3688086,
author = {Schmucker, Robin},
title = {Harnessing Machine Learning and Generative AI: A New Era in Online Tutoring Systems},
year = {2024},
issue_date = {Fall 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1528-4972},
url = {https://doi.org/10.1145/3688086},
doi = {10.1145/3688086},
abstract = {Discover how the convergence of machine learning and generative AI is revolutionizing online tutoring, enabling systems that evolve to become better teachers--continuously refining their instructional methods based on student data and feedback.},
journal = {XRDS},
month = oct,
pages = {40–45},
numpages = {6}
}

@inproceedings{10.1145/3678884.3681819,
author = {Zheng, Qingxiao and Rabbani, Parisa and Lin, Yu-Rou and Mansour, Daan and Huang, Yun},
title = {SOAP.AI: A Collaborative Tool for Documenting Human Behavior in Videos through Multimodal Generative AI},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678884.3681819},
doi = {10.1145/3678884.3681819},
abstract = {Large Multimodal Models offer new opportunities for analyzing human activities and social behavior in fields requiring expert knowledge. Their in-context learning and adaptive abilities make customization possible for experts without coding skills. This paper introduces SOAP.AI, a collaborative tool facilitating experts to analyze human behaviors using AI. SOAP.AI is designed to foster a sense of ownership during human-AI collaboration, encouraging task modifications and evaluations to meet diverse goals. For instance, teaching AI to recognize behavioral nuances in autistic individuals could enhance AI's inclusion and value alignment. Our demonstration will engage CSCW researchers and HCI practitioners to discuss the design of collaborative AI systems for behavioral insights generation in various settings, such as medical settings, sports, social media, education, home care, and more.},
booktitle = {Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
pages = {87–90},
numpages = {4},
keywords = {behavior analysis, collaborative work, generative ai, videos, vision-language models},
location = {San Jose, Costa Rica},
series = {CSCW Companion '24}
}

@article{10.1145/3712295,
author = {Bosco, Cristina and Shojaei, Fereshtehossadat and Theisz, Alec A. and Nguyen, Vivian and Song, Haoru and Han, Ruixiang and Osorio Torres, John A. and Chheda, Darshil and Lin, Jenny and Peng, Xinran and Waseem, Nawal Z. and Simpkins, Chelsea and Cureton, Bianca and Himes, Anna K. and Jessup, Nenette M. and Lu, Yvonne and Hendrie, Hugh C. and Barnes, Priscilla A. and Hill, Carl V. and Shih, Patrick C.},
title = {“I don’t see anything specifically about Black/African Americans.” Testing an Alzheimer-specific generative AI tool tailored for African American/Black communities},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712295},
doi = {10.1145/3712295},
abstract = {Low levels of health literacy concerning Alzheimer's Disease and related dementias (ADRD) impact African American/Black communities access to appropriate ADRD care. Additionally, a legacy of mistrust in medical research due to systemic racism, has resulted in insufficient participation in ADRD clinical trials among African American/Black adults.This study explores the potential of generative AI to improve ADRD literacy and encourage participation in clinical trials among African American/Black older adults. We designed a mobile health intervention featuring AI-driven conversational agents - a chatbot and a voice assistant - specifically developed for this population. We tested the quality of the intervention using heuristics methodology adapted to the target population along with inputs from African American/ Black medical professionals and UX designers.Key findings highlight the unique needs of the African American/Black communities for culturally relevant content that is accessible to users with varying language levels and tailored to users’ geographical location. Concerning the interaction, high levels of personalization and control over the interaction can promote the use of the tool, by minimizing complexity and maximizing accessibility.These findings show the novel contribution offered by our study in the domain of designing health technology with generative AI, particularly LLMS, for African American/Black communities.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Healthcare},
month = jan,
keywords = {Generative AI, African American/Blacks, ADRD, under-served communities}
}

@inproceedings{10.1145/3711403.3711425,
author = {Mi, Zejia and Li, Kangkang},
title = {Research on the Application of Generative Artificial Intelligence in Human-machine Cooperative Teaching},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711425},
doi = {10.1145/3711403.3711425},
abstract = {The rise of Generative Artificial Intelligence (GAI) has brought new transformations to education. AI-driven educational applications that employ human-machine collaborative teaching are expected to become one of the mainstream teaching methods in the future. This study proposes a human-machine collaborative teaching model based. It developed a human-machine collaborative learning system utilizing the SparkDesk and the WeChat system, providing learners with functions such as conversation, resource sharing, and intelligent teaching. The study adopts a quasi-experimental research method, using the learning tasks of the "Smart Application of Educational Media" course as an example to test the effectiveness of the model above. The experimental results show that this model and its system can significantly enhance online collaborative learning interaction, improve online collaborative learning performance, and elevate the online collaborative learning experience. Finally, based on the experimental research, three recommendations are made: expanding the application scenarios of human-machine collaborative teaching, cultivating students' abilities and competencies in human-machine collaborative inquiry, and strengthening the evaluation and management of human-machine collaborative teaching, with the aim of profoundly integrating generative AI into human-machine collaborative teaching.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {154–159},
numpages = {6},
keywords = {generative artificial intelligence, human-machine collaboration, large language model, teaching mode},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3706468.3706530,
author = {Thomas, Danielle R and Borchers, Conrad and Kakarla, Sanjit and Lin, Jionghao and Bhushan, Shambhavi and Guo, Boyuan and Gatz, Erin and Koedinger, Kenneth R},
title = {Does Multiple Choice Have a Future in the Age of Generative AI? A Posttest-only RCT},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706530},
doi = {10.1145/3706468.3706530},
abstract = {The role of multiple-choice questions (MCQs) as effective learning tools has been debated in past research. While MCQs are widely used due to their ease in grading, open response questions are increasingly used for instruction, given advances in large language models (LLMs) for automated grading. This study evaluates MCQs effectiveness relative to open-response questions, both individually and in combination, on learning. These activities are embedded within six tutor lessons on advocacy. Using a posttest-only randomized control design, we compare the performance of 234 tutors (790 lesson completions) across three conditions: MCQ only, open response only, and a combination of both. We find no significant learning differences across conditions at posttest, but tutors in the MCQ condition took significantly less time to complete instruction. These findings suggest that MCQs are as effective, and more efficient, than open response tasks for learning when practice time is limited. To further enhance efficiency, we autograded open responses using GPT-4o and GPT-4-turbo. GPT models demonstrate proficiency for purposes of low-stakes assessment, though further research is needed for broader use. This study contributes a dataset of lesson log data, human annotation rubrics, and LLM prompts to promote transparency and reproducibility.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {494–504},
numpages = {11},
keywords = {Tutoring, Generative AI, Human-AI tutoring, AI-assisted tutoring, Assessment},
location = {
},
series = {LAK '25}
}

@article{10.1145/3615859,
author = {Cusumano, Michael A.},
title = {Generative AI as a New Innovation Platform},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/3615859},
doi = {10.1145/3615859},
abstract = {Considering the stability and longevity of a potential new foundational technology.},
journal = {Commun. ACM},
month = sep,
pages = {18–21},
numpages = {4}
}

@article{10.1145/3710912,
author = {Guridi, Jose A. and Hwang, Angel Hsing-Chi and Santo, Duarte and Goula, Maria and Cheyre, Cristobal and Humphreys, Lee and Rangel, Marco},
title = {From Fake Perfects to Conversational Imperfects: Exploring Image-Generative AI as a Boundary Object for Participatory Design of Public Spaces},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3710912},
doi = {10.1145/3710912},
abstract = {Designing public spaces requires balancing the interests of diverse stakeholders within a constrained physical and institutional space. Designers usually approach these problems through participatory methods but struggle to incorporate diverse perspectives into design outputs. The growing capabilities of image-generative artificial intelligence (IGAI) could support participatory design. Prior work in leveraging IGAI's capabilities in design has focused on augmenting the experience and performance of individual creators. We study how IGAI could facilitate participatory processes when designing public spaces, a complex collaborative task. We conducted workshops and IGAI-mediated interviews in a real-world participatory process to upgrade a park in Los Angeles. We found (1) a shift from focusing on accuracy to fostering richer conversations as the desirable outcome of adopting IGAI in participatory design, (2) that IGAI promoted more space-aware conversations, and (3) that IGAI-mediated conversations are subject to the abilities of the facilitators in managing the interaction between themselves, the AI, and stakeholders. We contribute by discussing practical implications for using IGAI in participatory design, including success metrics, relevant skills, and asymmetries between designers and stakeholders. We finish by proposing a series of open research questions.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW014},
numpages = {33},
keywords = {artificial intelligence, design, generative AI, human-AI interaction}
}

@article{10.5555/3636988.3637005,
author = {Luckett, Jonathan},
title = {Regulating Generative AI: A Pathway to Ethical and Responsible Implementation},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {3},
issn = {1937-4771},
abstract = {Artificial intelligence (AI) is becoming more and more prevalent in our daily lives, and its potential applications are practically limitless. However, as with any technology, there are concerns about how AI could be misused or abused. One of the most serious concerns is the potential for discrimination, particularly against women or minorities, when AI systems are used for tasks like job hiring. Additionally, there are concerns about privacy and security, as AI could be used to monitor people's movements or launch cyberattacks. To address these concerns, regulations must be developed to ensure that AI is developed and used ethically and responsibly. These regulations should address issues like safety, privacy, security, and discrimination. Finally, it is important to educate the public about AI and how to use it safely and responsibly. In this paper, I will examine the AI regulations and challenges that exist today, particularly in the United States. Two regulations I will focus on are the AI in Government Act of 2020 and the National Artificial Intelligence Initiative Act of 2020. Additionally, I will examine two Executive Orders that have addressed the issue of AI in the federal government. This paper examines AI generative tools, such as Bing, Bard, and Chat-GPT. Finally, the paper concludes with some policy considerations and recommendations for federal agencies.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {47–65},
numpages = {19}
}

@inproceedings{10.1145/3686038.3686063,
author = {Clos, Jeremie and Chen, Yoke Yie},
title = {Investigating the Impact of Generative AI on Students and Educators: Evidence and Insights from the Literature},
year = {2024},
isbn = {9798400709890},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686038.3686063},
doi = {10.1145/3686038.3686063},
abstract = {Generative artificial intelligence (AI) has become one of the main concerns of knowledge workers due to its ability to mimic realistic human reasoning and creativity. However, this integration raises critical concerns about trust and ethics, which are crucial in shaping both the acceptance and effective utilisation of these technologies. There are many reports, articles and papers currently exploring the opportunities and challenges of LLMs in higher education from the perspective of students and educators. However, these papers often focus on specific contexts like in the UK, US or a particular institutions. In this paper, we examine the problems of generative AI in higher education from educator and student perspectives using scientometrics and text analysis to provide an overview of the research landscape, followed by a narrative review and thematic analysis of selected literature. Some findings of this work are: (1) Students and educators found different ways to use generative AI. Students focus more on using it as an assistant (revising and preparing for lectures, helping with homework) and educators as a content production assistant (writing lecture notes, personalising content). Commonalities are that both students and educators use generative AI as an accessibility aid, e.g., to rephrase sentences or explain concepts. (2) The main concerns of higher education regarding generative AI are equity in access, clarity of rules regarding usage, and job displacement.},
booktitle = {Proceedings of the Second International Symposium on Trustworthy Autonomous Systems},
articleno = {25},
numpages = {6},
location = {Austin, TX, USA},
series = {TAS '24}
}

@inproceedings{10.1145/3706468.3706490,
author = {Strugatski, Alona and Alexandron, Giora},
title = {Applying IRT to Distinguish Between Human and Generative AI Responses to Multiple-Choice Assessments},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706490},
doi = {10.1145/3706468.3706490},
abstract = {Generative AI is transforming the educational landscape, raising significant concerns about cheating. Despite the widespread use of multiple-choice questions (MCQs) in assessments, the detection of AI cheating in MCQ-based tests has been almost unexplored, in contrast to the focus on detecting AI-cheating on text-rich student outputs. In this paper, we propose a method based on the application of Item Response Theory (IRT) to address this gap. Our approach operates on the assumption that artificial and human intelligence exhibit different response patterns, with AI cheating manifesting as deviations from the expected patterns of human responses. These deviations are modeled using Person-Fit Statistics (PFS). We demonstrate that this method effectively highlights the differences between human responses and those generated by premium versions of leading chatbots (ChatGPT, Claude, and Gemini), but that it is also sensitive to the amount of AI cheating in the data. Furthermore, we show that the chatbots differ in their reasoning profiles. Our work provides both a theoretical foundation and empirical evidence for the application of IRT to identify AI cheating in MCQ-based assessments.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {817–823},
numpages = {7},
keywords = {Cheating with AI, separating AI from humans, Item-response theory, person-fit statistics},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3641555.3705061,
author = {Liu, Rongxin and Xu, Benjamin and Perez, Christopher and Zhao, Julianna and Zhukovets, Yuliia and Malan, David J.},
title = {Assessment in CS50 with AI: Leveraging Generative Artificial Intelligence for Personalized Student Evaluation},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705061},
doi = {10.1145/3641555.3705061},
abstract = {The scalability challenges of code review and pair-programming assessments in large computer science courses, such as CS50 at Harvard University, have opened up opportunities for the application of Generative AI. Leveraging large language models (LLMs), CS50.ai offers a suite of AI-based tools that assist both students and instructors in mastering course material while overcoming the limitations posed by human resource constraints. This demo highlights how generative AI can be employed to conduct code reviews and pair-programming simulations, providing real-time feedback, code explanations, and collaborative programming insights. By integrating these AI tools into students' learning journeys, we aim to mimic the 1:1 interaction between instructor and student, improving both formative and summative assessments. We will showcase how these tools are implemented to scale personalized feedback, ensure academic integrity, and maintain pedagogical efficacy. Our presentation will also reflect on lessons learned from deploying these AI-driven tools in recent course offerings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1735},
numpages = {1},
keywords = {AI, LLMs, artificial intelligence, generative AI, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3722237.3722258,
author = {Fang, Wenjie and Luo, Bin},
title = {Application and Impact of Generative Artificial Intelligence Techniques in Education--Citespace-based visualization and analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722258},
doi = {10.1145/3722237.3722258},
abstract = {Recently, generative AI technology has arisen as a trending research agenda in education.  This study makes an review of 260 documents from the CNKI database published from 2020 to 2024. Through the bibliometric and content analysis methods, together with the CiteSpace tool, highlight the trending application of this technology in education, the distribution characteristics of the core authors and institutions' postings, and the clustering analysis of the research hotspots. The results show continued wide adoption of generative AI technology in education in recent years, peaking sharply in 2023. There hasn't been a stable core group of authors within the field, and the collaborative network is relatively sparse. Research hotspots mainly cover artificial intelligence, human-computer collaboration and educational transformation, which indicates the function generative AI technology could have within the digital transformation and quality enhancement of education. This paper additionally shows the actualization of generative AI technology through its presentation of AI tutors and teaching assistants, teaching models reform, and reshaped instructional evaluation systems via case studies. In face of misuse, integrity issues, and ethical concerns arising, there is a need to find a balance in the application of the technology, such that its more proper development can promote rather than replace human subjectivity.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {117–122},
numpages = {6},
keywords = {CiteCpace visual analytic, Educational Application, Generative AI, Human-computer collaboration},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3722237.3722399,
author = {Lin, Yan and Zhang, Lu},
title = {Applications and Challenges of Generative Artificial Intelligence Enabling Critical Thinking Development in International Undergraduate Education},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722399},
doi = {10.1145/3722237.3722399},
abstract = {In today's fast-changing information-exploding era, developing students' critical thinking has become one of the most important tasks in international undergraduate education. Generative AI can simulate human creativity and imagination, providing brand-new resources and tools for critical thinking development. This paper details the application of generative AI technology in providing intelligent teaching resources, implementing personalized learning tutoring, promoting interdisciplinary integrated learning, cultivating the spirit of questioning and reforming assessment methods, etc. It also points out that the application of this intelligent technology in the teaching process is also facing the main challenges of data bias and false information, data privacy and security, and the enhancement of teachers' application ability, and gives specific countermeasures. Therefore, this paper aims to provide a useful reference for international undergraduate education practice and promote the integration of generative AI technology to empower students' critical thinking development.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {944–949},
numpages = {6},
keywords = {Critical Thinking, Generative Artificial Intelligence, Intelligent Teaching, Technological Risks},
location = {
},
series = {ICAIE '24}
}

@article{10.1145/3664824,
author = {Zhang, Hongzhou and Khanal, Shaleen and Taeihagh, Araz},
title = {Public-Private Powerplays in Generative AI Era: Balancing Big Tech Regulation Amidst Global AI Race},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664824},
doi = {10.1145/3664824},
abstract = {The past decades have seen unbridled growth in the economic, social and political influence of large technology corporations (Big Tech) in the United States. The rising popularity of Generative Artificial Intelligence (GenAI) is likely to further consolidate the power of these companies. The rapid expansion of Big Tech in various domains has triggered a wide range of economic, ethical, and political concerns. However, the US Government is also engaged in a growing technology and AI race with China. As a result, the US government now faces the challenges of balancing the external goal of winning the AI race through close collaboration with the Big Tech and the internal objective of regulating the Big Tech. In this paper, we argue that this intersection of interest has been the primary motivator of US policy on the governance of Big Tech. By exploring the evolution of AI policy in the US, we highlight the role internal and external pressures have played in its approach to AI governance.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = may,
keywords = {Generative AI, GenAI, Big Tech, artificial intelligence, AI Race, governance, United States}
}

@inproceedings{10.1145/3706468.3706544,
author = {Yang, Kaixun and Rakovi\'{c}, Mladen and Liang, Zhiping and Yan, Lixiang and Zeng, Zijie and Fan, Yizhou and Ga\v{s}evi\'{c}, Dragan and Chen, Guanliang},
title = {Modifying AI, Enhancing Essays: How Active Engagement with Generative AI Boosts Writing Quality},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706544},
doi = {10.1145/3706468.3706544},
abstract = {Students are increasingly relying on Generative AI (GAI) to support their writing—a key pedagogical practice in education. In GAI-assisted writing, students can delegate core cognitive tasks (e.g., generating ideas and turning them into sentences) to GAI while still producing high-quality essays. This creates new challenges for teachers in assessing and supporting student learning, as they often lack insight into whether students are engaging in meaningful cognitive processes during writing or how much of the essay’s quality can be attributed to those processes. This study aimed to help teachers better assess and support student learning in GAI-assisted writing by examining how different writing behaviors, especially those indicative of meaningful learning versus those that are not, impact essay quality. Using a dataset of 1,445 GAI-assisted writing sessions, we applied the cutting-edge method, X-Learner, to quantify the causal impact of three GAI-assisted writing behavioral patterns (i.e., seeking suggestions but not accepting them, seeking suggestions and accepting them as they are, and seeking suggestions and accepting them with modification) on four measures of essay quality (i.e., lexical sophistication, syntactic complexity, text cohesion, and linguistic bias). Our analysis showed that writers who frequently modified GAI-generated text—suggesting active engagement in higher-order cognitive processes—consistently improved the quality of their essays in terms of lexical sophistication, syntactic complexity, and text cohesion. In contrast, those who often accepted GAI-generated text without changes, primarily engaging in lower-order processes, saw a decrease in essay quality. Additionally, while human writers tend to introduce linguistic bias when writing independently, incorporating GAI-generated text—even without modification—can help mitigate this bias.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {568–578},
numpages = {11},
keywords = {GAI-assisted Writing, Causal Inference, Writing Quality, Linguistic Bias},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3593013.3593981,
author = {Solaiman, Irene},
title = {The Gradient of Generative AI Release: Methods and Considerations},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3593981},
doi = {10.1145/3593013.3593981},
abstract = {As increasingly powerful generative AI systems are developed, the release method greatly varies. We propose a framework to assess six levels of access to generative AI systems: fully closed; gradual or staged access; hosted access; cloud-based or API access; downloadable access; and fully open. Each level, from fully closed to fully open, can be viewed as an option along a gradient. We outline key considerations across this gradient: release methods come with tradeoffs, especially around the tension between concentrating power and mitigating risks. Diverse and multidisciplinary perspectives are needed to examine and mitigate risk in generative AI systems from conception to deployment. We show trends in generative system release over time, noting closedness among large companies for powerful systems and openness among organizations founded on principles of openness. We also enumerate safety controls and guardrails for generative systems and necessary investments to improve future releases.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {111–122},
numpages = {12},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

@inproceedings{10.1145/3633083.3633094,
author = {Marassi, Lidia},
title = {Assessing User Perceptions of Bias in Generative AI Models: Promoting Social Awareness for Trustworthy AI},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633094},
doi = {10.1145/3633083.3633094},
abstract = {Recently, generative Artificial Intelligence (AI) models have experienced an incredible surge in interest and use. The proliferation of these technologies suggests that it would be prudent to raise awareness of the potential consequences of irresponsible use of these models. Indeed, to achieve trustworthy AI solutions, it is essential to promote AI education as a fundamental step. Educating people to use AI responsibly not only improves their understanding of the technology, but also equips them to address issues of bias and discrimination. Indeed, informed users are more likely to recognize when AI is producing biased or discriminatory results and to demand appropriate solutions. This awareness of the ethical implications of AI decisions is crucial for the responsible and socially conscious adoption of AI. The aim of this poster is to report the results obtained as a final thesis work, pursued within the context of the Human-Centred AI Masters (HCAIM) programme in Naples, focused on the analysis of users’ perceptions of biases in media created by generative AI models.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {46},
numpages = {1},
keywords = {AI Ethics, Bias, Generative AI, Social Awareness, Trustworthy AI},
location = {Dublin, Ireland},
series = {HCAIep '23}
}

@article{10.1145/3656588,
author = {Guridi, Jose A. and Cheyre, Cristobal and Goula, Maria and Santo, Duarte and Humphreys, Lee and Souras, Achilleas and Shankar, Aishwarya},
title = {Image Generative AI to Design Public Spaces: a Reflection of How AI Could Improve Co-Design of Public Parks},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
url = {https://doi.org/10.1145/3656588},
doi = {10.1145/3656588},
abstract = {Image generative AI (IGAI) could change how policymakers engage with the public to design public spaces, facilitating how designers translate the public’s desires into features. However, using IGAI has challenges, such as encoded biases, which might reinforce stereotypes and harm underrepresented communities. We conducted a case study to explore how using IGAI alters the co-design process of public parks through public engagement. We use data collected from interviews with immigrants discussing the Puente Hills Landfill Park design in Los Angeles, which will re-purpose a former landfill into a new public park. We use Dream Studio as a Design Probe, generating images from the interviewees’ insights and critically reflecting on the design process through internal interviews and a reflective workshop. We analyze our case in three domains: Opportunities, Risks and Challenges, and Features and Requirements. In the opportunities domain, we discuss how the enhanced translation of words to images changes the relationship between stakeholder engagement, multiplicity, and efficiency. In the risks and challenges domain, we discuss how IGAI might enhance power imbalances and biases. Finally, we reflect on what features would ease the safe and responsible use of IGAI to engage citizens in co-designing public parks.},
journal = {Digit. Gov.: Res. Pract.},
month = feb,
articleno = {7},
numpages = {14},
keywords = {Image-generative AI, landscape architecture, design, public spaces}
}

@inproceedings{10.1145/3616855.3635737,
author = {Roychowdhury, Sohini},
title = {Journey of Hallucination-minimized Generative AI Solutions for Financial Decision Makers},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635737},
doi = {10.1145/3616855.3635737},
abstract = {Generative AI has significantly reduced the entry barrier to the domain of AI owing to the ease of use and core capabilities of automation, translation, and intelligent actions in our day to day lives. Currently, Large language models (LLMs) that power such chatbots are being utilized primarily for their automation capabilities on a limited scope. One major limitation of the currently evolving family of LLMs is hallucinations, wherein inaccurate responses are reported as factual. Hallucinations are primarily caused by biased training data, ambiguous prompts and inaccurate LLM parameters, and they majorly occur while combining mathematical facts with language-based context. In this work we present the three major stages in the journey of designing hallucination-minimized LLM-based solutions that are specialized for the decision makers of the financial domain, namely: prototyping, scaling and LLM evolution using human feedback. These three stages and the novel data to answer generation modules presented in this work are necessary to ensure that the Generative AI products are reliable and high-quality to aid key decision-making processes.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {1180–1181},
numpages = {2},
keywords = {hallucinations, llmops, llms, prompt engineering},
location = {Merida, Mexico},
series = {WSDM '24}
}

@article{10.1145/3722449.3722466,
author = {Shah, Chirag and White, Ryen W.},
title = {Report on the 2nd Workshop on Task-Focused IR in the Era of Generative AI},
year = {2025},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {58},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3722449.3722466},
doi = {10.1145/3722449.3722466},
abstract = {Generative Artificial Intelligence (GenAI) is revolutionizing how people access information and how they tackle and complete complex information tasks. This report is a summary of a recent workshop at Microsoft on this important and pressing topic. The event brought together a diverse mix of attendees from different professions and at different career stages for an engaging day of presentations and discussions. The emergent themes are described in detail in this summary.Date: 27 September 2024.Website: https://ir-ai.github.io.},
journal = {SIGIR Forum},
month = mar,
pages = {1–7},
numpages = {7}
}

@inproceedings{10.1145/3665463.3678792,
author = {Gao, Fengsen and Fang, Ke and Chan, Wai Kin (Victor)},
title = {Humanizing Artifacts: An Educational Game For Cultural Heritage Artifacts and History Using Generative AI},
year = {2024},
isbn = {9798400706929},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665463.3678792},
doi = {10.1145/3665463.3678792},
abstract = {Artifacts are vivid carriers of history and culture. Current applications of cultural heritage (CH) education present knowledge from a third-person perspective, potentially overlooking the emotional connection between users and artifacts. This paper introduces the concept of "Knowledge Actor", which humanizes artifacts, making them natural first-person narrators of knowledge. For instance, in the game, the glazed porcelain artifact is humanized as a boy. Players evoke his memories and advance the game using key information. To gather key information, players talk with ores to solve the creation puzzle or to the map to get location details, simultaneously deducing, acquiring, and memorizing knowledge. The humanized design and generative AI capabilities seamlessly integrate puzzle-solving gameplay with educational objectives. Experimental results indicate this game design fosters emotional connections between users and artifacts, enhances learning outcomes, and improves the game experience. This paper explores new directions of humanized design and generative AI in CH education.},
booktitle = {Companion Proceedings of the 2024 Annual Symposium on Computer-Human Interaction in Play},
pages = {91–96},
numpages = {6},
keywords = {artifact, cultural heritage, education, game design, humanized design},
location = {Tampere, Finland},
series = {CHI PLAY Companion '24}
}

@inproceedings{10.1145/3704289.3704296,
author = {Almadhoob, Ali Husain and Saleh, Akbar Sayed Kadhem and Akbar, Fatema},
title = {QuizWiz: Integrating Generative Artificial Intelligence in an Online Study Tool},
year = {2025},
isbn = {9798400716980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704289.3704296},
doi = {10.1145/3704289.3704296},
abstract = {The recent emergence of Generative Artificial Intelligence (GenAI) tools, such as ChatGPT, has introduced revolutionary capabilities that are predicted to transform numerous facets of society. For students, the advent of GenAI has the potential to profoundly alter studying and learning practices. This paper presents the development of QuizWiz: a web application that provides innovative study tools integrating GenAI. QuizWiz includes two GenAI features, (1) generating study flashcards with questions and answers from uploaded study material and (2) answering study questions with an intelligent chatbot. We detail the technical aspects of developing tools that integrate GenAI, as well as provide recommendations for developers and academics interested in the use of GenAI for students.},
booktitle = {Proceedings of the 2024 7th International Conference on Big Data and Education},
pages = {87–96},
numpages = {10},
keywords = {Chatbot, Educational Technology, Generative AI, LLMs, Learning Technologies, flashcards},
location = {
},
series = {ICBDE '24}
}

@inproceedings{10.1145/3636555.3636879,
author = {Garg, Ryan and Han, Jaeyoung and Cheng, Yixin and Fang, Zheng and Swiecki, Zachari},
title = {Automated Discourse Analysis via Generative Artificial Intelligence},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636879},
doi = {10.1145/3636555.3636879},
abstract = {Coding discourse data is critical to many learning analytics studies. To code their data, researchers may use manual techniques, automated techniques, or a combination thereof. Manual coding can be time-consuming and error prone; automated coding can be difficult to implement for non-technical users. Generative artificial intelligence (GAI) offers a user friendly alternative to automated discourse coding via prompting and APIs. We assessed the ability of GAI, specifically the GPT class of models, at automatically coding discourse in the context of a learning analytics study using a variety of prompting and training strategies. We found that fine-tuning approaches produced the best results; however, no results achieved standard thresholds for reliability in our field.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {814–820},
numpages = {7},
keywords = {Automated Discourse Coding, Generative Artificial Intelligence},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.14236/ewic/BCSHCI2023.11,
author = {Espinoza, Fernanda and Cook, Darren and Butler, Chris R. and Calvo, Rafael A.},
title = {Supporting dementia caregivers in Peru through chatbots: generative AI vs structured conversations.},
year = {2024},
isbn = {1234567891011},
publisher = {BCS Learning &amp; Development Ltd},
address = {Swindon, GBR},
url = {https://doi.org/10.14236/ewic/BCSHCI2023.11},
doi = {10.14236/ewic/BCSHCI2023.11},
abstract = {In Peru, dementia caregivers face burnout, depression, stress, and financial strain. Addressing their needs involves tackling the intricacies of caregiving and managing emotional burdens. Chatbots can serve as a viable support mechanism in regions with limited resources. This study delves into the perceptions of dementia caregivers in Peru regarding a chatbot tailored to offer care navigation and emotional support. We divided the study into three phases: the initial stage encompassed engaging stakeholders to define design requirements for the chatbot; the second stage focused on the creation of ‘Ana’, a chatbot for dementia caregivers; and the final stage assessed the chatbot through interviews and a caregiver satisfaction survey. ‘Ana’ was tested in two configurations - one employed pre-defined conversation patterns, while the other harnessed generative AI for more dynamic responses. The findings reveal that caregivers seek immediate access to information on handling behavioural symptoms and a platform for emotional release. Moreover, participants preferred the generative AI alternative of Ana, as it was perceived to be more empathic and human-like. The participants valued the generative approach despite knowing the potential risk of receiving inaccurate information.},
booktitle = {Proceedings of the 36th International BCS Human-Computer Interaction Conference},
pages = {89–98},
numpages = {10},
keywords = {Dementia, Chatbot, Conversational design, Human-centred design, Generative AI, Caregiver support, Caregiver intervention},
location = {University of York, UK},
series = {BCS HCI '23}
}

@inproceedings{10.1145/3711403.3711410,
author = {Wen, Jiacun and Lin, Yi and Si, Nian},
title = {Behavioral Analysis of Classroom Interactions Supported by Generative Artificial Intelligence},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711410},
doi = {10.1145/3711403.3711410},
abstract = {Generative artificial intelligence, represented by Chatgpt, has been developing rapidly because of its superiority in form and process, covering almost all industries. In order to comply with the development of technology, some classroom teaching also incorporates it to build a generative artificial intelligence classroom. The classroom interaction behavior has an important reference value to help teachers reconstruct the teaching design and reform the teaching mode. The purpose of this paper is to derive significant behavioral sequence characteristics by coding and recording the actual video of generative artificial intelligence classrooms and analyzing the classroom interaction behaviors using lag sequence analysis. The study shows that the teacher-student interaction in the generative artificial intelligence classroom is more active, and the students' active participation in the classroom is very high, which will further promote the generative artificial intelligence classroom and realize the deep integration of the new technology and the classroom.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {49–54},
numpages = {6},
keywords = {Classroom interactive behavior, Generative artificial intelligence, lagged series analysis},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3615335.3623035,
author = {York, Eric},
title = {Evaluating ChatGPT: Generative AI in UX Design and Web Development Pedagogy},
year = {2023},
isbn = {9798400703362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615335.3623035},
doi = {10.1145/3615335.3623035},
abstract = {The advent of widely-accessible generative AI tools and their rapid adoption across industry and education is necessitating large-scale revisions to user experience design and web development pedagogies and curricula, a process that will take some time. This report describes a series of initial experiments using generative AI tools as a student or junior designer or web developer might, sometimes na\"{\i}vely and sometimes in more sophisticated ways, to complete beginner-level and advanced projects. The report evaluates how ChatGPT performs across three categories of prompts (brainstorming, design, and coding) and assesses the quality of the outputs in order to inform the research design of a larger, ongoing interdisciplinary study in its initial phases and to document the results for instructors or senior members of design and development teams to aid them in assessing the fitness of generative AI for user experience design and web development production.},
booktitle = {Proceedings of the 41st ACM International Conference on Design of Communication},
pages = {197–201},
numpages = {5},
keywords = {Artificial Intelligence, Pedagogy, User experience (UX) design, Web development},
location = {Orlando, FL, USA},
series = {SIGDOC '23}
}

@inproceedings{10.1145/3573051.3596191,
author = {Smolansky, Adele and Cram, Andrew and Raduescu, Corina and Zeivots, Sandris and Huber, Elaine and Kizilcec, Rene F.},
title = {Educator and Student Perspectives on the Impact of Generative AI on Assessments in Higher Education},
year = {2023},
isbn = {9798400700255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573051.3596191},
doi = {10.1145/3573051.3596191},
abstract = {The sudden popularity and availability of generative AI tools, such as ChatGPT that can write compelling essays on any topic, code in various programming languages, and ace standardized tests across domains, raises questions about the sustainability of traditional assessment practices. To seize this opportunity for innovation in assessment practice, we conducted a survey to understand both the educators' and students' perspectives on the issue. We measure and compare attitudes of both stakeholders across various assessment scenarios, building on an established framework for examining the quality of online assessments along six dimensions. Responses from 389 students and 36 educators across two universities indicate moderate usage of generative AI, consensus for which types of assessments are most impacted, and concerns about academic integrity. Educators prefer adapted assessments that assume AI will be used and encourage critical thinking, but students' reaction is mixed, in part due to concerns about a loss of creativity. The findings show the importance of engaging educators and students in assessment reform efforts to focus on the process of learning over its outputs, higher-order thinking, and authentic applications.},
booktitle = {Proceedings of the Tenth ACM Conference on Learning @ Scale},
pages = {378–382},
numpages = {5},
keywords = {ChatGPT, assessment, educators, generative AI, students, survey},
location = {Copenhagen, Denmark},
series = {L@S '23}
}

@inproceedings{10.1145/3675888.3676033,
author = {Pramod, Dhanya and Patil, Kanchan Pranay},
title = {Generative AI for Elderly Well-being through the Computer as Social Actor Paradigm},
year = {2024},
isbn = {9798400709722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675888.3676033},
doi = {10.1145/3675888.3676033},
abstract = {Artificial intelligence and machine learning (AI/ML) technologies like generative AI solutions are proliferating in the real-world healthcare sector. The purpose of this research is to investigate social norms, expectations, and standards of the elderly population for improving trust relationships while interacting with generative AI. The study is based on the CASA paradigm to gain a better understanding of the trust dynamics in human-computer communication to improve the adoption of GAI for elders' health and well-being. We validated the conceptual model with empirical data from 287 elderly users collected through an online and offline survey tool. Quantitative responses received were analysed using structural equation modeling. The study highlights how multimodal interaction, empathy, personalization, augmentation, bias stereotyping, and privacy and security affect the extent to which elderly consumers perceive GAI as trustworthy. Findings indicate that multimodal interaction, personalization, augmentation, and bias stereotyping significantly influenced the trust relationship between the elderly population and GAI. However, empathy privacy, and security were found to be insignificant in trust relationships. Further trust relationships significantly impacted GAI usage. The research provides strong theoretical and practical implications as all the stakeholders like healthcare professionals, patients/users, caregivers, and technology developers can be involved in building applications that cater to diverse needs and promote positive social interactions that can enhance GAI trust and usage.},
booktitle = {Proceedings of the 2024 Sixteenth International Conference on Contemporary Computing},
pages = {65–72},
numpages = {8},
location = {Noida, India},
series = {IC3-2024}
}

@inproceedings{10.1145/3649217.3653575,
author = {Smith, C. Estelle and Shiekh, Kylee and Cooreman, Hayden and Rahman, Sharfi and Zhu, Yifei and Siam, Md Kamrul and Ivanitskiy, Michael and Ahmed, Ahmed M. and Hallinan, Michael and Grisak, Alexander and Fierro, Gabe},
title = {Early Adoption of Generative Artificial Intelligence in Computing Education: Emergent Student Use Cases and Perspectives in 2023},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653575},
doi = {10.1145/3649217.3653575},
abstract = {Because of the rapid development and increasing public availability of Generative Artificial Intelligence (GenAI) models and tools, educational institutions and educators must immediately reckon with the impact of students using GenAI. There is limited prior research on computing students' use and perceptions of GenAI. In anticipation of future advances and evolutions of GenAI, we capture a snapshot of student attitudes towards and uses of yet emerging GenAI, in a period of time before university policies had reacted to these technologies. We surveyed all computer science majors in a small engineering-focused R1 university in order to: (1) capture a baseline assessment of how GenAI has been immediately adopted by aspiring computer scientists; (2) describe computing students' GenAI-related needs and concerns for their education and careers; and (3) discuss GenAI influences on CS pedagogy, curriculum, culture, and policy. We present an exploratory qualitative analysis of this data and discuss the impact of our findings on the emerging conversation around GenAI and education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {3–9},
numpages = {7},
keywords = {ai literacy, code generator, education, generative artificial intelligence, image generator, interactive tutoring, large language model, policy, student experience, survey},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@article{10.1145/3690391,
author = {Liu, Jiangfeng and Ma, Xueliang and Wang, Lanyu and Pei, Lei},
title = {How Can Generative Artificial Intelligence Techniques Facilitate Intelligent Research into Ancient Books?},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1556-4673},
url = {https://doi.org/10.1145/3690391},
doi = {10.1145/3690391},
abstract = {Generative AI changes the paradigm of natural language processing research, sets off a new trend of research in computational humanities and computational social sciences, and provides unique perspectives on digital intelligence-enabled ancient book revitalization and intelligent applications. The article explores the role of multimodal large models in image processing and OCR of ancient books. We discuss and exemplify how to use Large Language Models for intelligent information processing of ancient texts and explore combining prompt engineering, retrieval augmented generation (RAG), supervised fine-tuning, LangChain, and other techniques to improve performance in ancient text mining and applications. This article also looks forward to the broad prospect of intelligent agent technology combined with the Large Language Model in the innovative application of ancient book revitalization. The research focuses on digitizing ancient books, intelligent processing of ancient texts, and intelligent application of ancient book revitalization. It demonstrates the feasibility, advancement, and creativity of the application of generative AI and its derivative technologies in the field of computational humanities, especially in the field of ancient book preservation, to provide intelligent solutions for the dissemination of traditional thought and culture, from the perspective of the whole process of the technology of digital humanities and computational humanities research. The article also gives examples of the intelligent application of AI in the restoration of ancient books and the annotation of ancient texts. Although Large Language Models demonstrate transformative potential in advancing the field of ancient text research toward intelligent analysis, there remain certain limitations. This article points out their shortcomings in areas such as knowledge completion for ancient texts, understanding emotions and cultural nuances, as well as ethical and accountability issues. It emphasizes the need for a more balanced perspective on the role that generative AI plays in the exploration and utilization of cultural heritage.},
journal = {J. Comput. Cult. Herit.},
month = dec,
articleno = {57},
numpages = {20},
keywords = {Computational Humanities, Ancient Book Revitalization, Intelligent Information Processing of Ancient Texts, ChatGPT, Generative AI, AIGC}
}

@inproceedings{10.1145/3613904.3642480,
author = {Chen, Qing and Shuai, Wei and Zhang, Jiyao and Sun, Zhida and Cao, Nan},
title = {Beyond Numbers: Creating Analogies to Enhance Data Comprehension and Communication with Generative AI},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642480},
doi = {10.1145/3613904.3642480},
abstract = {Unfamiliar measurements usually hinder readers from grasping the scale of the numerical data, understanding the content, and feeling engaged with the context. To enhance data comprehension and communication, we leverage analogies to bridge the gap between abstract data and familiar measurements. In this work, we first conduct semi-structured interviews with design experts to identify design problems and summarize design considerations. Then, we collect an analogy dataset of 138 cases from various online sources. Based on the collected dataset, we characterize a design space for creating data analogies. Next, we build a prototype system, AnalogyMate, that automatically suggests data analogies, their corresponding design solutions, and generated visual representations powered by generative AI. The study results show the usefulness of AnalogyMate in aiding the creation process of data analogies and the effectiveness of data analogy in enhancing data comprehension and communication.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {377},
numpages = {14},
keywords = {creativity support, interview, lab study, prototyping/implementation, qualitative methods, quantitative methods},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642794,
author = {Choi, DaEun and Hong, Sumin and Park, Jeongeon and Chung, John Joon Young and Kim, Juho},
title = {CreativeConnect: Supporting Reference Recombination for Graphic Design Ideation with Generative AI},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642794},
doi = {10.1145/3613904.3642794},
abstract = {Graphic designers often get inspiration through the recombination of references. Our formative study (N=6) reveals that graphic designers focus on conceptual keywords during this process, and want support for discovering the keywords, expanding them, and exploring diverse recombination options of them, while still having room for designers’ creativity. We propose CreativeConnect, a system with generative AI pipelines that helps users discover useful elements from the reference image using keywords, recommends relevant keywords, generates diverse recombination options with user-selected keywords, and shows recombinations as sketches with text descriptions. Our user study (N=16) showed that CreativeConnect helped users discover keywords from the reference and generate multiple ideas based on them, ultimately helping users produce more design ideas with higher self-reported creativity, compared to the baseline system without generative pipelines. While CreativeConnect was shown effective in ideation, we discussed how CreativeConnect can be extended to support other types of tasks in creativity support.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1055},
numpages = {25},
keywords = {Creativity support tool, Graphic Design ideation, Machine Learning, Reference recombination},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3677892.3677941,
author = {Hu, Changping and Yang, Jie},
title = {A Bibliometric Comparison of Chinese and International Research in the Field of Generative AI},
year = {2024},
isbn = {9798400709838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677892.3677941},
doi = {10.1145/3677892.3677941},
abstract = {Rapid advancements in artificial intelligence incited a global fervor towards further AI research. Being the forefront of modern AI advancements, the current state and boundaries of generative AI research lended itself to further examination, especially the differences regarding topics and quality of research between International and Chinese academia. Through a bibliometric study examining the body of research contained within the China National Knowledge Infrastructure and Web of Science, the results suggested that Chinese academia have four areas of improvement: (1) determining the sample, (2) expanding the limits, (3) examining moral efficacy, and (4) researching foundational knowledge.},
booktitle = {Proceedings of the 2024 International Conference on Digital Society and Artificial Intelligence},
pages = {303–310},
numpages = {8},
location = {Qingdao, China},
series = {DSAI '24}
}

@inproceedings{10.1145/3652037.3663893,
author = {Bird, Jordan J. and Wright, David and Sumich, Alexander and Lotfi, Ahmad},
title = {Generative AI in Psychological Therapy: Perspectives on Computational Linguistics and Large Language Models in Written Behaviour Monitoring},
year = {2024},
isbn = {9798400717604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652037.3663893},
doi = {10.1145/3652037.3663893},
abstract = {Technological intervention to support care areas that some people may not have access to is of paramount importance to promote sustainable development of good health and wellbeing. This study aims to explore the linguistic similarities and differences between human professionals and Generative Artificial Intelligence (AI) conversational agents in therapeutic dialogues. Initially, the MISTRAL-7B Large Language Model (LLM) is instructed to generate responses to patient queries to form a synthetic equivalent to a publicly available psychology dataset. A large set of linguistic features (e.g., text metrics, lexical diversity and richness, readability scores, sentiment, emotions, and named entities) is extracted and studied from both the expert and synthetically-generated text. The results suggest a significantly richer vocabulary in humans than the LLM approach. Similarly, the use of sentiment was significantly different between the two, suggesting a difference in the supportive or objective language used and that synthetic linguistic expressions of emotion may differ from those expressed by an intelligent being. However, no statistical significance was observed between human professionals and AI in the use of function words, pronouns and several named entities; possibly reflecting an increased proficiency of LLMs in modelling some language patterns, even in a specialised context (i.e., therapy). However, current findings do not support the similarity in sentimental nuance and emotional expression, which limits the effectiveness of contemporary LLMs as standalone agents. Further development is needed towards clinically validated algorithms.},
booktitle = {Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {322–328},
numpages = {7},
keywords = {AI, Computational Linguistics, Generative Artificial Intelligence, LLMs, Large Language Models, Psychology},
location = {Crete, Greece},
series = {PETRA '24}
}

@inproceedings{10.1145/3628454.3629552,
author = {Faruk, Lawal Ibrahim Dutsinma and Rohan, Rohani and Ninrutsirikun, Unhawa and Pal, Debajyoti},
title = {University Students’ Acceptance and Usage of Generative AI (ChatGPT) from a Psycho-Technical Perspective},
year = {2023},
isbn = {9798400708497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628454.3629552},
doi = {10.1145/3628454.3629552},
abstract = {The emergence of ChatGPT as a generative AI tool has revolutionized the educational scenario by bringing in unprecedented changes. In this respect exploring the factors that affect the adoption and acceptance of ChatGPT services for educational purpose is of utmost importance. Accordingly, in this work we take a hybrid psycho-technical approach by considering the technological (perceived usefulness, ease of use and facilitating conditions), contextual (perceived humanness and novelty value), and psychological (agreeableness, extraversion, openness, conscientiousness, and neuroticism) gratifications of ChatGPT use. Data is collected from a sample of university students who use ChatGPT regularly across two Asian countries. The data analysis is done using Partial Least Squares Structural Equation Modelling. Results indicate that among the technical factors only perceived usefulness successfully predicts ChatGPT usage. Both the contextual factors of humanness and novelty use significantly explain ChatGPT usage. Finally, among the psychological factors’ openness, agreeableness, and neuroticism determine the usage scenario, however, the later two are found to be negatively associated with ChatGPT usage.},
booktitle = {Proceedings of the 13th International Conference on Advances in Information Technology},
articleno = {15},
numpages = {8},
keywords = {ChatGPT, higher education, novelty value, perceived humanness, personality},
location = {Bangkok, Thailand},
series = {IAIT '23}
}

@inproceedings{10.1145/3677045.3685493,
author = {Alshaigy, Bedour and Grande, Virginia},
title = {Forgotten Again: Addressing Accessibility Challenges of Generative AI Tools for People with Disabilities},
year = {2024},
isbn = {9798400709654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677045.3685493},
doi = {10.1145/3677045.3685493},
abstract = {This paper critically examines the persistent inequities between the rapid development of GenAI technologies and the accessibility needs of people with disabilities in a professional setting. We draw our criticism from the literature and accounts of individuals who have shared their challenges. Additionally, we critique how these tools were predominantly developed by able-bodied individuals, alongside the notable absence of design guidelines specifically tailored for the inclusivity of GenAI tools, which are relatively new innovations. As a community, we must commit to educating about accessibility and elevating the voices and experiences of people with disabilities, to ensure their needs are prioritised and addressed. This commitment will bridge the existing gap and foster a more inclusive approach to GenAI. Otherwise, the cycle of exclusion will persist.},
booktitle = {Adjunct Proceedings of the 2024 Nordic Conference on Human-Computer Interaction},
articleno = {68},
numpages = {6},
keywords = {GenAI, accessibility, disability},
location = {Uppsala, Sweden},
series = {NordiCHI '24 Adjunct}
}

@inproceedings{10.1145/3605098.3636180,
author = {Aguilar, Stephen J and Wang, Changzhao},
title = {Duty vs. Consequence: Exploring Teachers' Assessment of the Ethical Dimensions of Generative AI Technologies},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636180},
doi = {10.1145/3605098.3636180},
abstract = {This study examines how K-12 teachers (n=248) in the United States evaluated multiple ethical propositions grounded within classic philosophic distinction of deontology and consequentialism. Notably, we observed gender differences in ethical evaluations, with women scoring higher in several deontological propositions. Furthermore, teachers' attitudes significantly predicted their stances on consequentialist propositions, while self-efficacy and anxiety were related to both consequentialist and deontological perspectives.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {106–108},
numpages = {3},
keywords = {ethics, generative AI, deontology, consequentialism, teachers, pedagogy},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3672608.3707749,
author = {Kim, Jaewoong and Hur, Minseok and Min, Moohong},
title = {From RAG to QA-RAG: Integrating Generative AI for Pharmaceutical Regulatory Compliance Process},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707749},
doi = {10.1145/3672608.3707749},
abstract = {Regulatory compliance in the pharmaceutical industry involves navigating complex and voluminous guidelines, often requiring significant amounts of human resources. Recent advancements in Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) methods provide promising enhancements to data processing and knowledge management, potentially easing these burdens. However, despite these advancements, conventional Retrieval-Augmented Generation (RAG) methods fall short in this domain due to inherent structural problems. To address these challenges, we introduce the Question and Answer Retrieval Augmented Generation (QA-RAG) framework. This framework enhances the conventional RAG framework. It integrates a dual-track retrieval mechanism tailored to the specific and dynamic nature of pharmaceutical regulations. It utilizes not only the original query but also the answers generated by a fine-tuned LLM, thus providing a more robust foundation for document retrieval. Our experiments demonstrate that QA-RAG outperforms conventional methods in various evaluation metrics including precision, recall, and F1-score. These results underscore QA-RAG's capability to enhance both the accuracy and efficiency of regulatory compliance processes in the pharmaceutical industry. This paper details the structure and efficacy of QA-RAG, emphasizing its potential to revolutionize the regulatory compliance process in the pharmaceutical industry and beyond.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {1293–1295},
numpages = {3},
keywords = {retrieval-augmented generation (RAG), fine-tuning large language models (LLMs), information retrieval effectiveness, pharmaceutical regulatory compliance},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3657604.3664694,
author = {Calo, Tommaso and Maclellan, Christopher},
title = {Towards Educator-Driven Tutor Authoring: Generative AI Approaches for Creating Intelligent Tutor Interfaces},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664694},
doi = {10.1145/3657604.3664694},
abstract = {Intelligent Tutoring Systems (ITSs) have shown great potential in delivering personalized and adaptive education, but their widespread adoption has been hindered by the need for specialized programming and design skills. Existing approaches overcome the programming limitations with no-code authoring through drag and drop, however they assume that educators possess the necessary skills to design effective and engaging tutor interfaces. To address this assumption we introduce generative AI capabilities to assist educators in creating tutor interfaces that meet their needs while adhering to design principles. Our approach leverages Large Language Models (LLMs) and prompt engineering to generate tutor layout and contents based on high-level requirements provided by educators as inputs. However, to allow them to actively participate in the design process, rather than relying entirely on AI-generated solutions, we allow generation both at the entire interface level and at the individual component level. The former provides educators with a complete interface that can be refined using direct manipulation, while the latter offers the ability to create specific elements to be added to the tutor interface. A small-scale comparison shows the potential of our approach to enhance the efficiency of tutor interface design. Moving forward, we raise critical questions for assisting educators with generative AI capabilities to create personalized, effective, and engaging tutors, ultimately enhancing their adoption.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {305–309},
numpages = {5},
keywords = {human-centered computing, intelligent tutoring systems, intelligent-user-interfaces, ui/ux},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3702163.3702165,
author = {Gong, Rushi and Jiang, Rui and Guo, Chuanlei and Hu, Wanqing and Li, Yanyan},
title = {Roles emerging during the knowledge construction process in collaborative learning: Does a generative AI-support chatbot matter?},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702165},
doi = {10.1145/3702163.3702165},
abstract = {Students’ emerging roles in computer supported collaborative learning (CSCL) are crucial in revealing what learning characteristics and states students present during their collaborative knowledge construction. Previous researchers have unveiled the fact that pedagogical scaffoldings such as AI chatbots play a pivotal role in students’ role emerging, but with the prevalence of generative AI (GAI), there is also an urgent need to investigate whether GAI chatbots influence students’ emerging roles during the knowledge construction process in collaborative learning. Therefore, this study conducted a quasi-experiment, using an integration of cluster analysis, chi-square test, case analysis, and content analysis to investigate whether and how a GAI chatbot affected students’ emerging roles in their online collaborative knowledge construction. Results demonstrated statistical significance that the GAI chatbot and the traditional static scripts did not have a distinct difference in students’ emerging roles. However, qualitative data showed that the GAI chatbot had an impact on the allocation of roles and that there were perceptual differences in how students with the same roles experienced the writing process and collaborative atmosphere under different support conditions. The study will provide insights into how GAI chatbots can be adapted for future development and application in a collaborative learning context with consideration of students’ roles.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {8–16},
numpages = {9},
keywords = {Computer Supported Collaborative Learning, Generative AI Chatbot, Knowledge Construction, Students’ Roles},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3726010.3726089,
author = {Zhou, Zhixin and Han, Junwei and Li, Bo},
title = {Research and Analysis on the Application of Generative Artificial Intelligence Technology in Product Design},
year = {2025},
isbn = {9798400712845},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726010.3726089},
doi = {10.1145/3726010.3726089},
abstract = {This paper systematically reviews and summarizes the current application status of Generative Artificial Intelligence in product design. This paper analyzes and sorts out the basic concept, research status, application scenarios through literature analysis, and design practice. It discusses the potential applications, problems, and challenges of it in product design and prospects for the future. Based on this, through the research, a conclusion has been drawn that the research of Generative AI is in its infancy in the field of product design. Generative AI is very advantageous in shortening the design cycle, improving design efficiency, and saving time and cost. At the same time, it also has certain application potential for designers in designing, product development, and enhancing user experience. However, there are many challenges that must also be faced, including technical limitations, ethical dilemmas, and legal problems. Therefore, how to properly cope with the current challenges and effectively integrate Generative AI into the existing design process has become an important issue at present.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence, Digital Media Technology and Interaction Design},
pages = {501–507},
numpages = {7},
keywords = {Content Generation, Design Science, Generative Artificial Intelligence (AIGC), Product Design},
location = {
},
series = {ICADI '24}
}

@inproceedings{10.1145/3605098.3636055,
author = {Taiye, Mohammed and High, Christopher and Velander, Johanna and Matar, Khaled and Okmanis, Rihards and Milrad, Marcelo},
title = {Generative AI-Enhanced Academic Writing: A Stakeholder-Centric Approach for the Design and Development of CHAT4ISP-AI},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636055},
doi = {10.1145/3605098.3636055},
abstract = {This study examines the impact of Generative AI (GenAI) chatbots on improving students' academic writing and critical thinking skills. It addresses ethical and operational challenges, including concerns about academic integrity within AI in education (AIEd). Our study aims to analyze perspectives from a diverse array of stakeholders to inform the creation of effective GenAI chatbots. The insights gained will guide the development of comprehensive AI literacy and robust regulatory frameworks, ensuring that these advancements are both ethically sound and practically viable. The primary focus of the study is to understand stakeholders' expectations of GenAI in academic writing, leading to the development of CHAT4ISP-AI, a specialized chatbot aimed at improving the academic writing, analytical, and critical reasoning skills of first-year undergraduate social science students. This study promotes a contemporary educational approach by fostering collaboration among teachers, students, and other stakeholders, significantly advancing the integration of AI into the educational system, and thus preparing students for an AI-driven future.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {74–80},
numpages = {7},
keywords = {generative AI (GenAI), AI literacy, academic writing, soft systems methodology (SSM), stakeholder},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3706598.3713778,
author = {Lee, Hao-Ping (Hank) and Sarkar, Advait and Tankelevitch, Lev and Drosos, Ian and Rintel, Sean and Banks, Richard and Wilson, Nicholas},
title = {The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713778},
doi = {10.1145/3706598.3713778},
abstract = {The rise of Generative AI (GenAI) in knowledge workflows raises questions about its impact on critical thinking skills and practices. We survey 319 knowledge workers to investigate 1) when and how they perceive the enaction of critical thinking when using GenAI, and 2) when and why GenAI affects their effort to do so. Participants shared 936 first-hand examples of using GenAI in work tasks. Quantitatively, when considering both task- and user-specific factors, a user’s task-specific self-confidence and confidence in GenAI are predictive of whether critical thinking is enacted and the effort of doing so in GenAI-assisted tasks. Specifically, higher confidence in GenAI is associated with less critical thinking, while higher self-confidence is associated with more critical thinking. Qualitatively, GenAI shifts the nature of critical thinking toward information verification, response integration, and task stewardship. Our insights reveal new design challenges and opportunities for developing GenAI tools for knowledge work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1121},
numpages = {22},
keywords = {Critical thinking, Generative AI tools, Knowledge worker, Bloom’s taxonomy, Survey},
location = {
},
series = {CHI '25}
}

@article{10.5555/3637036.3637049,
author = {Mehta, Jean and Becker, Brett A. and Hsin, Wen-Jung and Hummel, Joe and Kerney, Bill and Krupp, Brian},
title = {The Influence of Generative AI on Pedagogy and Assessment in Computing Education},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {4},
issn = {1937-4771},
abstract = {Student access to Generative AI tools stands to alter the way we teach as well as the way we assess our student's learning. ChatGPT has only been available for a few months, but already instructors are concerned about its wide use and implications. Love it? Hate it? Embed it in your course? Ban its use? Will this change not just how we teach but what we teach, when we teach it and even who we teach? Most of us have been wrestling with these questions, and more. Panelists will speak of how they altered their pedagogy, and the results, in both in-person and online courses.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {99},
numpages = {1}
}

@inproceedings{10.1145/3711403.3711454,
author = {Sai, Naolamu},
title = {Research on the Status Quo of Rural Teaching Based on Generative Artificial Intelligence},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711454},
doi = {10.1145/3711403.3711454},
abstract = {In the field of education, generative artificial intelligence is gradually becoming a key force to promote educational innovation and intelligent development. This technology simulates the process of human creation, generates innovative and practical teaching content, and provides a strong technical support for personalized teaching. For rural education with relatively scarce resources, the application of generative artificial intelligence is expected to solve the problem of educational inequity and improve the quality of teaching. However, rural education still faces many challenges, such as resource shortage and information block, which limit the effective application of generative artificial intelligence in rural education. This study deeply analyzes the application status and advantages of generative artificial intelligence in rural teaching, reveals the main problems and difficulties encountered by rural teachers in the process of use, and puts forward targeted solutions, in order to promote the optimal application of generative artificial intelligence in rural education and promote the development of rural education in a fairer and smarter direction.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {309–314},
numpages = {6},
keywords = {Generative artificial intelligence, Rural education, Teaching optimization strategy},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3704217.3704224,
author = {Qi, Linyi and Zhu, Jiangqin},
title = {Visualizing Research Trends on the Use of Generative AI in Assessment in the WOS database from 2019 to 2024 via Vosviewer and CiteSpace},
year = {2025},
isbn = {9798400707094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704217.3704224},
doi = {10.1145/3704217.3704224},
abstract = {The first typical generative Artificial Intelligence (Gen AI) model ChatGpt 1 was introduced in 2018, but has not drawn much attention until the release of ChatGpt 3 in 2022. Since then, researchers and educators have been experimenting with Gen AI tools to explore their possibilities in various fields. In education, the use of Gen AI in assessment is a research focus. To reveal the research patterns in this field, the study employed Vosviewer and CiteSpace to analyze 816 papers in the Web of Science (WOS) database published between 2019 and 2024. The annual publications surged during the period of 2023-2024 due to the release of higher versions of Gen AI tools such as ChatGpt 3. Researchers in the United States, United Kingdom and China engage most actively in the field. American and Hong Kong universities are particularly productive. However, the collaboration between institutions and authors still needs to be enhanced. Highly influential journals such as Nature and famous medical journals such as JMIR Medical Education and Cureus Journal of Medical sciences are most frequently cited. The analysis of co-occurrence keywords and keyword clusters identified two research areas: responding to the academic integrity issue with the use of Gen AI in assessment and exploring the valuable use of Gen AI in assessments in higher education especially medical education. Future research could explore the design of innovative or alternative assessments and the use of Gen AI tools in interactive and game-based assessment creation, marking and feedback giving.},
booktitle = {Proceedings of the 2024 8th International Conference on E-Society, E-Education and E-Technology},
pages = {28–35},
numpages = {8},
keywords = {Academic integrity, Assessment, Education, Generative AI},
location = {
},
series = {ESET '24}
}

@inproceedings{10.1145/3609395.3610594,
author = {Zhang, Xuechen and Li, Zheng and Oymak, Samet and Chen, Jiasi},
title = {Text-to-3D Generative AI on Mobile Devices: Measurements and Optimizations},
year = {2023},
isbn = {9798400703034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609395.3610594},
doi = {10.1145/3609395.3610594},
abstract = {Emerging generative models can create 3D objects from text prompts. However, deploying these models on mobile devices is challenging due to resource constraints and user demand for real-time performance. We take a first step towards understanding the bottlenecks by performing a measurement study of three recent text-to-3D generative models (Point-E, Shap-E, and CLIP-Mesh) in terms of their runtime GPU memory usage, latency, and synthesis quality. We investigate the effectiveness of quantization and distillation techniques to overcome these challenges by speeding up inference execution, potentially at the expense of quality. We find that the Shap-E model is promising for mobile deployment, but requires further optimization in its bottleneck diffusion step for real-time performance, as well as reduced memory usage and load times. Further work is needed on custom optimizations for generative text-to-3D models, including targeting specific metrics at each computation stage, efficient representations of 3D objects, and adaptive network and system support for resource-hungry models.},
booktitle = {Proceedings of the 2023 Workshop on Emerging Multimedia Systems},
pages = {8–14},
numpages = {7},
keywords = {text-to-3D, generative AI, mobile devices, latency, GPU memory},
location = {New York, NY, USA},
series = {EMS '23}
}

@inbook{10.5555/3716662.3716743,
author = {Luna, Jose and Tan, Ivan and Xie, Xiaofei and Jiang, Lingxiao},
title = {Navigating Governance Paradigms: A Cross-Regional Comparative Study of Generative AI Governance Processes &amp; Principles},
year = {2025},
publisher = {AAAI Press},
abstract = {As Generative Artificial Intelligence (GenAI) technologies evolve at an unprecedented rate, global governance approaches struggle to keep pace with the technology, highlighting a critical issue in the governance adaptation of significant challenges. Depicting the nuances of nascent and diverse governance approaches based on risks, rules, outcomes, principles, or a mix, across different regions around the globe, is fundamental to discern discrepancies and convergences, and to shed light on specific limitations that need to be addressed, thereby facilitating the safe and trustworthy adoption of GenAI. In response to the need and the evolving nature of GenAI, this paper seeks to provide a collective view of different governance approaches around the world. Our research introduces a Harmonized GenAI Framework, "H-GenAIGF", based on the current governance approaches of six regions: (European Union (EU), United States (US), China (CN), Canada (CA), United Kingdom (UK), and Singapore (SG)). We have identified four constituents, fifteen processes, twenty-five sub-processes, and nine principles that aid the governance of GenAI, thus providing a comprehensive perspective on the current state of GenAI governance. In addition, we present a comparative analysis to facilitate identification of common ground and distinctions based on coverage of the processes by each region. The results show that risk-based approaches allow for better coverage of the processes, followed by mixed approaches. Other approaches lag behind, covering less than 50% of the processes. Most prominently, the analysis demonstrates that amongst the regions, only one process aligns across all approaches, highlighting the lack of consistent and executable provisions. Moreover, our case study on ChatGPT reveals process coverage deficiency, showing that harmonization of approaches is necessary to find alignment for GenAI governance.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {917–931},
numpages = {15}
}

@article{10.1145/3677082,
author = {Panchanadikar, Ruchi and Freeman, Guo},
title = {"I'm a Solo Developer but AI is My New Ill-Informed Co-Worker": Envisioning and Designing Generative AI to Support Indie Game Development},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CHI PLAY},
url = {https://doi.org/10.1145/3677082},
doi = {10.1145/3677082},
abstract = {Indie game developers are often defined as game developers who are typically not employed by or affiliated with tech giants or large gaming companies/publishers. Although people may decide to "go indie" for various purposes, indie game development has become a crucial part of the global gaming culture. However, this community is now facing unprecedented tensions as generative AI technologies are shifting how games can be designed, produced, and experienced. Through a qualitative analysis of 3,091 online posts and comments from subreddits and Facebook groups for indie game developers, we offer an in-depth investigation of how indie game developers perceive and envision the multifaceted role of generative AI in their creative practices. Our empirical investigation reveals that generative AI both promotes and harms indie game developers' endeavors to innovate the traditional game production model, which further influences the nature and workflow of creativity in game development. We also propose three principles for designing future generative AI technologies to improve indie developers' work while mitigating potential risks, harm, and negative impacts of AI. We hope that this study can help design and develop future generative AI technologies to foster and sustain more democratic and inclusive practices in game development rather than replacing human creators.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {317},
numpages = {26},
keywords = {creativity, game development, generative AI, indie game development}
}

@inproceedings{10.1145/3613904.3642114,
author = {Li, Jie and Cao, Hancheng and Lin, Laura and Hou, Youyang and Zhu, Ruihao and El Ali, Abdallah},
title = {User Experience Design Professionals’ Perceptions of Generative Artificial Intelligence},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642114},
doi = {10.1145/3613904.3642114},
abstract = {Among creative professionals, Generative Artificial Intelligence (GenAI) has sparked excitement over its capabilities and fear over unanticipated consequences. How does GenAI impact User Experience Design (UXD) practice, and are fears warranted? We interviewed 20 UX Designers, with diverse experience and across companies (startups to large enterprises). We probed them to characterize their practices, and sample their attitudes, concerns, and expectations. We found that experienced designers are confident in their originality, creativity, and empathic skills, and find GenAI’s role as assistive. They emphasized the unique human factors of “enjoyment” and “agency”, where humans remain the arbiters of “AI alignment’’. However, skill degradation, job replacement, and creativity exhaustion can adversely impact junior designers. We discuss implications for human-GenAI collaboration, specifically copyright and ownership, human creativity and agency, and AI literacy and access. Through the lens of responsible and participatory AI, we contribute a deeper understanding of GenAI fears and opportunities for UXD.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {381},
numpages = {18},
keywords = {Generative AI, Human-AI Collaboration, Responsible AI, UX Designers, User Experience},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3686852.3687066,
author = {Glantz, Edward J. and Peca, Joanne C. and Nasereddin, Mahdi and Stager, Sarah J. and Bartolacci, Michael R.},
title = {Beyond the Code: The Role of Non-Traditional Sectors in Shaping Generative AI Innovations and Transforming Global Industries},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3687066},
doi = {10.1145/3686852.3687066},
abstract = {This paper examines the role of non-traditional sectors in integrating and advancing Generative Artificial Intelligence (GenAI) across diverse industries, extending beyond the traditional boundaries of the technology sector. Non-traditional sector players in GenAI have recently enabled a foothold in both industry and education to rapidly expand. With a focus on healthcare, agriculture, education, and finance, we highlight case studies that demonstrate the innovative applications of GenAI, illustrating its capability to drive significant industry transformations. Through this exploration, the paper emphasizes the crucial role of interdisciplinary collaboration in catalyzing technological progress and broadening the impact of GenAI. By providing a comprehensive analysis of the current and potential future states of GenAI applications, this research aims to deepen understanding of its broader societal and economic implications. This study not only captures GenAI's transformative potential but also addresses the dual narrative of GenAI as both a promising tool, particularly for education, and a formidable challenge, underscoring its growing influence in non-traditional sectors.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {1–6},
numpages = {6},
keywords = {AI implementation, AI in education, Generative artificial intelligence (AI), Interdisciplinary innovation},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3636555.3636850,
author = {Hutt, Stephen and DePiro, Allison and Wang, Joann and Rhodes, Sam and Baker, Ryan S and Hieb, Grayson and Sethuraman, Sheela and Ocumpaugh, Jaclyn and Mills, Caitlin},
title = {Feedback on Feedback: Comparing Classic Natural Language Processing and Generative AI to Evaluate Peer Feedback},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636850},
doi = {10.1145/3636555.3636850},
abstract = {Peer feedback can be a powerful tool as it presents learning opportunities for both the learner receiving feedback as well as the learner providing feedback. Despite its utility, it can be difficult to implement effectively, particularly for younger learners, who are often novices at providing feedback. It can be difficult for students to learn what constitutes “good” feedback – particularly in open-ended problem-solving contexts. To address this gap, we investigate both classical natural language processing techniques and large language models, specifically ChatGPT, as potential approaches to devise an automated detector of feedback quality (including both student progress towards goals and next steps needed). Our findings indicate that the classical detectors are highly accurate and, through feature analysis, we elucidate the pivotal elements influencing its decision process. We find that ChatGPT is less accurate than classical NLP but illustrate the potential of ChatGPT in evaluating feedback, by generating explanations for ratings, along with scores. We discuss how the detector can be used for automated feedback evaluation and to better scaffold peer feedback for younger learners.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {55–65},
numpages = {11},
keywords = {Generative AI, Language Analytics, Large Language Models, Natural Language Processing, Peer Feedback},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3706599.3720142,
author = {Ghosh, Pratik and Rintel, Sean},
title = {YES AND: A Generative AI Multi-Agent Framework for Enhancing Diversity of Thought in Individual Ideation for Problem-Solving Through Confidence-Based Agent Turn-Taking},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720142},
doi = {10.1145/3706599.3720142},
abstract = {Diversity of thought is crucial in ideation for problem-solving, yet professionals in organisational settings often face challenges such as limited access to varied expertise and resource constraints which hinder the ideation process. To address this issue, we propose YES AND, a Generative AI based multi-agent framework that simulates diverse perspectives through AI agents for ideation with a single user. Leveraging a unique confidence-based turn-taking model, these agents organically take turns as they build on ideas, pose clarification questions to the user for improved contextual understanding, and allow the user to interject and steer the conversation. Beyond addressing the limitations of traditional ideation, this framework offers a novel approach to leveraging Generative AI for ideation, moving away from the rigidity of pre-defined interaction rules towards a more dynamic and creative process that enables serendipitous development of ideas.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {607},
numpages = {13},
keywords = {individual problem solving, diversity of thought, Generative AI, agents, expertise, role-based personas, conversational turn-taking, design improv},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706598.3713348,
author = {Shi, Jingyu and Jain, Rahul and Chi, Seunggeun and Doh, Hyungjun and Chi, Hyung-gun and Quinn, Alexander J. and Ramani, Karthik},
title = {CARING-AI: Towards Authoring Context-aware Augmented Reality INstruction through Generative Artificial Intelligence},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713348},
doi = {10.1145/3706598.3713348},
abstract = {Context-aware AR instruction enables adaptive and in-situ learning experiences. However, hardware limitations and expertise requirements constrain the creation of such instructions. With recent developments in Generative Artificial Intelligence (Gen-AI), current research tries to tackle these constraints by deploying AI-generated content (AIGC) in AR applications. However, our preliminary study with six AR practitioners revealed that the current AIGC lacks contextual information to adapt to varying application scenarios and is therefore limited in authoring. To utilize the strong generative power of GenAI to ease the authoring of AR instruction while capturing the context, we developed CARING-AI, an AR system to author context-aware humanoid-avatar-based instructions with GenAI. By navigating in the environment, users naturally provide contextual information to generate humanoid-avatar animation as AR instructions that blend in the context spatially and temporally. We showcased three application scenarios of CARING-AI: Asynchronous Instructions, Remote Instructions, and Ad Hoc Instructions based on a design space of AIGC in AR Instructions. With two user studies (N=12), we assessed the system usability of CARING-AI and demonstrated the easiness and effectiveness of authoring with Gen-AI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {29},
numpages = {23},
keywords = {Augmented Reality, Generative Artificial Intelligence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3686852.3687075,
author = {Beaton, Catherine and Weeden, Elissa and Zilora, Stephen},
title = {Instructional Approaches Complementing the Use of Generative Artificial Intelligence in Higher Education},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3687075},
doi = {10.1145/3686852.3687075},
abstract = {The explosion of generative artificial intelligence (AI) has created a level of chaos in higher education as both students and faculty try to determine its utility and how best to incorporate it into the learning process. Students may view generative AI as a means to an end of achieving a perfect grade, skipping important elements of the learning process, or they may view it as an opportunity to expand their creative efforts. Faculty may view it as a tool students use to circumvent plagiarism detection, may feel it potentially minimizes the role of faculty in the classroom, or they may view it as an opportunity to avail of a supplement to existing activities and assignments. Ultimately, faculty are faced with maintaining academic integrity and reinforcing the need and importance of the learning process. This paper explores the combination of three approaches: peer-supported incremental learning, master/apprentice model, and growth mindset as a way for faculty to guide appropriate student use of generative AI, while also maintaining the integrity of the learning process.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {62–67},
numpages = {6},
keywords = {Artificial intelligence, Growth mindset, Master/Apprentice model, Peer-supported incremental learning},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3708036.3708151,
author = {Yan, Erkai and Gao, Mengxiao and Tang, Mei},
title = {Analysis and Research on Generative Artificial Intelligence in the Field of International Library and Information Science},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708151},
doi = {10.1145/3708036.3708151},
abstract = {Generative artificial intelligence is an artificial intelligence technology based on deep learning whose core lies in leveraging computer algorithms and training data to generate new, practically valuable content, encompassing text, images, audio, videos, etc. This technology is poised to exert profound impacts on the transformation and development of libraries. Drawing on generative artificial intelligence research publications in the field of international library and information science included in the Scopus database as the data source, this paper employs CiteSpace software and SciVal tools to conduct a visual analysis of literature outputs, core authors, journal sources, and keywords. The results show that generative artificial intelligence research in the international library and information science field is applied primarily in areas such as reference services, information literacy education, and smart libraries. Recommendations are made to promote the application and development of generative artificial intelligence technology in libraries by strengthening technological research and application, boosting data analysis and data sharing, emphasizing information security and privacy protection, promoting cross-boundary integration and ecological development, etc.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {679–686},
numpages = {8},
keywords = {ChatGPT, Generative artificial intelligence, library},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3706598.3713289,
author = {Zhang, Zheng and Peng, Weirui and Chen, Xinyue and Cao, Luke and Li, Toby Jia-Jun},
title = {LADICA: A Large Shared Display Interface for Generative AI Cognitive Assistance in Co-located Team Collaboration},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713289},
doi = {10.1145/3706598.3713289},
abstract = {Large shared displays, such as digital whiteboards, are useful for supporting co-located team collaborations by helping members perform cognitive tasks such as brainstorming, organizing ideas, and making comparisons. While recent advancement in Large Language Models (LLMs) has catalyzed AI support for these displays, most existing systems either only offer limited capabilities or diminish human control, neglecting the potential benefits of natural group dynamics. Our formative study identified cognitive challenges teams encounter, such as diverse ideation, knowledge sharing, mutual awareness, idea organization, and synchronization of live discussions with the external workspace. In response, we introduce LADICA, a large shared display interface that helps collaborative teams brainstorm, organize, and analyze ideas through multiple analytical lenses, while fostering mutual awareness of ideas and concepts. Furthermore, LADICA facilitates the real-time extraction of key information from verbal discussions and identifies relevant entities. A lab study confirmed LADICA’s usability and usefulness.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {147},
numpages = {22},
keywords = {computer-mediated communication, co-located collaboration, large shared display, cognitive assistance},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3626252.3630817,
author = {Fernandez, Amanda S. and Cornell, Kimberly A.},
title = {CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630817},
doi = {10.1145/3626252.3630817},
abstract = {As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create "black box" code with significant security vulnerabilities. We outline methods for integrating basic AI knowledge and traditional software verification steps into CS1 along with LLMs, which will better prepare students for software development in professional settings.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {345–351},
numpages = {7},
keywords = {ai, artificial intelligence, code generation, copilot, cs1, gpt-4, introductory programming, large language model, llm, machine learning, novice programmers, programming, prompt engineering, secure code, software verification},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3670243.3670781,
author = {Banyasz, Peter and Szadeczky, Tamas and Vaczi, Kincso Boroka},
title = {The relationship between generative artificial intelligence and cybersecurity},
year = {2024},
isbn = {9798400717093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670243.3670781},
doi = {10.1145/3670243.3670781},
abstract = {This research paper investigates the adoption of generative artificial intelligence by citizens using the Technology Adoption Propensity (TAP) index. The study aims to explore the influence of cybersecurity factors on the acceptance of generative artificial intelligence technologies. The data for the research will be collected through a questionnaire survey that seeks to understand respondents' attitudes, expectations and concerns towards generative artificial intelligence technologies. The research will use a mixed-methods approach to analyse the data, including quantitative such as descriptive statistics, cross-tabulation analysis, cluster analysis. The expected outcomes of this study include a better understanding of the factors that influence the adoption of generative artificial intelligence technologies by citizens and the development of strategies to address any concerns that citizens may have.},
booktitle = {Proceedings of the Central and Eastern European EDem and EGov Days 2024},
pages = {209–215},
numpages = {7},
keywords = {Cybersecurity, Survey, Technology Adoption Propensity Index},
location = {Budapest, Hungary},
series = {CEEeGov '24}
}

@inproceedings{10.1145/3585088.3593867,
author = {Han, Ariel and Cai, Zhenyao},
title = {Design implications of generative AI systems for visual storytelling for young learners},
year = {2023},
isbn = {9798400701313},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585088.3593867},
doi = {10.1145/3585088.3593867},
abstract = {The study examines the design implications of leveraging generative AI tools such as ChatGPT, Stable Diffusion, Midjourney for literacy development and creative expression for children [6, 8, 18]. We sought to elicit insights on the applicability of generative AI for educational purposes from various stakeholders (i.e., parents, teachers, and AI researchers). We recruited nine participants to elicit their perspectives on designing a visual narrative app with generative AI. We examined the opportunities and limitations of the current generative AI tools. Using the implications from our evaluation, we propose AIStory, an AI-powered visual storytelling application prototype that can be used for children’s creative expression, storytelling, and literacy development.},
booktitle = {Proceedings of the 22nd Annual ACM Interaction Design and Children Conference},
pages = {470–474},
numpages = {5},
keywords = {AI for education, AI literacy, Creativity, Storytelling},
location = {Chicago, IL, USA},
series = {IDC '23}
}

@inproceedings{10.1145/3643834.3660720,
author = {Takaffoli, Macy and Li, Sijia and M\"{a}kel\"{a}, Ville},
title = {Generative AI in User Experience Design and Research: How Do UX Practitioners, Teams, and Companies Use GenAI in Industry?},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3660720},
doi = {10.1145/3643834.3660720},
abstract = {User Experience (UX) practitioners, like UX designers and researchers, have begun to adopt Generative Artificial Intelligence (GenAI) tools into their work practices. However, we lack an understanding of how UX practitioners, UX teams, and companies actually utilize GenAI and what challenges they face. We conducted interviews with 24 UX practitioners from multiple companies and countries, with varying roles and seniority. Our findings include: 1) There is a significant lack of GenAI company policies, with companies informally advising caution or leaving the responsibility to individual employees; 2) UX teams lack team-wide GenAI practices. UX practitioners typically use GenAI individually, favoring writing-based tasks, but note limitations for design-focused activities, like wireframing and prototyping; 3) UX practitioners call for better training on GenAI to enhance their abilities to generate effective prompts and evaluate output quality. Based on our findings, we provide recommendations for GenAI integration in the UX sector.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {1579–1593},
numpages = {15},
keywords = {Company Policies, GenAI, Generative Artificial Intelligence, Human-AI Collaboration, Industry Practices, Interaction Design, User Experience Design, User Experience Research},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3706599.3720026,
author = {Song, Xinheng and Song, Haiwen and Gao, Bingjie and Gao, Qijun and Li, Wenting and Xu, Linci and Lu, Zhaolin},
title = {“Do You Need the Sage's Tea or the Friend's Cola” Exploring the Differential Healing Effects of Generative AI Conversational Styles},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720026},
doi = {10.1145/3706599.3720026},
abstract = {While the preliminary exploration of Generative AI in aiding psychotherapy has already commenced, there has been no research on the intrinsic selection mechanism on the user side during the process of GAI-assisted psychological healing. To address this gap, we experimented with 30 participants using the fine-tuned large language model, assessing emotional responses through heart rate variability, facial expressions, and SAM scales. Results show that participants engaging with GAI therapists exhibiting slow response times and rich content experienced higher happiness, while those interacting with faster, brief-content GAI therapists showed greater surprise. Additionally, despite the stress levels initially slightly rising during conversations with GAI therapists, they decrease over time and ultimately lead to an improved emotional state. These findings validate the effectiveness of GAI therapists and provide a basis for applying GAI in different psychotherapy scenarios.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {616},
numpages = {8},
keywords = {Affective healing, Dialogue Styles, Facial expression, Heart rate variability, Human-AI interaction},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3686852.3686887,
author = {Chhetri, Chola},
title = {Exploring Large Language Model-Powered Pedagogical Approaches to Cybersecurity Education},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3686887},
doi = {10.1145/3686852.3686887},
abstract = {The adoption of artificial intelligence (AI) technologies by businesses and corporations is rising. AI technologies continue to be adopted in cybersecurity for both defensive and offensive strategies. However, threat actors also persist in utilizing these technologies to enhance the speed, accuracy, and sophistication of their attacks. Hence, it is essential to train the next generation of cybersecurity learners not only on how to use AI technology but also on how to leverage these technologies to enhance the efficiency of their work. This extended abstract describes our exploratory work on the use of generative AI-based pedagogical approaches in cybersecurity education. This extended abstract will describe some preliminary findings on large language model-powered pedagogical approaches to cybersecurity education and training. These approaches will help cybersecurity educators enhance their teaching methods to equip learners with the essential skills needed to succeed in the dynamic field of cybersecurity.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {163–166},
numpages = {4},
keywords = {AI, Artificial intelligence, GenAI, LLM, cybersecurity, education., generative AI, large language models},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3632776.3632827,
author = {LC, RAY and Tang, Yuying},
title = {Speculative Design with Generative AI: Applying Stable Diffusion and ChatGPT to imagining climate change futures},
year = {2024},
isbn = {9798400708725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632776.3632827},
doi = {10.1145/3632776.3632827},
abstract = {Policy mandates in addressing climate change are hindered by a lack of intrinsic motivation amongst participants to take collective action. Instead of overt persuasion, this study applied generative AI tools to speculative imagining of future climate scenarios and their adaptation strategies, using a workshop to encourage participants to align themselves with climate action. Participants used text-to-image tools to generate visions of the future in speculative scenarios, then prompted ChatGPT for potential solutions in these scenarios. They then asked text-to-image again to visualize the ChatGPT suggestions. Participants encountered difficulties editing or removing visual elements, dealt with the lack of transparency in the generation process by specifying the physical layout as opposed to the semantics, and collaboratively developed linguistic strategies for visual depiction of novel artifacts. This work shows how generative tools can be used to prototype future scenarios and envision designs that serve social purposes.},
booktitle = {Proceedings of the 11th International Conference on Digital and Interactive Arts},
articleno = {36},
numpages = {8},
keywords = {ChatGPT, Stable diffusion, climate change, co-design workshop, prompt design, speculative design},
location = {Faro, Portugal},
series = {ARTECH '23}
}

@inproceedings{10.1145/3613904.3642861,
author = {Mahdavi Goloujeh, Atefeh and Sullivan, Anne and Magerko, Brian},
title = {Is It AI or Is It Me? Understanding Users’ Prompt Journey with Text-to-Image Generative AI Tools},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642861},
doi = {10.1145/3613904.3642861},
abstract = {Generative Artificial Intelligence (AI) has witnessed unprecedented growth in text-to-image AI tools. Yet, much remains unknown about users’ prompt journey with such tools in the wild. In this paper, we posit that designing human-centered text-to-image AI tools requires a clear understanding of how individuals intuitively approach crafting prompts, and what challenges they may encounter. To address this, we conducted semi-structured interviews with 19 existing users of a text-to-image AI tool. Our findings (1) offer insights into users’ prompt journey including structures and processes for writing, evaluating, and refining prompts in text-to-image AI tools and (2) indicate that users must overcome barriers to aligning AI to their intents, and mastering prompt crafting knowledge. From the findings, we discuss the prompt journey as an individual yet a social experience and highlight opportunities for aligning text-to-image AI tools and users’ intents.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {183},
numpages = {13},
keywords = {Prompt engineering, generative AI, text-to-image generation, user journey},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3616961.3617804,
author = {Thibault, Mattia and Kivikangas, Timo and Roihankorpi, Riku and Pohjola, Petri and Aho, Markus},
title = {Who am AI?: Mapping Generative AI Impact and Transformative Potential in Creative Ecosystem},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3617804},
doi = {10.1145/3616961.3617804},
abstract = {Generative AI’s emergence reshapes creative ecosystems, presenting diverse prospects and trials. As these systems adjust to AI’s inclusion, equilibrium is disrupted, influencing workers and society. A proactive cross-sectoral approach becomes crucial in navigating this transformation, harnessing AI’s potential for sustainable growth. This poster proposes two dimensions relevant to map the possible impacts of AI on the creative sector: the impact of AI on the Industry from a perspective of labour, professionalisation, and management and the Actor Network status of AI in creative efforts. This marks an initial step in a cross-disciplinary endeavor to comprehend and guide the evolution of creative ecosystems, underlining the necessity for comprehensive data engagement and broad academic collaboration.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {344–349},
numpages = {6},
keywords = {Artificial Intelligence, Creative Industries, Cultural Production, GPT, Large Language Models},
location = {Tampere, Finland},
series = {Mindtrek '23}
}

@inproceedings{10.1145/3613904.3642852,
author = {Liu, Di and Zhou, Hanqing and An, Pengcheng},
title = {"When He Feels Cold, He Goes to the Seahorse"—Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642852},
doi = {10.1145/3613904.3642852},
abstract = {Storymaking, as an integrative form of expressive arts therapy, is an effective means to foster family communication. Yet, the integration of generative AI as expressive materials in therapeutic storymaking remains underexplored. And there is a lack of HCI implications on how to support families and therapists in this context. Addressing this, our study involved five weeks of storymaking sessions with seven families guided by a professional therapist. In these sessions, the families used both traditional art-making materials and image-based generative AI to create and evolve their family stories. Via the rich empirical data and commentaries from four expert therapists, we contextualize how families creatively melded AI and traditional expressive materials to externalize their ideas and feelings. Through the lens of Expressive Therapies Continuum (ETC), we characterize the therapeutic implications of AI as expressive materials. Desirable interaction qualities to support children, parents, and therapists are distilled for future HCI research.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {118},
numpages = {21},
keywords = {Expressive arts therapy, children, family, generative AI, human-AI interaction., storymaking},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3672608.3707764,
author = {Heilala, Ville and Araya, Roberto and H\"{a}m\"{a}l\"{a}inen, Raija},
title = {Beyond Text-to-Text: An Overview of Multimodal and Generative Artificial Intelligence for Education Using Topic Modeling},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707764},
doi = {10.1145/3672608.3707764},
abstract = {Generative artificial intelligence (GenAI) can reshape education and learning. While large language models (LLMs) like ChatGPT dominate current educational research, multimodal capabilities—such as text-to-speech and text-to-image—are less explored. This study uses topic modeling to map the research landscape of multimodal and generative AI in education. An extensive literature search yielded 4175 articles. Employing a topic modeling approach, latent topics were extracted, resulting in 38 interpretable topics organized into 14 thematic areas. Findings indicate a predominant focus on text-to-text models in educational contexts, with other modalities underexplored, overlooking the broader potential of multimodal approaches. The results suggest a research gap, stressing the importance of more balanced attention across different AI modalities and educational levels. In summary, this research provides an overview of current trends in generative AI for education, underlining opportunities for future exploration of multimodal technologies to fully realize the transformative potential of artificial intelligence in education.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {54–63},
numpages = {10},
keywords = {artificial intelligence, education, topic modeling, large language models, multimodal},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3663384.3663401,
author = {Das Swain, Vedant and Saha, Koustuv},
title = {Teacher, Trainer, Counsel, Spy: How Generative AI can Bridge or Widen the Gaps in Worker-Centric Digital Phenotyping of Wellbeing},
year = {2024},
isbn = {9798400710179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663384.3663401},
doi = {10.1145/3663384.3663401},
abstract = {The increasing integration of computing technologies in the workplace has also seen the conceptualization and development of data-driven and algorithmic tools that aim to improve workers’ wellbeing and performance. However, both research and practice have revealed several gaps in the effectiveness and deployment of these tools. Meanwhile, the recent advances in generative AI have highlighted the tremendous capabilities of large language models (LLMs) in processing large volumes of data in producing human-interactive natural language content. This paper explores the opportunities for LLMs in facilitating worker-centered design for Wellbeing Assessment Tools (WATs). In particular, we map features of LLMs against known challenges of WAT. We highlight how the LLMs can bridge or even widen the gaps in worker-centeric WAT. This paper aims to inspire new research directions focused on empowering workers and anticipating harms in integrating LLMs with workplace technologies.},
booktitle = {Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {3},
numpages = {13},
keywords = {LLMs, generative AI, large language models, worker performance, worker wellbeing, workplace},
location = {Newcastle upon Tyne, United Kingdom},
series = {CHIWORK '24}
}

@inproceedings{10.1145/3579028.3609016,
author = {Acher, Mathieu and Martinez, Jabier},
title = {Generative AI for Reengineering Variants into Software Product Lines: An Experience Report},
year = {2023},
isbn = {9798400700927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579028.3609016},
doi = {10.1145/3579028.3609016},
abstract = {The migration and reengineering of existing variants into a software product line (SPL) is an error-prone and time-consuming activity. Many extractive approaches have been proposed, spanning different activities from feature identification and naming to the synthesis of reusable artefacts. In this paper, we explore how large language model (LLM)-based assistants can support domain analysts and developers. We revisit four illustrative cases of the literature where the challenge is to migrate variants written in different formalism (UML class diagrams, Java, GraphML, statecharts). We systematically report on our experience with ChatGPT-4, describing our strategy to prompt LLMs and documenting positive aspects but also failures. We compare the use of LLMs with state-of-the-art approach, BUT4Reuse. While LLMs offer potential in assisting domain analysts and developers in transitioning software variants into SPLs, their intrinsic stochastic nature and restricted ability to manage large variants or complex structures necessitate a semiautomatic approach, complete with careful review, to counteract inaccuracies.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume B},
pages = {57–66},
numpages = {10},
location = {Tokyo, Japan},
series = {SPLC '23}
}

@inproceedings{10.1145/3628454.3629998,
author = {Rohan, Rohani and Faruk, Lawal Ibrahim Dutsinma and Puapholthep, Kittiphan and Pal, Debajyoti},
title = {Unlocking the Black Box: Exploring the use of Generative AI (ChatGPT) in Information Systems Research},
year = {2023},
isbn = {9798400708497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628454.3629998},
doi = {10.1145/3628454.3629998},
abstract = {With the gaining popularity of generative AI tools like ChatGPT and their usage across several domains and disciplines, the question that naturally arises is how it can help the Information Systems (IS) researchers? Measuring hidden or latent constructs is one critical and primitive aspects of the IS domain that has always been challenging due to its abstractness. How good or bad these specially trained AI-based models are with respect to their conceptual understanding capabilities of specific IS constructs together with their usage for the purpose of testing IS theories is an unknown area. We set out to explore these unknown aspects in this work by conducting two separate experiments with ChatGPT using the already proven and robust Technology Acceptance Model (TAM) as the reference. Our results suggest that ChatGPT has good conceptual understanding of the presented latent constructs, although there might be certain validity issues in case of complex models. Therefore, it shows promise in the broader aspect of testing theories, but not without its limitations that we present in this research.},
booktitle = {Proceedings of the 13th International Conference on Advances in Information Technology},
articleno = {17},
numpages = {9},
keywords = {ChatGPT, information systems, latent constructs, scale, technology acceptance model},
location = {Bangkok, Thailand},
series = {IAIT '23}
}

@inproceedings{10.1145/3729605.3729611,
author = {Li, Jingchao and Zhan, Meiwei and Li, Shanshan},
title = {Study on the Role of Generative Artificial Intelligence in Advancing the Knowledge System of Traditional Chinese Medicine in Higher Education},
year = {2025},
isbn = {9798400714405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3729605.3729611},
doi = {10.1145/3729605.3729611},
abstract = {The transfer and promotion of effectively inheritance and innovation of knowledge is a problem that higher education of Chinese medicine must face. This study provides a novel generative AI framework to promote the inheritance and innovative development of knowledge in traditional Chinese medical education. Utilizing multi-modal data processing (textual, visual and experiential) to construct a knowledge base, the model is based on Generative Adversarial Networks (GANs) and Transformer-based architecture. This context-aware and semantic-rich embedding is made possible using state-of-the-art technology, including attention mechanism and knowledge graph embedding. The learning structure of the model foreshadows the traditional Chinese medicine teaching model and cultivates students as good at in-depth understanding and creative application of knowledge. Furthermore, through transfer learning and domain-specific fine-tuning, the framework attains high fidelity of captured knowledge representation while also supporting the generation of new hypotheses and therapeutics. Our generative AI model improves knowledge transfer accuracy and depth, and encourage innovative thinking compared to traditional educational methodologies, as we demonstrate through experimental results.},
booktitle = {Proceedings of the 2025 International Conference on Big Data and Informatization Education},
pages = {28–33},
numpages = {6},
keywords = {Educational Innovation, Generative AI, Generative Model, Higher Education, Knowledge Transfer},
location = {
},
series = {ICBDIE '25}
}

@inproceedings{10.1145/3711403.3711457,
author = {Zhao, Dong and Zhang, Dan and Ma, Xiujuan},
title = {The Application of Generative Artificial Intelligence in the Teaching of Engineering Courses in Chinese Universities},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711457},
doi = {10.1145/3711403.3711457},
abstract = {Generative Artificial Intelligence (GenAI) is revolutionizing the field of higher education by leveraging deep learning models to generate human-like content. However, the use of GenAI in education raises ethical concerns such as the potential impact on critical thinking skills and the unethical or dishonest use by students. This paper analyzed the main problems existing in engineering courses in Chinese universities firstly and then proposed corresponding teaching reform measures based on the comprehensive consideration of the benefits and threats of GenAI. We applied the proposed teaching reform measures in the teaching of engineering courses, which greatly improved the teaching quality.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {328–332},
numpages = {5},
keywords = {Chinese universities, Engineering courses, Generative Artificial Intelligence, Higher education, Teaching reform},
location = {
},
series = {ICETM '24}
}

@article{10.5555/3665609.3665633,
author = {Liu, Sa and Grey, Brian and Watkins, Ryan and Chu, Chad and Grim, Phillip and McManus, Thomas},
title = {Assessing Risks, Challenges and Opportunities of Generative AI in Computer Programming Education --- Lightning Talk},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {8},
issn = {1937-4771},
abstract = {Artificial Intelligence (AI) has the potential to transform the education sector by enhancing teaching and learning experiences. According to Sal Khan, founder of Khan Academy, AI is about to start "the biggest positive transformation that education has ever seen"1 by making high-quality personalized tutoring available (tuition free) to everyone on the planet. Given AI's, and more specifically Generative AI's (GAI), rapidly developing capabilities (e.g., to provide tailored feedback, ask questions of students, give examples and non-examples, and offer general learning support), incorporating GAI into programming education has the potential to enhance student engagement and learning outcomes. At the same time, they identified challenges in using GAI, such as its inability to answer some questions and its tendency to provide incorrect or incomplete responses. Students also report an increase in anxiety surrounding GAI and its potential effects on future professional opportunities. Outside of the classroom there is likewise an increasing prevalence of GAI in computational professions, making it crucial to equip students with the necessary knowledge and skills to effectively, responsibly, and ethically utilize GAI. Rather than avoiding the use of GAI in the classroom, in this study we aim to investigate the pros and cons of leveraging GAI's capabilities to offer personalized guidance and assistance to students as they learn programming. By doing this research, we are learning to create more interactive and engaging learning experiences that better equip students with the skills and knowledge needed to succeed in the field of programming. This project, which is currently being conducted, was designed to address this research question: To what extent does the incorporation of GAI impact students' engagement, motivation, and achievement, particularly with the material in Intro to Programming courses and their chosen STEM field of study? It is utilizing case studies that focus on the integration of GAI into computer programming education. The team has 1) developed a series of GAI-supported teaching modules specifically designed to improve problem-solving skills in programming tasks among undergraduate students; and 2) is in the process of analyzing student feedback on GAI integration in computer programming education. This project offers an important exploration into the intersection of GAI and programming education, with the expectation that results will provide useful guidance for programming instructors who are adapting their instructional strategies for the emerging role of GAI in programming. The team will briefly present the status of the research and early insights from the project, and then engage with the audience on how lessons learned from this work can pragmatically shape programming courses in their institutions. Quick tips, takeaways, and prompting strategies will be shared throughout this interactive lighting talk.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {210–211},
numpages = {2}
}

@inproceedings{10.1145/3686038.3686060,
author = {Chen, Cheng and Lee, Sangwook and Jang, Eunchae and Sundar, S. Shyam},
title = {Is Your Prompt Detailed Enough? Exploring the Effects of Prompt Coaching on Users' Perceptions, Engagement, and Trust in Text-to-Image Generative AI Tools},
year = {2024},
isbn = {9798400709890},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686038.3686060},
doi = {10.1145/3686038.3686060},
abstract = {Prompts are the primary medium for interacting with generative AI tools. However, users often lack sufficient prompt literacy and motivation to fully benefit from these tools. To address this, we explore whether introducing prompt coaching into a chatbot-based generative AI interface can influence users’ perceptions and engagement of prompting, and further affect their trust in the system. In a user study (N = 132), we found that prompt coaching encourages users to specify more details in their prompts, even though over half initially believed their prompts were sufficient. Furthermore, the coach increased users’ cognitive elaboration, which was associated with higher perceived trust calibration. However, prompt coaching did not significantly enhance UX, although users in the coaching absent condition expressed a strong need for prompt assistance for better user experience. These findings have practical implications for the design of&nbsp;trustworthy and responsible generative AI interfaces.},
booktitle = {Proceedings of the Second International Symposium on Trustworthy Autonomous Systems},
articleno = {9},
numpages = {12},
keywords = {Cognitive elaboration, Generative AI, Perceived trust calibration, Prompt coaching, User Engagement, User Experience, User Interface},
location = {Austin, TX, USA},
series = {TAS '24}
}

@inproceedings{10.1145/3613905.3650845,
author = {Panchanadikar, Ruchi and Freeman, Guo and Li, Lingyuan and Schulenberg, Kelsea and Hu, Yang},
title = {"A New Golden Era" or "Slap Comps": How Non-Profit Driven Indie Game Developers Perceive the Emerging Role of Generative AI in Game Development},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650845},
doi = {10.1145/3613905.3650845},
abstract = {While the boom in generative AI technologies continues to transform modern creative work, it also introduces new and urgent risks. We endeavor to unpack these complicated phenomena by focusing on how non-profit driven indie game developers perceive the opportunities and challenges of using generative AI for their creative practices. Based on qualitative analysis of 1,540 posts and comments from online forums dedicated to this creative community, we provide early empirical evidence of the potential for generative AI to shape the trajectory of creative technology communities such as non-profit driven indie game developers. These insights may inform future research regarding AI’s impacts on the nature of creative work and the growth of creative workforces in technology, which may also help design future AI technologies to support rather than harm these creative communities.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {1},
numpages = {7},
keywords = {Creativity, Game Development, Generative AI, Indie Game Development},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3613904.3642461,
author = {Shelby, Renee and Rismani, Shalaleh and Rostamzadeh, Negar},
title = {Generative AI in Creative Practice: ML-Artist Folk Theories of T2I Use, Harm, and Harm-Reduction},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642461},
doi = {10.1145/3613904.3642461},
abstract = {Understanding how communities experience algorithms is necessary to mitigate potential harmful impacts. This paper presents folk theories of text-to-image (T2I) models to enrich understanding of how artist communities experience creative machine learning systems. This research draws on data collected from a workshop with 15 artists from 10 countries who incorporate T2I models in their creative practice. Through reflexive thematic analysis of workshop data, we highlight artist folk theories of T2I use, harm, and harm reduction. Folk theories of use envision T2I models as an artistic medium, a mundane tool, and locate true creativity as rising above model affordances. Theories of harm articulate T2I models as harmed by engineering efforts to eliminate glitches and product policy efforts to limit functionality. Theories of harm-reduction orient towards protecting T2I models for creative practice through transparency and distributed governance. We examine how these theories relate, and conclude by discussing how folk theorization informs responsible AI efforts.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {32},
numpages = {17},
keywords = {Art &amp; Technology, Creativity, Folk Theory, Generative AI, T2I},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3675094.3677586,
author = {Zhu, Yue and Zhou, Zhiyuan and Miao, Jinlin and Mi, Haipeng and Guo, Yijie},
title = {TangibleNegotiation: Probing Design Opportunities for Integration of Generative AI and Swarm Robotics for Imagination Cultivation in Child Art Education},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3677586},
doi = {10.1145/3675094.3677586},
abstract = {While traditional methods in art education primarily focus on observation and imitation, they often fail to adequately support the imaginative and creative capacities of children. This paper introduces TangibleNegotiation, a novel child-AI co-creation system that integrates Tangible User Interfaces (TUIs) with Generative AI technologies to enhance imagination cultivation in child art education. Leveraging the capabilities of swarm user interfaces (SUIs) for both visualization and dynamic narrative, this system embeds an LLM-based agent for conversational and motion planning alongside real-time image-to-image generation. TangibleNegotiation offers a comprehensive pipeline with four interactive modalities: Pre-creation Tips, Real-time Conversation, Real-time Artwork Rendering, and Final Artwork Generation, each designed to foster an engaging and interactive learning environment. A pilot study involving semi-structured interviews with four elementary school art teachers suggests that the system effectively enhances children's engagement and stimulates their imagination through dynamic, real-time artistic feedback. The findings highlight the potential of combining SUI with generative AI to make art education more accessible, inclusive, and effective in fostering artistic imagination.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {66–70},
numpages = {5},
keywords = {art education, imagination, llm-based agent, swarm user interface},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3613904.3642899,
author = {Tang, Yilin and Chen, Liuqing and Chen, Ziyu and Chen, Wenkai and Cai, Yu and Du, Yao and Yang, Fan and Sun, Lingyun},
title = {EmoEden: Applying Generative Artificial Intelligence to Emotional Learning for Children with High-Function Autism},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642899},
doi = {10.1145/3613904.3642899},
abstract = {Children with high-functioning autism (HFA) often face challenges in emotional recognition and expression, leading to emotional distress and social difficulties. Conversational agents developed for HFA children in previous studies show limitations in children's learning effectiveness due to the conversational agents’ inability to dynamically generate personalized and contextual content. Recent advanced generative Artificial Intelligence techniques, with the capability to generate substantial diverse and high-quality texts and visual content, offer an opportunity for personalized assistance in emotional learning for HFA children. Based on the findings of our formative study, we integrated large language models and text-to-image models to develop a tool named EmoEden supporting children with HFA. Over a 22-day study involving six HFA children, it is observed that EmoEden effectively engaged children and improved their emotional recognition and expression abilities. Additionally, we identified the advantages and potential risks of applying generative AI to assist HFA children in emotional learning.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1001},
numpages = {20},
keywords = {Conversational agents, Emotional learning, Generative AI, High-functioning autism},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3700297.3700354,
author = {Wang, Xiling and Lei, Lei},
title = {A Path Study of Generative Artificial Intelligence Enabling Online Education Platforms in Colleges and Universities},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700354},
doi = {10.1145/3700297.3700354},
abstract = {With the development of Internet and AI technologies, online education platforms in colleges and universities face challenges in personalized teaching and teacher-student interaction. Based on the technical characteristics of generative AI, combined with the project-based learning (PBL) approach, this study proposes specific paths and strategies to optimize online education platforms in colleges and universities. The study adopts the literature analysis method to systematically sort out the status quo and feasibility of generative AI and online education platform in colleges and universities. On this basis, this paper designs two main paths of intelligent generation of teaching resources and optimization of learning process based on generative AI. The former includes course content generation, teaching interaction generation and evaluation feedback generation; the latter covers learning data analysis, intelligent learning progress tracking and dynamic evaluation of learning effects. Through the theoretical analysis of the path design, this study provides a preliminary theoretical framework and practical ideas for the intelligent upgrading of online education platforms in colleges and universities, which can be used as a reference for the subsequent research and practical application in this field.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {332–338},
numpages = {7},
keywords = {Educational innovation, Generative artificial intelligence, Learning process optimization, Online education platform for universities, Teaching resource generation},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3663548.3675600,
author = {Lee, Seonghee and Kohga, Maho and Landau, Steve and O'Modhrain, Sile and Subramonyam, Hari},
title = {AltCanvas: A Tile-Based Editor for Visual Content Creation with Generative AI for Blind or Visually Impaired People},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3675600},
doi = {10.1145/3663548.3675600},
abstract = {People with visual impairments often struggle to create content that relies heavily on visual elements, particularly when conveying spatial and structural information. Existing accessible drawing tools, which construct images line by line, are suitable for simple tasks like math but not for more expressive artwork. On the other hand, emerging generative AI-based text-to-image tools can produce expressive illustrations from descriptions in natural language, but they lack precise control over image composition and properties. To address this gap, our work integrates generative AI with a constructive approach that provides users with enhanced control and editing capabilities. Our system, AltCanvas, features a tile-based interface enabling users to construct visual scenes incrementally, with each tile representing an object within the scene. Users can add, edit, move, and arrange objects while receiving speech and audio feedback. Once completed, the scene can be rendered as a color illustration or as a vector for tactile graphic generation. Involving 14 blind or low-vision users in design and evaluation, we found that participants effectively used the AltCanvas’s workflow to create illustrations.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {70},
numpages = {22},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@inproceedings{10.1145/3706598.3713569,
author = {Qin, Hua Xuan and Zhu, Guangzhi and Fan, Mingming and Hui, Pan},
title = {Toward Personalizable AI Node Graph Creative Writing Support: Insights on Preferences for Generative AI Features and Information Presentation Across Story Writing Processes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713569},
doi = {10.1145/3706598.3713569},
abstract = {As story writing requires diverse resources, a single system combining these resources could improve personalization. We leverage the broad capabilities of generative AI to support both more general story writing needs and an understudied but essential aspect: reflection on the moral (lesson) conveyed. Through a formative study (N=12), a user study (N=14), and external evaluation (N=19), we designed, implemented, then studied a prototype plugin for FigJam supporting visualization of the story structure through customizable node graph editing, LLM audience impersonation (chatbot and non-chatbot interfaces), and image and audio generative AI features. Our findings support writers’ preference for leveraging unique interplays of our breadth of features to satisfy shifting needs across writing processes, from conveying a moral across audience groups to story writing in general. We discuss how our tool design and findings can inform model bias, personalized writing support, and visualization research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {897},
numpages = {30},
keywords = {Creativity Support, Writing Assistants, Visualization, Human-AI Collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3633083.3633099,
author = {Stone, Irene},
title = {Exploring the Research Gap: Generative AI and Learning of Python Programming among Post-Primary Students},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633099},
doi = {10.1145/3633083.3633099},
abstract = {The introduction of Leaving Certificate Computer Science (LCCS) in Ireland in 2018 signifies a notable advancement in post-primary education. Moreover, developments in generative Artificial Intelligence (GAI) in education, are gaining prominence, yet we do not understand its value or how best to implement it in post-primary educational settings. Despite a growing international body of research in this area, my scoping review highlights that many aspects of these topics have yet to be explored, particularly in the context of post-primary students in Ireland. My study will begin to bridge this gap by exploring how a purposeful sample of LCCS post-primary students in Ireland engage with GAI tools, such as ChatGPT, during their initial experiences learning Python programming. These findings, when approached through the lens of Human-Centred Artificial Intelligence (HCAI), can help enhance pedagogical strategies and lead to improved learning experiences for students.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {51},
numpages = {1},
location = {Dublin, Ireland},
series = {HCAIep '23}
}

@inproceedings{10.1145/3587102.3588815,
author = {Daun, Marian and Brings, Jennifer},
title = {How ChatGPT Will Change Software Engineering Education},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588815},
doi = {10.1145/3587102.3588815},
abstract = {This position paper discusses the potential for using generative AIs like ChatGPT in software engineering education. Currently, discussions center around potential threats emerging from student's use of ChatGPT. For instance, generative AI will limit the usefulness of graded homework dramatically. However, there exist potential opportunities as well. For example, ChatGPT's ability to understand and generate human language allows providing personalized feedback to students, and can thus accompany current software engineering education approaches. This paper highlights the potential for enhancing software engineering education. The availability of generative AI will improve the individualization of education approaches. In addition, we discuss the need to adapt software engineering curricula to the changed profiles of software engineers. Moreover, we point out why it is important to provide guidance for using generative AI and, thus, integrate it in courses rather than accepting the unsupervised use by students, which can negatively impact the students' learning.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {110–116},
numpages = {7},
keywords = {ChatGPT, generative AI, software engineering education},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3702163.3702167,
author = {Liang, Huiyang and Tse, Alex Wing Cheung},
title = {The Influence of Interacting with Generative AI Chatbots in Informal English Learning Environments on Undergraduate Students’ Willingness to Communicate in Mainland China: a Case Study},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702167},
doi = {10.1145/3702163.3702167},
abstract = {Willingness to communicate (WTC) is a crucial factor in second language acquisition, significantly impacting undergraduates' English-speaking skills. Although there is research on generative AI chatbots for language learning, the field is still in its early stages. This study examined the impact of willingness to interact with generative AI chatbots for English-speaking practice on the willingness to communicate in informal learning environments among mainland Chinese undergraduates. Qualitative research with purposively selected 10 students showed that generative AI chatbots provided a relaxed, informal English-speaking practice environment, positively impacting their willingness to communicate with native speakers in school settings and improving speaking skills, confidence, and classroom participation. However, the interaction capabilities of generative AI chatbots were limited, showing no significant correlation to the willingness to communicate with non-native speakers. These findings highlight the potential and limitations of generative AI chatbots in enhancing language learning and emphasize the need for further research on their role in different communication contexts and other influencing factors, providing valuable insights for learning spoken English in Chinese higher education.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {26–32},
numpages = {7},
keywords = {English speaking skills, Generative AI chatbots, Informal digital learning of English, Second language learning, Willingness to communicate},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3652628.3652678,
author = {Liu, Yanghe},
title = {Research on cross-media dissemination mechanism of generative AI artworks based on ISM model},
year = {2024},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652628.3652678},
doi = {10.1145/3652628.3652678},
abstract = {The rapid development of Artificial Intelligence (AI) has facilitated the digital generation and cross-media dissemination of artworks, which has led to an explosion of artistic information and increased aesthetic opportunities. However, this also presents a dilemma for the sustainable development of generative AI artworks in media communication. In this paper, we aim to explore the cross-media communication mechanism of generative AI artworks using the ISM model. Firstly, we conduct a literature review to identify the influencing factors of cross-media communication of generative AI artworks. We then select 10 direct factors by merging similar ones. Secondly, we analyze the interaction between each factor, determine the adjacency matrix and reachability matrix, and construct the explanatory structural model. Finally, we establish the hierarchical relationship between the various factors of cross-media communication of generative AI artworks and their logical architecture. Our findings indicate that the algorithmic recommendation mechanism of the media and the audience's interest in appreciating AI art creations are the most direct reasons, while the diversity of art communication forms, the formal aesthetics of AI artworks, and the social commentary on AI artworks serve as the underlying reasons. The research presented in this paper is of practical significance in addressing the cross-media communication dilemma of generative AI artworks and ultimately contributes to the improvement of the overall aesthetic quality of society.},
booktitle = {Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
pages = {301–305},
numpages = {5},
location = {Dalian, China},
series = {ICAICE '23}
}

@inproceedings{10.1145/3672608.3707817,
author = {Set\"{a}l\"{a}, Mika and Heilala, Ville and Sikstr\"{o}m, Pieta and K\"{a}rkk\"{a}inen, Tommi},
title = {The Use of Generative Artificial Intelligence for Upper Secondary Mathematics Education Through the Lens of Technology Acceptance},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707817},
doi = {10.1145/3672608.3707817},
abstract = {This study investigated the students' perceptions of using Generative Artificial Intelligence (GenAI) in upper-secondary mathematics education. Data was collected from Finnish high school students to represent how key constructs of the Technology Acceptance Model—Perceived Usefulness, Perceived Ease of Use, Perceived Enjoyment, and Intention to Use—influence the adoption of AI tools. First, a structural equation model for a comparative study with a prior study was constructed and analyzed. Then, an extended model with the additional construct of Compatibility, which represents the alignment of AI tools with students' educational experiences and needs, was proposed and analyzed. The results demonstrated a strong influence of perceived usefulness on the intention to use GenAI, emphasizing the statistically significant role of perceived enjoyment in determining perceived usefulness and ease of use. The inclusion of compatibility improved the model's explanatory power, particularly in predicting perceived usefulness. This study contributes to a deeper understanding of how AI tools can be integrated into mathematics education and highlights key differences between the Finnish educational context and previous studies based on structural equation modeling.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {74–82},
numpages = {9},
keywords = {mathematics education, upper secondary school, generative artificial intelligence, technology acceptance},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3613904.3641951,
author = {Mim, Nusrat Jahan and Nandi, Dipannita and Khan, Sadaf Sumyia and Dey, Arundhuti and Ahmed, Syed Ishtiaque},
title = {In-Between Visuals and Visible: The Impacts of Text-to-Image Generative AI Tools on Digital Image-making Practices in the Global South},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641951},
doi = {10.1145/3613904.3641951},
abstract = {This paper joins the growing body of HCI work on critical AI studies and focuses on the impact of Generative Artificial Intelligence (GAI) tools in Bangladesh. While the West has started to examine the limitations and risks associated with these tools, their impacts on the Global South have remained understudied. Based on our interviews, focus group discussions (FGD), and social media-based qualitative study, this paper reports how popular text-to-image GAI tools (ex., DALL-E, Midjourney, Stable Diffusion, Firefly) are affecting various image-related local creative fields. We report how these tools limit the creative explorations of marginal artists, struggle to understand linguistic nuances, fail to generate local forms of art and architecture, and misrepresent the diversity among citizens in the image production process. Drawing from a rich body of work on critical image theory, postcolonial computing, and design politics, we explain how our findings are pertinent to HCI’s broader interest in social justice, decolonization, and global development.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {474},
numpages = {18},
keywords = {Architecture, Art, Artificial Intelligence, Generative AI, Image, Urban Design},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3703459,
author = {Billiris, Grace and Gill, Asif and Oppermann, Ian and Niazi, Mahmood},
title = {Towards the Development of a Copyright Risk Checker Tool for Generative Artificial Intelligence Systems},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
url = {https://doi.org/10.1145/3703459},
doi = {10.1145/3703459},
abstract = {Generative Artificial Intelligence (GAI) is fundamentally changing the ways of working and blurring the boundaries between human and machine-generated contents. While there is an increasing interest in the adoption of GAI systems, such as ChatGPT and DALL-E, there are also serious concerns about the copyright of the contents—the inputs or generated as outputs by the GAI systems. Such concerns need to be identified and assessed to ensure the ethical and responsible use of GAI systems. Thus, this article aims to address the key research challenge: “how to identify and assess GAI system's copyright concerns”? In response, we propose the development of a Copyright Risk Checker (CRC) Tool. This tool has been formulated and evaluated using a recognised design science research methodology, drawing on an analysis of 10 legal cases across Australia, the United Kingdom, the United States, and Europe. The CRC Tool has undergone evaluation through an experimental scenario, and the results suggest that it is suitable for conducting an indicative copyright risk check of GAI systems. The outcomes of this preliminary assessment can be further examined by expert legal advisors for an in-depth analysis. The development of the CRC Tool provides a foundation for continued research and advancement in this significant area of study.},
journal = {Digit. Gov.: Res. Pract.},
month = dec,
articleno = {41},
numpages = {21},
keywords = {Generative Artificial Intelligence, Copyright Concern, GAI Governance, Copyright Regulations, Independent Intellectual Effort, Authorship}
}

@inproceedings{10.1145/3680127.3680219,
author = {Alves, Karine and Santos, Edney and Silva, Matheus Fidelis and Chaves, Ana Carolina and Fernandes, Jose Andre and Valenca, George and Brito, Kellyton},
title = {Towards the regulation of Large Language Models (LLMs) and Generative AI use in the Brazilian Government: the case of a State Court of Accounts},
year = {2024},
isbn = {9798400717802},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680127.3680219},
doi = {10.1145/3680127.3680219},
abstract = {The rapid evolution of Artificial Intelligence (AI) and Large Language Models (LLMs) has been highlighted by the rise of platforms like ChatGPT, which garnered a significant user base within a short span of time. This sudden surge has sparked both excitement and concern among the government and public bodies, which are struggling to establish regulations governing AI usage. In Brazil, for instance, the legal landscape for AI remains uncertain, leaving public organizations uncertain about the path forward. In light of this ambiguity, this paper aims to develop and implement a methodology for establishing AI regulations in the public service, with a specific emphasis and partnership with the State Court of Accounts. To achieve this, a comprehensive methodology with five stages was collaboratively developed: (i) research and analysis; (ii) define the content of the regulation; (iii) categorize and refine; (iv) write a draft proposal; and (v) discuss and validate with stakeholders. Notably, the initial stage involved extensive research encompassing academic literature, existing and pending legislation in Brazil, and global initiatives. As a result, a set of 4 principles, 13directives, 22 acceptable uses, and 25 best practices were delineated and validated. This work represents a pioneering approach to AI regulation within Brazilian public institutions, offering a clear and actionable methodology that can serve as a reference point for future regulatory initiatives.},
booktitle = {Proceedings of the 17th International Conference on Theory and Practice of Electronic Governance},
pages = {28–35},
numpages = {8},
keywords = {Generative AI, Regulation, Framework},
location = {
},
series = {ICEGOV '24}
}

@inproceedings{10.5555/3716662.3716702,
author = {Ghosh, Sourojit and Venkit, Pranav Narayanan and Gautam, Sanjana and Wilson, Shomir and Caliskan, Aylin},
title = {Do Generative AI Models Output Harm While Representing Non-Western Cultures: Evidence from a Community-Centered Approach},
year = {2025},
publisher = {AAAI Press},
abstract = {Our research investigates the impact of Generative Artificial Intelligence (GAI) models, specifically text-to-image generators (T2Is), on the representation of non-Western cultures, with a focus on Indian contexts. Despite the transformative potential of T2Is in content creation, concerns have arisen regarding biases that may lead to misrepresentations and marginalizations. Through a Non-Western community-centered approach and grounded theory analysis of 5 focus groups from diverse Indian subcultures, we explore how T2I outputs to English input prompts depict Indian culture and its subcultures, uncovering novel representational harms such as exoticism and cultural misappropriation. These findings highlight the urgent need for inclusive and culturally sensitive T2I systems. We propose design guidelines informed by a sociotechnical perspective, contributing to the development of more equitable and representative GAI technologies globally. Our work underscores the necessity of adopting a community-centered approach to comprehend the sociotechnical dynamics of these models, complementing existing work in this space while identifying and addressing the potential negative repercussions and harms that may arise as these models are deployed on a global scale.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {476–489},
numpages = {14},
location = {San Jose, California, USA},
series = {AIES '24}
}

@inproceedings{10.1145/3622758.3622882,
author = {Sarkar, Advait},
title = {Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models?},
year = {2023},
isbn = {9798400703881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622758.3622882},
doi = {10.1145/3622758.3622882},
abstract = {The research field of end-user programming has largely been concerned with helping non-experts learn to code sufficiently well in order to achieve their tasks. Generative AI stands to obviate this entirely by allowing users to generate code from naturalistic language prompts. In this essay, we explore the extent to which "traditional" programming languages remain relevant for non-expert end-user programmers in a world with generative AI. We posit the "generative shift hypothesis": that generative AI will create qualitative and quantitative expansions in the traditional scope of end-user programming. We outline some reasons that traditional programming languages may still be relevant and useful for end-user programmers. We speculate whether each of these reasons might be fundamental and enduring, or whether they may disappear with further improvements and innovations in generative AI. Finally, we articulate a set of implications for end-user programming research, including the possibility of needing to revisit many well-established core concepts, such as Ko's learning barriers and Blackwell's attention investment model.},
booktitle = {Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {153–167},
numpages = {15},
keywords = {attention investment model, end-user software customization, generative shift hypothesis, learning barriers, live programming, prompt engineering, self-efficacy},
location = {Cascais, Portugal},
series = {Onward! 2023}
}

@article{10.1145/3689433,
author = {Zhang, Hongbo and Chen, Pei and Xie, Xuelong and Jiang, Zhaoqu and Zhou, Zihong and Sun, Lingyun},
title = {A Hybrid Prototype Method Combining Physical Models and Generative Artificial Intelligence to Support Creativity in Conceptual Design},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {5},
issn = {1073-0516},
url = {https://doi.org/10.1145/3689433},
doi = {10.1145/3689433},
abstract = {Conceptual design is an essential stage in the design process, and its ultimate success largely depends on designers’ creativity. Both physical and digital prototypes are commonly adopted by designers to support ideation and creativity, providing intuitive perception and rapid iteration, respectively. In recent advancements, large-scale generation models are able to offer data-enabled creativity support by generating high-quality solutions comparable to human designers. This opens up an imaginary space for designers and brings new possibilities for design tools. In this study, we proposed a hybrid prototype method that synergistically combines physical models and generative artificial intelligence (AI) in the conceptual design stage. Correspondingly, we developed a hybrid prototype system to implement the proposed method. We conducted a comparative user study with 45 designers who completed a design task using the physical prototype method, standalone generative AI and the hybrid prototype method, respectively. Our results verified the effectiveness of the hybrid prototype method and investigated its mechanism in supporting creativity. Finally, we discussed the application value and optimisation space of the hybrid prototype method.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = nov,
articleno = {65},
numpages = {34},
keywords = {Hybrid Prototype, Generative AI, Co-creative Systems, Physical Prototype, Creativity Support Tool (CST), Applications of Large-scale Generation Models}
}

@inproceedings{10.1145/3674805.3690743,
author = {Felizardo, Katia Romero and Steinmacher, Igor and Lima, M\'{a}rcia Sampaio and Deizepe, Anderson and Conte, Tayana Uch\^{o}a and Barcellos, Monalessa Perini},
title = {Data extraction for systematic mapping study using a large language model - a proof-of-concept study in software engineering},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690743},
doi = {10.1145/3674805.3690743},
abstract = {Context: Systematic mapping studies (SMS) are adopted in Software Engineering (SE) to select and synthesize relevant literature on a research topic and, thus, support evidence-based decision-making. Performing SMS is effort-demanding and time-consuming. Hence, using tools is beneficial. Large Language Models (LLMs) such as ChatGPT–4.o can potentially accelerate repetitive activities, such as data extraction in SMS, saving time and effort. Goal: We conducted this work to evaluate and provide preliminary evidence on how ChatGPT–4.o can support data extraction in SMS. Method: We performed a proof-of-concept study and assessed the results’ accuracy of using ChatGPT 4.0 to extract data in one SMS compared to the results produced manually. Results: The accuracy of ChatGPT–4.o was 87.83%. Conclusions: Our preliminary findings suggest that entirely replacing the manual data extraction with ChatGPT–4.o is not recommended. However, employing ChatGPT for semi-automated data extraction to aid in evidence synthesis in SMS is promising.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {407–413},
numpages = {7},
keywords = {ChatGPT, Data Extraction, LLM, Mapping Study},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3657604.3664720,
author = {Lin, Jionghao and Chen, Eason and Gurung, Ashish and Koedinger, Kenneth R.},
title = {MuFIN: A Framework for Automating Multimodal Feedback Generation using Generative Artificial Intelligence},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664720},
doi = {10.1145/3657604.3664720},
abstract = {Written feedback has long been a cornerstone in educational and professional settings, essential for enhancing learning outcomes. However, multimodal feedback-integrating textual, auditory, and visual cues-promises a more engaging and effective learning experience. By leveraging multiple sensory channels, multimodal feedback better accommodates diverse learning preferences and aids in deeper information retention. Despite its potential, creating multimodal feedback poses challenges, including the need for increased time and resources. Recent advancements in generative artificial intelligence (GenAI) offer solutions to automate the feedback process, predominantly focusing on textual feedback. Yet, the application of GenAI in generating multimodal feedback remains largely unexplored. Our study investigates the use of GenAI techniques to generate multimodal feedback, aiming to provide this feedback for large cohorts of learners, thereby enhancing learning experience and engagement. By exploring the potential of GenAI for this purpose, we propose a framework for automating the generation of multimodal feedback, which we name MuFIN.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {550–552},
numpages = {3},
keywords = {generative artificial intelligence, large language models, multimodal feedback},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3597638.3614548,
author = {Glazko, Kate S and Yamagami, Momona and Desai, Aashaka and Mack, Kelly Avery and Potluri, Venkatesh and Xu, Xuhai and Mankoff, Jennifer},
title = {An Autoethnographic Case Study of Generative Artificial Intelligence's Utility for Accessibility},
year = {2023},
isbn = {9798400702204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597638.3614548},
doi = {10.1145/3597638.3614548},
abstract = {With the recent rapid rise in Generative Artificial Intelligence (GAI) tools, it is imperative that we understand their impact on people with disabilities, both positive and negative. However, although we know that AI in general poses both risks and opportunities for people with disabilities, little is known specifically about GAI in particular. To address this, we conducted a three-month autoethnography of our use of GAI to meet personal and professional needs as a team of researchers with and without disabilities. Our findings demonstrate a wide variety of potential accessibility-related uses for GAI while also highlighting concerns around verifiability, training data, ableism, and false promises.},
booktitle = {Proceedings of the 25th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {99},
numpages = {8},
keywords = {ableism, accessibility, auto-ethnography, generative artificial intelligence},
location = {New York, NY, USA},
series = {ASSETS '23}
}

@inproceedings{10.1145/3568812.3603469,
author = {Amoozadeh, Matin and Daniels, David and Chen, Stella and Nam, Daye and Kumar, Aayush and Hilton, Michael and Alipour, Mohammad Amin and Ragavan, Sruti Srinivasa},
title = {Towards Characterizing Trust in Generative Artificial Intelligence among Students},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603469},
doi = {10.1145/3568812.3603469},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {3–4},
numpages = {2},
keywords = {Generative AI, Novice programmers, Trust},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3649165.3690101,
author = {Hellas, Arto and Leinonen, Juho and Lepp\"{a}nen, Leo},
title = {Experiences from Integrating Large Language Model Chatbots into the Classroom},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690101},
doi = {10.1145/3649165.3690101},
abstract = {We provided students access to a state-of-the-art large language model (LLM) chatbot through the online materials of three university-level courses. One of the courses focused on software engineering with LLMs, while the two other courses were not directly related to LLMs. The chatbot used OpenAI GPT-4 without additional filters or system prompts.  Our results suggest that only a minority of students engage with the chatbot in the courses that do not relate to LLMs. At the same time, unsurprisingly, nearly all students in the LLM-focused course leveraged the chatbot. In all courses, the majority of the chatbot usage came from a few superusers, whereas the majority of the students did not heavily use the chatbot even though it effectively provided free access to OpenAI's GPT-4 model (which would have otherwise required a paid subscription at the time of the study). We observe that in addition to students using the chatbot for course-specific purposes, many use the chatbot for their own purposes.  Overall, our results suggest that the worst fears of educators -- all students overrelying on chatbots -- did not materialize. Finally, we discuss potential reasons for low usage, including the need for more tailored and scaffolded chatbot experiences targeted for specific types of use cases.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {46–52},
numpages = {7},
keywords = {chatbots, classroom experiences, experience report, generative ai, large language models, usage analysis},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3643834.3661507,
author = {Park, Gun Woo (Warren) and Panda, Payod and Tankelevitch, Lev and Rintel, Sean},
title = {The CoExplorer Technology Probe: A Generative AI-Powered Adaptive Interface to Support Intentionality in Planning and Running Video Meetings},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661507},
doi = {10.1145/3643834.3661507},
abstract = {Effective meetings are effortful, but traditional videoconferencing systems offer little support for reducing this effort across the meeting lifecycle. Generative AI (GenAI) has the potential to radically redefine meetings by augmenting intentional meeting behaviors. CoExplorer, our novel adaptive meeting prototype, preemptively generates likely phases that meetings would undergo, tools that allow capturing attendees’ thoughts before the meeting, and for each phase, window layouts, and appropriate applications and files. Using CoExplorer as a technology probe in a guided walkthrough, we studied its potential in a sample of participants from a global technology company. Our findings suggest that GenAI has the potential to help meetings stay on track and reduce workload, although concerns were raised about users’ agency, trust, and possible disruption to traditional meeting norms. We discuss these concerns and their design implications for the development of GenAI meeting technology.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {1638–1657},
numpages = {20},
keywords = {adaptive user interface, design, effectiveness, effort, intent recognition, speech recognition, technology probe, video meetings, windowing system},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3702212.3702217,
author = {Maguire, Joseph and English, Rosanne and Cao, Qi and Seow, Chee Kiat},
title = {Themes in the Declared Use of Generative Artificial Intelligence in Assessment},
year = {2025},
isbn = {9798400711725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702212.3702217},
doi = {10.1145/3702212.3702217},
abstract = {Generative Artificial Intelligence use by students completing assessments has been an area of concern for academics. Some educators believe such use will undermine all assessment, while others think it has the potential to revolutionise assessments. This has resulted in some institutions and educators adopting various approaches to control the use of Generative Artificial Intelligence However, much of this is taking place without fully appreciating how students are already making use of such tools. In this paper a practice where an existing assessment is presented with the addition that students are not prevented from using Generative Artificial Intelligence but must declare and explain such use. These declarations and explanations are considered to better understand how students approached the assessment and how it could be refined in future.},
booktitle = {Proceedings of the 9th Conference on Computing Education Practice},
pages = {17–20},
numpages = {4},
keywords = {cyber security, research-led teaching, artificial intelligence},
location = {
},
series = {CEP '25}
}

@inproceedings{10.1145/3708597.3708606,
author = {Han, Xiaotian},
title = {Generative Artificial Intelligence for Future Education: Current Research Status, Hot Spots, and Research Trends},
year = {2025},
isbn = {9798400718304},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708597.3708606},
doi = {10.1145/3708597.3708606},
abstract = {Generative artificial intelligence (GenAI), leveraging deep learning techniques such as neural networks, is revolutionizing education. This study explores the current research status, key areas, and emerging trends by analyzing 2,856 papers from 2014 to 2023 using CiteSpace software. Key findings reveal that: 1. The focus of GenAI research has shifted towards large language models, such as ChatGPT, especially since 2022. 2. Major research contributions come from China, the U.S., and South Korea, with China leading in institutional involvement. 3. Research trends indicate growing interest in AI applications for immersive education, deep learning models, and medical education. 4. Ethical considerations and data processing methodologies, including anomaly detection and data augmentation, are crucial emerging topics in the field. This paper outlines the most active research clusters and provides future directions for interdisciplinary applications and ethical AI.},
booktitle = {Proceedings of the 2024 8th International Conference on Algorithms, Computing and Systems},
pages = {56–61},
numpages = {6},
keywords = {Generative artificial intelligence 1, current research status 3, future educationn2, hot spots 4, research trends 5},
location = {
},
series = {ICACS '24}
}

@inproceedings{10.1145/3626252.3630927,
author = {Kirova, Vassilka D. and Ku, Cyril S. and Laracy, Joseph R. and Marlowe, Thomas J.},
title = {Software Engineering Education Must Adapt and Evolve for an LLM Environment},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630927},
doi = {10.1145/3626252.3630927},
abstract = {In the era of artificial intelligence (AI), generative AI, and Large Language Models (LLMs) in particular, have become increasingly significant in various sectors. LLMs such as GPT expand their applications, from content creation to advanced code completion. They offer unmatched opportunities but pose unique challenges to the software engineering domain. This paper discusses the necessity and urgency for software engineering education to adapt and evolve to prepare software engineers for the emerging LLM environment. While existing literature and social media have investigated AI's integration into various educational spheres, there is a conspicuous gap in examining the specifics of LLMs' implications for software engineering education. We explore the goals of software engineering education, and changes to software engineering, software engineering education, course pedagogy, and ethics. We argue that a holistic approach is needed, combining technical skills, ethical awareness, and adaptable learning strategies. This paper seeks to contribute to the ongoing conversation about the future of software engineering education, emphasizing the importance of adapting and evolving to remain in sync with rapid advancements in AI and LLMs. It is hoped that this exploration will provide valuable insights for educators, curriculum developers, and policymakers in software engineering.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {666–672},
numpages = {7},
keywords = {chatgpt, generative ai, large language models (llms), responsible ai, software engineering, software engineering education, software engineering ethics, software ethics},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inbook{10.1145/3724504.3724526,
author = {Zhang, Wenxiang and Liang, Zheng and Xie, Tao and Liu, Mingxing},
title = {Application of Generative Artificial Intelligence in the BOPPPS Teaching Model},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724526},
abstract = {With the rapid development of GenAI technologies represented by systems like ChatGPT and DALL-E, AI applications have become increasingly popular in aspects of content generation, logical reasoning, and learning evaluation. The BOPPPS (Bridge-in, Objective, Pre-assessment, Participatory learning, Post-assessment, Summary) teaching model provides a structured format for lesson planning and instruction, with the purpose of enhancing student learning and engagement. However, there are still some challenges in the use of the BOPPPS model in practice teaching. For instance, it will take a lot time and energy for teachers to prepare personalized learning resources in different forms and of high quality, and the assessment of students' learning outcomes is difficult to be performed in real time. The following paper discusses how to apply GenAI to the six steps of the BOPPPS teaching model, and in turn, assist the teacher with each of these areas.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {124–128},
numpages = {5}
}

@inproceedings{10.1145/3583780.3615314,
author = {Chen, Zheng and Jiang, Ziyan and Yang, Fan and He, Zhankui and Hou, Yupeng and Cho, Eunah and McAuley, Julian and Galstyan, Aram and Hu, Xiaohua and Yang, Jie},
title = {The First Workshop on Personalized Generative AI @ CIKM 2023: Personalization Meets Large Language Models},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615314},
doi = {10.1145/3583780.3615314},
abstract = {The First Workshop on Personalized Generative AI1 aims to be a cornerstone event fostering innovation and collaboration in the dynamic field of personalized AI. Leveraging the potent capabilities of Large Language Models (LLMs) to enhance user experiences with tailored responses and recommendations, the workshop is designed to address a range of pressing challenges including knowledge gap bridging, hallucination mitigation, and efficiency optimization in handling extensive user profiles. As a nexus for academics and industry professionals, the event promises rich discussions on a plethora of topics such as the development and fine-tuning of foundational models, strategies for multi-modal personalization, and the imperative ethical and privacy considerations in LLM deployment. Through a curated series of keynote speeches, insightful panel discussions, and hands-on sessions, the workshop aspires to be a catalyst in the development of more precise, contextually relevant, and user-centric AI systems. It aims to foster a landscape where generative AI systems are not only responsive but also anticipatory of individual user needs, marking a significant stride in personalized experiences.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {5267–5270},
numpages = {4},
keywords = {large language models, personalization},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3700297.3700308,
author = {Zhang, Qishan and Luo, Yuxin and Ren, Wenxuan and Mohamad, Syamsul Nor Azlan and Shi, Jingjing and Ning, Huichun},
title = {Path Exploration of Generative Artificial Intelligence Enabling the Construction of Civic Education in Primary and Secondary Schools},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700308},
doi = {10.1145/3700297.3700308},
abstract = {This study focuses on the application of generative artificial intelligence in the resource library for moral and civic education in primary and secondary schools, exploring its integration, evaluation, and development pathways for educational materials. Although AI technology has seen some practical applications in moral and civic education at the university level, research on its role in generating and evaluating localized materials for primary and secondary education remains insufficient. Through literature analysis, expert interviews, and qualitative coding, this study investigates the potential of generative AI to enhance the creation and assessment of educational materials in primary and secondary moral and civic education, aiming to fill the current research gap.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {59–64},
numpages = {6},
keywords = {Artificial intelligence, Civics Education Materials, Civics Resource Bank, Path Exploration},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3691720.3691809,
author = {Deng, Ming and Meng, Suying},
title = {Exploration and research of generative artificial intelligence on higher vocational education},
year = {2024},
isbn = {9798400710230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691720.3691809},
doi = {10.1145/3691720.3691809},
abstract = {Under the background of the rapid development of generative artificial intelligence, this paper deeply discusses the impact of generative artificial intelligence on higher vocational education, mainly from the following aspects. The first is the level of students, students in the knowledge acquisition, learning scene, learning experience, evaluation of the analysis; Secondly, at the level of teachers, teachers need to actively and quickly change the concept of education, shift the focus of work to ability cultivation, quality cultivation, psychological counseling, personality building, etc., to provide more emotional support for students. From the past "teacher - student" dual structure, to a new generation of learning mode, to achieve "teacher - machine - student" three-way collaborative intelligent learning state, accelerate the process of digital transformation of education. Then it discusses the risks and challenges brought by generative artificial intelligence to higher vocational education, and finally looks forward to the future of higher vocational education.},
booktitle = {Proceedings of the 2nd International Conference on Educational Knowledge and Informatization},
pages = {520–525},
numpages = {6},
location = {Shanghai, China},
series = {EKI '24}
}

@inproceedings{10.1145/3671151.3671178,
author = {Liao, Guangheng},
title = {Algorithm risks and governance considerations for Sora generative artificial intelligence},
year = {2024},
isbn = {9798400718106},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671151.3671178},
doi = {10.1145/3671151.3671178},
abstract = {Sora is an artificial intelligence cultural and biological video model released by the American artificial intelligence research company OpenAI. It is a generative artificial intelligence algorithm based on deep learning and neural network technology. Although this technology has made significant progress, it also comes with some potential algorithmic risks. With the development of technology, it is possible to further expand the risks caused by artificial intelligence, due to the delay in legal regulations in China during this process. The problem is analyzed as follows, and based on this, several opinions are proposed. The relevant issues are now analyzed.},
booktitle = {Proceedings of the 5th International Conference on Computer Information and Big Data Applications},
pages = {143–147},
numpages = {5},
location = {Wuhan, China},
series = {CIBDA '24}
}

@inproceedings{10.1145/3724504.3724537,
author = {Zhang, Wen-di and Dou, Huan-xin},
title = {Generation and Evaluation of International Chinese Teaching Resources by Generative Artificial Intelligence},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724537},
doi = {10.1145/3724504.3724537},
abstract = {Generative artificial intelligence has set off a new round of intelligent revolution and promoted the reform and development of the education industry. The development of international Chinese education also requires the digitalization and intelligence of international Chinese teaching resources. In this regard, this article utilizes the technology of ChatGPT platform to integrate teaching resources, constructs an artificial intelligence teaching resource generation framework consisting of demand analysis, intelligent generation, and quality assessment modules, as well as a quality evolution model of artificial intelligence international Chinese teaching resources. Based on this framework and resource quality evolution model, an experiment on the generation of artificial intelligence teaching resources was carried out, and inspections and evaluations were conducted from the perspectives of natural language processing technology, learners, and teachers. The results show that the teaching resources generated by artificial intelligence pass the inspection of natural language understanding technology and have good quality; learners and teachers are optimistic about the application of teaching resources in teaching and believe that most of these resources have reached a usable state; learners' overall experience in using teaching resources is positive and they believe that these resources can promote learning in many aspects. The application of artificial intelligence in generating teaching resources in this article helps to optimize the construction mode of international Chinese teaching resources and promote the high-quality development of international Chinese education.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {187–192},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, International Chinese Education, Teaching Resources},
location = {
},
series = {ICIEAI '24}
}

@inproceedings{10.1145/3613904.3642492,
author = {Newman, Michele and Sun, Kaiwen and Dalla Gasperina, Ilena B and Shin, Grace Y. and Pedraja, Matthew Kyle and Kanchi, Ritesh and Song, Maia B. and Li, Rannie and Lee, Jin Ha and Yip, Jason},
title = {"I want it to talk like Darth Vader": Helping Children Construct Creative Self-Efficacy with Generative AI},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642492},
doi = {10.1145/3613904.3642492},
abstract = {The emergence of generative artificial intelligence (GenAI) has ignited discussions surrounding its potential to enhance creative pursuits. However, distinctions between children’s and adult’s creative needs exist, which is important when considering the possibility of GenAI for children’s creative usage. Building upon work in Human-Computer Interaction (HCI), fostering children’s computational thinking skills, this study explores interactions between children (aged 7-13) and GenAI tools through methods of participatory design. We seek to answer two questions: (1) How do children in co-design workshops perceive GenAI tools and their usage for creative works? and (2) How do children navigate the creative process while using GenAI tools? How might these interactions support their confidence in their ability to create? Our findings contribute a model that describes the potential contexts underpinning child-GenAI creative interactions and explores implications of this model for theories of creativity, design, and use of GenAI as a constructionist tool for creative self-efficacy.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {117},
numpages = {18},
keywords = {Artificial Intelligence, Children, Co-Design, Constructionism, Creativity, Participatory Design},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3663384.3663389,
author = {Drosos, Ian and Sarkar, Advait and Xu, Xiaotong and Negreanu, Carina and Rintel, Sean and Tankelevitch, Lev},
title = {"It's like a rubber duck that talks back": Understanding Generative AI-Assisted Data Analysis Workflows through a Participatory Prompting Study},
year = {2024},
isbn = {9798400710179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663384.3663389},
doi = {10.1145/3663384.3663389},
abstract = {Generative AI tools can help users with many tasks. One such task is data analysis, which is notoriously challenging for non-expert end-users due to its expertise requirements, and where AI holds much potential, such as finding relevant data sources, proposing analysis strategies, and writing analysis code. To understand how data analysis workflows can be assisted or impaired by generative AI, we conducted a study (n=15) using Bing Chat via participatory prompting. Participatory prompting is a recently developed methodology in which users and researchers reflect together on tasks through co-engagement with generative AI. In this paper we demonstrate the value of the participatory prompting method. We found that generative AI benefits the information foraging and sensemaking loops of data analysis in specific ways, but also introduces its own barriers and challenges, arising from the difficulties of query formulation, specifying context, and verifying results.},
booktitle = {Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {16},
numpages = {21},
location = {Newcastle upon Tyne, United Kingdom},
series = {CHIWORK '24}
}

@inproceedings{10.1145/3657054.3659122,
author = {Hu, Shiming and Li, Yifan},
title = {Policy Interventions and Regulations on Generative Artificial Intelligence: Key Gaps and Core Challenges},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3659122},
doi = {10.1145/3657054.3659122},
abstract = {This study examines policy interventions and regulation of generative artificial intelligence (AI), focusing on key differences in generative AI policy in the EU, the US, and China. Using a comparative research methodology, the study analyzed the most recent policy documents from these regions through text-mining techniques to assess their key differences in terms of word frequency and specific content. This work highlights the different strategies, goals, and approaches to regulating generative AI across the regions. It found that the EU adopts a more comprehensive and stringent regulation of generative AI, emphasizing regional harmonization and foresight; the U.S. regulation is characterized by pragmatism, closely aligned with industry innovation, and a focus on risk avoidance; while China focuses more on macro-level regulation aimed at promoting innovation and encouraging ecological construction.Participants may be interested in this study because it not only uses up-to-date materials but also employs text-mining methods to present the findings in a clearer way than previous studies. It provides insights into how regulatory policies for generative AI affect the development and practice of digital government. The study sheds light on different countries’ strategies for technology governance, which is crucial for understanding and designing effective digital government policies. In addition, due to the potential of generative AI technologies to deliver public services and drive government transparency, these insights help participants better assess the opportunities and challenges of technological innovation in the digital government space.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {1034–1036},
numpages = {3},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

@inproceedings{10.1145/3649329.3656545,
author = {Guo, Shiyu and Ju, Yuhao and Chen, Xi and Gu, Jie},
title = {LLM-MARK:  A Computing Framework on Efficient Watermarking of Large Language Models for  Authentic Use of Generative AI at Local Devices},
year = {2024},
isbn = {9798400706011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649329.3656545},
doi = {10.1145/3649329.3656545},
abstract = {As generative AI such as ChatGPT rapidly evolves, the increasing incidence of data misconduct such as the proliferation of counterfeit news or unauthorized use of Large Language Models (LLMs) presents a significant challenge for consumers to obtain authentic information. While new watermarking schemes are recently being proposed to protect the intellectual property (IP) of LLM, the computation cost is unfortunately too high for the targeted real-time execution on local devices. In this work, a specialized hardware-efficient watermarking computing framework is proposed enabling model authentication at local devices. By employing the proposed hardware hashing for fast lookup and pruned bitonic sorting network acceleration, the developed architecture framework enables fast and efficient watermarking of LLM on the small local devices. The proposed architecture is evaluated on Xilinx XCZU15EG FPGA, demonstrating 30x computing speed-up, making this architecture highly suitable for integration into local mobile devices. The proposed algorithm to architecture codesign framework offers a practical solution to the immediate challenges posed by LLM misuse, providing a feasible hardware solution for Intellectual Property protection in the era of generative AI.},
booktitle = {Proceedings of the 61st ACM/IEEE Design Automation Conference},
articleno = {253},
numpages = {6},
location = {San Francisco, CA, USA},
series = {DAC '24}
}

@inproceedings{10.1145/3704289.3704293,
author = {Duah, James Ewert and Lu, Xin and McGivern, Paul and Jing, Yanguo},
title = {Interdisciplinary Perspectives on Generative Artificial Intelligence Adoption in Higher Education: A Theoretical Framework Review},
year = {2025},
isbn = {9798400716980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704289.3704293},
doi = {10.1145/3704289.3704293},
abstract = {The ongoing integration of Generative Artificial Intelligence (GenAI) within higher education (HE) signifies a pivotal shift in pedagogical paradigms, demanding comprehensive theoretical and practical considerations. This paper critically examines the multifaceted adoption of GenAI in HE by reviewing interdisciplinary theoretical frameworks from psychology, computer science, and pedagogy. It highlights the insufficiency of traditional technology acceptance models, which predominantly address cognitive and rational decision-making processes, and advocates for the inclusion of emotional and ethical dimensions often overlooked in existing frameworks. By synthesizing research across various disciplines, this review identifies significant gaps and proposes an integrated theoretical model to effectively understand and guide GenAI adoption. The proposed framework emphasizes the need for robust, empirically supported methodologies that accommodate the complex, dynamic nature of GenAI applications. This paper not only contributes to academic discourse by providing a comprehensive review of existing literature but also sets a foundation for future empirical studies aimed at refining GenAI integration strategies in HE, ensuring they are ethically aligned and educationally effective.},
booktitle = {Proceedings of the 2024 7th International Conference on Big Data and Education},
pages = {1–9},
numpages = {9},
keywords = {GenAI, Higher Education, Psychology, Theoretical Frameworks},
location = {
},
series = {ICBDE '24}
}

@inproceedings{10.1145/3650400.3650606,
author = {Xing, Kongduo},
title = {Design and implementation of digital training evaluation management system based on AI's generative AI technology},
year = {2024},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650400.3650606},
doi = {10.1145/3650400.3650606},
abstract = {With the advancement of information technology, traditional offline training is gradually giving way to online digital training. The conventional online digital training evaluation management system entails manual data collection followed by the utilization of these gathered data for training effectiveness assessment. This entire process is intricate and can introduce potential biases. To address these challenges, we have developed a digital training management system rooted in AI's generative AI technology. This innovative system employs both the fuzzy comprehensive evaluation method and the artificial intelligence evaluation method to assess the quality and effectiveness indexes of digital training. Furthermore, it is designed on the foundation of deep learning algorithms, creating an AI-driven digital training evaluation management system. To ensure the security and privacy of the system, extensive simulation experiments have been conducted. These experiments help control the deviation values of evaluation results, ultimately guaranteeing the fairness of outcomes generated by the evaluation system.},
booktitle = {Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1222–1226},
numpages = {5},
location = {Xiamen, China},
series = {EITCE '23}
}

@inbook{10.1145/3724504.3724511,
author = {Zhang, Shuai and Li, Hong and Chen, Xuanchao},
title = {The logical transformation and realization path of generative artificial intelligence empowerment instructional design from the perspective of digital transformation},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724511},
abstract = {The precise empowerment instructional design of generative artificial intelligence is a key means to promote and improve the quality of teaching, which responds to the urgent needs of China 's digital transformation. As a new generation of digital technology, generative artificial intelligence, with its powerful natural language processing capabilities, continues to have a profound impact on the innovation and change of teaching paradigm, teaching evaluation, teaching design, etc., and has broad prospects and potential in the field of education. Based on the background of digital transformation of education, this paper discusses the logical turn of generative artificial intelligence-enabled instructional design, namely, the change of teachers ' role, the change of training orientation, the change of teaching thinking, the change of resource generation and the change of teaching evaluation. After that, starting from the problems existing in the current teaching design, ( macro level : the integration of curriculum standards, the addition of teaching materials, and the support of learning segments; micro level : teaching design link, teaching process link, teaching evaluation link ) make a useful discussion on generative artificial intelligence to help solve the macro and micro level problems of teaching design. In order to better meet the teaching design of generative artificial intelligence empowerment.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {34–39},
numpages = {6}
}

@inproceedings{10.1145/3641555.3705080,
author = {Morales, Jamie and Raman, Preeti},
title = {Prompt-Engineering Strategies for Minimizing Bias in Large Language Model Outputs: Applications in Computing Education},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705080},
doi = {10.1145/3641555.3705080},
abstract = {As large language models (LLMs) increasingly permeate educational applications, concerns about the perpetuation of bias persist. We present our preliminary work on developing prompt-engineering strategies to mitigate bias in content generated by LLMs in computer science (CS) education. This work investigates both empirical insights into fairness-aware prompt formulation and actionable takeaways for educators. We focus on an initial list of prompting strategies for mitigating bias and explore their impact on educational content generation. Recent research has shown the efficacy of prompt-base debiasing [1] as well as the potential disadvantages of using prompts that have not been mitigated for bias, from user dissatisfaction [2] to unsafe outputs [5, 6]. Additionally, a growing body of empirical work points to the idea that certain properties of in-context examples such as flow [7], illustration [3], and order [4] could either improve or derail LLM performance. Our study leverages these findings in the context of generating educational content. The goal is to promote fairness-aware approaches which can be applied to the automated generation of learning materials and the development of LLM-based educational tools. This work also contributes practical insights on prompt-engineering to the evolving curriculum of Ethics in Artificial Intelligence (AI).},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1743},
numpages = {1},
keywords = {bias, education, ethics, generative ai, in-context examples, language model, language technology, llm, nlp, prompt-engineering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713971,
author = {Ravi, Prerna and Masla, John and Kakoti, Gisella and Lin, Grace C. and Anderson, Emma and Taylor, Matt and Ostrowski, Anastasia K. and Breazeal, Cynthia and Klopfer, Eric and Abelson, Hal},
title = {Co-designing Large Language Model Tools for Project-Based Learning with K12 Educators},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713971},
doi = {10.1145/3706598.3713971},
abstract = {The emergence of generative AI, particularly large language models (LLMs), has opened the door for student-centered and active learning methods like project-based learning (PBL). However, PBL poses practical implementation challenges for educators around project design and management, assessment, and balancing student guidance with student autonomy. The following research documents a co-design process with interdisciplinary K-12 teachers to explore and address the current PBL challenges they face. Through teacher-driven interviews, collaborative workshops, and iterative design of wireframes, we gathered evidence for ways LLMs can support teachers in implementing high-quality PBL pedagogy by automating routine tasks and enhancing personalized learning. Teachers in the study advocated for supporting their professional growth and augmenting their current roles without replacing them. They also identified affordances and challenges around classroom integration, including resource requirements and constraints, ethical concerns, and potential immediate and long-term impacts. Drawing on these, we propose design guidelines for future deployment of LLM tools in PBL.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {138},
numpages = {25},
keywords = {Generative AI, LLMs, AI for education, project-based learning, co-design, teachers, interviews},
location = {
},
series = {CHI '25}
}

@article{10.1145/3589659,
author = {Leong, Joanne},
title = {Using Generative AI to Cultivate Positive Emotions and Mindsets for Self-Development and Learning},
year = {2023},
issue_date = {Spring 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {3},
issn = {1528-4972},
url = {https://doi.org/10.1145/3589659},
doi = {10.1145/3589659},
abstract = {The arrival of new generative AI tools is creating waves. Here are some ideas for how we could channel them for supporting self-development and learning.},
journal = {XRDS},
month = apr,
pages = {52–56},
numpages = {5}
}

@inproceedings{10.1145/3657604.3662029,
author = {Li, Hai and Guo, Rui and Li, Chenglu and Xing, Wanli},
title = {Automated Quality Assessment of Multimodal Mathematical Stories Generated by Generative Artificial Intelligence},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662029},
doi = {10.1145/3657604.3662029},
abstract = {Mathematical stories have demonstrated the ability to bolster the motivation and interest of students in learning mathematics, thereby exerting a positive influence on their academic performance. However, due to a lack of adequate resources and the desire to engage students in the creation process, Generative Artificial Intelligence (GAI) is utilized to generate mathematical stories accompanied by images. This study presents a framework for automatic quality assessment to evaluate the coherence of multimodal text and images generated by GAI, as well as the appropriateness of the stories for different grade levels. The dataset comprises mathematical stories generated by GAI for grades 3, 4, and 5, obtained from an American online learning platform, each story consisting of titles, bodies, and image illustrations generated by GP4, images generated by DALL-E3. Initially, a method is devised based on CLIP model and Mini-GPT4 for extracting multimodal semantic features to establish the relationship between text and images in mathematical stories and their generation parameters. Subsequently, mathematical text features are designed, including nine mathematical text attributes and ten traditional text readability indicators, followed by collinearity feature selection and statistical testing. Finally, five machine learning grade regressor for mathematical stories were trained, and the correlation between these 19 features and grades is explored using genetic algorithm-based factor mining and the interpretable artificial intelligence method SHapley Additive exPlanations (SHAP). To further understand advanced text features, the latest natural language processing (NLP) readability indicators are also integrated into the analysis. Through multimodal features, traditional text readability metrics, and NLP readability indicators, this method introduces a novel approach for automatically assessing the quality of GAI-generated multimodal mathematical stories, providing a tool for grade predictor and shedding light on the factors (Image-text relevance and textual features) influencing the grade level of analyzed stories, thereby offering new insights for leveraging GAI in mathematical education.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {110–121},
numpages = {12},
keywords = {generative artificial intelligence, mathematical story, multimodal quality assessment, text readability},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3706598.3714121,
author = {Atcheson, Alex and Khan, Omar and Siemann, Brian and Jain, Anika and Karahalios, Karrie},
title = {"I'd Never Actually Realized How Big An Impact It Had Until Now": Perspectives of University Students with Disabilities on Generative Artificial Intelligence},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714121},
doi = {10.1145/3706598.3714121},
abstract = {Prior research on the experiences of students with disabilities in higher education has surfaced a number of barriers that prevent full inclusion. Generative artificial intelligence (GenAI) has begun to attract interest for its potential to address longstanding barriers to access. However, little is known about the impact of these tools on the living and learning experiences of post-secondary students with disabilities. As a mixed-abilities team, we investigated student experiences with GenAI tools by collecting survey and interview responses from 62 and 21 students with disabilities, respectively, across two universities to measure students’ use of GenAI tools and their perspectives on the impact of these tools in ways related to disability, university support, and sense of belonging. Despite concerns over potential risks of GenAI and unclear university policies, students described GenAI tools as a useful resource for personalizing learning, promoting self-care, and assisting with important self-advocacy work. Guidance demonstrating safe, acceptable uses of GenAI tools, along with clear policies and resources that acknowledge diverse student needs, were desired. We discuss implications of these tools for accessibility and inclusion in higher education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {42},
numpages = {22},
keywords = {Students with Disabilities, Higher Education, Generative Artificial Intelligence, Student Perspectives},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3677052.3698628,
author = {Noels, Sander and De Blaere, Jorne and De Bie, Tijl},
title = {A Dutch Financial Large Language Model},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698628},
doi = {10.1145/3677052.3698628},
abstract = {This paper presents FinGEITje, the first Dutch financial Large Language Model (LLM) specifically designed and optimized for various financial tasks. Together with the model, we release a specialized Dutch financial instruction tuning dataset with over 140,000 samples, constructed employing an automated translation and data processing method. The open-source data construction method is provided, facilitating the creation of financial instruction datasets in different languages. To evaluate model performance, the study introduces the first Dutch financial evaluation benchmark, along with an automated evaluation method that utilizes an LLM as an independent evaluator, reducing manual intervention in performance evaluation. The experimental results highlight the superior performance of FinGEITje across five critical Dutch and English financial tasks.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {283–291},
numpages = {9},
keywords = {Financial Large Language Model, Instruction Tuning., Natural Language Processing},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@article{10.1145/3731559,
author = {Pezz\`{e}, Mauro and Abrah\~{a}o, Silvia and Penzenstadler, Birgit and Poshyvanyk, Denys and Roychoudhury, Abhik and Yue, Tao},
title = {A 2030 Roadmap for Software Engineering},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3731559},
doi = {10.1145/3731559},
abstract = {The landscape of software engineering has dramatically changed in recent years. The impressive advances of artificial intelligence are just the latest and most disruptive innovation that has remarkably changed the software engineering research and practice. This special issue shares a roadmap to guide the software engineering community in this confused era. This roadmap is the outcome of a 2-day intensive discussion at the 2030 Software Engineering workshop. The roadmap spotlights and discusses seven main landmarks in the new software engineering landscape: artificial intelligence for software engineering, human aspects of software engineering, software security, verification and validation, sustainable software engineering, automatic programming, and quantum software engineering. This editorial summarizes the core aspects discussed in the 37 papers that comprise the seven sections of the special issue and guides the interested readers throughout the issue. This roadmap is a living body that we will refine with follow-up workshops that will update the roadmap for a series of forthcoming ACM TOSEM special issues.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {118},
numpages = {55},
keywords = {A roadmap for software engineering, AI and software engineering, Human factor in software engineering, Automatic Programming, Sustainable software engineering, Quantum software engineering, AI for verification and validation, security and software engineering, generative AI for software engineering, Large language models for software engineering}
}

@inproceedings{10.1145/3687311.3687415,
author = {Zhang, Yushuang and Miao, Miao},
title = {The Roles and Functions of Foreign Language Teachers of China in the Context of Generative Artificial Intelligence},
year = {2024},
isbn = {9798400709920},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687311.3687415},
doi = {10.1145/3687311.3687415},
abstract = {With the rapid development of Generative Artificial Intelligence (Generative AI) technology, its application in the field of foreign language teaching is becoming increasingly widespread, showing great potential for improving teaching efficiency and personalized learning in higher education. This paper discusses the application of Generative AI in foreign language teaching and analyzes teachers' roles and functions in this process. Teachers face challenges in adapting to this new technology, which calls for teachers to transform from authorities and disseminators of language knowledge to innovative designers, co-learner supporters, and navigators for future education.},
booktitle = {Proceedings of the 2024 International Conference on Intelligent Education and Computer Technology},
pages = {584–586},
numpages = {3},
location = {Guilin, China},
series = {IECT '24}
}

@proceedings{10.1145/3728725,
title = {GAIIS '25: Proceedings of the 2025 2nd International Conference on Generative Artificial Intelligence and Information Security},
year = {2025},
isbn = {9798400713453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3728725.3728728,
author = {Yang, Kai and Shi, Huaifeng and Wang, Rui and Zhou, Lei and Peng, Jiahui and Liu, Chaofan},
title = {Trend Decomposition Enhanced Large Language Model for Non-Stationary Network Traffic Prediction},
year = {2025},
isbn = {9798400713453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3728725.3728728},
doi = {10.1145/3728725.3728728},
abstract = {Regular network traffic prediction techniques, which generally rely on data normalization, often fail to account for the non-stable characteristics of network traffic, leading to a decline in estimate reliability. A novel approach to this problem is the Trend Decomposition Enhanced Large Language Model for Non-Static Network Traffic Prediction (TD-LLM). Applying trend decomposition as the preparation approach, the proposed strategy first divides raw information into resolved and non-fixed parts. The predetermined portion is standardized and processed, implementing a multi-head cross-attention mechanism, while a better self-attention mechanism improves the non-stationary element. Prompt engineering is used to create specially designed causes that serve as a guideline for the design throughout the forecast process. Finally, the processed data and creates are integrated into the large language model to produce the predicted results. In contrast to foundation models like Time- LLM, LSTM, Informer, and Transformer, the TD-LLM type drastically reduces mean squared error for network traffic prediction across many regions, according to exploratory evaluations, with decreases of 19.73 %, 54.71 %, 76.88 %, and 61.48 %, respectively.},
booktitle = {Proceedings of the 2025 2nd International Conference on Generative Artificial Intelligence and Information Security},
pages = {12–19},
numpages = {8},
keywords = {Large Language Model, Network Traffic Prediction, Non-Stationary Time Series, Prompt Engineering, Trend Decomposition},
location = {
},
series = {GAIIS '25}
}

@inproceedings{10.1145/3636555.3636856,
author = {Yan, Lixiang and Martinez-Maldonado, Roberto and Gasevic, Dragan},
title = {Generative Artificial Intelligence in Learning Analytics: Contextualising Opportunities and Challenges through the Learning Analytics Cycle},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636856},
doi = {10.1145/3636555.3636856},
abstract = {Generative artificial intelligence (GenAI), exemplified by ChatGPT, Midjourney, and other state-of-the-art large language models and diffusion models, holds significant potential for transforming education and enhancing human productivity. While the prevalence of GenAI in education has motivated numerous research initiatives, integrating these technologies within the learning analytics (LA) cycle and their implications for practical interventions remain underexplored. This paper delves into the prospective opportunities and challenges GenAI poses for advancing LA. We present a concise overview of the current GenAI landscape and contextualise its potential roles within Clow’s generic framework of the LA cycle. We posit that GenAI can play pivotal roles in analysing unstructured data, generating synthetic learner data, enriching multimodal learner interactions, advancing interactive and explanatory analytics, and facilitating personalisation and adaptive interventions. As the lines blur between learners and GenAI tools, a renewed understanding of learners is needed. Future research can delve deep into frameworks and methodologies that advocate for human-AI collaboration. The LA community can play a pivotal role in capturing data about human and AI contributions and exploring how they can collaborate most effectively. As LA advances, it is essential to consider the pedagogical implications and broader socioeconomic impact of GenAI for ensuring an inclusive future.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {101–111},
numpages = {11},
keywords = {ChatGPT, Midjourney, educational technology, generative artificial intelligence, human-AI collaboration, learning analytics},
location = {Kyoto, Japan},
series = {LAK '24}
}

@article{10.1145/3731626.3689825,
author = {Salhab, Reham},
title = {E-learning in the Generative Artificial Intelligence Era: Exploring the Middle Eastern context},
year = {2025},
issue_date = {04-01-2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2025},
number = {4},
url = {https://doi.org/10.1145/3731626.3689825},
doi = {10.1145/3731626.3689825},
abstract = {The objective of this article is to examine the potential benefits and challenges of generative artificial intelligence (GenAI) in e-learning in the Middle East region. Literature review was conducted and revealed several benefits of GenAI, including but not limited to: enhanced teaching practices, understanding, enhanced engagement, personalized learning promotion, flexibility, and enhanced academic performance. Some challenges are ethical and cultural considerations, data privacy, the digital divide, lower accuracy, and misleading information.},
journal = {ELearn},
month = apr,
articleno = {1}
}

@inproceedings{10.1145/3691016.3691035,
author = {Wu, Jinyong and Cui, Yujia and Cui, Yingwei},
title = {The image-generative artificial intelligence Midjourney empowers Chinese landscape painting teaching and creation with positive nurturing},
year = {2024},
isbn = {9798400710285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691016.3691035},
doi = {10.1145/3691016.3691035},
abstract = {This study explores the positive impacts of the image-generative AI, Midjourney, on teaching and creating Chinese landscape paintings. Amid the rapid development of image-generative AI, Midjourney acts as an "assistive creative tool" in the creation of Chinese landscape paintings. The visual effects generated by key descriptive words play a significant role in guiding landscape painters' innovative thinking, brush and ink techniques, and creative concepts, even forming new circles of innovative thinking. The process of "human-machine interaction" is analyzed through the principles of human-machine cooperative Chinese landscape painting, using Midjourney training as an example to explore the mechanisms and processes of generating stylized painting schemes.},
booktitle = {Proceedings of the 2024 International Conference on Image Processing, Intelligent Control and Computer Engineering},
pages = {104–108},
numpages = {5},
location = {Qingdao, China},
series = {IPICE '24}
}

@article{10.1145/3711061,
author = {Zhang, Zhiping and Shen, Chenxinran and Yao, Bingsheng and Wang, Dakuo and Li, Tianshi},
title = {Secret Use of Large Language Model (LLM)},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711061},
doi = {10.1145/3711061},
abstract = {The advancements of Large Language Models (LLMs) have decentralized the responsibility for the transparency of AI usage. Specifically, LLM users are now encouraged or required to disclose the use of LLM-generated content for varied types of real-world tasks. However, an emerging phenomenon, users' secret use of LLM, raises challenges in ensuring end users adhere to the transparency requirement. Our study used mixed-methods with an exploratory survey (125 real-world secret use cases reported) and a controlled experiment among 300 users to investigate the contexts and causes behind the secret use of LLMs. We found that such secretive behavior is often triggered by certain tasks, transcending demographic and personality differences among users. Task types were found to affect users' intentions to use secretive behavior, primarily through influencing perceived external judgment regarding LLM usage. Our results yield important insights for future work on designing interventions to encourage more transparent disclosure of the use of LLMs or other AI technologies.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW163},
numpages = {26},
keywords = {ai transparency, large-language models (llms), mixed-methods studies, privacy}
}

@article{10.1145/3732792,
author = {Hazzan, Orit and Erez, Yael},
title = {Rethinking Computer Science Education in the Age of GenAI},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3732792},
doi = {10.1145/3732792},
abstract = {In this opinion piece, we explore the idea that GenAI has the potential to fundamentally disrupt computer science education (CSE) by drawing insights from ten pedagogical and cognitive theories and models. We highlight how GenAI improves CSE by making educational practices more effective and requires less effort and time, and all at a lower cost, properties that have the potential to make GenAI a disruptive technology for CSE.Each of the ten theories and models examined serves as a lens through which we observe and interpret the impact of GenAI on CSE. The ten theories and models are grouped into three categories: Learning (Constructivism, Cognitive Load, and Motivation), Pedagogy (Bloom's Taxonomy, Assessment, Personalization/Diversity /Equity, and Didactic Transposition), and Competencies (the KSA Model, Computational Thinking, and Metacognition).},
note = {Just Accepted},
journal = {ACM Trans. Comput. Educ.},
month = apr,
keywords = {GenAI, computer science education, disruptive technology, learning, pedagogy, competencies}
}

@inproceedings{10.1145/3728725.3728736,
author = {Fang, Heng},
title = {ColKGC: Collaborative Enhancement using Large Language Model for Knowledge Graph Completion},
year = {2025},
isbn = {9798400713453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3728725.3728736},
doi = {10.1145/3728725.3728736},
abstract = {Knowledge Graph Completion (KGC) aims to address incomplete facts in Knowledge Graphs (KGs). As a mainstream approach for KGC, text-based methods are limited in performance due to insufficient knowledge caused by constraints in fine-tuning data. To incorporate broader external knowledge, some researchers explored KGC approaches based on large language models (LLMs), but general-purpose LLMs lack direct awareness of knowledge graph domain knowledge, making it challenging for them to independently perform KGC tasks. To balance the dependence of text-based methods on knowledge graph domain knowledge and LLMs on external knowledge, we propose Collaborative Enhancement using Large Language Model for KGC (ColKGC). We define the prompt template to implement the interaction between the text-based model and the LLMs, and divide the knowledge graph completion process into two stages. In the concept enhancement stage, we supplement the fine-tuning data by interacting with the prompts of the LLMs to enrich the graph domain knowledge learned by the text-based model. In completion inference stage, we adopted the iterative interaction strategy, taking the text-based model output as the prompt and taking the interaction content of the previous stage as the context to enhance the inference, which improved the LLMs' understanding of the KGC task. Our experiments demonstrate that ColKGC achieves superior results across various standard knowledge graph benchmarks. Extensive experiments also bear out ColKGC's efectiveness in generated data and the iterative interaction framework in assisting LLMs reasoning.},
booktitle = {Proceedings of the 2025 2nd International Conference on Generative Artificial Intelligence and Information Security},
pages = {66–71},
numpages = {6},
keywords = {Knowledge graph completion, Large language models, Link prediction},
location = {
},
series = {GAIIS '25}
}

@article{10.1145/3633287,
author = {Richards, Mike and Waugh, Kevin and Slaymaker, Mark and Petre, Marian and Woodthorpe, John and Gooch, Daniel},
title = {Bob or Bot: Exploring ChatGPT's Answers to University Computer Science Assessment},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
url = {https://doi.org/10.1145/3633287},
doi = {10.1145/3633287},
abstract = {Cheating has been a long-standing issue in university assessments. However, the release of ChatGPT and other free-to-use generative AI tools has provided a new and distinct method for cheating. Students can run many assessment questions through the tool and generate a superficially compelling answer, which may or may not be accurate.&nbsp;We ran a dual-anonymous “quality assurance” marking exercise across four end-of-module assessments across a distance university computer science (CS) curriculum. Each marker received five ChatGPT-generated scripts alongside 10 student scripts. A total of 90 scripts were marked; every ChatGPT-generated script for the undergraduate modules received at least a passing grade (&gt;40%), with all of the introductory module CS1 scripts receiving a distinction (&gt;85%). None of the ChatGPT-taught postgraduate scripts received a passing grade (&gt;50%). We also present the results of interviewing the markers and of running our sample scripts through a GPT-2 detector and the TurnItIn AI detector, which both identified every ChatGPT-generated script but differed in the number of false positives. As such, we contribute a baseline understanding of how the public release of generative AI is likely to significantly impact quality assurance processes. Our analysis demonstrates that in most cases, across a range of question formats, topics, and study levels, ChatGPT is at least capable of producing adequate answers for undergraduate assessment.},
journal = {ACM Trans. Comput. Educ.},
month = jan,
articleno = {5},
numpages = {32},
keywords = {ChatGPT, generative AI, cheating, quality assurance, university assessment’}
}

@article{10.1145/3708526,
author = {Moreira, Ana and Lago, Patricia and Heldal, Rogardt and Betz, Stefanie and Brooks, Ian and Capilla, Rafael and Coroam\u{a}, Vlad Constantin and Duboc, Leticia and Fernandes, Jo\~{a}o Paulo and Leifler, Ola and Nguyen, Ngoc-Thanh and Oyedeji, Shola and Penzenstadler, Birgit and Peters, Anne-Kathrin and Porras, Jari and Venters, Colin C.},
title = {A Roadmap for Integrating Sustainability into Software Engineering Education},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708526},
doi = {10.1145/3708526},
abstract = {The world faces escalating crises: record-breaking temperatures, widespread fires, severe flooding, increased oceanic microplastics, and unequal resource distribution. Academia introduces courses around sustainability to meet the new demand, but software engineering education lags behind. While software systems contribute to environmental issues through high energy consumption, they also hold the potential for solutions, such as more efficient and equitable resource management. Yet, sustainability remains a low priority for many businesses, including those in the digital sector. Business as usual is no longer viable. A transformational change in software engineering education is urgently needed. We must move beyond traditional curriculum models and fully integrate sustainability into every aspect of software development. By embedding sustainability as a core competency, we can equip future engineers not only to minimise harm but also to innovate solutions that drive positive, sustainable change. Only with such a shift can software engineering education meet the demands of a world in crisis and prepare students to lead the next generation of sustainable technology. This article discusses a set of challenges and proposes a customisable education roadmap for integrating sustainability into the software engineering curricula. These challenges reflect our perspective on key considerations, stemming from regular, intensive discussions in regular workshops among the authors and the community, as well as our extensive research and teaching experience in the field.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {139},
numpages = {27},
keywords = {Software engineering, Sustainability, Computing, Education, Software sustainability, Sustainable software, Sustainable development goals, Software competencies, Sustainability skills}
}

@inproceedings{10.1145/3706599.3719287,
author = {Oh, Sunggyeol and Zhao, Jiacheng and Russo, Carson and Bolmer, Michael},
title = {Boosting Diary Study Outcomes with a Fine-Tuned Large Language Model},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719287},
doi = {10.1145/3706599.3719287},
abstract = {This study explores fine-tuned Large Language Models (LLMs) integration into diary studies within the Human-Computer Interaction (HCI) field to enhance data collection and analysis. Leveraging a Mistral 7B model fine-tuned with a curated dataset of over 1,000 diary entries, this research addresses challenges such as participant engagement and data richness. The fine-tuned model offers personalized feedback, facilitating deeper reflection and structured recording while reducing the cognitive load on participants. The DiaryQuest educational platform, enhanced with advanced visualization tools and semantic search capabilities, enables educators to efficiently analyze diary data, extract thematic insights, and provide targeted guidance. Results from user evaluations reveal that the optimized platform improves learning outcomes, teaching efficiency, and overall user experience. By bridging traditional diary methodologies with state-of-the-art LLMs, this study advances HCI education and establishes a scalable framework for applying AI in broader educational and research contexts.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {896},
numpages = {7},
keywords = {Diary Study, Large Language Model},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3722237.3722377,
author = {Xu, Yao and Jian, Xiao},
title = {Generative Artificial Intelligence Empowers the Research of Digital Textbooks in Vocational Education},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722377},
doi = {10.1145/3722237.3722377},
abstract = {This research focuses on the application of AIGC in vocational education digital textbooks and how RAG technology can be used to further improve the interactivity and educational effectiveness of digital textbooks. The paper first analyzes the development of AIGC technology and its great potential in the field of education, especially the role of LLM in content generation. It then discusses the concept, risks, and construction strategies of vocational education digital textbooks, emphasizing the importance of digital textbooks in teaching and their differences compared with paper textbooks. The study also designs a knowledge retrieval question-answering system based on RAG, which combines school-based textbooks and cooperative enterprise manuals as a knowledge base to generate responses to student questions. While ensuring accuracy and completeness, the quality of the responses was improved by the merge of students' queries with relevant texts using RAG technology. Regarding implementation, RAG technology consists of knowledge base construction and knowledge retrieval. It includes segmenting the document, recognizing and vectorizing it in order to build a vector database. During user retrieval, queries are sorted through the vector database interface, and the matched knowledge fragments and query statements are merged to generate answers including specific domain knowledge. This framework of the RAG question-answering system can provide accurate answers to satisfy students of all levels in personalized teaching while maintaining explainability and timeliness of the content.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {802–806},
numpages = {5},
keywords = {Digital Textbooks, Retrieval-Augmented Generation, Vocational Education},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3706468.3706559,
author = {Li, Tongguang and Nath, Debarshi and Cheng, Yixin and Fan, Yizhou and Li, Xinyu and Rakovi\'{c}, Mladen and Khosravi, Hassan and Swiecki, Zachari and Tsai, Yi-Shan and Ga\v{s}evi\'{c}, Dragan},
title = {Turning Real-Time Analytics into Adaptive Scaffolds for Self-Regulated Learning Using Generative Artificial Intelligence},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706559},
doi = {10.1145/3706468.3706559},
abstract = {In computer-based learning environments (CBLEs), adopting effective self-regulated learning (SRL) strategies requires sophisticated coordination of multiple SRL processes. While various studies have proposed adaptive SRL scaffolds (i.e. real-time advice on adopting effective SRL processes) and embedded them in CBLEs to facilitate learners’ effective use of SRL strategies, two key research gaps remain. First, there is a lack of research on SRL scaffolds that are based on continuous assessment of both learners’ SRL processes and learning conditions (e.g., awareness of learning resources) to provide adaptive support. Second, current analytics-based scaffolding mechanisms lack the scalability needed to effectively address multiple learning conditions. Integration of analytics of SRL with generative artificial intelligence (GenAI) can provide scalable scaffolding for real-time SRL processes and evolving conditions. Yet, empirical studies implementing and evaluating effects of this integration remain scarce. To address these limitations, we conducted a randomized control trial, assigning participants to three groups (control, process only, and process with condition groups) to investigate the effects of using GenAI to turn insights from real-time analytics about students’ SRL processes and conditions into adaptive scaffolds. The results demonstrate that integrating real-time analytics with GenAI in adaptive SRL scaffolds – addressing both SRL processes and dynamic conditions – promotes more metacognitive learning patterns compared to the control and process-only groups. In addition, the learners showed varying levels of compliance with analytics-based GenAI scaffolds, and this was also reflected in how the learners coordinated their SRL processes, particularly in the performance phase of SRL. This study contributes to the literature by designing, implementing, and evaluating the impact of adaptive scaffolds on learners’ SRL processes using real-time analytics with GenAI.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {667–679},
numpages = {13},
keywords = {self-regulated learning, scaffolding compliance, GenAI, scaffolding, learning analytics},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3641554.3701873,
author = {Thorgeirsson, Sverrir and Ewen, Tracy and Su, Zhendong},
title = {What Can Computer Science Educators Learn From the Failures of Top-Down Pedagogy?},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701873},
doi = {10.1145/3641554.3701873},
abstract = {While educational researchers in various disciplines are grappling with how to develop policies and pedagogical approaches that address the use of generative artificial intelligence, the challenge is particularly complex in computer science education where the new technology is changing the core of the field. In this paper, we take a look at the pedagogy of other subjects with a longer history than computer science and a more extensive body of educational research to collect insights on how this challenge can be met. We begin by drawing from recent neurological research to find domains that share cognitive commonalities with computer programming and then build upon comparisons that others have made to literacy and mathematics education. We then consider how the "reading wars" and "math wars" have shaped these fields, which we see as conflicts between less effective top-down pedagogy and more effective bottom-up pedagogy, and reflect on what would be comparable approaches in teaching computing. We find that approaches that make heavy use of large language models without teaching fundamentals can be compared to the top-down pedagogy of reading and mathematics and are likely to be ineffective on their own. Therefore, we advise against the exclusive use of such approaches with novices. However, we also acknowledge that the social science surrounding computer science education is complex and that effectiveness only tells a part of the story, with other factors such as engagement, motivation and social dynamics also being important.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1127–1133},
numpages = {7},
keywords = {bottom-up pedagogy, computer science education, generative artificial intelligence, large language models, literacy, math wars, phonics, position paper, reading, reading wars, top-down pedagogy, whole language},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@proceedings{10.1145/3665348,
title = {GAIIS '24: Proceedings of the 2024 International Conference on Generative Artificial Intelligence and Information Security},
year = {2024},
isbn = {9798400709562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kuala Lumpur, Malaysia}
}

@inproceedings{10.1145/3706598.3714135,
author = {Chen, Wei-Hao and Tong, Weixi and Case, Amanda and Zhang, Tianyi},
title = {Dango: A Mixed-Initiative Data Wrangling System using Large Language Model},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714135},
doi = {10.1145/3706598.3714135},
abstract = {Data wrangling is a time-consuming and challenging task in a data science pipeline. While many tools have been proposed to automate or facilitate data wrangling, they often misinterpret user intent, especially in complex tasks. We propose Dango, a mixed-initiative multi-agent system for data wrangling. Compared to existing tools, Dango enhances user communication of intent by: (1) allowing users to demonstrate on multiple tables and use natural language prompts in a conversation interface, (2) enabling users to clarify their intent by answering LLM-posed multiple-choice clarification questions, and (3) providing multiple forms of feedback such as step-by-step NL explanations and data provenance to help users evaluate the data wrangling scripts. We conducted a within-subjects user study (n=38) and demonstrated that Dango’s features can significantly improve intent clarification, accuracy, and efficiency in data wrangling. Furthermore, we demonstrated the generalizability of Dango by applying it to a broader set of data wrangling tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {389},
numpages = {28},
keywords = {Data Wrangling, Data Science, Large Language Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3531146.3533077,
author = {Longoni, Chiara and Fradkin, Andrey and Cian, Luca and Pennycook, Gordon},
title = {News from Generative Artificial Intelligence Is Believed Less},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533077},
doi = {10.1145/3531146.3533077},
abstract = {Artificial Intelligence (AI) can generate text virtually indistinguishable from text written by humans. A key question, then, is whether people believe news headlines generated by AI as much as news headlines generated by humans. AI is viewed as lacking human motives and emotions, suggesting that people might view news written by AI as more accurate. By contrast, two pre-registered experiments on representative U.S. samples (N = 4,034) showed that people rated news headlines written by AI as less accurate than those written by humans. People were more likely to incorrectly rate news headlines written by AI (vs. a human) as inaccurate when they were actually true, and more likely to correctly rate them as inaccurate when they were indeed false. Our findings are important given the increasing adoption of AI in news generation, and the associated ethical and governance pressures to disclose it use and address standards of transparency and accountability.},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {97–106},
numpages = {10},
keywords = {algorithmic transparency, fairness, generative artificial intelligence, news, news generation},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@inproceedings{10.1145/3675417.3675574,
author = {Ji, Wei and Sun, Jian and Chen, Biaoxin and Luo, Chuangli},
title = {The Current Status and Trends of Research on the Impact of Generative Artificial Intelligence on Employment in China},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675417.3675574},
doi = {10.1145/3675417.3675574},
abstract = {With the increasing expansion of technology application scenarios, generative artificial intelligence is set to significantly boost global productivity and profoundly impact China's employment market. This article employs 218 academic papers from 2013 to 2023, featured in Peking University's core journals and CSSCI, focusing on generative AI's impact on China's job market, for quantitative analysis using CiteSpace software. Multidimensional exploration of research overviews and hotspots reveals that the evolving and rapid application of generative AI on China's employment market becomes more and more in-depth. On this basis, the paper analyzes the challenges and opportunities generative AI presents to China's job market and proposes corresponding strategies.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {948–953},
numpages = {6},
location = {Hongkong, China},
series = {DEAI '24}
}

@inproceedings{10.1145/3708036.3708229,
author = {Ma, Xiaoye and Liu, Weiheng and Zhao, Changyi and Tukhvatulina, Liliya R.},
title = {Can Large Language Model Predict Employee Atrition?},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708229},
doi = {10.1145/3708036.3708229},
abstract = {Employee attrition is a critical issue faced by organizations, with significant costs associated with turnover and the loss of valuable talent. Traditional methods for predicting attrition often rely on statistical techniques that, while useful, struggle to capture the com- plexity of modern workforces. Recent advancements in machine learning (ML) have provided more accurate, scalable solutions, al- lowing organizations to analyze diverse data points and predict attrition with greater precision. However, the emergence of large language models (LLMs) has opened new possibilities in human resource management by offering the ability to interpret contextual information from employee communications and detect subtle cues related to turnover.In this paper, we leverage the IBM HR Analytics Employee At- trition dataset to evaluate the effectiveness of a fine-tuned GPT-3.5 model in comparison to traditional machine learning classifiers, including Logistic Regression, k-Nearest Neighbors (KNN), Support Vector Machine (SVM), Decision Tree, Random Forest, AdaBoost, and XGBoost. Our study focuses on assessing the predictive power, interpretability, and real-world applicability of each model. While traditional models offer ease of use and transparency, LLMs have the potential to uncover more nuanced patterns in employee behavior. Through our analysis, we aim to provide practical insights for or- ganizations seeking to enhance their employee retention strategies with advanced predictive tools.Our results show that the fine-tuned GPT-3.5 large language model (LLM) outperforms traditional machine learning approaches in terms of prediction accuracy, with an impressive precision of 0.91, recall of 0.94, and an F1-score of 0.92. In contrast, the best-performing traditional model, Support Vector Machine (SVM), achieved an F1-score of 0.82, while ensemble methods like Random Forest and XGBoost reached F1-scores of 0.80. These findings highlight the ability of GPT-3.5 to capture complex patterns in employee behavior and attrition risks, offering enhanced interpretability by identifying subtle linguistic cues and recurring themes. This demonstrates the potential of integrating LLMs into HR strategies to significantly improve predictive performance and decision-making in employee retention.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {1164–1172},
numpages = {9},
keywords = {Business, LLM, Machine learning},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3641554.3701863,
author = {Raihan, Nishat and Siddiq, Mohammed Latif and Santos, Joanna C.S. and Zampieri, Marcos},
title = {Large Language Models in Computer Science Education: A Systematic Literature Review},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701863},
doi = {10.1145/3641554.3701863},
abstract = {Large language models (LLMs) are becoming increasingly better at a wide range of Natural Language Processing tasks (NLP), such as text generation and understanding. Recently, these models have extended their capabilities to coding tasks, bridging the gap between natural languages (NL) and programming languages (PL). Foundational models such as the Generative Pre-trained Transformer (GPT) and LLaMA series have set strong baseline performances in various NL and PL tasks. Additionally, several models have been fine-tuned specifically for code generation, showing significant improvements in code-related applications. Both foundational and fine-tuned models are increasingly used in education, helping students write, debug, and understand code. We present a comprehensive systematic literature review to examine the impact of LLMs in computer science and computer engineering education. We analyze their effectiveness in enhancing the learning experience, supporting personalized education, and aiding educators in curriculum development. We address five research questions to uncover insights into how LLMs contribute to educational outcomes, identify challenges, and suggest directions for future research.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {938–944},
numpages = {7},
keywords = {code generation, cs education, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3715602.3715612,
author = {Crandall, Johannah L. and Crandall, Aaron S.},
title = {Large Language Model-Supported Software Testing with the CS Matrix Taxonomy},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {New breakthroughs in code synthesis from Generative Pre-Trained Transformers (GPT) and Large Language Model (LLM) algorithms are driving significant changes to software engineering education. Having algorithms able to generate components of a software project means that software developers will need stronger skills in requirements specification to guide code generation as well as stronger skills in code review, testing, and integration to incorporate AI-generated code into projects. Shifts in industry and classroom practices are already occurring with the availability of inline code generation tools like GitHub's Copilot, which makes discussion of pedagogical strategies in this area a timely topic. Of immediate concern in computer science education is the potential for LLM-generated code and code help to undermine the learning of CS students. In order to avoid such undermining in even intentional uses of LLM-enhanced learning supports, it is necessary to clarify the roles such supports need to play in the pedagogical process. The Computer Science Matrix Taxonomy provides a strong framework for organizing software testing learning outcomes as well as delineating the operational space in which LLM-based feedback tools should operate to support those learning outcomes. In this paper, the authors operationalize the CS Matrix Taxonomy for software testing learning outcomes and illustrate the integration of LLM-generated test strategy suggestions as an extension of the peer coding/testing model. The work includes examples of AI-generated code testing suggestions that students would use to help guide their own code synthesis for assignments or projects.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {49–58},
numpages = {10}
}

@inproceedings{10.1145/3649217.3653570,
author = {Frazier, Matthew and Damevski, Kostadin and Pollock, Lori},
title = {Customizing ChatGPT to Help Computer Science Principles Students Learn Through Conversation},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653570},
doi = {10.1145/3649217.3653570},
abstract = {This paper explores leveraging conversational agents, specifically ChatGPT, to enhance the introduction of computing, focused on the Advanced Placement Computer Science Principles (CSP) course in secondary schools. Despite the potential benefits for diverse student audiences, little research has investigated their effectiveness and engagement in this context. We examine the customization of ChatGPT for secondary school CSP students, assessing its impact on exploratory searches for learning CSP concepts. Results from 20 high school students in grades 10-12 (ages 15-18) in a CSP course indicate that students preferred a customized ChatGPT, with its terminology more suitable to secondary school level, examples more understandable, and better connections to personal experiences compared to standard ChatGPT.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {633–639},
numpages = {7},
keywords = {chatgpt, computer science principles, conversational agent, exploratory search},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3717383.3721236,
author = {Rathore, Santosh Singh and Tiwari, Saurabh and Farooq, Sheikh Umar},
title = {Seventh Workshop on Emerging Software Engineering Education(WESEE 2025)},
year = {2025},
isbn = {9798400714245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3717383.3721236},
doi = {10.1145/3717383.3721236},
abstract = {The seventh Workshop on Emerging Software Engineering Education (WESEE) aims to discuss and examine the development of learning environments that are influencing the pedagogical strategies for the education of software engineering courses in institutions, specifically through the adoption of Generative AI (GenAI) tools and techniques. Additionally, the workshop aims to examine how industries are utilizing GenAI tools and technologies for teaching software development methods and how the developers are utilizing the material for self-learning and skill acquisition. The report is an overview of the upcoming seventh edition of WESEE, which will be held on 20th February 2025 at NIT Kurukshetra. The workshop will be held alongside the 18th Innovations in Software Engineering Conference (ISEC 2025).},
booktitle = {Proceedings of the 18th Innovations in Software Engineering Conference},
articleno = {22},
numpages = {3},
location = {
},
series = {ISEC '25}
}

@article{10.1145/3708524,
author = {Robinson, Diana and Cabrera, Christian and Gordon, Andrew D. and Lawrence, Neil D. and Mennen, Lars},
title = {Requirements Are All You Need: The Final Frontier for End-User Software Engineering},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708524},
doi = {10.1145/3708524},
abstract = {What if end-users could own the software development lifecycle from conception to deployment using only requirements expressed in language, images, video or audio? We explore this idea, building on the capabilities that Generative AI brings to software generation and maintenance techniques. How could designing software in this way better serve end-users? What are the implications of this process for the future of end-user software engineering and the software development lifecycle? We discuss the research needed to bridge the gap between where we are today and these imagined systems of the future.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {141},
numpages = {22},
keywords = {End-User Software Engineering, End-User Programming, Large Language Models}
}

@inproceedings{10.1145/3700297.3700395,
author = {Qi, Wenqian and Liu, Mengmeng and Li, Na and Qu, Chenfei and Wang, Shaoqing and Li, Yuanmeng and Zhao, Mengyue and Liu, Chao},
title = {Introduction to the research on the path of generative artificial intelligence technology ChatGPT to help teachers' professional development},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700395},
doi = {10.1145/3700297.3700395},
abstract = {This research explores the application of ChatGPT, a generative artificial intelligence technology, in the field of education. ChatGPT, short for "generative pre-training," continuously evolves and adapts through user feedback, facilitating authentic human-machine interaction. It can process natural language input and generate relevant responses, thereby providing information and answering questions. The study highlights the potential of ChatGPT in university teacher education, where it can offer intelligent teaching assistance, personalized learning resources, and instructional support. However, the integration of ChatGPT also raises challenges, such as redefining the authority of knowledge and altering the dynamics of the teacher-student relationship. Some scholars contend that ChatGPT cannot replicate genuine emotions or free will, underscoring the irreplaceable nature of education. The transformative impact of ChatGPT on education demands a reevaluation of teachers' roles and professional development in the digital age. This study seeks to clarify the role of teachers within the digital transformation represented by ChatGPT and to explore strategies for successfully navigating this shift. Additionally, the research aims to assess teachers' perceptions and utilization of ChatGPT, address related challenges, and evaluate the feasibility, potential applications, and limitations of its integration into teaching.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {568–573},
numpages = {6},
keywords = {ChatGPT, Teacher, professional development},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3660043.3660178,
author = {Ma, Shuaiyao and Lei, Lei},
title = {Opportunities and Challenges of Generative Artificial Intelligence in Facilitating Learning for Chinese University Students},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660178},
doi = {10.1145/3660043.3660178},
abstract = {With the emergence of Artificial Intelligence in General Chat (AIGC), represented by ChatGPT, collaborative learning tasks between university students and machines have become a new norm in higher education. Simply prohibiting this new wave of technology cannot fundamentally address its challenges. This article presents the results of a survey investigating Chinese university students' perspectives on generative artificial intelligence technologies, such as ChatGPT, in supporting their learning. It analyzes the opportunities and challenges presented by this technology. Universities need to adapt to this transformation by altering the nature of student assignments and the methods of assessment. Additionally, they must effectively leverage the advantages of students conveniently acquiring knowledge through AIGC and the opportunity for personalized tutoring across various subjects. Striking the right balance between opportunities and challenges is crucial for creating a more productive and beneficial learning environment. Ultimately, this adaptation will better prepare education for the developments and changes in the era of artificial intelligence.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {756–760},
numpages = {5},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@inproceedings{10.1145/3701716.3715295,
author = {Yuan, Shen and Gong, Shukai and Xu, Hongteng},
title = {USPTO-LLM: A Large Language Model-Assisted Information-enriched Chemical Reaction Dataset},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715295},
doi = {10.1145/3701716.3715295},
abstract = {Over the past few years, the machine learning community has given increasing attention to chemical reaction prediction and retrosynthesis. Despite impressive achievements, the existing datasets in this field have gradually become the bottleneck of current research --- the limitation of dataset size and the lack of reaction condition information hinder the practicability of the current methods. In this study, we construct an information-enriched chemical reaction dataset called USPTO-LLM, with the help of large language models (LLMs). This dataset comprises over 247K chemical reactions extracted from the patent documents of USPTO (United States Patent and Trademark Office), encompassing abundant information on reaction conditions. We employ large language models to expedite the data collection procedures automatically with a reliable quality control process. Experiments show that USPTO-LLM helps pre-train the existing retrosynthesis methods and the condition information in the dataset helps improve the model performance. The dataset is open-sourced at https://zenodo.org/records/14396156 and the annotation code is open-sourced at https://github.com/GONGSHUKAI/USPTO_LLM.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {817–820},
numpages = {4},
keywords = {chemical reaction data, large language model, retrosynthesis},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3696500.3696575,
author = {Ran, Xiaoping and zeng, yuyue},
title = {Research on the scenario application of generative artificial intelligence in ideological and political education of colleges and universities},
year = {2024},
isbn = {9798400710278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696500.3696575},
doi = {10.1145/3696500.3696575},
abstract = {with the rapid development of generative artificial intelligence technology, its application in the field of education is increasingly extensive. The positions outside the first classroom, such as the university network space, the campus environment and the community activities, are loose but most active and most vital, schools should take the initiative to occupy and timely implantation of ideological and political elements (hereinafter referred to as extracurricular ideological and political education). The generative artificial intelligence, represented by CHATGPT, which is embedded in the extracurricular ideological and political education work as a scientific and technological tool, is the frontier and hot spot of the current network ideological and Political Education Research, it can make the educators understand the object of education more efficiently and systematically, enrich the existing educational resources and forms, and further strengthen the effect of extra-curricular ideological and political education. The purpose of this paper is to explore how generative artificial intelligence can enhance the effectiveness, attraction and participation of extracurricular ideological and political education in colleges and universities.},
booktitle = {Proceedings of the 2024 International Conference on Big Data and Digital Management},
pages = {454–459},
numpages = {6},
location = {Shanghai, China},
series = {ICBDDM '24}
}

@inproceedings{10.1145/3641399.3641436,
author = {Rathore, Santosh Singh and Tiwari, Saurabh and Farooq, Sheikh Umar},
title = {Workshop Report on Emerging Software Engineering Education},
year = {2024},
isbn = {9798400717673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641399.3641436},
doi = {10.1145/3641399.3641436},
abstract = {Software engineering is rapidly adapting to meet the demands of contemporary customers and the challenges posed by relentless technological advancements. A well-prepared and highly competent workforce is crucial to propel this evolution, making it a pivotal element for the successful future of software engineering. To instill the art and science of software engineering across diverse age groups, innovative teaching methods must be introduced at all levels of education dissemination. Software engineering stands out as one of the most dynamic subjects in computer science curricula, spanning both undergraduate and postgraduate levels, given the continuous emergence of new software development process models, methods, and tools. A comprehensive software engineering course should encompass various processes, methods, and tools necessary to support large-scale software systems’ development, operation, and maintenance. Moreover, these courses should significantly emphasize developing the interpersonal and communication skills essential for a well-rounded software engineer.},
booktitle = {Proceedings of the 17th Innovations in Software Engineering Conference},
articleno = {20},
numpages = {2},
keywords = {Collaborative and Creative Software Engineering, Large Language models (LLMs) in software engineering education, Software engineering education},
location = {Bangalore, India},
series = {ISEC '24}
}

@inproceedings{10.1145/3649217.3653624,
author = {Grande, Virginia and Kiesler, Natalie and Francisco R., Mar\'{\i}a Andre\'{\i}na},
title = {Student Perspectives on Using a Large Language Model (LLM) for an Assignment on Professional Ethics},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653624},
doi = {10.1145/3649217.3653624},
abstract = {The advent of Large Language Models (LLMs) started a serious discussion among educators on how LLMs would affect, e.g., curricula, assessments, and students' competencies. Generative AI and LLMs also raised ethical questions and concerns for computing educators and professionals.This experience report presents an assignment within a course on professional competencies, including some related to ethics, that computing master's students need in their careers. For the assignment, student groups discussed the ethical process by Lennerfors et al. by analyzing a case: a fictional researcher considers whether to attend the real CHI 2024 conference in Hawaii. The tasks were (1) to participate in in-class discussions on the case, (2) to use an LLM of their choice as a discussion partner for said case, and (3) to document both discussions, reflecting on their use of the LLM.Students reported positive experiences with the LLM as a way to increase their knowledge and understanding, although some identified limitations. The LLM provided a wider set of options for action in the studied case, including unfeasible ones. The LLM would not select a course of action, so students had to choose themselves, which they saw as coherent.From the educators' perspective, there is a need for more instruction for students using LLMs: some students did not perceive the tools as such but rather as an authoritative knowledge base. Therefore, this work has implications for educators considering the use of LLMs as discussion partners or tools to practice critical thinking, especially in computing ethics education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {478–484},
numpages = {7},
keywords = {chatgpt, ethics, experience report, large language models, llms, student perspective},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3706468.3706566,
author = {Yeung, Steven},
title = {A comparative study of rule-based, machine learning and large language model approaches in automated writing evaluation (AWE)},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706566},
doi = {10.1145/3706468.3706566},
abstract = {Automated Writing Evaluation (AWE) tools have proved beneficial to writing development. Research on AWE methods is essential for improving tool performance and further comparative studies are needed as new methods emerge. This study examines the performance of several AWE approaches, comparing rule-based and statistical methods, machine learning (ML) models, and a large language model (LLM). These three AWE methods were applied to a representative sample of academic essays from the TOEFL11 dataset to compare their assessment performance. Results show that the selected LLM, GPT-4, outperformed the other two approaches in terms of QWK and Pearson’s correlation coefficient, while the Support Vector Machine (SVM) model in the ML approach had the highest accuracy and the lowest mean absolute error. This paper provides a detailed comparison of these three approaches and discusses implications for educational practice and future research around AWE.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {984–991},
numpages = {8},
keywords = {Rule-based method, machine learning, large language model, automated writing evaluation, automated essay scoring, generative AI},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3689492.3690050,
author = {Padhye, Rohan},
title = {Software Engineering Methods for AI-Driven Deductive Legal Reasoning},
year = {2024},
isbn = {9798400712159},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689492.3690050},
doi = {10.1145/3689492.3690050},
abstract = {The recent proliferation of generative artificial intelligence (AI) technologies such as pre-trained large language models (LLMs) has opened up new frontiers in computational law. An exciting area of development is the use of AI to automate the deductive rule-based reasoning inherent in statutory and contract law. This paper argues that such automated deductive legal reasoning can now be viewed from the lens of software engineering, treating LLMs as interpreters of natural-language programs with natural-language inputs. We show how it is possible to apply principled software engineering techniques to enhance AI-driven legal reasoning of complex statutes and to unlock new applications in automated meta-reasoning such as mutation-guided example generation and metamorphic property-based testing.},
booktitle = {Proceedings of the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {85–95},
numpages = {11},
keywords = {computational law, example generation, generative artificial intelligence, large language models, legal reasoning, mutation testing, property-based testing, software engineering, statutory reasoning},
location = {Pasadena, CA, USA},
series = {Onward! '24}
}

@article{10.1145/3674149,
author = {Mendon\c{c}a, Nabor C.},
title = {Evaluating ChatGPT-4 Vision on Brazil's National Undergraduate Computer Science Exam},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
url = {https://doi.org/10.1145/3674149},
doi = {10.1145/3674149},
abstract = {The recent integration of visual capabilities into Large Language Models (LLMs) has the potential to play a pivotal role in science and technology education, where visual elements such as diagrams, charts, and tables are commonly used to improve the learning experience. This study investigates the performance of ChatGPT-4 Vision, OpenAI’s most advanced visual model at the time the study was conducted, on the Bachelor in Computer Science section of Brazil’s 2021 National Undergraduate Exam (ENADE). By presenting the model with the exam’s open and multiple-choice questions in their original image format and allowing for reassessment in response to differing answer keys, we were able to evaluate the model’s reasoning and self-reflecting capabilities in a large-scale academic assessment involving textual and visual content. ChatGPT-4 Vision significantly outperformed the average exam participant, positioning itself within the top 10 best score percentile. While it excelled in questions that incorporated visual elements, it also encountered challenges with question interpretation, logical reasoning, and visual acuity. A positive correlation between the model’s performance in multiple-choice questions and the performance distribution of the human participants suggests multimodal LLMs can provide a useful tool for question testing and refinement. However, the involvement of an independent expert panel to review cases of disagreement between the model and the answer key revealed some poorly constructed questions containing vague or ambiguous statements, calling attention to the critical need for improved question design in future exams. Our findings suggest that while ChatGPT-4 Vision shows promise in multimodal academic evaluations, human oversight remains crucial for verifying the model’s accuracy and ensuring the fairness of high-stakes educational exams. The paper’s research materials are publicly available at .},
journal = {ACM Trans. Comput. Educ.},
month = aug,
articleno = {37},
numpages = {56},
keywords = {Multimodal generative AI, ChatGPT-4 vision, educational assessment, computer science education}
}

@article{10.1145/3715964,
author = {Susnjak, Teo and Hwang, Peter and Reyes, Napoleon and Barczak, Andre L. C. and McIntosh, Timothy and Ranathunga, Surangika},
title = {Automating Research Synthesis with Domain-Specific Large Language Model Fine-Tuning},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1556-4681},
url = {https://doi.org/10.1145/3715964},
doi = {10.1145/3715964},
abstract = {This research pioneers the use of fine-tuned Large Language Models (LLMs) to automate Systematic Literature Reviews (SLRs), presenting a significant and novel contribution in integrating AI to enhance academic research methodologies. Our study employed advanced fine-tuning methodologies on open sourced LLMs, applying textual data mining techniques to automate the knowledge discovery and synthesis phases of an SLR process, thus demonstrating a practical and efficient approach for extracting and analyzing high-quality information from large academic datasets. The results maintained high fidelity in factual accuracy in LLM responses, and were validated through the replication of an existing PRISMA-conforming SLR. Our research proposed solutions for mitigating LLM hallucination and proposed mechanisms for tracking LLM responses to their sources of information, thus demonstrating how this approach can meet the rigorous demands of scholarly research. The findings ultimately confirmed the potential of fine-tuned LLMs in streamlining various labor-intensive processes of conducting literature reviews. As a scalable proof-of-concept, this study highlights the broad applicability of our approach across multiple research domains. The potential demonstrated here advocates for updates to PRISMA reporting guidelines, incorporating AI-driven processes to ensure methodological transparency and reliability in future SLRs. This study broadens the appeal of AI-enhanced tools across various academic and research fields, demonstrating how to conduct comprehensive and accurate literature reviews with more efficiency in the face of ever-increasing volumes of academic studies while maintaining high standards.},
journal = {ACM Trans. Knowl. Discov. Data},
month = mar,
articleno = {68},
numpages = {39},
keywords = {AI-Assisted Literature Review, Text Mining for Research Synthesis, LLM Fine-tuning, Systematic Literature Review Automation, Retrieval-Augmented Generation for Research, Domain-Specific Model Training, Knowledge Synthesis AI, AI-Driven Research, Literature Review Automation, Generative AI, AI-Enhanced Systematic Reviews, PRISMA and AI, Question and Answering}
}

@inproceedings{10.1145/3708036.3708272,
author = {Yang, Guangyuan and Xie, Quanying and Chen, Lei},
title = {A Scientometrics Analysis and Visualization of Large Language Model in China's Library},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708272},
doi = {10.1145/3708036.3708272},
abstract = {Large Language Model has been researched in the field of library from the following aspects:space reproduction, service reform, library construction and so on. In order to clarify the current research situation of Large Language Model's application research in the field of library, and provide some reference for the further development of research fields related to Large Language Model empowering library in the future. This paper utilizes two methods of scientometrics and data visualization to analyze and study the journal papers on the application of Large Language Model in the field of Chinese libraries from the aspects of the degree of academic focus, the way of creating academic achievements and research topics of academic achievements, and puts forward the research practice of strengthening the application of Large Language Model in library from the aspects of ’Strengthen the practical research of Large Language Model empowering Chinese library’ and ‘Broaden the field of research related to Large Language Model empowering Chinese library’, in order to promote the all-round development of Large Language Model in the field of library.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {1403–1407},
numpages = {5},
keywords = {Chinese libraries, Data Visualization, Large Language Model, Library Service, Scientometrics},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3643690.3648236,
author = {Hamza, Muhammad and Siemon, Dominik and Akbar, Muhammad Azeem and Rahman, Tahsinur},
title = {Human-AI Collaboration in Software Engineering: Lessons Learned from a Hands-On Workshop},
year = {2024},
isbn = {9798400705717},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643690.3648236},
doi = {10.1145/3643690.3648236},
abstract = {This paper investigates the dynamics of human-AI collaboration in software engineering, focusing on the use of ChatGPT. Through a thematic analysis of a hands-on workshop in which 22 professional software engineers collaborated for three hours with ChatGPT, we explore the transition of AI from a mere tool to a collaborative partner. The study identifies key themes such as the evolving nature of human-AI interaction, the capabilities of AI in software engineering tasks, and the challenges and limitations of integrating AI in this domain. The findings show that while AI, particularly ChatGPT, improves the efficiency of code generation and optimization, human oversight remains crucial, especially in areas requiring complex problem-solving and security considerations. This research contributes to the theoretical understanding of human-AI collaboration in software engineering and provides practical insights for effectively integrating AI tools into development processes. It highlights the need for clear role allocation, effective communication, and balanced AI-human collaboration to realize the full potential of AI in software engineering.},
booktitle = {Proceedings of the 7th ACM/IEEE International Workshop on Software-Intensive Business},
pages = {7–14},
numpages = {8},
keywords = {generative AI, ChatGPT, software engineering, workshop, empirical investigation},
location = {Lisbon, Portugal},
series = {IWSiB '24}
}

@inproceedings{10.1145/3649217.3653543,
author = {Bassner, Patrick and Frankford, Eduard and Krusche, Stephan},
title = {Iris: An AI-Driven Virtual Tutor for Computer Science Education},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653543},
doi = {10.1145/3649217.3653543},
abstract = {Integrating AI-driven tools in higher education is an emerging area with transformative potential. This paper introduces Iris, a chat-based virtual tutor integrated into the interactive learning platform Artemis that offers personalized, context-aware assistance in large-scale educational settings. Iris supports computer science students by guiding them through programming exercises and is designed to act as a tutor in a didactically meaningful way. Its calibrated assistance avoids revealing complete solutions, offering subtle hints or counter-questions to foster independent problem-solving skills. For each question, it issues multiple prompts in a Chain-of-Thought to GPT-3.5-Turbo. The prompts include a tutor role description and examples of meaningful answers through few-shot learning. Iris employs contextual awareness by accessing the problem statement, student code, and automated feedback to provide tailored advice. An empirical evaluation shows that students perceive Iris as effective because it understands their questions, provides relevant support, and contributes to the learning process. While students consider Iris a valuable tool for programming exercises and homework, they also feel confident solving programming tasks in computer-based exams without Iris. The findings underscore students' appreciation for Iris' immediate and personalized support, though students predominantly view it as a complement to, rather than a replacement for, human tutors. Nevertheless, Iris creates a space for students to ask questions without being judged by others.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {394–400},
numpages = {7},
keywords = {chatgpt, cs1, education technology, generative ai, interactive learning, large language models, programming exercises},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626253.3635408,
author = {Xiang, Lili},
title = {SQL Query Evaluation with Large Language Model and Abstract Syntax Trees},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635408},
doi = {10.1145/3626253.3635408},
abstract = {SQL stands as the foundational language for data analysis and manipulation, playing a pivotal role in the database learning process. Proficiency in SQL is essential for students seeking to excel in data-related fields. However, the conventional approaches to assessing SQL queries rely heavily on manual grading, and the automated assessment tools are usually producing only binary decisions for the submitted queries. Our primary research objective is to develop effective methods for evaluating the quality of the SQL queries. To meet this objective, we introduce two approaches: structure-based analysis and evaluation by an instruction tuned large language model (LLM). The first approach deconstructs queries into Abstract Syntax Trees (AST) and employs cosine similarity to assess student submissions. The second approach utilizes a pre-trained LLM: FLAN-T5, fine-tuned for predicting the quality of student submissions. These methodologies are tested on a SQL dataset, and our experimental findings evaluate against a grading rubric with categories ranging from "good" to "unacceptable". The experimental results demonstrate that we can enhance the grading efficiency by applying these approaches and illustrate the ability of utilizing LLM to classify the assessed SQL statements more accurately. In addition, this research contributes to Computer Science (CS) education by integrating these approaches into our team's automated SQL statement assessment tool, improving the learning experience and evaluation process.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1890},
numpages = {1},
keywords = {abstract syntax trees, auto-grader, cs education, large language model, sql},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3616961.3616974,
author = {Rajala, Jaakko and Hukkanen, Jenni and Hartikainen, Maria and Niemel\"{a}, Pia},
title = {"\"Call me Kiran\" – ChatGPT as a Tutoring Chatbot in a Computer Science Course"},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616974},
doi = {10.1145/3616961.3616974},
abstract = {Natural language processing has taken enormous steps during the last few years. The development of large language models and generative AI has elevated natural language processing to the level that it can output coherent and contextually relevant text for a given natural language prompt. ChatGPT is one incarnation of these steps, and its use in education is a rather new phenomenon. In this paper, we study students’ perception on ChatGPT during a computer science course. On the course, we integrated ChatGPT into Teams private discussion groups. In addition, all the students had freedom to employ ChatGPT and related technologies to help them in their coursework. The results show that the majority of students had at least tested AI-powered chatbots, and that students are using AI-powered chatbots for multiple tasks, e.g., debugging code, tutoring, and enhancing comprehension. The amount of positive implications of using ChatGPT takes over the negative implications, when the implications were considered from an understanding, learning and creativity perspective. Relatively many students reported reliability issues with the outputs and that the iterations with prompts might be necessary for satisfactory outputs. It is important to try to steer the usage of ChatGPT so that it complements students’ learning processes, but does not replace it.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {83–94},
numpages = {12},
keywords = {ChatGPT, artificial intelligence, chatbots, discussion forum, education, generative AI, student perceptions, tutoring},
location = {Tampere, Finland},
series = {Mindtrek '23}
}

@inproceedings{10.1145/3702163.3702169,
author = {Bergerhoff, Jan and Bendler, Johannes and Stefanov, Stefan and Cavinato, Enrico and Esser, Leonard and Tran, Tommy and H\"{a}rm\"{a}, Aki},
title = {Automatic conversational assessment using large language model technology},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702169},
doi = {10.1145/3702163.3702169},
abstract = {Student evaluation is an important, yet costly, part of instruction. Traditional exams are a burden for teachers and stressful for students. This paper uses a large language model (LLM) technology to create a system for Automated Conversational Assessment, ACA, where a dialog system, based on content and intended learning outcomes, interviews the student to determine the level of learning. In a pilot experiment in a university course, we found that the ACA system scores correlate with the grades given by a human and also have a positive correlation with the results of a conventional exam of the same students. Based on a questionnaire study, the students responded that the assessment was perceived to be fair and acceptable.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {39–45},
numpages = {7},
keywords = {Automatic assessment, LLM-driven examination, Artificial Intelligence, Education Technology},
location = {
},
series = {ICETC '24}
}

@article{10.1145/3712002,
author = {Murillo, Juan Manuel and Garcia-Alonso, Jose and Moguel, Enrique and Barzen, Johanna and Leymann, Frank and Ali, Shaukat and Yue, Tao and Arcaini, Paolo and P\'{e}rez-Castillo, Ricardo and Garc\'{\i}a-Rodr\'{\i}guez de Guzm\'{a}n, Ignacio and Piattini, Mario and Ruiz-Cort\'{e}s, Antonio and Brogi, Antonio and Zhao, Jianjun and Miranskyy, Andriy and Wimmer, Manuel},
title = {Quantum Software Engineering: Roadmap and Challenges Ahead},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712002},
doi = {10.1145/3712002},
abstract = {As quantum computers advance, the complexity of the software they can execute increases as well. To ensure this software is efficient, maintainable, reusable, and cost-effective—key qualities of any industry-grade software—mature software engineering practices must be applied throughout its design, development, and operation. However, the significant differences between classical and quantum software make it challenging to directly apply classical software engineering methods to quantum systems. This challenge has led to the emergence of Quantum Software Engineering (QSE) as a distinct field within the broader software engineering landscape. In this work, a group of active researchers analyze in depth the current state of QSE research. From this analysis, the key areas of QSE are identified and explored in order to determine the most relevant open challenges that should be addressed in the next years. These challenges help identify necessary breakthroughs and future research directions for advancing QSE.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {154},
numpages = {48},
keywords = {Quantum Software Engineering, open challenges, Quantum Computing, QSE}
}

@inproceedings{10.1145/3708359.3712156,
author = {Chen, Chaoran and Zhou, Daodao and Ye, Yanfang and Li, Toby Jia-Jun and Yao, Yaxing},
title = {CLEAR: Towards Contextual LLM-Empowered Privacy Policy Analysis and Risk Generation for Large Language Model Applications},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712156},
doi = {10.1145/3708359.3712156},
abstract = {The rise of end-user applications powered by large language models (LLMs), including both conversational interfaces and add-ons to existing graphical user interfaces (GUIs), introduces new privacy challenges. However, many users remain unaware of the risks. This paper explores methods to increase user awareness of privacy risks associated with LLMs in end-user applications. We conducted five co-design workshops to uncover user privacy concerns and their demand for contextual privacy information within LLMs. Based on these insights, we developed CLEAR (Contextual LLM-Empowered Privacy Policy Analysis and Risk Generation), a just-in-time contextual assistant designed to help users identify sensitive information, summarize relevant privacy policies, and highlight potential risks when sharing information with LLMs. We evaluated the usability and usefulness of CLEAR across two example domains: ChatGPT and the Gemini plugin in Gmail. Our findings demonstrated that CLEAR is easy to use and improves users’ understanding of data practices and privacy risks. We also discussed LLM’s duality in posing and mitigating privacy risks, offering design and policy implications.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {277–297},
numpages = {21},
keywords = {large language model, privacy awareness, privacy intervention, privacy literacy},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3641554.3701917,
author = {Wang, Kevin Shukang and Lawrence, Ramon},
title = {Quantitative Evaluation of Using Large Language Models and Retrieval-Augmented Generation in Computer Science Education},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701917},
doi = {10.1145/3641554.3701917},
abstract = {Generative artificial intelligence (GenAI) is transforming Computer Science education, and every instructor is reflecting on how AI will impact their courses. Instructors must determine how students may use AI for course activities and what AI systems they will support and encourage students to use. This task is challenging with the proliferation of large language models (LLMs) and related AI systems. The contribution of this work is an experimental evaluation of the performance of multiple open-source and commercial LLMs utilizing retrieval-augmented generation in answering questions for computer science courses and a cost-benefit analysis for instructors when determining what systems to use. A key factor is the time an instructor has to maintain their supported AI systems and the most effective activities for improving their performance. The paper offers recommendations for deploying, using, and enhancing AI in educational settings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1183–1189},
numpages = {7},
keywords = {artificial intelligence, human-in-the-loop, large language model, question answering, retrieval-augmented generation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705267,
author = {Zabir, Zubair and Tisha, Sirazum Munira},
title = {The Role of Virtual Reality in Enhancing Computer Science Education},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705267},
doi = {10.1145/3641555.3705267},
abstract = {This paper examines the application of Virtual Reality (VR) in com- puter science education through a review of 28 academic papers. The study investigates VR's effectiveness in teaching complex topics such as finite state machines, computational thinking, and algo- rithms. The authors highlight VR's advantages, including immersive learning experiences and intuitive visualization of abstract concepts, while also noting challenges such as high costs and limited acces- sibility. The analysis reveals critical research gaps, including the need to evaluate VR's cost-effectiveness, scalability, integration with AI for adaptive learning, and support for diverse learners. To address these gaps, the paper proposes research questions for future investigations. While underscoring VR's potential to revolutionize computer science education, the study emphasizes the need for further research to optimize its implementation and effectiveness.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1673–1674},
numpages = {2},
keywords = {artificial intelligence, computer science education, immersive learning, virtual reality},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3614407.3643696,
author = {Lee, Katherine and Cooper, A. Feder and Grimmelmann, James},
title = {Talkin' 'Bout AI Generation: Copyright and the Generative-AI Supply Chain (The Short Version)},
year = {2024},
isbn = {9798400703331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614407.3643696},
doi = {10.1145/3614407.3643696},
abstract = {"Does generative AI infringe copyright?" is an urgent question. It is also a difficult question, for two reasons. First, "generative AI" is not just one product from one company. It is a catch-all name for a massive ecosystem of loosely related technologies. These systems behave differently and raise different legal issues. Second, copyright law is notoriously complicated, and generative-AI systems manage to touch on a great many corners of it. They raise issues of authorship, similarity, direct and indirect liability, and fair use, among much else. These issues cannot be analyzed in isolation, because there are connections everywhere. We aim to bring order to the chaos. To do so, we introduce the generative-AI supply chain: an interconnected set of stages that transform training data into generations. The supply chain reveals all of the places at which companies and users make choices that have copyright consequences. It enables us to trace the effects of upstream technical designs on downstream uses, and to assess who in these complicated sociotechnical systems bears responsibility for infringement when it happens. Because we engage so closely with the technology of generative AI, we are able to shed more light on the copyright questions. We identify the key decisions that courts will need to make as they grapple with these issues, and point out the consequences that would likely flow from different liability regimes. This article is a much-abbreviated version of a forthcoming law review article at The Journal of the Copyright Society.},
booktitle = {Proceedings of the 2024 Symposium on Computer Science and Law},
pages = {48–63},
numpages = {16},
location = {Boston, MA, USA},
series = {CSLAW '24}
}

@inproceedings{10.1145/3675417.3675461,
author = {Liu, Shitou and Liang, Zhenjie and Zhang, Ling},
title = {Analyzing Key Influencing Factors of University Teachers45 Use of Generative Artificial Intelligence in a Small-Sample Data Environment},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675417.3675461},
doi = {10.1145/3675417.3675461},
abstract = {This study focuses on exploring the key factors influencing the use of generative artificial intelligence (AI) by university teachers in the context of digital education, particularly in the backdrop of human-computer interaction. Considering the challenges posed by small-sample data, we employed various machine learning models such as linear regression, random forest regression, and support vector regression (SVR), and optimized model parameters through grid search and cross-validation techniques. The optimized models exhibited significantly improved performance, with the linear regression model showing a mean squared error (MSE) of 0.1239 and an R² score of 0.6362, indicating its good predictive accuracy and generalization ability on the small-sample dataset. The study results emphasize performance expectations, perceived value, and community influence as primary influencing factors for university teachers' use of generative AI, especially in the context of human-computer interaction. This is crucial for understanding and promoting the acceptance and use of educational technology. This research provides valuable insights for education policymakers and technology developers and offers important methodological guidance for machine learning applications dealing with small-sample data.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {271–279},
numpages = {9},
location = {Hongkong, China},
series = {DEAI '24}
}

@inproceedings{10.1145/3706598.3713205,
author = {Monge Roffarello, Alberto and Cal\`{o}, Tommaso and Scibetta, Luca and De Russis, Luigi},
title = {Investigating How Computer Science Researchers Design Their Co-Writing Experiences With AI},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713205},
doi = {10.1145/3706598.3713205},
abstract = {Recent advancements in AI have significantly enhanced collaboration between humans and writing assistants. However, empirical evidence is still lacking on how this collaboration unfolds in scientific writing, especially considering the variety of tools researchers can use nowadays. We conducted observations and retrospective interviews to investigate how 19 computer science researchers collaborated with intelligent writing assistants while working on their ongoing projects. We adopted a design-in-use lens to analyze the collected data, exploring how researchers adapt writing assistants during their use to overcome challenges and meet their specific needs and preferences. Our findings identify issues such as workflow disruptions and over-reliance on AI, and reveal five distinct design-in-use styles—teaching, resisting, repurposing, orchestrating, and complying—each consisting of different practices used by researchers. This study contributes to understanding the evolving landscape of human-AI co-writing in scientific research and offers insights for designing more effective writing assistants.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1215},
numpages = {17},
keywords = {Generative AI, scientific writing, writing assistants, design-in-use},
location = {
},
series = {CHI '25}
}

@article{10.1145/3725529,
author = {Lambiase, Stefano and Catolino, Gemma and Palomba, Fabio and Ferrucci, Filomena and Russo, Daniel},
title = {Investigating the Role of Cultural Values in Adopting Large Language Models for Software Engineering},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3725529},
doi = {10.1145/3725529},
abstract = {As a socio-technical activity, software development involves the close interconnection of people and technology. The integration of Large Language Models (LLMs) into this process exemplifies the socio-technical nature of software development. Although LLMs influence the development process, software development remains fundamentally human-centric, necessitating an investigation of the human factors in this adoption. Thus, with this study we explore the factors influencing the adoption of LLMs in software development, focusing on the role of professionals’ cultural values. Guided by the Unified Theory of Acceptance and Use of Technology (UTAUT2) and Hofstede’s cultural dimensions, we hypothesized that cultural values moderate the relationships within the UTAUT2 framework. Using Partial Least Squares-Structural Equation Modelling and data from 188 software engineers, we found that habit and performance expectancy are the primary drivers of LLM adoption, while cultural values do not significantly moderate this process. These findings suggest that, by highlighting how LLMs can boost performance and efficiency, organizations can encourage their use, no matter the cultural differences. Practical steps include offering training programs to demonstrate LLM benefits, creating a supportive environment for regular use, and continuously tracking and sharing performance improvements from using LLMs.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
keywords = {UTAUT2, Culture, Hofstede, Generative AI, LLM, Empirical Software Engineering}
}

@inproceedings{10.1145/3649405.3659512,
author = {Gutica, Mirela},
title = {Fostering Teamwork in Software Engineering Projects},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659512},
doi = {10.1145/3649405.3659512},
abstract = {Part of computer science disciplines, software engineering (SE) is concerned with the software lifecycle and the rigorous methods and processes required for designing, implementing, modifying and maintaining high-quality software systems. Project-based and experiential learning are core to developing SE competencies and skills. Besides technical competencies, soft skills including adaptability, communication, critical thinking and teamwork are required and highly valued by employers. Several aspects affect the success of a project: the student engagement and participation, the team's dynamics and diversity, the mentoring strategy and the peer feedback process. Important aspects of teamwork are achievement of a high-level of cohesiveness between team members, and effective communication. However, we found that these aspects are impacted by deterrents to diversity and inclusion, and are not always achieved. The purpose of this study is to explore instructional models for teaching SE project courses that foster diversity and inclusion in teamwork, and promote engagement.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {820},
numpages = {1},
keywords = {diversity and inclusion, software engineering, teamwork},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3701716.3717544,
author = {Lu, Zhicheng and Moni, Mohammad Ali and Chung, Yuk Ying and Cai, Weidong and Chen, Xiaoming},
title = {LLM-UM: The 1st&nbsp;Workshop on Large Language Model Using Multi-modal Data for User Modeling},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717544},
doi = {10.1145/3701716.3717544},
abstract = {Web-based user modeling is important because it enables personalized experiences by analyzing users' online behavior, preferences, and interactions, allowing systems to deliver tailored content, recommendations, and services in real-time. The workshop will explore cutting-edge approaches to enhancing user models through the integration of diverse data modalities. The discussions will begin with an introduction to the fundamental concepts of large language models (LLMs), including their architectures and applications in user-centric systems. The workshop will also introduce important ethical and technical considerations surrounding multi-modal data use. Issues such as data bias, privacy concerns, and the ethical implications of modeling users based on extensive personal data will be thoroughly examined. Additionally, the workshop will focus on future trends and innovations in the field, including emerging modalities like AR/VR data and the growing importance of real-time adaptation in user models. A discussion will provide an opportunity for collaboration, allowing participants to share their own experiences, challenges, and ideas for pushing the boundaries of multi-modal LLMs in user modeling.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2225–2228},
numpages = {4},
keywords = {large language model, multi-modal data, user modeling},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3617553.3617887,
author = {Fulcini, Tommaso and Torchiano, Marco},
title = {Is ChatGPT Capable of Crafting Gamification Strategies for Software Engineering Tasks?},
year = {2023},
isbn = {9798400703737},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617553.3617887},
doi = {10.1145/3617553.3617887},
abstract = {Gamification has gained significant attention in the last decade for its potential to enhance engagement and motivation in various domains. During the last year ChatGPT, a state-of-the-art large language model has received even more attention both in the field of scientific research and in common use by individuals or companies.  
In this study, we investigate the possibility of adopting ChatGPT as a tool for designing gamification platforms in the Software Engineering domain. Leveraging the capabilities of ChatGPT, we assess how good is it at generating effective suggestions and ideas for designers or developers.  
To evaluate ChatGPT's potential as a gamification platform creator we narrowed the context to one particular Software Engineering activity, asking for possible aspects of the activity to be gamified. Each proposed aspect was subsequently unraveled by ChatGPT both asking in a shared and separate context, first following the conversational nature of the model, then applying a validated design framework. The study assesses ChatGPT's ability to select and integrate game elements to build a thriving gamification environment by framing the design of the platform to a state-of-the-art conceptual framework. To evaluate the goodness of the design choices made we relied both on the Octalysis framework and on personal experience.  
The findings of the papers show that ChatGPT can only create simple playful experiences not very effective. Although, by instructing the model with more specific desired mechanics and dynamics, it is possible to guide it toward the application of the ideas suggested. We argue that ChatGPT is not capable of building a gamified environment on its own, but it could still be used to build the foundation of a gamification platform as long as the designers refine and rough out the advice gained from a user-centered solution.},
booktitle = {Proceedings of the 2nd International Workshop on Gamification in Software Development, Verification, and Validation},
pages = {22–28},
numpages = {7},
keywords = {Artificial Intelligence, Gamification, Large Language Model, Software Engineering, Software Lifecycle},
location = {San Francisco, CA, USA},
series = {Gamify 2023}
}

@article{10.1145/3717825,
author = {Kugler, Logan},
title = {Computer Science Under Trump},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0001-0782},
url = {https://doi.org/10.1145/3717825},
doi = {10.1145/3717825},
abstract = {Experts say that computer science could look a lot different under the new administration.},
note = {Online First},
journal = {Commun. ACM},
month = feb,
numpages = {4}
}

@inproceedings{10.1145/3729605.3729639,
author = {Zhang, Qingpu},
title = {Park Message Recommendation System Based on Large Language Model And Evaluation Metrics},
year = {2025},
isbn = {9798400714405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3729605.3729639},
doi = {10.1145/3729605.3729639},
abstract = {With the continuous development of the park, it is necessary for the park managers to get the information related to the development of the park in time, so it becomes more important to build a message recommendation system for the managers of science and technology parks. We propose an message recommendation algorithm that combines the large language model and the park evaluation metrics, and there are two main innovations: one is to fine-tune the large language model to do the message representation, so as to synthesize the open general knowledge of the large language model and improve the model's representation of the message; the other is to embed the evaluation information of the users into the user's representation, analyze the data of the parks, and derive the labels of each park using the hierarchical analysis method. Then we use the label to generate new message for the user's representation, which makes the representation of the user more accurate. Finally, we conducted experiments on the paper and patent dataset, which showed that using the algorithm can improve the accuracy of the recommendation system.},
booktitle = {Proceedings of the 2025 International Conference on Big Data and Informatization Education},
pages = {190–195},
numpages = {6},
keywords = {LLM, Park message recommendation, hierarchical analysis method evaluation},
location = {
},
series = {ICBDIE '25}
}

@article{10.1145/3709147,
author = {Mu, Jie and Wang, Wei and Liu, Wenqi and Yan, Tiantian and Wang, Guanglu},
title = {Multimodal Large Language Model with LoRA Fine-Tuning for Multimodal Sentiment Analysis},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3709147},
doi = {10.1145/3709147},
abstract = {Multimodal sentiment analysis has become a popular research topic in recent years. However, existing methods have two unaddressed limitations: (1) they use limited supervised labels to train models, which makes it impossible for model to fully learn sentiments in different modal data; (2) they employ text and image pre-trained models trained in different unimodal tasks to extract different modal features, so that the extracted features cannot take into account the interactive information between image and text. To solve these problems, in this paper we propose a Vision-Language Contrastive Learning network (VLCLNet). First, we introduce a pre-trained Large Language Model (LLM), which is trained from vast quantities of multimodal data, has better understanding ability for image and text contents, thus being effectively applied to different tasks while requiring few amount of labelled training data. Second, we adapt a Multimodal Large Language Model (MLLM), BLIP-2 (Bootstrapping Language-Image Pre-training) network, to extract multimodal fusion feature. Such MLLM can fully consider the correlation between images and texts when extracting features. In addition, due to the discrepancy between the pre-training task and the sentiment analysis task, the pre-trained model will output the suboptimal prediction results. We use LoRA (Low-Rank Adaptation) fine-tuning strategy to update the model parameters on sentiment analysis task, which avoids the issue of inconsistent task between pre-training task and downstream task. Experiments verify that the proposed VLCLNet is superior to other strong baselines.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = dec,
keywords = {Deep learning, Large language model, Multimodal representation learning, Sentiment analysis}
}

@inproceedings{10.1145/3711403.3711408,
author = {Song, Ningning and Han, Fengwu and He, Pengyang},
title = {The Research on the Influencing Factors of College Students'Dishonest Behaviors in Online Learning in the background of Generative Artificial Intelligence},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711408},
doi = {10.1145/3711403.3711408},
abstract = {With the popularity of online learning and the development of generative artificial intelligence technology, a significant scale of dishonest behaviors have emerged in the online learning environment, directly harming the construction and development of online learning ecology. Therefore, based on the Theory of Planned Behavior (TPB) and Self-Determination Theory (SDT), this study adopts the method of structural equation model to deeply understand the influencing factors of college students' dishonest behaviors in online learning under the background of generative artificial intelligence. The results show that attitude, perceived behavioral control, and subjective norm all have a significant positive impact on behavior intention of dishonesty when online learning. Specifically, the attitude of dishonest behaviors in online learning is influenced by autonomous motivation (e.g., intrinsic interest, self-improvement) and controlled motivation (e.g., external rewards, avoidance of punishments); perceived behavioral control is influenced by autonomous motivation, controlled motivation, and moral obligation; and the subjective norm is not only affected by autonomous motivation but also by moral obligation. Based on this, this study proposes some interventions to mitigate dishonest behaviors in online learning to create a good learning atmosphere for the online learning environment.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {28–35},
numpages = {8},
keywords = {Dishonest behaviors, Online learning, Structural equation model},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3641554.3701832,
author = {Koitz-Hristov, Roxane and Mandl, Franz and Wotawa, Franz},
title = {VisOpt - Visualization of Compiler Optimizations for Computer Science Education},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701832},
doi = {10.1145/3641554.3701832},
abstract = {Visualizations in teaching have become a common practice as they effectively convey theoretical concepts. Compiler construction, a heavily theory-based subject in computer science education, is particularly challenging for students to understand. While many tools simulate a compiler's front end, or analysis phase, applications that focus on the back end, or synthesis phase, are scarce. This paper describes VisOpt, a web-based visualization tool designed for a master's level Compiler Construction course. VisOptfocuses on the synthesis phase, i.e., code optimization and code generation. Its primary objective is to help students comprehend various local compiler optimizations, which can be visualized on the original code, an intermediate representation, or an assembler-like target code. A quasi-experiment with a pre-test-post-test design revealed that students who used VisOpt reported higher self-efficacy compared to those who did not. Although no significant improvement in learning outcomes was observed overall, we propose VisOpt as an engaging pedagogical tool that effectively complements traditional methods for teaching the synthesis phase of compilers.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {603–609},
numpages = {7},
keywords = {compiler optimization, compiler visualization, computer science education, simulation software, visualization},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3709352,
author = {K\"{o}nig, Christoph and Lang, Daniel J. and Schaefer, Ina},
title = {Sustainable Software Engineering: Concepts, Challenges, and Vision},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3709352},
doi = {10.1145/3709352},
abstract = {Information and communication technology (ICT) offers promising opportunities to address global sustainability challenges such as climate change and social inequality by enabling energy savings and social innovations. At the same time, ICT threatens to exacerbate these crises, as evident in the increasing consumption of resources and widening digital inequalities. As one of the enablers of ICT, software engineering plays a key role to tackle the problems and explore the potentials of ICT for sustainability. However, sustainability in software engineering is still a niche topic, with little structure, a limited understanding of sustainability and few comprehensive strategies. In this article, we introduce the main concepts of Sustainable Software Engineering, critically review the state of research and identify seven future research challenges across all research areas. We further present our research vision—sustainability-driven software engineering and transdisciplinary research formats—and outline a research roadmap with the key steps to be achieved by 2030.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {135},
numpages = {28},
keywords = {Sustainability, Sustainable development, ICT, Sustainable Software Engineering, Sustainability assessments, Transdisciplinary research, Real-world lab}
}

@inproceedings{10.1145/3660650.3660668,
author = {Rajabi, Parsa},
title = {Experience Report: Adopting AI-Usage Policy in Software Engineering Education},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660668},
doi = {10.1145/3660650.3660668},
abstract = {This report examines the introduction of an AI-usage policy within a Software Engineering course, aiming to overcome the challenges of incorporating generative AI (genAI) tools in academic settings. As the debate around the impact of technologies like ChatGPT in education continues, this policy represents a proactive stance, addressing both the opportunities and risks associated with AI tool usage. With N=86 students, this course implemented a policy that promotes responsible AI use through guidelines and an "AI-usage disclosure" form for coursework submissions. This approach sought to improve AI literacy, ensure academic integrity, and mitigate potential academic misconduct cases. Despite challenges, including adherence to AI disclosures and the evolving definition of AI tools, the policy promoted a more inclusive learning environment and encouraged a deeper understanding of AI’s role and limitations in computer science education. The findings highlight the need for ongoing policy revisions to adapt to technological advancements, emphasizing the pilot as an essential step towards integrating AI responsibly in educational contexts.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {19},
numpages = {2},
keywords = {AI in Education, AI-usage Policy, Academic Integrity, ChatGPT, Software Engineering Education},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3702163.3702182,
author = {Yaqub, Irfan and Chen, Zhiyuan and Liao, Iman Yi and Maul, Tomas and Seow, Hsin-Vonn and Chandesa, Tissa},
title = {A Novel Framework using Large Language Models to Automate Coursework Feedback for Computer Science modules},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702182},
doi = {10.1145/3702163.3702182},
abstract = {Prompt and sufficient feedback is essential for students' academic learning since it enables them to review their learning techniques and improve their areas of weakness. Nevertheless, delivering personalised feedback to every student continues to be difficult&nbsp;for teachers due to its demanding and time-intensive nature. While automated feedback systems are available, their primary focus is providing feedback on a single subject, and most of them utilise statistical analysis or traditional machine learning techniques to provide feedback. Moreover, no feedback model utilises the same criteria to generate text-based feedback for more than one subject. Generative artificial intelligence (GEN AI) has recently made incredible progress, and large language models (LLMs) can retain the context from the vast amount of text. Hence, this research presents a framework that employs an innovative technique to offer text-based feedback to students in different fields of study. This framework employs two LLMs, one for generating the feedback and another for categorising it into separate subjects using suitable headings for structural organising. Consequently, the output produced by this technology corresponds to the original tone of the teacher.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {130–137},
numpages = {8},
keywords = {Deep Learning Artificial Intelligence, Generative Artificial Intelligence, Large Language Model},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3708359.3712106,
author = {Zeng, Xiyin and Zhou, Qianyi and Liu, Shouqiang},
title = {SAE: A Multimodal Sentiment Analysis Large Language Model},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712106},
doi = {10.1145/3708359.3712106},
abstract = {The effective capture of subtle emotional changes and long-term affective trends in cross-modal information, particularly within speech modes, is found to be challenging by the current multimodal emotion analysis models. To address these challenges, an end-to-end multimodal Sentiment Analysis model, designated as the Sentiment Analysis Engine (SAE), has been proposed. Video, audio, and text information are integrated by SAE, with speech being converted into a text vector through the utilization of DeepSpeech and LSTM networks. Emotional features from speech are extracted via the EmoVoiceAnalyzer (EVA) module. Visual features are extracted through the application of ResNet-50 networks for timing modeling, while sensitivity to microexpression details is enhanced by the Multi-scale Efficient Channel Spatio Attention (MECS) mechanism. For the purpose of achieving efficient multi-modal fusion, a self- attention mechanism is employed, leading to the generation of descriptive text and the execution of in-depth emotion analysis.The experimental results show that SAE ranks first in NExT-QA testing and achieves performance indicators ahead of other SOTA in Class 2-7 emotion recognition tasks and IEMOCAP tests using the CMU-MOSI dataset, with F1 scores of 91.14 and 86.5, respectively. Furthermore, in ablation experiments, the removal of the EVA module resulted in an average 5% decrease in classification accuracy, thereby confirming the critical role played by voice components in enhancing the precision of emotion analysis.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {1232–1241},
numpages = {10},
keywords = {Multimodal AI assistants, End-user interaction with LLMs and Multimodal models, Personalized user interaction with LLMs},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3698587.3701356,
author = {Bian, Jnuyi and Zheng, Jiaxuan and Zhang, Yuyi and Zhou, Hong and Zhu, Shanfeng},
title = {One-shot Biomedical Named Entity Recognition via Knowledge-Inspired Large Language Model},
year = {2024},
isbn = {9798400713026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698587.3701356},
doi = {10.1145/3698587.3701356},
abstract = {Large Language Models (LLMs) have demonstrated exceptional performance in numerous natural language processing tasks, particularly in generative tasks. Nevertheless, their performance in non-generative tasks, such as information extraction, especially within specialized domain-specific extraction tasks like Biomedical Named Entity Recognition (NER), has been less successful when applied in an unsupervised manner. To address this challenge, we draw inspiration from the chain-of-thought concept and adopt a two-step approach for NER using LLMs: entity span extraction and entity type determination. Additionally, we introduce a framework for incorporating domain-specific entity knowledge to mitigate the LLM's inherent lack of domain expertise during entity category determination. Experimental results from four biomedical NER datasets illustrate a significant improvement in our approach when compared to prior LLM-based methods. Furthermore, our approach achieves results on par with other few-shot methods using just one shot, in contrast to their requirement of 50 shots.},
booktitle = {Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {26},
numpages = {10},
keywords = {Biomedical Named Entity Recognition, Large Language Model, One-shot learning},
location = {Shenzhen, China},
series = {BCB '24}
}

@inproceedings{10.1145/3662739.3665685,
author = {Li, Wei and Wang, Shimin and Yao, Junyan},
title = {Research on Large Language Model Q&amp;A Method Based on Specific Domain Regulation Documents},
year = {2024},
isbn = {9798400718144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662739.3665685},
doi = {10.1145/3662739.3665685},
abstract = {In response to the lack of relevant high-quality Q&amp;A (question and answer) datasets in some specific domain Q&amp;A systems, this paper proposes a large language model Q&amp;A Method based on specific domain regulation documents. The paper adopts natural language processing technology combined with a large language model. Firstly, data processing is performed on regulatory documents to extract text that meets the requirements. Then extracting the information of interest from the text and structuring it, and performing vector transformation to store it in a vector database for building a knowledge base. At the same time, performing vector transformation on user's question, and using cosine similarity to calculate the distance between the problem vector and the vector in the knowledge base. Finally, a random method is proposed to form the problem context, and the Lang Chain tool is used to return the Q&amp;A results, which are then displayed in the front-end. Through system design and engineering application, this paper proposes a large language model Q&amp;A method based on specific domain regulation documents, which can accurately obtain Q&amp;A results.},
booktitle = {Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications},
pages = {319–323},
numpages = {5},
keywords = {cosine similarity, large language model, question and answer system, vector database},
location = {Ningbo, China},
series = {MIDA '24}
}

@article{10.1145/3593230,
author = {Brie, Paul and Burny, Nicolas and Slu\"{y}ters, Arthur and Vanderdonckt, Jean},
title = {Evaluating a Large Language Model on Searching for GUI Layouts},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {EICS},
url = {https://doi.org/10.1145/3593230},
doi = {10.1145/3593230},
abstract = {The field of generative artificial intelligence has seen significant advancements in recent years with the advent of large language models, which have shown impressive results in software engineering tasks but not yet in engineering user interfaces. Thus, we raise a specific research question: would an LLM-based system be able to search for relevant GUI layouts? To address this question, we conducted a controlled study evaluating how Instigator, an LLM-based system for searching GUI layouts of web pages by generative pre-trained training, would return GUI layouts that are relevant to a given instruction and what would be the user experience of (N =34) practitioners interacting with Instigator. Our results identify a very high similarity and a moderate correlation between the rankings of the GUI layouts generated by Instigator and the rankings of the practitioners with respect to their relevance to a given design instruction. We highlight the results obtained through thirteen UEQ+ scales that characterize the user experience of the practitioner with Instigator, which we use to discuss perspectives for improving such future tools.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {178},
numpages = {37},
keywords = {generative pre-training, gui design, gui layout, large language model, web pages}
}

@inproceedings{10.1145/3586183.3606737,
author = {Jiang, Peiling and Rayan, Jude and Dow, Steven P. and Xia, Haijun},
title = {Graphologue: Exploring Large Language Model Responses with Interactive Diagrams},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606737},
doi = {10.1145/3586183.3606737},
abstract = {Large language models (LLMs) have recently soared in popularity due to their ease of access and the unprecedented ability to synthesize text responses to diverse user questions. However, LLMs like ChatGPT present significant limitations in supporting complex information tasks due to the insufficient affordances of the text-based medium and linear conversational structure. Through a formative study with ten participants, we found that LLM interfaces often present long-winded responses, making it difficult for people to quickly comprehend and interact flexibly with various pieces of information, particularly during more complex tasks. We present Graphologue, an interactive system that converts text-based responses from LLMs into graphical diagrams to facilitate information-seeking and question-answering tasks. Graphologue employs novel prompting strategies and interface designs to extract entities and relationships from LLM responses and constructs node-link diagrams in real-time. Further, users can interact with the diagrams to flexibly adjust the graphical presentation and to submit context-specific prompts to obtain more information. Utilizing diagrams, Graphologue enables graphical, non-linear dialogues between humans and LLMs, facilitating information exploration, organization, and comprehension.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {3},
numpages = {20},
keywords = {Large Language Model, Natural Language Interface, Visualization},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3626252.3630789,
author = {Liu, Mengqi and M'Hiri, Faten},
title = {Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630789},
doi = {10.1145/3626252.3630789},
abstract = {As the prominence of Large Language Models (LLMs) grows in various sectors, their potential in education warrants exploration. In this study, we investigate the feasibility of employing GPT-3.5 from OpenAI, as an LLM teaching assistant (TA) or a virtual TA in computer science (CS) courses. The objective is to enhance the accessibility of CS education while maintaining academic integrity by refraining from providing direct solutions to current-semester assignments. Targeting Foundations of Programming (COMP202), an undergraduate course that introduces students to programming with Python, we have developed a virtual TA using the LangChain framework, known for integrating language models with diverse data sources and environments. The virtual TA assists students with their code and clarifies complex concepts. For homework questions, it is designed to guide students with hints rather than giving out direct solutions. We assessed its performance first through a qualitative evaluation, then a survey-based comparative analysis, using a mix of questions commonly asked on the COMP202 discussion board and questions created by the authors. Our preliminary results indicate that the virtual TA outperforms human TAs on clarity and engagement, matching them on accuracy when the question is non-assignment-specific, for which human TAs still proved more reliable. These findings suggest that while virtual TAs, leveraging the capabilities of LLMs, hold great promise towards making CS education experience more accessible and engaging, their optimal use necessitates human supervision. We conclude by identifying several directions that could be explored in future implementations.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {743–749},
numpages = {7},
keywords = {adaptive teaching, chatgpt, cs education, gpt, llm, machine learning, novice programmers, openai, programming},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649409.3691094,
author = {Feng, Ty and Liu, Sa and Ghosal, Dipak},
title = {CourseAssist: Pedagogically Appropriate AI Tutor for Computer Science Education},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691094},
doi = {10.1145/3649409.3691094},
abstract = {The growing enrollments in computer science courses and increase in class sizes necessitate scalable, automated tutoring solutions to adequately support student learning. While Large Language Models (LLMs) like GPT-4 have demonstrated potential in assisting students through question-answering, educators express concerns over student overreliance, miscomprehension of generated code, and the risk of inaccurate answers. Rather than banning these tools outright, we advocate for a constructive approach that harnesses the capabilities of AI while mitigating potential risks. This poster introduces CourseAssist, a novel LLM-based tutoring system tailored for computer science education. Unlike generic LLM systems, CourseAssist uses retrieval-augmented generation, user intent classification, and question decomposition to align AI responses with specific course materials and learning objectives, thereby ensuring pedagogical appropriateness of LLMs in educational settings. We evaluated CourseAssist against a baseline of GPT-4 using a dataset of 50 question-answer pairs from a programming languages course, focusing on the criteria of usefulness, accuracy, and pedagogical appropriateness. Evaluation results show that CourseAssist significantly outperforms the baseline, demonstrating its potential to serve as an effective learning assistant. We have also deployed CourseAssist in 6 computer science courses at a large public R1 research university reaching over 500 students. Interviews with 20 student users show that CourseAssist improves computer science instruction by increasing the accessibility of course-specific tutoring help and shortening the feedback loop on their programming assignments. Future work will include extensive pilot testing at more universities and exploring better collaborative relationships between students, educators, and AI that improve computer science learning experiences.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {310–311},
numpages = {2},
keywords = {AI tutor, computer science education, intelligent tutoring systems, large language models, pedagogical appropriateness, question answering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@article{10.1145/3715111,
author = {Abrah\~{a}o, Silvia and Grundy, John and Pezz\`{e}, Mauro and Storey, Margaret-Anne and Tamburri, Damian A.},
title = {Software Engineering by and for Humans in an AI Era},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715111},
doi = {10.1145/3715111},
abstract = {The landscape of software engineering is undergoing a transformative shift driven by advancements in machine learning, Artificial Intelligence (AI), and autonomous systems. This roadmap article explores how these technologies are reshaping the field, positioning humans not only as end users but also as critical components within expansive software ecosystems. We examine the challenges and opportunities arising from this human-centered paradigm, including ethical considerations, fairness, and the intricate interplay between technical and human factors. By recognizing humans at the heart of the software lifecycle—spanning professional engineers, end users, and end user developers—we emphasize the importance of inclusivity, human-aligned workflows, and the seamless integration of AI-augmented socio-technical systems. As software systems evolve to become more intelligent and human-centric, software engineering practices must adapt to this new reality. This article provides a comprehensive examination of this transformation, outlining current trends, key challenges, and opportunities that define the emerging research and practice landscape, and envisioning a future where software engineering and AI work synergistically to place humans at the core of the ecosystem.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {129},
numpages = {46},
keywords = {Software engineering, Human and social aspects, Large language models}
}

@inproceedings{10.1145/3641555.3705102,
author = {Novak, Ed and Ohmann, Peter and Reckinger, Scott and Reckinger, Shanon},
title = {Oral Exams in Computer Science Education Amidst ChatGPT Dependency},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705102},
doi = {10.1145/3641555.3705102},
abstract = {Oral exams provide a compelling alternative to traditional evaluation methods, expanding or replacing traditional written work. Interest in oral exams is growing rapidly in computer science (CS) education due to shifts to remote learning and concerns around AI-supported programming. This Birds of a Feather (BoF) session is broadly applicable to many in the CS education community, whether they have previously tried oral exams, have concerns about the use of oral exams in CS education, or are curious to hear more about how oral exams might work. The BoF session will provide a forum to discover and discuss previous approaches to oral exams, dive into common themes of interest in small groups, and collectively identify promising future directions for oral exams in CS courses.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1725},
numpages = {1},
keywords = {assessment, large language models, oral exams, remote learning},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3685265,
author = {Felderer, Michael and Goedicke, Michael and Grunske, Lars and Hasselbring, Wilhelm and Lamprecht, Anna-Lena and Rumpe, Bernhard},
title = {Investigating Research Software Engineering: Toward RSE Research},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {68},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3685265},
doi = {10.1145/3685265},
abstract = {Research software engineering research aims at understanding and improving how software is developed for research.},
journal = {Commun. ACM},
month = jan,
pages = {20–23},
numpages = {4}
}

@article{10.1145/3718739,
author = {Zhang, Yuwei and Jin, Zhi and Xing, Ying and Li, Ge and Liu, Fang and Zhu, Jiaxin and Dou, Wensheng and Wei, Jun},
title = {PATCH: Empowering Large Language Model with Programmer-Intent Guidance and Collaborative-Behavior Simulation for Automatic Bug Fixing},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3718739},
doi = {10.1145/3718739},
abstract = {Bug fixing holds significant importance in software development and maintenance. Recent research has made substantial strides in exploring the potential of large language models (LLMs) for automatically resolving software bugs. However, a noticeable gap in existing approaches lies in the oversight of collaborative facets intrinsic to bug resolution, treating the process as a single-stage endeavor. Moreover, most approaches solely take the buggy code snippet as input for LLMs during the patch generation stage. To mitigate the aforementioned limitations, we introduce a novel stage-wise framework named PATCH. Specifically, we first augment the buggy code snippet with corresponding dependence context and intent information to better guide LLMs in generating the correct candidate patches. Additionally, by taking inspiration from bug management practices, we decompose the bug-fixing task into four distinct stages: bug reporting, bug diagnosis, patch generation, and patch verification. These stages are performed interactively by LLMs, aiming to simulate the collaborative behavior of programmers during the resolution of software bugs. By harnessing these collective contributions, PATCH effectively enhances the bug-fixing capability of LLMs. We implement PATCH by employing the powerful dialogue-based LLM ChatGPT. Our evaluation on the widely used bug-fixing benchmark BFP demonstrates that PATCH has achieved better performance than state-of-the-art LLMs.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {Bug Fixing, Large Language Model, Bug Management, Multi-Agent Collaboration}
}

@proceedings{10.1145/3569966,
title = {CSSE '22: Proceedings of the 5th International Conference on Computer Science and Software Engineering},
year = {2022},
isbn = {9781450397780},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guilin, China}
}

@inproceedings{10.1145/3626252.3630803,
author = {Joshi, Ishika and Budhiraja, Ritvik and Dev, Harshal and Kadia, Jahnvi and Ataullah, Mohammad Osama and Mitra, Sayan and Akolekar, Harshal D. and Kumar, Dhruv},
title = {ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses for Solving Undergraduate Computer Science Questions},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630803},
doi = {10.1145/3626252.3630803},
abstract = {This research paper aims to analyze the strengths and weaknesses associated with the utilization of ChatGPT as an educational tool in the context of undergraduate computer science education. ChatGPT's usage in tasks such as solving assignments and exams has the potential to undermine students' learning outcomes and compromise academic integrity. This study adopts a quantitative approach to demonstrate the notable unreliability of ChatGPT in providing accurate answers to a wide range of questions within the field of undergraduate computer science. While the majority of existing research has concentrated on assessing the performance of Large Language Models in handling programming assignments, our study adopts a more comprehensive approach. Specifically, we evaluate various types of questions such as true/false, multi-choice, multi-select, short answer, long answer, design-based, and coding-related questions. Our evaluation highlights the potential consequences of students excessively relying on ChatGPT for the completion of assignments and exams, including self-sabotage. We conclude with a discussion on how can students and instructors constructively use ChatGPT and related tools to enhance the quality of instruction and the overall student experience.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {625–631},
numpages = {7},
keywords = {chatgpt, computer science, education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3722237.3722310,
author = {Hwang, Min-Shiang and Fatima, Kanza and Chan, Chi-Shiang and Wu, Chia-Chun},
title = {Research on Steganography Course with Large Language Model ChatGPT Assisted Learning},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722310},
doi = {10.1145/3722237.3722310},
abstract = {In this study, by integrating practice-oriented teaching methods and combining large language models to assist learning and teaching situations, it is proposed that the Steganography course is practical-oriented and integrates ChatGPT with the Steganography language model teaching and teaching established by the applicant. In addition to focusing In addition to cultivating students with Steganography concepts and practical operational abilities, we hope to cultivate students' abilities of active observation, independent research, and critical thinking so that students can meet the technology industry's professional skills and requirements for Steganography studies. This research explores the pre-test and post-test, of course, students' use of large language models to learn to have higher learning attitudes and achievements towards Steganography theory and practice.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {422–425},
numpages = {4},
keywords = {ChatGPT, Social Media Learning, Independent Thinking Ability, Learning Effectiveness, Project-based Learning, Steganography, Information Security Theory and Practice},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3696410.3714758,
author = {Wang, Shuyao and Zheng, Zhi and Sui, Yongduo and Xiong, Hui},
title = {Unleashing the Power of Large Language Model for Denoising Recommendation},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714758},
doi = {10.1145/3696410.3714758},
abstract = {Recommender systems are crucial for personalizing user experiences but often depend on implicit feedback data, which can be noisy and misleading. Existing denoising studies involve incorporating auxiliary information or learning strategies from interaction data. However, they struggle with the inherent limitations of external knowledge and interaction data, as well as the non-universality of certain predefined assumptions, hindering accurate noise identification. Recently, large language models (LLMs) have gained attention for their extensive world knowledge and reasoning abilities, yet their potential in enhancing denoising in recommendations remains underexplored. In this paper, we introduce LLaRD, a framework leveraging LLMs to improve denoising in recommender systems, thereby boosting overall recommendation performance. Specifically, LLaRD generates denoising-related knowledge by first enriching semantic insights from observational data via LLMs and inferring user-item preference knowledge. It then employs a novel Chain-of-Thought (CoT) technique over user-item interaction graphs to reveal relation knowledge for denoising. Finally, it applies the Information Bottleneck (IB) principle to align LLM-generated denoising knowledge with recommendation targets, filtering out noise and irrelevant LLM knowledge. Empirical results demonstrate LLaRD's effectiveness in enhancing denoising and recommendation accuracy.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {252–263},
numpages = {12},
keywords = {denoising, large language models, recommendation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3686081.3686126,
author = {Tang, Valerie and Wong, Lap and Lam, Hoi Yan and Tang, Yuk Ming},
title = {Amplifying Learning and Teaching Effectiveness through Generative Artificial Intelligence: A Qualitative Approach with Case Studies on Supply Chain and Cold Chain Management},
year = {2024},
isbn = {9798400718151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686081.3686126},
doi = {10.1145/3686081.3686126},
abstract = {The increasing popularity of Generative Artificial Intelligence (GAI) technology offers new possibilities and challenges for teaching and promoting human-AI collaborative learning. In order to enhance the learning quality and experience of students, it is important to develop an effective instructional design, particularly in defining the goals and strategies, solving individual needs, and enhancing learning performance. However, the impact of implementing GAI in student learning and performance enhancement considerations is still lacking. Therefore, this study proposes an experimental framework for evaluating the effectiveness of GAI-based learning for students. By scrutinizing instructional goals and design strategies to achieve desirable learning outcomes, it provides guidelines on coverage design and development in GAI-based learning environments. Experiment with case studies on supply chain and cold chain management is adopted to analyze the effectiveness and facilitate instructional design in GAI-based learning to enhance the student learning experience. The result indicates that the treatment group outperformed the control group. This study is expected to provide insights into academic development and future education on GAI-based learning.},
booktitle = {Proceedings of the International Conference on Decision Science &amp; Management},
pages = {264–269},
numpages = {6},
keywords = {Cold Chain Management, Generative Artificial Intelligence (GAI), Qualitative Approach, Supply Chain Management, Teaching and Learning},
location = {
},
series = {ICDSM '24}
}

@inproceedings{10.1145/3663529.3663818,
author = {Jaccheri, Letizia and Duc, Anh Nguyen},
title = {Software Engineering and Gender: A Tutorial},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663818},
doi = {10.1145/3663529.3663818},
abstract = {Software runs the world and should provide equal rights and opportunities to all genders. However, the gender gap exists in the software engineering workforce and many software products are still gender biased. Recently, AI systems, including modern large language models are shown to be related to gender bias issues. Many efforts have been devoted to understanding the problem and investigating solutions. The tutorial aims to present a set of scientific studies based on qualitative and quantitative research methods. The authors have a long record of research leadership in interdisciplinary projects with a focus on gender and software engineering. The issues with team diversity in software development and AI engineering will be presented to highlight the importance of fostering inclusive and diverse software development teams.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {704–706},
numpages = {3},
keywords = {Software engineering, bias, gender, research methods},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3691720.3691768,
author = {Shan, Qiang},
title = {Design and application of a web front-end development course training platform based on generative artificial intelligence and low code development},
year = {2024},
isbn = {9798400710230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691720.3691768},
doi = {10.1145/3691720.3691768},
abstract = {With the rapid development of artificial intelligence technology, generative artificial intelligence has shown strong application potential in various fields, and low code development has become a popular choice for quickly building application systems due to its efficient and easy-to-use characteristics. With the continuous updates and iterations of web front-end development technology, how to improve learners' practical abilities and development efficiency has become an important issue in the field of vocational education. Therefore, we have designed an innovative web front-end development course training platform that combines the automation generation ability of generative artificial intelligence and the fast construction advantage of low code development. In platform design, we fully utilize the automated generation capability of generative artificial intelligence to achieve intelligent generation and layout optimization of front-end page elements. At the same time, with the help of the visual programming interface and component-based development methods of low code development platforms, the front-end development process is simplified, the technical threshold is lowered, and students can focus more on the implementation of business logic and creative expression.},
booktitle = {Proceedings of the 2nd International Conference on Educational Knowledge and Informatization},
pages = {287–291},
numpages = {5},
location = {Shanghai, China},
series = {EKI '24}
}

@article{10.1613/jair.1.17809,
author = {Wei, Chuyuan and Duan, Ke and Zhuo, Shengda and Wang, Hongchun and Huang, Shuqiang and Liu, Jie},
title = {Enhanced Recommendation Systems with Retrieval-Augmented Large Language Model},
year = {2025},
issue_date = {May 2025},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {82},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.17809},
doi = {10.1613/jair.1.17809},
abstract = {Recommender systems have long struggled with challenges such as cold start and data sparsity, which can lead to poor recommendation performance. While previous approaches have attempted to address these issues by incorporating side information, they often introduce noise, lack flexibility for data expansion, and suffer from inconsistent data quality—factors that hinder accurate user preference inference and reduce recommendation performance. With the vast knowledge bases and advanced reasoning capabilities of large language models (LLMs), these models are particularly well-suited to supplement auxiliary information and capture implicit user intent. To address these challenges, we propose a novel framework, ER2ALM, which leverages the capabilities of LLMs enhanced by Retrieval-Augmented Generation (RAG) to improve recommendation outcomes. Our framework specifically addresses the challenges by flexibly and accurately augmenting auxiliary information and capturing users’ implicit preferences and interests. Additionally, to mitigate the risk of introducing noise, we incorporate a noise reduction strategy to ensure the reliability of the augmented information. Experimental validation on two real-world datasets demonstrates the efficacy of our approach, significantly enhancing both the accuracy and robustness of recommendations compared to state-of-the-art methods. This demonstrates the potential of our framework as a new paradigm for preference mining in recommendation systems.},
journal = {J. Artif. Int. Res.},
month = apr,
numpages = {27}
}

@inproceedings{10.1145/3675417.3675453,
author = {Wang, Shuyi and Sun, Jian},
title = {Research on the Maturity Evaluation of Generative Artificial Intelligence Industry under the Background of Digital Economy: A Case Study of Guangdong Province},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675417.3675453},
doi = {10.1145/3675417.3675453},
abstract = {In order to scientifically measure the development stage of generative AI industry under the background of digital economy and evaluate the degree of perfection of emerging industry structure, this study takes Guangdong Province as an example, constructs the evaluation index system and model of generative AI industry maturity in Guangdong Province from the four dimensions of environment, technology, market and industry chain, and evaluates the current situation of the maturity of generative AI industry in each region of Guangdong Province by using entropy method and TOPSIS method. On this basis, conclusions and insights are presented. The construction of the model provides a reference standard for the scientific evaluation of the high-quality development of generative AI emerging industries, and provides empirical reference for empirical research in other regions.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {224–229},
numpages = {6},
location = {Hongkong, China},
series = {DEAI '24}
}

@article{10.1145/3725853,
author = {Deldjoo, Yashar and Di Noia, Tommaso},
title = {CFaiRLLM: Consumer Fairness Evaluation in Large-Language Model Recommender System},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3725853},
doi = {10.1145/3725853},
abstract = {This work takes a critical stance on previous studies concerning fairness evaluation in Large Language Model (LLM)-based recommender systems, which have primarily assessed consumer fairness by comparing recommendation lists generated with and without sensitive user attributes. Such approaches implicitly treat discrepancies in recommended items as biases, overlooking whether these changes might stem from genuine personalization aligned with true preferences of users. Moreover, these earlier studies typically address single sensitive attributes in isolation, neglecting the complex interplay of intersectional identities. In response to these shortcomings, we introduce CFaiRLLM, an enhanced evaluation framework that not only incorporates true preference alignment but also rigorously examines intersectional fairness by considering overlapping sensitive attributes. Additionally, CFaiRLLM introduces diverse user profile sampling strategies—random, top-rated, and recency-focused—to better understand the impact of profile generation fed to LLMs in light of inherent token limitations in these systems. Given that fairness depends on accurately understanding users’ tastes and preferences, these strategies provide a more realistic assessment of fairness within RecLLMs.To validate the efficacy of CFaiRLLM, we conducted extensive experiments using MovieLens and LastFM datasets, applying various sampling strategies and sensitive attribute configurations. The evaluation metrics include both item similarity measures and true preference alignment considering both hit and ranking (Jaccard Similarity and PRAG), thereby conducting a multifaceted analysis of recommendation fairness. The results demonstrated that true preference alignment offers a more personalized and fair assessment compared to similarity-based measures, revealing significant disparities when sensitive and intersectional attributes are incorporated. Notably, our study finds that intersectional attributes amplify fairness gaps more prominently, especially in less structured domains such as music recommendations in LastFM. These findings suggest that future fairness evaluations in RecLLMs should incorporate true preference alignment to ensure equitable and genuinely personalized recommendations.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = mar,
keywords = {Consumer Fairness, Recommender Systems, Large Language Models, Bias Mitigation, Evaluation Framework, User Profile Sampling}
}

@article{10.5555/3715602.3715614,
author = {Rhee, Junghwan and Shrestha, Aakankshya and Qian, Gang and Zuo, Fei and Fu, Jicheng and Park, Myungah and Qu, Xianshan and Mylavarapu, Goutam and Sung, Hong},
title = {An Evaluation on the Impact of Large Language Models on Computer Science Curricula},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {Since their introduction, large language model (LLM) services have been widely used in our society, including the computer science education area. While this technology provides various types of intelligent assistance to users, its capabilities and impact on computer science education regarding students' learning need further study. In this paper, we present our manual assessment of LLM services' ability to solve questions in various course assignments and projects in our computer science curriculum. Based on the result of the study, we provide our observations of the extent of LLM services' impact on different computer science disciplines. Suggestions are summarized and offered to computer science instructors on the possible strategies for dealing with LLMs in current and future computer science curriculum designs.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {70–80},
numpages = {11}
}

@article{10.1145/3660767,
author = {Liang, Jenny T. and Badea, Carmen and Bird, Christian and DeLine, Robert and Ford, Denae and Forsgren, Nicole and Zimmermann, Thomas},
title = {Can GPT-4 Replicate Empirical Software Engineering Research?},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660767},
doi = {10.1145/3660767},
abstract = {Empirical software engineering research on production systems has brought forth a better understanding of the software engineering process for practitioners and researchers alike. However, only a small subset of production systems is studied, limiting the impact of this research. While software engineering practitioners could benefit from replicating research on their own data, this poses its own set of challenges, since performing replications requires a deep understanding of research methodologies and subtle nuances in software engineering data. Given that large language models (LLMs), such as GPT-4, show promise in tackling both software engineering- and science-related tasks, these models could help replicate and thus democratize empirical software engineering research.
 

 
In this paper, we examine GPT-4’s abilities to perform replications of empirical software engineering research on new data. We specifically study their ability to surface assumptions made in empirical software engineering research methodologies, as well as their ability to plan and generate code for analysis pipelines on seven empirical software engineering papers. We perform a user study with 14 participants with software engineering research expertise, who evaluate GPT-4-generated assumptions and analysis plans (i.e., a list of module specifications) from the papers. We find that GPT-4 is able to surface correct assumptions, but struggles to generate ones that apply common knowledge about software engineering data. In a manual analysis of the generated code, we find that the GPT-4-generated code contains correct high-level logic, given a subset of the methodology. However, the code contains many small implementation-level errors, reflecting a lack of software engineering knowledge. Our findings have implications for leveraging LLMs for software engineering research as well as practitioner data scientists in software teams.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {60},
numpages = {24},
keywords = {Large language models, empirical software engineering, study replication}
}

@article{10.1145/3726533,
author = {Bellovin, Steven M.},
title = {Computer Science and the Law},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {68},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/3726533},
doi = {10.1145/3726533},
abstract = {Making a case for stronger influence and overlap of technology and law.},
journal = {Commun. ACM},
month = jun,
pages = {20–22},
numpages = {3}
}

@article{10.1145/3715003,
author = {Terragni, Valerio and Vella, Annie and Roop, Partha and Blincoe, Kelly},
title = {The Future of AI-Driven Software Engineering},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715003},
doi = {10.1145/3715003},
abstract = {A paradigm shift is underway in Software Engineering, with AI systems such as LLMs playing an increasingly important role in boosting software development productivity. This trend is anticipated to persist. In the next years, we expect a growing symbiotic partnership between human software developers and AI. The Software Engineering research community cannot afford to overlook this trend; we must address the key research challenges posed by the integration of AI into the software development process. In this article, we present our vision of the future of software development in an AI-driven world and explore the key challenges that our research community should address to realize this vision.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {120},
numpages = {20},
keywords = {Software Engineering, Artificial Intelligence, Machine Learning, Large Language Models, APIs, Libraries, Software Testing, Requirements Engineering}
}

@inproceedings{10.1145/3702163.3702186,
author = {Weng, Cheng-Kai and Lai, Chao-Feng and Yeh, Wei-Chieh},
title = {Examining the Advantages of AI Integration in Interior Design Education},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702186},
doi = {10.1145/3702163.3702186},
abstract = {This study aims to explore the differences in benefits between students using artificial intelligence (AI) technology, websites (such as Chat GPT), and those not using them in the process of interior design. The research will assess the impact of using AI technology on students' efficiency, creativity, and the quality, completeness, and professionalism of their design works in the interior design process. This study employs literature review, experimental methods, questionnaire surveys, and in-depth interviews to assist in data analysis. The experimental design used in the research compares the performance of students with similar knowledge backgrounds and skill levels in conducting interior design assignments with or without AI assistance. The results of the study will provide insights into students' attitudes, perceptions, and skill improvements when using AI technology in interior design, and will offer reference value for educational practices and future research.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {161–166},
numpages = {6},
keywords = {AI-assisted interior design, Chat GPT, Generative AI, artificial intelligence},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3711496.3711505,
author = {Song, Tianyu and Liu, Zhengyi and Zhao, Ruibin and Fu, Jie},
title = {ElderEase AR: Enhancing Elderly Daily Living with the Multimodal Large Language Model and Augmented Reality},
year = {2025},
isbn = {9798400710186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711496.3711505},
doi = {10.1145/3711496.3711505},
abstract = {Elderly individuals often face challenges in independent living due to age-related cognitive and physical decline. To address these issues, we propose an innovative Augmented Reality (AR) system, “ElderEase AR”, designed to assist elderly users in their daily lives by leveraging a Multimodal Large Language Model (MLLM). This system enables elderly users to capture images of their surroundings and ask related questions, providing context-aware feedback. We evaluated the system's perceived ease-of-use and feasibility through a pilot study involving 30 elderly users, aiming to enhance their independence and quality of life. Our system integrates advanced AR technology with an intelligent agent trained on multimodal datasets. Through prompt engineering, the agent is tailored to respond in a manner that aligns with the speaking style of elderly users. Experimental results demonstrate high accuracy in object recognition and question answering, with positive feedback from user trials. Specifically, the system accurately identified objects in various environments and provided relevant answers to user queries. This study highlights the powerful potential of AR and AI technologies in creating support tools for the elderly. It suggests directions for future improvements and applications, such as enhancing the system's adaptability to different user needs and expanding its functionality to cover more aspects of daily living.},
booktitle = {Proceedings of the 2024 International Conference on Virtual Reality Technology},
pages = {60–67},
numpages = {8},
keywords = {Augmented Reality, Daily Life Support, Multimodal Large Language Model, elderly},
location = {
},
series = {ICVRT '24}
}

@article{10.1145/3722449.3722461,
author = {Rahmani, Hossein A. and Siro, Clemencia and Aliannejadi, Mohammad and Craswell, Nick and Clarke, Charles L. A. and Faggioli, Guglielmo and Mitra, Bhaskar and Thomas, Paul and Yilmaz, Emine},
title = {Report on the 1st Workshop on Large Language Model for Evaluation in Information Retrieval (LLM4Eval 2024) at SIGIR 2024},
year = {2025},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {58},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3722449.3722461},
doi = {10.1145/3722449.3722461},
abstract = {The first edition of the workshop on Large Language Model for Evaluation in Information Retrieval (LLM4Eval 2024) took place in July 2024, co-located with the ACM SIGIR Conference 2024 in the USA (SIGIR 2024). The aim was to bring information retrieval researchers together around the topic of LLMs for evaluation in information retrieval that gathered attention with the advancement of large language models and generative AI. Given the novelty of the topic, the workshop was focused around multi-sided discussions, namely panels and poster sessions of the accepted proceedings papers.Date: 18 July 2024.Website: https://llm4eval.github.io.},
journal = {SIGIR Forum},
month = mar,
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3722237.3722338,
author = {Xiang, Xiuzhen and Li, Yi},
title = {Using Large Language Model for Assessing Business English Students’ Pragmatic Competence},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722338},
doi = {10.1145/3722237.3722338},
abstract = {Pragmatic competence is the the ability to say and do things appropriately in various contexts. Scholars have been studied this topic from different aspects and a large quantities of methods have been attest to assess students’ pragmatic competence. However, human rating is not only laborious but also less efficient. The emergency of Artificial Intelligence (AI), particularly Large Language Model shed a light on this matter. This essay put prompts into kimi—a LLM of China to see if it can evaluate Business English major students’ pragmatic competence and compare its scoring with human rater's. It is found that LLM's core shows consistency with human score and LLM can give instant and personalized feedback which is impossible for human. Therefore, the reliability of LLM evaluation on pragmatic competence is proved.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {572–576},
numpages = {5},
keywords = {LLM, evaluation, pragmatic competence},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3702386.3702396,
author = {Wei, Qizhi and Chen, Xuanyu and Ni, Yifei and Cao, Cong},
title = {A Technical Framework for Recognizing and Interpreting Complex Medical Records: Based on Multimodal Large Language Model},
year = {2025},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702386.3702396},
doi = {10.1145/3702386.3702396},
abstract = {This paper brings up a technical framework for Interpreting medical documentation that integrates multi-modal large language modals, aiming to provide patients and doctors with the ability to read non-standard medical documentation in complex environments and to obtain text interpretation based on generative AI. The framework proposes a three-stage solution, namely Recognition, Formatting, and AI-Processing, involving technologies such as OCR, medical multi-modal models, and large language models, abbreviated as the RF-AI framework. This paper focuses on explaining the potential issues encountered when applying the framework and describes the resolution within the framework. In addition, this paper conducts experiments on two key stages of the framework, recognition and AI-processing, which effectively demonstrate the feasibility of the framework. This framework can significantly reduce the difficulty for patients in understanding medical records and provides necessary resolution for situations where paper records might be used. It helps patients better understand their conditions and enhances the efficiency of diagnosis and treatment between doctors and patients. Benefiting from a large language model, this framework allows developers to expand based on actual needs and can be integrated into existing electronic healthcare systems to achieve more comprehensive functionality.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
pages = {76–83},
numpages = {8},
keywords = {LLM, Medical Record, Multimodal Model, OCR, Technical Framework},
location = {
},
series = {ICAITE '24}
}

@article{10.1145/3704739,
author = {Le, Linh and Tran, Dung},
title = {A Metric-Based Detection System for Large Language Model Texts},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3704739},
doi = {10.1145/3704739},
abstract = {More efforts are being put into improving the capabilities of Large Language Models (LLM) than into dealing with their implications. Current LLMs are able to generate high-quality texts seemingly indistinguishable from those written by human experts. While offering great potential, such breakthroughs also pose new challenges for safe and ethical uses of LLMs in education, science, and a multitude of other areas. Thus, majority of current approaches in LLM text detection are either computationally expensive or need access to the LLMs’ internal computations, both of which hinder their public accessibility. With such motivation, this article presents a novel metric learning paradigm for detection of LLM-generated texts that is able to balance computational costs, accessibility, and performances. Specifically, the detection is based on learning a similarity function between a given text and an equivalent example generated by LLMs that outputs high values for LLM-LLM text pairs and low values for LLM-human text pairs. In terms of architecture, the detection framework includes a pre-trained language model for the text embedding task and a newly designed deep metric model. The metric component can be trained on triplets or pairs of same-context instances to signify the distances between human and LLM texts while reducing that among LLM texts. Next, we develop five datasets totaling more than 95,000 contexts and triplets of responses in which one is from humans and two are from GPT-3.5 TURBO or GPT-4 TURBO for benchmarking. Experiment studies show that our best architectures maintain F1 scores between 0.87 and 0.95 across the tested corpora in multiple experiment settings. The metric framework also demands significantly less time in training and inference compared to RoBERTa, LLaMA 3, Mistral v0.3, and Ghostbuster, while keeping 90% to 150% performance of the best benchmark.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {8},
numpages = {19},
keywords = {LLM text detection, contrastive learning, triplet learning, metric learning}
}

@inproceedings{10.1145/3698587.3701359,
author = {Yue, Ling and Xing, Sixue and Chen, Jintai and Fu, Tianfan},
title = {ClinicalAgent: Clinical Trial Multi-Agent System with Large Language Model-based Reasoning},
year = {2024},
isbn = {9798400713026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698587.3701359},
doi = {10.1145/3698587.3701359},
abstract = {Large Language Models (LLMs) and multi-agent systems have shown impressive capabilities in natural language tasks but face challenges in clinical trial applications, primarily due to limited access to external knowledge. Recognizing the potential of advanced clinical trial tools that aggregate and predict based on the latest medical data, we propose an integrated solution to enhance their accessibility and utility. We introduce Clinical Agent System (ClinicalAgent), a clinical multi-agent system designed for clinical trial tasks, leveraging GPT-4, multi-agent architectures, LEAST-TO-MOST, and ReAct reasoning technology. This integration not only boosts LLM performance in clinical contexts but also introduces novel functionalities. The proposed method achieves competitive predictive performance in clinical trial outcome prediction (0.7908 PR-AUC), obtaining a 0.3326 improvement over the standard prompt Method. Publicly available code can be found at https://github.com/LeoYML/clinical-agent.},
booktitle = {Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {11},
numpages = {10},
keywords = {Clinical Trial, Clinical Trial Outcome Prediction, Drug Development, Healthcare, Large Language Model-based Reasoning, Large Language Models, Multi-Agent Planning},
location = {Shenzhen, China},
series = {BCB '24}
}

@inproceedings{10.1145/3639474.3640061,
author = {Frankford, Eduard and Sauerwein, Clemens and Bassner, Patrick and Krusche, Stephan and Breu, Ruth},
title = {AI-Tutoring in Software Engineering Education},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640061},
doi = {10.1145/3639474.3640061},
abstract = {With the rapid advancement of artificial intelligence (AI) in various domains, the education sector is set for transformation. The potential of AI-driven tools in enhancing the learning experience, especially in programming, is immense. However, the scientific evaluation of Large Language Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an AI-Tutor remains largely unexplored. Therefore, there is a need to understand how students interact with such AI-Tutors and to analyze their experiences.In this paper, we conducted an exploratory case study by integrating the GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis. Through a combination of empirical data collection and an exploratory survey, we identified different user types based on their interaction patterns with the AI-Tutor. Additionally, the findings highlight advantages, such as timely feedback and scalability. However, challenges like generic responses and students' concerns about a learning progress inhibition when using the AI-Tutor were also evident. This research adds to the discourse on AI's role in education.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {309–319},
numpages = {11},
keywords = {programming education, automated programming assessment systems, artificial intelligence, ChatGPT, OpenAI, ChatBots},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@proceedings{10.1145/3641555,
title = {SIGCSETS 2025: Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 56th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2025)! For the first time since 1978, our symposium is being held in the "Steel City" of Pittsburgh, Pennsylvania, at the intersection of the Allegheny, Ohio, and Monongahela rivers. We are looking forward to four days of productive and informative presentations, vibrant and engaging discussions, and an overall wonderful experience with our SIGCSE community members. We are confident that our program of events provides meaningful and productive experiences for all.Our theme for this year is "Leading the Transformation". Our theme reflects the role of the computer science education community in adapting educational practice to new technologies and challenges. With advances in Artificial Intelligence (AI) transforming both academia and the workplace, the computer science education community has a unique opportunity to help shape the future use and application of computing. Our program this year is quite diverse and offers something for everyone, so please take time to peruse the schedule and choose the sessions which appeal to you. Pittsburgh is also an exciting city with lots to see and do, so you are encouraged to enjoy all the city has to offer.The format of the 2025 Technical Symposium is similar to 2024 in many ways. We will once again have a program that extends into Saturday afternoon, including papers and the Nifty Assignment session after lunch. We will also again have three Birds-of-a-Feather sessions, two on Thursday evening and one during lunch on Friday. For online attendees, we will continue to offer streaming of keynotes, the Nifty Assignment session, the First-Timers Lunch presentation, and a small set of paper, panel, and special sessions.This year we received almost 1200 submissions. Submission statistics for all of the Technical Symposium's tracks can be found in the table that follows. Papers were submitted to one of three tracks (Computing Education Research, Experience Reports and Tools, Position and Curricula Initiatives) with reviewing tailored to each track. Each paper submission was reviewed by at least three reviewers, with a substantial proportion of papers receiving four (or more) reviews, plus a meta review. We sincerely appreciate the work of the more than 800 reviewers and 112 Associate Program Chairs who contributed to the creation of this years' program. Their reviews helped us decide which submissions were accepted while also providing detailed feedback that allowed authors to further improve the final versions of their submissions.},
location = {Pittsburgh, PA, USA}
}

@inproceedings{10.1145/3706598.3713582,
author = {Lima, Maria R. and O'Connell, Amy and Zhou, Feiyang and Nagahara, Alethea and Hulyalkar, Avni and Deshpande, Anura and Thomason, Jesse and Vaidyanathan, Ravi and Matari\'{c}, Maja},
title = {Promoting Cognitive Health in Elder Care with Large Language Model-Powered Socially Assistive Robots},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713582},
doi = {10.1145/3706598.3713582},
abstract = {As the global population ages, there is increasing need for accessible technologies that promote cognitive health and detect early signs of cognitive decline. This research demonstrates the potential for in-residence monitoring and assessment of cognitive health using large language model (LLM)-powered socially assistive robots (SARs). We conducted a 5-week within-subjects study involving 22 older adults in retirement homes to investigate the feasibility of large language model (LLM)-powered socially assistive robots (SARs) for promoting and assessing cognitive health. We designed tasks that involved verbal dialogue based on clinically validated cognitive tools. Our findings reveal improved task performance after three robot-administered sessions, with significantly more detailed picture descriptions, fewer word repetitions in semantic fluency, and reduced need for hints. We found that older adults were more socially engaged in robot-administered tasks compared to those administered by a human, and they accepted and were willing to engage with socially assistive robots (SARs) in this context, which had not been tested before.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {317},
numpages = {22},
keywords = {socially assistive robotics, large language models, cognitive health, elder care},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3589334.3645682,
author = {Zhang, Mengmei and Sun, Mingwei and Wang, Peng and Fan, Shen and Mo, Yanhu and Xu, Xiaoxiao and Liu, Hong and Yang, Cheng and Shi, Chuan},
title = {GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645682},
doi = {10.1145/3589334.3645682},
abstract = {Large language models (LLMs) like ChatGPT, exhibit powerful zero-shot and instruction-following capabilities, have catalyzed a revolutionary transformation across diverse fields, especially for open-ended tasks. While the idea is less explored in the graph domain, despite the availability of numerous powerful graph models (GMs), they are restricted to tasks in a pre-defined form. Although several methods applying LLMs to graphs have been proposed, they fail to simultaneously handle the pre-defined and open-ended tasks, with LLM as a node feature enhancer or as a standalone predictor. To break this dilemma, we propose to bridge the pretrained GM and LLM by a Translator, named GraphTranslator, aiming to leverage GM to handle the pre-defined tasks effectively and utilize the extended interface of LLMs to offer various open-ended tasks for GM. To train such Translator, we propose a Producer capable of constructing the graph-text alignment data along node information, neighbor information and model information. By translating node representation into tokens, GraphTranslator empowers an LLM to make predictions based on language instructions, providing a unified perspective for both pre-defined and open-ended tasks. Extensive results demonstrate the effectiveness of our proposed GraphTranslator on zero-shot node classification. The graph question answering experiments reveal our GraphTranslator potential across a broad spectrum of open-ended tasks through language instructions. Our code is available at: https://github.com/alibaba/GraphTranslator},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1003–1014},
numpages = {12},
keywords = {graph neural network, large language model},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3699538.3699571,
author = {Birillo, Anastasiia},
title = {Bringing Industry-Grade Code Quality and Practices into Software Engineering Education (Doctoral Consortium)},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699571},
doi = {10.1145/3699538.3699571},
abstract = {Using professional development tools and practices is an essential part of being a programmer. However, beginners often struggle with professional tools. In this work, we ask the question: “How can we adapt professional programming tools to improve software engineering education?” and aim to find efficient ways to solve this problem.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {33},
numpages = {2},
keywords = {Code Quality Assessment, Code Formatting, LLMs, Generative AI, Next-Step Hints},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3723010.3723014,
author = {Bigler, Dimitri and Hagel, Georg and Becker, Matthias},
title = {Enhancing Learning Analytics: H5P Results for Personalized Software Engineering Education},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723014},
doi = {10.1145/3723010.3723014},
abstract = {Learning Management Systems have become fundamental in higher education for delivering and managing educational content. However, traditional implementations often lack the ability to provide personalized learning experiences and detailed insights into learner behavior. A new approach addresses these limitations by enabling more detailed Learning Analytics through the integration of interactive H5P content and the implementation of Moodle’s LogStore xAPI plugin to send Experience API-based statements within a Moodle Learning Management System. By extending this plugin, detailed user interactions, including activity outcomes, scores, durations and completion status, are captured as Learning Records and stored in a Learning Record Store for further analysis. The enriched Learning Records enable more advanced Learning Analytics that provide deeper insights into student behavior, such as identifying learning preferences, activity patterns, and knowledge levels. Future work will involve developing a recommendation system that uses the Learning Analytics data to identify the next activity best suited to fill learning gaps. The system should monitor learner preferences to maintain engagement, enable adaptive learning paths and offer personalized suggestions. Further efforts will focus on refining the system and evaluating its effectiveness in improving educational outcomes.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {176–179},
numpages = {4},
keywords = {Learning Management Systems, H5P, xAPI, Learning Analytics, Personalized learning, Software Engineering, Exercise Result Interpretation, Microlearning},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3706599.3719785,
author = {Huffman, Shuxu and Chen, Si and Mack, Kelly Avery and Su, Haotian and Wang, Qi and Kushalnagar, Raja},
title = {"We do use it, but not how hearing people think": How the Deaf and Hard of Hearing Community Uses Large Language Model Tools},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719785},
doi = {10.1145/3706599.3719785},
abstract = {Generative AI tools, particularly those utilizing large language models (LLMs), are increasingly used in everyday contexts. While these tools enhance productivity and accessibility, little is known about how Deaf and Hard of Hearing (DHH) individuals engage with them or the challenges they face when using them. This paper presents a mixed-method study exploring how the DHH community uses Text AI tools like ChatGPT to reduce communication barriers and enhance information access. We surveyed 80 DHH participants and conducted interviews with 9 participants. Our findings reveal important benefits, such as eased communication and bridging Deaf and hearing cultures, alongside challenges like lack of American Sign Language (ASL) support and Deaf cultural understanding. We highlight unique usage patterns, propose inclusive design recommendations, and outline future research directions to improve Text AI accessibility for the DHH community.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {33},
numpages = {9},
keywords = {Accessibility, LLM, ChatGPT, Deaf and Hard of hearing},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.5555/3709347.3743852,
author = {Wang, Peng-Yuan and Pang, Jing-Cheng and Wang, Chen-Yang and Liu, Xuhui and Liu, Tian-Shuo and Yang, Si-Hang and Qian, Hong and Yu, Yang},
title = {InCLET: Large Language Model In-context Learning can Improve Embodied Instruction-following},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Natural language-conditioned reinforcement learning (NLC-RL) empowers embodied agent to complete various tasks following human instruction. However, the unbounded natural language examples still introduce much complexity for the agent that solves concrete RL tasks, which can distract policy learning from completing the task. Consequently, extracting effective task representation from human instruction emerges as the critical component of NLC-RL. While previous methods have attempted to address this issue by learning task-related representation using large language models (LLMs), they highly rely on pre-collected task data and require extra training procedure. In this study, we uncover the inherent capability of LLMs to generate task representations and present a novel method, in-context learning embedding as task representation (InCLET). InCLET is grounded on a foundational finding that LLM in-context learning using trajectories can greatly help represent tasks. We thus firstly employ LLM to imagine task trajectories following the natural language instruction, then use in-context learning of LLM to generate task representations, and finally aggregate and project into a compact low-dimensional task representation. This representation is then used to train a human instruction-following agent. We conduct experiments on various embodied control environments and results show that InCLET creates effective task representations. Furthermore, this representation can significantly improve the RL training efficiency, compared to the baseline methods.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {2134–2142},
numpages = {9},
keywords = {embodiment agent, in-context learning, reinforcement learning},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@proceedings{10.1145/3689187,
title = {ITiCSE 2024: 2024 Working Group Reports on Innovation and Technology in Computer Science Education},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {In these proceedings, we present papers from the Working Groups that worked in the context of the 29th Annual Conference on Innovation &amp; Technology in Computer Science Education (ITiCSE), held in Milan Italy, and hosted by Universit\`{a} degli Studi di Milano from the 8th to the 10th of July 2024.The concept of Working Groups has been a unique feature of the ITiCSE conference series since its inception. Working Groups are now part of CompEd and SIGCSE Virtual. An ITiCSE Working Group is typically composed of 8-12 researchers who work together for about nine months on a research project related to computing education. Working Groups provide a wonderful opportunity to work intensively on a topic of interest with an international group of computing education researchers. This unique experience is one that, in our opinion, each Computer Science Educator should strive to participate in at least once.In 2024, 13 proposals for Working Groups were received and ten Working Groups were selected by the Working Group chairs to recruit members and proceed for ITiCSE 2024. There were 166 member applications to Working Groups, with 134 being accepted including 33 Working Group leaders across the ten Working Groups. This is a record number of both Working Groups and Working Group members at a single conference.Working Groups began their work virtually from March up until the beginning of the ITiCSE conference. Their work included intensive collaboration on-site for the three days prior to the conference. A draft report was then submitted on the Sunday prior to the conference; a few weeks after the conference, the Working Groups submitted their final report for peer review.If the report was accepted for publication, the groups revised it based on the reviewers' comments and suggestions. This dedicated ITiCSE Working Group proceedings volume presents the final camera-ready version of the reports. We are glad that all ten papers were selected for publication in these proceedings for the ACM Digital Library.},
location = {Milan, Italy}
}

@proceedings{10.1145/3723010,
title = {ECSEE '25: Proceedings of the 6th European Conference on Software Engineering Education},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3589335.3641253,
author = {Gao, Chen and Xu, Fengli and Chen, Xu and Wang, Xiang and He, Xiangnan and Li, Yong},
title = {Simulating Human Society with Large Language Model Agents: City, Social Media, and Economic System},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641253},
doi = {10.1145/3589335.3641253},
abstract = {This tutorial will delve into the fascinating realm of simulating human society using Large Language Model (LLM)-driven agents, exploring their applications in cities, social media, and economic systems. Through this tutorial, participants will gain insights into the integration of LLMs into human society simulation, providing a comprehensive understanding of how these models can accurately represent human interactions, decision-making processes, and societal dynamics from cities to social media and to economic systems. The tutorial will introduce the essential background, discuss the motivation and challenges, and elaborate on the recent advances.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1290–1293},
numpages = {4},
keywords = {agent-based modeling and simulation, large language model agents},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.14778/3685800.3685835,
author = {Shankar, Shreya and Li, Haotian and Asawa, Parth and Hulsebos, Madelon and Lin, Yiming and Zamfirescu-Pereira, J. D. and Chase, Harrison and Fu-Hinthorn, Will and Parameswaran, Aditya G. and Wu, Eugene},
title = {spade: Synthesizing Data Quality Assertions for Large Language Model Pipelines},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685835},
doi = {10.14778/3685800.3685835},
abstract = {Large language models (LLMs) are being increasingly deployed as part of pipelines that repeatedly process or generate data of some sort. However, a common barrier to deployment are the frequent and often unpredictable errors that plague LLMs. Acknowledging the inevitability of these errors, we propose data quality assertions to identify when LLMs may be making mistakes. We present spade, a method for automatically synthesizing data quality assertions that identify bad LLM outputs. We make the observation that developers often identify data quality issues during prototyping prior to deployment, and attempt to address them by adding instructions to the LLM prompt over time. spade therefore analyzes histories of prompt versions over time to create candidate assertion functions and then selects a minimal set that fulfills both coverage and accuracy requirements. In testing across nine different real-world LLM pipelines, spade efficiently reduces the number of assertions by 14% and decreases false failures by 21% when compared to simpler baselines. spade has been deployed as an offering within LangSmith, LangChain's LLM pipeline hub, and has been used to generate data quality assertions for over 2000 pipelines across a spectrum of industries.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4173–4186},
numpages = {14}
}

@inproceedings{10.1145/3639476.3639773,
author = {Wang, Jiabo and Chu, Guojun and Wang, Jingyu and Sun, Haifeng and Qi, Qi and Wang, Yuanyi and Qi, Ji and Liao, Jianxin},
title = {LogExpert: Log-based Recommended Resolutions Generation using Large Language Model},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639476.3639773},
doi = {10.1145/3639476.3639773},
abstract = {Software logs play a vital role in ensuring the reliability and availability of large-scale software systems. In recent years, researchers have made significant efforts to build log analysis approaches to manage software systems. However, these approaches focus on log compression, log parsing and log anomaly detection. In the current context, engineers continue to spend substantial time and effort on resolving errors once anomalous logs have been detected. To achieve truly automated software system management and high-level Artificial Intelligence for IT Operations (AIOps), it's necessary to bridge the gap between anomalous logs and their resolutions.In this paper, we propose a novel framework LogExpert to automatically generate recommended resolutions for anomalous logs. Specifically, we build a log recognizer to utilize the wealth of software knowledge in technical forums such as Stack Overflow (SO). In addition, LogExpert combines the great power of a Large Language Model (LLM) with domain-specific knowledge to generate the resolution. We conducted a preliminary evaluation of our framework on datasets from SO. Our log recognizer achieves the F1 score of 0.936. Our lexical metrics and human evaluation show the overall LogExpert framework achieves excellent performance in log-based resolution generation.},
booktitle = {Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {42–46},
numpages = {5},
keywords = {log-based resolution generation, log anomaly detection, large language models, Stack Overflow},
location = {Lisbon, Portugal},
series = {ICSE-NIER'24}
}

@inproceedings{10.1145/3663529.3663820,
author = {Cogo, Filipe Roseiro and Rajbahadur, Gopi Krishnan and Lin, Dayi and Hassan, Ahmed E.},
title = {A Tutorial on Software Engineering for FMware},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663820},
doi = {10.1145/3663529.3663820},
abstract = {Foundation Models (FMs) like GPT-4 have given rise to FMware, FM-powered applications representing a new generation of software that is developed with new roles, assets, and paradigms. FMware has been widely adopted in both software engineering (SE) research (e.g., test generation) and industrial products (e.g., GitHub copilot), despite the numerous challenges introduced by the stochastic nature of FMs. In our tutorial, we will present the latest research and industrial practices in engineering FMware, along with a hands-on session to acquaint attendees with core tools and techniques to build FMware. Our tutorial's perspective is firmly rooted in SE rather than artificial intelligence (AI), ensuring that participants are spared from delving into mathematical and AI-related intricacies unless they are crucial for introducing SE challenges and opportunities.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {710–712},
numpages = {3},
keywords = {FMware, Foundation Model, Software engineering for FMware},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@proceedings{10.1145/3639474,
title = {ICSE-SEET '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3617650.3624928,
author = {Raj, Rajendra K. and Becker, Brett A. and Goldweber, Michael and Jalote, Pankaj},
title = {Perspectives on Computer Science Curricula 2023 (CS2023)},
year = {2023},
isbn = {9798400703744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617650.3624928},
doi = {10.1145/3617650.3624928},
abstract = {This panel examines Computer Science Curricula 2023 (CS2023) from different perspectives. All panelists serve on the CS2023 steering committee and have an intimate understanding of CS2023. The moderator will lay out its overall vision and structure while panelists will emphasize three major perspectives of CS education: software development fundamentals; systems development; and the increased role of societal, ethical, and professional aspects crucial to a modern CS graduate. Strong interdependencies exist between these perspectives, along with tensions arising from how much can be squeezed into a tight undergraduate CS curriculum. Attendees will take home an understanding of the approach taken by the CS2023 task force, the constraints on curriculum design, and how best to use the CS2023 guidelines to educate the next generation of CS graduates.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 2},
pages = {187–188},
numpages = {2},
keywords = {computer science curricular guidelines, model curricula},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@article{10.1145/3709360,
author = {Mastropaolo, Antonio and Escobar-Vel\'{a}squez, Camilo and Linares-V\'{a}squez, Mario},
title = {From Triumph to Uncertainty: The Journey of Software Engineering in the AI Era},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3709360},
doi = {10.1145/3709360},
abstract = {Over the last 10 years, the realm of AI has experienced an explosion of revolutionary breakthroughs, transforming what seemed like a far-off dream into a reality that is now deeply embedded in our everyday lives. AI’s widespread impact is revolutionizing virtually all aspects of human life, and software engineering (SE) is no exception. As we explore this changing landscape, we are faced with questions about what the future holds for SE and how AI will reshape the roles, duties, and methodologies within the field. The introduction of these groundbreaking technologies highlights the inevitable shift toward a new paradigm, suggesting a future where AI’s capabilities may redefine the boundaries of SE, potentially even more than human input.In this article, we aim at outlining the key elements that, based on our expertise, are vital for the smooth integration of AI into SE, all while preserving the intrinsic human creativity that has been the driving force behind the field. First, we provide a brief description of SE and AI evolution. Afterward, we delve into the intricate interplay between AI-driven automation and human innovation, exploring how these two components can work together to advance SE practices to new methods and standards.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {131},
numpages = {34},
keywords = {Software engineering, Artificial Intelligence, History, AI4SE, LLM4Code}
}

@inproceedings{10.1145/3699538.3699542,
author = {Kreinsen, Moritz and Rabe, Anna and Grospietsch, Finja and Schulz, Sandra},
title = {Leveraging Conceptual Change regarding Artificial Intelligence in Computer Science Education},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699542},
doi = {10.1145/3699538.3699542},
abstract = {Various research studies have been conducted on the topic of students’ conceptions of artificial intelligence (AI), but there is insufficient research into how these conceptions can be changed. In computer science education, there is a need to empirically research solutions or activities for conceptions that have already been discovered in order to make them usable in terms of educational reconstruction and integrate them into instruction. However, this is hardly ever done yet. Our work addresses this issue and can be transferred as a prototype study to other areas of conceptions research in computer science education. To this end, a teaching intervention was conducted with 10th and 11th grade secondary school students in Germany in order to measure the change in their agreement to specific conceptions with the help of pre- and post-tests. This study was conducted with N = 76&nbsp;students who were divided into an experimental and control group. The results of the study show that conceptual change texts are a promising teaching method for expanding students’ conceptions of AI. This is indicated by the results of the post-test, in which students who worked with the conceptual change text were able to demonstrate greater agreement to the conception presented. However, the results of the study needs to be critically discussed in terms of validity and future perspectives.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {49},
numpages = {7},
keywords = {ai, conceptual change, conceptual change text, computer science education, quasi-experimental study, chatgpt},
location = {
},
series = {Koli Calling '24}
}

@proceedings{10.1145/3641554,
title = {SIGCSETS 2025: Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 56th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2025)! For the first time since 1978, our symposium is being held in the "Steel City" of Pittsburgh, Pennsylvania, at the intersection of the Allegheny, Ohio, and Monongahela rivers. We are looking forward to four days of productive and informative presentations, vibrant and engaging discussions, and an overall wonderful experience with our SIGCSE community members. We are confident that our program of events provides meaningful and productive experiences for all.Our theme for this year is "Leading the Transformation". Our theme reflects the role of the computer science education community in adapting educational practice to new technologies and challenges. With advances in Artificial Intelligence (AI) transforming both academia and the workplace, the computer science education community has a unique opportunity to help shape the future use and application of computing. Our program this year is quite diverse and offers something for everyone, so please take time to peruse the schedule and choose the sessions which appeal to you. Pittsburgh is also an exciting city with lots to see and do, so you are encouraged to enjoy all the city has to offer.The format of the 2025 Technical Symposium is similar to 2024 in many ways. We will once again have a program that extends into Saturday afternoon, including papers and the Nifty Assignment session after lunch. We will also again have three Birds-of-a-Feather sessions, two on Thursday evening and one during lunch on Friday. For online attendees, we will continue to offer streaming of keynotes, the Nifty Assignment session, the First-Timers Lunch presentation, and a small set of paper, panel, and special sessions.This year we received almost 1200 submissions. Submission statistics for all of the Technical Symposium's tracks can be found in the table that follows. Papers were submitted to one of three tracks (Computing Education Research, Experience Reports and Tools, Position and Curricula Initiatives) with reviewing tailored to each track. Each paper submission was reviewed by at least three reviewers, with a substantial proportion of papers receiving four (or more) reviews, plus a meta review. We sincerely appreciate the work of the more than 800 reviewers and 112 Associate Program Chairs who contributed to the creation of this years' program. Their reviews helped us decide which submissions were accepted while also providing detailed feedback that allowed authors to further improve the final versions of their submissions.},
location = {Pittsburgh, PA, USA}
}

@inproceedings{10.1145/3674805.3686666,
author = {Felizardo, Katia Romero and Lima, M\'{a}rcia Sampaio and Deizepe, Anderson and Conte, Tayana Uch\^{o}a and Steinmacher, Igor},
title = {ChatGPT application in Systematic Literature Reviews in Software Engineering: an evaluation of its accuracy to support the selection activity},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3686666},
doi = {10.1145/3674805.3686666},
abstract = {Context: The Systematic Literature Review (SLR) process involves searching, selecting, and synthesizing relevant literature on a specific research topic for evidence-based decision-making in Software Engineering (SE). Due to the time-consuming of the SLR process, tool support is essential. Gap: ChatGPT is a significant advancement in Natural Language Processing (NLP), and it can potentially accelerate time-consuming and propone-error activities, such as the selection activity of the SLR process. Therefore, having a tool to assist in the selection process appears beneficial, and we argue that ChatGPT can facilitate the analysis of extensive studies, saving time and effort. Objective: We aim to evaluate the accuracy (i.e., studies correctly classified) of using ChatGPT–4.0 in SLR in SE, particularly to support the first stage, based on the title, abstract, and keywords. Method: We assessed the accuracy of utilizing ChatGPT for selecting studies, the first stage, to be included in two SLRs (SLR1 and SLR2), in contrast to the conventional method of reading the title and abstract. Results: The accuracy of ChatGPT supporting the initial selection activity was 75.3% (SLR1 – 101 correct selections: 48 inclusions and 53 exclusions; 33 incorrect selections: 17 inclusions and 16 exclusions) and 86.1% (SLR2 – 386 correct selections: 113 inclusions and 273 exclusions; 62 incorrect selections: 27 inclusions and 35 exclusions). Conclusions: Our accuracy results indicate that it is not advisable to completely outsource the selection process to ChatGPT. However, it could be valuable as a support tool, aiding novice researchers or even experienced ones when they are in doubt.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {25–36},
numpages = {12},
keywords = {ChatGPT, Selection of studies, Software Engineering, Systematic literature review},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@article{10.1145/3701223,
author = {Shein, Esther},
title = {The Evolution of Computer Science at the University Level},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {68},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3701223},
doi = {10.1145/3701223},
abstract = {Combining computer science with arts disciplines may be the wave of the future for education.},
journal = {Commun. ACM},
month = jan,
pages = {14–16},
numpages = {3}
}

@inproceedings{10.1145/3653666.3656092,
author = {Levitt, Diane and Ray, Meg},
title = {Ecosystems That Build Equitable, K-5 Sustainable Computer Science Education},
year = {2024},
isbn = {9798400706264},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653666.3656092},
doi = {10.1145/3653666.3656092},
abstract = {The rollout of computer science education has been dependent on a patchwork of uncoordinated professional learning experiences. This has left some schools serving students from underrepresented groups without an articulated, rigorous, joyful K-12 CS education. Based on our work with four urban schools serving such students, we propose that an ecosystem of support that prepares every administrator and teacher to include CS in every student's education with a whole school approach and sustained professional learning, is one way to assure an equitable, sustainable CS education. We propose changes in policy to scaffold such an ecosystem.},
booktitle = {Proceedings of the 2024 on RESPECT Annual Conference},
pages = {254–258},
numpages = {5},
keywords = {K-5 computer science education, computational agency, computational thinking, content coaching, equity, justice-centered computing, teacher professional development},
location = {Atlanta, GA, USA},
series = {RESPECT 2024}
}

@inproceedings{10.1145/3641554.3701841,
author = {Aljedaani, Wajdi and Eler, Marcelo Medeiros and Parthasarathy, P D},
title = {Enhancing Accessibility in Software Engineering Projects with Large Language Models (LLMs)},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701841},
doi = {10.1145/3641554.3701841},
abstract = {Digital accessibility ensures that digital products and services are usable by a diverse range of users, regardless of their physical or cognitive abilities. While numerous standards and guidelines have been established to aid developers in creating accessible content, studies reveal a persistent lack of accessibility in many web and mobile applications. This gap is often attributed to barriers such as lack of awareness, insufficient knowledge, absence of specific requirements, time constraints, and lack of executive support. In this context, we aim to address the lack of awareness and knowledge challenges by proposing a hands-on approach that leverages the capabilities of Large Language Models (LLMs) like ChatGPT to enhance students' accessibility awareness, knowledge, and practical skills. We engaged software engineering students in tasks involving website development and accessibility evaluation using checker tools, and we utilized ChatGPT 3.5 to fix identified accessibility issues. Our findings suggest that practical assignments significantly enhance learning outcomes, as interactions with LLMs allow students to develop a deeper understanding of accessibility concepts. This approach not only reinforces theoretical knowledge but also highlights the real-world impact of their work. The results indicate that combining practical assignments with AI-driven support effectively improves students' proficiency in web accessibility.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {25–31},
numpages = {7},
keywords = {chatgpt 3.5, digital accessibility, large language models, llms, project based learning, software engineering, wcag},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@book{10.1145/3664191,
author = {Kumar, Amruth N. and Raj, Rajendra K. and Aly, Sherif G. and Anderson, Monica D. and Becker, Brett A. and Blumenthal, Richard L. and Eaton, Eric and Epstein, Susan L. and Goldweber, Michael and Jalote, Pankaj and Lea, Douglas and Oudshoorn, Michael and Pias, Marcelo and Reiser, Susan and Servin, Christian and Simha, Rahul and Winters, Titus and Xiang, Qiao},
title = {Computer Science Curricula 2023},
year = {2024},
isbn = {9798400710339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA}
}

@inproceedings{10.1145/3677619.3678092,
author = {Bahr, Tobias and Manzocco, Mario and Schuster, Dennis},
title = {Differentiated Tasks by ChatGPT for Secondary Computer Science Education: Useful or not?},
year = {2024},
isbn = {9798400710056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677619.3678092},
doi = {10.1145/3677619.3678092},
abstract = {In recent years, there has been a growing interest in exploring the capabilities of AI chatbots, such as ChatGPT. Studies have investigated diverse applications, including the response of AI chatbots to undergraduate exam questions and the generation of student exercises for programming. However, the question remains if AI chatbots provide adequate results for K-12 CS in different application scenarios. AI chatbots are increasingly integrated into K-12 education by both students and teachers. In this context, a tool using didactical parameters was created to differentiate tasks with ChatGPT-4 in an ongoing project. Preliminary findings from this work in progress reveal that teachers see a benefit using the tool. Future directions for using the tool are discussed.},
booktitle = {Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {34},
numpages = {2},
keywords = {AI chatbots, ChatGPT, Computer Science Education, Expert rating, K-12},
location = {Munich, Germany},
series = {WiPSCE '24}
}

@article{10.1145/3712007,
author = {Cruz, Lu\'{\i}s and Franch, Xavier and Mart\'{\i}nez-Fern\'{a}ndez, Silverio},
title = {Innovating for Tomorrow: The Convergence of Software Engineering and Green AI},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712007},
doi = {10.1145/3712007},
abstract = {The latest advancements in machine learning, specifically in foundation models, are revolutionizing the frontiers of existing software engineering (SE) processes. This is a bi-directional phenomenon, where (1) software systems are now challenged to provide AI-enabled features to their users, and (2) AI is used to automate tasks within the software development lifecycle. In an era where sustainability is a pressing societal concern, our community needs to adopt a long-term plan enabling a conscious transformation that aligns with environmental sustainability values. In this article, we reflect on the impact of adopting environmentally friendly practices to create AI-enabled software systems and make considerations on the environmental impact of using foundation models for software development.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {138},
numpages = {13},
keywords = {Green AI, Green Software, Sustainability, Software Engineering}
}

@article{10.1145/3680469,
author = {Huang, Qing and Sun, Yanbang and Xing, Zhenchang and Cao, Yuanlong and Chen, Jieshan and Xu, Xiwei and Jin, Huan and Lu, Jiaxing},
title = {Let’s Discover More API Relations: A Large Language Model-Based AI Chain for Unsupervised API Relation Inference},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {8},
issn = {1049-331X},
url = {https://doi.org/10.1145/3680469},
doi = {10.1145/3680469},
abstract = {APIs have intricate relations that can be described in text and represented as knowledge graphs to aid software engineering tasks. Existing relation extraction methods have limitations, such as limited API text corpus, and are affected by the characteristics of the input text. To address these limitations, we propose utilizing large language models (LLMs) (e.g., GPT-3.5) as a neural knowledge base for API relation inference. This approach leverages the entire Web used to pre-train LLMs as a knowledge base and is insensitive to the context and complexity of input texts. To ensure accurate inference, we design an AI chain consisting of three AI modules: API Fully Qualified Name (FQN) Parser, API Knowledge Extractor, and API Relation Decider. The accuracy of the API FQN Parser and API Relation Decider is 0.81 and 0.83, respectively. Using the generative capacity of the LLM and our approach’s inference capability, we achieve an average F1 value of 0.76 under the three datasets, significantly higher than the state-of-the-art method’s average F1 value of 0.40. Compared to the original CoT and modularized CoT methods, our AI chain design has improved the performance of API relation inference by 71% and 49%, respectively. Meanwhile, the prompt ensembling strategy enhances the performance of our approach by 32%. The API relations inferred by our method can be further organized into structured forms to provide support for other software engineering tasks.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {212},
numpages = {34},
keywords = {API Relation, AI Chain, Knowledge Inference, Large Language Model}
}

@inproceedings{10.1145/3663548.3675633,
author = {Haroon, Rukhshan and Dogar, Fahad},
title = {TwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3675633},
doi = {10.1145/3663548.3675633},
abstract = {Autistic individuals often experience difficulties in conveying and interpreting emotional tone and non-literal nuances. Many also mask1 their communication style to avoid being misconstrued by others, spending considerable time and mental effort in the process. To address these challenges in text-based communication, we present TwIPS2, a prototype texting application powered by a large language model (LLM), which can assist users with: a) deciphering tone and meaning of incoming messages, b) ensuring the emotional tone of their message is in line with their intent, and c) coming up with alternate phrasing for messages that could be misconstrued and received negatively by others. We leverage an AI-based simulation and a conversational script to evaluate TwIPS with 8 autistic participants in an in-lab setting. Our findings show TwIPS enables a convenient way for participants to seek clarifications, provides a better alternative to tone indicators, and facilitates constructive reflection on writing technique and style. We also examine how autistic users utilize language for self-expression and interpretation in instant messaging, and gather feedback for enhancing our prototype. We conclude with a discussion around balancing user-autonomy with AI-mediation, establishing appropriate trust levels in AI systems, and autistic users’ customization needs in the context of AI-assisted communication.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {24},
numpages = {18},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@inproceedings{10.1145/3627673.3679596,
author = {Liu, Zhongzhou and Zhang, Hao and Dong, Kuicai and Fang, Yuan},
title = {Collaborative Cross-modal Fusion with Large Language Model for Recommendation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679596},
doi = {10.1145/3627673.3679596},
abstract = {Despite the success of conventional collaborative filtering (CF) approaches for recommendation systems, they exhibit limitations in leveraging semantic knowledge within the textual attributes of users and items. Recent focus on the application of large language models for recommendation (LLM4Rec) has highlighted their capability for effective semantic knowledge capture. However, these methods often overlook the collaborative signals in user behaviors. Some simply instruct-tune a language model, while others directly inject the embeddings of a CF-based model, lacking a synergistic fusion of different modalities. To address these issues, we propose a framework of Collaborative Cross-modal Fusion with Large Language Models, termed CCF-LLM, for recommendation. In this framework, we translate the user-item interactions into a hybrid prompt to encode both semantic knowledge and collaborative signals, and then employ an attentive cross-modal fusion strategy to effectively fuse latent embeddings of both modalities. Extensive experiments demonstrate that CCF-LLM outperforms existing methods by effectively utilizing semantic and collaborative signals in the LLM4Rec context.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {1565–1574},
numpages = {10},
keywords = {collaborative filtering, cross-modal, large language models, recommendation systems},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627508.3638344,
author = {Wang, Ben and Liu, Jiqun and Karimnazarov, Jamshed and Thompson, Nicolas},
title = {Task Supportive and Personalized Human-Large Language Model Interaction: A User Study},
year = {2024},
isbn = {9798400704345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627508.3638344},
doi = {10.1145/3627508.3638344},
abstract = {Large language model (LLM) applications, such as ChatGPT, are a powerful tool for online information-seeking (IS) and problem-solving tasks. However, users still face challenges initializing and refining prompts, and their cognitive barriers and biased perceptions further impede task completion. These issues reflect broader challenges identified within the fields of IS and interactive information retrieval (IIR). To address these, our approach integrates task context and user perceptions into human-ChatGPT interactions through prompt engineering. We developed a ChatGPT-like platform integrated with supportive functions, including perception articulation, prompt suggestion, and conversation explanation. Our findings of a user study demonstrate that the supportive functions help users manage expectations, reduce cognitive loads, better refine prompts, and increase user engagement. This research enhances our comprehension of designing proactive and user-centric systems with LLMs. It offers insights into evaluating human-LLM interactions and emphasizes potential challenges for under served users.},
booktitle = {Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
pages = {370–375},
numpages = {6},
keywords = {ChatGPT, Human-LLM Interaction, Information Seeking, Proactive System, Prompt Engineering},
location = {Sheffield, United Kingdom},
series = {CHIIR '24}
}

@inproceedings{10.1145/3641554.3701829,
author = {Liu, Runda and Chen, Shengqi and Chen, Jiajie and Niu, Songjie and Ma, Yuchun and Tang, Xiaofeng},
title = {Iterative Design of a Teaching Assistant Training Program in Computer Science Using the Agile Method},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701829},
doi = {10.1145/3641554.3701829},
abstract = {Facing soaring enrollment and disruptive educational technologies, computing education increasingly relies on the contributions of teaching assistants (TAs), hence the critical importance of high-quality TA training. However, the design and implementation of TA training in computer science face substantial barriers, such as the lack of experienced TA trainers and the scarcity of relevant training materials.This experience report describes the design and implementation of a peer-led computer science TA training program that began in 2022 and has since undergone three iterations, inspired by the approach of agile software development. The current program consists of 10 sessions, organized to serve TAs in three respective stages of professional development. The iterations involved updating and enrichment of the syllabus, transitioning from lecture-centered to discussion-centered training, and discussions of emerging topics in computing education such as the use of large language models (LLMs). Participant feedback showed that TAs approved the iterative design of the training, while identifying areas for further improvement. We summarize lessons learned from the iterative process, reflect on the role of peer TA trainers, and discuss plans for future iterations.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {680–686},
numpages = {7},
keywords = {agile, ta training, teaching assistant},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713644,
author = {Rogers, Kantwon and Davis, Michael and Maharana, Mallesh and Etheredge, Pete and Chernova, Sonia},
title = {Playing Dumb to Get Smart: Creating and Evaluating an LLM-based Teachable Agent within University Computer Science Classes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713644},
doi = {10.1145/3706598.3713644},
abstract = {This work presents the iterative design and evaluation of a large-language-model (LLM) based teachable agent, MatlabTutee, that facilitates learning-by-teaching (LBT) experiences within university computer science courses. We detail four different experiments, with a total of 119 students, where we refine our system, compare it to human-facilitated LBT experiences, and deploy it in two, month-long in-the-wild environments. We find that our system is able to successfully convey a learner persona similar to a human pretending to be novice while also providing comparable LBT benefits. These benefits include helping students identify areas for improvement, develop a more accurate assessment of their own abilities, and improve their overall attitudes toward computer science. We also explore how students choose to adopt our system into their study habits while situated in real university courses.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {126},
numpages = {22},
keywords = {Computer Science Education, LLM, Teachable Agent, Deception, Learning by Teaching, University Students, Longitudinal},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3698300.3698320,
author = {Xie, Limiao and Li, Yingying and Zhang, Jianfeng and Jia, Ning and Xiong, Lin and Deng, Gansheng},
title = {Data Security Protection and Analysis of ERP System Based on NL2SQL with Large Language Model and Encrypted Database},
year = {2024},
isbn = {9798400717512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698300.3698320},
doi = {10.1145/3698300.3698320},
abstract = {In the era of big data, enterprises have higher and higher requirements for data security, especially when dealing with massive amounts of sensitive information in ERP systems, data security issues become particularly important. To address this challenge, In this paper, we propose a multi-layer encryption scheme based on a encrypted database, including device-level encryption, user-level encryption, table-level encryption, field-level encryption, and row-level authentication, aiming to protect the data information of the ERP system in a multi-dimensional way. To verify the effectiveness of the scheme, this paper applies it on the human resource data of the ERP system to ensure that the data storage, transmission, and access processes are in an encrypted state in the big data environment. In addition, this paper incorporates NL2SQL with Large Language Model(LLM) to realize conversational data analysis, generating SQL queries through natural language to cope with the complex and changing query requirements in the big data environment, and to enhance the flexibility and intelligence of data access. The research results show that the proposed multi-layer encryption scheme and conversational data analysis method not only significantly improves the data security of the ERP system in the big data environment, but also optimizes the efficiency of the enterprise in the process of big data analysis and retrieval, and mends the natural defects of the NL2SQL security protection, which guarantees the data security for the landing of LLM applications.},
booktitle = {Proceedings of the 2024 7th International Conference on Big Data Technologies},
pages = {71–75},
numpages = {5},
keywords = {big data, data security, encrypted database, Large Language Model, NL2SQL},
location = {
},
series = {ICBDT '24}
}

@article{10.1145/3732895.3732900,
author = {Blaser, Brianna},
title = {RESPECT 2025: Designing an Accessible Future for Equitable Computer Science},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0097-8418},
url = {https://doi.org/10.1145/3732895.3732900},
doi = {10.1145/3732895.3732900},
abstract = {The ACM SIGCSE Conference on Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT) 2025 will be held 14–16 July at the New Jersey Institute of Technology in Newark, NJ, USA. The theme for this year is Designing an Accessible Future for Equitable Computer Science. 2025 marks the fiftieth anniversary of the Individuals with Disabilities in Education Act, landmark legislation in the United States developed to ensure students with disabilities receive a free, appropriate public education. When we began planning the conference, we envisioned an opportunity to reflect on disability inclusion.},
journal = {SIGCSE Bull.},
month = apr,
pages = {4},
numpages = {1}
}

@article{10.5555/3729857.3729865,
author = {Kulkarni, Sourabh and Attarwala, Abbas and Raigoza, Jaime},
title = {Impact of COVID-19 on Live-Coding in First-Year Computer Science Education: A Literature Review},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {6},
issn = {1937-4771},
abstract = {The COVID pandemic has significantly influenced educational methodologies, leading to a shift towards more interactive and technology-integrated teaching approaches. Live-coding, which involves real-time coding demonstrations, has gained recognition as a valuable tool in computer science education. This study investigates the impact of the pandemic on the popularity and application of live-coding. By conducting a comprehensive literature review of 22 research papers, this study categorizes the papers based on their publication date relative to the pandemic: pre-COVID (2017 to 2019), during COVID (2020 to 2022), and post-COVID (2023 to 2024). The papers were selected using a specific search query for live-coding in introductory computer science education on Google Scholar. A systematic literature review was performed to determine their sentiment towards live-coding, categorizing the sentiments as positive, neutral, or negative. The sentiment data were then statistically analyzed using Fisher's Exact Test to assess significant differences across the three periods. Results from this manuscript indicate shifts in positive sentiment towards live-coding during and after the pandemic.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {65–74},
numpages = {10}
}

@inproceedings{10.1145/3636243.3636257,
author = {Budhiraja, Ritvik and Joshi, Ishika and Challa, Jagat Sesh and Akolekar, Harshal D. and Kumar, Dhruv},
title = {“It's not like Jarvis, but it's pretty close!” - Examining ChatGPT's Usage among Undergraduate Students in Computer Science},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636257},
doi = {10.1145/3636243.3636257},
abstract = {Large language models (LLMs) such as ChatGPT and Google Bard have garnered significant attention in the academic community. Previous research has evaluated these LLMs for various applications such as generating programming exercises and solutions. However, these evaluations have predominantly been conducted by instructors and researchers, not considering the actual usage of LLMs by students. This study adopts a student-first approach to comprehensively understand how undergraduate computer science students utilize ChatGPT, a popular LLM, released by OpenAI. We employ a combination of student surveys and interviews to obtain valuable insights into the benefits, challenges, and suggested improvements related to ChatGPT. Our findings suggest that a majority of students (over 57%) have a convincingly positive outlook towards adopting ChatGPT as an aid in coursework-related tasks. However, our research also highlights various challenges that must be resolved for long-term acceptance of ChatGPT amongst students. The findings from this investigation have broader implications and may be applicable to other LLMs and their role in computing education.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {124–133},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, User Study},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@article{10.1145/3719006,
author = {Ahmed, Iftekhar and Aleti, Aldeida and Cai, Haipeng and Chatzigeorgiou, Alexander and He, Pinjia and Hu, Xing and Pezz\`{e}, Mauro and Poshyvanyk, Denys and Xia, Xin},
title = {Artificial Intelligence for Software Engineering: The Journey So Far and the Road Ahead},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3719006},
doi = {10.1145/3719006},
abstract = {Artificial intelligence and recent advances in deep learning architectures, including transformer networks and large language models, change the way people think and act to solve problems. Software engineering, as an increasingly complex process to design, develop, test, deploy, and maintain large-scale software systems for solving real-world challenges, is profoundly affected by many revolutionary artificial intelligence tools in general and machine learning in particular. In this roadmap for artificial intelligence in software engineering, we highlight the recent deep impact of artificial intelligence on software engineering by discussing successful stories of applications of artificial intelligence to classic and new software development challenges. We identify the new challenges that the software engineering community has to address in the coming years to successfully apply artificial intelligence in software engineering, and we share our research roadmap toward the effective use of artificial intelligence in the software engineering profession, while still protecting fundamental human values.We spotlight three main areas that challenge the research in software engineering: the use of generative artificial intelligence and large language models for engineering large software systems, the need of large and unbiased datasets and benchmarks for training and evaluating deep learning and large language models for software engineering, and the need of a new code of digital ethics to apply artificial intelligence in software engineering.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {119},
numpages = {27},
keywords = {Automated Software Development, Machine Learning, Large Language Models, Artificial Intelligence, Explainable AI, Ethical AI}
}

@article{10.1145/3709616.3709620,
author = {Parra, Esteban and Aponte, Jairo},
title = {Report from the Summer School on Software Engineering andArtificial Intelligence},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/3709616.3709620},
doi = {10.1145/3709616.3709620},
abstract = {This report summarizes the curriculum and academic outcomes of the Summer School on Software Engineering and Artificial Intelligence (AI) held at the Universidad de Los Andes in Bogot´a, Colombia. The summer school offered an in-depth introduction to the fields of Machine Learning (ML), Artificial Intelligence (AI), and Natural Language Processing (NLP); their role and applications in Software Engineering (SE) and the software development process. The feedback we received from the participants indicates that the program successfully enhanced their knowledge and the skills needed for them to navigate the role of AI in the current landscape of software engineering.The students of the summer school were engaged in the development of a full software system using AI-based tools as part of the development process. We found that the project was successful in providing the students with experience regarding how to incorporate AI-based tools as part of their software development process but not all students showed the same level of proficiency when leveraging AI tools.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jan,
pages = {12–14},
numpages = {3}
}

@inproceedings{10.1145/3627673.3679760,
author = {Fu, Lingyue and Guan, Hao and Du, Kounianhua and Lin, Jianghao and Xia, Wei and Zhang, Weinan and Tang, Ruiming and Wang, Yasheng and Yu, Yong},
title = {SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679760},
doi = {10.1145/3627673.3679760},
abstract = {Knowledge Tracing (KT) aims to determine whether students will respond correctly to the next question, which is a crucial task in intelligent tutoring systems (ITS). In educational KT scenarios, transductive ID-based methods often face severe data sparsity and cold start problems, where interactions between individual students and questions are sparse, and new questions and concepts consistently arrive in the database. In addition, existing KT models only implicitly consider the correlation between concepts and questions, lacking direct modeling of the more complex relationships in the heterogeneous graph of concepts and questions. In this paper, we propose a &lt;u&gt;S&lt;/u&gt;tructure-aware &lt;u&gt;IN&lt;/u&gt;ductive &lt;u&gt;K&lt;/u&gt;nowledge &lt;u&gt;T&lt;/u&gt;racing model with large language model (dubbed SINKT), which, for the first time, introduces large language models (LLMs) and realizes inductive knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural relationships between concepts and constructs a hetero- geneous graph for concepts and questions. Secondly, by encoding concepts and questions with LLMs, SINKT incorporates semantic information to aid prediction. Finally, SINKT predicts the student's response to the target question by interacting with the student's knowledge state and the question representation. Experiments on four real-world datasets demonstrate that SINKT achieves state-of-the-art performance among 12 existing transductive KT models. Additionally, we explore the performance of SINKT on the inductive KT task and provide insights into various modules.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {632–642},
numpages = {11},
keywords = {inductive learning, knowledge tracing, online education},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inbook{10.1145/3724504.3724627,
author = {Chen, Yanbing},
title = {Research on the application of large language model to financial digital literacy education},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724627},
abstract = {This study investigates the integration of large models into financial digital literacy education in Xi 'an Eurasia University by means of questionnaire. The results show that the large model helps to transcend the limitations of teachers and time and space, and helps to improve students' financial inclusion literacy. This study can be used as a reference for other schools to integrate large models into the classroom and for education equality in poor areas.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {748–752},
numpages = {5}
}

@inproceedings{10.1145/3641555.3705236,
author = {Chopra, Ryka C. and Chakraborty, Suparna},
title = {RAFIKI: Leveraging Large Language Models to Increase AP Computer Science A Enrollment among Disadvantaged High School Females},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705236},
doi = {10.1145/3641555.3705236},
abstract = {The gender gap in computing persists even after decades of investment in lowering the gap. Evidence suggests that stereotypical attitudes and bias perceptions play a critical role in limiting female participation in STEM, beginning in middle and high school. The gap is exacerbated in developing nations with limited academic counselor support. Therefore, the goal is to provide early targeted counseling. RAFIKI - "friend" in Swahili is a large language model-based web application designed to mimic an academic coach. Using user inputs, it provides customized academic counseling with curated information on STEM and computing pathways. Initial experimental evidence shows that RAFIKI use leads to a significant increase in AP Computer Science A course enrollment, considered a pathway to future computing career, particularly among female high school students.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1417–1418},
numpages = {2},
keywords = {AP CSA, ChatGPT, digital coach, female enrollment},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705266,
author = {Hou, Irene and Nguyen, Hannah Vy and Man, Owen and MacNeil, Stephen},
title = {The Evolving Usage of GenAI by Computing Students},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705266},
doi = {10.1145/3641555.3705266},
abstract = {Help-seeking is a critical aspect of learning and problem-solving for computing students. Recent research has shown that many students are aware of generative AI (GenAI) tools; however, there are gaps in the extent and effectiveness of how students use them. With over two years of widespread GenAI usage, it is crucial to understand whether students' help-seeking behaviors with these tools have evolved and how. This paper presents findings from a repeated cross-sectional survey conducted among computing students across North American universities ( n=95 ). Our results indicate shifts in GenAI usage patterns. In 2023, 34.1% of students ( n=47 ) reported never using ChatGPT for help, ranking it fourth after online searches, peer support, and class forums. By 2024, this figure dropped sharply to 6.3% ( n=48 ), with ChatGPT nearly matching online search as the most commonly used help resource. Despite this growing prevalence, there has been a decline in students' hourly and daily usage of GenAI tools, which may be attributed to a common tendency to underestimate usage frequency. These findings offer new insights into the evolving role of GenAI in computing education, highlighting its increasing acceptance and solidifying its position as a key help resource.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1481–1482},
numpages = {2},
keywords = {chatgpt, computing education, generative ai, help-seeking},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641822.3641880,
author = {Alami, Adam and Ernst, Neil},
title = {Understanding the building blocks of accountability in software engineering},
year = {2024},
isbn = {9798400705335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641822.3641880},
doi = {10.1145/3641822.3641880},
abstract = {In the social and organizational sciences, accountability has been linked to the efficient operation of organizations. However, it has received limited attention in software engineering (SE) research, in spite of its central role in the most popular software development methods (e.g., Scrum). In this article, we explore the mechanisms of accountability in SE environments. We investigate the factors that foster software engineers' individual accountability within their teams through an interview study with 12 people. Our findings recognize two primary forms of accountability shaping software engineers individual senses of accountability: institutionalized and grassroots. While the former is directed by formal processes and mechanisms, like performance reviews, grassroots accountability arises organically within teams, driven by factors such as peers' expectations and intrinsic motivation. This organic form cultivates a shared sense of collective responsibility, emanating from shared team standards and individual engineers' inner commitment to their personal, professional values, and self-set standards. While institutionalized accountability relies on traditional "carrot and stick" approaches, such as financial incentives or denial of promotions, grassroots accountability operates on reciprocity with peers and intrinsic motivations, like maintaining one's reputation in the team.},
booktitle = {Proceedings of the 2024 IEEE/ACM 17th International Conference on Cooperative and Human Aspects of Software Engineering},
pages = {153–163},
numpages = {11},
keywords = {accountability, human aspects of software engineering, qualitative methods, interviews},
location = {Lisbon, Portugal},
series = {CHASE '24}
}

@inproceedings{10.1145/3613904.3641904,
author = {Cheng, Furui and Zouhar, Vil\'{e}m and Arora, Simran and Sachan, Mrinmaya and Strobelt, Hendrik and El-Assady, Mennatallah},
title = {RELIC: Investigating Large Language Model Responses using Self-Consistency},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641904},
doi = {10.1145/3613904.3641904},
abstract = {Large Language Models (LLMs) are notorious for blending fact with fiction and generating non-factual content, known as hallucinations. To address this challenge, we propose an interactive system that helps users gain insight into the reliability of the generated text. Our approach is based on the idea that the self-consistency of multiple samples generated by the same LLM relates to its confidence in individual claims in the generated texts. Using this idea, we design RELIC, an interactive system that enables users to investigate and verify semantic-level variations in multiple long-form responses. This allows users to recognize potentially inaccurate information in the generated text and make necessary corrections. From a user study with ten participants, we demonstrate that our approach helps users better verify the reliability of the generated text. We further summarize the design implications and lessons learned from this research for future studies of reliable human-LLM interactions.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {647},
numpages = {18},
keywords = {hallucination detection, human-AI interaction, natural language processing},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@proceedings{10.1145/3709025,
title = {CSLAW '25: Proceedings of the 2025 Symposium on Computer Science and Law},
year = {2025},
isbn = {9798400714214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Munich, Germany}
}

@inproceedings{10.1145/3726010.3726020,
author = {Zhang, Bo and Wei, Yuqin},
title = {Research on the Communication and Activation Strategies of Traditional Culture by Large Language Model (LLM) Technology—Taking “Shun Culture” as an Example},
year = {2025},
isbn = {9798400712845},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726010.3726020},
doi = {10.1145/3726010.3726020},
abstract = {In the context of todays rapid development of large language model (LLM) technology, it is particularly important to study the dissemination and activation strategies of traditional culture by digital technology. With the continuous advancement of artificial intelligence technology, large language models have become an important tool to promote cultural inheritance and innovation. Through digital processing and intelligent analysis of traditional cultural content, LL M can help us better understand and disseminate these precious cultural heritages.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence, Digital Media Technology and Interaction Design},
pages = {67–71},
numpages = {5},
keywords = {Shun culture, digital technology, inheritance of traditional culture, large language model},
location = {
},
series = {ICADI '24}
}

@inproceedings{10.1145/3641554.3701852,
author = {Hunter, Jessica and Bai, Elena and Alberini, Giulia and Robinson, Kristy A.},
title = {Needs-Supportive Teaching Interventions in an Intro Computer Science Course: Exploring Impacts on Student Motivation and Achievement},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701852},
doi = {10.1145/3641554.3701852},
abstract = {The instructor of a large, introductory computer science (CS) course at a public Canadian university implemented two interventions designed to support students' academic success and basic psychological needs as posited by self-determination theory (SDT). Interventions involved providing grading scheme choice for all students and sending targeted support emails to students who struggled on early term assessments. In keeping with SDT, we assessed the possible effect of these interventions on students' perceptions of competence (self-efficacy), autonomy, relatedness (via measures of instructor warmth), and final grades, by comparing the intervention cohort with a previous control cohort. Results indicate that all students in the intervention term may have benefited from grading scheme choice, as they earned higher final grades and felt more autonomous than the control group students. Moreover, struggling students who received support emails earned an average final grade 11.3% higher than struggling students in the control term. These students also performed closer to their non-struggling counterparts than those in the control group, reducing the achievement gap between early struggling and non-struggling students by 8.1%. Furthermore, even when controlling for past achievement, perceptions of self-efficacy and autonomy support positively predicted students' final grades across groups, with a small effect size. These results offer theoretical and practical insight into effective, light-touch teaching interventions which CS instructors can implement in large courses.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {534–539},
numpages = {6},
keywords = {academic achievement, grading scheme choice, motivation, targeted support, teaching interventions},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3686852.3686864,
author = {Dakshit, Sagnik},
title = {Faculty Perspectives on the Potential of RAG in Computer Science Higher Education},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3686864},
doi = {10.1145/3686852.3686864},
abstract = {The emergence of Large Language Models (LLMs) has significantly impacted the field of Natural Language Processing and has transformed conversational tasks across various domains because of their widespread integration in applications and public access. The discussion surrounding the application of LLMs in education has raised ethical concerns, particularly concerning plagiarism and policy compliance. Despite the prowess of LLMs in conversational tasks, the limitations of reliability and hallucinations exacerbate the need to guardrail conversations, motivating our investigation of RAG in computer science higher education. We developed Retrieval Augmented Generation (RAG) applications for the two tasks of virtual teaching assistants and teaching aids. In our study, we collected the ratings and opinions of faculty members in undergraduate and graduate computer science university courses at various levels, using our personalized RAG systems for each course. This study is the first to gather faculty feedback on the application of LLM-based RAG in education. The investigation revealed that while faculty members acknowledge the potential of RAG systems as virtual teaching assistants and teaching aids, certain barriers and features are suggested for their full-scale deployment. These findings contribute to the ongoing discussion on the integration of advanced language models in educational settings, highlighting the need for careful consideration of ethical implications and the development of appropriate safeguards to ensure responsible and effective implementation.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {19–24},
numpages = {6},
keywords = {Education, Large Language Models, Learning, Neural Networks, Retrieval Augmented Generation},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3543507.3587431,
author = {Bhavya, Bhavya and Xiong, Jinjun and Zhai, Chengxiang},
title = {CAM: A Large Language Model-based Creative Analogy Mining Framework},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3587431},
doi = {10.1145/3543507.3587431},
abstract = {Analogies inspire creative solutions to problems, and facilitate the creative expression of ideas and the explanation of complex concepts. They have widespread applications in scientific innovation, creative writing, and education. The ability to discover creative analogies that are not explicitly mentioned but can be inferred from the web is highly desirable to power all such applications dynamically and augment human creativity. Recently, Large Pre-trained Language Models (PLMs), trained on massive Web data, have shown great promise in generating mostly known analogies that are explicitly mentioned on the Web. However, it is unclear how they could be leveraged for mining creative analogies not explicitly mentioned on the Web. We address this challenge and propose Creative Analogy Mining (CAM), a novel framework for mining creative analogies, which consists of the following three main steps: 1) Generate analogies using PLMs with effectively designed prompts, 2) Evaluate their quality using scoring functions, and 3) Refine the low-quality analogies by another round of prompt-based generation. We propose both unsupervised and supervised instantiations of the framework so that it can be used even without any annotated data. Based on human evaluation using Amazon Mechanical Turk, we find that our unsupervised framework can mine 13.7% highly-creative and 56.37% somewhat-creative analogies. Moreover, our supervised scores are generally better than the unsupervised ones and correlate moderately with human evaluators, indicating that they would be even more effective at mining creative analogies. These findings also shed light on the creativity of PLMs 1.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {3903–3914},
numpages = {12},
keywords = {analogy mining, creativity, large language model},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3641554.3701861,
author = {Barkhuff, Grace and Pruitt, Ian and Namani, Vyshnavi and Johnson, William Gregory and Borela, Rodrigo and Zegura, Ellen and Bourgeois, Anu G. and Shapiro, Ben Rydal},
title = {Exploring the Humanistic Role of Computer Science Teaching Assistants across Diverse Institutions},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701861},
doi = {10.1145/3641554.3701861},
abstract = {Recently, there has been a growing interest in the role of teaching assistants (TAs) in computer science (CS). This interest is due to the vital role CS TAs play in supporting student learning and their expanding responsibilities driven by growing enrollments in CS programs worldwide. While much of this research focuses on the technical and pedagogical aspects of CS TAs' duties, researchers recognize the need to further explore the unique value human CS TAs provide, particularly with the rise of AI tools and assistants. In this paper, we use qualitative methods to analyze 109 survey responses collected across two different institutions in the United States as part of a larger design-based research project to make two contributions. First, we illustrate how CS TAs adopt humanistic stances and demonstrate care in their roles, thereby expanding prevailing understandings of CS TAs. Second, we detail similarities and differences across CS TAs' experiences at each institution that underscore the importance of understanding CS TAs as they are situated in different institutional contexts. We conclude by discussing implications of this work for computing instruction and TA training, emphasizing the importance of foregrounding the roles and values brought by TAs.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {67–73},
numpages = {7},
keywords = {cs education, pedagogy, qualitative methods, responsive pedagogy, ta training, tas, teaching assistants},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3613372.3614189,
author = {Albonico, Michel and Varela, Paulo J\'{u}nior},
title = {A Report on the Use of ChatGPT in Software Engineering and Systems Analysis Courses},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613372.3614189},
doi = {10.1145/3613372.3614189},
abstract = {ChatGPT is a natural language model that works as a virtual chat assistant. It has the potential to be used for fostering classroom discussions and addressing student needs when the professor is not accessible. Although it is still early to assess the impact of ChatGPT and similar technologies, there is a considerable discussion on social media and blogs regarding the aspirations and opportunities of utilizing ChatGPT in the software industry and education. The main perception is that ChatGPT can serve as a support tool but should not completely replace interpersonal interaction, as face-to-face dialogue remains crucial for the development of interpersonal skills and a deeper understanding of concepts. This article reports a recent classroom experience in the subjects of Software Engineering and Systems Analysis, while also analyzing ChatGPT’s responses to student inquiries.},
booktitle = {Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
pages = {303–311},
numpages = {9},
keywords = {ChatGPT, Software Engineering, Student Support, System Analysis},
location = {Campo Grande, Brazil},
series = {SBES '23}
}

@inproceedings{10.1145/3660043.3660174,
author = {Wu, Dongjie and Chen, Lizhu and Han, Yunbing},
title = {Challenges that generative artificial intelligence poses to higher education and management and the countermeasures— A visualized analysis of literature from 2019 to 2023 using CiteSpace},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660174},
doi = {10.1145/3660043.3660174},
abstract = {In this study, a visualized analysis of the target literature is made from different perspectives using CiteSpace and the literature analysis module of the Chinese National Knowledge Infrastructure (CNKI) to identify the challenges that the generative artificial intelligence (GAI) technology poses to higher education and management and corresponding countermeasures. Our analysis revealed that GAI would reduce the demand for teachers, weaken the teacher-student tie, and exacerbate the students’ digital overdependence, causing conflicts in data ethics and intellectual property. Thus, recommendations are made here for the four parties involved in the research: the government should formulate laws to strengthen network supervision; schools need to advance the digital reform on talent training models; teachers need to keep up with the latest educational theories to shift their roles; and students need to remain critical and independent thinkers in the age of educational digitalization 2.0.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {733–738},
numpages = {6},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@inproceedings{10.1145/3641555.3704749,
author = {Hare, Brian K. and Gladbach, Joan and Shah, S. Jawad and Xu, Dianxiang},
title = {Building AI-Powered Responsible Workforce by Integrating Large Language Models into Computer Science Curriculum},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704749},
doi = {10.1145/3641555.3704749},
abstract = {Software development is undergoing a revolutionary transformation, fueled by remarkable advancements in Large Language Models (LLMs). This wave of innovation is reshaping the entire landscape and holds the promise of streamlining the development process, leading to increased productivity and efficiency. By providing text prompts, developers can now receive entirely generated code outputs, representing a fundamental shift in how software is built. This paradigm change can accelerate development cycles and unlock new levels of creativity and ingenuity, resulting in the realization of novel applications and business outcomes. However, this paradigm shift also brings new challenges and necessitates acquiring additional skills for software developers to fully harness the capabilities of LLM-powered tools. These skills include prompt engineering for software development, structural complexity management, debugging of AI errors, and compliance with ethical guidelines and principles.The special session will introduce our NSF-sponsored 3-year project, which aims to integrate LLMs into the standard CS curriculum. To the best of our knowledge, this project is among the first department-level initiatives to renovate CS curriculum, rather than individual courses, with the new developments of LLMs. Our project focuses on (a) enhancing students' problem-solving and programming skills by leveraging LLMs as a learning tool in core programming courses, (b) improving students' software development skills by integrating LLM-powered tools into the software engineering course sequence, and (c) educating students on ethical and responsible AI practices. The special session will discuss the objectives and methods of our project, as well as the current results and lessons learned.This NSF-supported project aims to integrate LLMs into the standard CS curriculum. The revolutionized computer science education will cultivate a new generation of AI-powered responsible developers. The objectives are to enhance student programming, software development, and problem-solving skills; educate students on ethical and responsible AI practices; and develop faculty development materials and workshops. Our presentation will discuss the objectives and methods of our project, currently in year 1 of a 3-year timeline.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1709–1710},
numpages = {2},
keywords = {AI, curriculum development, large language models, undergraduate education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3696410.3714800,
author = {Sun, Zhongxiang and Si, Zihua and Zang, Xiaoxue and Zheng, Kai and Song, Yang and Zhang, Xiao and Xu, Jun},
title = {LargePiG for Hallucination-Free Query Generation: Your Large Language Model is Secretly a Pointer Generator},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714800},
doi = {10.1145/3696410.3714800},
abstract = {Recent research on query generation has focused on using Large Language Models (LLMs), which, despite achieving state-of-the-art performance, also introduce hallucination issues in generated queries. In this work, we categorize these issues into relevance hallucination and factuality hallucination, proposing a new typology for hallucinations arising from LLM-based query generation. We present an effective approach to decouple content from form in LLM-generated queries, preserving the factual knowledge extracted and integrated from inputs while leveraging the LLM's linguistic capabilities to construct syntactic structures, including function words. Specifically, we introduce a model-agnostic and training-free method that transforms the Large Language Model into a Pointer-Generator (LargePiG), where the pointer attention distribution utilizes the LLM's inherent attention weights, and the copy probability is derived from the difference between the vocabulary distribution in the model's high layers and the last layer. To validate the effectiveness of LargePiG, we constructed two datasets for assessing hallucination issues in query generation, covering both document and video scenarios. Empirical studies on various LLMs demonstrated LargePiG's superiority across both datasets. Additional experiments further verified that LargePiG reduces hallucination in large vision-language models and enhances the accuracy of document-based question-answering and factuality evaluation tasks. The source code and dataset are available at https://github.com/Jeryi-Sun/LargePiG.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4766–4779},
numpages = {14},
keywords = {hallucination, pointer generator, query generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@proceedings{10.1145/3717383,
title = {ISEC '25: Proceedings of the 18th Innovations in Software Engineering Conference},
year = {2025},
isbn = {9798400714245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3639477,
title = {ICSE-SEIP '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@article{10.1145/3701622,
author = {Green, Karen},
title = {In an Interdisciplinary World, Computer Science Education Must Adapt},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {2153-2184},
url = {https://doi.org/10.1145/3701622},
doi = {10.1145/3701622},
journal = {ACM Inroads},
month = nov,
pages = {67–73},
numpages = {7}
}

@inproceedings{10.1145/3663548.3688515,
author = {Knapp, Vaclav and Bohacek, Matyas},
title = {Pose-aware Large Language Model Interface for Providing Feedback to Sign Language Learners},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3688515},
doi = {10.1145/3663548.3688515},
abstract = {Sign language learners often find it challenging to self-identify and correct mistakes, and so many turn to automated methods that provide sign language feedback. However, they find that existing methods either require specialized equipment or lack robustness. They, therefore, have to seek human tutors or give up on the inquiry altogether. To overcome the barriers in accessibility and robustness, we build a large language model (LLM)-based tool for that provide feedback to sign language learners. The tool can analyze videos from diverse camera and background settings without specialized equipment thanks to a sign language segmentation and keyframe identification model. Using a pose-aware LLM, the tool can then produce feedback in written language. We present our tool as a demo web application, opening its implementation into specialized learning applications.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {121},
numpages = {5},
keywords = {Large Language Models, Learning Tool, Sign Language},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@article{10.1145/3673428,
author = {Shein, Esther},
title = {The Impact of AI on Computer Science Education},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {9},
issn = {0001-0782},
url = {https://doi.org/10.1145/3673428},
doi = {10.1145/3673428},
abstract = {Understanding why “working hard and struggling is … an important way of learning.”},
journal = {Commun. ACM},
month = aug,
pages = {13–15},
numpages = {3}
}

@article{10.1145/3712003,
author = {He, Junda and Treude, Christoph and Lo, David},
title = {LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision, and the Road Ahead},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712003},
doi = {10.1145/3712003},
abstract = {Integrating Large Language Models (LLMs) into autonomous agents marks a significant shift in the research landscape by offering cognitive abilities that are competitive with human planning and reasoning. This article explores the transformative potential of integrating Large Language Models into Multi-Agent (LMA) systems for addressing complex challenges in software engineering (SE). By leveraging the collaborative and specialized abilities of multiple agents, LMA systems enable autonomous problem-solving, improve robustness, and provide scalable solutions for managing the complexity of real-world software projects. In this article, we conduct a systematic review of recent primary studies to map the current landscape of LMA applications across various stages of the software development lifecycle (SDLC). To illustrate current capabilities and limitations, we perform two case studies to demonstrate the effectiveness of state-of-the-art LMA frameworks. Additionally, we identify critical research gaps and propose a comprehensive research agenda focused on enhancing individual agent capabilities and optimizing agent synergy. Our work outlines a forward-looking vision for developing fully autonomous, scalable, and trustworthy LMA systems, laying the foundation for the evolution of Software Engineering 2.0.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {124},
numpages = {30},
keywords = {Large Language Models, Autonomous Agents, Multi-Agent Systems, Software Engineering}
}

@inproceedings{10.1145/3649409.3691074,
author = {Zarb, Mark and Brown, John N.A. and Goodfellow, Martin and Liaskos, Konstantinos and Young, Tiffany},
title = {Ethical Implications of Gen-AI and LLMs in Computing Education},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691074},
doi = {10.1145/3649409.3691074},
abstract = {The panel convenes five educators to discuss the ethical implications of utilising Generative AI (Gen-AI) and Large Language Models (LLMs) in computing education. Their expertise spans various domains, including organising national workshops on the implications of generative AI tools, conducting surveys on their use within curricula, implementing institutional policies related to technology use, and engaging with students directly in the classroom. They reflect on the evolution of Gen-AI and LLMs from challenging-to-use technologies to indispensable tools for users of all levels. Furthermore, they examine the ethical dilemmas arising from the widespread adoption of these technologies in educational contexts, particularly regarding issues of originality, integrity, and responsible use. In addition, they explore practical strategies for integrating ethics education into computing curriculum design and classroom practices. This includes discussions on the role of educators in guiding students towards ethical technology usage, addressing uncertainties surrounding Gen-AI tools, and fostering a culture of responsible innovation within educational institutions. Through their collective insights and experiences, the panel aims to provide recommendations for navigating the ethical complexities inherent in the integration of Gen-AI technologies into computing education curricula.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {293–294},
numpages = {2},
keywords = {ChatGPT, curriculum design, ethics, generative AI, large language models, responsibility},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@article{10.1145/3702231,
author = {ter Beek, Maurice and Broy, Manfred and Dongol, Brijesh},
title = {The Role of Formal Methods in Computer Science Education},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {2153-2184},
url = {https://doi.org/10.1145/3702231},
doi = {10.1145/3702231},
journal = {ACM Inroads},
month = nov,
pages = {58–66},
numpages = {9}
}

@inproceedings{10.1145/3664647.3681407,
author = {Zhao, Jianing and Wang, Jingjing and Jin, Yujie and Luo, Jiamin and Zhou, Guodong},
title = {Hawkeye: Discovering and Grounding Implicit Anomalous Sentiment in Recon-videos via Scene-enhanced Video Large Language Model},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681407},
doi = {10.1145/3664647.3681407},
abstract = {In real-world recon-videos such as surveillance and drone reconnaissance videos, commonly used explicit language, acoustic and facial expressions information is often missing. However, these videos are always rich in anomalous sentiments (e.g., criminal tendencies), which urgently requires the implicit scene information (e.g., actions and object relations) to fast and precisely identify these anomalous sentiments. Motivated by this, this paper proposes a new chat-paradigm Implicit anomalous sentiment Discovering and grounding (IasDig) task, aiming to interactively, fast discovering and grounding anomalous sentiments in recon-videos via leveraging the implicit scene information (i.e., actions and object relations). Furthermore, this paper believes that this IasDig task faces two key challenges, i.e., scene modeling and scene balancing. To this end, this paper proposes a new Scene-enhanced Video Large Language Model named Hawkeye, i.e., acting like a raptor (e.g., a Hawk) to discover and locate prey, for the IasDig task. Specifically, this approach designs a graph-structured scene modeling module and a balanced heterogeneous MoE module to address the above two challenges, respectively. Extensive experimental results on our constructed scene-sparsity and scene-density IasDig datasets demonstrate the great advantage of Hawkeye to IasDig over the advanced Video-LLM baselines, especially on the metric of false negative rates. This justifies the importance of the scene information for identifying implicit anomalous sentiments and the impressive practicality of Hawkeye for real-world applications.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {592–601},
numpages = {10},
keywords = {anomalous information, implicit sentiment, recon videos, scene-enhanced llm},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3638530.3664179,
author = {Pluhacek, Michal and Kovac, Jozef and Janku, Peter and Kadavy, Tomas and Senkerik, Roman and Viktorin, Adam},
title = {A Critical Examination of Large Language Model Capabilities in Iteratively Refining Differential Evolution Algorithm},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3664179},
doi = {10.1145/3638530.3664179},
abstract = {In this study, we investigate the applicability, challenges, and effectiveness of the advanced large language model GPT 4 Turbo in enhancing the selected metaheuristic algorithm, which is Differential Evolution. Our research primarily examines whether iterative, repetitive prompting could lead to progressive improvements in algorithm performance. We also explore the potential of developing enhanced algorithms through this process that markedly surpass the established baseline in terms of performance. In addition, the impact of the model's temperature parameter on these improvements is evaluated. As part of our diverse testing approach, we conduct an experiment where the best-performing algorithm from the initial phase is used as a new baseline. This step is to determine if further refinement via GPT 4 Turbo can achieve even better algorithmic efficiency. Finally, we have performed the benchmarking comparison of selected enhanced variants against the top three algorithms from the CEC 2022 competition.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1855–1862},
numpages = {8},
keywords = {evolutionary computation, large language models, metaheuristic optimization, automatic algorithm design, GPT},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@proceedings{10.1145/3639475,
title = {ICSE-SEIS'24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Society},
year = {2024},
isbn = {9798400704994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3723010.3723025,
author = {Ishmael, Ontiretse and Kiely, Etain and Healy, John},
title = {Soft Skills as Predictors of Success in Software Engineering Through Analysis of Confidence, Adaptability and Time Management},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723025},
doi = {10.1145/3723010.3723025},
abstract = {While successful software engineering students must demonstrate robust technical skills, the ability to acquire and master soft skills is just as crucial to their long-term professional success. These abilities are essential as they compliment technical expertise. Currently, research on soft skills primarily focuses on areas such as communication, teamwork and leadership. However, there is limited research exploring how confidence, adaptability and time management correlate with academic performance and contribute to building better prepared students for the job market. Time management, adaptation and building confidence are crucial non-technical abilities that allow software engineering students to succeed in a holistic way in academia and in their careers. In addition, the belief of a student in their own abilities to accomplish tasks and understand the concepts or modules learning outcomes presented to them forms the foundation of their growth. This study investigated whether soft skills such as confidence, adaptation and time management can be a predictor of success for software engineering students. The analysis of student self-reported data identified four principal clusters: high achievers (46.4%), mid-high performers (33.3%), mid-performers (13%) and developing performers (7.2%). Performance indicators suggest high reliability in grade prediction with an R2 value of 0.837 indicating that approximately 83.7% of the variance in student grades can be explained by the model results. Furthermore, an RMSE of 3.63 indicates that predictions deviate by less than 4 points on a 100 point scale. A standard deviation of RMSE (0.98) suggests consistent prediction accuracy across different student data. This study shows that software engineering curricula should also focus on equipping students with not only cutting edge technological tools and technical skills but also the most effective approaches to education by incorporating these soft skills.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {200–209},
numpages = {10},
keywords = {soft skills, confidence, students, adaptability, time management},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3501709.3544280,
author = {MacNeil, Stephen and Tran, Andrew and Mogil, Dan and Bernstein, Seth and Ross, Erin and Huang, Ziheng},
title = {Generating Diverse Code Explanations using the GPT-3 Large Language Model},
year = {2022},
isbn = {9781450391955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501709.3544280},
doi = {10.1145/3501709.3544280},
abstract = {Good explanations are essential to efficiently learning introductory programming concepts [10]. To provide high-quality explanations at scale, numerous systems automate the process by tracing the execution of code [8, 12], defining terms [9], giving hints [16], and providing error-specific feedback [10, 16]. However, these approaches often require manual effort to configure and only explain a single aspect of a given code segment. Large language models (LLMs) are also changing how students interact with code [7]. For example, Github's Copilot can generate code for programmers [4], leading researchers to raise concerns about cheating [7]. Instead, our work focuses on LLMs' potential to support learning by explaining numerous aspects of a given code snippet. This poster features a systematic analysis of the diverse natural language explanations that GPT-3 can generate automatically for a given code snippet. We present a subset of three use cases from our evolving design space of AI Explanations of Code.},
booktitle = {Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 2},
pages = {37–39},
numpages = {3},
keywords = {code explanations, computer science education, large language models, natural language processing},
location = {Lugano and Virtual Event, Switzerland},
series = {ICER '22}
}

@inproceedings{10.1145/3641554.3701961,
author = {Brown, Cameron and Cruz Castro, Laura},
title = {Coordinate: A Virtual Classroom Management Tool For Large Computer Science Courses Using Discord},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701961},
doi = {10.1145/3641554.3701961},
abstract = {Effective classroom management is becoming increasingly challenging with the growing size of core computer science classrooms. However, classroom management remains a critical component of instruction in higher education. Successful classroom management ensures a structured, respectful environment that maximizes student engagement and learning outcomes. To address this, we present Coordinate, a novel educational tool based on Discord, a widely used free voice, video, and text chat application. Coordinate leverages Discord's interface, extensibility, and familiarity with young people. With the innovative blending between communication and logistics, this tool addresses the need to reduce instructors' time on classroom management tasks. Coordinate automatically manages several integral classroom offerings, including office hour queues, student assignment extension requests, teaching team performance, student feedback, and Q&amp;As. Alongside these features, we present details about the tool architecture, implementation, and deployment. Our tool has been deployed throughout a growing number of classes at a large state university to thousands of students. We present the perception of four distinct computer science instructors and their students. Overall, students are satisfied with the tool and find it valuable and easy to use. At the same time, instructors believe it can be a critical component of their classrooms, significantly reducing their time spent on class management and allowing them to focus on other necessary tasks. We also discuss the challenges and opportunities of using the Discord platform in an educational context. Our findings suggest that Coordinate can be a valuable tool for classroom management in higher education.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {165–171},
numpages = {7},
keywords = {classroom management, discord, higher education, software tools},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@proceedings{10.1145/3649217,
title = {ITiCSE 2024: Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 29th annual conference on Innovation and Technology in Computer Science Education (ITiCSE 2024), hosted by Universit\`{a} degli Studi di Milano in Milan, Italy.ITiCSE 2024 will take place from Friday July 5 to Wednesday July 10. The conference program includes a keynote address, paper sessions, a panel, tips, techniques &amp; courseware demonstrations, posters, a doctoral consortium, and working group presentations. Working groups meet July 5-7 and will submit draft reports before the conference begins on July 8.The submissions to ITiCSE 2024 were reviewed by 446 researchers and practitioners from computing education and related fields, including 44 program committee members and 402 reviewers. Thanks to their outstanding effort and commitment, every submission received a metareview and most received at least three reviews, providing authors of all submissions with constructive feedback. Although no review process is flawless, we are confident that this effort led to a vibrant conference program, capturing multiple voices and perspectives in the field.},
location = {Milan, Italy}
}

@inproceedings{10.1145/3636555.3636883,
author = {Xu, Austin and Monroe, Will and Bicknell, Klinton},
title = {Large language model augmented exercise retrieval for personalized language learning},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636883},
doi = {10.1145/3636555.3636883},
abstract = {We study the problem of zero-shot exercise retrieval in the context of online language learning, to give learners the ability to explicitly request personalized exercises via natural language. Using real-world data collected from language learners, we observe that vector similarity approaches poorly capture the relationship between exercise content and the language that learners use to express what they want to learn. This semantic gap between queries and content dramatically reduces the effectiveness of general-purpose retrieval models pretrained on large scale information retrieval datasets like MS MARCO&nbsp;[2]. We leverage the generative capabilities of large language models to bridge the gap by synthesizing hypothetical exercises based on the learner’s input, which are then used to search for relevant exercises. Our approach, which we call mHyER, overcomes three challenges: (1) lack of relevance labels for training, (2) unrestricted learner input content, and (3) low semantic similarity between input and retrieval candidates. mHyER outperforms several strong baselines on two novel benchmarks created from crowdsourced data and publicly available data.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {284–294},
numpages = {11},
keywords = {large language models, online language learning, personalization, zero-shot exercise retrieval},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3626253.3635542,
author = {Smith, David H. and Zilles, Craig},
title = {Evaluating Large Language Model Code Generation as an Autograding Mechanism for "Explain in Plain English" Questions},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635542},
doi = {10.1145/3626253.3635542},
abstract = {The ability of students to ''Explain in Plain English'' (EiPE) the purpose of code is a critical skill for students in introductory programming courses to develop. EiPE questions serve as both a mechanism for students to develop and demonstrate code comprehension skills. However, evaluating this skill has been challenging as manual grading is time consuming and not easily automated. The process of constructing a prompt for the purposes of code generation for a Large Language Model, such OpenAI's GPT-4, bears a striking resemblance to constructing EiPE responses. In this paper, we explore the potential of using test cases run on code generated by GPT-4 from students' EiPE responses as a grading mechanism for EiPE questions. We applied this proposed grading method to a corpus of EiPE responses collected from past exams, then measured agreement between the results of this grading method and human graders. Overall, we find moderate agreement between the human raters and the results of the unit tests run on the generated code. This appears to be attributable to GPT-4's code generation being more lenient than human graders on low-level descriptions of code.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1824–1825},
numpages = {2},
keywords = {autograding, eipe, gpt-4, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@proceedings{10.1145/3649405,
title = {ITiCSE 2024: Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 29th annual conference on Innovation and Technology in Computer Science Education (ITiCSE 2024), hosted by Universita degli Studi di Milano in Milan, Italy.ITiCSE 2024 will take place from Friday July 5 to Wednesday July 10. The conference program includes a keynote address, paper sessions, a panel, tips, techniques &amp; courseware demonstrations, posters, a doctoral consortium, and working group presentations. Working groups meet July 5-7 and will submit draft reports before the conference begins on July 8.The submissions to ITiCSE 2024 were reviewed by 446 researchers and practitioners from computing education and related fields, including 44 program committee members and 402 reviewers. Thanks to their outstanding effort and commitment, every submission received a metareview and most received at least three reviews, providing authors of all submissions with constructive feedback. Although no review process is flawless, we are confident that this effort led to a vibrant conference program, capturing multiple voices and perspectives in the field.},
location = {Milan, Italy}
}

@inproceedings{10.1145/3626252.3630753,
author = {Liut, Michael and Ly, Anna and Xu, Jessica Jia-Ni and Banson, Justice and Vrbik, Paul and Hardin, Caroline D.},
title = {"I Didn't Know": Examining Student Understanding of Academic Dishonesty in Computer Science},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630753},
doi = {10.1145/3626252.3630753},
abstract = {In contrast with studies that have identified why students commit academic offences, many educators are familiar with the excuse that an accused student did not know the behavior counted as dishonest. Given the variations in policy and the ways collaboration and code sharing occur in professional and hobbyist spaces, this might be plausible. Mismatches between students' conceptions of academic honesty and course policy can have major consequences, from being kicked out of programs to being too nervous to study with peers. In this work, we investigate what students understand about academic integrity in computer science courses and if there are differences based on university, country, demographic, or online versus in-person courses. We present a study that surveys undergraduate computer science students (N = 1,011) at three universities (Australia, Canada, and the United States of America). The results show that all three institutions take academic integrity seriously, and their students are aware of its importance, but confusion on what is covered under the policies is common. Interestingly, the results also show that course instructors play a huge role as to what students perceive to be a violation of the academic integrity policy at their institution. By understanding student's perspectives on academic integrity, educators can better develop policies and practices that reduce inadvertent and mistaken violations of academic integrity policies.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {757–763},
numpages = {7},
keywords = {academic dishonesty, academic integrity, assessment, cheating, computer science students, computing students, education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3701041,
author = {Yuan, Aijia and Garcia Colato, Edlin and Pescosolido, Bernice and Song, Hyunju and Samtani, Sagar},
title = {Improving Workplace Well-being in Modern Organizations: A Review of Large Language Model-based Mental Health Chatbots},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3701041},
doi = {10.1145/3701041},
abstract = {The global rise in mental disorders, particularly in workplaces, necessitated innovative and scalable solutions for delivering therapy. Large Language Model (LLM)-based mental health chatbots have rapidly emerged as a promising tool for overcoming the time, cost, and accessibility constraints often associated with traditional mental health therapy. However, LLM-based mental health chatbots are in their nascency, with significant opportunities to enhance their capabilities to operate within organizational contexts. To this end, this research seeks to examine the role and development of LLMs in mental health chatbots over the past half-decade. Through our review, we identified over 50 mental health-related chatbots, including 22 LLM-based models targeting general mental health, depression, anxiety, stress, and suicide ideation. These chatbots are primarily used for emotional support and guidance but often lack capabilities specifically designed for workplace mental health, where such issues are increasingly prevalent. The review covers their development, applications, evaluation, ethical concerns, integration with traditional services, LLM-as-a-Service, and various other business implications in organizational settings. We provide a research illustration of how LLM-based approaches could overcome the identified limitations and also offer a system that could help facilitate systematic evaluation of LLM-based mental health chatbots. We offer suggestions for future research tailored to workplace mental health needs.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {3},
numpages = {26},
keywords = {Large language models, chatbots, conversational agents, mental health, workplace, well-being}
}

@inproceedings{10.1145/3702138.3702140,
author = {DiMario, Carmen L. and Bacha, Rio C. and Butka, Brian K.},
title = {Combatting Senior Scams Using a Large Language Model-Created Rubric: This paper explains a novel approach to reinforcement learning designed for the detection and prevention of scams aimed at senior citizens},
year = {2025},
isbn = {9798400717543},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702138.3702140},
doi = {10.1145/3702138.3702140},
abstract = {This paper addresses the critical issue of internet scams targeting seniors by developing a robust, Machine Learning (ML) based solution employing a Large Language Model (LLM), specifically ChatGPT, to enhance scam detection and prevention. Elderly internet users are particularly vulnerable to digital fraud due to a lack of familiarity with technological safeguards and a tendency not to report incidents. Traditional security measures often fail to accommodate the unique challenges faced by this demographic, prompting our focus on a specialized, user-friendly solution. We propose an innovative approach using ChatGPT 3.5 to analyze and score emails based on their likelihood of being scams, thus providing seniors with a tool that requires minimal interaction while offering maximum protection. This system uses a custom rubric developed through ML techniques to evaluate potential threats effectively. By integrating word embeddings and a diverse training dataset, the model adapts to the nuanced and evolving nature of scam tactics. The methodology utilized in this paper ensures that the ML model not only identifies common scam indicators but also provides actionable feedback to users, making it a practical tool for real-world applications. Preliminary results demonstrate the system's efficacy in recognizing scam emails, thereby significantly reducing the risk of financial loss among seniors and enhancing their confidence in digital communication. This paper outlines the design, implementation, and testing phases of the project, highlighting the potential of LLMs in cybersecurity, specifically in protecting a vulnerable population.},
booktitle = {Proceeding of the 2024 5th Asia Service Sciences and Software Engineering Conference},
pages = {130–136},
numpages = {7},
keywords = {Cyber security, artificial intelligence, email, machine learning, scam},
location = {
},
series = {ASSE '24}
}

@article{10.1145/3735645,
author = {Zhou, Yinghai and Wang, Ziyu and Jiang, Yunxin and Ma, Bingqi and Wang, Rui and Liu, Yuan and Zhao, Yue and Tian, Zhihong},
title = {AEKG4APT: An AI-Enhanced Knowledge Graph for Advanced Persistent Threats with Large Language Model Analysis},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3735645},
doi = {10.1145/3735645},
abstract = {This paper introduces AEKG4APT, an APT Knowledge Graph (KG) enhanced by Large Language Models (LLMs), as a way to deal with the cybersecurity problems caused by Advanced Persistent Threats (APTs). The core of AEKG4APT lies in the combined application of LLMs, Cyber Threat Intelligence (CTI), and KG. The first part of the paper goes into great detail about how the AEKG4APT was constructed, including its ontology schema, data sources, and dataset features. There are also statistics on the AEKG4APT’s nodes, relationships, and key attributes. Secondly, it was shown how to utilize LLMs and public sandboxes for the collection and analysis of CTI Additionally, tests that compare traditional deep learning models to LLM methods show that LLM is both more efficient and more accurate at extracting information. Subsequently, the Decision Making Trial and Evaluation Laboratory - Interpretive Structural Modeling (DEMATEL-ISM) analytical method was introduced to identify and analyse the factors and their interrelationships within the AEKG4APT data, thereby revealing the key dependencies and influence paths within the data structure. Experiments were designed to demonstrate its applications in modeling, computing, and obtaining interpretable computational results on AEKG4APT. In addition, this paper also explores the dynamic expansion capabilities of AEKG4APT, including data expansion, schema expansion, and permanent maintenance strategies, to address the evolving APT threats. Finally, this paper summarizes the competitiveness and application value of AEKG4APT by comparing it with other CTI KGs and platforms in academia and industry, demonstrating its extensive application potential in the field of cybersecurity.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
keywords = {Advanced Persistent Threat, Large Language Models, Knowledge Graph, Cyber Threat Intelligence, Sandboxes, DEMATEL-ISM}
}

@inproceedings{10.1145/3639474.3640076,
author = {Xue, Yuankai and Chen, Hanlin and Bai, Gina R. and Tairas, Robert and Huang, Yu},
title = {Does ChatGPT Help With Introductory Programming?An Experiment of Students Using ChatGPT in CS1},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640076},
doi = {10.1145/3639474.3640076},
abstract = {Generative AI, notably ChatGPT, has garnered attention in computer science education. This paper presents a controlled experiment that explores ChatGPT's role in CS1 in a classroom setting. Specifically, we aim to investigate the impact of ChatGPT on student learning outcomes and their behaviors when working on programming assignments. Participants were tasked with creating a UML diagram and subsequently implementing its design through programming, followed by a closed-book post-evaluation and a post-survey. All the participants were required to screen-record the whole process. In total, 56 participants were recruited, with 48 successful screen recordings. Participants in the Experimental Group can access ChatGPT 3.5 and other online resources, such as Google and Stack Overflow when creating the UML diagram and programming; however, participants in the Control Group can access all online resources except for ChatGPT (i.e., the only design variable is the access to ChatGPT). Finally, we measured and analyzed participants' learning outcomes through their UML diagram, programming, and post-evaluation scores. We also analyzed the time participants took to complete the tasks and their interactions with ChatGPT and other resources from the screen recordings. After finishing the tasks, student participants also provided their perceptions of using ChatGPT in CS1 through a post-survey.With rigorous quantitative and qualitative analysis, we found that (1) using ChatGPT does not present a significant impact on students' learning performance in the CS1 assignment-style tasks; (2) once using ChatGPT, students' tendency to explore other traditional educational resources is largely reduced (though available) and they tend to rely solely on ChatGPT, and this reliance on ChatGPT did not guarantee enhanced learning performance; (3) the majority of students hold neutral views on ChatGPT's role in CS1 programming but most of them raised concerns about its potential ethical issues and inconsistent performance across different tasks. We hope this study can help educators and students better understand the impact of ChatGPT in CS1 and inspire future work to provide proper guidelines for using ChatGPT in introductory programming classes.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {331–341},
numpages = {11},
keywords = {CS education, CS1, generative AI, ChatGPT, OOP},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3661167.3661273,
author = {Mezzaro, Simone and Gambi, Alessio and Fraser, Gordon},
title = {An Empirical Study on How Large Language Models Impact Software Testing Learning},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661273},
doi = {10.1145/3661167.3661273},
abstract = {Software testing is a challenging topic in software engineering education and requires creative approaches to engage learners. For example, the Code Defenders game has students compete over a Java class under test by writing effective tests and mutants. While such gamified approaches deal with problems of motivation and engagement, students may nevertheless require help to put testing concepts into practice. The recent widespread diffusion of Generative AI and Large Language Models raises the question of whether and how these disruptive technologies could address this problem, for example, by providing explanations of unclear topics and guidance for writing tests. However, such technologies might also be misused or produce inaccurate answers, which would negatively impact learning. To shed more light on this situation, we conducted the first empirical study investigating how students learn and practice new software testing concepts in the context of the Code Defenders testing game, supported by a smart assistant based on a widely known, commercial Large Language Model. Our study shows that students had unrealistic expectations about the smart assistant, “blindly” trusting any output it generated, and often trying to use it to obtain solutions for testing exercises directly. Consequently, students who resorted to the smart assistant more often were less effective and efficient than those who did not. For instance, they wrote 8.6% fewer tests, and their tests were not useful in 78.0% of the cases. We conclude that giving unrestricted and unguided access to Large Language Models might generally impair learning. Thus, we believe our study helps to raise awareness about the implications of using Generative AI and Large Language Models in Computer Science Education and provides guidance towards developing better and smarter learning tools.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {555–564},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, Generative AI, Smart Learning Assistant},
location = {Salerno, Italy},
series = {EASE '24}
}

@article{10.5555/3715622.3715634,
author = {Attarwala, Abbas and Raigoza, Pablo},
title = {Assessing Student Perceptions of Co-Teaching in a 3rd-Year Computer Science Course},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {2},
issn = {1937-4771},
abstract = {In this research, the effects of various teaching methodologies such as solo teaching, parallel coordinated teaching (PCT), and sequential teaching (SEQT) on student perceptions in a third-year programming language course at Boston University (BU) are studied. PCT and SEQT, as variants of co-teaching, contrast with the independent approach of solo teaching. This research uses student evaluation data to analyze eight distinct evaluative questions, including areas such as fairness in grading, stimulation of student's interest in the course material, and overall instructor ratings. These eight questions are analyzed using student course evaluations across the three aforementioned teaching methodologies to determine if there are statistically significant differences in perceptions. The results show that consistent instructor presence throughout the semester, as seen in solo teaching and PCT scenarios, significantly enhances student perceptions of fairness and overall satisfaction. In contrast, SEQT, which involves instructor changes in the middle of the semester, is associated with less favorable student evaluations. The study highlights the importance of instructor consistency and the potential disruptions caused by changing instructors mid-course.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {83–94},
numpages = {12}
}

@inproceedings{10.1145/3641555.3704765,
author = {Liu, Rongxin and Malan, David J. and Zhukovets, Yuliia and Lloyd, Doug},
title = {Teaching with AI (GPT)},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704765},
doi = {10.1145/3641555.3704765},
abstract = {Teaching computer science at scale can be challenging. From our experience in CS50, Harvard University's introductory course, we've seen firsthand the impactful role that generative artificial intelligence can play in education. Recognizing its potential and stakes, we integrated OpenAI's GPT into our own teaching methodology. The goal was to emulate a 1:1 teacher-to-student ratio, incorporating "pedagogical guardrails" to maintain instructional integrity. The result was a personalized, AI-powered bot in the form of a friendly rubber duck aimed at delivering instructional responses and troubleshooting without giving outright solutions. In this tutorial, we share our journey and offer insights into responsibly harnessing AI in educational settings. Participants will gain hands-on experience working with GPT through OpenAI's latest APIs, understanding and crafting prompts, answering questions using embedding-based search, and finally, collaboratively building their own AI chatbot. Ultimately, we'll not only share lessons learned from our own approach but also equip educators hands-on with the knowledge and tools with which they, too, can implement these technologies in their unique teaching environments.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1773},
numpages = {1},
keywords = {AI, AI ethics, ChatGPT, GPT, generative AI, programming, prompt, prompt engineering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3696117.3696126,
author = {Pezz\`{e}, Mauro and Ciniselli, Matteo and Di Grazia, Luca and Puccinelli, Niccol\`{o} and Qiu, Ketai},
title = {The Trailer of the ACM 2030 Roadmap for Software Engineering},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/3696117.3696126},
doi = {10.1145/3696117.3696126},
abstract = {The landscape of software engineering has dramatically changed. The recent advances in AI, the new opportunities of quantum computing, and the new challenges of sustainability and cyber security upset the software engineering research prospective. The 2030 SE-Roadmap special issue of ACM TOSEM Transactions on Software Engineering and Methodology gives a 360° view of the research challenges of the 30ties with a thorough editorial, four roadmap papers from the ACM TOSEM editorial board, and over 30 peer-reviewed papers from the research community.This paper previews the main content of the 2030 roadmap special issue with a report from the 2030 Software Engineering Roadmap workshop, co-located with ACM SIGSOFT FSE Foundations of Software engineering on July 15th and 16th, 2024 in Porto de Galinhas, Brazil, that spotlighted the software engineering research horizon to feed ideas into the ACM TOSEM special issue. The paper discusses the new challenges to software engineering that emerged in the SE2030 workshop: AI for software engineering, software engineering by and for humans, sustainable software engineering, automatic programming, cyber security, validation and verification, and quantum software engineering.},
journal = {SIGSOFT Softw. Eng. Notes},
month = oct,
pages = {31–40},
numpages = {10}
}

@article{10.1145/3644816,
author = {Hamilton, Margaret and Hol, Ana and Richardson, Joan and McGovern, James},
title = {Computer Science Undergraduate Programs in Australia},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {2153-2184},
url = {https://doi.org/10.1145/3644816},
doi = {10.1145/3644816},
journal = {ACM Inroads},
month = feb,
pages = {18–26},
numpages = {9}
}

@inproceedings{10.1145/3649405.3659537,
author = {Aly, Sherif G. and Becker, Brett A. and Kumar, Amruth N. and Raj, Rajendra K.},
title = {Computer Science Curricula 2023 (CS2023): Rising to the Challenges of Change in AI, Security, and Society},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659537},
doi = {10.1145/3649405.3659537},
abstract = {Model curricula for baccalaureate computer science (CS) have been published regularly from 1968 through 2013. In early 2021, the ACM, IEEE-Computer Society, and the Association for the Advancement of Artificial Intelligence (AAAI) constituted a task force to revise these curricula, which have now been released as Computer Science 2023 Curricula (CS2023). The CS2023 curricular guidelines inform educators and administrators on the what, why, and how to cover undergraduate CS over the next decade. Like past guidelines, CS2023 provides curricular content - a knowledge model largely backward compatible with CS2013, supplemented by a competency framework influenced by Computing Curricula 2020 (CC2020) - and complementary curricular practices, which include articles by international experts on program design and delivery. Ongoing drafts of CS2023 were disseminated via the CS2023 website, along with regular publications or presentations at various computing education venues.This panel focuses on three among the 17 CS2023 knowledge areas: Society, Ethics, and the Profession (SEP), Artificial Intelligence (AI), and Security (SEC). While the other 14 knowledge areas remain important in CS education, these three have been in the news due to inadequacies in current CS education. The panelists, who served on the CS2023 steering committee, will discuss how CS2023 addresses these challenges. Attendees will appreciate the approach taken by CS2023 toward these three hot-button items of CS education, especially constraints on curriculum design, and how CS2023 may be used to educate the next generation of CS graduates to rise to these three challenges.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {852–853},
numpages = {2},
keywords = {artificial intelligence education, computer science curricular guidelines, professional ethics education, security education, societal considerations},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3613944.3613946,
author = {Qureshi, Basit},
title = {ChatGPT in Computer Science Curriculum Assessment: An analysis of Its Successes and Shortcomings},
year = {2023},
isbn = {9798400700415},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613944.3613946},
doi = {10.1145/3613944.3613946},
abstract = {The application of Artificial intelligence for teaching and learning in the academic sphere is a trending subject of interest in computing education. ChatGPT, as an AI-based tool, provides various advantages, such as heightened student involvement, cooperation, accessibility, and availability. This paper addresses the prospects and obstacles associated with utilizing ChatGPT as a tool for learning and assessment in undergraduate Computer Science curriculum in particular to teaching and learning fundamental programming courses. Students having completed the course work for a Data Structures and Algorithms (a sophomore-level course) participated in this study. Two groups of students were given programming challenges to solve within a short period of time. The control group (group A) had access to textbooks and notes of programming courses, however, no Internet access was provided. Group B students were given access to ChatGPT and were encouraged to use it to help solve the programming challenges. The challenge was conducted in a computer lab environment using Programming Contest Control (PC2) environment which is widely used in ACM International Collegiate Programming Contest (ICPC). Each team of students addresses the problem by writing executable code that satisfies a certain number of test cases. Student teams were scored based on their performance in terms of the number of successfully passed test cases. Results show that students using ChatGPT had an advantage in terms of earned scores, however, there were inconsistencies and inaccuracies in the submitted code consequently affecting the overall performance. After a thorough analysis, the paper’s findings indicate that incorporating AI in higher education brings about various opportunities and challenges. Nonetheless, universities can efficiently manage these apprehensions by adopting a proactive and ethical stance toward the implementation of such tools.},
booktitle = {Proceedings of the 2023 9th International Conference on E-Society, e-Learning and e-Technologies},
pages = {7–13},
numpages = {7},
keywords = {Academic assessment, ChatGPT, Data Structures and Algorithms, programming concepts},
location = {Portsmouth, United Kingdom},
series = {ICSLT '23}
}

@inproceedings{10.1145/3613905.3650868,
author = {Cai, Zhenyao and Park, Seehee and Nixon, Nia and Doroudi, Shayan},
title = {Advancing Knowledge Together: Integrating Large Language Model-based Conversational AI in Small Group Collaborative Learning},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650868},
doi = {10.1145/3613905.3650868},
abstract = {In today’s educational landscape, students learn collaboratively, where students benefit from both peer interactions and facilitator guidance. Prior research in Human-Computer Interaction (HCI) and Computer-Supported Collaborative Learning (CSCL) has explored chatbots and AI techniques to aid such collaboration. However, these methods often depend on predefined dialogues (which limits adaptability), are not based on collaborative learning theories, and do not fully recognize the learning context. In this paper, we introduce an Large Language Model (LLM)-powered conversational AI, designed to enhance small group learning through its advanced language understanding and generation capabilities. We detail the iterative design process, final design, and implementation. Our preliminary evaluation indicates that the bot performs as designed but points to considerations in the timing of interventions and bot’s role in discussions. The evaluation also reveals that learners perceive the bot’s tone and behavior as important for engagement. We discuss design implications for chatbot integration in collaborative learning and future research directions.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {37},
numpages = {9},
keywords = {AI facilitator, Collaborative Learning, Human-AI Collaboration},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3641555.3705227,
author = {Hou, Xinying and Wu, Zihan and Wang, Xu and Ericson, Barbara J.},
title = {Personalized Parsons Puzzles as Scaffolding Enhance Practice Engagement Over Just Showing LLM-Powered Solutions},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705227},
doi = {10.1145/3641555.3705227},
abstract = {As generative AI products could generate code and assist students with programming learning seamlessly, integrating AI into programming education contexts has driven much attention. However, one emerging concern is that students might get answers without learning from the LLM-generated content. In this work, we deployed the LLM-powered personalized Parsons puzzles as scaffolding to write-code practice in a Python learning classroom (PC condition) and conducted an 80-minute randomized between-subjects study. Both conditions received the same practice problems. The only difference was that when requesting help, the control condition showed students a complete solution (CC condition), simulating the most traditional LLM output. Results indicated that students who received personalized Parsons puzzles as scaffolding engaged in practicing significantly longer than those who received complete solutions when struggling.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1483–1484},
numpages = {2},
keywords = {GPT, LLM, active learning, generative AI, parsons problems},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3722227,
author = {Govers, Jarod and Pareek, Saumya and Velloso, Eduardo and Goncalves, Jorge},
title = {Feeds of Distrust: Investigating How AI-Powered News Chatbots Shape User Trust and Perceptions},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2160-6455},
url = {https://doi.org/10.1145/3722227},
doi = {10.1145/3722227},
abstract = {The start of the 2020s ushered in a new era of Artificial Intelligence through the rise of Generative AI Large Language Models (LLMs) such as Chat-GPT. These AI chatbots offer a form of interactive agency by enabling users to ask questions and query for more information. However, prior research only considers if LLMs have a political bias or agenda, and not how a biased LLM can impact a user's opinion and trust. Our study bridges this gap by investigating a scenario where users read online news articles and then engage with an interactive AI chatbot, where both the news and the AI are biased to hold a particular stance on a news topic. Interestingly, participants were far more likely to adopt the narrative of a biased chatbot over news articles with an opposing stance. Participants were also substantially more inclined to adopt the chatbot's narrative if its stance aligned with the news—all compared to a control news-article only group. Our findings suggest that the very interactive agency offered by an AI chatbot significantly enhances its perceived trust and persuasive ability compared to the ‘static’ articles from established news outlets, raising concerns about the potential for AI-driven indoctrination. We outline the reasons behind this phenomenon and conclude with the implications of biased LLMs for HCI research, as well as the risks of Generative AI undermining democratic integrity through AI-driven Information Warfare.},
note = {Just Accepted},
journal = {ACM Trans. Interact. Intell. Syst.},
month = mar,
keywords = {Generative AI, News, Bias, Indoctrination, Chatbots, Transparency, Trust, Polarisation, Large Language Models}
}

@inproceedings{10.1145/3643562.3672613,
author = {Zhang, Yang and Zong, Ruohan and Shang, Lanyu and Yue, Zhenrui and Zeng, Huimin and Liu, Yifan and Wang, Dong},
title = {Tripartite Intelligence: Synergizing Deep Neural Network, Large Language Model, and Human Intelligence for Public Health Misinformation Detection (Archival Full Paper)},
year = {2024},
isbn = {9798400705540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643562.3672613},
doi = {10.1145/3643562.3672613},
abstract = {The threat of rapidly spreading health misinformation through social media during crises like COVID-19 emphasizes the importance of addressing both clear falsehoods and complex misinformation, including conspiracy theories and subtle distortions. This paper designs a novel tripartite collective intelligence approach that integrates deep neural networks (DNNs), large language models (LLMs), and crowdsourced human intelligence (HI) to collaboratively detect complex forms of public health misinformation on social media. Our design is inspired by the collaborative strengths of DNNs, LLMs, and HI, which complement each other. We observe that DNNs efficiently handle large datasets for initial misinformation screening but struggle with complex content and rely on high-quality training data. LLMs enhance misinformation detection with improved language understanding but may sometimes provide eloquent yet factually incorrect explanations, risking misinformation mislabeling. HI provides critical thinking and ethical judgment superior to DNNs and LLMs but is slower and more costly in misinformation detection. In particular, we develop TriIntel , a tripartite collaborative intelligence framework that leverages the collective intelligence of DNNs, LLMs, and HI to tackle the public health information detection problem under a novel few-shot and uncertainty-aware maximum likelihood estimation framework. Evaluation results on a real-world public health misinformation detection application related to COVID-19 show that TriIntel outperforms representative DNNs, LLMs, and human-AI collaboration baselines in accurately detecting public health misinformation under a diverse set of evaluation scenarios.},
booktitle = {Proceedings of the ACM Collective Intelligence Conference},
pages = {63–75},
numpages = {13},
keywords = {Collective Intelligence, Human-AI Collaboration, Large Language Model, Misinformation},
location = {Boston, MA, USA},
series = {CI '24}
}

@proceedings{10.1145/3626253,
title = {SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is "Blazing New Trails in CS Education." This broad theme captures the exceptional work being performed by this community to enhance our teaching, improve our assessments, attract diverse students, and all of the other laudable projects, initiatives, and undertakings that affect positive change. The breadth of the program is substantial - there truly should be something for everyone. In fact, your biggest challenge may be deciding which session to attend in each time slot because there is so much going on! We know that many of you want to attend as many sessions as possible while you are here in Portland, but we encourage you to also find a little bit of time for yourself so that you leave Portland refreshed, renewed and encouraged, rather than exhausted or burnt out.},
location = {Portland, OR, USA}
}

@inproceedings{10.1145/3545945.3569793,
author = {Holland-Minkley, Amanda and Barnard, Jakob and Barr, Valerie and Braught, Grant and Davis, Janet and Reed, David and Schmitt, Karl and Tartaro, Andrea and Teresco, James D.},
title = {Computer Science Curriculum Guidelines: A New Liberal Arts Perspective},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569793},
doi = {10.1145/3545945.3569793},
abstract = {ACM/IEEE curriculum guidelines for computer science, such as CS2013 or the forthcoming CS2023, provide well-researched and detailed guidance about the content and skills that make up an undergraduate computer science (CS) program. Liberal arts CS programs often struggle to apply these guidelines within their institutional context and goals. Historically, this has been addressed through the development of model CS curricula tailored for the liberal arts context. We take a different position: that no single model curriculum can apply across the wide range of liberal arts institutions. Instead, we argue that liberal arts CS educators need best practices for using guidelines such as CS2023 to inform curriculum design. These practices must acknowledge the opportunities and priorities of a liberal arts philosophy as well as a program's mission and identity. This paper reviews the context and motivation behind computing in the liberal arts. We also review the history of liberal arts CS educators and ACM/IEEE curriculum guidelines. We present data and trends about liberal arts computing programs, discussing how this informs curriculum design. Finally, we propose a process that guides programs to work with curriculum guidelines through the lens of institutional and program missions and identities, goals, and situational factors.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {617–623},
numpages = {7},
keywords = {cs education, curriculum, liberal arts},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3643795.3648379,
author = {Rasnayaka, Sanka and Wang, Guanlin and Shariffdeen, Ridwan and Iyer, Ganesh Neelakanta},
title = {An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648379},
doi = {10.1145/3643795.3648379},
abstract = {Large Language Models (LLMs) represent a leap in artificial intelligence, excelling in tasks using human language(s). Although the main focus of general-purpose LLMs is not code generation, they have shown promising results in the domain. However, the usefulness of LLMs in an academic software engineering project has not been fully explored yet. In this study, we explore the usefulness of LLMs for 214 students working in teams consisting of up to six members. Notably, in the academic course through which this study is conducted, students were encouraged to integrate LLMs into their development tool-chain, in contrast to most other academic courses that explicitly prohibit the use of LLMs.In this paper, we analyze the AI-generated code, prompts used for code generation, and the human intervention levels to integrate the code into the code base. We also conduct a perception study to gain insights into the perceived usefulness, influencing factors, and future outlook of LLM from a computer science student's perspective. Our findings suggest that LLMs can play a crucial role in the early stages of software development, especially in generating foundational code structures, and helping with syntax and error debugging. These insights provide us with a framework on how to effectively utilize LLMs as a tool to enhance the productivity of software engineering students, and highlight the necessity of shifting the educational focus toward preparing students for successful human-AI collaboration.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {111–118},
numpages = {8},
keywords = {LLM for code generation, software engineering},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3657604.3664660,
author = {Nguyen, Ha and Stott, Nate and Allan, Vicki},
title = {Comparing Feedback from Large Language Models and Instructors: Teaching Computer Science at Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664660},
doi = {10.1145/3657604.3664660},
abstract = {Large language models (LLMs) can provide formative feedback in programming to help students improve the code they have written. We investigate the use of LLMs (GPT-4) to provide formative code feedback in a sophomore-level computer science (CS) course on data structures and algorithms. In three quizzes on recursion, half of the students randomly received GPT-4's feedback, while the other half received feedback from the course instructor. Students resubmitted their code based on the provided feedback. We found that students in the LLM-feedback condition scored higher in resubmissions than those receiving feedback from the instructor. Students perceived the two types of feedback as equally supportive of guiding resubmissions. We discuss the implications of using LLMs to provide formative feedback at scale in CS instruction.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {335–339},
numpages = {5},
keywords = {computer science education, feedback, large language models},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3663548.3675609,
author = {Mo, Wen and Singh, Aneesha and Holloway, Catherine},
title = {From Information Seeking to Empowerment: Using Large Language Model Chatbot in Supporting Wheelchair Life in Low Resource Settings},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3675609},
doi = {10.1145/3663548.3675609},
abstract = {To tackle the lack of wheelchair service information and training in low and middle-income countries (LMICs), we deployed Wheelpedia, a WhatsApp chatbot powered by a large language model (LLM) as a design probe for 2 months to concretely explore how it can support wheelchair users and professionals in Nigeria and Kenya. Through 18 semi-structured interviews and analysis of 471 messages, we focused on not only Wheelpedia's acceptability and usability but also how users orient themselves with the probe, integrate its information, and manage trust with it. The findings revealed participants' overwhelming enthusiasm towards the chatbot's potential in education, fostering empowerment, and reducing social stigma. We discuss challenges like users' difficulty in formulating questions, unfamiliarity with the concept of chatbots, and requests for image output. This paper contributes valuable insights into the design implications and research opportunities for deploying LLM chatbots in low-resourced settings with complex accessibility needs.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {21},
numpages = {18},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@inproceedings{10.1145/3626252.3630794,
author = {Cheng, Alan Y. and Tanimura, Ellie and Tey, Joseph and Wu, Andrew C. and Brunskill, Emma},
title = {Brief, Just-in-Time Teaching Tips to Support Computer Science Tutors},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630794},
doi = {10.1145/3626252.3630794},
abstract = {As enrollments in computing-related programs continue to rise, computer science departments are increasingly relying on teaching assistants (TAs) to provide additional educational support to students, such as one-on-one tutoring or office hours. Tutoring is more effective with highly trained tutors, but most TAs receive little to no training in pedagogical skills. How might we provide support to TAs working with students one-on-one, especially in online settings? We propose a just-in-time intervention that shows a tutor actionable teaching tips and relevant information right before they begin an online tutoring session with a student. We conducted a crossover experiment (n = 46) where participants engaged in two tutoring roleplays for an introductory computer science programming task and found that participants demonstrated effective instructional strategies for much longer periods of time after receiving the intervention. We discuss the implications of these findings for both educators looking to support tutors and researchers seeking to build technology for tutors.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {200–206},
numpages = {7},
keywords = {online tutoring teacher training, remote tutoring, ta training, tutoring},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3644477,
author = {Kumar, Amruth N. and Raj, Rajendra K.},
title = {Toward a Globalized Understanding of Computer Science Education},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {2153-2184},
url = {https://doi.org/10.1145/3644477},
doi = {10.1145/3644477},
journal = {ACM Inroads},
month = feb,
pages = {5},
numpages = {1}
}

@inproceedings{10.1145/3626252.3630755,
author = {Shah, Anshul and Yu, Jerry and Tong, Thanh and Soosai Raj, Adalbert Gerald},
title = {Working with Large Code Bases: A Cognitive Apprenticeship Approach to Teaching Software Engineering},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630755},
doi = {10.1145/3626252.3630755},
abstract = {Prior work has highlighted the gap between industry expectations for recent university graduates and the abilities those recent graduates possess. These works have even specifically recommended that students be given the opportunity to work on large, pre-existing code bases in their undergraduate career. This paper presents our experience teaching a newly-created course calledWorking with Large Code Bases. Guided by a Cognitive Apprenticeship approach to provide an authentic classroom experience that emphasizes the implicit processes and techniques involved in real-world software engineering, the course serves as a practical introduction to the skills and workflow involved in navigating and understanding a large code base. The goal of this experience report is to provide the motivation for key course design decisions, an overview of the course content, and a detailed description of key course components. We present student feedback indicating improved confidence in navigating a large code base and course outcomes related to specific tools and techniques students used in the course. Finally, we provide the full set of course materials we used and actionable recommendations for instructors to administer this course at their own institution, even with limited TA support.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1209–1215},
numpages = {7},
keywords = {cognitive apprenticeship, large code bases, program comprehension, project-based learning},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3605468.3605471,
author = {Vo, Gia Minh and Pancratz, Nils},
title = {AI Education in German K-10 Computer Science Curricula},
year = {2023},
isbn = {9798400708510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605468.3605471},
doi = {10.1145/3605468.3605471},
abstract = {The growing importance of artificial intelligence (AI) in our daily lives leads to an increasing demand for AI in learning, teaching, and education. Recent developments, such as ChatGPT, have further pushed the significance of AI, garnering media attention and prompting politicians to require stakeholders in education to place a stronger emphasis on AI education in schools. As a result, a growing number of computer science (CS) curricula are expanding to include the topic of AI. This paper aims to contribute to the understanding of AI in K-10 education in Germany by analyzing CS curricula for lower secondary school education across the 16 federal states of Germany. The results indicate that AI-related content is inconsistently addressed in the CS curricula of various federal states, with a noticeable absence of standardized AI competencies for K-10 education. In several federal states, AI-related content is only implicitly addressed from a socio-cultural perspective. To ensure up-to-date education, it is essential to include mandatory AI content in K-10 CS curricula. These contents should be considered holistically by taking into account the technological, socio-cultural, and user-oriented perspectives, in accordance with the Dagstuhl Triangle.},
booktitle = {Proceedings of the 18th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {15},
numpages = {4},
keywords = {K-10 education, artificial intelligence, computer science education, curriculum analysis},
location = {Cambridge, United Kingdom},
series = {WiPSCE '23}
}

@inproceedings{10.1145/3545945.3569792,
author = {Goetze, Trystan S.},
title = {Integrating Ethics into Computer Science Education: Multi-, Inter-, and Transdisciplinary Approaches},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569792},
doi = {10.1145/3545945.3569792},
abstract = {While calls to integrate ethics into computer science education go back decades, recent high-profile ethical failures related to computing technology by large technology companies, governments, and academic institutions have accelerated the adoption of computer ethics education at all levels of instruction. Discussions of how to integrate ethics into existing computer science programmes often focus on the structure of the intervention---embedded modules or dedicated courses, humanists or computer scientists as ethics instructors---or on the specific content to be included---lists of case studies and essential topics to cover. While proponents of computer ethics education often emphasize the importance of closely connecting ethical and technical content in these initiatives, most do not reflect in depth on the variety of ways in which the disciplines can be combined. In this paper, I deploy a framework from cross-disciplinary studies that categorizes academic projects that work across disciplines as multidisciplinary, interdisciplinary, or transdisciplinary, depending on the degree of integration. When applied to computer ethics education, this framework is orthogonal to the structure and content of the initiative, as I illustrate using examples of dedicated ethics courses and embedded modules. It therefore highlights additional features of cross-disciplinary teaching that need to be considered when planning a computer ethics programme. I argue that computer ethics education should aim to be at least interdisciplinary-multidisciplinary initiatives are less aligned with the pedagogical aims of computer ethics-and that computer ethics educators should experiment with fully transdisciplinary education that could transform computer science as a whole for the better.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {645–651},
numpages = {7},
keywords = {cross-disciplinary studies, data justice, embedded ethics, ethics course, ethics education, higher education, interdisciplinary studies, interdisciplinary teaching and learning, responsible computing, transdisciplinary studies},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@proceedings{10.1145/3643667,
title = {Q-SE 2024: Proceedings of the 5th ACM/IEEE International Workshop on Quantum Software Engineering},
year = {2024},
isbn = {9798400705700},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 5th International Workshop on Quantum Software Engineering (Q-SE 2024), co-located with ICSE 2024, provides a platform for researchers and practitioners to discuss challenges in developing quantum software in high-level quantum languages, novel solutions to build correct methods for testing quantum programs, executing quantum software, developing best practices, and creating a research roadmap of quantum software engineering.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3636243.3636249,
author = {Sheese, Brad and Liffiton, Mark and Savelka, Jaromir and Denny, Paul},
title = {Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636249},
doi = {10.1145/3636243.3636249},
abstract = {Providing personalized assistance at scale is a long-standing challenge for computing educators, but a new generation of tools powered by large language models (LLMs) offers immense promise. Such tools can, in theory, provide on-demand help in large class settings and be configured with appropriate guardrails to prevent misuse and mitigate common concerns around learner over-reliance. However, the deployment of LLM-powered tools in authentic classroom settings is still rare, and very little is currently known about how students will use them in practice and what type of help they will seek. To address this, we examine students’ use of an innovative LLM-powered tool that provides on-demand programming assistance without revealing solutions directly. We deployed the tool for 12 weeks in an introductory computer and data science course&nbsp;(n = 52), collecting more than 2,500 queries submitted by students throughout the term. We manually categorized all student queries based on the type of assistance sought, and we automatically analyzed several additional query characteristics. We found that most queries requested immediate help with programming assignments, whereas fewer requests asked for help on related concepts or for deepening conceptual understanding. Furthermore, students often provided minimal information to the tool, suggesting this is an area in which targeted instruction would be beneficial. We also found that students who achieved more success in the course tended to have used the tool more frequently overall. Lessons from this research can be leveraged by programming educators and institutions who plan to augment their teaching with emerging LLM-powered tools.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {49–57},
numpages = {9},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@article{10.1145/3643646,
author = {Pias, Marcelo and Cuadros-Vargas, Ernesto and Duran, Rodrigo},
title = {Computer Science Education in Latin America and the Caribbean},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {2153-2184},
url = {https://doi.org/10.1145/3643646},
doi = {10.1145/3643646},
journal = {ACM Inroads},
month = feb,
pages = {38–47},
numpages = {10}
}

@inproceedings{10.1145/3626252.3630964,
author = {Bhaskar, Niharika and Lewis, Amari N. and Darabi, Rona and Fang, Joana and Liu, Jingting and Vaccaro, Kristen and Politz, Joe Gibbs and Minnes, Mia},
title = {Welcoming Students to Undergraduate Computer Science Programs: On-ramps, Rest Areas, and Lane Changes},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630964},
doi = {10.1145/3626252.3630964},
abstract = {Studying computer science is a journey: people start at different times, travel at different paces, and pause along the way. In this experience report, we describe a peer-led, year-long program designed to welcome students to Computer Science and Engineering as a discipline, department, and academic program. We detail the logistical, curricular, and personnel structures of this program, highlighting design choices we made to (a) open multiple ways to join the program all year, (b) de-emphasize "getting ahead", (c) prioritize reflection, and (d) connect students to existing resources. Throughout, we emphasize the critical role of peer mentors in leading and shaping this space. We share our own lessons learned, as well as reflections from students and mentors on the value of this learning community outside of formal classroom structures.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {109–115},
numpages = {7},
keywords = {broadening participation, hidden curriculum, peer mentors, undergraduate computing programs},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3623762.3633494,
author = {Cutts, Quintin and Kallia, Maria and Anderson, Ruth and Crick, Tom and Devlin, Marie and Farghally, Mohammed and Mirolo, Claudio and Runde, Ragnhild Kobro and Sepp\"{a}l\"{a}, Otto and Urquiza-Fuentes, Jaime and Vahrenhold, Jan},
title = {Arguments for and Approaches to Computing Education in Undergraduate Computer Science Programmes},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633494},
doi = {10.1145/3623762.3633494},
abstract = {Computing education (CE), the scientific foundation of the teaching and learning of subject matter specific to computing, has matured into a field with its own research journals and conferences as well as graduate programmes. Yet, and unlike other mature subfields of computer science (CS), it is rarely taught as part of undergraduate CS programmes. In this report, we present a gap analysis resulting from semi-structured interviews with various types of stakeholders and derive a set of arguments for teaching CE courses in undergraduate CS programmes. This analysis and the arguments highlight a number of opportunities for the discipline of CS at large, in academia, in industry, and in school education, that would be opened up with undergraduate CE courses, as well as potential barriers to implementation that will need to be overcome. We also report on the results of a Delphi process performed to elicit topics for such a course with various audiences in mind. The Delphi process yielded 19 high-level categories that encompass the subject matter CE courses should incorporate, tailored to the specific needs of their intended student audiences. This outcome underscores the extensive range of content that can be integrated into a comprehensive CE programme. Based on these two stakeholder interactions as well as a systematic literature review aiming to explore the current practices in teaching CE to undergraduate students, we develop two prototypical outlines of such a course, keeping in mind that departments may have different preferences and affordances resulting in different kinds of CE offerings. Overall, input from external stakeholders underscores the clear significance of undergraduate CE courses. We anticipate leveraging this valuable feedback to actively promote these courses on a broader scale.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {160–195},
numpages = {36},
keywords = {argument, computing education, curriculum outline, undergraduate},
location = {Turku, Finland},
series = {ITiCSE-WGR '23}
}

@inproceedings{10.1109/ICSE48619.2023.00169,
author = {McGuire, Sean and Schultz, Erin and Ayoola, Bimpe and Ralph, Paul},
title = {Sustainability is Stratified: Toward a Better Theory of Sustainable Software Engineering},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00169},
doi = {10.1109/ICSE48619.2023.00169},
abstract = {Background: Sustainable software engineering (SSE) means creating software in a way that meets present needs without undermining our collective capacity to meet our future needs. It is typically conceptualized as several intersecting dimensions or "pillars"---environmental, social, economic, technical and individual. However; these pillars are theoretically underdeveloped and require refinement. Objectives: The objective of this paper is to generate a better theory of SSE. Method: First, a scoping review was conducted to understand the state of research on SSE and identify existing models thereof. Next, a meta-synthesis of qualitative research on SSE was conducted to critique and improve the existing models identified. Results: 961 potentially relevant articles were extracted from five article databases. These articles were de-duplicated and then screened independently by two screeners, leaving 243 articles to examine. Of these, 109 were non-empirical, the most common empirical method was systematic review, and no randomized controlled experiments were found. Most papers focus on ecological sustainability (158) and the sustainability of software products (148) rather than processes. A meta-synthesis of 36 qualitative studies produced several key propositions, most notably, that sustainability is stratified (has different meanings at different levels of abstraction) and multisystemic (emerges from interactions among multiple social, technical, and sociotechnical systems). Conclusion: The academic literature on SSE is surprisingly non-empirical. More empirical evaluations of specific sustainability interventions are needed. The sustainability of software development products and processes should be conceptualized as multisystemic and stratified, and assessed accordingly.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {1996–2008},
numpages = {13},
keywords = {meta-synthesis, scoping review, sustainable software engineering, software engineering, sustainable development},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@proceedings{10.1145/3626252,
title = {SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is "Blazing New Trails in CS Education." This broad theme captures the exceptional work being performed by this community to enhance our teaching, improve our assessments, attract diverse students, and all of the other laudable projects, initiatives, and undertakings that affect positive change. The breadth of the program is substantial - there truly should be something for everyone. In fact, your biggest challenge may be deciding which session to attend in each time slot because there is so much going on! We know that many of you want to attend as many sessions as possible while you are here in Portland, but we encourage you to also find a little bit of time for yourself so that you leave Portland refreshed, renewed and encouraged, rather than exhausted or burnt out.},
location = {Portland, OR, USA}
}

@inproceedings{10.1145/3641555.3705201,
author = {Bejarano, Andres and Dickey, Ethan and Setsma, Rhianna},
title = {Implementing the AI-Lab Framework: Enhancing Introductory Programming Education for CS Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705201},
doi = {10.1145/3641555.3705201},
abstract = {The advent of generative AI tools presents novel opportunities and challenges in computer science education, particularly in introductory programming courses. This study explores the implementation of AI-Lab, a framework designed to guide students in the effective and ethical use of generative AI, in this case ChatGPT, in academic settings without compromising skill development. Conducted during Spring 2024, our use of the intervention targeted over 500 Computer Science and Data Science majors enrolled in their major-specific Data Structures and Algorithms courses. The AI-Lab framework enabled students to develop both conceptual questions and c++ and Python programs by interacting with ChatGPT and iteratively correcting its errors. Focus groups and post-intervention surveys revealed a generally positive experience. Students appreciated the ability to leverage AI for tasks outside their major, recognizing the value of understanding correct solutions through AI-assisted programming. Moreover, the guided use of generative AI by professors alleviated concerns regarding academic dishonesty, fostering a supportive learning environment. Despite these benefits, students expressed awareness of the potential drawbacks of over-reliance on AI, noting the risk of impeding their professional growth. Nevertheless, they acknowledged the practical utility of AI for non-major related tasks. This study highlights the importance of incorporating structured AI training in curricula to balance skill development and ethical AI usage, offering insights for broader applications in higher education.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1383–1384},
numpages = {2},
keywords = {ai lab, ai-assisted programming, ai-lab framework, ethical ai usage, generative ai in education, skill development with ai, structured ai training},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3711026,
author = {Keppler, Samantha and Sinchaisri, Wichinpong Park and Snyder, Clare},
title = {Making ChatGPT Work for Me},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711026},
doi = {10.1145/3711026},
abstract = {Increasingly, work happens through human collaboration with generative AI (e.g., ChatGPT). In this paper, we present a qualitative study of this collaboration for real-life work tasks. We focus our study on US K12 public school teachers (N = 24) who regularly design and complete text-generation tasks such as creating quizzes, slide decks, word problems, reading passages, lesson plans, classroom activities, and projects. In one-on-one video- and audio-recorded virtual sessions, we observe each teacher using ChatGPT-4 for work tasks of their choosing for 15 minutes, then debrief their experience. Analyzing 201 prompts inputted by the 24 teachers, we uncover four main modes with which the teachers request support from ChatGPT: (1) make for me (55% of prompts), (2) find for me (15%), (3) jump-start for me (10.5%), and (4) iterate with me (15.5%). The first three modes (make, find, and jump-start) are often requests of generative AI to do something, whereas the fourth mode (iterate) is a request of generative AI to think. In a follow-up survey of the same 24 teachers, most report using multiple modes for their work, but infrequently. Our study contributes new data and knowledge about how teachers are coming to understand whether and how to integrate generative AI into their teaching preparation routines.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW128},
numpages = {23},
keywords = {K12 education, generative AI, human-computer interaction}
}

@inproceedings{10.1145/3706598.3713470,
author = {Schneiders, Eike and Seabrooke, Tina and Krook, Joshua and Hyde, Richard and Leesakul, Natalie and Clos, Jeremie and Fischer, Joel E},
title = {Objection Overruled! Lay People can Distinguish Large Language Models from Lawyers, but still Favour Advice from an LLM},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713470},
doi = {10.1145/3706598.3713470},
abstract = {Large Language Models (LLMs) are seemingly infiltrating every domain, and the legal context is no exception. In this paper, we present the results of three experiments (total N&nbsp;=&nbsp;288) that investigated lay people’s willingness to act upon, and their ability to discriminate between, LLM- and lawyer-generated legal advice. In Experiment 1, participants judged their willingness to act on legal advice when the source of the advice was either known or unknown. When the advice source was unknown, participants indicated that they were significantly more willing to act on the LLM-generated advice. The result of the source unknown condition was replicated in Experiment 2. Intriguingly, despite participants indicating higher willingness to act on LLM-generated advice in Experiments 1 and 2, participants discriminated between the LLM- and lawyer-generated texts significantly above chance-level in Experiment 3. Lastly, we discuss potential explanations and risks of our findings, limitations and future work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1201},
numpages = {14},
keywords = {Large language model, LLM, legal advice, generative AI, ChatGPT},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3613904.3642216,
author = {Kim, Tae Soo and Lee, Yoonjoo and Shin, Jamin and Kim, Young-Ho and Kim, Juho},
title = {EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642216},
doi = {10.1145/3613904.3642216},
abstract = {By simply composing prompts, developers can prototype novel generative applications with Large Language Models (LLMs). To refine prototypes into products, however, developers must iteratively revise prompts by evaluating outputs to diagnose weaknesses. Formative interviews (N=8) revealed that developers invest significant effort in manually evaluating outputs as they assess context-specific and subjective criteria. We present EvalLM, an interactive system for iteratively refining prompts by evaluating multiple outputs on user-defined criteria. By describing criteria in natural language, users can employ the system’s LLM-based evaluator to get an overview of where prompts excel or fail, and improve these based on the evaluator’s feedback. A comparative study (N=12) showed that EvalLM, when compared to manual evaluation, helped participants compose more diverse criteria, examine twice as many outputs, and reach satisfactory prompts with 59% fewer revisions. Beyond prompts, our work can be extended to augment model evaluation and alignment in specific application contexts.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {306},
numpages = {21},
keywords = {Evaluation, Human-AI Interaction, Large Language Models, Natural Language Generation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.5555/3722479.3722508,
author = {Huang, Ching-yu},
title = {Innovative Career-Focused Curriculum for Computer Science and Information Technology},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {Undergraduate students from disadvantaged backgrounds often lack guidance when it comes to selecting college majors and exploring career paths. As a result, they may be unprepared for internships or job searches during their freshman or sophomore years. Many choose majors like computer science or information technology because of the promising job market, but they may not fully understand the types of jobs, roles, and skills required in these fields.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {65–66},
numpages = {2}
}

@inproceedings{10.1145/3657604.3662036,
author = {Lyu, Wenhan and Wang, Yimeng and Chung, Tingting (Rachel) and Sun, Yifan and Zhang, Yixuan},
title = {Evaluating the Effectiveness of LLMs in Introductory Computer Science Education: A Semester-Long Field Study},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662036},
doi = {10.1145/3657604.3662036},
abstract = {The integration of AI assistants, especially through the development of Large Language Models (LLMs), into computer science education has sparked significant debate, highlighting both their potential to augment student learning and the risks associated with their misuse. An emerging body of work has looked into using LLMs in education, primarily focusing on evaluating the performance of existing models or conducting short-term human subject studies. However, very little work has examined the impacts of LLM-powered assistants on students in entry-level programming courses, particularly in real-world contexts and over extended periods. To address this research gap, we conducted a semester-long, between-subjects study with 50 students using CodeTutor, an LLM-powered assistant developed by our research team. Our study results show that students who used CodeTutor (the "CodeTutor group" as the experimental group) achieved statistically significant improvements in their final scores compared to peers who did not use the tool (the "control group"). Within the CodeTutor group, those without prior experience with LLM-powered tools demonstrated significantly greater performance gain than their counterparts. We also found that students expressed positive feedback regarding CodeTutor's capability to comprehend their queries and assist in learning programming language syntax. However, they had concerns about CodeTutor's limited role in developing critical thinking skills. Over the course of the semester, students' agreement with CodeTutor's suggestions decreased, with a growing preference for support from traditional human teaching assistants. Our findings also show that students turned to CodeTutor for different tasks, including programming task completion, syntax comprehension, and debugging, particularly seeking help for programming assignments. Our analysis further reveals that the quality of user prompts was significantly correlated with CodeTutor's response effectiveness. Building upon these results, we discuss the implications of our findings for the need to integrate Generative AI literacy into curricula to foster critical thinking skills, and turn to examining the temporal dynamics of user engagement with LLM-powered tools. We further discuss the discrepancy between the anticipated functions of tools and students' actual capabilities, which sheds light on the need for tailored strategies to improve educational outcomes.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {63–74},
numpages = {12},
keywords = {field study, large language models, tutoring},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.1145/3617946.3617959,
author = {Krusche, Stephan and Bell, Jonathan and Tenbergen, Bastian},
title = {Software Engineering Education for the Next Generation:SEENG 2023 Workshop Report},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/3617946.3617959},
doi = {10.1145/3617946.3617959},
abstract = {The 5th International Workshop on Software Engineering Education for the Next Generation was held on May 16, 2023 in Melbourne, Australia. The workshop was part of the 45th International Conference on Software Engineering. It specifically supported the general theme of "Educating the Next Generation of Software Engineers". Building on its predecessors, the workshop used a highly interactive format, structured around eight short paper presentations to generate discussion topics, an activity to select the most interesting topics, and structured breakout sessions. This enabled the participants to discuss the most interesting topics in detail. Participants presented the results of the breakout sessions using mind maps.},
journal = {SIGSOFT Softw. Eng. Notes},
month = oct,
pages = {66–69},
numpages = {4}
}

@inproceedings{10.1145/3641555.3705183,
author = {Brockenbrough, Allan and Feild, Henry and Salinas, Dominic},
title = {Exploring LLMs Impact on Student-Created User Stories and Acceptance Testing in Software Development},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705183},
doi = {10.1145/3641555.3705183},
abstract = {In Agile software development methodology, a user story describes a new feature or functionality from an end user's perspective. The user story details may also incorporate acceptance testing criteria, which can be developed through negotiation with users. When creating stories from user feedback, the software engineer may maximize their usefulness by considering story attributes, including scope, independence, negotiability, and testability. This study investigates how LLMs (large language models), with guided instructions, affect undergraduate software engineering students' ability to transform user feedback into user stories. Students, working individually, were asked to analyze user feedback comments, appropriately group related items, and create user stories following the principles of INVEST, a framework for assessing user stories. We found that LLMs help students develop valuable stories with well-defined acceptance criteria. However, students tend to perform better without LLMs when creating user stories with an appropriate scope.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1401–1402},
numpages = {2},
keywords = {LLM, generative AI, large language model, user story},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3665464.3665475,
author = {Moore, Meredith and Urness, Timothy},
title = {Inclusive Practices and Universal Design in the Computer Science Classroom},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {Universal Design is the principle for designing products to be usable by all people. In this paper, we discuss how universal design can be incorporated into the traditional computer science classroom by intentionally considering how classroom exercises, assignments, discussions, and designing of code can make for an inclusive learning environment. We describe Universal Design for Learning and give examples of effective practices including course design, classroom environment, equitable participation, lecture structure, assignments, and in-class exercises.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {93–102},
numpages = {10}
}

@proceedings{10.1145/3641399,
title = {ISEC '24: Proceedings of the 17th Innovations in Software Engineering Conference},
year = {2024},
isbn = {9798400717673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangalore, India}
}

@inproceedings{10.1145/3643664.3648207,
author = {Alami, Adam and Zahedi, Mansooreh and Ernst, Neil},
title = {Are You a Real Software Engineer? Best Practices in Online Recruitment for Software Engineering Studies},
year = {2024},
isbn = {9798400705670},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643664.3648207},
doi = {10.1145/3643664.3648207},
abstract = {Online research platforms, such as Prolific, offer rapid access to diverse participant pools but also pose unique challenges in participant qualification and skill verification. Previous studies reported mixed outcomes and challenges in leveraging online platforms for the recruitment of qualified software engineers. Drawing from our experience in conducting three different studies using Prolific, we propose best practices for recruiting and screening participants to enhance the quality and relevance of both qualitative and quantitative software engineering (SE) research samples. We propose refined best practices for recruitment in SE research on Prolific. (1) Iterative and controlled prescreening, enabling focused and manageable assessment of submissions (2) task-oriented and targeted questions that assess technical skills, knowledge of basic SE concepts, and professional engagement. (3) AI detection to verify the authenticity of free-text responses. (4) Qualitative and manual assessment of responses, ensuring authenticity and relevance in participant answers (5) Additional layers of prescreening are necessary when necessary to collect data relevant to the topic of the study. (6) Fair or generous compensation post-qualification to incentivize genuine participation. By sharing our experiences and lessons learned, we contribute to the development of effective and rigorous methods for SE empirical research. particularly the ongoing effort to establish guidelines to ensure reliable data collection. These practices have the potential to transferability to other participant recruitment platforms.},
booktitle = {Proceedings of the 1st IEEE/ACM International Workshop on Methodological Issues with Empirical Studies in Software Engineering},
pages = {52–57},
numpages = {6},
keywords = {empirical software engineering, prolific, participant recruitment, online research platforms},
location = {Lisbon, Portugal},
series = {WSESE '24}
}

@inproceedings{10.1145/3675094.3677578,
author = {Choi, Yoonseon and Jeong, Dayoung and Kim, Bogoan and Han, Kyungsik},
title = {Early Prediction of Cybersickness in Virtual Reality Using a Large Language Model for Multimodal Time Series Data},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3677578},
doi = {10.1145/3675094.3677578},
abstract = {Cybersickness in virtual reality (VR) significantly disrupts user immersion. Although recent studies have proposed cybersickness prediction models, existing models have considered the moment of cybersickness onset, limiting their applicability in proactive detection. To address this limitation, we used long-term time series forecasting (LTSF) models based on multimodal sensor data collected from the head-mounted display (HMD). We used a pre-trained large language model (LLM) to effectively learn the salient features (e.g., seasonality) of multimodal sensor data by understanding the nuanced context within the data. The results of our experiment demonstrated that our model achieved comparable performance to the baseline models, with an MAE of 0.971 and an RMSE of 1.696. This indicates the potential for early prediction of cybersickness by employing LLM- and LTSF-based models with multimodal sensor data, suggesting a new direction in model development.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {25–29},
numpages = {5},
keywords = {cybersickness, early prediction, multimodal sensor data, time-llm},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@proceedings{10.1145/3611643,
title = {ESEC/FSE 2023: Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to ESEC/FSE 2023, the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ESEC/FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. ESEC/FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {San Francisco, CA, USA}
}

@article{10.5555/3636988.3637014,
author = {Anewalt, Karen and Polack, Jennifer},
title = {Industry Trends in Software Engineering: Alumni Perspectives},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {3},
issn = {1937-4771},
abstract = {It is important for computer science curricula to prepare graduates for their future careers. Alignment efforts between academia and industry benefit both communities. Having data about current industry trends, including tools and critical experiences, allows academia to adjust course assignments and curricula to provide relevant and needed material in today's computer science job market. We present survey responses from industry professionals related to tool, project, communication, and collaboration experiences essential for new employees. The collected data can be used to update and enhance current assignments across curricula. Responding to industry trends and demands can give future computer science professionals valuable experience as they begin their careers.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {159–170},
numpages = {12}
}

@article{10.5555/3636517.3636523,
author = {Tribelhorn, Ben and Nuxoll, Andrew},
title = {A Course Model for Ethics Education in Computer Science},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {1},
issn = {1937-4771},
abstract = {This paper presents a course model for teaching ethics to Computer Science students without being linked to a technical topic which helps students think more holistically. The course model proposed allows for students to build on their philosophy of ethics course from the core and to focus on current issues in technology. The assignments and topic generation activities presented can be easily adopted, even into other courses for institutions that don't offer technology focused ethics course. This course assists in aligning the Computer Science major curriculum with one of the five ABET program outcomes and to align with current guidance from ACM. The course was evaluated with a student survey to assess five learning objectives. The initial survey results show that students felt they improved on all five, especially in their ability to identify ethical issues in design decisions.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {48–55},
numpages = {8}
}

@proceedings{10.1145/3623762,
title = {ITiCSE-WGR '23: Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {In these proceedings, we present papers from the Working Groups that worked in the context of the 28th Annual Conference on Innovation &amp; Technology in Computer Science Education (ITiCSE), held in Turku Finland, and hosted by University of Turku from the 10th to the 12th of July 2023.The concept of Working Groups has been a unique feature of the ITiCSE conference series since its inception, with CompEd adopting the Working Group practice in 2019. A Working Group typically comprises 5 to 10 researchers who work together on a project related to computing education. Working Groups provide a wonderful opportunity to work intensively on a topic of interest with an international group of computing education researchers. This unique experience is one that, in our opinion, each Computer Science Educator should strive to participate in at least once.In 2023, 13 proposals for Working Groups were received and six Working Groups were selected by the Working Group chairs to recruit members and proceed for ITiCSE 2023. There were over 100 member applications to Working Groups, with 67 being accepted across the six Working Groups.},
location = {Turku, Finland}
}

@inproceedings{10.1145/3587103.3594137,
author = {Tuson, Ella},
title = {Applications of Programming as Theory Building in Computer Science Education},
year = {2023},
isbn = {9798400701399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587103.3594137},
doi = {10.1145/3587103.3594137},
abstract = {The field of Computer Science has always been one of rapid growth and change. We propose the investigation of Peter Naur's framework of Programming as Theory building as a means to make CS education more resilient to emerging technology and to improve student outcomes by encouraging a focus on internal understanding over the external artifacts of programming.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2},
pages = {621–622},
numpages = {2},
keywords = {CS education, assessment, programming as theory building},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3641555.3705235,
author = {Gonzalez, Elias and Chan, Joel and Weintrop, David},
title = {Quack! Configuring Large Language Models to Serve as Rubber Duck Coding Assistants},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705235},
doi = {10.1145/3641555.3705235},
abstract = {The emergence of Generative Artificial Intelligence (GenAI) tools broadly, and Large Language Models (LLMs) specifically, are equipping introductory programming instructors with a whole new class of pedagogical tools. While GenAI certainly poses threats to time-honored instructional techniques, it also provides opportunities for new forms of instructional support. In this work, we introduce our strategy for configuring an LLM to serve as a ''rubber duck debugging'' coding assistant to help novice programmers when they encounter difficulties in programming assignments. The key contribution of this work is not in the idea of using LLMs for debugging itself (which has already been demonstrated elsewhere, e.g., [3]) but to demonstrate the ease, flexibility, and pedagogical potential of the strategy. In particular, through carefully crafted prompts and easily accessible platforms, rubber duck LLMs can assist learners with specific questions while also situating those questions alongside larger computer science concepts and computational thinking practices. This work contributes an easily replicated and model-agnostic instructional strategy that productively and responsibly leverages the power of LLMs to assist novice programmers in developing foundational programming skills.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1463–1464},
numpages = {2},
keywords = {computer science education, generative ai, introductory programming, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3657604.3664701,
author = {Popescu, Diana M. and Joyner, David A.},
title = {ChatGPT's Performance on Problem Sets in an At-Scale Introductory Computer Science Course},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664701},
doi = {10.1145/3657604.3664701},
abstract = {This work in progress paper examines the impact of LLMs such as ChatGPT in a college-level introductory computing course offered simultaneously as a massive open online course (MOOC) on the edX platform, focusing on its strengths and limitations in solving coding assignments. The study reveals ChatGPT's proficiency in some areas while highlighting challenges in pseudo-code interpretation, handling multiple correct answers, and addressing complex problem statements. In order to discourage over-reliance on AI assistance from students while preserving scalability, the paper proposes strategies to enhance the difficulty of coding assignments by adding more creative elements in their structure. This research provides insights into the dynamics of AI in education and emphasizes the need for a balanced approach between technological assistance and genuine student participation.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {486–490},
numpages = {5},
keywords = {applied computing, artificial intelligence, e-learning},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.1145/3579592,
author = {Karinshak, Elise and Liu, Sunny Xun and Park, Joon Sung and Hancock, Jeffrey T.},
title = {Working With AI to Persuade: Examining a Large Language Model's Ability to Generate Pro-Vaccination Messages},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW1},
url = {https://doi.org/10.1145/3579592},
doi = {10.1145/3579592},
abstract = {Artificial Intelligence (AI) is a transformative force in communication and messaging strategy, with potential to disrupt traditional approaches. Large language models (LLMs), a form of AI, are capable of generating high-quality, humanlike text. We investigate the persuasive quality of AI-generated messages to understand how AI could impact public health messaging. Specifically, through a series of studies designed to characterize and evaluate generative AI in developing public health messages, we analyze COVID-19 pro-vaccination messages generated by GPT-3, a state-of-the-art instantiation of a large language model. Study 1 is a systematic evaluation of GPT-3's ability to generate pro-vaccination messages. Study 2 then observed peoples' perceptions of curated GPT-3-generated messages compared to human-authored messages released by the CDC (Centers for Disease Control and Prevention), finding that GPT-3 messages were perceived as more effective, stronger arguments, and evoked more positive attitudes than CDC messages. Finally, Study 3 assessed the role of source labels on perceived quality, finding that while participants preferred AI-generated messages, they expressed dispreference for messages that were labeled as AI-generated. The results suggest that, with human supervision, AI can be used to create effective public health messages, but that individuals prefer their public health messages to come from human institutions rather than AI sources. We propose best practices for assessing generative outputs of large language models in future social science research and ways health professionals can use AI systems to augment public health messaging.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {116},
numpages = {29},
keywords = {AI-mediated communication, large language models, message factors, natural language processing, persuasion, public health messaging}
}

@proceedings{10.5555/3623295,
title = {ICSE-SEET '23: Proceedings of the 45th International Conference on Software Engineering: Software Engineering Education and Training},
year = {2023},
isbn = {9798350322590},
publisher = {IEEE Press},
location = {Melbourne, Australia}
}

@inproceedings{10.1145/3723010.3723031,
author = {Marquardt, Kai and Shang, Qiongdan and Hennh\"{o}fer, Oliver and Happe, Lucia},
title = {Interdisciplinary Harmonies: A Story-Driven Course on AI and Music to Increase Interest in Computer Science},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723031},
doi = {10.1145/3723010.3723031},
abstract = {To engage a broader spectrum of computer science (CS) students, particularly underrepresented groups such as novices and female students, this study introduces a unique interdisciplinary online course. This course merges the technical rigour of artificial intelligence (AI) with the aesthetic allure of music, underscoring the importance of beauty and arts in technology. It demonstrates AI’s applications in music through song recommendation algorithms and composition generation, captivating students and enhancing their interest in CS. Findings from a pre-test-post-test survey study involving two school classes (24 students, female: 17, male: 7, mean age: 17.63) indicate a significant rise in students’ engagement for CS with large effect sizes observed. These results highlight the potential of integrating arts into technology education, not only as an aesthetic enhancement but as a means to broaden the appeal and understanding of CS. This approach aligns with the growing emphasis on STEAM (Science, Technology, Engineering, Arts, Mathematics) education, aiming to make CS more accessible and prepare students for the diverse demands of the 21st-century workplace.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {145–153},
numpages = {9},
keywords = {Interdisciplinary curriculum, interest, e-learning, STEAM, music, artificial intelligence, storytelling},
location = {
},
series = {ECSEE '25}
}

@proceedings{10.1145/3723420,
title = {EBIMCS '24: Proceedings of the 2024 7th International Conference on E-Business, Information Management and Computer Science},
year = {2024},
isbn = {9798400712876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1109/ASE56229.2023.00096,
author = {Yan, Dapeng and Gao, Zhipeng and Liu, Zhiming},
title = {A Closer Look at Different Difficulty Levels Code Generation Abilities of ChatGPT},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00096},
doi = {10.1109/ASE56229.2023.00096},
abstract = {Code generation aims to generate source code implementing human requirements illustrated with natural language specifications. With the rapid development of intelligent software engineering, automated code generation has become a hot research topic in both artificial intelligence and software engineering, and researchers have made significant achievements on code generation. More recently, large language models (LLMs) have demonstrated outstanding performance on code generation tasks, such as ChatGPT released by OpenAI presents the fantastic potential on automated code generation. However, the existing studies are limited to exploring LLMs' ability for generating code snippets to solve simple programming problems, the task of competition-level code generation has never been investigated. The specifications of the programming competition are always complicated and require the specific input/output format as well as the high-level algorithmic reasoning ability. In this study, we conduct the first large empirical study to investigate the zero-shot learning ability of ChatGPT for solving competition programming problems. Specifically, we warm up the design of prompts by using the Human-Eval dataset. Then, we apply the well-designed prompt to the competition-level code generation dataset, namely APPS, to further explore the effectiveness of using ChatGPT for solving competition problems. We collect ChatGPT's outputs on 5,000 code competition problems, the evaluation results show that it can successfully pass 25.4% test cases. By further feeding extra information (e.g, test failed information) to ChatGPT, we observe that ChatGPT has the potential to fix partial pass into a fully pass program. Moreover, we investigate the solutions generated by LLMs and the existing solutions, we find that it prefers to directly copy the code instead of re-write when facing more difficult problems. Finally, we evaluate the code quality generated by ChatGPT in terms of "code cleanness", we observe that the generated codes are with small functions and file sizes, which are in line with the standard of clean code.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1887–1898},
numpages = {12},
keywords = {code generation, program competition, Chat-GPT, large language model, clean code},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@article{10.1145/3700773,
author = {Holland-Minkley, Amanda and Barnard, Jakob E. and Barr, Valerie and Braught, Grant and Davis, Janet and Reed, David and Schmitt, Karl and Tartaro, Andrea and Teresco, James D.},
title = {CS2023: Computer Science Curriculum Guidelines: A New Liberal Arts Perspective},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2153-2184},
url = {https://doi.org/10.1145/3700773},
doi = {10.1145/3700773},
journal = {ACM Inroads},
month = feb,
pages = {40–52},
numpages = {13}
}

@inproceedings{10.1145/3626253.3635511,
author = {Bhalerao, Rasika},
title = {My Learnings from Allowing Large Language Models in Introductory Computer Science Classes},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635511},
doi = {10.1145/3626253.3635511},
abstract = {Many instructors want to allow their students to use large language models (LLMs) in their introductory computer science courses, but they first want to see other instructors' results from doing so before taking on the risk in their own courses. Presented here are the results from allowing students to use LLMs in the second course in a sequence of intensive introductory courses designed to prepare students with a non-computational background for entry into a masters' degree program. We allowed students to use the internet and LLMs (such as ChatGPT or Github Copilot) to help with assignments, with guidelines to avoid plagiarism and encourage learning. We then surveyed students to ask about how they used LLMs, whether they saw others cheating, how they generally used internet-based resources on assignments and exams, and their feedback on the policies. We found that students are overwhelmingly using LLMs (and the internet generally) to learn and code "better" rather than cheat. These results are intended to be a starting point to spark discussion on the adoption of new technologies in introductory computer science courses. The authors themselves will continue teaching courses with the policy that students should interact with an LLM the way they interact with a person: students are encouraged to discuss and collaborate with it, but copying code from it is considered plagiarism.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1574–1575},
numpages = {2},
keywords = {AI, assignments, plagiarism, students},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3613905.3651096,
author = {Lo, Priscilla Y.},
title = {An Autoethnographic Reflection of Prompting a Custom GPT Based on Oneself},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3651096},
doi = {10.1145/3613905.3651096},
abstract = {What if you could have a chat with yourself? OpenAI’s introduction of custom GPTs in November 2023 provides an opportunity for non-technical users to create specialized generative artificial intelligence chatbots. Users can write prompts in plain language rather than code to instruct how the system should behave. What can one learn from using non-technical methods to develop a specific chatbot persona? To explore this, I conducted an autoethnography of my experience developing and interacting with a custom GPT based on myself. My findings include a discussion of my experiences throughout the process, and its impact on my personal introspection and understanding of prompt engineering. I summarize first-hand challenges and insights intended to inspire further discussion on the topic of generative AI and chatbots.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {40},
numpages = {9},
keywords = {autoethnography, chatbot, generative artificial intelligence, large language model, persona},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3652620.3687776,
author = {Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta and Scalera, Michele},
title = {Enhancing Software Modeling Learning with AI-Powered Scaffolding},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687776},
doi = {10.1145/3652620.3687776},
abstract = {This study introduces an innovative AI-powered scaffolding approach aimed at enhancing software modeling learning through UML diagrams. The focus of this research is on defining the principles and functions comprising the scaffolding. Leveraging recent advancements in generative AI, our approach provides a structured educational framework to improve comprehension and proficiency in modeling concepts. We present the initial implementation of the scaffolding, specifically highlighting the feedback function. By integrating theoretical insights with practical applications, this study seeks to advance Model-Driven Software Engineering education and underscores the potential of AI in enhancing instructional methodologies.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {103–106},
numpages = {4},
keywords = {generative AI, education, software modelling, model-driven software engineering, UML, scaffolding},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@article{10.1145/3634685,
author = {Brown, Noelle and Xie, Benjamin and Sarder, Ella and Fiesler, Casey and Wiese, Eliane S.},
title = {Teaching Ethics in Computing: A Systematic Literature Review of ACM Computer Science Education Publications},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
url = {https://doi.org/10.1145/3634685},
doi = {10.1145/3634685},
abstract = {The computing education research community now has at least 40 years of published research on teaching ethics in higher education. To examine the state of our field, we present a systematic literature review of papers in the Association for Computing Machinery computing education venues that describe teaching ethics in higher-education computing courses. Our review spans all papers published to SIGCSE, ICER, ITiCSE, CompEd, Koli Calling, and TOCE venues through 2022, with 100 papers fulfilling our inclusion criteria. Overall, we found a wide variety in content, teaching strategies, challenges, and recommendations. The majority of the papers did not articulate a conception of “ethics,” and those that did used many different conceptions, from broadly applicable ethical theories to social impact to specific computing application areas (e.g., data privacy and hacking). Instructors used many different pedagogical strategies (e.g., discussions, lectures, assignments) and formats (e.g., stand-alone courses, incorporated within a technical course). Many papers identified measuring student knowledge as a particular challenge, and 59% of papers included mention of assessments or grading. Of the 69% of papers that evaluated their ethics instruction, most used student self-report surveys, course evaluations, and instructor reflections. While many papers included calls for more ethics content in computing, specific recommendations were rarely broadly applicable, preventing a synthesis of guidelines. To continue building on the last 40 years of research and move toward a set of best practices for teaching ethics in computing, our community should delineate our varied conceptions of ethics, examine which teaching strategies are best suited for each, and explore how to measure student learning.},
journal = {ACM Trans. Comput. Educ.},
month = jan,
articleno = {6},
numpages = {36},
keywords = {computer science education, computing education, literature review, Ethics}
}

@proceedings{10.1145/3641142,
title = {ACSW '24: Proceedings of the 2024 Australasian Computer Science Week},
year = {2024},
isbn = {9798400717307},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@article{10.1145/3661143,
author = {Khanshan, Alireza and Van Gorp, Pieter and Markopoulos, Panos},
title = {Evaluation of Code Generation for Simulating Participant Behavior in Experience Sampling Method by Iterative In-Context Learning of a Large Language Model},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {EICS},
url = {https://doi.org/10.1145/3661143},
doi = {10.1145/3661143},
abstract = {The Experience Sampling Method (ESM) is commonly used to understand behaviors, thoughts, and feelings in the wild by collecting self-reports. Sustaining sufficient response rates, especially in long-running studies remains challenging. To avoid low response rates and dropouts, experimenters rely on their experience, proposed methodologies from earlier studies, trial and error, or the scarcely available participant behavior data from previous ESM protocols. This approach often fails in finding the acceptable study parameters, resulting in redesigning the protocol and repeating the experiment. Research has shown the potential of machine learning to personalize ESM protocols such that ESM prompts are delivered at opportune moments, leading to higher response rates. The corresponding training process is hindered due to the scarcity of open data in the ESM domain, causing a cold start, which could be mitigated by simulating participant behavior. Such simulations provide training data and insights for the experimenters to update their study design choices. Creating this simulation requires behavioral science, psychology, and programming expertise. Large language models (LLMs) have emerged as facilitators for information inquiry and programming, albeit random and occasionally unreliable. We aspire to assess the readiness of LLMs in an ESM use case. We conducted research using GPT-3.5 turbo-16k to tackle an ESM simulation problem. We explored several prompt design alternatives to generate ESM simulation programs, evaluated the output code in terms of semantics and syntax, and interviewed ESM practitioners. We found that engineering LLM-enabled ESM simulations have the potential to facilitate data generation, but they perpetuate trust and reliability challenges.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {255},
numpages = {19},
keywords = {Behavior Simulation, Experience Sampling Method, Large Language Model, Prompt Engineering}
}

@proceedings{10.1145/3708036,
title = {ICCSMT '24: Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
year = {2024},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3581754.3584111,
author = {Cao, Chen},
title = {Scaffolding CS1 Courses with a Large Language Model-Powered Intelligent Tutoring System},
year = {2023},
isbn = {9798400701078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581754.3584111},
doi = {10.1145/3581754.3584111},
abstract = {Programming skills are rapidly becoming essential for many educational paths and career opportunities. Yet, for many international students, the traditional approach to teaching introductory programming courses can be a significant challenge due to the complexities of the language, the lack of prior programming knowledge, and the language and cultural barriers. This study explores how large language models and gamification can scaffold coding learning and increase Chinese students’ sense of belonging in introductory programming courses. In this project, a gamification intelligent tutoring system was developed to adapt to Chinese international students’ learning needs and provides scaffolding to support their success in introductory computer programming courses. My research includes three studies: a formative study, a user study of an initial prototype, and a computer simulation study with a user study in progress. Both qualitative and quantitative data were collected through surveys, observations, focus group discussions and computer simulation. The preliminary findings suggest that GPT-3-enhanced gamification has great potential in scaffolding introductory programming learning by providing adaptive and personalised feedback, increasing students’ sense of belonging, and reducing their anxiety about learning programming.},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {229–232},
numpages = {4},
location = {Sydney, NSW, Australia},
series = {IUI '23 Companion}
}

@proceedings{10.1145/3614407,
title = {CSLAW '24: Proceedings of the 2024 Symposium on Computer Science and Law},
year = {2024},
isbn = {9798400703331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Boston, MA, USA}
}

@inproceedings{10.1145/3660650.3660656,
author = {Bird, William},
title = {Faceless Adversary, Feckless Colleague: The Many Sides of ChatGPT},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660656},
doi = {10.1145/3660650.3660656},
abstract = {Although CS educators have studied the potential of generative AI for years, the release of ChatGPT in late 2022 sparked a wave of uncertainty and anxiety. With students arriving at university already experienced with using ChatGPT for work across the academic spectrum, educators were under pressure to somehow address the presence of this new resource in their classroom. This article describes both the “climate of fear” surrounding ChatGPT’s impacts on education and an attempt by the authors to induct ChatGPT as a colleague instead of an adversary. While creating a video series where we used ChatGPT to generate practice exercises for CS1 and CS2, we found it to be patient, charismatic and friendly, but also sometimes obstinate, misinformed, stubborn and confused; in other words, it was surprisingly human.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {14},
numpages = {6},
keywords = {CS education, generative AI, teaching tools},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3641555.3705141,
author = {Alba, Charles and Xi, Wang and Wang, Chenyu and An, Ruopeng},
title = {ChatGPT Comes to Campus: Unveiling Core Themes in AI Policies Across U.S. Universities with Large Language Models},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705141},
doi = {10.1145/3641555.3705141},
abstract = {The release of popular generative artificial intelligence (AI) tools like ChatGPT have prompted universities to introduce new policies or update existing ones. Currently, most institutions adapt their policies reactively as challenges arise, often without adopting a systematic framework, with minimal guidance and limited knowledge of the approaches taken by other institutions across the United States (U.S.). This study aims to bridge this gap by identifying core themes surrounding AI policies and guidelines across the top 50 U.S. universities. Given the labor- and time-intensive nature required to manually synthesize multiple policy documents across many institutions, we leverage large language models (LLMs) to identify common and prevalent themes. Our framework first summarizes AI policies at the institutional level, followed by the generation of multiple sets of themes through an iterative process of prompt chaining and self-refinement. Finally, the common themes from these distinct sets were consolidated. This framework is designed to address potential flaws in pre-trained LLMs, such as hallucinations. Seven distinct themes are uncovered: (1) academic integrity and responsible AI use, (2) communication of AI policies, (3) data privacy and security concerns, (4) ethical considerations in AI use, (5) continuous adaptation and policy evolution, (6) documentation and transparency in AI usage, and (7) instructor discretion in AI integration. Our work lays the foundation for future analyses or recommendations in developing comprehensive and equitable AI policies. Furthermore, leveraging LLMs allows us to respond swiftly to developments surrounding AI policies across universities.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1359–1360},
numpages = {2},
keywords = {AI policies at universities, ChatGPT, academic integrity, generative AI, generative AI use in classrooms, large language models, teaching with AI},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@proceedings{10.5555/3623293,
title = {ICSE-SEIP '23: Proceedings of the 45th International Conference on Software Engineering: Software Engineering in Practice},
year = {2023},
isbn = {9798350300376},
publisher = {IEEE Press},
location = {Melbourne, Australia}
}

@inproceedings{10.1145/3689535.3689538,
author = {Sentance, Sue and Watson, Steven and Addo, Salomey Afua and Shi, Shengpeng and Waite, Jane and Yu, Bo},
title = {Developing Computing Teacher Guidance on GenAI},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689538},
doi = {10.1145/3689535.3689538},
abstract = {Generative AI (GenAI) is becoming widely available for use in schools by teachers and students. While many educators appreciate the potential benefits of GenAI for enhancing learning, there are also significant concerns about authorship, authenticity, plagiarism, ethics, biases, and the broader implications of their use in education. For computing teachers in schools, these issues can be even more acute. In this project, we established a working group of practising computing teachers to bring together a range of views and experiences. Initial results of the project led to a booklet for computing teachers on how to use GenAI, illustrating the effectiveness of teacher-researcher partnerships in developing resources for school use. This project will be followed by further work on computing teachers’ actual experience of GenAI in practice.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {12},
numpages = {1},
keywords = {AI education, K-12 education, generative AI, teachers},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3706598.3713624,
author = {Ali, Murtaza and Dasgupta, Sayamindu},
title = {"Even Though I Went Through Everything, I Didn't Feel Like I Learned a Lot": Insights From Experiences of Non-Computer Science Students Learning to Code},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713624},
doi = {10.1145/3706598.3713624},
abstract = {Programming education is increasingly seen as an important curricular component of non-Computer Science (CS) disciplines at the undergraduate level. While existing research has studied non-CS majors’ experiences in introductory programming courses, there is limited work that explores such experiences across universities and disciplines. To address this gap, we conducted semi-structured interviews with 12 non-CS major programming students across several majors and universities and interpreted the results through reflexive thematic analysis. Our findings suggest that while students are excited about and interested in learning programming, they face barriers that often arise from the design of the courses they take and a lack of targeted resources and tools to support them. Building on our findings, we conclude with a set of recommendations for the design of tools, artifacts, and courses that can support programming education for non-major students.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {49},
numpages = {18},
keywords = {computing education, novice programmers, learning to code, non-Computer Science majors},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3610978.3640752,
author = {Rogers, Kantwon and Webber, Reiden John Allen and Gorostiaga Zubizarreta, Geronimo and Melo Cruz, Arthur and Chen, Shengkang and Arkin, Ronald C. and Borenstein, Jason and Wagner, Alan R.},
title = {What Should a Robot Do? Comparing Human and Large Language Model Recommendations for Robot Deception},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3640752},
doi = {10.1145/3610978.3640752},
abstract = {This study compares human ethical judgments with Large Language Models (LLMs) on robotic deception in various scenarios. Surveying human participants and querying LLMs, we presented ethical dilemmas in high-risk and low-risk contexts. Findings reveal alignment between humans and LLMs in high-risk scenarios, prioritizing safety, but notable divergences in low-risk situations, reflecting challenges in AI development to accurately capture human social nuances and moral expectations.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {906–910},
numpages = {5},
keywords = {LLM, deception, ethical dilemmas, human-robot interaction},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3660650.3660662,
author = {Goddard, Quinn and Moton, Nathan and Hudson, Jonathan and He, Helen Ai},
title = {A Chatbot Won't Judge Me: An Exploratory Study of Self-disclosing Chatbots in Introductory Computer Science Classes},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660662},
doi = {10.1145/3660650.3660662},
abstract = {Students in introductory Computer Science (CS) courses sometimes struggle with learning course content, but feel these struggles are uniquely theirs. To foster a more inclusive CS culture and normalize challenges in the learning process, we designed a conversational agent (“chatbot”) that self-discloses information about the chatbot’s own imaginary struggles with learning course material. Inspired by previous work in the mental health domain where humans reciprocated disclosure when a chatbot disclosed sensitive information, our goal was to promote student self-disclosure of learning challenges and to help students feel less alone. To inform design, we first conducted three focus groups with CS students on themes of identity and belonging. Based on these findings, we designed a self-disclosing chatbot (“Mibi”) and deployed it in a pilot summer course (40 students) and a larger course (460 students) in the fall semester of 2023. Our work is the first real-world deployment of a chatbot in higher education for promoting student wellbeing, rather than assisting with practical course content. We highlight findings from this exploratory study, sharing how students engaged with Mibi, where it succeeded, where it has room to grow, and how that can inform future iterations of this promising new classroom companion for student mental health.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {9},
numpages = {7},
keywords = {CS1/CS2, Chatbot, Computer Science, Mental well-being, Qualitative, Self-Disclosure},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@article{10.1145/3654789,
author = {Borchardt, Mara and Roggi, In\'{e}s and Schapachnik, Fernando},
title = {Keys to a Comprehensive Computer Science at School Policy in Argentina},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {8},
issn = {0001-0782},
url = {https://doi.org/10.1145/3654789},
doi = {10.1145/3654789},
journal = {Commun. ACM},
month = aug,
pages = {83–85},
numpages = {3}
}

@inproceedings{10.1145/3689187.3709607,
author = {Clear, Tony and Cajander, \r{A}sa and Clear, Alison and McDermott, Roger and Daniels, Mats and Divitini, Monica and Forshaw, Matthew and Humble, Niklas and Kasinidou, Maria and Kleanthous, Styliani and Kultur, Can and Parvini, Ghazaleh and Polash, Mohammad and Zhu, Tingting},
title = {AI Integration in the IT Professional Workplace: A Scoping Review and Interview Study with Implications for Education and Professional Competencies},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709607},
doi = {10.1145/3689187.3709607},
abstract = {As Artificial Intelligence (AI) continues transforming workplaces globally, particularly within the Information Technology (IT) industry, understanding its impact on IT professionals and computing curricula is crucial. This research builds on joint work from two countries, addressing concerns about AI's increasing influence in IT sector workplaces and its implications for tertiary education. The study focuses on AI technologies such as generative AI (GenAI) and large language models (LLMs). It examines how they are perceived and adopted and their effects on workplace dynamics, task allocation, and human-system interaction.IT professionals, noted as early adopters of AI, offer valuable insights into the interplay between AI and work engagement, highlighting the significant competencies required for digital workplaces. This study employs a dual-method approach, combining a systematic and multi-vocal literature review and qualitative research methods. These included a thematic analysis of a set of 47 interviews conducted between March and May of 2024 with IT professionals in two countries (New Zealand and Sweden). The research aimed to understand the implications for computing students, education curricula, and the assessment of emerging professional competencies.The literature review found insufficient evidence addressing comprehensive AI practice methodologies, highlighting the need to both develop and regulate professional competencies for effective AI integration. Key interview findings revealed diverse levels of GenAI adoption, ranging from individual experimentation to institutional integration. Participants generally expressed positive attitudes toward the technology and were actively pursuing self-learning despite some concerns. The themes emerging from the interviews included AI's role in augmenting human tasks, privacy and security concerns, productivity enhancements, legal and ethical challenges, and the evolving need for new competencies in the workplace.The study underscores the critical role of competency frameworks in guiding professional development and ensuring preparedness for an AI-driven environment. Additionally, it highlights the need for educational institutions to adapt curricula to address these emerging demands effectively},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {34–67},
numpages = {34},
keywords = {artificial intelligence, computing competencies, computing curricula, generative ai, it profession, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@proceedings{10.1145/3709026,
title = {CSAI '24: Proceedings of the 2024 8th International Conference on Computer Science and Artificial Intelligence},
year = {2024},
isbn = {9798400718182},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3613904.3642024,
author = {Rajashekar, Niroop Channa and Shin, Yeo Eun and Pu, Yuan and Chung, Sunny and You, Kisung and Giuffre, Mauro and Chan, Colleen E and Saarinen, Theo and Hsiao, Allen and Sekhon, Jasjeet and Wong, Ambrose H and Evans, Leigh V and Kizilcec, Rene F. and Laine, Loren and Mccall, Terika and Shung, Dennis},
title = {Human-Algorithmic Interaction Using a Large Language Model-Augmented Artificial Intelligence Clinical Decision Support System},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642024},
doi = {10.1145/3613904.3642024},
abstract = {Integration of artificial intelligence (AI) into clinical decision support systems (CDSS) poses a socio-technological challenge that is impacted by usability, trust, and human-computer interaction (HCI). AI-CDSS interventions have shown limited benefit in clinical outcomes, which may be due to insufficient understanding of how health-care providers interact with AI systems. Large language models (LLMs) have the potential to enhance AI-CDSS, but haven’t been studied in either simulated or real-world clinical scenarios. We present findings from a randomized controlled trial deploying AI-CDSS for the management of upper gastrointestinal bleeding (UGIB) with and without an LLM interface within realistic clinical simulations for physician and medical student participants. We find evidence that LLM augmentation improves ease-of-use, that LLM-generated responses with citations improve trust, and HCI varies based on clinical expertise. Qualitative themes from interviews suggest the perception of LLM-augmented AI-CDSS as a team-member used to confirm initial clinical intuitions and help evaluate borderline decisions.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {442},
numpages = {20},
keywords = {Artificial Intelligence, Clinical Decision Support Systems, Electronic Health Record, Health-Clinical, Machine Learning, Medical: Nursing Homes/Hospitals, Qualitative Methods, Quantitative Methods, Workflows},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3631802.3631829,
author = {Ten\'{o}rio, Kamilla and Romeike, Ralf},
title = {AI Competencies for non-computer science students in undergraduate education: Towards a competency framework},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631829},
doi = {10.1145/3631802.3631829},
abstract = {Artificial Intelligence (AI) has been increasingly applied in various societal areas such as medicine, education, and science. For example, through the generation of more accurate medical diagnoses to support patients’ treatment, more content personalization to provide adaptive learning for students and more accurate predictions for future climate changes. Consequently, there is an increasing demand for professionals from different fields with AI competencies. These future professionals need preparation during their undergraduate education to deal with the remarkable AI breakthroughs in their domains and to understand, use, and help with the responsible development of these technologies. However, to address AI to non-computer science students in undergraduate education, it is necessary to thoroughly investigate the core AI competencies essential to these students acquire in order to prepare them effectively. Based on this, the objective of the research is to develop a framework with core AI competencies that can be adopted in future work to inform AI education for this target audience. Therefore, towards the AI competency framework for non-computer science students in undergraduate education, as an initial part of the process, we conducted semi-structured interviews with professionals working in the intersection of AI and other domains. The objective of the interviews was to qualitatively investigate the AI competencies considered suitable for incorporation into the undergraduate education curricula of non-computer science students from these professionals’ points of view. In this work, we present the results of these interviews and the list of core AI competencies for non-computer science students in undergraduate education according to these professionals. In summary, this list encompasses different perspectives, varying from basic AI competencies related to AI definition, history, and capabilities to more complex theoretical knowledge and practical skills regarding data and machine learning. The list also includes responsible AI competencies, covering AI’s social, ethical, and legal aspects.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {6},
numpages = {12},
keywords = {AI education, competency-based education, interviews, undergraduate education},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@article{10.5555/3665653.3665656,
author = {Attarwala, Abbas},
title = {Rethinking Linear Algebra for Computer Science: Applying Vygotsky's Theory of Learning},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {10},
issn = {1937-4771},
abstract = {This paper explores the application of Vygotsky's educational theories within the teaching of applied linear algebra for computer science students. The key point of this pedagogical study is a case study on principal component analysis (PCA), illustrated through noisy image compression, which serves as a representative example of the comprehensive teaching methodology applied throughout the course. This case study highlights the integration of key linear algebra concepts---eigenvectors, eigenvalues, covariance matrices, dot products, and change of basis matrices---demonstrating their application in a tangible real-world scenario. Employing MATLAB as a mediational tool, the teaching approach is scaffolded in accordance with Vygotsky's theory of learning, which progressively builds upon students' existing knowledge. The significance of aligning teaching practices with Vygotsky's theories lies in their proven ability to enhance conceptual understanding and student engagement, ultimately creating a deeper learning experience.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {23–32},
numpages = {10}
}

@inproceedings{10.1145/3649217.3653554,
author = {Liu, Suqing and Yu, Zezhu and Huang, Feiran and Bulbulia, Yousef and Bergen, Andreas and Liut, Michael},
title = {Can Small Language Models With Retrieval-Augmented Generation Replace Large Language Models When Learning Computer Science?},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653554},
doi = {10.1145/3649217.3653554},
abstract = {Leveraging Large Language Models (LLMs) for personalized learning and support is becoming a promising tool in computing education. AI Assistants can help students with programming, problem-solving, converse with them to clarify course content, explain error messages to help with debugging, and much more. However, using cloud-based LLMs poses risks around data security, privacy, but also control of the overarching system.To address these concerns, we created a locally-stored Small Language Model (SLM) that leverages different Retrieval-Augmented Generation (RAG) methods to support computing students' learning. We compare one SLM (neural-chat-7b-v3 - fine-tuned version of Mistral-7B-v0.1) against two popular LLMs (gpt-3.5-turbo and gpt-4-32k) to see the viability for computing educators to use in their course(s).We use conversations from a CS1 course (N = 1,260), providing students with an AI Assistant (using gpt-3.5-turbo) to help them learn content and support problem-solving while completing their Python programming assignment. In total, we had 269 students use the AI Assistant, with a total of 1,988 questions asked. Using this real conversational data, we re-ran student questions using our novel SLM (neural-chat-7b-v3 testing nine different RAG methods) and gpt-4-32k, then compared those results against the original gpt-3.5-turbo responses. Our findings indicate that using an SLM with RAG can perform similarly, if not better, than LLMs. This shows that it is possible for computing educators to use SLMs (with RAG) in their course(s) as a tool for scalable learning, supporting content understanding and problem-solving needs, while employing their own policies on data privacy and security.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {388–393},
numpages = {6},
keywords = {computing education, conversational agent, cs1, intelligence concentration, intelligent teaching assistant, intelligent tutoring system, large language models, locally deployable ai, personalized ai agent, retrieval augmented generation, small language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3581783.3612838,
author = {Li, Ruizhe and Guo, Jiahao and Li, Mingxi and Wu, Zhengqian and Liang, Chao},
title = {A Hierarchical Deep Video Understanding Method with Shot-Based Instance Search and Large Language Model},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612838},
doi = {10.1145/3581783.3612838},
abstract = {Deep video understanding (DVU) is often considered a challenge due to the aim of interpreting a video with storyline, which is designed to solve two levels of problems: predicting the human interaction in scene-level and identifying the relationship between two entities in movie-level. Based on our understanding of the movie characteristics and analysis of DVU tasks, in this paper, we propose a four-stage method to solve the task, which includes video structuring, shot based instance search, interaction &amp; relation prediction and shot-scene summary &amp; Question Answering (QA) with ChatGPT. In these four stages, shot based instance search allows accurate identification and tracking of characters at an appropriate video granularity. Using ChatGPT in QA, on the one hand, can narrow the answer space, on the other hand, with the help of the powerful text understanding ability, ChatGPT can help us answer the questions by giving background knowledge. We rank first in movie-level group 2 and scene-level group 1, second in movie-level group 1 and scene-level group 2 in ACM MM 2023 Grand Challenge.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {9425–9429},
numpages = {5},
keywords = {instance search, multi-modal feature, vedio understanding},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3587102.3588773,
author = {Denny, Paul and Becker, Brett A. and Leinonen, Juho and Prather, James},
title = {Chat Overflow: Artificially Intelligent Models for Computing Education - renAIssance or apocAIypse?},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588773},
doi = {10.1145/3587102.3588773},
abstract = {Recent breakthroughs in deep learning have led to the emergence of generative AI models that exhibit extraordinary performance at producing human-like outputs. Using only simple input prompts, it is possible to generate novel text, images, video, music, and source code, as well as tackle tasks such as answering questions and translating and summarising text.However, the potential for these models to impact computing education practice is only just beginning to be explored. For example, novices learning to code can now use free tools that automatically suggest solutions to programming exercises and assignments; yet these tools were not designed with novices in mind and little to nothing is known about how they will impact learning. Furthermore, much attention has focused on the immediate challenges these models present, such as academic integrity concerns. It seems that even in the AI-era a pending apocalypse sells better than a promising renaissance.Generative AI will likely play an increasing role in people's lives in the reasonably foreseeable future. Model performance seems set to continue accelerating while novel uses and new possibilities multiply. Given this, we should devote just as much effort to identifying and exploiting new opportunities as we do to identifying and mitigating challenges.In this talk, we begin by discussing several concrete and research-backed opportunities for computing educators. Many of these have already shown great promise in positively impacting current practice. We then discuss more short- to medium-term possibilities in areas such as student recruitment, and curricular changes. Finally - against our better judgement - we speculate over the longer-term, including rethinking the very fundamentals of the practice of teaching introductory and advanced computing courses. In these discussions we suggest potential research questions and directions. Although making remotely accurate predictions in such a fast-changing landscape is foolhardy, we believe that now is the time to explore and embrace opportunities to help make positive change in as many computing classrooms as possible.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {3–4},
numpages = {2},
keywords = {ai, artificial intelligence, chatgpt, computer programming, computer science education, computing education, copilot, deep learning, generative ai, large language models, llm, machine learning},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3578245.3584352,
author = {Bondi, Andr\'{e} Benjamin and Xiao, Lu},
title = {Early Progress on Enhancing Existing Software Engineering Courses to Cultivate Performance Awareness},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3584352},
doi = {10.1145/3578245.3584352},
abstract = {Software engineering and computer science courses are frequently focused on particular areas in a way that neglects such cross-cutting quality attributes as performance, reliability, and security. We will describe the progress we have made in developing enhancements to some of our existing software engineering courses to draw attention and even lay the foundations of an awareness of performance considerations in the software development life cycle. In doing so, we wish to make performance considerations integral to the software engineering mindset while avoiding the need to remove current material from our existing courses. This work is part of an NSF-funded project for undergraduate curriculum development.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {345–349},
numpages = {5},
keywords = {performance engineering, software engineering curriculum development},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3672608.3707909,
author = {Zambach, Sine},
title = {AI-Enhanced Learning: Comparing Outcomes in Introductory and Advanced Programming Courses},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707909},
doi = {10.1145/3672608.3707909},
abstract = {Generative AI chatbots have recently transformed education, necessitating new teaching methods for this paradigm. This study compares the impact of generative AI on introductory and advanced programming courses in fall 2023. Advanced students showed better outcomes, while the performance of introductory students remained unchanged or declined. This highlights the need for tailored AI integration strategies based on students' skill levels.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {104–105},
numpages = {2},
keywords = {teaching, higher education, chatbots, generative AI},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3670653.3677507,
author = {Kubullek, Ann-Kathrin and Kuma\c{c}, Nadire and Dogang\"{u}n, Ayseg\"{u}l},
title = {Understanding the Adoption of ChatGPT in Higher Education: A Comparative Study with Insights from STEM and Business Students},
year = {2024},
isbn = {9798400709982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670653.3677507},
doi = {10.1145/3670653.3677507},
abstract = {Since ChatGPT’s introduction, generative artificial intelligence (AI) has significantly influenced the media, technological innovation, and educational discourse. Its increasing importance, especially in academia, necessitates a detailed examination of the impact of AI on higher education, particularly on how it changes teaching and learning processes. This study therefore looks at the factors affecting students’ attitudes towards AI technologies in the university setting, with a particular focus on the differences between business and STEM programmes. Using a mixed methods approach, the study combines surveys and interviews to collect data on students’ perceptions, attitudes and experiences with generative AI technology in academia. The data collected is analysed both quantitatively and qualitatively to reveal significant trends and insights into the adoption and use of generative AI tools in the university environment. The main objective of the study is to shed light on the determinants that determine the varying degrees of AI adoption in different academic disciplines. The findings have the potential to inform the implementation of educational technology and assist in the development of strategies for the effective integration of generative AI tools to meet the different needs and preferences of students in a range of academic contexts.},
booktitle = {Proceedings of Mensch Und Computer 2024},
pages = {684–689},
numpages = {6},
keywords = {ChatGPT, STEM degree programs, academic disciplines, acceptance of AI, business degree programs, generative AI adoption, higher education, students},
location = {Karlsruhe, Germany},
series = {MuC '24}
}

@proceedings{10.1145/3704814,
title = {CSAE '24: Proceedings of the 8th International Conference on Computer Science and Application Engineering},
year = {2024},
isbn = {9798400718090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3626253.3633433,
author = {Liu, Rongxin and Zenke, Carter and Lloyd, Doug and Malan, David J.},
title = {Teaching with AI (GPT)},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633433},
doi = {10.1145/3626253.3633433},
abstract = {Teaching computer science at scale can be challenging. From our experience in CS50, Harvard University's introductory course, we've seen firsthand the impactful role that generative artificial intelligence can play in education. Recognizing its potential and stakes, we integrated OpenAI's GPT into our own teaching methodology. The goal was to emulate a 1:1 teacher-to-student ratio, incorporating "pedagogical guardrails" to maintain instructional integrity. The result was a personalized, AI-powered bot in the form of a friendly rubber duck aimed at delivering instructional responses and troubleshooting without giving outright solutions. We plan to share our journey and offer insights into responsibly harnessing AI in educational settings. Participants will gain hands-on experience working with GPT through OpenAI's APIs, understanding and crafting prompts, answering questions using embedding-based search, and finally, building their own AI chatbot. Ultimately, we'll not only share lessons learned from our own approach but also equip educators hands-on with the knowledge and tools with which they, too, can implement these technologies in their unique teaching environments.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1902},
numpages = {1},
keywords = {ai, artificial intelligence, chatgpt, ethics, generative ai, gpt, programming, prompt, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3594739.3610695,
author = {Sun, Yuqian and Li, Xingyu and Peng, Jun and Gao, Ze},
title = {Inspire creativity with ORIBA: Transform Artists' Original Characters into Chatbots through Large Language Model},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3610695},
doi = {10.1145/3594739.3610695},
abstract = {This research delves into the intersection of illustration art and artificial intelligence (AI), focusing on how illustrators engage with AI agents that embody their original characters (OCs). We introduce ’ORIBA’, a customizable AI chatbot that enables illustrators to converse with their OCs. This approach allows artists to not only receive responses from their OCs but also to observe their inner monologues and behavior. Despite the existing tension between artists and AI, our study explores innovative collaboration methods that are inspiring to illustrators. By examining the impact of AI on the creative process and the boundaries of authorship, we aim to enhance human-AI interactions in creative fields, with potential applications extending beyond illustration to interactive storytelling and more.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing &amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {78–82},
numpages = {5},
keywords = {creative support, drawing assistants, humanAI collaboration, interactive AI literacy, interactive language models},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3674213.3674214,
author = {Lyu, Minzhao and Wang, Yifan and Sivaraman, Vijay},
title = {Measuring GenAI Usage Patterns in a University Campus via Network Traffic Analysis},
year = {2024},
isbn = {9798400709852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674213.3674214},
doi = {10.1145/3674213.3674214},
abstract = {Generative AI platforms backed by large-language models (LLMs) are taking the world by storm. Starting with ChatGPT launched a mere 18 months ago that can generate amazingly human-like text responses to prompts, there are now platforms that can generate code (GitHub Copilot), images (Dall-E), and even video clips (Sora). In this fast evolving world of GenAI, there is huge interest in the community in tracking the usage patterns of these platforms, as well as performance in terms of responsiveness and network load. Our paper is the first attempt to track usage of emerging GenAI platforms via real-time analysis of network traffic. This can be useful to enterprises seeking to know which GenAI services their employees use most; to Communications Service Providers wanting to know the network loads imposed; and to financial investors needing a pulse on market trends. We begin by explaining the network anatomy of ChatGPT prompt/response interactions in detail, and extend it to six other GenAI platforms supporting text, code, and image generation. We then develop a measurement method to identify and quantify GenAI interactions via real-time analysis of network traffic. We deploy our monitoring system in a University campus over a 5-month period, and reveal interesting insights such as GenAI usage distribution across days of the week and deviations during assessment periods; variation in prompt-to-response-size ratios across the various GenAI platforms; and differences in response times arising from model versions.},
booktitle = {Proceedings of the Asian Internet Engineering Conference 2024},
pages = {1–9},
numpages = {9},
keywords = {Generative AI platform, network traffic analysis},
location = {Sydney, NSW, Australia},
series = {AINTEC '24}
}

@inproceedings{10.1145/3647444.3647910,
author = {Rawat, Swati and Mittal, Sumit and Nehra, Deepa and Sharma, Chandani and Kamboj, Dalip},
title = {Exploring the Potential of ChatGPT to improve experiential learning in Education},
year = {2024},
isbn = {9798400709418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3647444.3647910},
doi = {10.1145/3647444.3647910},
abstract = {Artificial Intelligence (AI) is revolutionizing the field of education by offering new possibilities for personalized and experiential learning along with data-driven insights. The advancement in AI to Generative Artificial Intelligence (GAI) has made the tables turn notably in the field of education. Generative AI application tool ChatGPT is emerging as a game changer offering personalized learning experiences by analyzing huge amounts of student data, generating study materials and pacing to individual needs. Intelligent educational tools powered by AI provide personalized guidance and feedback, adapting to curriculum to address knowledge gaps. GAI also automates the grading process, providing instant feedback and relieving teachers for qualitative assessments. This research paper offers a thorough examination of the potential uses, advantages, difficulties, and moral issues related to implementing ChatGPT in educational contexts. The authors closely analyze how ChatGPT can improve educational experiences, assist personalized learning, and encourage student- teacher interaction, while exploring the drawbacks of using generative AI models in education, such as concerns about bias, data privacy, and over-reliance on technology. This research article intends to offer educators &amp; academicians useful insights into the usage of ChatGPT in the educational field through a critical analysis of the existing literature and real- world experiences.},
booktitle = {Proceedings of the 5th International Conference on Information Management &amp; Machine Intelligence},
articleno = {83},
numpages = {8},
keywords = {ChatGPT, Generative Artificial Intelligence (GAI), Natural Language Processing, OpenAI, Teaching &amp; Learning, Education},
location = {Jaipur, India},
series = {ICIMMI '23}
}

@inproceedings{10.1145/3689218.3689222,
author = {Zhao, Jinxiong and Ma, Zhicheng and Zhao, Hong and Zhang, Xun and Liu, Qichuan and Peng, Xinjie and Zhang, Gefei},
title = {Power Large Language Model Exploration: Activation, Measurement and Enhancement for Operations and Maintenance Knowledge: Activation, Measurement and Enhancement for Power O&amp;M Knowledge},
year = {2024},
isbn = {9798400718250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689218.3689222},
doi = {10.1145/3689218.3689222},
abstract = {With the rapid advancement of Large Language Models, their applications are gradually transitioning from general to specific domains. However, the application of LLM in the electric power domain is still in its early stages, and few studies have explored power LLM. Currently, there are two main challenges against power LLMs: (1) determining how to measure the real power knowledge capacity of LLMs to facilitate targeted enhancement of specific knowledge. (2) identifying practical enhancement methods to facilitate efficient and feasible power LLM applications in real-world scenarios. In this paper, we ask three insightful questions that address the power knowledge capacity of LLMs and then draw inspiration from Reflexion and CoT to design an Activation, Measurement and Enhancement framework (AME) for power operations and maintenance (O&amp;M) knowledge. Specifically, we ask three “HOW” questions based on the activation, measurement, and enhancement of power O&amp;M knowledge. We introduce a Reflexion Module to discover the knowledge capacity of LLM and a Knowledge Graph Module to provide external knowledge of LLM in our proposed AME. Experiments on the real-world dataset provide strong evidence when we answer the above three insightful questions.},
booktitle = {Proceedings of the 2024 6th International Conference on Pattern Recognition and Intelligent Systems},
pages = {1–7},
numpages = {7},
keywords = {Power Large Language Model, Power Operations and Maintenance, Practical Knowledge Graph, Reflexion},
location = {Hong Kong, Hong Kong},
series = {PRIS '24}
}

@proceedings{10.1145/3644815,
title = {CAIN '24: Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The goal of the CAIN Conference Series is to bring together researchers and practitioners in software engineering, data science, and artificial intelligence (AI) as part of a growing community that is targeting the challenges of Software Engineering for AI-enabled systems.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3636555.3636846,
author = {Phung, Tung and P\u{a}durean, Victor-Alexandru and Singh, Anjali and Brooks, Christopher and Cambronero, Jos\'{e} and Gulwani, Sumit and Singla, Adish and Soares, Gustavo},
title = {Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636846},
doi = {10.1145/3636555.3636846},
abstract = {Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4HINTS-GPT3.5VAL. As a first step, our technique leverages GPT-4 as a “tutor” model to generate hints – it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a “student” model to further validate the hint quality – it performs an automatic quality validation by simulating the potential utility of providing this feedback. We show the efficacy of our technique via extensive evaluation using three real-world datasets of Python programs covering a variety of concepts ranging from basic algorithms to regular expressions and data analysis using pandas library.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {12–23},
numpages = {12},
keywords = {ChatGPT, Feedback Generation, GPT4, Generative AI, Programming Education},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3641822.3641877,
author = {Melegati, Jorge and Nascimento, Nicolas and Chanin, Rafael and Sales, Afonso and Wiese, Igor},
title = {Exploring potential implications of intelligent tools for human aspects of software engineering},
year = {2024},
isbn = {9798400705335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641822.3641877},
doi = {10.1145/3641822.3641877},
abstract = {Background. The emergence of tools based on artificial intelligence (AI) to support software development suggests an overhaul on how developers program and interact among themselves. This disruption might bring challenges regarding human and social aspects of the software development process. Objective. This paper is a first exploration of the consequences of AI-based tools for software development teams and their members. Method. We conducted a social science fiction exercise, a sort of thought experiment, narrating two fictional stories about a futuristic software company employing AI-based tools. Then, we evaluated the plausibility of one of the scenarios through a qualitative experiment with 38 students to observe their perception regarding the use of AI-based tools. Results. The stories suggest potential challenges related to the adoption of these tools: a change on how developers perceive themselves, a clash between quantitative and qualitative worker contribution assessment, and the training of future developers to handle the imminent changes on their profession. In the qualitative experiment, we collected evidence supporting negative feelings, such as lack of trust and control and fear of being replaced. We also identified other attitudes and perceptions of developers, such as positive feelings towards AI-based tools. Conclusion. We identified several aspects that might influence the adoption of AI-based tools and their implications for individuals involved. They should be further investigated and represent a challenge for the research on human aspects of software engineering. We also demonstrated the use of social science fiction to explore novel research problems.},
booktitle = {Proceedings of the 2024 IEEE/ACM 17th International Conference on Cooperative and Human Aspects of Software Engineering},
pages = {121–132},
numpages = {12},
keywords = {AI for SE, social science fiction, human aspects of software development, qualitative experiment},
location = {Lisbon, Portugal},
series = {CHASE '24}
}

@proceedings{10.1145/3663529,
title = {FSE 2024: Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to FSE 2024, the ACM International Conference on the Foundations of Software Engineering (FSE) 2024. The conference now has a shorter name! FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {Porto de Galinhas, Brazil}
}

@article{10.1145/3659624,
author = {Cuadra, Andrea and Breuch, Justine and Estrada, Samantha and Ihim, David and Hung, Isabelle and Askaryar, Derek and Hassanien, Marwan and Fessele, Kristen L. and Landay, James A.},
title = {Digital Forms for All: A Holistic Multimodal Large Language Model Agent for Health Data Entry},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659624},
doi = {10.1145/3659624},
abstract = {Digital forms help us access services and opportunities, but they are not equally accessible to everyone, such as older adults or those with sensory impairments. Large language models (LLMs) and multimodal interfaces offer a unique opportunity to increase form accessibility. Informed by prior literature and needfinding, we built a holistic multimodal LLM agent for health data entry. We describe the process of designing and building our system, and the results of a study with older adults (N =10). All participants, regardless of age or disability status, were able to complete a standard 47-question form independently using our system---one blind participant said it was "a prayer answered." Our video analysis revealed how different modalities provided alternative interaction paths in complementary ways (e.g., the buttons helped resolve transcription errors and speech helped provide more options when the pre-canned answer choices were insufficient). We highlight key design guidelines, such as designing systems that dynamically adapt to individual needs.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {72},
numpages = {39},
keywords = {Accessibility, Artifact or System, Field Study, Health - Clinical, Input Techniques, Interaction Design, Mobile Devices: Phones/Tablets, Older Adults, Prototyping/Implementation, Qualitative Methods, Text/Speech/Language, User Experience Design}
}

@proceedings{10.1145/3702138,
title = {ASSE '24: Proceeding of the 2024 5th Asia Service Sciences and Software Engineering Conference},
year = {2024},
isbn = {9798400717543},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3705618,
title = {DECS '24: Proceedings of the 2024 International Conference on Digital Economy and Computer Science},
year = {2024},
isbn = {9798400711855},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3686852.3686881,
author = {Alhazeem, Ensaf and Alsobeh, Anas and Al-Ahmad, Bilal},
title = {Enhancing Software Engineering Education through AI: An Empirical Study of Tree-Based Machine Learning for Defect Prediction},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3686881},
doi = {10.1145/3686852.3686881},
abstract = {In the rapidly evolving field of information technology education,integrating artificial intelligence (AI) and machine learning (ML) techniques presents opportunities and challenges. This empirical study investigates the application of tree-based ML techniques, specifically Random Forest (RF) and Extreme Gradient Boosting (XGBoost), for software defect prediction in the context of IT education. We analyze nine publicly available NASA software defect datasets to compare the performance of these algorithms across multiple metrics, including accuracy, precision, recall, and ROC area. Our findings demonstrate that XGBoost consistently outperforms Random Forest, achieving near-perfect accuracy across most datasets. The paper explores how these advanced techniques can be responsibly integrated into software engineering (SE) education to enhance student learning while addressing concerns about potential over-reliance on AI tools. We discuss the implications of our results for IT education, emphasizing the need to balance the use of sophisticated AI technologies with the development of fundamental software assurance skills. Furthermore, we examine the role of AI in augmenting SE education, particularly in areas such as software assurance explanations, feature identification, and data augmentation.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {153–156},
numpages = {4},
keywords = {AI in Education, Machine Learning (ML), Random Forest, Software Defect Prediction, Software Engineering, XGBoost},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@proceedings{10.1145/3597503,
title = {ICSE '24: Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3674805,
title = {ESEM '24: Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Barcelona, Spain}
}

@inproceedings{10.1145/3702163.3702409,
author = {Zylowski, Thorsten and Sautchuk-Patricio, Nathalia and Hettmann, Wladimir and Anderer, Katharina and Fischer, Karl and W\"{o}lfel, Matthias and Henning, Peter},
title = {User Study on the Trustworthiness, Usability and Explainability of Intent-based and Large Language Model-based Career Planning Conversational Agents},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702409},
doi = {10.1145/3702163.3702409},
abstract = {Choosing a career and educational path is a challenging decision for young people. Career planning conversational agents (CAs) can assist by identifying suitable occupations and educational paths. Trustworthiness is an important dimension for the acceptance of a career planning CA and is influenced by several factors. We conducted a user study with n=114 participants across three schools in Germany to explore the trustworthiness of different career planning CAs. We examined the correlation between trustworthiness and perceived competence, autonomy, and social relatedness from self-determination theory (SDT), as well as the explainability of interactions and several usability dimensions of the assistants. These dimensions included the ability to guide the conversation, onboarding quality, error tolerance, and information relevance. We tested three different variants of the career planning assistant: a form-based assistant, an intent-based CA, and a large language model (LLM)-based CA. The results showed that the LLM-based CA was on average significantly more trustworthy and was perceived as more explainable than the intent-based CA. Key trust factors included conversation flexibility, chatbot credibility, intent recognition, and maintenance of a secure conversation. Additionally, perceived autonomy was crucial for trust across all types of assistants and perceived relatedness for the two CAs. Our findings highlight key areas essential for developing trustworthy CAs.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {46–53},
numpages = {8},
keywords = {Career Planning Conversational Agents, Explainable Artificial Intelligence, Self-Determination Theory, Trustworthy Artificial Intelligence, Usability},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3626253.3635543,
author = {Glynn, Colin and Hed, Emily and Pexa, Abbigail and Pohlmann, Tyler and Rahal, Imad and Hesse, Robert},
title = {CAET: Code Analysis and Education Tutor},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635543},
doi = {10.1145/3626253.3635543},
abstract = {The introduction of OpenAI's ChatGPT in 2022 kickstarted the release of Generative Artificial Intelligence (GAI) applications to the public domain. Such chat interfaces are based on large language models (LLMs) and possess a vast array of abilities spanning conversation, the writing and debugging of code, the writing of papers, and the creation of images, music, and songs. With students now having access to a myriad of GAI tools, academia has been permanently altered.Our proposed system, named Code Analysis and Education Tutor (CAET), integrates GAI into early Computer Science education by providing students with an ethical alternative to existing GAI tools. CAET is designed to assist students with programming tasks in a manner tailored to their individual needs without jeopardizing the integrity of their learning. A point of uniqueness from existing works is CAET's ability to display or hide generated code based on its pertinence to the problem at hand. After subjecting multiple GAI models to common programming errors and queries, we settled on OpenAI's GPT-3.5 Turbo model due to its comprehensive capabilities and cost-effectiveness. Overall, CAET underscored the model's conversational dynamics and provided insights for creating a more personalized learning experience for students in an introductory computer science course.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1656–1657},
numpages = {2},
keywords = {computer science education, generative artificial intelligence, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@proceedings{10.1145/3643787,
title = {NLBSE '24: Proceedings of the Third ACM/IEEE International Workshop on NL-based Software Engineering},
year = {2024},
isbn = {9798400705762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Natural Language Processing (NLP) refers to the automated elaboration of human language, including both algorithms that take human-produced text as input and algorithms that produce natural-looking text as outputs. NLP is widely used to optimize many aspects of the software development process. Since natural language artifacts are used and reused during the software development life-cycle, the availability of natural language-based approaches and tools has led to improvements in the software process and product efficiency. Indeed, NLP approaches (including LLMs) have proven useful for retrieving key information from a wide range of structured or unstructured sources. Besides, they show promise for the automated generation of fine-grained source code documentation to ease program comprehension and maintenance activities. Literature has shown that many software engineering (SE)-related tasks can benefit from adopting NLP techniques. The main objective of the Natural Language-Based Software Engineering Workshop (NLBSE) is to bring together researchers and industrial practitioners from the NLP and SE communities to share experiences. Our workshop aims to provide directions for future research and encourage the development of increasingly effective NLP solutions for addressing SE-specific challenges.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3663533,
title = {PROMISE 2024: Proceedings of the 20th International Conference on Predictive Models and Data Analytics in Software Engineering},
year = {2024},
isbn = {9798400706752},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our pleasure to welcome you to the 20th ACM International Conference on Predictive Models and Data Analytics in Software Engineering (PROMISE 2024), to be held in presence on July 16th, 2024, co-located with the International Conference on the Foundations of Software Engineering (FSE 2024).},
location = {Porto de Galinhas, Brazil}
}

@proceedings{10.1145/3650105,
title = {FORGE '24: Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {FORGE aims to bring researchers, practitioners, and educators from the AI and Software Engineering community to solve the new challenges we meet in the era of foundation models.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3722237.3722329,
author = {Zhang, Xiaoyan},
title = {Analysis of a Comparative Study between Traditional Online Automatic Writing Evaluation Systems and Large Language Model-Assisted Online Revision for Second Language Writing},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722329},
doi = {10.1145/3722237.3722329},
abstract = {This paper compares two online revision modes of L2 writing: the traditional online automatic writing evaluation system (represented by Pigaiwang in this study) and Large Language Models (LLMs). Through experimental data, it is found that there are significant differences between the two modes in assisting learners' writing levels. The results show that compared with the traditional automatic online writing correction system, LLMs-assisted online writing correction and feedback can improve learners' writing levels and stimulate their enthusiasm for writing revision.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {528–532},
numpages = {5},
keywords = {large language models, online automatic writing evaluation system, personalized feedback},
location = {
},
series = {ICAIE '24}
}

@article{10.1145/3572905,
author = {Kotti, Zoe and Galanopoulou, Rafaila and Spinellis, Diomidis},
title = {Machine Learning for Software Engineering: A Tertiary Study},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3572905},
doi = {10.1145/3572905},
abstract = {Machine learning (ML) techniques increase the effectiveness of software engineering (SE) lifecycle activities. We systematically collected, quality-assessed, summarized, and categorized 83 reviews in ML for SE published between 2009 and 2022, covering 6,117 primary studies. The SE areas most tackled with ML are software quality and testing, while human-centered areas appear more challenging for ML. We propose a number of ML for SE research challenges and actions, including conducting further empirical validation and industrial studies on ML, reconsidering deficient SE methods, documenting and automating data collection and pipeline processes, reexamining how industrial practitioners distribute their proprietary data, and implementing incremental ML approaches.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {256},
numpages = {39},
keywords = {systematic literature review, software engineering, machine learning, Tertiary study}
}

@inproceedings{10.1145/3691422.3691471,
author = {Ma, Xiaoqian},
title = {The potential legal risks of artificial intelligence},
year = {2025},
isbn = {9798400717260},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691422.3691471},
doi = {10.1145/3691422.3691471},
abstract = {ChatGPT, as a typical application of generative artificial intelligence, means that human society is moving towards the "era of high knowledge revolution". From the perspective of functionalism, generative artificial intelligence will certainly have an important impact on the reshaping of legal society at the level of "instrument" and "Tao". However, while generative AI is deeply embedded in Chinese society, it also impacts personal information security on a large scale, challenges national security, causes intellectual property rights disputes, and academic ethics irregularities. Therefore, it is necessary for the national regulatory authorities to exercise careful governance, formulate accurate and fair market access guidelines and mechanism accountability systems, improve the public's awareness of risk prevention, and gradually improve the generative AI governance system.},
booktitle = {Proceedings of the 2024 15th International Conference on E-Business, Management and Economics},
pages = {366–370},
numpages = {5},
keywords = {ChatGPT, Generative artificial intelligence, Legal regulation, Risk management},
location = {
},
series = {ICEME '24}
}

@inproceedings{10.1145/3641237.3691673,
author = {Trim, Michelle and Butler, Erin and Suttcliffe, Christina},
title = {Seeing How the Sausage is Made: Data Storytelling as Means and Method in a Computer Science Writing Course},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691673},
doi = {10.1145/3641237.3691673},
abstract = {As data corpus-driven tools and technologies increasingly push users to passively search for an answer, rather than search to understand, we believe that technical and computing disciplinary writing courses have a duty to teach the process of responsible data storytelling. While students can grasp that generative AI makes mistakes, hallucinates, and perpetuates bias, they can need help understanding the antecedent causes of those difficulties. All algorithmically driven decision-making or recommending software have in common a large data set that has been labeled, either by users or by the system itself. The origins of that data and the reasonable applications/deductions and conclusions possible for any given dataset have everything to do with why some tools help and some tools perpetuate harms. By starting at the very beginning and asking students to make sense of data, students can more easily see how purpose and audience impact analysis of any given collection of data. Once those opportunities for rhetorical choice making are known, students become ready to understand the connection between data and complex A.I. systems and some of the ways that bias and other kinds of harm can result if designers are not careful. Combining instruction in a technical coding environment with basic data literacy lessons such as ‘the seven data stories,’ [14] we developed and delivered a three-week writing unit designed around responsible data exploration and storytelling. In this experience report, we provide the assignment we used, and the scaffolded activities we employed to bring students through the process, remarking on what worked well and what we want to improve. We provide attendees with a link to an R-based notebook with a walk-through lesson on data exploration commands, and the rubric used to assess students’ texts, notebooks with code and commentary and results, all existing in a referential context. We provide the survey results of students’ perception of learning from this activity. Early findings demonstrate that students internalized lessons about the non-objective nature of data analysis and of specific responsible data storytelling practices required by anyone seeking to ethically represent answers within and limitations of any dataset.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {217–222},
numpages = {6},
keywords = {Data Visualization, Data storytelling, Pedagogy, Technical communication},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@proceedings{10.1145/3643663,
title = {RoSE '24: Proceedings of the 2024 ACM/IEEE 6th International Workshop on Robotics Software Engineering},
year = {2024},
isbn = {9798400705663},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Software engineering is a crucial enabler for successful deployment of robotic applications. However, much of the research that is advancing the state of the art in robotics software engineering is dispersed across numerous conferences that are either primarily attended by robotics researchers and practitioners (e.g., ICRA, IROS, SIMPAR) or attended mostly by software engineering researchers and practitioners (e.g., ICSE, FSE, MODELS). At robotics conferences, software engineering lacks visibility and vice versa.RoSE brings together researchers and practitioners from both domains at a prominent conference to foster crossfertilization between the two domains. Through a combination of presentations, papers, and discussions, RoSE helps researchers within the budding field of robotics software engineering to learn more about the challenges faced by robotics practitioners that (i) require further research from the software engineering community or (ii) are already solved but solutions have not yet been widely adopted by practitioners.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3641555.3705175,
author = {Bouamor, Houda and Gongora-Svartzman, Gabriela and Heimann, Larry and Huang, Shihong},
title = {Evaluating GenAI's Effectiveness for Students with Varied Programming Backgrounds in a Software Development Course},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705175},
doi = {10.1145/3641555.3705175},
abstract = {Using Generative AI (GenAI) tools in education presents both opportunities and challenges to the traditional teaching methods and students' learning experience and outcomes, particularly in technical and programming courses. This experience report evaluates the impact of GenAI tools, specifically ChatGPT and GitHub CoPilot, in leveling the playing field for Information Systems students with varying technical backgrounds in an application design and development course. By integrating these tools into course labs and projects, this study aimed to determine whether they improve the success rates of less technically prepared and struggling students. Data were collected from five sessions of a semester-long course across two campuses, involving 162 students with five parallel sessions across two continents. The analysis of student performance metrics and surveys revealed that GenAI tools significantly helped students complete programming tasks. However, those who were less technically prepared and relied heavily on AI assistance struggled with more complex, transformative tasks, such as closed-book exams. These findings suggest that while GenAI tools can help close gaps in temporary programming skills, they are less effective - and may even exacerbate disparities - in fostering long-term deeper learning and developing transformative knowledge and critical thinking.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1395–1396},
numpages = {2},
keywords = {generative AI, impact of Genai tools in education, information systems education (IS), leveling playfield, programming background, student performance evaluation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3613904.3642482,
author = {Ma, Zilin and Mei, Yiyang and Long, Yinru and Su, Zhaoyuan and Gajos, Krzysztof Z.},
title = {Evaluating the Experience of LGBTQ+ People Using Large Language Model Based Chatbots for Mental Health Support},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642482},
doi = {10.1145/3613904.3642482},
abstract = {LGBTQ+ individuals are increasingly turning to chatbots powered by large language models (LLMs) to meet their mental health needs. However, little research has explored whether these chatbots can adequately and safely provide tailored support for this demographic. We interviewed 18 LGBTQ+ and 13 non-LGBTQ+ participants about their experiences with LLM-based chatbots for mental health needs. LGBTQ+ participants relied on these chatbots for mental health support, likely due to an absence of support in real life. Notably, while LLMs offer prompt support, they frequently fall short in grasping the nuances of LGBTQ-specific challenges. Although fine-tuning LLMs to address LGBTQ+ needs can be a step in the right direction, it isn’t the panacea. The deeper issue is entrenched in societal discrimination. Consequently, we call on future researchers and designers to look beyond mere technical refinements and advocate for holistic strategies that confront and counteract the societal biases burdening the LGBTQ+ community.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {872},
numpages = {15},
keywords = {Chatbot, Gender, Identity, LGBTQIA+ Health, Large Language Models, Mental health, Socio-technical AI, Stigma},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@proceedings{10.5555/3606010,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@inproceedings{10.1145/3702386.3702388,
author = {Xu, Xiao},
title = {Comparative Analysis of GPT-4o and GPT-4.0 in Business Ethics Role-Play Simulations},
year = {2025},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702386.3702388},
doi = {10.1145/3702386.3702388},
abstract = {The rapid advancement of artificial intelligence (AI) technologies has opened new frontiers in educational methodologies, particularly in enhancing interactive learning environments. This paper examines the integration of two AI-driven models, ChatGPT-4.0 and its advanced iteration, GPT-4o, into the teaching of complex subjects such as climate risk management within higher education. Utilizing role-play simulations, a method proven to effectively deepen understanding and engagement, we explore how these models enhance traditional educational approaches by providing dynamic, real-time interactions that mimic real-world decision-making processes. Our comparative analysis focuses on the performance of these models in terms of response time, emotional intelligence, and quality of engagement. The findings indicate that GPT-4o, with its quicker response times and enhanced emotional recognition capabilities, significantly improves learner engagement and the effectiveness of role-play simulations. This study highlights the potential of AI to not only complement but substantially enrich pedagogical practices, offering educators valuable insights into selecting appropriate AI tools for their instructional needs. Through this exploration, we advocate for a hybrid educational model that synergistically combines the strengths of both traditional and AI-enhanced learning, proposing a future where education is more adaptive, personalized, and aligned with the evolving demands of the digital age.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
pages = {57–63},
numpages = {7},
keywords = {ChatGPT, Large Language Model, Role-play, generative AI},
location = {
},
series = {ICAITE '24}
}

@inproceedings{10.1145/3669754.3669806,
author = {Batac, Carlo Antonio and Baroja, Marc Jethro and Caballero, Don John Daniel and Coloma, Louis Gabriel and Tan, Lind Matthew and Ebardo, Ryan},
title = {Do Human Beliefs and Traits Influence the Adoption of ChatGPT among Programming Students?},
year = {2024},
isbn = {9798400717055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669754.3669806},
doi = {10.1145/3669754.3669806},
abstract = {Abstract: Increased use of generative artificial intelligence or AI in various academic activities such as programming is a significant milestone in technology diffusion in learning. To bring AI closer to how programmers think, behave, and interact, it is imperative for research to establish a clear connection between various human factors that lead to its adoption. Using a model based on the Theory of Reasoned Action, we positioned human traits of academic stress, risk propensity, neuroticism, and computer self-efficacy as factors that positively influence attitudes toward the use of AI in programming among university students. We further posited that attitude and social norms lead to the behavioral intention to use AI in programming. We used PLS-SEM to analyze responses from 131 programming students who use ChatGPT to accomplish learning tasks. We found that both academic stress and computer self-efficacy influence attitudes toward using AI in programming. While attitude positively influences the behavioral intention to use ChatGPT, we found that risk propensity and neuroticism do not affect attitude, and social norms do not influence behavioral intention. We discuss the implications of our investigation to the industry and the academe.},
booktitle = {Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence},
pages = {339–344},
numpages = {6},
keywords = {ChatGPT, PLS-SEM, education, generative AI, programming},
location = {Bali Island, Indonesia},
series = {ICCAI '24}
}

@inproceedings{10.1145/3706599.3720032,
author = {Ko, Eunhye Grace and Nanayakkara, Shaini and Huff, Earl W},
title = {"We need to avail ourselves of [GenAI] to enhance knowledge distribution": Empowering Older Adults through GenAI Literacy},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720032},
doi = {10.1145/3706599.3720032},
abstract = {As generative AI (GenAI) becomes increasingly ubiquitous, it is crucial to equip users, particularly vulnerable populations like older adults (65+), with the knowledge to understand its benefits and potential risks. Older adults often face greater reservations about adopting emerging technologies and require tailored literacy support. Using a mixed methods approach, this study examines strategies for delivering GenAI literacy to older adults through a chatbot named Litti, evaluating its impact on their Al literacy (knowledge, safety, and ethical use). The quantitative data showed a trend toward improved AI literacy, though the results were not statistically significant. However, the qualitative interviews revealed diverse levels of familiarity with generative AI, along with a strong desire to learn more. Qualitative findings also show that although Litti provided a positive learning experience, it did not significantly enhance participants’ trust or sense of safety regarding GenAI. This exploratory case study highlights the challenges and opportunities in designing AI literacy education for the rapidly growing older adult population.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {34},
numpages = {7},
keywords = {generative artificial intelligence, AI literacy, older adults},
location = {
},
series = {CHI EA '25}
}

@proceedings{10.1145/3643658,
title = {GAS '24: Proceedings of the ACM/IEEE 8th International Workshop on Games and Software Engineering},
year = {2024},
isbn = {9798400705618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {GAS is an annual workshop that brings together researchers and practitioners who are keen on exchanging ideas and progressing techniques in the intersection of game engineering and software engineering.GAS explores how advanced technologies can be used to benefit the engineering of gameful systems, including entertainment games, serious games, and gamified applications. The goal of this one-day workshop is to bring together the greater community of software engineers and game engineers to encourage discussions from an interdisciplinary perspective, on the emerging research challenges around game and software engineering.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3706598.3713176,
author = {Biehl, Austin and Perez, Daniela and Ingle, Jessica and Ames, Morgan G.},
title = {Prestige and Prejudice: How the Interplay of Recruiting Work and Algorithms Reinforces Social Inequities in Software Engineering},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713176},
doi = {10.1145/3706598.3713176},
abstract = {The technology industry has long sought to diversify its workforce. This study evaluates one avenue that works against these efforts: the interaction between recruiter work practices and algorithmic recruiting tools. Through interviews and cognitive walkthroughs with fifteen recruiters, we find that recruiters—often under deadlines and quotas—develop shortcuts (e.g., computer science degrees and employment at prestigious companies) for identifying “typical” software engineers (one of the most sought-after roles in the field) who have a higher chance of being successfully hired. We then analyze the results of searches like those recruiters often conduct in one commonly-used recruitment tool. We see recruiters’ shortcuts also reflected in these results: candidates with computer science degrees, living in expensive tech hubs, and employed at high-profile tech companies are disproportionately favored. Given the lack of demographic diversity in software engineering at prestigious companies, we assert that algorithmically preferencing these factors helps to reify existing stereotypes, impacting the diversity of candidates who are ultimately hired.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {344},
numpages = {16},
keywords = {Technology companies, hiring, recruiting automation, algorithmic decision systems, social class},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3649217.3653584,
author = {Vadaparty, Annapurna and Zingaro, Daniel and Smith IV, David H. and Padala, Mounika and Alvarado, Christine and Gorson Benario, Jamie and Porter, Leo},
title = {CS1-LLM: Integrating LLMs into CS1 Instruction},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653584},
doi = {10.1145/3649217.3653584},
abstract = {The recent, widespread availability of Large Language Models (LLMs) like ChatGPT and GitHub Copilot may impact introductory programming courses (CS1) both in terms of what should be taught and how to teach it. Indeed, recent research has shown that LLMs are capable of solving the majority of the assignments and exams we previously used in CS1. In addition, professional software engineers are often using these tools, raising the question of whether we should be training our students in their use as well. This experience report describes a CS1 course at a large research-intensive university that fully embraces the use of LLMs from the beginning of the course. To incorporate the LLMs, the course was intentionally altered to reduce emphasis on syntax and writing code from scratch. Instead, the course now emphasizes skills needed to successfully produce software with an LLM. This includes explaining code, testing code, and decomposing large problems into small functions that are solvable by an LLM. In addition to frequent, formative assessments of these skills, students were given three large, open-ended projects in three separate domains (data science, image processing, and game design) that allowed them to showcase their creativity in topics of their choosing. In an end-of-term survey, students reported that they appreciated learning with the assistance of the LLM and that they interacted with the LLM in a variety of ways when writing code. We provide lessons learned for instructors who may wish to incorporate LLMs into their course.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {297–303},
numpages = {7},
keywords = {copilot, cs1, generative ai, introductory programming, llm},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3686852.3687071,
author = {G\"{o}hler, Volker and Yadav, Garima},
title = {Analyzing Concept Maps in Computer Science Education: An Unsupervised Learning Approach with Graph Neural Networks},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3687071},
doi = {10.1145/3686852.3687071},
abstract = {It is of paramount importance for teachers to comprehend the knowledge acquired by their students in order to validate their teaching methods and ensure accuracy. Concept maps (CMs), which graphically represent knowledge, are effective tools for visualising learning and tracking progress. However, interpreting CMs is challenging due to their complexity and the multitude of interconnected concepts. To address this challenge, we propose an unsupervised learning methodology leveraging graph neural networks—specifically Node2Vec and GraphSAGE—to analyze CMs autonomously. Our preliminary results demonstrate the potential of the method to automatically identify clusters and relationships within CMs, thereby reducing manual analysis effort. Using this approach, we identified ten clusters of subgraphs within our dataset consisting of the eight most recent CMs. In summary, this paper introduces a novel application of unsupervised learning in the analysis of concept maps, aiming to enhance educational practices by providing scalable and insightful methods for understanding student knowledge representations.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {56–61},
numpages = {6},
keywords = {Concept Maps, Graph Neural Networks, GraphSAGE, Node2Vec, Unsupervised Learning},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3632620.3671094,
author = {Chen, Melissa and Li, Yinmiao and O'Rourke, Eleanor},
title = {Understanding the Reasoning Behind Students' Self-Assessments of Ability in Introductory Computer Science Courses},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671094},
doi = {10.1145/3632620.3671094},
abstract = {Although enrollments in introductory computing courses are rising, many students still struggle to learn programming. Previous research has found that students’ perceptions of the programming process may be one factor that contributes to this problem. Students often assess their own programming abilities overly harshly when experiencing low-level programming moments that are considered normal and expected parts of learning to program. For example, many students think they are doing poorly if they need to stop coding to plan. Research has also shown that students who self-assess negatively in these moments tend to have lower self-efficacy, defined as one’s belief in their ability to achieve a particular outcome. In turn, students with lower self-efficacy tend not to persist in their computing studies. While the criteria that students use to assess their ability have been studied extensively, we have a limited understanding of the origins of these criteria and students’ reasons for adopting them. To address this gap, we conducted a total of 36 interviews with seven introductory computer science students throughout an academic quarter. In each interview, we asked students to think aloud and explain their reasoning while filling out a self-assessment survey. Through a qualitative analysis of the data, we identified the most common reasons students gave for negatively assessing their performance, including having high expectations for their abilities and feeling like they cannot overcome a struggle. We also identified common reasons why students do not negatively assess their ability in these moments, including believing an experience is “normal” or feeling like they can learn from or overcome a struggle. These findings contribute valuable new knowledge about the underpinnings of students’ self-assessments of ability, and suggest that interventions that explicitly emphasize best practices and normalize struggles in the programming learning process are needed to increase student self-efficacy and persistence in computing.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {1–13},
numpages = {13},
keywords = {CS0, CS1, self-assessments},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3573051.3596200,
author = {Han, Jieun and Yoo, Haneul and Kim, Yoonsu and Myung, Junho and Kim, Minsun and Lim, Hyunseung and Kim, Juho and Lee, Tak Yeon and Hong, Hwajung and Ahn, So-Yeon and Oh, Alice},
title = {RECIPE: How to Integrate ChatGPT into EFL Writing Education},
year = {2023},
isbn = {9798400700255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573051.3596200},
doi = {10.1145/3573051.3596200},
abstract = {The integration of generative AI in the field of education is actively being explored. In particular, ChatGPT has garnered significant interest, offering an opportunity to examine its effectiveness in English as a foreign language (EFL) education. To address this need, we present a novel learning platform called RECIPE (Revising an Essay with ChatGPT on an Interactive Platform for EFL learners). Our platform features two types of prompts that facilitate conversations between ChatGPT and students: (1) a hidden prompt for ChatGPT to take an EFL teacher role and (2) an open prompt for students to initiate a dialogue with a self-written summary of what they have learned. We deployed this platform for 213 undergraduate and graduate students enrolled in EFL writing courses and seven instructors. For this study, we collect students' interaction data from RECIPE, including students' perceptions and usage of the platform, and user scenarios are examined with the data. We also conduct a focus group interview with six students and an individual interview with one EFL instructor to explore design opportunities for leveraging generative AI models in the field of EFL education.},
booktitle = {Proceedings of the Tenth ACM Conference on Learning @ Scale},
pages = {416–420},
numpages = {5},
keywords = {ChatGPT, EFL learners, essay writing, generative AI, learner-ChatGPT interaction},
location = {Copenhagen, Denmark},
series = {L@S '23}
}

@proceedings{10.1145/3639478,
title = {ICSE-Companion '24: Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICSE is the leading and, by far, the largest conference in Software Engineering, attracting researchers, practitioners, and students worldwide. ICSE2024 is co-located with 11 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3631802.3631823,
author = {Rahimi, Ebrahim and Passier, Harrie and Stuurman, Sylvia},
title = {Exploring Factors Influencing the Satisfaction of Adult Software Engineering Students with Teamwork in Distance Education},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631823},
doi = {10.1145/3631802.3631823},
abstract = {Using team-based software development assignments is a prevalent instructional strategy in software engineering (SE) education. Students utilize these development assignments as a vehicle to (co-)learn SE concepts, practice problem-solving, and develop soft skills. The satisfaction of SE students with their teamwork experience in team-based assignments is an important educational and motivational factor that contributes to increased participation in future team-based projects. There is a scarcity of research on the satisfaction of SE students with teamwork in distance and online education specifically for adult learners. This study reports on a case study conducted to identify factors influencing the satisfaction of adult SE graduate students with their teamwork experiences in team-based software design and development assignments at the Open University of the Netherlands (OUNL), a distance education university for adult learners. The self-reflection reports of 29 adult SE students, aged between 25 and 35 years, documented and self-evaluated their experiences with a team-based design and development assignment within a master SE course were analyzed using an open thematic analysis approach. The analysis of the reports revealed six categories of factors that influenced the adult online SE students’ satisfaction with their team-working experience, namely, the attitude of team members, communication, collaboration, team characteristics, tooling and technology, and learning. Additionally, we conducted a literature review to identify any similarities and differences between the results obtained from the literature and those derived from our study on this topic.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {15},
numpages = {11},
keywords = {Adult learners, Distance and online education, Human aspects of software engineering, Software engineering education, Teamework satisfaction},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@proceedings{10.1145/3540250,
title = {ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of all members of the organizing committee, we are delighted to welcome everyone to the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2022. The event continues the long, distinguished ESEC/FSE tradition of presenting the most innovative research, and facilitating interactions between scientists and engineers who are passionate about advancing the theory and practice of software engineering.},
location = {Singapore, Singapore}
}

@article{10.5555/3606431.3606434,
author = {Dey, Pradip Peter and Amin, Mohammad and Sinha, Bhaskar Raj},
title = {Iterative Efforts for Improving Learning Experience in Software Engineering},
year = {2023},
issue_date = {April 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {38},
number = {7},
issn = {1937-4771},
abstract = {In a project-based learning environment, students and teachers jointly made iterative efforts for improving learning experience in software engineering through all major tasks including requirements analysis, design, implementation, and testing. The iterative efforts were implemented in a prototype-based evolutionary process by performing reviews jointly by students and teachers after each major task, and assessing student performance based on their participation in task-related activities. End of course evaluation data, collected in a standard anonymous process, indicated improvements in student learning experience and teaching effectiveness attributable to the iterative efforts. The major advantages of the iterative efforts were engaging students in the review process, and eliminating or reducing plagiarism-based academic dishonesty by emphasizing participation-based grading. One of the major challenges for teachers was making extra efforts for participation-based grading, rather than using automated grading of multiple choice exams and quizzes. In addition, extra efforts were needed to complete three iterations for sizable software engineering projects in a timely manner in order get benefits of iterative efforts in project-based learning environments. There are opportunities for future research in this area for creating a set of revealing software engineering projects of appropriate sizes and explaining their potential benefits in teaching learning environments.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {27–35},
numpages = {9}
}

@inproceedings{10.1145/3649409.3691093,
author = {Garcia, Yuan and Ngo, Jenny and Lin, Florence Rui},
title = {Code Metrics, Rules of Thumb for Introductory CS},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691093},
doi = {10.1145/3649409.3691093},
abstract = {In response to the recent surge in easily accessible generative AI, Harvey Mudd College has integrated AI-assisted coding into the introductory Computer Science course. In this context, a question arises: How do we measure the quality of students' code when AI-generated code is present?Allowing generative AI to write coding assignments comes with the expectation of improved efficiency and accuracy. While generative AI is a useful tool, it merely supplements fundamental computing skills. This technological step towards being fully syntax-free allows for emphasis on the already important skill of developing problem-solving and critical thinking skills in more abstract contexts. In past years, metrics were designed to measure quantitative aspects of code, but these metrics alone are insufficient when evaluating how code written with the assistance of AI will perform in broader applications. When students submit code written with the assistance of generative AI, they are still expected to meet standards given by past metrics, such as Correctness and Complexity. To establish foundational computing skills, students will also be held to new standards and evaluated by new metrics such as Individuality and Ambition.While the model does give objective measures of the metrics, due to the fast-evolving nature of programming, predefined rules-of-thumb for these metrics are not provided. As users of our system, we recognize that evaluating the measurements will require our judgment, which will evolve over time. This work offers the foundation for that evolution.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {314–315},
numpages = {2},
keywords = {computing as a general education requirement, computing as a shared literacy, generative AI, undergraduate-universal computing},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@proceedings{10.1145/3661167,
title = {EASE '24: Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Salerno, Italy}
}

@inproceedings{10.1145/3657604.3664640,
author = {Morales-Chan, Miguel and Amado-Salvatierra, Hector R. and Hernandez-Rizzardini, Rocael},
title = {AI-Driven Content Creation: Revolutionizing Educational Materials},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664640},
doi = {10.1145/3657604.3664640},
abstract = {The integration of Artificial Intelligence (AI) into the field of education is an unprecedented trend with the potential to revolutionize teaching approaches and significantly improve the overall learning experience. This workshop offers an opportunity for a strategic implementation of generative artificial intelligence in higher education, demonstrating its capacity to substantially enhance the creation and customization of digital educational materials. It is essential for educators to possess the capacity to utilize generative artificial intelligence tools, specifically when it comes to developing prompts for Large Language Models (LLMs). In addition to fostering a more interactive learning environment, these LLMs are driving the transition to educational systems that are more autonomous and adaptable. An in-depth exploration of the pragmatic and ethical aspects of generative AI implementation is undertaken to equip educators with the necessary knowledge and skills to employ AI in a responsible manner, thereby cultivating an engaging and equitable learning environment. This workshop was prepared based on successful previous experiences in different conferences and meetings in Spain, Portugal, Germany, M\'{e}xico, Guatemala, Colombia, and USA.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {556–558},
numpages = {3},
keywords = {LLMs, artificial intelligence, generative AI, prompt engineering},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.5555/3637036.3637057,
author = {Amin, Mohammad and Sinha, Bhaskar and Dey, Pradip Peter and Any, Laith Al},
title = {Strategies for Introducing Mathematical Concepts to Computer Science Students},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {4},
issn = {1937-4771},
abstract = {In Computer Science, mathematics plays a fundamental role in developing analytical thinking and algorithmic reasoning skills. However, students often struggle to grasp the significance and applicability of mathematics in this field. They need a clear understanding of math concepts and skills for the application of mathematical constructs in computational problem-solving. One of the challenges for math teachers is to help poorly prepared students at introductory levels. This requires an innovative approach that bridges the gap between theory and application. Computational problem-solving requires more than just memorizing formulas. Examples of real- world problem-solving applications of formulas can be integrated into computational solution techniques to develop students' intuitive concepts of math at introductory levels. Proper integration of motivational activities with practice-based math instructions in multiple classes requires careful planning and execution.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {110–111},
numpages = {2}
}

@proceedings{10.1145/3617570,
title = {QP4SE 2023: Proceedings of the 2nd International Workshop on Quantum Programming for Software Engineering},
year = {2023},
isbn = {9798400703768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the second edition of the workshop on Quantum Programming for Software Engineering (QP4SE) to be held virtually, December 4th, 2023, co-located with ESEC/FSE 2023, San Francisco.},
location = {San Francisco, CA, USA}
}

@inproceedings{10.1145/3701625.3701681,
author = {Menolli, Andr\'{e} and Strik, Bruno and Rodrigues, Luiz},
title = {Teaching Refactoring to Improve Code Quality with ChatGPT: An Experience Report in Undergraduate Lessons},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701681},
doi = {10.1145/3701625.3701681},
abstract = {Refactoring presents a complex computational challenge, and its learning is intricate, requiring a solid foundation in computational thinking, programming and object-oriented concepts. Moreover, making students realize the importance and benefits of refactoring is also challenging. To address this complexity, we introduce a refactoring teaching method based on Generative Artificial Intelligence (GAI), incorporating single-loop and double-loop learning principles, focusing on fostering deeper and critical learning. We used ChatGPT, a GAI-based tool, and conducted an eight-week mixed-methods study involving 23 computer science undergraduate students. The study involved applying four distinct projects extracted from GitHub, where participants were tasked with identifying code smells and performing the necessary refactoring to improve code quality. The primary focus was on identifying both the positive and negative aspects of the method, as well as delineating the computational thinking characteristics developed during the process. The results indicate that the use of ChatGPT facilitated the learning of refactoring, contributing to the development of numerous computational thinking skills, especially problem formulation, decomposition, and abstraction. Thus, this paper contributes a GAI-based teaching method along with evidence on how it helps students develop refactoring skills.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {563–574},
numpages = {12},
keywords = {Generative Artificial Intelligence, ChatGPT, Refactory, Higher Education, Teaching, Computational Thinking},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3603555.3603565,
author = {Leiser, Florian and Eckhardt, Sven and Knaeble, Merlin and Maedche, Alexander and Schwabe, Gerhard and Sunyaev, Ali},
title = {From ChatGPT to FactGPT: A Participatory Design Study to Mitigate the Effects of Large Language Model Hallucinations on Users},
year = {2023},
isbn = {9798400707711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603555.3603565},
doi = {10.1145/3603555.3603565},
abstract = {Large language models (LLMs) like ChatGPT recently gained interest across all walks of life with their human-like quality in textual responses. Despite their success in research, healthcare, or education, LLMs frequently include incorrect information, called hallucinations, in their responses. These hallucinations could influence users to trust fake news or change their general beliefs. Therefore, we investigate mitigation strategies desired by users to enable identification of LLM hallucinations. To achieve this goal, we conduct a participatory design study where everyday users design interface features which are then assessed for their feasibility by machine learning (ML) experts. We find that many of the desired features are well-perceived by ML experts but are also considered as difficult to implement. Finally, we provide a list of desired features that should serve as a basis for mitigating the effect of LLM hallucinations on users.},
booktitle = {Proceedings of Mensch Und Computer 2023},
pages = {81–90},
numpages = {10},
keywords = {Artificial Hallucinations, ChatGPT, Disney Method, Large Language Models, Participatory Design},
location = {Rapperswil, Switzerland},
series = {MuC '23}
}

@inproceedings{10.1145/3649217.3653569,
author = {Chen, Yige and Pereira Nunes, Bernardo},
title = {Stubents: Videos Created by and for Students, Active Learning Resources in Large and Diverse Computer Science Classrooms},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653569},
doi = {10.1145/3649217.3653569},
abstract = {This paper introduces an innovative pedagogical strategy, employing active learning methodology through peer-reviewed video assignments in a large and diverse computer science (CS) classroom. This approach encourages CS students to create and utilize multimodal learning resources from "Stubents" platform and to build a more inclusive, effective, and sustainable learning environment. Our study assessed how this instructional activity promotes the mastery of students' different levels of cognitive learning skills, and identified the soft skills developed. Textual analysis indicated the high quality of peer review feedback. Website traffic analysis confirmed that student-created knowledge-sharing platforms can be consistently used as a valid learning resource. The proposed active learning pedagogical framework holds the potential for broad adaptability across other CS disciplines and levels, aiming to improve CS students' general literacy, academic competence, and employability.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {653–659},
numpages = {7},
keywords = {active learning methodologies, large classroom, peer-reviewed video-assignment, pluralize teaching},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@proceedings{10.1145/3613372,
title = {SBES '23: Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Campo Grande, Brazil}
}

@proceedings{10.1145/3593663,
title = {ECSEE '23: Proceedings of the 5th European Conference on Software Engineering Education},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seeon/Bavaria, Germany}
}

@article{10.1145/3687028,
author = {Bashardoust, Amirsiavosh and Feuerriegel, Stefan and Shrestha, Yash Raj},
title = {Comparing the Willingness to Share for Human-generated vs. AI-generated Fake News},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687028},
doi = {10.1145/3687028},
abstract = {Generative artificial intelligence (AI) presents large risks for society when it is used to create fake news. A crucial factor for fake news to go viral on social media is that users share such content. Here, we aim to shed light on the sharing behavior of users across human-generated vs. AI-generated fake news. Specifically, we study: (1) What is the perceived veracity of human-generated fake news vs. AI-generated fake news? (2) What is the user's willingness to share human-generated fake news vs. AI-generated fake news on social media? (3) What socio-economic characteristics let users fall for AI-generated fake news? To this end, we conducted a pre-registered, online experiment with N= 988 subjects and 20 fake news from the COVID-19 pandemic generated by GPT-4 vs. humans. Our findings show that AI-generated fake news is perceived as less accurate than human-generated fake news, but both tend to be shared equally. Further, several socio-economic factors explain who falls for AI-generated fake news.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {489},
numpages = {21},
keywords = {fake news, generative ai, large language model, misinformation, online experiment, survey}
}

@inproceedings{10.1145/3658271.3658320,
author = {Saldanha, Mateus Santos and Digiampietri, Luciano Antonio},
title = {ChatGPT and Bard Performance on the POSCOMP Exam},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658271.3658320},
doi = {10.1145/3658271.3658320},
abstract = {Context: Modern chatbots, built upon advanced language models, have achieved remarkable proficiency in answering questions across diverse fields. Problem: Understanding the capabilities and limitations of these chatbots is a significant challenge, particularly as they are integrated into different information systems, including those in education. Solution: In this study, we conducted a quantitative assessment of the ability of two prominent chatbots, ChatGPT and Bard, to solve POSCOMP questions. IS Theory: The IS theory used in this work is Information processing theory. Method: We used a total of 271 questions from the last five POSCOMP exams that did not rely on graphic content as our materials. We presented these questions to the two chatbots in two formats: directly as they appeared in the exam and with additional context. In the latter case, the chatbots were informed that they were answering a multiple-choice question from a computing exam. Summary of Results: On average, chatbots outperformed human exam-takers by more than 20%. Interestingly, both chatbots performed better, in average, without additional context added to the prompt. They exhibited similar performance levels, with a slight advantage observed for ChatGPT. Contributions and Impact in the IS area: The primary contribution to the field involves the exploration of the capabilities and limitations of chatbots in addressing computing-related questions. This information is valuable for individuals developing Information Systems with the assistance of such chatbots or those relying on technologies built upon these capabilities.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {49},
numpages = {10},
keywords = {Bard, ChatBot, ChatGPT, Computer Science Examination, Large Language Model},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

@inproceedings{10.1145/3689217.3690614,
author = {Cong, Tianshuo and Ran, Delong and Liu, Zesen and He, Xinlei and Liu, Jinyuan and Gong, Yichen and Li, Qi and Wang, Anyu and Wang, Xiaoyun},
title = {Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging},
year = {2024},
isbn = {9798400712098},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689217.3690614},
doi = {10.1145/3689217.3690614},
abstract = {Model merging is a promising lightweight model empowerment technique that does not rely on expensive computing devices (e.g., GPUs) or require the collection of specific training data. Instead, it involves editing different upstream model parameters to absorb their downstream task capabilities. However, uncertified model merging can infringe upon the Intellectual Property (IP) rights of the original upstream models. In this paper, we conduct the first study on the robustness of IP protection methods under model merging scenarios. Specifically, we investigate two state-of-the-art IP protection techniques: Quantization Watermarking and Instructional Fingerprint, along with various advanced model merging technologies, such as Task Arithmetic, TIES-MERGING, and so on. Experimental results indicate that current Large Language Model (LLM) watermarking techniques cannot survive in the merged models, whereas model fingerprinting techniques can. Our research aims to highlight that model merging should be an indispensable consideration in the robustness assessment of model IP protection techniques, thereby promoting the healthy development of the open-source LLM community.},
booktitle = {Proceedings of the 1st ACM Workshop on Large AI Systems and Models with Privacy and Safety Analysis},
pages = {69–76},
numpages = {8},
keywords = {intellectual property, large language models, model merging},
location = {Salt Lake City, UT, USA},
series = {LAMPS '24}
}

@proceedings{10.1145/3651640,
title = {ESSE '23: Proceedings of the 4th European Symposium on Software Engineering},
year = {2023},
isbn = {9798400708817},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Napoli, Italy}
}

@inproceedings{10.1109/ASE56229.2023.00101,
author = {Chatterjee, Prantik and Kalita, Pankaj Kumar and Lahiri, Sumit and Muduli, Sujit Kumar and Singh, Vishal and Takhar, Gourav and Roy, Subhajit},
title = {An Integrated Program Analysis Framework for Graduate Courses in Programming Languages and Software Engineering},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00101},
doi = {10.1109/ASE56229.2023.00101},
abstract = {Program analysis, verification and testing are important topics in programming languages and software engineering. They aim to produce engineers who are not only capable of empirically evaluating but, also formally reasoning on the correctness of software systems. We propose a specialized framework, Chiron, designed to teach graduate-level courses on these topics. Chiron has a small code base for easy understanding, uses a unified intermediate representation across all its analysis modules, maintains a modular architecture for plugging in new algorithms and uses a "fun" programming language to provide a gamified experience. Currently, it packages a dataflow analysis engine for driving compiler optimizations, an abstract interpretation engine for verification, a symbolic execution engine, a fuzzer and an evolutionary test generator for program testing, and a spectrum based statistical bug localization module.Within Chiron, program analysis tasks are posed in an unconventional setting (as adventures of a turtle) to provide a gamified experience; the accompanying animations (showing the movements of the turtle) allow the student to understand the underlying concepts better, and the detailed logs allow the teaching assistants in their grading activities.Chiron has been used in two offerings of a graduate level course on program analysis, verification and testing. In response to our survey questionnaire, all the students unanimously held the opinion that Chiron was extremely helpful in aiding their learning, and recommended its use in similar courses.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {598–610},
numpages = {13},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3673805.3673828,
author = {S\"{o}derstr\"{o}m, Ulrik and Hedstr\"{o}m, Elsa and Lambertsson, Karl and Mejtoft, Thomas},
title = {ChatGPT in education: Teachers’ and Students’ views},
year = {2024},
isbn = {9798400718243},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673805.3673828},
doi = {10.1145/3673805.3673828},
abstract = {Since its launch just over two years ago, the conversational chatbot ChatGPT developed by OpenAI has become integrated into the studies of students within the Swedish educational system. This paper investigates both teachers’ perspectives and attitudes toward students using ChatGPT and the students’ view of their perceived learning. Insights were gathered through questionnaires (for both students and teachers) and a learning session for students, revealing concerns and enthusiasm regarding ChatGPT’s integration. Teachers express a lack of understanding on incorporating ChatGPT into education and perceive a lack of support from school leadership and the Swedish National Agency for Education. Identified scenarios suggest ChatGPT’s potential for understanding concepts, but resistance toward its use in examinations. The students have a statistically significant enhancement in confidence and understanding of magnetism concepts after engaging with ChatGPT. This research contributes to ongoing discussions about integrating AI tools in education, emphasizing benefits and addressing ethical concerns and learning outcomes.},
booktitle = {Proceedings of the European Conference on Cognitive Ergonomics 2024},
articleno = {32},
numpages = {10},
keywords = {ChatGPT, Education, Generative Artificial Intelligence, Higher education, Perceived Learning, Sweden, Upper Secondary School},
location = {Paris, France},
series = {ECCE '24}
}

@proceedings{10.1145/3641822,
title = {CHASE '24: Proceedings of the 2024 IEEE/ACM 17th International Conference on Cooperative and Human Aspects of Software Engineering},
year = {2024},
isbn = {9798400705335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {CHASE 2024 continues the tradition of a high-quality venue for research related to the cooperative and human aspects of software engineering. Researchers and practitioners have long recognized the need to investigate the cooperative and human aspects. However, their articles have been scattered across many conferences and communities. The CHASE conference provides academics and practitioners with a unified forum for discussing high-quality research studies, models, methods, and tools for human and cooperative aspects of software engineering.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3657604.3664663,
author = {Wang, Tianjia and Ramanujan, Ramaraja and Lu, Yi and Mao, Chenyu and Chen, Yan and Brown, Chris},
title = {DevCoach: Supporting Students in Learning the Software Development Life Cycle at Scale with Generative Agents},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664663},
doi = {10.1145/3657604.3664663},
abstract = {Supporting novice computer science students in learning the software development life cycle (SDLC) at scale is vital for ensuring the quality of future software systems. However, this presents unique challenges, including the need for effective interactive collaboration and access to diverse skill sets of members in the software development team. To address these problems, we present ''DevCoach'', an online system designed to support students learning the SDLC at scale by interacting with generative agents powered by large language models simulating members with different roles in a software development team. Our preliminary user study results reveal that DevCoach improves the experiences and outcomes for students, with regard to learning concepts in SDLC's ''Plan and Design'' and ''Develop'' phases. We aim to use our findings to enhance DevCoach to support the entire SDLC workflow by incorporating additional simulated roles and enabling students to choose their project topics. Future studies will be conducted in an online Software Engineering class at our institution, aiming to explore and inspire the development of intelligent systems that provide comprehensive SDLC learning experiences to students at scale.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {351–355},
numpages = {5},
keywords = {computer science education, generative ai, software development life cycle, software engineering},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3652620.3688336,
author = {Bucchiarone, Antonio and Panciera, Marco and Cicchetti, Antonio and Mana, Nadia and Castelluccio, Carlotta and Stott, Lee},
title = {PromptDeck: A No-Code Platform for Modular Prompt Engineering},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688336},
doi = {10.1145/3652620.3688336},
abstract = {This paper introduces a no-code platform for modular prompt engineering, designed to democratize access to generative AI for nondevelopers. By integrating advanced technologies such as Node.js, Express, MongoDB, and Azure OpenAI services, the platform provides a robust and flexible environment for creating and managing AI-driven tasks. The intuitive frontend, built with React and TypeScript, enables users with minimal coding expertise to design, execute, and evaluate complex AI workflows. A key feature of the platform is its extensible plugin system, which allows users to easily incorporate additional functionalities to meet their specific needs. This no-code approach empowers a broader audience to harness the power of generative AI, fostering innovation and enabling diverse applications across various fields. By lowering the technical barriers, the platform paves the way for widespread adoption of AI technologies, driving the future of AI-enhanced solutions.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {895–904},
numpages = {10},
keywords = {low-code development platforms, no-code, generative AI, prompt engineering, modularization},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@proceedings{10.1145/3627915,
title = {CSAE '23: Proceedings of the 7th International Conference on Computer Science and Application Engineering},
year = {2023},
isbn = {9798400700590},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, China}
}

@proceedings{10.1145/3579375,
title = {ACSW '23: Proceedings of the 2023 Australasian Computer Science Week},
year = {2023},
isbn = {9798400700057},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Melbourne, VIC, Australia}
}

@proceedings{10.1145/3698062,
title = {WSSE '24: Proceedings of the 2024 The 6th World Symposium on Software Engineering (WSSE)},
year = {2024},
isbn = {9798400717086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3631991,
title = {WSSE '23: Proceedings of the 2023 5th World Symposium on Software Engineering},
year = {2023},
isbn = {9798400708053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@inproceedings{10.1145/3702138.3702145,
author = {Blancaflor, Eric B. and Abaleta, Raphael M. and Achacoso, Luke Martin D.L. and Amper, Alden Christian C. and Ampiloquio, Pfrancis Isaiah R.},
title = {Emerging Threat: The Use of AI Voice Cloning Software and Services to Deceive Victims Through Phone Conversations and its Potential Effects on the Filipino Population},
year = {2025},
isbn = {9798400717543},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702138.3702145},
doi = {10.1145/3702138.3702145},
abstract = {Generative Artificial Intelligence (AI) tools have become increasingly advanced and accessible via the Internet. These advancements and upgraded accessibility of access have resulted in the usage of generative AI in phishing, which has increased the incidences&nbsp;of these attacks. The researchers explore AI voice phishing, or vishing, and its possible implications on the Filipino community by analyzing and reviewing existing literature on AI voice cloning and its application in vishing schemes. The review covers the definition of vishing and AI voice cloning, the methods malicious actors use to clone voices, the Philippines' cybersecurity posture and its current laws on AI vishing, real-life examples of AI vishing, how to protect against it, and the future of AI vishing, as well as the future direction of the study. The researchers ended the study by demanding and advocating additional research on AI detection and recognition, as well as the establishment and stronger implementation of developing legislation in the Philippines and other nations that prohibit the use of generative AI for illegal purposes.},
booktitle = {Proceeding of the 2024 5th Asia Service Sciences and Software Engineering Conference},
pages = {137–146},
numpages = {10},
keywords = {AI Vishing, AI Voice Cloning, Artificial Intelligence, Cybersecurity, Generative AI, Philippines, Voice Phishing},
location = {
},
series = {ASSE '24}
}

@proceedings{10.5555/3606013,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@article{10.5555/3637068.3637079,
author = {von Briesen, Elizabeth},
title = {Do We Need to Write? Researching Perceptions of Disciplinary Writing Importance and Skills in an Advanced Computer Science Course},
year = {2023},
issue_date = {November 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {5},
issn = {1937-4771},
abstract = {Our research explores perceptions related to writing in the computer science discipline. It is a common misconception that this skill is not important in the field, and we are motivated to dispel that notion and assist students in gaining experience and confidence in their disciplinary writing skills. To that end, we surveyed undergraduate students at the start and end of term in our Artificial Intelligence course, an advanced computer science elective. Students wrote two blogs-like items, one each for audiences with and without technical knowledge of the field, and also produced technical documentation related to two programming assignments. We found that on average, students agreed that writing in the discipline is important, and that they have some confidence in their writing abilities across audiences. While we did not find a statistically significant difference between perceptions at the start and end of the term, our overall results and open-ended feedback indicate that students find writing in the field to be important, and that there is strong interest in further curricular enhancements in this area.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {119–128},
numpages = {10}
}

@inproceedings{10.1145/3698204.3716446,
author = {Yang, Yuyu and Urgo, Kelsey and Arguello, Jaime and Capra, Robert},
title = {Search+Chat: Integrating Search and GenAI to Support Users with Learning-oriented Search Tasks},
year = {2025},
isbn = {9798400712906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698204.3716446},
doi = {10.1145/3698204.3716446},
abstract = {Generative AI (GenAI) technologies such as ChatGPT are changing the ways people interact with information. To illustrate, popular search engines (e.g., Google) have started integrating responses from GenAI tools with the traditional search results. In this paper, we explore the integration of GenAI technology with traditional search in the context of a learning-oriented task. We report on a between-subjects study (N = 40) in which participants completed a complex, learning-oriented search task. Participants were assigned to one of two conditions. In the SearchOnly condition, participants used a traditional web search system to gather information. In the Search+Chat condition, participants used an experimental system that combined a traditional web search component and an interactive GenAI-based chat component (Chat AI). The study investigated seven research questions. RQ1-RQ3 focused on differences between groups: (RQ1) post-task perceptions, (RQ2) search behaviors, and (RQ3) learning outcomes. To measure learning, participants completed a multiple-choice test before the search task, immediately after, and one week later (to measure retention). RQ4-RQ7 delved deeper into participants’ behaviors and experiences in the Search+Chat condition: (RQ4) motivations for (and gains from) engaging with the Chat AI; (RQ5) the phases during which participants engaged with the Chat AI; (RQ6) the types of queries issued to each component; and (RQ7) perceptions about the information returned by each component.},
booktitle = {Proceedings of the 2025 ACM SIGIR Conference on Human Information Interaction and Retrieval},
pages = {57–70},
numpages = {14},
keywords = {Generative AI, search-as-learning, search behavior, mixed-methods},
location = {
},
series = {CHIIR '25}
}

@inproceedings{10.1145/3652620.3687811,
author = {M. Mosthaf, My and Wasowski, Andrzej},
title = {From a Natural to a Formal Language with DSL Assistant},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687811},
doi = {10.1145/3652620.3687811},
abstract = {The development of domain-specific languages (DSLs) is a laborious and iterative process that seems to naturally lean to the use of generative artificial intelligence. We design and prototype DSL Assistant, a tool that integrates generative language models to support the development of DSLs. DSL Assistant uses OpenAI's assistant API with GPT-4o to generate DSL grammars and example instances. To reflect real-world use, DSL Assistant supports several different interaction modes for evolving a DSL design, and includes automatic error repair. Our experiments show that DSL Assistant helps users to create and modify DSLs. However the quality of the generated DSLs depends on the specific domain and the followed interaction patterns.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {541–549},
numpages = {9},
keywords = {domain-specific languages, generative AI, large language models},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inbook{10.1145/3724504.3724632,
author = {Lin, Yunjing},
title = {A Bibliometric Analysis of ChatGPT in the Field of Education: Global Trends and Research Hotspots},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724632},
abstract = {A total of 1,031 literatures concerning the use of ChatGPT in the field of education in Web of Science database from 2023 to 2024 were analyzed thoroughly in this study by combing the bibliometric method and VOSviewer software. Results showed that the USA, China, Australia, England and T\"{u}rkiye are major contributors in relevant researches. Universities in Hong Kong, China show particular remarkable contributions and have become core institutions in this field. Six hot themes are identified through a keyword co-occurrence analysis, including AI in education, ChatGPT in higher education, educational practices and innovation, assessment and curriculum development, generative AI and academic integrity, language learning and systematic reviews. Future studies are recommended to discuss from perspectives of ethics, legal and technology, emphasize on importance of privacy protection, prejudice recognition, copyright and compliance issues, and propose the technological improvement goals to improve accuracy and reliability of ChatGPT.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {776–781},
numpages = {6}
}

@inproceedings{10.1145/3613372.3614199,
author = {Font\~{a}o, Awdren and Matsubara, Edson and Mongelli, Henrique and Medeiros, Marcio and Louren\c{c}o, Carlos and Martins, Henrique and Cortez, Igor and Borges, Maria},
title = {Hyacinth macaw: a project-based learning program to develop talents in Software Engineering for Artificial Intelligence},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613372.3614199},
doi = {10.1145/3613372.3614199},
abstract = {Software Engineering for Artificial Intelligence (SE4A) uses SE principles to design and maintain AI systems, requiring analytical thinking for software complexity, while AI demands mathematical knowledge and algorithm adjustment. The IEEE Curriculum Guidelines for Undergraduate Degree Programs in Software Engineering states that extracurricular elements impact students’ preparation. This study focuses on the first module of a project-based learning talent development program involving undergraduate students, two expert professors (in AI and SE), and mentors from sponsoring companies. An exploratory case study with 39 students from four courses was conducted, challenging them to deliver an MVP in machine learning within 1.5 months. Results showed high agreement (87.5%) in applying learned skills to future projects, recognizing SE’s benefits (96.9%) in AI, and acknowledging the connection between SE and AI (78.1%). Participants applied relevant knowledge in ML performance, data analysis, and software architecture for AI. We share strategies used by students to enhance developer experience.},
booktitle = {Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
pages = {312–321},
numpages = {10},
location = {Campo Grande, Brazil},
series = {SBES '23}
}

@article{10.1145/3593007,
author = {Haigh, Thomas},
title = {Conjoined Twins: Artificial Intelligence and the Invention of Computer Science},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/3593007},
doi = {10.1145/3593007},
abstract = {How artificial intelligence and computer science grew up together.},
journal = {Commun. ACM},
month = may,
pages = {33–37},
numpages = {5}
}

@inproceedings{10.1145/3708557.3716337,
author = {Xing, Yunhao and Liu, Que and Wang, Jingwu and G\'{o}mez-Zar\'{a}, Diego},
title = {sMoRe: Spatial Mapping and Object Rendering Environment},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716337},
doi = {10.1145/3708557.3716337},
abstract = {In mixed reality (MR) environments, understanding space and creating virtual objects is crucial to providing an intuitive user experience. This paper introduces sMoRe (Spatial Mapping and Object Rendering Environment), an MR application that combines Generative AI (GenAI) to assist users in creating, placing, and managing virtual objects within physical spaces. sMoRe allows users to use voice or typed text commands to create and place virtual objects using GenAI while specifying spatial constraints. The system employs Large Language Models (LLMs) to interpret users’ commands, analyze the current scene, and identify optimal locations. Additionally, sMoRe integrates a text-to-3D generative model to dynamically create 3D objects based on users’ descriptions. Our user study demonstrates the effectiveness of sMoRe in enhancing user comprehension, interaction, and organization of the MR environment.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {115–119},
numpages = {5},
keywords = {Large Language Models, Generative AI, Space Manipulation},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3613904.3642332,
author = {Belghith, Yasmine and Mahdavi Goloujeh, Atefeh and Magerko, Brian and Long, Duri and Mcklin, Tom and Roberts, Jessica},
title = {Testing, Socializing, Exploring: Characterizing Middle Schoolers’ Approaches to and Conceptions of ChatGPT},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642332},
doi = {10.1145/3613904.3642332},
abstract = {As generative AI rapidly enters everyday life, educational interventions for teaching about AI need to cater to how young people, in particular middle schoolers who are at a critical age for reasoning skills and identity formation, conceptualize and interact with AI. We conducted nine focus groups with 24 middle school students to elicit their interests, conceptions of, and approaches to a popular generative AI tool, ChatGPT. We highlight a) personally and culturally-relevant topics to this population, b) three distinct approaches in students’ open-ended interactions with ChatGPT: AI testing-oriented, AI socializing-oriented, and content exploring-oriented, and 3) an improved understanding of youths’ conceptions and misconceptions of generative AI. While misconceptions highlight gaps in understanding what generative AI is and how it works, most learners show interest in learning about what AI is and what it can do. We discuss the implications of these conceptions for designing AI literacy interventions in museums.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {276},
numpages = {17},
keywords = {AI literacy, ChatGPT, Child-AI Interaction, Conceptions of AI, Conversational Agents (CAs), Generative AI, Informal Learning, Large Language Models (LLMs)},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3660650.3660673,
author = {Rajabi, Parsa and Kerslake, Chris},
title = {Can You Spot the AI? Incorporating GenAI into Technical Writing Assignments},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660673},
doi = {10.1145/3660650.3660673},
abstract = {In an effort to foster critical reflection on the usage of generative AI (genAI) during computer science writing assignments, this three-part assignment challenges students to predict whether their peers can detect which essays are generated using AI. Implemented as part of a third-year professional responsibility and technical writing course for N=200 students during Spring 2024, students individually generated two short persuasive essays, one using genAI and the other without. They then combined the two essays into a single document and submitted it for peer-review. Additionally, they formulated a guess on whether their peers would be able to detect which essay was generated as well as a rationale for their guess. Following the peer-review process, students reflected on their own experience trying to detect which essays were generated as well as the outcome of their guess about their peers abilities as well. Feedback indicates its effectiveness in engaging students in their understanding of the potentials and limitations of genAI. Recommended prerequisites include a clear course AI-usage policy and a brief overview of genAI prompt engineering.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {23},
numpages = {2},
keywords = {AI Literacy, AI in Education, AI-usage Policy, ChatGPT, Generative AI, Technical Writing},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3491102.3517582,
author = {Wu, Tongshuang and Terry, Michael and Cai, Carrie Jun},
title = {AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517582},
doi = {10.1145/3491102.3517582},
abstract = {Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by “unit-testing” sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {385},
numpages = {22},
keywords = {Human-AI Interaction, Large Language Models, Natural Language Processing},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3626253.3635572,
author = {Wang, Sierra and Mitchell, John and Haber, Nick and Piech, Chris},
title = {Math IDE: A Platform for Creating with Math},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635572},
doi = {10.1145/3626253.3635572},
abstract = {To inspire student engagement in middle school math, we explore the possibility of using generative AI to enhance the creativity of math learning. We present the Math IDE, a math education environment in which students learn about math concepts by building artifacts. We aimed to create a platform in which students can engage with mathematical concepts, create an artifact that embodies the math that they are learning about, and practice their high-level specification skills. In the current iteration of the Math IDE, students can create custom web pages by describing and demonstrating understanding of the math that is involved in the web page. In this short overview, we describe our process and discuss several open questions regarding the design and application of this novel method of math education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1844–1845},
numpages = {2},
keywords = {creating, education, generative ai, math},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641555.3705171,
author = {Gonzaga, Justin T. and Jiang, Yuchao and Vassar, Alexandra},
title = {Empowering CS1 Educators: Enhancing Automated Feedback Instruction with Cognitive Load Theory},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705171},
doi = {10.1145/3641555.3705171},
abstract = {Delivering personalised and timely feedback is crucial for helping students address gaps in their understanding. However, the increasing demands of large class sizes make this task particularly challenging for CS1 educators, especially for casual teaching assistants who lack formal training and experience. Existing feedback training methods are often inconsistent and ineffective, leaving educators unprepared to handle diverse student needs.To address this, we designed an adaptive fading procedure based on Cognitive Load Theory (CLT) to support educators in delivering high-quality, personalised feedback. This pedagogical technique is integrated into FeedbackPulse-CLT, an automated tool that evaluates feedback in real-time and provides guidance for improvement. This paper outlines our approach to designing scalable, evidence-based feedback instruction using Generative AI and large language models (LLMs) to overcome feedback quality concerns in CS1 education.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1461–1462},
numpages = {2},
keywords = {cognitive load theory, cs1, feedback, generative ai, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706599.3720016,
author = {Katsuragi, Miki and Tanaka, Kenji},
title = {Comparing AI-Generated and Human-Crafted T-Shirt Layouts through an XAI Lens: Key Design Elements and Implications for Co-Creative Tools},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720016},
doi = {10.1145/3706599.3720016},
abstract = {In recent years, the apparel industry has also begun to draw attention to the use of generative AI for design assistance. This study utilized 30 existing T-shirt illustrations provided by graniph and compared: (1) the layouts proposed by the generative AI system “Gemini,” (2) the actual product layouts, and (3) the choices made by five professional designers. First, when evaluated based on eight strictly defined categories (sub-categories), Gemini's layouts matched the actual product in only 12 of the 30 cases. However, by grouping similar placement categories into five broader categories, the number of matches increased to 20. Furthermore, in terms of these broad categories, the matches between Gemini and the five designers ranged from 18 to 24, indicating that Gemini's proposals exhibit a certain level of commonality with human decisions. In addition, when Gemini explained in text why it chose a particular layout, over half of the illustrators found these explanations “reasonable,” suggesting that explainable AI can effectively support collaborative design. This study clarifies both the practical and academic significance of using generative AI in the fashion design field and highlights the importance of interaction design and explanation methods to facilitate smoother collaboration between humans and AI.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {143},
numpages = {10},
keywords = {Generative AI, Human-AI Collaboration, Interaction Design, Layout Recommendation},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3652614,
author = {Li, Jiayi},
title = {Join Our Team: A Unique Opportunity for Aspiring Computer Science Students},
year = {2024},
issue_date = {Spring 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {1528-4972},
url = {https://doi.org/10.1145/3652614},
doi = {10.1145/3652614},
journal = {XRDS},
month = may,
pages = {5–6},
numpages = {2}
}

@inproceedings{10.1145/3706599.3720249,
author = {Reinhard, Philipp and Li, Mahei Manhai and Fina, Matteo and Leimeister, Jan Marco},
title = {Fact or Fiction? Exploring Explanations to Identify Factual Confabulations in RAG-Based LLM Systems},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720249},
doi = {10.1145/3706599.3720249},
abstract = {The adoption of generative artificial intelligence (GenAI) and large language models (LLMs) in society and business is growing rapidly. While these systems often generate convincing and coherent responses, they risk producing incorrect or non-factual information, known as confabulations or hallucinations. Consequently, users must critically assess the reliability of these outputs when interacting with LLM-based agents. Although advancements such as retrieval-augmented generation (RAG) have improved the technical performance of these systems, there is a lack of empirical models that explain how humans detect confabulations. Building on the explainable AI (XAI) literature, we examine the role of reasoning-based explanations in helping users identify confabulations in LLM systems. An online experiment (n = 97) reveals that analogical and factual explanations improve detection accuracy but require more time and cognitive effort than the no explanation baseline.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {274},
numpages = {13},
keywords = {Generative AI, Explainable AI, XAI, RAG, LLM, Confabulations, Hallucinations, GenXAI},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3657604.3662032,
author = {Hou, Xinying and Wu, Zihan and Wang, Xu and Ericson, Barbara J.},
title = {CodeTailor: LLM-Powered Personalized Parsons Puzzles for Engaging Support While Learning Programming},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662032},
doi = {10.1145/3657604.3662032},
abstract = {Learning to program can be challenging, and providing high-quality and timely support at scale is hard. Generative AI and its products, like ChatGPT, can create a solution for most intro-level programming problems. However, students might use these tools to just generate code for them, resulting in reduced engagement and limited learning. In this paper, we present CodeTailor, a system that leverages a large language model (LLM) to provide personalized help to students while still encouraging cognitive engagement. CodeTailor provides a personalized Parsons puzzle to support struggling students. In a Parsons puzzle, students place mixed-up code blocks in the correct order to solve a problem. A technical evaluation with previous incorrect student code snippets demonstrated that CodeTailor could deliver high-quality (correct, personalized, and concise) Parsons puzzles based on their incorrect code. We conducted a within-subjects study with 18 novice programmers. Participants perceived CodeTailor as more engaging than just receiving an LLM-generated solution (the baseline condition). In addition, participants applied more supported elements from the scaffolded practice to the posttest when using CodeTailor than baseline. Overall, most participants preferred using CodeTailor versus just receiving the LLM-generated code for learning. Qualitative observations and interviews also provided evidence for the benefits of CodeTailor, including thinking more about solution construction, fostering continuity in learning, promoting reflection, and boosting confidence. We suggest future design ideas to facilitate active learning opportunities with generative AI techniques.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {51–62},
numpages = {12},
keywords = {active learning, generative ai, gpt, introductory programming, large language models, parsons problems, personalization},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@proceedings{10.1145/3677182,
title = {ASENS '24: Proceedings of the International Conference on Algorithms, Software Engineering, and Network Security},
year = {2024},
isbn = {9798400709784},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanchang, China}
}

@inproceedings{10.1145/3657054.3657092,
author = {Mancera Andrade, Jos\'{e} Alberto and Ter\'{a}n, Luis},
title = {From GenAI to Political Profiling Avatars: A Data-Driven Approach to Crafting Virtual Experts for Voting Advice Applications},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657092},
doi = {10.1145/3657054.3657092},
abstract = {Voting advice applications (VAAs) are pivotal web-based tools that guide citizens to align with political parties and candidates that match their preferences. Traditional methods for creating candidate profiles predominantly rely on questionnaire responses, a time-intensive and costly process. To address these challenges, we introduce a data-centric methodology utilizing generative artificial intelligence (GenAI), culminating in creating political avatars. These political avatars are engineered using cutting-edge large language models (LLMs), including GPT-4 and Bard. They are adept at processing and interpreting data primarily sourced from Twitter and leveraging bespoke, self-trained datasets. Integrating advanced AI technology with diverse data sources equips political avatars with unprecedented analytical and predictive capabilities, setting a new standard in political analysis. Unlike traditional methods, political avatars are adept at emulating the responses of real politicians or experts, showcasing a remarkable capacity to interact with VAA surveys. This novel approach presents the potential to either compete with or enhance the insights traditionally obtained from human experts. Another critical aspect of our study is comparing political avatars and previous research employing question-answering (QA) models based on advanced natural language processing (NLP) techniques for political profiling. This comparative analysis reveals that Political Avatars offer a significantly more robust solution for profile construction. While QA models provide structured responses based on specific queries, political avatars bring an element of dynamism and depth, capable of generating nuanced, context-aware responses. This shift from static, questionnaire-based profiling to dynamic, AI-driven avatars marks a substantial leap in political analysis. Generative AI in crafting Political Avatars introduces a transformative element to data analysis. This approach facilitates a layered and more sophisticated interpretation of political stances, moving beyond the limitations of traditional profiling methods. By employing political avatars, our methodology not only streamlines the profiling process but also enriches the quality of insights derived, paving the way for a more nuanced understanding of the political landscape.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {305–311},
numpages = {7},
keywords = {Bard, GPT-4, Generative AI, Large Language Models, Natural Language Processing, Political Avatars, Question Answering, Social Media, Voting Advice Applications},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

@inproceedings{10.1145/3652620.3687810,
author = {Tabassum, Mirza Rehenuma and Ritchie, Matthew J. and Mustafiz, Sadaf and Kienzle, J\"{o}rg},
title = {Using LLMs for Use Case Modelling of IoT Systems: An Experience Report},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687810},
doi = {10.1145/3652620.3687810},
abstract = {Requirements engineering (RE) plays an essential role in the success of system and software development. Textual use case models are valuable for capturing diverse scenarios describing the interactions between the system and its actors, but their development, particularly for the Internet of Things (IoT), can be tedious and error-prone due to the added complexities and heterogeneous nature of such systems. Automating requirements elicitation and specification tasks with the use of generative AI is highly desirable. This paper explores the potential of large language models (LLMs) for generating interaction models for IoT systems from informal problem descriptions. We investigate the capabilities of OpenAI's GPT-4 and Google's Gemini for generating standard and UCM4IoT textual use cases by carrying out a comparative study using four IoT applications. While both of these LLMs show promise as supporting tools, our findings indicate a need for further refinement and domain-specific training to enhance their precision and reliability in requirements development for the IoT domain.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {611–619},
numpages = {9},
keywords = {requirements engineering, use case modelling, large language model, LLM, model-based development},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3644116.3644294,
author = {Zhu, Jinyang and Gong, Qingyue and Zhou, Chunfang and Luan, Huidan},
title = {ZhongJing: A Locally Deployed Large Language Model for Traditional Chinese Medicine and Corresponding Evaluation Methodology: A Large Language Model for data fine-tuning in the field of Traditional Chinese Medicine, and a new evaluation method called TCMEval are proposed},
year = {2024},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644116.3644294},
doi = {10.1145/3644116.3644294},
abstract = {The success of ChatGPT has showcased the potential applications of Large Language Models (LLMs) in the field of Traditional Chinese Medicine (TCM), encompassing areas such as medical diagnosis, adjunctive therapy, and TCM talent cultivation. However, the current challenges, including hardware constraints, insufficient model domain knowledge, and difficulties in domain-specific evaluation, have constrained the fusion of LLMs with TCM. In an attempt to address these issues, this paper introduces ZhongJing, a domain-specific LLM fine-tuned within the domain of TCM, capable of generating responses at a rate of 8 tokens per second, smoothly operating on local personal computers. To assess the model's domain expertise, this paper introduces the TCMEval evaluation method, designed concerning medical students' exams. Experimental results demonstrate that ZhongJing achieves a 6.49 TCMEval Score improvement over Chinese-LLaMA2 in the field of TCM, indicating the model's ability to generate more specialized responses compared to baseline models.},
booktitle = {Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
pages = {1036–1042},
numpages = {7},
location = {Chengdu, China},
series = {ISAIMS '23}
}

@inproceedings{10.1145/3663548.3675660,
author = {Seo, JooYoung and Kamath, Sanchita S. and Zeidieh, Aziz and Venkatesh, Saairam and McCurry, Sean},
title = {MAIDR Meets AI: Exploring Multimodal LLM-Based Data Visualization Interpretation by and with Blind and Low-Vision Users},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3675660},
doi = {10.1145/3663548.3675660},
abstract = {This paper investigates how blind and low-vision (BLV) users interact with multimodal large language models (LLMs) to interpret data visualizations. Building upon our previous work on the multimodal access and interactive data representation (MAIDR) framework, our mixed-visual-ability team co-designed maidrAI, an LLM extension providing multiple AI responses to users’ visual queries. To explore generative AI-based data representation, we conducted user studies with 8 BLV participants, tasking them with interpreting box plots using our system. We examined how participants personalize LLMs through prompt engineering, their preferences for data visualization descriptions, and strategies for verifying LLM responses. Our findings highlight three dimensions affecting BLV users’ decision-making process: modal preference, LLM customization, and multimodal data representation. This research contributes to designing more accessible data visualization tools for BLV users and advances the understanding of inclusive generative AI applications.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {57},
numpages = {31},
keywords = {Accessibility, Blind, Data Visualization, Generative AI, Large Language Models, Low Vision, Multimodality, Screen Readers},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@article{10.1145/3635439.3635446,
author = {Jabbarvand, Reyhaneh and Tizpaz-Niari, Saeid and Barr, Earl T. and Chandra, Satish},
title = {Summary of the 1st Interpretability and Robustness in Neural Software Engineering (InteNSE 2023)},
year = {2023},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/3635439.3635446},
doi = {10.1145/3635439.3635446},
abstract = {InteNSE is an interdisciplinary workshop for research at the intersection of Machine Learning (ML) and Software Engineering (SE) and would be a pioneer in emphasizing the implicit properties of neural software engineering and analysis. Due to recent computational advancements, ML has become an inseparable part of the SE research community. ML can indeed improve and revolutionize many SE tasks. However, most research in the AI and SE communities consider ML as a closed box, i.e., only considering the final performance of the developed models as an evaluation metric. Ignoring the implicit properties of neural models, such as interpretability and robustness, one cannot validate the model's actual performance, generalizability, and whether it is learning what it is supposed to do. Specifically, in the domain of SE, where the result of ML4SE tools is code synthesis, bug finding, or repair, interpretability and robustness are crucial to ensure the reliability of the products.},
journal = {SIGSOFT Softw. Eng. Notes},
month = dec,
pages = {30–33},
numpages = {4}
}

@proceedings{10.1145/3647722,
title = {ICSIM '24: Proceedings of the 2024 7th International Conference on Software Engineering and Information Management},
year = {2024},
isbn = {9798400709197},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Suva, Fiji}
}

@inproceedings{10.1145/3613904.3642420,
author = {Jo, Eunkyung and Jeong, Yuin and Park, Sohyun and Epstein, Daniel A. and Kim, Young-Ho},
title = {Understanding the Impact of Long-Term Memory on Self-Disclosure with Large Language Model-Driven Chatbots for Public Health Intervention},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642420},
doi = {10.1145/3613904.3642420},
abstract = {Recent large language models (LLMs) offer the potential to support public health monitoring by facilitating health disclosure through open-ended conversations but rarely preserve the knowledge gained about individuals across repeated interactions. Augmenting LLMs with long-term memory (LTM) presents an opportunity to improve engagement and self-disclosure, but we lack an understanding of how LTM impacts people’s interaction with LLM-driven chatbots in public health interventions. We examine the case of CareCall—an LLM-driven voice chatbot with LTM—through the analysis of 1,252 call logs and interviews with nine users. We found that LTM enhanced health disclosure and fostered positive perceptions of the chatbot by offering familiarity. However, we also observed challenges in promoting self-disclosure through LTM, particularly around addressing chronic health conditions and privacy concerns. We discuss considerations for LTM integration in LLM-driven chatbots for public health monitoring, including carefully deciding what topics need to be remembered in light of public health goals.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {440},
numpages = {21},
keywords = {Chatbot, Check-up calls, Large language models, Long-term memory, Open-domain dialog systems, Public health, Social isolation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3545947.3576365,
author = {Katyshev, Alexander and Anikin, Anton and Sychev, Oleg},
title = {Using Transformer Models for Knowledge Graph Construction in Computer Science Education},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3576365},
doi = {10.1145/3545947.3576365},
abstract = {The volume of information that can be used in the development of knowledge bases that can be used in education is constantly increasing. Also, this amount of data is very difficult to process and store. When designing a knowledge base to optimize the educational process, it is important to use ontologies. At the moment, the creation of an ontological knowledge model is the most promising option for storing and processing information. The article describes effective approaches for generating an ontological model using machine learning models based on the Transformer model.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1421},
numpages = {1},
keywords = {concepts, machine learning, neural networks, ontological graph, ontologies, relations between concepts, semantics, transformers},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3613904.3642749,
author = {Precel, Heila and McDonald, Allison and Hecht, Brent and Vincent, Nicholas},
title = {A Canary in the AI Coal Mine: American Jews May Be Disproportionately Harmed by Intellectual Property Dispossession in Large Language Model Training},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642749},
doi = {10.1145/3613904.3642749},
abstract = {Systemic property dispossession from minority groups has often been carried out in the name of technological progress. In this paper, we identify evidence that the current paradigm of large language models (LLMs) likely continues this long history. Examining common LLM training datasets, we find that a disproportionate amount of content authored by Jewish Americans is used for training without their consent. The degree of over-representation ranges from around 2x to around 6.5x. Given that LLMs may substitute for the paid labor of those who produced their training data, they have the potential to cause even more substantial and disproportionate economic harm to Jewish Americans in the coming years. This paper focuses on Jewish Americans as a case study, but it is probable that other minority communities (e.g., Asian Americans, Hindu Americans) may be similarly affected and, most importantly, the results should likely be interpreted as a “canary in the coal mine” that highlights deep structural concerns about the current LLM paradigm whose harms could soon affect nearly everyone. We discuss the implications of these results for the policymakers thinking about how to regulate LLMs as well as for those in the AI field who are working to advance LLMs. Our findings stress the importance of working together towards alternative LLM paradigms that avoid both disparate impacts and widespread societal harms.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {761},
numpages = {17},
keywords = {dataset documentation, economic impacts, large language models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3704262,
author = {Cao, Yihan and Li, Siyu and Liu, Yixin and Yan, Zhiling and Dai, Yutong and Yu, Philip and Sun, Lichao},
title = {A Survey of AI-Generated Content (AIGC)},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3704262},
doi = {10.1145/3704262},
abstract = {Recently, Artificial Intelligence Generated Content (AIGC) has gained significant attention from society, especially with the rise of Generative AI (GAI) techniques such as ChatGPT, GPT-4 [165], DALL-E-3 [184], and Sora [137]. AIGC involves using AI models to create digital content, such as images, music, and natural language, with the goal of making the content creation process more efficient and accessible. Large-scale models have become increasingly important in AIGC as they provide better intent extraction and generation results. This survey provides a comprehensive review of the history of generative models and recent advances in AIGC, focusing on both unimodal and multimodal interaction. From the perspective of unimodality, we introduce the generation tasks and relative models of text and image. From the perspective of multimodality, we introduce the cross-application between the modalities mentioned above. Finally, the survey discusses the existing open problems and future challenges in AIGC. Overall, this survey serves as a valuable resource for individuals interested in understanding the background and secrets behind the impressive performance of AIGC techniques.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {125},
numpages = {38},
keywords = {Generative AI, AI-generated content, multimodal machine learning}
}

@inproceedings{10.1145/3678610.3678631,
author = {Robledo-Rella, V\'{\i}ctor and Toh, Bee-Yen},
title = {Artificial Intelligence in Physics Courses to Support Active Learning},
year = {2024},
isbn = {9798400716799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678610.3678631},
doi = {10.1145/3678610.3678631},
abstract = {The integration of generative artificial intelligence (AI), particularly Large Language Models (LLMs) like OpenAI's ChatGPT and Microsoft's Copilot, is transforming educational methodologies, including undergraduate physics courses for engineering students. Despite their potential, these LLMs typically rely on statistical learning methods and often exhibit algebraic inaccuracies in solving standard university-level physics problems. This study explores the use of LLMs in physics courses for N = 91 freshman engineering students over two academic terms (Spring and Fall 2023). Students engaged in AI-assisted activities to solve physics problems and were asked to identify and correct the errors made by the chatbot. The outcomes were compared with those from traditional teaching methods without AI involvement, and no significant difference in student learning gains was found. To assess the impact of AI tools in education, a more detailed approach using pre-test and post-test instruments&nbsp;with control and experimental groups is necessary. Survey results revealed, however, that AI-assisted sessions enhanced student engagement, problem-solving skills, and understanding of physics concepts. Students also indicated a strong preference for AI-assisted activities, citing increased motivation and a firm belief in the educational benefits of using these tools. Our findings suggest that well-designed AI interventions can effectively complement traditional instructional methods, especially when the LLMs are integrated with symbolic computational tools like WolframAlpha to improve their accuracy.},
booktitle = {Proceedings of the 2024 10th International Conference on E-Society, e-Learning and e-Technologies (ICSLT)},
pages = {68–75},
numpages = {8},
keywords = {ChatGPT, Copilot, Educational Innovation, Generative AI, Higher Education, Interactive Learning, Physics Education Research},
location = {
},
series = {ICSLT '24}
}

@inproceedings{10.1145/3706598.3714322,
author = {Hohendanner, Michel and Ullstein, Chiara and Onyekwelu, Bukola Abimbola and Katirai, Amelia and Kuribayashi, Jun and Babalola, Olusola and Ema, Arisa and Grossklags, Jens},
title = {Initiating the Global AI Dialogues: Laypeople Perspectives on the Future Role of genAI in Society from Nigeria, Germany and Japan},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714322},
doi = {10.1145/3706598.3714322},
abstract = {With the rapid development and release of generative AI (genAI) applications, policy discourses primarily take place on an expert level. Little space is given to laypeople – who have to adapt to and adopt the genAI innovations – to share their opinions and experiences. Addressing this gap, we organized 6h/3.5h laypeople dialogues in Nigeria, Japan, and Germany in July and August 2024. During the dialogues, participants discussed what a desirable future in light of genAI development could look like in one of three contexts: education, public service, and arts &amp; culture. Participants explored the consequences of technology deployment, assessed the risks, mapped stakeholders, and derived measures to achieve a desirable goal. This study contributes to policy debates on genAI by providing recommendations derived from participants’ identified requirements and suggested measures for genAI to create value and to foster a socially desirable future. We reflect on the results through a cross-national lens.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {571},
numpages = {35},
keywords = {citizen dialogue, civic participation, participatory AI, stakeholder involvement, public perception, generative artificial intelligence},
location = {
},
series = {CHI '25}
}

@article{10.1145/3711068,
author = {Yan, Zihan and Xiang, Yaohong},
title = {Social Life Simulation for Non-Cognitive Skills Learning},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711068},
doi = {10.1145/3711068},
abstract = {Non-cognitive skills are crucial for personal and social life well-being, and such skill development can be supported by narrative-based (e.g., storytelling) technologies. While generative AI enables interactive and role-playing storytelling, little is known about how users engage with and perceive the use of AI in social life simulation for non-cognitive skills learning. Additionally, the benefits of AI mentorship on self-reflection awareness and ability in this context remain largely underexplored. To this end, we introduced Simulife++, an interactive platform enabled by a large language model (LLM). The system allows users to act as protagonists, creating stories with one or multiple AI-based characters in diverse social scenarios. In particular, we expanded the Human-AI interaction to a Human-AI-AI collaboration by including a Sage Agent, who acts as a bystander, providing users with some perspectives and guidance on their choices and conversations in terms of non-cognitive skills to promote reflection. In a within-subject user study, our quantitative results reveal that, when accompanied by Sage Agent, users exhibit significantly higher levels of reflection on motivation, self-perceptions, and resilience &amp; coping, along with an enhanced experience of narrative transportation. Additionally, our qualitative findings suggest that Sage Agent plays a crucial role in promoting reflection on non-cognitive skills, enhancing social communication and decision-making performance, and improving overall user experience within Simulife++. Multiple supportive relationships between Sage Agent and users were also reported. We offer design implications for the application of generative AI in narrative solutions and the future potential of Sage Agent for non-cognitive skill development in broader social contexts. Our quantitative data and code are released at https://github.com/yzihan/Simulife.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW170},
numpages = {44},
keywords = {generative AI, narrative, non-cognitive skill, social life simulation}
}

@proceedings{10.1145/3686424,
title = {EDCS '24: Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Education Digitalization and Computer Science},
year = {2024},
isbn = {9798400710360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shenzhen, China}
}

@inproceedings{10.1145/3689535.3689554,
author = {Santos, Eddie Antonio and Becker, Brett A.},
title = {Not the Silver Bullet: LLM-enhanced Programming Error Messages are Ineffective in Practice},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689554},
doi = {10.1145/3689535.3689554},
abstract = {The sudden emergence of large language models (LLMs) such as ChatGPT has had a disruptive impact throughout the computing education community. LLMs have been shown to excel at producing correct code to CS1 and CS2 problems, and can even act as friendly assistants to students learning how to code. Recent work shows that LLMs demonstrate unequivocally superior results in being able to explain and resolve compiler error messages—for decades, one of the most frustrating parts of learning how to code. However, LLM-generated error message explanations have only been assessed by expert programmers in artificial conditions. This work sought to understand how novice programmers resolve programming error messages (PEMs) in a more realistic scenario. We ran a within-subjects study with n = 106 participants in which students were tasked to fix six buggy C programs. For each program, participants were randomly assigned to fix the problem using either a stock compiler error message, an expert-handwritten error message, or an error message explanation generated by GPT-4. Despite promising evidence on synthetic benchmarks, we found that GPT-4 generated error messages outperformed conventional compiler error messages in only 1 of the 6 tasks, measured by students’ time-to-fix each problem. Handwritten explanations still outperform LLM and conventional error messages, both on objective and subjective measures.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {5},
numpages = {7},
keywords = {AI, C, CS1, GPT-4, GenAI, Generative AI, LLMs, PEM, compiler error messages, computing education, debugging, feedback, large language models, novice programmers, programming error messages},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3706598.3713338,
author = {Lima, Gabriel and Grgi\'{c}-Hla\v{c}a, Nina and Redmiles, Elissa M.},
title = {Public Opinions About Copyright for AI-Generated Art: The Role of Egocentricity, Competition, and Experience},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713338},
doi = {10.1145/3706598.3713338},
abstract = {Breakthroughs in generative AI (GenAI) have fueled debates concerning the artistic and legal status of AI-generated creations. We investigate laypeople’s perceptions (N = 432) of AI-generated art through the lens of copyright law. We study lay judgments of GenAI images concerning several copyright-related factors and capture people’s opinions of who should be the authors and rights-holders of AI-generated images. To do so, we held an incentivized AI art competition in which some participants used a GenAI model to create art while others evaluated these images. We find that participants believe creativity and effort, but not skills, are needed to create AI-generated art. Participants were most likely to attribute authorship and copyright to the AI model’s users and to the artists whose creations were used for training. We find evidence of egocentric effects: participants favored their own art with respect to quality, creativity, and effort—particularly when these assessments determined real monetary awards.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1120},
numpages = {32},
keywords = {Generative AI, Large Language Models, GenAI, LLM, Copyright, Egocentric Effects, Competition, Exhibition, Art, AI-Generated Art, Intellectual Property, IP},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3643834.3661587,
author = {Long, Tao and Gero, Katy Ilonka and Chilton, Lydia B},
title = {Not Just Novelty: A Longitudinal Study on Utility and Customization of an AI Workflow},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661587},
doi = {10.1145/3643834.3661587},
abstract = {Generative AI brings novel and impressive abilities to help people in everyday tasks. There are many AI workflows that solve real and complex problems by chaining AI outputs together with human interaction. Although there is an undeniable lure of AI, it is uncertain how useful generative AI workflows are after the novelty wears off. Additionally, workflows built with generative AI have the potential to be easily customized to fit users’ individual needs, but do users take advantage of this? We conducted a three-week longitudinal study with 12 users to understand the familiarization and customization of generative AI tools for science communication. Our study revealed that there exists a familiarization phase, during which users were exploring the novel capabilities of the workflow and discovering which aspects they found useful. After this phase, users understood the workflow and were able to anticipate the outputs. Surprisingly, after familiarization the perceived utility of the system was rated higher than before, indicating that the perceived utility of AI is not just a novelty effect. The increase in benefits mainly comes from end-users’ ability to customize prompts, and thus potentially appropriate the system to their own needs. This points to a future where generative AI systems can allow us to design for appropriation.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {782–803},
numpages = {22},
keywords = {AI chains, LLMs, customization, familiarization, generative AI, longitudinal user experience, mental model, novelty, ownership, scaffolding, science communication, technology appropriation, workflow},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@proceedings{10.1145/3578527,
title = {ISEC '23: Proceedings of the 16th Innovations in Software Engineering Conference},
year = {2023},
isbn = {9798400700644},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Allahabad, India}
}

@proceedings{10.1145/3634814,
title = {ASSE '23: Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference},
year = {2023},
isbn = {9798400708534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Aizu-Wakamatsu City, Japan}
}

@inproceedings{10.1145/3706598.3713479,
author = {Mei, Yihan and Wu, Zhao and Yu, Junnan and Li, Wenan and Zhou, Zhibin},
title = {GeneyMAP: Exploring the Potential of GenAI to Facilitate Mapping User Journeys for UX Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713479},
doi = {10.1145/3706598.3713479},
abstract = {Generative AI (GenAI) has been widely applied in UX design, yet its potential in the Journey Map (JM) creation process remains under-explored. We conducted a formative study (N = 24) to identify designers’ needs for GenAI in JM creation, resulting in six design goals (e.g., Acting as Different Stakeholders) implemented in our tool, GeneyMAP. GeneyMAP streamlines the JM creation process, allowing designers to map interview data efficiently with flexibility, uncovering design opportunities through visual inspiration. A subsequent user study (N = 20) demonstrated that GeneyMAP, compared with the common tool, accelerated JM creation and fostered creativity mainly by providing diverse inspirations and facilitating progressive discussions. Our findings proved GeneyMAP’s utility and effectiveness while challenges in maintaining control and trust in GenAI outputs were noted. Our research highlights the promising role of GenAI in refining JM creation practices and suggests implications for incorporating GenAI in JM and design workflows.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {270},
numpages = {22},
keywords = {Generative AI, LLMs, Design Tool, UX Design, User Research, Journey Map},
location = {
},
series = {CHI '25}
}

@proceedings{10.1145/3647632,
title = {MOBILESoft '24: Proceedings of the IEEE/ACM 11th International Conference on Mobile Software Engineering and Systems},
year = {2024},
isbn = {9798400705946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3638584,
title = {CSAI '23: Proceedings of the 2023 7th International Conference on Computer Science and Artificial Intelligence},
year = {2023},
isbn = {9798400708688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@inproceedings{10.1145/3698322.3698361,
author = {Laue, Ralf and Maranh\~{a}o, Jo\~{a}o Jos\'{e} and Guerra, Eduardo Martins},
title = {Asking ChatGPT for Pattern Recommendations: EuroPLoP 2024 Focus Group Report},
year = {2024},
isbn = {9798400716836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698322.3698361},
doi = {10.1145/3698322.3698361},
abstract = {This report summarizes a focus group held at EuroPLoP 2024 on using ChatGPT as a recommender for design patterns. Apart from the organizers, 11 participants from academia and industry took part in the focus group. In this focus group, we discussed the results of two experiments exploring how well ChatGPT gives recommendations on using patterns from the GoF collection when a situation is described which suggests the application of such a pattern. It was found that the responses are promising in many cases, but their quality depends on a good choice of prompts. The quality of the responses was comparable for prompts in English, German, and Russian, but a little lower for Arabic and absolutely useless in Kyrgyz. Based on our observations, some recommendations are given for selecting suitable prompts when communicating with the chatbot.},
booktitle = {Proceedings of the 29th European Conference on Pattern Languages of Programs, People, and Practices},
articleno = {37},
numpages = {7},
keywords = {generative AI, ChatGPT, Large Language Model, design patterns},
location = {
},
series = {EuroPLoP '24}
}

@inproceedings{10.1145/3630106.3658984,
author = {Wang, Ruotong and Cheng, Ruijia and Ford, Denae and Zimmermann, Thomas},
title = {Investigating and Designing for Trust in AI-powered Code Generation Tools},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658984},
doi = {10.1145/3630106.3658984},
abstract = {Trust is a crucial factor for the adoption and responsible usage of generative AI tools in complex tasks such as software engineering. However, we have a limited understanding of how software developers evaluate the trustworthiness of AI-powered code generation tools in real-world settings. To address this gap, we conducted Study 1, an interview study with 17 developers who use AI-powered code generation tools in professional or personal settings. We found that developers’ trust is rooted in the AI tool’s perceived ability, integrity, and benevolence, and is situational, varying according to the context of usage. Existing AI code generation tools lack the affordances for developers to efficiently and effectively evaluate the trustworthiness of AI-powered code generation tools. To explore designs that can augment the existing interface of AI-powered code generation tools, we explored three sets of design concepts (suggestion quality indicators, usage stats, and control mechanisms) that derived from Study 1 findings. In Study 2, a design probe study with 12 developers, we investigated the potential of these design concepts to help developers make effective trust judgments. We discuss the implication of our findings on the design of AI-powered code generation tools and future research on trust in AI.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1475–1493},
numpages = {19},
keywords = {generative AI, human-AI interaction, software engineering tooling, trust in AI},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3663384.3663398,
author = {He, Jessica and Houde, Stephanie and Gonzalez, Gabriel E. and Silva Moran, Dar\'{\i}o Andr\'{e}s and Ross, Steven I. and Muller, Michael and Weisz, Justin D.},
title = {AI and the Future of Collaborative Work: Group Ideation with an LLM in a Virtual Canvas},
year = {2024},
isbn = {9798400710179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663384.3663398},
doi = {10.1145/3663384.3663398},
abstract = {The introduction of generative AI into multi-user applications raises novel considerations for the future of collaborative work. How might collaborative work practices change? How might we incorporate generative AI into shared tools with users’ needs at the forefront? We examine these questions in the context of a remote team conducting ideation tasks – an example of collaborative work enabled by a shared digital workspace. We conducted a user study with 17 professionals experienced with virtual group ideation workshops. Our study examined their use of the Collaborative Canvas, a virtual canvas tool with integrated generative AI capabilities that we created as a probe. Participants saw value in using generative AI to assist with group facilitation and to augment perspectives and ideas. However, they worried about losing human perspectives and critical thinking, as well as reputational harms resulting from harmful AI outputs. Participants shared suggestions for appropriate ways to incorporate generative AI capabilities within multi-user applications and identified needs for transparency of content ownership, private digital spaces, and specialized AI capabilities. Based on participants’ insights, we share implications and opportunities for the incorporation of generative AI into collaborative work in ways that place user needs at the forefront.},
booktitle = {Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {9},
numpages = {14},
keywords = {Brainstorming, Future of work, Generative AI, Group ideation, Mixed initiative, Shared virtual canvas},
location = {Newcastle upon Tyne, United Kingdom},
series = {CHIWORK '24}
}

@inproceedings{10.1145/3568812.3603453,
author = {Tran, Minh},
title = {Prompt Engineering for Large Language Models to Support K-8 Computer Science Teachers in Creating Culturally Responsive Projects},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603453},
doi = {10.1145/3568812.3603453},
abstract = {The power of large language models has opened up opportunities for educational use. In computing education, recent studies have demonstrated the potential of these models to improve learning and teaching experiences in university-level programming courses. However, research into leveraging them to aid computer science instructors in curriculum development and course material design is relatively sparse, especially at the K-12 level. This work aims to fill this gap by exploring the capability of large language models in ideating and designing culturally responsive projects for elementary and middle school programming classes. Our ultimate goal is to support K-8 teachers in effectively extracting suggestions from large language models by only using natural language modifications. Furthermore, we aim to develop a comprehensive assessment framework for culturally responsive AI-generated project ideas. We also hope to provide valuable insight into teachers’ perspectives on large language models and their integration into teaching practices.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {110–112},
numpages = {3},
keywords = {culturally responsive pedagogy, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3706598.3713478,
author = {Fan, Min and Cui, Xinyue and Ma, Wanqing and Li, Haiyan and Tong, Xin and Yang, Lin and Wang, Yonghui},
title = {From Words to Wonder: Designing and Evaluating an AI-Empowered Creative Storytelling System for Elementary Children},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713478},
doi = {10.1145/3706598.3713478},
abstract = {While several digital tools exist for children's creative storytelling, few have explored how generative AI can enhance storytelling quality. Our formative research identified five design requirements for AI-powered storytelling tools for elementary students. We developed a system named StoryPrompt that enables children to co-create stories and comics with AI, boosting literacy and creativity. Pilot tests with children and HCI experts demonstrated good usability and positive learning experiences. In a mixed-methods evaluation with 40 children from Grades 2-6, we found that StoryPrompt significantly improved storytelling creativity and richness, compared to the storyboard method. Observations indicated more purposeful planning and strategic use of AI-generated words and images, facilitating efficient exploration of storytelling alternatives. While children preferred AI images, they recognized the limitations in representing storytelling details. Teacher interviews highlighted the system's motivational potential and classroom flexibility. We discuss the benefits and considerations of using generative AI to enhance creative storytelling for children.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {328},
numpages = {15},
keywords = {Children, Creativity, Design and Evaluation, Generative AI, Storytelling},
location = {
},
series = {CHI '25}
}

@proceedings{10.1145/3623462,
title = {KUI '23: Proceedings of the 20th International Conference on Culture and Computer Science: Code and Materiality},
year = {2023},
isbn = {9798400708367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@inproceedings{10.14236/ewic/BCSHCI2024.2,
author = {O’Neill, Ian},
title = {Getting GPT to answer like me},
year = {2025},
publisher = {BCS Learning &amp; Development Ltd},
address = {Swindon, GBR},
url = {https://doi.org/10.14236/ewic/BCSHCI2024.2},
doi = {10.14236/ewic/BCSHCI2024.2},
abstract = {This paper provides insights into the development of a prototype tutorial chatbot, using Azure AI and GPT-4. The prototype system answers and poses questions in the manner of a module lecturer in tutorials – able to vary content and phrasing according to circumstance. Use cases in the Unified Modeling Language (UML) are the topic of the tutorial. The system asks questions about and explains core concepts, using the rules of thumb and simplifications that the author/module lecturer would use. By assimilating or ‘ingesting’ natural language instructions and core documents (one of which represents basic domain knowledge while others represent the author’s own presentational tips and hints) the system’s dialogue style comes to resemble that of the author. While the system described here remains a prototype which will require further testing, the results are very encouraging. The paper will be of interest to other educators wishing to create a chatbot that can answer recurrent enquiries about, and reinforce basic concepts in, an academic specialism.},
booktitle = {Proceedings of the 37th International BCS Human-Computer Interaction Conference},
pages = {7–13},
numpages = {7},
keywords = {generative AI, education, chatbots},
location = {University of Central Lancashire (UCLan)},
series = {BCS HCI '24}
}

@inproceedings{10.1145/3699538.3699567,
author = {Amoozadeh, Matin and Nam, Daye and Prol, Daniel and Alfageeh, Ali and Prather, James and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Amin},
title = {Student-AI Interaction: A Case Study of CS1 students},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699567},
doi = {10.1145/3699538.3699567},
abstract = {Generative artificial intelligence tools (Generative AI), such as ChatGPT, allow users to interact with them in intuitive ways (e.g., conversational) and receive (mostly) good-quality answers. In education, such systems can support students’ learning objectives by providing accessible explanations and examples even when students pose vague queries. But, they also encourage undesired help-seeking behaviors, such as by providing solutions to the students’ homework. Therefore, it is important to better understand how students approach such tools and the potential issues such approaches might present for the learners.In this paper, we present a case study for understanding student-AI collaboration to solve programming tasks in the CS1 introductory programming course. To this end, we recruited a gender-balanced majority non-white set of 15 CS1 students at the University of Houston, a large public university in the US. We observed them solving programming tasks. We used a mixed-method approach to study their interactions as they tackled Python programming tasks, focusing on when and why they used ChatGPT for problem-solving. We analyze and classify the questions submitted by the 15 participants to ChatGPT. Additionally, we analyzed user interaction patterns, their reactions to ChatGPT’s responses, and the potential impacts of Generative AI on their perception of self-efficacy.Our results suggest that, in about a third of the cases, the student attempted to complete the task by submitting the full description of the tasks to ChatGPT without making any effort on their own. We also observed that few students verified their solutions. We discuss the potential implications of these results.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {13},
numpages = {13},
keywords = {Generative Artificial Intelligence, Human-AI Interaction, Self-regulation, CS1, User study, Novice programmers},
location = {
},
series = {Koli Calling '24}
}

@proceedings{10.1145/3643664,
title = {WSESE '24: Proceedings of the 1st IEEE/ACM International Workshop on Methodological Issues with Empirical Studies in Software Engineering},
year = {2024},
isbn = {9798400705670},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {WSESE 2024 was a one-day event held on April 16, 2024, in Lisbon, Portugal. The theme of the workshop was "Methodological Issues with Empirical Studies in Software Engineering". The primary goal was to gain a better understanding of the adoption of the empirical paradigm in SE. Specifically, our focus was on identifying, discussing and finding solutions for the issues in the empirical methods currently employed. The workshop provided an opportunity for researchers and practitioners to discuss current methodological challenges and explore ways to address them.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3636243.3636247,
author = {Hou, Irene and Man, Owen and Mettille, Sophia and Gutierrez, Sebastian and Angelikas, Kenneth and MacNeil, Stephen},
title = {More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636247},
doi = {10.1145/3636243.3636247},
abstract = {Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {29–38},
numpages = {10},
keywords = {Bard, ChatGPT, GPT-4V, Generative AI, LLMs, Parsons Problems, computing education, visual programming problems},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3593434.3593463,
author = {Savarimuthu, Bastin Tony Roy and Zareen, Zoofishan and Cheriyan, Jithin and Yasir, Muhammad and Galster, Matthias},
title = {Barriers for Social Inclusion in Online Software Engineering Communities - A Study of Offensive Language Use in Gitter Projects},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593434.3593463},
doi = {10.1145/3593434.3593463},
abstract = {Social inclusion is a fundamental feature of thriving societies. This paper first investigates barriers for social inclusion in online Software Engineering (SE) communities, by identifying a set of 11 attributes and organising them as a taxonomy. Second, by applying the taxonomy and analysing language used in the comments posted by members in 189 Gitter projects (with &gt; 3 million comments), it presents the evidence for the social exclusion problem. It employs a keyword-based search approach for this purpose. Third, it presents a framework for improving social inclusion in SE communities.},
booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
pages = {217–222},
numpages = {6},
keywords = {software engineering communities, exclusion, Social inclusion},
location = {Oulu, Finland},
series = {EASE '23}
}

@inproceedings{10.1145/3615886.3627745,
author = {Mooney, Peter and Cui, Wencong and Guan, Boyuan and Juh\'{a}sz, Levente},
title = {Towards Understanding the Geospatial Skills of ChatGPT: Taking a Geographic Information Systems (GIS) Exam},
year = {2023},
isbn = {9798400703485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615886.3627745},
doi = {10.1145/3615886.3627745},
abstract = {This paper examines the performance of ChatGPT, a large language model (LLM), in a geographic information systems (GIS) exam. As LLMs like ChatGPT become increasingly prevalent in various domains, including education, it is important to understand their capabilities and limitations in specialized subject areas such as GIS. Human learning of spatial concepts significantly differs from LLM training methodologies. Therefore, this study aims to assess ChatGPT's performance and ability to grasp geospatial concepts by challenging it with a real GIS exam. By analyzing ChatGPT's responses and evaluating its understanding of GIS principles, we gain insights into the potential applications and challenges of LLMs in spatially-oriented fields. We conduct our evaluation with two models, GPT-3.5 and GPT-4, to understand whether general improvements of an LLM translate to improvements in answering questions related to the spatial domain. We find that both GPT variants can pass a balanced, introductory GIS exam, scoring 63.3% (GPT-3.5) and 88.3% (GPT-4), which correspond to grades D and B+ respectively in standard US letter grading scale. In addition, we also identify specific questions and topics where the LLMs struggle to grasp spatial concepts, highlighting the challenges in teaching such topics to these models. Finally, we assess ChatGPT's performance in specific aspects of GIS, including spatial analysis, basic concepts of mapping, and data management. This granular analysis provides further insights into the strengths and weaknesses of ChatGPT's GIS literacy. This research contributes to the ongoing dialogue on the integration of AI models in education and can provide guidance for educators, researchers, and practitioners seeking to leverage LLMs in GIS. By focusing on specific questions or concepts that pose difficulties for the LLM, this study addresses the nuances of teaching spatial concepts to AI models and offers potential avenues for improvement in spatial literacy within future iterations of LLMs.},
booktitle = {Proceedings of the 6th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {85–94},
numpages = {10},
keywords = {geospatial, foundation model, education, Large Language Models, Generative AI, GIS, ChatGPT},
location = {Hamburg, Germany},
series = {GeoAI '23}
}

@inproceedings{10.1145/3717867.3717872,
author = {Li, Weijiang and Lai, Yinmeng and Soni, Sandeep and Saha, Koustuv},
title = {Emails by LLMs: A Comparison of Language in AI-Generated and Human-Written Emails},
year = {2025},
isbn = {9798400714832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3717867.3717872},
doi = {10.1145/3717867.3717872},
abstract = {The growing excitement around generative AI (and LLMs) is fueling a heightened interest in the development of AI-assisted writing tools. One popular context is AI-assisted email writing, and this paper explores how AI-generated emails compare to human-written emails. We obtained human-written emails from the W3C corpus and generated analogous AI-generated emails using GPT-3.5, GPT-4, Llama-2, and Mistral-7B, and compared AI-generated and human-written emails using a suite of natural language analyses across syntactic, semantic, and psycholinguistic dimensions. AI-generated emails are generally consistent across different LLMs but differ significantly from human-written emails. Specifically, AI-generated emails tend to be more formal, verbose, and complex, whereas human-written emails are often more concise and personalized. While AI-generated emails are slightly more polite, both types exhibit a similar level of empathetic tone in language. Further, we qualitatively examined user perceptions of AI and human-written emails by conducting a small survey of 41 participants and interviewing a subset of them. This study highlights preliminary insights into generative AI’s distinct strengths and weaknesses in assisting email communication, and we discuss the theoretical and practical implications of the evolving landscape of AI-generated content.},
booktitle = {Proceedings of the 17th ACM Web Science Conference 2025},
pages = {391–403},
numpages = {13},
keywords = {email, language, generative AI, LLMs, linguistic analysis},
location = {
},
series = {Websci '25}
}

@article{10.5555/3722479.3722506,
author = {Liao, Weidong and Guzide, Osman},
title = {Enhancing Undergraduate Computing Education with LMMs and ChatGPT-4o},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {Large Language Models (LLMs) and ChatGPT have significantly impacted programming practices and computer science education. The rapid advancements in natural language processing, recurrent neural networks, and Transformer architectures have captured the attention of students and educators alike. These tools aid students in brainstorming, coding, analyzing code, and writing reports. Although concerns about cheating and plagiarism persist, these tools also provide educators with novel ways to create and assess assignments. Despite some hesitancy among educators to integrate these AI tools into the classroom, the advert and development of Large MultiModal Models (LMMs), the enhancement of LLMs that can deal with multimedia inputs and outputs, illustrates a significant evolution in generative AI capabilities.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {62},
numpages = {1}
}

@inproceedings{10.1145/3568812.3603474,
author = {Singla, Adish},
title = {Evaluating ChatGPT and GPT-4 for Visual Programming},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603474},
doi = {10.1145/3568812.3603474},
abstract = {Generative AI has the potential to drastically improve the landscape of computing education by automatically generating personalized feedback and content. In particular, this potential lies in the advanced capabilities of state-of-the-art deep generative and large language models such as OpenAI’s Codex&nbsp;[7], ChatGPT&nbsp;[11], and GPT-4&nbsp;[12]. In our work, we seek to investigate the capabilities of these models in visual programming domains popularly used for K-8 programming education, including domains like Scratch&nbsp;[17], Hour of Code: Maze Challenge by Code.org&nbsp;[4, 5], and Karel&nbsp;[13]. Recent works have shown us sparks of advanced capabilities of such models for various education scenarios in introductory Python programming&nbsp;[2, 14, 18, 20]. In fact, a study in 2022 had ranked Codex in the top quartile w.r.t students in a large Python programming course&nbsp;[8]. However, all these works consider only text-based Python programming and leave open the question of how well these models would perform for visual programming. The main research question is: Do state-of-the-art neural generative models show advanced capabilities for visual programming on par with their capabilities on text-based Python programming?In our work, we evaluate these models for visual programming based on the following three settings designed to capture various generative and problem-solving capabilities: We conduct our evaluation based on 10 representative tasks from two visual programming domains: Hour of Code: Maze Challenge by Code.org&nbsp;[4, 5] and Intro to Programming with Karel course by CodeHS.com&nbsp;[3, 13]. As illustrative examples, Figures&nbsp;1,&nbsp;2,&nbsp;and&nbsp;3 show the output of GPT-4 in three settings for Maze18 task. We will provide the detailed analysis and prompts used in a longer version of this poster. Our preliminary results for ChatGPT (based on GPT-3.5) and GPT-4 show that these models perform poorly and produce incorrect output the majority of the time. These results highlight that state-of-the-art neural generative models like GPT-4 still struggle to combine spatial, logical, and programming skills crucial for visual programming. As the next step, it would be important to curate novel benchmarks that the research community can use to evaluate improvements in future versions of these models for visual programming.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {14–15},
numpages = {2},
keywords = {ChatGPT, block-based visual programming, generative AI, introductory programming education, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3637528.3671445,
author = {dos Santos Junior, Jos\'{e} Cassio and Hu, Rachel and Song, Richard and Bai, Yunfei},
title = {Domain-Driven LLM Development: Insights into RAG and Fine-Tuning Practices},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671445},
doi = {10.1145/3637528.3671445},
abstract = {To improve Large Language Model (LLM) performance on domain specific applications, ML developers often leverage Retrieval Augmented Generation (RAG) and LLM Fine-Tuning. RAG extends the capabilities of LLMs to specific domains or an organization's internal knowledge base, without the need to retrain the model. On the other hand, Fine-Tuning approach updates LLM weights with domain-specific data to improve performance on specific tasks. The fine-tuned model is particularly effective to systematically learn new comprehensive knowledge in a specific domain that is not covered by the LLM pre-training. This tutorial walks through the RAG and Fine-Tuning techniques, discusses the insights of their advantages and limitations, and provides best practices of adopting the methodologies for the LLM tasks and use cases. The hands-on labs demonstrate the advanced techniques to optimize the RAG and fine-tuned LLM architecture that handles domain specific LLM tasks. The labs in the tutorial are designed by using a set of open-source python libraries to implement the RAG and fine-tuned LLM architecture.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6416–6417},
numpages = {2},
keywords = {fine tuning, generative artificial intelligence, large language model, retrieval augmented generation},
location = {Barcelona, Spain},
series = {KDD '24}
}

@proceedings{10.1145/3639476,
title = {ICSE-NIER'24: Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3643915,
title = {SEAMS '24: Proceedings of the 19th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
year = {2024},
isbn = {9798400705854},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, AA, Portugal}
}

@proceedings{10.5555/3623288,
title = {ICSE-NIER '23: Proceedings of the 45th International Conference on Software Engineering: New Ideas and Emerging Results},
year = {2023},
isbn = {9798350300390},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Australia}
}

@inproceedings{10.1145/3706599.3719982,
author = {Jeck, Jakub and Leiser, Florian and H\"{u}sges, Anne and Sunyaev, Ali},
title = {TELL-ME: Toward Personalized Explanations of Large Language Models},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719982},
doi = {10.1145/3706599.3719982},
abstract = {This paper introduces TELL-ME, a prototype designed to provide personalized explanations for outputs generated by large language models (LLMs). Traditional explanation approaches often fail to address diverse user needs in understanding generative AI (GenAI) outputs. TELL-ME bridges this gap by tailoring explanations to three distinct user groups: beginners, advanced users, and experts. Two literature reviews on explanation and personalization informed the design of TELL-ME. With that, TELL-ME provides feature ablation, counterfactual, and self-explainability explanations on text generation tasks. A preliminary evaluation of TELL-ME with six participants showed that the personalized explanations enhanced users’ understanding of model outputs. Nonetheless, areas for improvement were identified, such as integrating state-of-the-art LLMs into the prototype. The full code for TELL-ME is available at https://github.com/jayjkb/TELL-ME.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {498},
numpages = {18},
keywords = {Personalization, Customization, Explainable AI, GenXAI, Generative AI, Artifact Development},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3636243.3636252,
author = {Jury, Breanna and Lorusso, Angela and Leinonen, Juho and Denny, Paul and Luxton-Reilly, Andrew},
title = {Evaluating LLM-generated Worked Examples in an Introductory Programming Course},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636252},
doi = {10.1145/3636243.3636252},
abstract = {Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, ‘WorkedGen’, which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for optimising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen’s value in a range of programming languages, and with more complex questions suitable for more advanced courses.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {77–86},
numpages = {10},
keywords = {CS1, GPT-3.5, LLM, chat-GPT, computing education, large language models, worked examples},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3657604.3664685,
author = {Jiang, Lan and Bosch, Nigel},
title = {Short answer scoring with GPT-4},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664685},
doi = {10.1145/3657604.3664685},
abstract = {Automatic short-answer scoring is a long-standing research problem in education. However, assessing short answers at human-level accuracy requires a deep understanding of natural language. Given the notable abilities of recent generative pre-trained transformer (GPT) models, we investigate gpt-4-1106-preview to automatically score student responses from the Automated Student Assessment Prize Short Answer Scoring dataset. We systematically varied information given to the model including possible correct answers and scoring examples, as well as the order of sub-tasks within short answer scoring (e.g., assigning a score vs. generating a rationale for an assigned score) to understand what affects short answer scoring. With the best configuration, GPT-4 yielded a quadratic weighted kappa of .677 across 10 questions. However, we observe that the performance differs across educational subjects (e.g., biology, English), the quality of scoring rubrics might affect the predictions, and the overall utility of rationales generated to explain scores is uncertain.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {438–442},
numpages = {5},
keywords = {gpt (generative pre-trained transformer), short answer scoring, text classification},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3597503.3639075,
author = {Serafini, Raphael and Otto, Clemens and Horstmann, Stefan Albert and Naiakshina, Alena},
title = {ChatGPT-Resistant Screening Instrument for Identifying Non-Programmers},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639075},
doi = {10.1145/3597503.3639075},
abstract = {To ensure the validity of software engineering and IT security studies with professional programmers, it is essential to identify participants without programming skills. Existing screening questions are efficient, cheating robust, and effectively differentiate programmers from non-programmers. However, the release of ChatGPT raises concerns about their continued effectiveness in identifying non-programmers. In a simulated attack, we showed that Chat-GPT can easily solve existing screening questions. Therefore, we designed new ChatGPT-resistant screening questions using visual concepts and code comprehension tasks. We evaluated 28 screening questions in an online study with 121 participants involving programmers and non-programmers. Our results showed that questions using visualizations of well-known programming concepts performed best in differentiating between programmers and non-programmers. Participants prompted to use ChatGPT struggled to solve the tasks. They considered ChatGPT ineffective and changed their strategy after a few screening questions. In total, we present six ChatGPT-resistant screening questions that effectively identify non-programmers. We provide recommendations on setting up a ChatGPT-resistant screening instrument that takes less than three minutes to complete by excluding 99.47% of non-programmers while including 94.83% of programmers.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {181},
numpages = {13},
keywords = {chatgpt, programmer screening, developer study, study protection},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@proceedings{10.1145/3568160,
title = {CSCS '22: Proceedings of the 6th ACM Computer Science in Cars Symposium},
year = {2022},
isbn = {9781450397865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Ingolstadt, Germany}
}

@proceedings{10.1145/3637792,
title = {ICSED '23: Proceedings of the 2023 5th International Conference on Software Engineering and Development},
year = {2023},
isbn = {9798400709463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3644523,
title = {ICCSMT '23: Proceedings of the 2023 4th International Conference on Computer Science and Management Technology},
year = {2023},
isbn = {9798400709517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi'an, China}
}

@proceedings{10.1145/3568364,
title = {WSSE '22: Proceedings of the 4th World Symposium on Software Engineering},
year = {2022},
isbn = {9781450396950},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@inproceedings{10.1145/3632621.3671429,
author = {Potriasaeva, Anna and Dzialets, Katsiaryna and Golubev, Yaroslav and Birillo, Anastasiia},
title = {Using a Low-Code Environment to Teach Programming in the Era of LLMs},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671429},
doi = {10.1145/3632621.3671429},
abstract = {LLMs change the landscape of software engineering, and the question arises: “How can we combine LLMs with traditional teaching approaches in computer science?”. In this work, we propose to teach students in a low-code environment of code generation, developing not only their coding but also decomposition and prompting skills.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {542–543},
numpages = {2},
keywords = {Generative AI, LLMs, MOOC, Programming Education},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3706599.3719971,
author = {Gu, Quan Connie and Hickey, Daniel and Ryokai, Kimiko},
title = {When AI Tells Their Story: Researchers’ Reactions to AI-Generated Podcasts as a Tool for Communicating Research},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719971},
doi = {10.1145/3706599.3719971},
abstract = {Podcasts have been recognized as an accessible and engaging medium for education and science communication. Recent advances in generative AI have led to the development of tools that transform science communication by summarizing complex research for broader audiences. However, little research has explored original authors’ perspectives and reactions to these tools, leaving gaps in understanding their views on accurate representation of their work. Through interviews with 10 authors from 9 different disciplines, our study examines authors’ perspectives on the accuracy, effectiveness, and role of AI-generated podcasts in engaging both academic and general audiences. The study also explores their reflections on the opportunities and risks these tools present, both for broader audiences and for authors themselves, along with their ideas for improving the design. By centering authors’ perspectives, this study aims to provide insights for designing AI-assisted science communication systems that respect the integrity of academic work while enhancing accessibility.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {597},
numpages = {6},
keywords = {science communication, generative AI, podcast},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706598.3714159,
author = {Wang, Huanchen and Qiu, Tianrun and Li, Jiaping and Lu, Zhicong and Ma, Yuxin},
title = {HarmonyCut: Supporting Creative Chinese Paper-cutting Design with Form and Connotation Harmony},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714159},
doi = {10.1145/3706598.3714159},
abstract = {Chinese paper-cutting, an Intangible Cultural Heritage (ICH), faces challenges from the erosion of traditional culture due to the prevalence of realism alongside limited public access to cultural elements. While generative AI can enhance paper-cutting design with its extensive knowledge base and efficient production capabilities, it often struggles to align content with cultural meaning due to users’ and models’ lack of comprehensive paper-cutting knowledge. To address these issues, we conducted a formative study (N=7) to identify the workflow and design space, including four core factors (Function, Subject Matter, Style, and Method of Expression) and a key element (Pattern). We then developed HarmonyCut, a generative AI-based tool that translates abstract intentions into creative and structured ideas. This tool facilitates the exploration of suggested related content (knowledge, works, and patterns), enabling users to select, combine, and adjust elements for creative paper-cutting design. A user study (N=16) and an expert evaluation (N=3) demonstrated that HarmonyCut effectively provided relevant knowledge, aiding the ideation of diverse paper-cutting designs and maintaining design quality within the design space to ensure alignment between form and cultural connotation.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {661},
numpages = {22},
keywords = {Creativity support tool, Chinese paper-cutting, Generative AI-aided design, Intangible Cultural Heritage},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641555.3705037,
author = {Piech, Chris and Sahami, Mehran and Alonso, Yasmine and Liu, Katie and Arifov, Javokhir and Sreenivas, Anjali and Webber, Dan and Zheng, Tina and Nguyen, Ngoc and Mlauzi, Iddah and Woodrow, Juliette},
title = {Infinite Story},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705037},
doi = {10.1145/3641555.3705037},
abstract = {In Infinite Story, students build a choose-your-own-adventure game that integrates generative AI to create a dynamic, interactive "infinite story" experience. The game is powered by nested dictionary (JSON) objects that store pre-existing scenes. Each scene is a nested dictionary, containing user choices, descriptions, and more. Students are challenged to navigate and manipulate these deeply nested data structures, which helps them appreciate the utility and complexity of dictionary objects. When a user ventures into an undefined scene, the program makes an API call to ChatGPT to generate the next scene, allowing the adventure to continue seamlessly. To the best of our knowledge it is one of the first assignments in intro CS that uses ChatGPT. What makes this assignment truly nifty is how it teaches students to leverage generative AI in a creative, meaningful way. By blending generative storytelling with technical skills, students get to see the power of AI in extending their projects beyond predefined boundaries, creating an open-ended, exciting experience. Many students expanded on this assignment for their final projects, creating sophisticated programs like AI-driven Chess and Go games. Using the techniques from this assignment, they leveraged the course's OpenAI integration to build functional AI agents that enhanced gameplay. These projects showcased the flexibility of the assignment, inspiring students to think critically about the creative and practical applications of AI in real-world contexts.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1750},
numpages = {1},
keywords = {API, CS1, JSON, dictionaries, generative AI, nested structures, python, storytelling},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705025,
author = {Diaz, Marc and Karp, Dustin and Tuli, Prayuj and Kapoor, Amanpreet},
title = {Edugator: An AI-enabled Tool for Creating and Delivering Interactive Computing Content},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705025},
doi = {10.1145/3641555.3705025},
abstract = {Edugator is a browser-based, AI-enabled tool designed to help instructors of introductory computing courses create and deliver interactive educational content. It streamlines the content authoring process by incorporating generative AI models into both the creation and delivery stages. Instructors can create bespoke interactive computing lessons and programming problems by providing a prompt and a few clicks. They can also author templates and test cases in programming languages such as C++, Java, C, and Python. Additionally, instructors can validate programming problems by running them against an auto-generated solution, allowing them to refine the problems before releasing it to students, preventing misinformation or ambiguity. Students can complete lessons and solve programming problems in a browser-based text editor receiving immediate feedback. They can also interact with a large language model-powered AI chatbot that scaffolds a student on how to approach the problem without giving out solutions. Edugator is built using modern web frameworks and the goal of the tool is to accelerate the adoption of automated assessment tools by minimizing the challenges instructors face with such tools. It also supports Learning Tools Interoperability (LTI), allowing seamless integration with learning management systems (LMS). The demo will provide an overview of Edugator's features, including authoring programming problems and lessons using AI or remixing existing problems obtained from test banks, LTI integration, and AI-chatbot. More information about the tool can be found at https://edugator.app/ and https://github.com/edugatorlabs/resources},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1732},
numpages = {1},
keywords = {ai tutor, automated assessment tool, generative ai, introductory programming, learning by doing},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@proceedings{10.1145/3555228,
title = {SBES '22: Proceedings of the XXXVI Brazilian Symposium on Software Engineering},
year = {2022},
isbn = {9781450397353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Brazil}
}

@inproceedings{10.1145/3671127.3698182,
author = {Sawada, Tomoya and Hasegawa, Takaomi and Yokoyama, Keiichi and Mizuno, Masahiro},
title = {Office-in-the-Loop for Building HVAC Control with Multimodal Foundation Models},
year = {2024},
isbn = {9798400707063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671127.3698182},
doi = {10.1145/3671127.3698182},
abstract = {This p aper i nvestigates t he p otential of l arge l anguage models (LLMs) for optimizing HVAC systems in real-world settings. While prior research has primarily focused on simulated environments, this study bridges the gap by deploying and evaluating an LLM-based control system in an actual office. The system collects real-time environmental data and occupant feedback on thermal comfort. This data, along with historical environmental and feedback information, is used to prompt the generative AI model, which predicts optimal HVAC setpoint temperatures throughout the day. The results demonstrate a significant reduction in power consumption (up to 47.92%, equivalent to 39.48 kWh) and a concurrent improvement in occupant comfort (up to 26.36%) compared to the baseline. Notably, regression analysis confirms that these improvements persist even after accounting for external factors such as outside temperature and occupancy. This study highlights the significant potential of generative AI for optimizing HVAC systems, enhancing both energy efficiency and occupant comfort in real-world scenarios. Future research will explore the scalability of this approach, targeting larger-scale building energy management systems in data centers and industrial facilities.},
booktitle = {Proceedings of the 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {110–120},
numpages = {11},
keywords = {Electricity consumption, Generative AI, HVAC Control, Occupant feedback},
location = {Hangzhou, China},
series = {BuildSys '24}
}

@inproceedings{10.1145/3657604.3664669,
author = {Bradford, Allison and Li, Weiying and Gerard, Libby and Linn, Marcia C.},
title = {Comparing Expert and ChatGPT-authored Guidance Prompts},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664669},
doi = {10.1145/3657604.3664669},
abstract = {Students bring a multitude of ideas and experiences to the classroom while they are reasoning about scientific phenomena. They often need timely guidance to refine build upon their initial ideas. In this study we explore the development of guidance prompts to provide students with personalized, real-time feedback in the context of a pedagogically grounded chatbot. In the current version of the tool, guidance prompts are authored by learning scientists who are experts in the content of the items and in Knowledge Integration pedagogy. When students engage with the chatbot, an idea detection model is used to determine the ideas that are present in a student explanation and then the expert-authored guidance prompts are assigned based on rules about which ideas are or are not present in the student explanation. While this approach allows for close attention to and control of the pedagogical intent of each prompt, it is time consuming and not easily generalizable. Further this rule-based approach limits the ways in which students can interact with the chatbot. The work in progress study presented in this paper explores the potential of using generative AI to create similarly pedagogically grounded guidance prompts as a first step towards increasing the generalizability and scalability of this approach. Specifically, we ask: using criteria from the Knowledge Integration Pedagogical Framework, how do ChatGPT 3.5-authored guidance prompts compare to human expert-authored guidance prompts? We find that while prompt engineering can enhance the alignment of ChatGPT-authored guidance prompts with pedagogical criteria, the human expert-authored guidance prompts more consistently meet the pedagogical criteria.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {388–392},
numpages = {5},
keywords = {automated guidance, generative AI, knowledge integration pedagogy},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.1145/3674846,
author = {Raman, Raghu and Nair, Vinith and Dinesh, Sofi and Acharyulu, Ramana},
title = {Comparative Analysis of ChatGPT and Bard in Digital Governance: Accuracy, Adaptability, and Readability Insights},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674846},
doi = {10.1145/3674846},
abstract = {In a comprehensive assessment of ChatGPT and Bard's performance across three key indices—Government AI Readiness, Digital Economy and Society, and UN E-Government Survey, the study delves into nuanced insights regarding their accuracy, adaptability, and readability within the context of Digital Governance. ChatGPT demonstrated a superior accuracy rate of 93.55%, surpassing Bard's performance at 88.57%. Notably, both models exhibited variations in individual and mutual error correction capabilities, particularly evident when faced with confirmation queries. Bard showcased an adjustment post-confirmation, suggesting potential error correction, whereas ChatGPT displayed limited adaptability in similar scenarios. While there was a notable congruence in their responses to Digital Governance content, challenges arose in deciphering complex information, especially concerning sustainability initiatives. Bard generally produced more accessible content, evident in readability metrics, in contrast to ChatGPT's inclination towards using complex language. Both models demonstrated promising alignment in addressing intricate topics within the realm of Digital Governance. The findings emphasize the need for policymakers to critically evaluate the adaptability and accuracy of language models like ChatGPT and Bard when considering their integration into digital governance practices. Awareness of their diverse performance and error correction capabilities is crucial for responsible implementation, ensuring the maximal benefits of AI in public decision-making.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = jun,
keywords = {digital governance, generative AI, ChatGPT, Bard, readability, similarity analysis, public sector, policy, ethics}
}

@inproceedings{10.1145/3641554.3701932,
author = {Farinetti, Laura and Cagliero, Luca},
title = {A Critical Approach to ChatGPT: An Experience in SQL Learning},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701932},
doi = {10.1145/3641554.3701932},
abstract = {ChatGPT potential value in education is broadly recognized and many studies report experiments of its use inside or outside the classroom by students and teachers. On the other hand, the use of ChatGPT rises lots of concerns about well-known problems such as hallucination, plagiarism, overreliance, or misinformation. It is of primary importance to teach students a correct and constructive use of ChatGPT and a critical approach to its returned outputs. The paper presents a classroom experience where students were asked to interact with ChatGPT in the context of a database course. The declared challenge for the students was, given a set of predefined relational database schemata, to invent questions for ChatGPT and try to force wrong SQL solutions. Students had to record the question, the ChatGPT solution, their solution, and the comments about the eventual ChatGPT syntactical and/or semantical errors. This gamification approach was meant to enhance students' motivation, but the main teachers' goal was to make them reflect critically (i) on ChatGPT output, experiencing that it does make mistakes, (ii) on the interpretation of ChatGPT errors, and (iii) on the possible strategies for forcing ChatGPT errors. The experiment involved 166 B.S. students in Engineering and the collected data have been analyzed under different points of view to get an insight into the approach and the critical attitude of the students. The paper reports the results of this analysis and discusses the impact of the activity on learning by analyzing the correlation between students' participation and exam performance.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {318–324},
numpages = {7},
keywords = {critical thinking, database education, human-computer interaction, large language model, sql},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3657054.3657126,
author = {Alnahhas, Noor and Yousef, Dima},
title = {GAI as a Catalyst in National Technology Sovereignty: Evaluating the Influence of GAI on Government Policy},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657126},
doi = {10.1145/3657054.3657126},
abstract = {As a result of the prominence of generative artificial intelligence across diverse fields, it has become necessary for governments to develop national strategies for directing the ethical use of artificial intelligence to respect fundamental human values. This paper explores the role of Generative Artificial Intelligence (GAI) in technology sovereignty, its contributions, and benefits for the government, associated risks, and challenges, and how it influences government policies. It begins with examining GAI's capabilities to comprehend how it understands natural language, trains on existing data, and generates realistic outputs, followed by a discussion of its potential benefits for governments that enable them to act independently and autonomously in diverse sectors. It highlights how it can empower them to administer technological ecosystems, promote domestic innovation, and facilitate policy-making processes. However, contrary to its benefits, GAI is also capable of inflicting negative consequences on society. Therefore, the paper also addresses the risks and challenges associated with GAI that necessitate reflection on existing policies and developing new ones that align with a nation's legal frameworks. Exploring the influence of GAI on government policies, the paper highlights the significance of collaboration in policy-making endeavors to ensure ethical future developments and bring value to public interest and democratic values. This comprehensive analysis aims to shed light on the responsible and ethical use of GAI to preserve human rights, promote economic growth, sustain social justice, and inform the responsible use of GAI within the framework of technology sovereignty.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {618–626},
numpages = {9},
keywords = {Generative AI, Governance, Sovereignty, Technology},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

@inproceedings{10.1145/3706598.3713529,
author = {Page, Rowan and See, Jian Shin},
title = {Creative Reflections on Image-Making with Artificial Intelligence: Interactions with a Provocative 'Camera'},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713529},
doi = {10.1145/3706598.3713529},
abstract = {Cameras are increasingly augmented with computational processing, producing images that blur the line between documenting reality and creative expression. The rise of text-to-image models has redefined the concept of imagery, sparking ethical and philosophical debates. This paper presents the findings of a qualitative study that employed a provocative prototype ‘camera’ – the A(I)Cam – to engage creative practitioners directly in these discussions. Developed using a Research-through-Design (RtD) approach, the tangible prototype generates and instantly prints AI-created images. A(I)Cam facilitated reflection among creative practitioners (N=15) on their experiences with AI-driven tools and the broader implications for their future practices. We examine the shifts in perspective that emerged from engaging with this embodied form of generative AI (genAI), challenging traditional text-based interaction paradigms, and inviting new modes of creative exploration and reflection. In addition, we offer insights from the RtD project, highlighting the integration of genAI tools into the industrial design process.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {543},
numpages = {16},
keywords = {Creative AI, Generative AI, Research through Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3626252.3630826,
author = {Hoq, Muntasir and Shi, Yang and Leinonen, Juho and Babalola, Damilola and Lynch, Collin and Price, Thomas and Akram, Bita},
title = {Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630826},
doi = {10.1145/3626252.3630826},
abstract = {The emergence of publicly accessible large language models (LLMs) such as ChatGPT poses unprecedented risks of new types of plagiarism and cheating where students use LLMs to solve exercises for them. Detecting this behavior will be a necessary component in introductory computer science (CS1) courses, and educators should be well-equipped with detection tools when the need arises. However, ChatGPT generates code non-deterministically, and thus, traditional similarity detectors might not suffice to detect AI-created code. In this work, we explore the affordances of Machine Learning (ML) models for the detection task. We used an openly available dataset of student programs for CS1 assignments and had ChatGPT generate code for the same assignments, and then evaluated the performance of both traditional machine learning models and Abstract Syntax Tree-based (AST-based) deep learning models in detecting ChatGPT code from student code submissions. Our results suggest that both traditional machine learning models and AST-based deep learning models are effective in identifying ChatGPT-generated code with accuracy above 90%. Since the deployment of such models requires ML knowledge and resources that are not always accessible to instructors, we also explore the patterns detected by deep learning models that indicate possible ChatGPT code signatures, which instructors could possibly use to detect LLM-based cheating manually. We also explore whether explicitly asking ChatGPT to impersonate a novice programmer affects the code produced. We further discuss the potential applications of our proposed models for enhancing introductory computer science instruction.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {526–532},
numpages = {7},
keywords = {artificial intelligence, chatgpt, cheat detection, cs1, introductory programming course, large language model, plagiarism detection},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@proceedings{10.1145/3644479,
title = {EBIMCS '23: Proceedings of the 2023 6th International Conference on E-Business, Information Management and Computer Science},
year = {2023},
isbn = {9798400709333},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hong Kong, Hong Kong}
}

@inproceedings{10.1145/3657604.3664700,
author = {Thomas, Danielle R. and Lin, Jionghao and Bhushan, Shambhavi and Abboud, Ralph and Gatz, Erin and Gupta, Shivang and Koedinger, Kenneth R.},
title = {Learning and AI Evaluation of Tutors Responding to Students Engaging in Negative Self-Talk},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664700},
doi = {10.1145/3657604.3664700},
abstract = {Addressing negative self-talk by students, such as responding to a student when saying, "I am dumb" or "I can't do this" can be difficult for even the most experienced tutor. Despite potential tutor learning from scenario-based lessons on this topic, human-graded assessment remains time-consuming. Leveraging generative AI for evaluating textual responses in online training presents a scalable solution. Research suggests a tutor validates student's feelings when they speak negatively of themselves, e.g., by a tutor responding, "I understand how you feel" or "I recognize this is difficult." This ongoing work assesses the performance of 60 undergraduate tutors within an online lesson on enhancing tutors' abilities to respond to students engaging in negative self-talk. We find statistically significant tutor learning gains from pretest to posttest. Additionally, we describe a method of using generative AI for assessing tutors' responses to predict the best approach and subsequently explain the rationale behind it. Using the large language model GPT-4, we find high absolute performance when evaluating tutor responses involving predicting (F1 = 0.85) and explaining (F1 = 0.83) the best approach. Minor improvements are needed to the lesson itself. A future goal of this work is to fully develop automated systems of assessing tutor learning attending to barriers to students' motivation and doing so at scale.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {481–485},
numpages = {5},
keywords = {assessment, generative ai, large language models, tutor training},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3643479.3662056,
author = {Vu, Sinh Trong and Truong, Huong Thu and Do, Oanh Tien and Le, Tu Anh and Mai, Tai Tan},
title = {A ChatGPT-based approach for questions generation in higher education},
year = {2024},
isbn = {9798400705472},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643479.3662056},
doi = {10.1145/3643479.3662056},
abstract = {Large language models have been widely applied in many aspects of real life, bringing significant efficiency to businesses and offering distinctive user experiences. In this paper, we focus on exploring the application of ChatGPT, a chatbot based on a large language model, to support higher educator in generating quiz questions and assessing learners. Specifically, we explore interactive prompting patterns to design an optimal AI-powered question bank creation process. The generated questions are evaluated through a "Blind test" survey sent to various stakeholders including lecturers and learners. Initial results at the Banking Academy of Vietnam are relatively promising, suggesting a potential direction to streamline the time and effort involved in assessing learners at higher education institutes.},
booktitle = {Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia},
pages = {13–18},
numpages = {6},
keywords = {ChatGPT, Large language model, question generation},
location = {Phuket, Thailand},
series = {AIQAM '24}
}

@inproceedings{10.1145/3649217.3653621,
author = {Margulieux, Lauren E. and Prather, James and Reeves, Brent N. and Becker, Brett A. and Cetin Uzun, Gozde and Loksa, Dastyni and Leinonen, Juho and Denny, Paul},
title = {Self-Regulation, Self-Efficacy, and Fear of Failure Interactions with How Novices Use LLMs to Solve Programming Problems},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653621},
doi = {10.1145/3649217.3653621},
abstract = {We explored how undergraduate introductory programming students naturalistically used generative AI to solve programming problems. We focused on the relationship between their use of AI to their self-regulation strategies, self-efficacy, and fear of failure in programming. In this repeated-measures, mixed-methods research, we examined students' patterns of using generative AI with qualitative student reflections and their self-regulation, self-efficacy, and fear of failure with quantitative instruments at multiple times throughout the semester. We also explored the relationships among these variables to learner characteristics, perceived usefulness of AI, and performance. Overall, our results suggest that student factors affect their baseline use of AI. In particular, students with higher self-efficacy, lower fear of failure, or higher prior grades tended to use AI less or later in the problem-solving process and rated it as less useful than others. Interestingly, we found no relationship between students' self-regulation strategies and their use of AI. Students who used AI less or later in problem-solving also had higher grades in the course, but this is most likely due to prior characteristics as our data do not suggest that this is a causal relationship.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {276–282},
numpages = {7},
keywords = {CS1, LLMs, artificial intelligence, copilot, fear of failure, generative ai, introductory programming, large language models, metacognition, self-efficacy, self-regulated learning, self-regulation},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3641554.3701827,
author = {Renzella, Jake and Vassar, Alexandra and Lee Solano, Lorenzo and Taylor, Andrew},
title = {Compiler-Integrated, Conversational AI for Debugging CS1 Programs},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701827},
doi = {10.1145/3641554.3701827},
abstract = {Large Language Models (LLMs) present a transformative opportunity to address longstanding challenges in computing education. This paper presents a conversational AI extension to an LLM-enhanced C/C++ compiler which generates pedagogically sound programming error explanations. Our new tool, DCC Sidekick, retains compiler integration, allowing students to see their code, error messages, and stack frames alongside a conversational AI interface. Compiler context improves error explanations, and provides a seamless development experience. We present quantitative analyses of Sidekick's usage and engagement patterns in a large CS1 course. In the first seven weeks of use, 959 students initiated 11,222 DCC Sidekick sessions, generating 17,982 error explanations. Over half of all conversations occur outside of business hours, highlighting the value of these always-available tools. Early results indicate strong adoption of conversational AI debugging tools, demonstrating scalability in supporting large CS1 courses. We share implementation details and lessons learned, offering guidance to educators considering integrating AI tools with pedagogical guardrails.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {994–1000},
numpages = {7},
keywords = {ai in education, cs1, generative ai, programming error messages},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3617946.3617955,
author = {Bucchiarone, Antonio and Cooper, Kendra M. L. and Lin, Dayi and Smith, Adam and Wanick, Vanissa},
title = {Fostering Collaboration and Advancing Research in Software Engineering and Game Development for Serious Contexts},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/3617946.3617955},
doi = {10.1145/3617946.3617955},
abstract = {The potential benefits of using the engaging and interactive nature of games to achieve specific objectives have been recognized by researchers and professionals from numerous domains. Serious games have been developed to impart knowledge, skills, and awareness in areas such as education, healthcare and the environment, while gamification has been applied to enhance the engagement, motivation, and participation of users in non-game activities such as sustainability and learning. As a result, the fields of game engineering, software engineering, and user experience are increasingly converging to create innovative solutions that blend the strengths of games with real-world applications.},
journal = {SIGSOFT Softw. Eng. Notes},
month = oct,
pages = {46–50},
numpages = {5}
}

@inproceedings{10.1145/3702386.3702399,
author = {Huang, Hui-Wen and Chang, Jessica (Chieh-Yu)},
title = {Human-AI Interactions in Teacher Education: Examining Social Presence and Friendship},
year = {2025},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702386.3702399},
doi = {10.1145/3702386.3702399},
abstract = {This study examines the potential of AI chatbots, such as ChatGPT, to establish meaningful human-AI friendships with college students enrolled in teacher education programs. Fifty-nine junior-level elementary education majors participated in a three-week intervention study. Using the framework of social presence theory, this research explores whether generative AI technologies can replicate key qualities of friendship, such as empathy, social support, and trust. The findings reveal that while AI chatbots provide practical benefits and reliable assistance, they fall short in fostering the deep emotional and empathetic connections that are fundamental to human relationships. Notably, some participants expressed trust in AI chatbots, citing their ability to keep users' secrets private. The results suggest that enhancing social presence may improve emotional engagement and trust in human-AI interactions. This study contributes to the understanding of AI's role in offering social and emotional support, particularly in explaining student teachers' behaviors with AI technologies within educational settings.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
pages = {64–69},
numpages = {6},
keywords = {Generative AI, emotional support, human-AI Interaction, social presence theory, virtual friends},
location = {
},
series = {ICAITE '24}
}

@inproceedings{10.1145/3593663.3593695,
author = {Dobslaw, Felix and Bergh, Peter},
title = {Experiences with Remote Examination Formats in Light of GPT-4},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593663.3593695},
doi = {10.1145/3593663.3593695},
abstract = {Sudden access to the rapidly improving large language model GPT by OpenAI forces educational institutions worldwide to revisit their exam procedures. In the pre-GPT era, we successfully applied oral and open-book home exams for two courses in the third year of our predominantly remote Software Engineering BSc program. We ask in this paper whether our current open-book exams are still viable or whether a move back to a legally compliant but less scalable oral exam is the only workable alternative. We further compare work-effort estimates between oral and open-book exams and report on differences in throughput and grade distribution over eight years to better understand the impact of examination format on the outcome. Examining GPT-4 on the most recent open-book exams showed that our current Artificial Intelligence and Reactive Programming exams are not GPT v4 proof. Three potential weaknesses of GPT are outlined. We also found that grade distributions have largely been unaffected by the examination format, opening up for a move to oral examinations only if needed. Throughput was higher for open-book exam course instances (73% vs 64%), while fail rates were too (12% vs 7%), with teacher workload increasing even for smaller classes. We also report on our experience regarding effort. Oral examinations are efficient for smaller groups but come with caveats regarding intensity and stress.},
booktitle = {Proceedings of the 5th European Conference on Software Engineering Education},
pages = {220–225},
numpages = {6},
keywords = {Software Engineering Education, Oral Examinations, Examination Formats, ChatGPT},
location = {Seeon/Bavaria, Germany},
series = {ECSEE '23}
}

@inproceedings{10.1145/3641555.3705125,
author = {Zhang, Shan and Meshram, Pragati Shuddhodhan and Ganapathy Prasad, Priyadharshini and Israel, Maya and Bhat, Suma},
title = {An LLM-Based Framework for Simulating, Classifying, and Correcting Students' Programming Knowledge with the SOLO Taxonomy},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705125},
doi = {10.1145/3641555.3705125},
abstract = {Novice programmers often face challenges in designing computational artifacts and fixing code errors, which can lead to task abandonment and over-reliance on external support. While research has explored effective meta-cognitive strategies to scaffold novice programmers' learning, it is essential to first understand and assess students' conceptual, procedural, and strategic/conditional programming knowledge at scale. To address this issue, we propose a three-model framework that leverages Large Language Models (LLMs) to simulate, classify, and correct student responses to programming questions based on the SOLO Taxonomy. The SOLO Taxonomy provides a structured approach for categorizing student understanding into four levels: Pre-structural, Uni-structural, Multi-structural, and Relational. Our results showed that GPT-4o achieved high accuracy in generating and classifying responses for the Relational category, with moderate accuracy in the Uni-structural and Pre-structural categories, but struggled with the Multi-structural category. The model successfully corrected responses to the Relational level. Although further refinement is needed, these findings suggest that LLMs hold significant potential for supporting computer science education by assessing programming knowledge and guiding students toward deeper cognitive engagement.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1681–1682},
numpages = {2},
keywords = {computer science education, large language model, solo taxonomy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649165.3690116,
author = {Golesteanu, Matei A. and Vowinkel, Garrett B. and Dougherty, Ryan E.},
title = {Can ChatGPT pass a Theory of Computing Course?},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690116},
doi = {10.1145/3649165.3690116},
abstract = {Large Language Models (LLMs) have had considerable difficulty when prompted with mathematical and formal questions, especially those within theory of computing (ToC) courses. In this paper, we detail two experiments regarding our own ToC course and the ChatGPT LLM. For the first, we evaluated ChatGPT's ability to pass our own ToC course's exams. For the second, we created a database of sample ToC questions and responses to accommodate other ToC offerings' choices for topics and structure. We scored each of ChatGPT's outputs on these questions. Overall, we determined that ChatGPT can pass our ToC course, and is adequate at understanding common formal definitions and answering "simple''-style questions, e.g., true/false and multiple choice. However, ChatGPT often makes nonsensical claims in open-ended responses, such as proofs.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {33–38},
numpages = {6},
keywords = {automata theory, chatgpt, computer science education, formal languages, large language model, theoretical computer science},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@article{10.1145/3686970,
author = {Cheng, Zirui and Xu, Jingfei and Jin, Haojian},
title = {TreeQuestion: Assessing Conceptual Learning Outcomes with LLM-Generated Multiple-Choice Questions},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686970},
doi = {10.1145/3686970},
abstract = {The advances of generative AI have posed a challenge for using open-ended questions to assess conceptual learning outcomes, as it is increasingly common for students to use tools like ChatGPT to generate long textual answers. However, teachers still have to spend substantial time reading the answers and inferring students' learning outcomes. We present TreeQuestion, a human-in-the-loop system designed to help teachers create a set of multiple-choice questions to assess students' conceptual learning outcomes. When a teacher seeks to assess students' comprehension of specific concepts, TreeQuestion taps into the wealth of knowledge embedded within large language models and generates a set of multiple-choice questions organized in a tree-like structure. We evaluated TreeQuestion with 96 students and 10 teachers. Results indicated that students achieved similar performance in multiple-choice questions generated by TreeQuestion and open-ended questions graded by teachers. Meanwhile, TreeQuestion could reduce teachers' efforts in creating and grading the multiple-choice questions in contrast to manually generated open-ended questions. We estimate that in a hypothetical class with 20 students, using multiple-choice questions from TreeQuestion may require only 4.6% of the time compared to open-ended questions for assessing learning outcomes.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {431},
numpages = {29},
keywords = {education, generative AI, large language models, multiple-choice questions, open-ended questions}
}

@inproceedings{10.1145/3691620.3695286,
author = {Adejumo, Elijah Kayode and Johnson, Brittany},
title = {Towards Leveraging LLMs for Reducing Open Source Onboarding Information Overload},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695286},
doi = {10.1145/3691620.3695286},
abstract = {Consistent, diverse, and quality contributions are essential to the sustainability of the open source community. Therefore, it is important that there is infrastructure for effectively onboarding and retaining diverse newcomers to open source software projects. Most often, open source projects rely on onboarding documentation to support newcomers in making their first contributions. Unfortunately, prior studies suggest that information overload from available documentation, along with the predominantly monolingual nature of repositories, can have negative effects on the newcomer experiences and onboarding process. This, coupled with the effort involved in creating and maintaining onboarding documentation, suggest a need for support in creating more accessible documentation. Large language models (LLMs) have shown great potential in providing text transformation support in other domains, and even shown promise in simplifying or generating other kinds of computing artifacts, such as source code and technical documentation. We contend that LLMs can also help make software onboarding documentation more accessible, thereby reducing the potential for information overload. Using ChatGPT (GPT-3.5 Turbo) and Gemini Pro as case studies, we assessed the effectiveness of LLMs for simplifying software onboarding documentation, one method for reducing information overload. We discuss a broader vision for using LLMs to support the creation of more accessible documentation and outline future research directions toward this vision.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2210–2214},
numpages = {5},
keywords = {open-source, software, on-boarding, generative AI, documentation, ChatGPT, LLMs},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@proceedings{10.1145/3593434,
title = {EASE '23: Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Oulu, Finland}
}

@inproceedings{10.1145/3706468.3706536,
author = {Pan, Hongchen and Araujo Oliveira, Eduardo and Ferreira Mello, Rafael},
title = {Exploring Human-AI Collaboration in Educational Contexts: Insights from Writing Analytics and Authorship Attribution},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706536},
doi = {10.1145/3706468.3706536},
abstract = {This research investigates the characteristics of student essays written with and without generative AI assistance, using stylometric analysis and deep learning techniques to explore human-AI collaboration in academic writing. To address three research questions, the study examines: (1) patterns in vocabulary diversity, sentence structure, and readability in AI-generated versus student-written essays; (2) the development of a stylometry-based BERT model for authorship attribution, focusing on linguistic features to accurately distinguish between student and AI-generated content; and (3) the application of this model to measure AI involvement at the sentence level in collaborative essays. Using a dataset of student and AI-assisted essays, we observed distinct stylistic differences, with AI-generated content exhibiting higher lexical diversity and readability scores. The BERT model demonstrated high accuracy (85%), precision (79%), and F1-scores (74%) in identifying AI contributions, surpassing the adopted baseline. While limitations such as dataset imbalance and variability in AI outputs remain, this study highlights the potential of stylometric analysis in improving authorship attribution and quantifying AI involvement in academic writing. These findings provide educators with tools to monitor student progress, offer personalised feedback, and maintain academic integrity in the face of growing AI usage in education.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {903–909},
numpages = {7},
keywords = {Generative AI, Authorship Attribution, Writing Analytics},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3639477.3643648,
author = {Davila, Nicole and Wiese, Igor and Steinmacher, Igor and Lucio da Silva, Lucas and Kawamoto, Andre and Favaro, Gilson Jose Peres and Nunes, Ingrid},
title = {An Industry Case Study on Adoption of AI-based Programming Assistants},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3643648},
doi = {10.1145/3639477.3643648},
abstract = {Programming assistants based on artificial intelligence (AI), such as ChatGPT and GitHub Copilot, have gained worldwide popularity recently. Studies in software development have explored the adoption of these tools, investigating their characteristics and impacts and how practitioners interact and perceive them. To contribute to this growing body of knowledge, in this study, we aim to explore the adoption of AI-based programming assistants in the Brazilian industry. More specifically, we aim to understand how practitioners of a particular Brazilian agroindustry-related company perceive and use AI-based tools to develop software. Using an online survey, we collected and analyzed 72 responses from employees of the studied company. Our findings suggest that practitioners mainly adopt ChatGPT and GitHub Copilot, interacting with these tools to accelerate online searching, typing, and syntax recall. A recurrent difficulty is the lack of context in the suggestions provided by these tools, but participants work on detailed descriptions to contextualize and cope with this challenge. Among the reasons for not using AI-based tools, the most influential is that participants use a commercial programming language, i.e., Uniface, which these tools lack examples. Our results provide insights into the state of the practice related to AI-based programming assistants and discuss implications for practitioners and researchers.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {92–102},
numpages = {11},
keywords = {artificial intelligence, generative AI, ChatGPT, industry case study, software development},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@inproceedings{10.1145/3706598.3714312,
author = {Vachha, Cyrus and Kang, Yixiao and Dive, Zach and Chidambaram, Ashwat and Gupta, Anik and Jun, Eunice and Hartmann, Bj\"{o}rn},
title = {Dreamcrafter: Immersive Editing of 3D Radiance Fields Through Flexible, Generative Inputs and Outputs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714312},
doi = {10.1145/3706598.3714312},
abstract = {Authoring 3D scenes is a central task for spatial computing applications. Competing visions for lowering existing barriers are (1) focus on immersive, direct manipulation of 3D content or (2) leverage AI techniques that capture real scenes (3D Radiance Fields such as, NeRFs, 3D Gaussian Splatting) and modify them at a higher level of abstraction, at the cost of high latency. We unify the complementary strengths of these approaches and investigate how to integrate generative AI advances into real-time, immersive 3D Radiance Field editing. We introduce Dreamcrafter, a VR-based 3D scene editing system that: (1) provides a modular architecture to integrate generative AI algorithms; (2) combines different levels of control for creating objects, including natural language and direct manipulation; and (3) introduces proxy representations that support interaction during high-latency operations. We contribute empirical findings on control preferences and discuss how generative AI interfaces beyond text input enhance creativity in scene editing and world building.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {3},
numpages = {13},
keywords = {Graphics; Virtual Reality; Gaussian Splatting; Generative AI; Worldbuilding interface; AI assisted creativity tool},
location = {
},
series = {CHI '25}
}

@proceedings{10.1145/3528588,
title = {NLBSE '22: Proceedings of the 1st International Workshop on Natural Language-based Software Engineering},
year = {2022},
isbn = {9781450393430},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 1st edition of the International Workshop on Natural Language-Based Software Engineering (NLBSE). The potential of Natural Language Processing (NLP) and Natural Language Generation (NLG) to support developers and engineers in a wide number of software engineering-related tasks (e.g., requirements engineering, extraction of knowledge and patterns from the software artifacts, summarization and prioritization of development and maintenance activities, etc.) is increasingly evident. Furthermore, the current availability of libraries (e.g., NLTK, CoreNLP, and fasttext) and models (e.g., BERT) that allow efficiently and easily dealing with low-level aspects of natural language processing and representation, pushed more and more researchers to closely work with industry to attempt to solve software engineers' real-world problems.},
location = {Pittsburgh, Pennsylvania}
}

@inproceedings{10.1145/3675812.3675843,
author = {Zhang, Wenting and Zhang, Qiaorong and Cai, Mingming and Wang, Dongqing and Zheng, Yafeng},
title = {Navigating the Application Challenges of ChatGPT in Education: Promoting Responsible Use and Minimizing Mental Risks},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675843},
doi = {10.1145/3675812.3675843},
abstract = {With the wide application of artificial intelligence, especially generative AI like ChatGPT, the era of significant transformation in education has quietly arrived. This article first explores the current applications of ChatGPT in logical learning, language learning, as well as personalized and effective teaching. It then deeply analyzes the challenges brought by the application of ChatGPT in education from three aspects: digital ethics, psychological risks for teachers and students, and educational governance. Based on its potential risks and challenges, effective measures and suggestions are proposed, including improving information literacy education, fully utilizing human-computer collaboration, and establishing clear regulations for the use of ChatGPT. These measures aim to ensure that ChatGPT can maximize its application value in the field of education while minimizing the mental risks.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {23–28},
numpages = {6},
keywords = {Application Challenges, ChatGPT, Mental Risks},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@article{10.5555/3715622.3715633,
author = {Zuo, Fei and Tompkins, Cody and Qian, Gang and Rhee, Junghwan and Qu, Xianshan and Yang, Bokai},
title = {ChatGPT as an Assembly Language Interpreter for Computing Education},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {2},
issn = {1937-4771},
abstract = {Assembly language is a low-level programming language useful for a number of important computing areas, such as hardware and embedded systems programming, computer architecture, reverse engineering, and malware analysis. In recent years, generative AI, enhanced by GPT technology, has been widely adopted in the IT industry as well as computing education. However, little work has been done to investigate the applicability of GPT to teaching assembly language. In this paper, we fill in the gap by providing an empirical study of GPT's ability to interpret assembly instructions. In particular, we manually evaluated GPT-4's per-instruction explanations of code segments for four different computer architectures, namely x86, x86-64, ARM, and AArch64. Our study shows that, while inconsistencies and rare errors do exist, GPT's interpretations are highly accurate in general, demonstrating a great potential for such tools to be applied in pedagogical practices for tutoring assembly language.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {73–82},
numpages = {10}
}

@inproceedings{10.1145/3641555.3705250,
author = {Akhmetov, Ildar and Prpa, Mirjana},
title = {Simulating Requirement Elicitation: Development and Evaluation of a Persona-Based Tool},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705250},
doi = {10.1145/3641555.3705250},
abstract = {We present the Requirement Elicitation Tool that leverages Large Language Model (LLM) (gpt-4o-mini) to enable simulated real-world interactions of requirements gathering from three synthetic personas. We demonstrate the use case of Computer Science (CS) students in Database Management Systems leveraging the tool to build a conceptual model and Entity-Relationship (ER) diagrams. Our preliminary findings show the potential of this tool to engage students in discovery process without providing predefined solutions and set the directions for future work.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1357–1358},
numpages = {2},
keywords = {AI persona, requirement elicitation, software engineering education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713433,
author = {Tang, Xinru and Abdolrahmani, Ali and Gergle, Darren and Piper, Anne Marie},
title = {Everyday Uncertainty: How Blind People Use GenAI Tools for Information Access},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713433},
doi = {10.1145/3706598.3713433},
abstract = {Generative AI (GenAI) tools promise to advance non-visual information access but introduce new challenges due to output errors, hallucinations, biases, and constantly changing capabilities. Through interviews with 20 blind screen reader users who use various GenAI applications for diverse tasks, we show how they approached information access with everyday uncertainty, or a mindset of skepticism and criticality towards both AI- and human-mediated assistance as well as information itself. Instead of expecting information to be ‘correct’ and ‘complete’, participants extracted cues from error-prone information sources; treated all information as tentative; acknowledged and explored information subjectivity; and constantly adjusted their expectations and strategies considering the politics around access. The concept of everyday uncertainty situates GenAI tools among the interconnected assistive applications, humans, and sociomaterial conditions that both enable and hinder the ongoing production of access. We discuss the implications of everyday uncertainty for future design and research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {63},
numpages = {17},
keywords = {uncertainty, generative artificial intelligence, accessibility, blind, screen reader users},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713363,
author = {Lu, Zhuoran and Zhou, Qian and Wang, Yi},
title = {WhatELSE: Shaping Narrative Spaces at Configurable Level of Abstraction for AI-bridged Interactive Storytelling},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713363},
doi = {10.1145/3706598.3713363},
abstract = {Generative AI significantly enhances player agency in interactive narratives (IN) by enabling just-in-time content generation that adapts to player actions. While delegating generation to AI makes IN more interactive, it becomes challenging for authors to control the space of possible narratives - within which the final story experienced by the player emerges from their interaction with AI. In this paper, we present WhatELSE, an AI-bridged IN authoring system that creates narrative possibility spaces from example stories. WhatELSE provides three views (narrative pivot, outline, and variants) to help authors understand the narrative space and corresponding tools leveraging linguistic abstraction to control the boundaries of the narrative space. Taking innovative LLM-based narrative planning approaches, WhatELSE further unfolds the narrative space into executable game events. Through a user study (N=12) and technical evaluations, we found that WhatELSE enables authors to perceive and edit the narrative space and generates engaging interactive narratives at play-time.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {333},
numpages = {18},
keywords = {Interactive Narrative, Large Language Models, Abstraction, Narrative Space, Video Games, Generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3661167.3661226,
author = {Esposito, Matteo and Palagiano, Francesco},
title = {Leveraging Large Language Models for Preliminary Security Risk Analysis: A Mission-Critical Case Study},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661226},
doi = {10.1145/3661167.3661226},
abstract = {Preliminary security risk analysis (PSRA) provides a quick approach to identify, evaluate, and propose remediation to potential risks in specific scenarios. The extensive expertise required for an effective PSRA and the substantial textual-related tasks hinders quick assessments in mission-critical contexts, where timely and prompt actions are essential. The speed and accuracy of human experts in PSRA significantly impact response time. A large language model can quickly summarise information in less time than a human. To our knowledge, no prior study has explored the capabilities of fine-tuned models (FTM) in PSRA. Our case study investigates the proficiency of FTM in assisting practitioners in PSRA. We manually curated 141 representative samples from over 50 mission-critical analyses archived by the industrial context team in the last five years. We compared the proficiency of the FTM versus seven human experts. Within the industrial context, our approach has proven successful in reducing errors in PSRA, hastening security risk detection, and minimizing false positives and negatives. This translates to cost savings for the company by averting unnecessary expenses associated with implementing unwarranted countermeasures. Therefore, experts can focus on more comprehensive risk analysis, leveraging LLMs for an effective preliminary assessment within a condensed timeframe.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {442–445},
numpages = {4},
keywords = {Analysis, Fine-Tuning, Generative AI, Human Experts, LLM, Large Language Model, Management, Preliminary, Risk, Security, Standards},
location = {Salerno, Italy},
series = {EASE '24}
}

@proceedings{10.1145/3565387,
title = {CSAE '22: Proceedings of the 6th International Conference on Computer Science and Application Engineering},
year = {2022},
isbn = {9781450396004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, China}
}

@inproceedings{10.1145/3613905.3651118,
author = {Fan, Min and Cui, Xinyue and Hao, Jing and Ye, Renxuan and Ma, Wanqing and Tong, Xin and Li, Meng},
title = {StoryPrompt: Exploring the Design Space of an AI-Empowered Creative Storytelling System for Elementary Children},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3651118},
doi = {10.1145/3613905.3651118},
abstract = {Creative storytelling is a crucial learning activity for children. We conducted formative research with three teachers and 18 children and derived five design implications. Based on the findings, we developed StoryPrompt, an interactive system that enables elementary children to co-create stories and comics with generative AI, aiming to enhance their literacy and creativity. The preliminary evaluation, involving eight children and three HCI experts, demonstrated good system usability and children's satisfactory learning experience. We discuss the advantages and considerations of our design features in using generative AI to empower creative storytelling for elementary children.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {303},
numpages = {8},
keywords = {Children, Creativity, Design, Generative AI, Literacy, Storytelling},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3706599.3716293,
author = {ElAgroudy, Passant and V\"{a}\"{a}n\"{a}nen, Kaisa and Li, Jie and Oulasvirta, Antti and Barbareschi, Giulia and Gruenerbl, Agnes and Churchill, Elizabeth F and Mackay, Wendy E. and Schmidt, Albrecht and Lukowicz, Paul},
title = {Transforming Human-AI Collaboration using “Large Whatever Models” (LWMs)},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3716293},
doi = {10.1145/3706599.3716293},
abstract = {This Special Interest Group (SIG) focuses on re-imagining Human-AI collaboration in the age of off-the-shelf generative AI technologies reflecting the growing integration of AI into daily life and societal systems. The SIG addresses human-AI collaboration at three levels: interaction, collaboration, and symbiosis. Key topics include designing systems that adapt to human contexts, re-imagining collaboration interfaces, fostering inclusive urban environments, and balancing technological governance with equitable access. We also pose the question: what is the next big thing after GenAI to enhance collective intelligence, and societal equity and empower people? Our goal here is to build a sustainable, specialized, and interdisciplinary community beyond the scope of the SIG that focuses on creating a sustainable, equitable global impact through augmenting human capabilities with efficient, safe, and trustworthy collaborations with AI systems.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {863},
numpages = {4},
keywords = {Generative AI, Large Language Models, Large Multimodal Models, ChatGPT, Human-AI Collaboration, Hybrid Intelligence, Symbiosis},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3643795.3648375,
author = {Grandel, Skyler and Schmidt, Douglas C. and Leach, Kevin},
title = {Applying Large Language Models to Enhance the Assessment of Parallel Functional Programming Assignments},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648375},
doi = {10.1145/3643795.3648375},
abstract = {Courses in computer science (CS) often assess student programming assignments manually, with the intent of providing in-depth feedback to each student regarding correctness, style, efficiency, and other quality attributes. As class sizes increase, however, it is hard to provide detailed feedback consistently, especially when multiple assessors are required to handle a larger number of assignment submissions. Large language models (LLMs), such as ChatGPT, offer a promising alternative to help automate this process in a consistent, scalable, and minimally-biased manner.This paper explores ChatGPT-4's scalablility and accuracy in assessing programming assignments based on predefined rubrics in the context of a case study we conducted in an upper-level undergraduate and graduate CS course at Vanderbilt University. In this case study, we employed a method that compared assessments generated by ChatGPT-4 against human graders to measure the accuracy, precision, and recall associated with identifying programming mistakes. Our results show that when ChatGPT-4 is used properly (e.g., with appropriate prompt engineering and feature selection) it can improve objectivity and grading efficiency, thereby acting as a complementary tool to human graders for advanced computer science graduate and undergraduate students.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {102–110},
numpages = {9},
keywords = {ChatGPT, education, generative AI, large language models, prompt engineering, automated grading},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3699538.3699591,
author = {Keuning, Hieke and Luxton-Reilly, Andrew and Ott, Claudia and Petersen, Andrew and Kiesler, Natalie},
title = {Goodbye Hello World - Research Questions for a Future CS1 Curriculum},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699591},
doi = {10.1145/3699538.3699591},
abstract = {Generative AI (GenAI) is currently capable of generating correct code for introductory level programming problems, and its performance is improving. We believe that this capability can be leveraged to improve student motivation, broaden students’ understanding of software development, and engage them in more authentic learning. We defined a set of assumptions about GenAI’s future capabilities (e.g., the ability to generate small pieces of code and to compose these pieces of code via user prompts) and engaged in a backcasting exercise to identify what else is needed to develop a CS1 course that places GenAI in a central role. Undertaking this thought experiment immediately revealed that aspects of the software development process usually reserved for later in the curriculum, such as requirements elicitation and design, could be introduced earlier in the process. With GenAI tools bearing the load of generating correct code snippets, students could focus on higher-level software design and construction skills and practice them in an authentic environment. Our thought experiment identified a set of questions that need to be addressed for such a course to actually exist, including questions about student preparation, and the ability of students to decompose problems effectively and to resolve problems that arise when integrating pieces of code. We also identified questions related to the design of a GenAI centered course, such as the impact on student motivation of using GenAI instead of engaging directly with code, the extent to which social learning theories apply to interactions with GenAI, and how existing pedagogies can integrate GenAI tools.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {27},
numpages = {2},
keywords = {Computing education, CS1, Generative AI, Mastery Learning, LLMs},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3613905.3650879,
author = {Yoon, Harin and Oh, Changhoon and Jun, Soojin},
title = {How Can I Trust AI? : Extending a UXer-AI Collaboration Process in the Early Stages},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650879},
doi = {10.1145/3613905.3650879},
abstract = {This paper explores the integration of generative AI into UX design by focusing on developing a collaborative process that facilitates work between UX practitioners (UXers) and AI. It identifies critical barriers in UXer–AI collaboration, investigates the need for modifications in the collaboration process, and proposes a new process involving verification and decision-making stages. Through a workshop with experienced UXers, this study examined their perspectives and challenges in working with AI. The findings emphasize the need to enhance the trustworthiness of generative AI’s outputs and discuss various verification methods. This research contributes to bridging the gap between AI technology and practical UX design, paving the way for more effective and trustworthy collaboration.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {186},
numpages = {7},
keywords = {Generative AI, Human-AI Collaboration Process, UX Design},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3678884.3681875,
author = {Li, Xian and Han, Yuanning and Liu, Di and An, Pengcheng and Niu, Shuo},
title = {FlowGPT: Exploring Domains, Output Modalities, and Goals of Community-Generated AI Chatbots},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678884.3681875},
doi = {10.1145/3678884.3681875},
abstract = {The advent of Generative AI and Large Language Models has not only enhanced the intelligence of interactive applications but also catalyzed the formation of communities passionate about customizing these AI capabilities. FlowGPT, an emerging platform for sharing AI prompts and use cases, exemplifies this trend, attracting many creators who develop and share chatbots with a broader community. Despite its growing popularity, there remains a significant gap in understanding the types and purposes of the AI tools created and shared by community members. In this study, we delve into FlowGPT and present our preliminary findings on the domain, output modality, and goals of chatbots. We aim to highlight common types of AI applications and identify future directions for research in AI-sharing communities.},
booktitle = {Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
pages = {355–361},
numpages = {7},
keywords = {ai, chatbot, flowgpt, gen-ai, generative ai, prompt},
location = {San Jose, Costa Rica},
series = {CSCW Companion '24}
}

@proceedings{10.1145/3577530,
title = {CSAI '22: Proceedings of the 2022 6th International Conference on Computer Science and Artificial Intelligence},
year = {2022},
isbn = {9781450397773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@inproceedings{10.1145/3716640.3716654,
author = {Gutierrez, Sebastian and Hou, Irene and Lee, Jihye and Angelikas, Kenneth and Man, Owen and Mettille, Sophia and Prather, James and Denny, Paul and MacNeil, Stephen},
title = {Seeing the Forest and the Trees: Solving Visual Graph and Tree Based Data Structure Problems using Large Multimodal Models},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716654},
doi = {10.1145/3716640.3716654},
abstract = {Recent advancements in generative AI systems have raised concerns about academic integrity among educators. Beyond excelling at solving programming problems and text-based multiple-choice questions, recent research has also found that large multimodal models (LMMs) can solve Parsons problems based only on an image. However, such problems are still inherently text-based and rely on the capabilities of the models to convert the images of code blocks to their corresponding text. In this paper, we further investigate the capabilities of LMMs to solve graph and tree data structure problems based only on images. To achieve this, we computationally construct and evaluate a novel benchmark dataset comprising 9,072 samples of diverse graph and tree data structure tasks to assess the performance of the GPT-4o, GPT-4 with Vision (GPT-4V), Gemini 1.5 Pro, Gemini 1.5 Flash, Gemini 1.0 Pro Vision, and Claude 3 model families. GPT–4o and Gemini 1.5 Flash performed best on trees and graphs respectively. GPT-4o achieved 87.6% accuracy on tree samples, while Gemini 1.5 Pro, achieved 76.9% accuracy on graph samples. Our findings highlight the influence of structural and visual variations on model performance. This research not only introduces an LMM benchmark to facilitate replication and further exploration but also underscores the potential of LMMs in solving complex computing problems, with important implications for pedagogy and assessment practices.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {124–133},
numpages = {10},
keywords = {Generative AI, Academic Integrity, Computing Education, Large Multimodal Models, LMMs, Large Language Models, LLMs},
location = {
},
series = {ACE '25}
}

@article{10.1145/3700142,
author = {Dwivedi, Divya and De', Rahul},
title = {Potential for GenAI in the Public Domain: A Review of Transportation, Healthcare, Agriculture, and Law},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
url = {https://doi.org/10.1145/3700142},
doi = {10.1145/3700142},
abstract = {Generative Artificial Intelligence (GenAI) tools are becoming quite popular for a variety of operations. One such tool, Chat Generative Pre-Trained Transformer (ChatGPT), is rapidly permeating into people's daily lives and is considered to have the potential to reshape our society. While private organizations are spending huge amounts of money on ChatGPT, its usage in the public domain is still driven by its open access and simple functionality. This study draws on the key concepts of Effective Use theory—Transparent Interaction, Representational Fidelity, Informed Action, and Learning and Adaptation—to examine ChatGPT's current state of diffusion in four public sector domains: transportation, healthcare, agriculture, and law. We find that transparent interaction is better in transportation, agriculture, and law than healthcare; representational fidelity presents a complex picture, whereas informed action has been positive across domains; and learning and adaptation is an ongoing need. We conclude with various suggestions related to research and policy toward boosting GenAI's adoption. We suggest that governments invest resources and develop new regulatory frameworks considering the specific context and use cases for leveraging the enormous potential of GenAI tools in the public domain.},
journal = {Digit. Gov.: Res. Pract.},
month = feb,
articleno = {3},
numpages = {11},
keywords = {GenAI, ChatGPT in public domain, Effective Use theory, Ethical and regulatory considerations, Policy suggestions}
}

@inproceedings{10.1145/3626253.3633436,
author = {Leinonen, Juho and MacNeil, Stephen and Denny, Paul and Hellas, Arto},
title = {Using Large Language Models for Teaching Computing},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633436},
doi = {10.1145/3626253.3633436},
abstract = {In the past year, large language models (LLMs) have taken the world by storm, demonstrating their potential as a transformative force in many domains including computing education. Computing education researchers have found that LLMs can solve most assessments in introductory programming courses, including both traditional code writing tasks and other popular tasks such as Parsons problems. As more and more students start to make use of LLMs, the question instructors might ask themselves is "what can I do?". We propose that one promising way forward is to integrate LLMs into teaching practice, providing all students with an equal opportunity to learn how to interact productively with LLMs as well as encounter and understand their limitations. In this workshop, we first present state-of-the-art research results on how to utilize LLMs in computing education practice, after which participants will take part in hands-on activities using LLMs. We end the workshop by brainstorming ideas with participants around adapting their classrooms to most effectively integrate LLMs while avoiding some common pitfalls.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1901},
numpages = {1},
keywords = {generative ai, large language models, teaching practice},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3716640.3716647,
author = {Leinonen, Juho and Denny, Paul and Kiljunen, Olli and MacNeil, Stephen and Sarsa, Sami and Hellas, Arto},
title = {LLM-itation is the Sincerest Form of Data: Generating Synthetic Buggy Code Submissions for Computing Education},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716647},
doi = {10.1145/3716640.3716647},
abstract = {There is a great need for data in computing education research. Data is needed to understand how students behave, to train models of student behavior to optimally support students, and to develop and validate new assessment tools and learning analytics techniques. However, relatively few computing education datasets are shared openly, often due to privacy regulations and issues in making sure the data is anonymous. Large language models (LLMs) offer a promising approach to create large-scale, privacy-preserving synthetic data, which can be used to explore various aspects of student learning, develop and test educational technologies, and support research in areas where collecting real student data may be challenging or impractical. This work explores generating synthetic buggy code submissions for introductory programming exercises using GPT-4o. We compare the distribution of test case failures between synthetic and real student data from two courses to analyze the accuracy of the synthetic data in mimicking real student data. Our findings suggest that LLMs can be used to generate synthetic incorrect submissions that are not significantly different from real student data with regard to test case failure distributions. Our research contributes to the development of reliable synthetic datasets for computing education research and teaching, potentially accelerating progress in the field while preserving student privacy.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {56–63},
numpages = {8},
keywords = {generative AI, genAI, large language models, LLMs, GPT-4o, prompt engineering, synthetic data, bugs, submissions, data generation},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3643834.3661515,
author = {Dangol, Aayushi and Newman, Michele and Wolfe, Robert and Lee, Jin Ha and Kientz, Julie A. and Yip, Jason and Pitt, Caroline},
title = {Mediating Culture: Cultivating Socio-cultural Understanding of AI in Children through Participatory Design},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661515},
doi = {10.1145/3643834.3661515},
abstract = {The surge in access to and awareness of Generative Artificial Intelligence (GenAI) such as ChatGPT has sparked discussion over the necessary technological literacies and competencies needed to effectively engage with these systems. In this context, we explore AI as a tool that mediates cultural understanding and remediates human values – that are often influenced by biases and inequities. Using participatory design for learning with a group of 13 children (ages 8-13), we engaged in five co-design sessions featuring different modalities for socio-cultural approaches to AI literacy. We found that children were more aware of the cultural mediation aspect of AI when the content of the interaction aligned with their cultural background and context. This underscored the significance of aligning the representation of culture in these GenAI systems with people’s socio-cultural ecosystems in modern technological literacies. We conclude with design principles for a more critical and holistic approach to AI literacy.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {1805–1822},
numpages = {18},
keywords = {AI Literacy, Cultural mediation, Generative AI, Participatory design},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3649405.3659527,
author = {Clear, Tony and Cajander, \r{A}sa and Clear, Alison and Mcdermott, Roger and Bergqvist, Andreas and Daniels, Mats and Divitini, Monica and Forshaw, Matthew and Humble, Niklas and Kasinidou, Maria and Kleanthous, Styliani and Kultur, Can and Parvini, Ghazaleh and Polash, Mohammad and Zhu, Tingting},
title = {A Plan for a Joint Study into the Impacts of AI on Professional Competencies of IT Professionals and Implications for Computing Students},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659527},
doi = {10.1145/3649405.3659527},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {757–758},
numpages = {2},
keywords = {artificial intelligence, computing competencies, computing curricula, generative ai, it profession, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@article{10.1145/3708520,
author = {Cederbladh, Johan and Cicchetti, Antonio and Jongeling, Robbert},
title = {A Road-Map to Readily Available Early Validation and Verification of System Behaviour in Model-Based Systems Engineering using Software Engineering Best Practices},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708520},
doi = {10.1145/3708520},
abstract = {In this article, we discuss how we can facilitate the growing need for early validation and verification (V&amp;V) of system behaviour in Model-Based Systems Engineering (MBSyE). Several aspects, such as reducing cost and time to market, push companies towards integration of V&amp;V methods earlier in development to support effective decision-making. One foundational methodology seeing increased attention in industry is the use of MBSyE, which brings benefits of models with well-defined syntax and semantics to support V&amp;V activities, rather than relying on natural language text documentation. Despite their promise, industrial adoption of these practices is still challenging.This article presents a vision for readily available early V&amp;V. We present a summary of the literature on early V&amp;V in MBSyE and position existing challenges regarding potential solutions and future investigations towards this vision. We elaborate our vision by means of challenges with a specific emphasis on early V&amp;V of system behaviour. We identify three specific challenge areas: Creating and managing Models, Organisational systems engineering aspects, and early V&amp;V Methods. Finally, we outline a road-map to address these categories of challenges, in which we propose the transfer of established best practices from the software engineering domain to support emerging technologies in the systems engineering domain.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {151},
numpages = {30},
keywords = {Validation, Verification, Models, Early, Systems, Behaviour}
}

@inproceedings{10.1145/3678610.3678630,
author = {Mei-seung, Cheng},
title = {Navigating the “Cooked” Data: A Framework for Understanding GenAI's Impact on Academic Writing and Learning},
year = {2024},
isbn = {9798400716799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678610.3678630},
doi = {10.1145/3678610.3678630},
abstract = {This article explores the integration of Generative AI (GenAI) technologies, such as ChatGPT, Bard, and LaMDA, in academic writing classrooms, examining both their potential to transform learning and the challenges they present. Building on Activity Theory, the study assesses the transformation of students' roles, the writing assistant tool, and the rules and division of labor within the academic community after technology integration. We argue that GenAI, while offering powerful potential for personalized feedback and learning, disrupts traditional educational dynamics. This raises critical questions about student roles, data integrity, and the evolving responsibilities of teachers. We propose eleven research questions to guide future investigations. These questions emphasize the need for a nuanced understanding of how GenAI impacts the learning experience and its implications for academic integrity. We also highlight the ethical considerations surrounding its use. This work aims to contribute to the ongoing conversation surrounding AI in education, promoting a more comprehensive understanding of the opportunities and challenges presented by this transformative technology.},
booktitle = {Proceedings of the 2024 10th International Conference on E-Society, e-Learning and e-Technologies (ICSLT)},
pages = {76–81},
numpages = {6},
keywords = {Academic Integrity, Activity Theory, Generative AI in education, Technology in higher education},
location = {
},
series = {ICSLT '24}
}

@inproceedings{10.1145/3708359.3712164,
author = {Dang, Hai and Lafreniere, Ben and Grossman, Tovi and Todi, Kashyap and Li, Michelle},
title = {Authoring LLM-Based Assistance for Real-World Contexts and Tasks},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712164},
doi = {10.1145/3708359.3712164},
abstract = {Advances in AI hold the possibility of assisting users with highly varied and individual needs, but the breadth of assistance that these systems could provide creates a challenge for how users specify their goals to the system. To support the authoring of AI assistance for real-world tasks, we propose the concept of Contextually-Driven Prompts (CDPs) that define how an AI assistant should respond to real-world context. We implemented a prototype system for authoring and executing CDPs, which provides suggestions to assist users with finding the right level of assistance for their goal. We also conducted a user study (N=10) to investigate how participants express and refine their goals for real-world tasks. Results revealed a number of strategies for initiating and refining CDPs with suggestions, and implications for the design of future authoring interfaces.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {211–230},
numpages = {20},
keywords = {virtual assistants, voice-based interaction, large language model, vision language model, generative AI},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3640310.3674091,
author = {L\'{o}pez, Jos\'{e} Antonio Hern\'{a}ndez and F\"{o}ldi\'{a}k, M\'{a}t\'{e} and Varr\'{o}, D\'{a}niel},
title = {Text2VQL: Teaching a Model Query Language to Open-Source Language Models with ChatGPT},
year = {2024},
isbn = {9798400705045},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640310.3674091},
doi = {10.1145/3640310.3674091},
abstract = {While large language models (LLMs) like ChatGPT has demonstrated impressive capabilities in addressing various software engineering tasks, their use in a model-driven engineering (MDE) context is still in an early stage. Since the technology is proprietary and accessible solely through an API, its use may be incompatible with the strict protection of intellectual properties in industrial models. While there are open-source LLM alternatives, they often lack the power of proprietary models and require extensive data fine-tuning to realize their full potential. Furthermore, open-source datasets tailored for MDE tasks are scarce, posing challenges for training such models effectively.In this work, we introduce Text2VQL, a framework that generates graph queries captured in the VIATRA Query Language (VQL) from natural language specifications using open-source LLMs. Initially, we create a high-quality synthetic dataset comprising pairs of queries and their corresponding natural language descriptions using ChatGPT and VIATRA parser. Leveraging this dataset, we use parameter-efficient tuning to specialize three open-source LLMs, namely, DeepSeek Coder 1b, DeepSeek Coder 7b, and CodeLlama 7b for VQL query generation. Our experimental evaluation demonstrates that the fine-tuned models outperform the base models in query generation, highlighting the usefulness of our synthetic dataset. Moreover, one of the fine-tuned models achieves performance comparable to ChatGPT.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {13–24},
numpages = {12},
keywords = {ChatGPT, VIATRA Query Language (VQL), large language model (LLM), model query language, query generation},
location = {Linz, Austria},
series = {MODELS '24}
}

@inproceedings{10.1145/3641554.3701910,
author = {Gonzalez-Maldonado, David and Liu, Jonathan and Franklin, Diana},
title = {Evaluating GPT for use in K-12 Block Based CS Instruction Using a Transpiler and Prompt Engineering},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701910},
doi = {10.1145/3641554.3701910},
abstract = {Though the increased availability of Large Language Models (LLMs) presents significant potential for change in the way students learn to program, the text-based nature of the available tools currently preclude block-based languages from much of that innovation. In an attempt to remedy this, we identify the strengths and weaknesses of using a transpiler to leverage the existing learning in commercially available LLMs and Scratch, a visual block-based programming language.Using only prompt engineering, we evaluate an LLM's performance on two common classroom tasks in a Scratch curriculum. We evaluate the LLM's ability to: 1) Create project solutions that compile and satisfy project requirements and 2) Analyze student projects' completion of project requirements using natural language. In both cases, we find results indicating that prompt-engineering alone is insufficient to reliably produce high-quality results. For projects of medium complexity, the LLM-generated solutions consistently failed to follow correct syntax or, in the few instances with correct syntax, produce correct solutions. When used for auto-grading, we found a correlation between scores assigned by the official Scratch Encore autograder and those generated by the LLM, nevertheless the discrepancies between the 'real' scores and the scores assigned by the LLM remained too great for the tool to be reliable in a classroom setting.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {388–394},
numpages = {7},
keywords = {block based programming, generative ai, k-12, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3585059.3611431,
author = {Zheng, Yong},
title = {ChatGPT for Teaching and Learning: An Experience from Data Science Education},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611431},
doi = {10.1145/3585059.3611431},
abstract = {ChatGPT, an implementation and application of large language models, has gained significant popularity since its initial release. Researchers have been exploring ways to harness the practical benefits of ChatGPT in real-world scenarios. Educational researchers have investigated its potential in various subjects, e.g., programming, mathematics, finance, clinical decision support, etc. However, there has been limited attention given to its application in data science education. This paper aims to bridge that gap by utilizing ChatGPT in a data science course, gathering perspectives from students, and presenting our experiences and feedback on using ChatGPT for teaching and learning in data science education. The findings not only distinguish data science education from other disciplines but also uncover new opportunities and challenges associated with incorporating ChatGPT into the data science curriculum.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {66–72},
numpages = {7},
keywords = {ChatGPT, data analytics, data science, large language model},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@article{10.1145/3689370,
author = {Rivadeneira, Lucia and Bellido de Luna, Daina and Fernandez, Carla},
title = {Exploring the Role of ChatGPT in Higher Education Institutions: Where does Latin America Stand?},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689370},
doi = {10.1145/3689370},
abstract = {This research examines how stakeholders in higher education institutions in Ecuador, Chile, and Costa Rica are adopting ChatGPT. Unlike existing literature that predominantly focuses on North America, Europe, or Asia, this research shifts the lens to Latin America. Adopting a qualitative approach, the study gathered data through 26 semi-structured interviews with higher education institution decision-makers (9), academic (14), and administrative staff (3), revealing the landscape of ChatGPT adoption and application. The findings show a varied level of ChatGPT adoption across different functions within these institutions, with no apparent contextual differences. While academic staff show a higher level of engagement for enhancing educational and research processes, administrative staff use it to perform day-to-day activities, such as improving writing. The role of ChatGPT in decision-making and transformative policies remains limited. Despite recognising the potential of ChatGPT to enhance education, decision-makers often mention challenges like discerning between human and artificial intelligence-generated content, fostering critical thinking, and addressing student inequalities. Decision-makers agree on the importance of training to tackle these challenges. The study seeks to help develop a strategic agenda for integrating technologies, such as ChatGPT, in Latin American universities.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = aug,
keywords = {Generative artificial intelligence, ChatGPT, Higher education institutions, Latin America}
}

@inproceedings{10.1145/3650212.3680399,
author = {Qiu, Yuxin and Hu, Jie and Zhang, Qian and Yin, Heng},
title = {Calico: Automated Knowledge Calibration and Diagnosis for Elevating AI Mastery in Code Tasks},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680399},
doi = {10.1145/3650212.3680399},
abstract = {Recent advancements in large language models (LLMs) have exhibited promising capabilities in addressing various tasks such as defect detection and program repair. Despite their prevalence, LLMs still face limitations in effectively handling these tasks. Common strategies to adapt them and improve their performance for specific tasks involve fine-tuning models based on user data or employing in-context learning with examples of desired inputs and outputs.    However, they pose challenges for practical adoption due to the need for extensive computational resources, high-quality data, and continuous maintenance. Furthermore, neither strategy can explain or reason about the deficiencies of LLMs in the given tasks.         We propose Calico to address the high cost of fine-tuning, eliminate the necessity for task-specific examples, and provide explanations of LLM deficiency. At the heart of Calico is an evolutionary approach that interleaves knowledge calibration and AI deficiency diagnosis. The key essence of Calico is as follows. First, it focuses on identifying knowledge gaps in LLMs’ program comprehension. Second, it conducts automated code refactoring to integrate the overlooked knowledge into the source code for mitigating those gaps. Third, it employs what-if analysis and counterfactual reasoning to determine a minimum set of overlooked knowledge necessary to improve the performance of LLMs in code tasks.        We have extensively evaluated Calico over 8,938 programs on three most commonly seen code tasks. Our experimental results show that vanilla ChatGPT cannot fully understand code structures. With knowledge calibration, Calico improves it by 20% and exhibits comparable proficiency compared to fine-tuned LLMs. Deficiency diagnosis contributes to 8% reduction in program sizes while ensuring performance. These impressive results demonstrate the feasibility of utilizing a vanilla LLM for automated software engineering (SE) tasks, thereby avoiding the high computational costs associated with a fine-tuned model.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1785–1797},
numpages = {13},
keywords = {Software engineering, large language model, software testing},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@proceedings{10.1145/3643655,
title = {SESoS '24: Proceedings of the 12th ACM/IEEE International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems},
year = {2024},
isbn = {9798400705571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {SESoS 2024 will provide a forum for researchers and practitioners with a forum to exchange ideas and experiences, analyze research and development issues, discuss promising solutions, and propose theoretical foundations for the development and evolution of complex software-intensive systems.},
location = {Lisbon, Portugal}
}

@article{10.1145/3589653,
author = {Mengi, Gopal},
title = {Accessible and Individualized Learning: MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) Cambridge, MA},
year = {2023},
issue_date = {Spring 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {3},
issn = {1528-4972},
url = {https://doi.org/10.1145/3589653},
doi = {10.1145/3589653},
journal = {XRDS},
month = apr,
pages = {58–59},
numpages = {2}
}

@article{10.1145/3539814.3539823,
author = {Wagner, Stefan and Gerosa, Marco A. and Wessel, Mairieli},
title = {Summary of the Third International Workshop on Bots in Software Engineering (BotSE 2021)},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/3539814.3539823},
doi = {10.1145/3539814.3539823},
abstract = {Bots automate tasks in software engineering projects and interact with software developers. Bots have been proposed, for example, for testing, maintenance, and automating bug fixes. The research community has been discussing these bots in the International Workshop on Bots in Software Engineering (BotSE), collocated with ICSE (the International Conference on Software Engineering). The workshop participants share experiences and challenges, discuss new usages of bots, and map out future directions. In this paper, we present a summary of the 3rd edition of the workshop, which comprised nine papers, one journal-first presentation, and two keynotes, followed by extensive discussion. More details can be found at http://botse.org/},
journal = {SIGSOFT Softw. Eng. Notes},
month = jul,
pages = {25–27},
numpages = {3},
keywords = {software bots, open source software, human-bot interaction, github bots, chatbots, collaborative development, automation}
}

@article{10.1145/3678172,
author = {Storey, Margaret-Anne and Russo, Daniel and Novielli, Nicole and Kobayashi, Takashi and Wang, Dong},
title = {A Disruptive Research Playbook for Studying Disruptive Innovations},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {8},
issn = {1049-331X},
url = {https://doi.org/10.1145/3678172},
doi = {10.1145/3678172},
abstract = {As researchers today, we are witnessing a fundamental change in our technologically-enabled world due to the advent and diffusion of highly disruptive technologies such as generative Artificial Intelligence (AI), Augmented Reality (AR) and Virtual Reality (VR). In particular, software engineering has been profoundly affected by the transformative power of disruptive innovations for decades, with a significant impact of technical advancements on social dynamics due to its socio-technical nature. In this article, we reflect on the importance of formulating and addressing research problems in software engineering through a socio-technical lens, thus ensuring a holistic understanding of the complex phenomena in this field. We propose a research playbook with the aim of providing a guide to formulate compelling and socially relevant research questions and to identify the appropriate research strategies for empirical investigations, with an eye on the long-term implications of technologies or their use. We showcase how to apply the research playbook. Firstly, we show how it can be used retrospectively to reflect on a prior disruptive technology, Stack Overflow, and its impact on software development. Secondly, we show how it can be used to question the impact of two current disruptive technologies: AI and AR/VR. Finally, we introduce a specialized GPT model to support the researcher in framing future investigations. We conclude by discussing the broader implications of adopting the playbook for both researchers and practitioners in software engineering and beyond.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
articleno = {195},
numpages = {29},
keywords = {Socio-technical Integration, Disruptive Innovation Evaluation, Empirical Software Engineering, AI-driven Code Generation, AR/VR Collaboration Tools}
}

@inproceedings{10.1145/3706599.3706641,
author = {Nacke, Lennart E.},
title = {How to write higher-quality CHI papers (with AI research tools)},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706641},
doi = {10.1145/3706599.3706641},
abstract = {Writing high-quality research papers is crucial for advancing your academic career. With the advent of generative artificial intelligence (AI) tools, researchers now have novel ways to improve their writing, literature reviews, and overall paper quality. This course, delivered in person at CHI 2025 in Yokohama, Japan, offers a practical exploration of how to use AI tools effectively throughout the research writing process. Over three interactive 75-minute sessions, participants will learn to apply AI tools to edit their writing, brainstorm ideas, and enhance their paper’s readability and impact. Through hands-on activities and peer discussions, attendees will gain the skills needed to produce high-impact CHI papers that meet publication standards. This course emphasizes using AI to support writing, structuring research, and refining contributions, providing attendees with practical tools and insights to succeed in academic publishing in the field of Human-Computer Interaction.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {816},
numpages = {3},
keywords = {Generative AI, Writing, ChatGPT, Publication, Writing, Submission Process, Research Methods},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706598.3714219,
author = {Zheng, Qingxiao and Chen, Minrui and Park, Hyanghee and Xu, Zhongwei and Huang, Yun},
title = {Evaluating Non-AI Experts' Interaction with AI: A Case Study In Library Context},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714219},
doi = {10.1145/3706598.3714219},
abstract = {Public libraries in the U.S. are increasingly facing labor shortages, tight budgets, and overworked staff, creating a pressing need for conversational agents to assist patrons. The democratization of generative AI has empowered public service professionals to develop AI agents by leveraging large language models. To understand the needs of non-AI library professionals in creating their own conversational agents, we conducted semi-structured interviews with library professionals (n=11) across the U.S. Insights from these interviews informed the design of AgentBuilder, a prototype tool that enables non-AI experts to create conversational agents without coding skills. We then conducted think-aloud sessions and follow-up interviews to evaluate the prototype experience and identify the key evaluation criteria emphasized by library professionals (n=12) when developing conversational agents. Our findings highlight how these professionals perceive the prototype experience and reveal five essential evaluation criteria: interpreting user intent, faithful paraphrasing, proper alignment with authoritative sources, tailoring the tone of voice, and handling unknown answers effectively. These insights provide valuable guidance for designing AI-supported "end-user creation tools" in public service domains beyond libraries.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1192},
numpages = {20},
keywords = {End-User AI Creation Tool, User Experience, Large language models, Generative AI, Public Service},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713933,
author = {Lei, Ying and Ma, Shuai and Sun, Yuling and Ma, Xiaojuan},
title = {"AI Afterlife" as Digital Legacy: Perceptions, Expectations, and Concerns},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713933},
doi = {10.1145/3706598.3713933},
abstract = {The rise of generative AI technology has sparked interest in using digital information to create AI-generated agents as digital legacy. These agents, often referred to as “AI Afterlives”, present unique challenges compared to traditional digital legacy. Yet, there is limited human-centered research on “AI Afterlife” as digital legacy, especially from the perspectives of the individuals being represented by these agents. This paper presents a qualitative study examining users’ perceptions, expectations, and concerns regarding AI-generated agents as digital legacy. We identify factors shaping people’s attitudes, their perceived differences compared with the traditional digital legacy, and concerns they might have in real practices. We also examine the design aspects throughout the life cycle and interaction process. Based on these findings, we situate “AI Afterlife” in digital legacy, and delve into design implications for maintaining identity consistency and balancing intrusiveness and support in “AI Afterlife” as digital legacy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {981},
numpages = {18},
keywords = {Generative AI, Agent, Afterlife, Digital Legacy, Perception, Expectation, Concern, Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3626253.3633407,
author = {Westerlund, Jill and Czajka, Sandra and Kuemmel, Andrew},
title = {Innovative Strategies for genAI in CS Courses},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633407},
doi = {10.1145/3626253.3633407},
abstract = {Students are using generative artificial intelligence (genAI), organizations are embracing AI and machine learning, tools are emerging almost daily, and addressing these evolving technologies can be overwhelming. Rather than choosing to ignore genAI, instructors of computer science (CS) can find ways to teach with and guide students in the use of genAI in their courses. Teaching about genAI can be incorporated with instruction about effective and appropriate uses of the ever-growing tools.This special session brings together three experienced CS educators who integrate genAI in their work with high school students, college students, and in-service teachers. The session environment allows for participant involvement in three model activities that showcase genAI tools with learner-focused practices. Participants will be provided supporting teaching resources for each guided activity and encouraged to discuss with peers and presenters.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1875–1876},
numpages = {2},
keywords = {ai, assessment, genai, instruction},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3663548.3675644,
author = {Bennett, Cynthia L and Shelby, Renee and Rostamzadeh, Negar and Kane, Shaun K},
title = {Painting with Cameras and Drawing with Text: AI Use in Accessible Creativity},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3675644},
doi = {10.1145/3663548.3675644},
abstract = {Generative AI (GAI) is proliferating, and among its many applications are to support creative work (e.g., generating text, images, music) and to enhance accessibility (e.g., captions of images and audio). As GAI evolves, creatives must consider how (or how not) to incorporate these tools into their practices. In this paper, we present interviews at the intersection of these applications. We learned from 10 creatives with disabilities who intentionally use and do not use GAI in and around their creative work. Their mediums ranged from audio engineering to leatherwork, and they collectively experienced a variety of disabilities, from sensory to motor to invisible disabilities. We share cross-cutting themes of their access hacks, how creative practice and access work become entangled, and their perspectives on how GAI should and should not fit into their workflows. In turn, we offer qualities of accessible creativity with responsible AI that can inform future research.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {5},
numpages = {19},
keywords = {Accessibility, creativity, disability, generative AI, responsible AI},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@inproceedings{10.1145/3641554.3701916,
author = {Ebert, Jack and Kramarczuk, Kristina},
title = {Leveraging Undergraduate Perspectives to Redefine AI Literacy},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701916},
doi = {10.1145/3641554.3701916},
abstract = {Artificial intelligence (AI) represents the future of the workforce, but existing curricula inadequately prepare students to comprehend and use these new technologies. Despite the push for educators to teach AI literacy, there is a distinct lack of research exploring student perspectives on the topic. Utilizing an explanatory sequential mixed methods research design, we first administered an AI literacy survey to undergraduate students in a computing major to learn how they think about AI, and then conducted focus group interviews after further refining our research questions. There was a discrepancy between undergraduate competence with AI applications and underlying AI principles, which were conflated on the survey and positively influenced overall knowledge. Participant confidence in AI's capability as a learning tool was infrequently limited by perception of personal ability, but rather by beliefs about limitations in AI tool efficacy. Participants believed that students pursuing any field would benefit from AI literacy and that AI literacy education, if implemented effectively, could mitigate concerns with AI pervasion in the workplace. A combination of surveys and assessments will be beneficial when centering students in AI curricula, the former establishing a student's AI confidence and the latter competence.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {290–296},
numpages = {7},
keywords = {ai literacy, artificial intelligence, generative ai},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3644815.3644959,
author = {Xia, Boming and Lu, Qinghua and Zhu, Liming and Lee, Sung Une and Liu, Yue and Xing, Zhenchang},
title = {Towards a Responsible AI Metrics Catalogue: A Collection of Metrics for AI Accountability},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644959},
doi = {10.1145/3644815.3644959},
abstract = {Artificial Intelligence (AI), particularly through the advent of large-scale generative AI (GenAI) models such as Large Language Models (LLMs), has become a transformative element in contemporary technology. While these models have unlocked new possibilities, they simultaneously present significant challenges, such as concerns over data privacy and the propensity to generate misleading or fabricated content. Current frameworks for Responsible AI (RAI) often fall short in providing the granular guidance necessary for tangible application, especially for Accountability---a principle that is pivotal for ensuring transparent and auditable decision-making, bolstering public trust, and meeting increasing regulatory expectations. This study bridges the Accountability gap by introducing our effort towards a comprehensive metrics catalogue, formulated through a systematic multivocal literature review (MLR) that integrates findings from both academic and grey literature. Our catalogue delineates process metrics that underpin procedural integrity, resource metrics that provide necessary tools and frameworks, and product metrics that reflect the outputs of AI systems. This tripartite framework is designed to operationalize Accountability in AI, with a special emphasis on addressing the intricacies of GenAI.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {100–111},
numpages = {12},
keywords = {responsible AI, accountable AI, risk assessment, generative AI},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3626252.3630875,
author = {Ishizue, Ryosuke and Sakamoto, Kazunori and Washizaki, Hironori and Fukazawa, Yoshiaki},
title = {Improved Program Repair Methods using Refactoring with GPT Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630875},
doi = {10.1145/3626252.3630875},
abstract = {Teachers often utilize automatic program repair methods to provide feedback on submitted student code using model answer code. A state-of-the-art tool is Refactory, which achieves a high repair success rate and small patch size (less code repair) by refactoring code to expand the variety of correct code samples that can be referenced. However, Refactory has two major limitations. First, it cannot fix code with syntax errors. Second, it has difficulty fixing code when there are few correct submissions. Herein we propose a new method that combines Refactory and OpenAI's GPT models to address these issues and conduct a performance measurement experiment. The experiment uses a dataset consisting of 5 programming assignment problems and almost 1,800 real-life incorrect Python program submissions from 361 students for an introductory programming course at a large public university. The proposed method improves the repair success rate by 1-21% when the set of correct code samples is sufficient and the patch size is smaller than Refactory alone in 16-45% of the cases. When there was no set of correct code samples at all (only the model answer code was used as a reference for repair), method improves the repair success rate by 1-43% and the patch size is smaller than Refactory alone in 42-68% of the cases.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {569–575},
numpages = {7},
keywords = {generative ai, program repair, programming assignment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@proceedings{10.1145/3584871,
title = {ICSIM '23: Proceedings of the 2023 6th International Conference on Software Engineering and Information Management},
year = {2023},
isbn = {9781450398237},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Palmerston North, New Zealand}
}

@article{10.1145/3665333,
author = {Lucke, J\"{o}rn Von and Frank, Sander},
title = {A few Thoughts on the Use of ChatGPT, GPT 3.5, GPT-4 and LLMs in Parliaments: Reflecting on the results of experimenting with LLMs in the parliamentarian context},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665333},
doi = {10.1145/3665333},
abstract = {Starting in November 2022 with the free provision of ChatGPT, large language models (LLM) are now publicly available. This has significantly increased the number of publications which scopes potential changes caused by the application of generative artificial intelligence (AI) in various societal domains. The private use of AI and the economic integration of generative LLMs have increased significantly. However, for parliamentarians and parliamentary professionals, the technology often remains abstract, impacting everyday work only peripherally. Due to the special responsibility of parliaments, governments, and administrations as the organizational instances of society, and through the inherent legitimations by society itself, there is a necessity to examine the implications of the use of generative LLMs within these institutions and traditional structures as well as their influence on political system logic. The paper analyzes the responses that the generative LLMs GPT 3.5 and GPT 4 have provided via ChatGPT, based on the same input command (prompt) over different times. The responses help to assess how LLMs can be used in the parliamentary context, to reflect what dangers exist as well as to respond to the question on how a business model of an AI department in parliament might look like. Furthermore, it shall be explored whether there are fluctuations in the quality of the responses and how these should be evaluated against the backdrop of the need for accurate and precise workflows in parliamentary operations. Ultimately, the paper aims to provide an answer as to whether the application of ChatGPT together with the LLMs GPT-3.5 and GPT-4 could already deliver this necessary quality and consistency for the parliamentarian working environment today.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = may,
keywords = {large language model, ChatGPT, GPT 3.5, GPT-4, parliament}
}

@inproceedings{10.1145/3706599.3706682,
author = {Sun, Ruixuan and Li, Xinyi and Akella, Avinash and Konstan, Joseph A.},
title = {Multi-Prompting Scenario-based Movie Recommendation with Large Language Models: Real User Case Study},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706682},
doi = {10.1145/3706599.3706682},
abstract = {This paper investigates the potential of using large language models (LLMs) for personalized movie recommendations in an online field experiment. We assess the performance of LLM recommenders using a combination of between-subject prompts, historical consumption patterns, and within-subject recommendation scenarios. Analyzing conversation and survey data from 160 active users, we find that while LLMs excel in providing explainable recommendations, they lack in personalization, diversity, and user trust. Interestingly, personalized prompting techniques do not significantly affect user-perceived recommendation quality, while the number of movies a user has watched plays a more significant role. Furthermore, LLMs demonstrate a stronger ability to recommend lesser-known or niche movies. Through qualitative analysis, we identify key conversational patterns linked to positive and negative user interaction experiences and conclude that providing personal context and examples is crucial for obtaining high-quality recommendations from LLMs. These insights offer practical implications for improving LLM-based RecSys in real-world applications.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {687},
numpages = {12},
keywords = {Large Language Model, Generative AI, Recommender System, Human-AI Interaction},
location = {
},
series = {CHI EA '25}
}

@proceedings{10.1145/3551349,
title = {ASE '22: Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
year = {2022},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rochester, MI, USA}
}

@inproceedings{10.1145/3690712.3690717,
author = {Wang, Yadi and Fussell, Susan R.},
title = {They May Have Seen My ChatGPT Tab: Exploring Social Perceptions of AI-Assisted Writing for ESL Students},
year = {2024},
isbn = {9798400710315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690712.3690717},
doi = {10.1145/3690712.3690717},
abstract = {Many English as a Second Language (ESL) students have begun to use generative artificial intelligence (AI) tools to improve their writing artifacts. In this process, however, ESL students are also facing scrutiny due to the social expectation of independent language acquisition. Therefore, we propose a study design consisting of diary studies and interviews to investigate the ways ESL students perceive and navigate the nuanced social dynamics around using generative AI in their writing. Through this study, we aim to gain a deeper understanding of the social-technical implication of AI usage in second language acquisition, and to offer suggestions to ESL learners and educators on ways to incorporate AI into their educational journey.},
booktitle = {Proceedings of the Third Workshop on Intelligent and Interactive Writing Assistants},
pages = {13–15},
numpages = {3},
location = {Honolulu, HI, USA},
series = {In2Writing '24}
}

@inproceedings{10.1145/3641554.3701867,
author = {Yeh, Thomas Y. and Tran, Karena and Gao, Ge and Yu, Tyler and Fong, Wai On and Chen, Tzu-Yi},
title = {Bridging Novice Programmers and LLMs with Interactivity},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701867},
doi = {10.1145/3641554.3701867},
abstract = {While Large Language Models (LLMs) enable experienced programmers to increase their productivity, LLMs' impact on learning and productivity for novices is currently unclear. Recent work showed novice programmers struggle with prompting LLMs for code generation and suggested that the use of LLMs in CS education could exacerbate existing equity issues. Educators are now faced with the difficult question of whether and when to incorporate the use of LLMs into the CS curriculum without adversely impacting student learning and equity. To address these concerns, we study the effects of using an interactive LLM on code generation with novice programmers. We find that using our interactive LLM improves the accuracy of code generation over the baseline LLM. Additionally, after using the interactive LLM, novices write improved prompts even when using the baseline LLM. Based on our findings, we plan to create iGPTs, a set of customized, interactive LLMs spanning CS education learning goals as templates to facilitate LLM integration for improving student learning and retention.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1295–1301},
numpages = {7},
keywords = {cs1, generative ai, llms, novice programmers},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3696010,
author = {Braun, Daniel},
title = {Why "Artificial Intelligence" Should Not Be Regulated},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696010},
doi = {10.1145/3696010},
abstract = {Lawmakers all over the world have started to draft new regulations for Artificial Intelligence (AI). While the European Union is currently leading the way with its AI Act, many other legislators will follow and already positioned themselves with white papers and other publications. This commentary argues that “Artificial Intelligence”, including Generative AI, should not be used as a regulatory category. Not because there is no potential for harm from AI systems and not because AI systems should not be regulated, but because “Artificial Intelligence” is a vaguely defined label that is neither suitable nor necessary for comprehensive regulation of technological risks. Instead of regulating a particular set of approaches and algorithms, lawmakers should focus and double down on regulating high-risk applications of software, independent of whether it is labelled as AI or not.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = sep,
keywords = {Artificial Intelligence, Generative AI, Regulation, AI Act}
}

@inproceedings{10.1145/3706599.3719762,
author = {Niu, Ruowen and Hu, Jiaxiong and Peng, Siyu and Cao, Caleb Chen and Liu, Chengzhong and Han, Sirui and Guo, Yike},
title = {Scenario, Role, and Persona: A Scoping Review of Design Strategies for Socially Intelligent AI Agents},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719762},
doi = {10.1145/3706599.3719762},
abstract = {As artificial intelligence (AI) agents have often been perceived as social actors, there is a growing expectation for them to demonstrate social intelligence. Social intelligence encompasses the ability of AI agents to align their actions with human intentions and behave in socially and culturally appropriate ways. This study conducts a scoping review to analyze the design strategies employed in current AI agent designs that support the exhibition of social intelligence. Our findings reveal three design strategy themes that interdependently and collectively shape the capabilities and behaviors of AI agents: scenario, role, and persona. These findings provide a structured perspective and actionable insights for designing AI agents that effectively integrate social intelligence into human-AI interactions.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {470},
numpages = {9},
keywords = {AI Agents; Design Strategy; Scoping Review; Social Intelligence},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3689215,
author = {Zlotnikova, Irina and Hlomani, Hlomani},
title = {GenAI in the Context of African Universities: A Crisis of Tertiary Education or Its New Dawn?},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689215},
doi = {10.1145/3689215},
abstract = {The rapid progression of generative artificial intelligence (GenAI) tools has raised significant interest and concern in academia. Instances of students submitting AI-generated assignments prompt investigations into implications for teaching, learning, and academic integrity. Recent publications highlight concerns such as a lack of conceptual understanding, threats to academic integrity, and disruptions to traditional assessment methods. While recognizing benefits like automated scoring and personalized learning, authors stress the responsible use of GenAI, emphasizing the educator's role in guiding students. This commentary identifies opportunities and threats of GenAI in African university contexts. Opportunities include increased operational efficiency, content generation, automated assessment, recognition of accessibility needs, overcoming language barriers, and accelerated research. However, these tools require human correction and cautious consideration of job displacement concerns. Threats encompass job displacement, privacy and security issues, threats to academic integrity, hallucinations/confabulations of GenAI, access and infrastructure challenges, technological overemphasis, lack of customization for local needs and cultural contexts, dependency on external providers, and unaffordable costs. The need for robust guidelines that balance technological advances with traditional teaching methods in African universities is emphasized. Given digital transformation initiatives like the African Union's Agenda 2063 and Botswana's SmartBots strategy, integrating GenAI could shape the future of African tertiary education. Proactive policies should address ethical concerns, ensure access, and make GenAI tools available, requiring a collaborative effort to navigate its impact responsibly.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = aug,
keywords = {Generative artificial intelligence, universities, African countries}
}

@inproceedings{10.1145/3652620.3687805,
author = {Netz, Lukas and Reimer, Jan and Rumpe, Bernhard},
title = {Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687805},
doi = {10.1145/3652620.3687805},
abstract = {Low-code development platforms (LCDPs) are becoming increasingly important in industry, which confronts us in academic teaching with the challenge of educating students in the basic principles, critical engagement, and evaluation of LCDPs. This leads us to the question, how to teach the usage of different LCDPs during an university course. The short time frame of university-level courses makes it challenging to teach more than only one LCDP. In our teaching approach, students use two different LCDPs and create a web-application with both of them. Firstly, we require the students to define a target application with common modeling languages, next they use the first LCDP, at about half the time they switch to the second LCDP and present their findings of the differences in methodology and development processes at the end. We discuss this approach, show survey results from the participants, and explain lessons learned. This concept allows students critical engagement with LCDPs and model-driven software engineering. Supervisors get an insight into the learnability of each LCDP and how novices adapt to different domain-specific languages and their notations.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {115–122},
numpages = {8},
keywords = {low-code development platforms, education, university-level courses, model-driven software engineering, problem-based learning},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3568812.3603487,
author = {Akram, Bita and Magooda, Ahmed},
title = {Analysis of Students’ Problem-Solving Behavior when Using Copilot for Open-Ended Programming Projects},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603487},
doi = {10.1145/3568812.3603487},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {32},
numpages = {1},
keywords = {CS1, Copilot, generative AI in CS education, introductory programming classrooms},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@article{10.1145/3705734,
author = {George, Amrita and Storey, Veda Catherine and Hong, Shuguang},
title = {Unraveling the Impact of ChatGPT as a Knowledge Anchor in Business Education},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3705734},
doi = {10.1145/3705734},
abstract = {The emergence of Large Language Models (LLM), such as ChatGPT, is considered a productivity revolution in many areas of business and society. For a classroom setting, especially, it would be useful to understand whether, and how, to incorporate ChatGPT, similar to any other productivity revolution technology, such as calculators or a Google search engine. Although there are concerns regarding the use of LLMs in business education, the positive or negative impact of LLM use is not well-understood. In this research, we examine the substitution and complementarity effects of using ChatGPT in business curricula on learning outcomes and well-being in a socially supportive learning environment. Specifically, we examine whether technology anchors impact students’ goal orientation, learning outcomes, and well-being by conducting an empirical study with students majoring in Information Systems. Our analysis reveals that a technology anchor (computer playfulness) can complement the effects of social support on learning outcomes, while enhancing well-being for simple tasks. Students’ well-being and learning outcomes are hindered by LLM use (specifically, the computer anxiety anchor), substituting social support for simple and difficult tasks. These findings have implications for educational institutions that are assessing how to incorporate LLMs into business curricula.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {4},
numpages = {30},
keywords = {ChatGPT, Large language model (LLM), technology self-efficacy, computer anxiety, goal orientation, computer playfulness, social support, technology anchors, generative AI, knowledge anchor, OpenAI, technology anchors, artificial intelligence (AI), achievement theory}
}

@inproceedings{10.1145/3680533.3697064,
author = {Feng, Tony Haoran and Denny, Paul and W\"{u}nsche, Burkhard C. and Luxton-Reilly, Andrew and Whalley, Jacqueline},
title = {An Eye for an AI: Evaluating GPT-4o's Visual Perception Skills and Geometric Reasoning Skills Using Computer Graphics Questions},
year = {2024},
isbn = {9798400711367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680533.3697064},
doi = {10.1145/3680533.3697064},
abstract = {CG (Computer Graphics) is a popular field of CS (Computer Science), but many students find this topic difficult due to it requiring a large number of skills, such as mathematics, programming, geometric reasoning, and creativity. Over the past few years, researchers have investigated ways to harness the power of GenAI (Generative Artificial Intelligence) to improve teaching. In CS, much of the research has focused on introductory computing. A recent study evaluating the performance of an LLM (Large Language Model), GPT-4 (text-only), on CG questions, indicated poor performance and reliance on detailed descriptions of image content, which often required considerable insight from the user to return reasonable results. So far, no studies have investigated the abilities of LMMs (Large Multimodal Models), or multimodal LLMs, to solve CG questions and how these abilities can be used to improve teaching.In this study, we construct two datasets of CG questions requiring varying degrees of visual perception skills and geometric reasoning skills, and evaluate the current state-of-the-art LMM, GPT-4o, on the two datasets. We find that although GPT-4o exhibits great potential in solving questions with visual information independently, major limitations still exist to the accuracy and quality of the generated results. We propose several novel approaches for CG educators to incorporate GenAI into CG teaching despite these limitations. We hope that our guidelines further encourage learning and engagement in CG classrooms.},
booktitle = {SIGGRAPH Asia 2024 Educator's Forum},
articleno = {5},
numpages = {8},
keywords = {Large Language Models, LLMs, Large Multimodal Models, LMMs, Visual Language Models, VLMs, Generative Artificial Intelligence, GenAI, GPT-4, GPT-4o, Visual Perception, Geometric Reasoning, Computer Graphics, Computing Education, Evaluation, Assessment},
location = {
},
series = {SA '24}
}

@article{10.1145/3694681,
author = {Chen, Chen and Nguyen, Cuong and Groueix, Thibault and Kim, Vladimir G. and Weibel, Nadir},
title = {MemoVis: A GenAI-Powered Tool for Creating Companion Reference Images for 3D Design Feedback},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {5},
issn = {1073-0516},
url = {https://doi.org/10.1145/3694681},
doi = {10.1145/3694681},
abstract = {Providing asynchronous feedback is a critical step in the 3D design workflow. A common approach to providing feedback is to pair textual comments with companion reference images, which helps illustrate the gist of text. Ideally, feedback providers should possess 3D and image editing skills to create reference images that can effectively describe what they have in mind. However, they often lack such skills, so they have to resort to sketches or online images that might not match well with the current 3D design. To address this, we introduce MemoVis, a text editor interface that assists feedback providers in creating reference images with generative AI driven by the feedback comments. First, a novel real-time viewpoint suggestion feature, based on a vision-language foundation model, helps feedback providers anchor a comment with a camera viewpoint. Second, given a camera viewpoint, we introduce three types of image modifiers based on pre-trained 2D generative models to turn a text comment into an updated version of the 3D scene from that viewpoint. We conducted a within-subjects study with  (14)  feedback providers, demonstrating the effectiveness of MemoVis. The quality and explicitness of the companion images were evaluated by another eight participants with prior 3D design experience.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = nov,
articleno = {67},
numpages = {41},
keywords = {3D Design Feedback, Reference Images, Tools for Asynchronous Design Collaborations, Applications of Generative AI and Vision-Language Foundation Models}
}

@inproceedings{10.1145/3545947.3576285,
author = {Kumar, Harsh and Yu, Kunzhi and Chung, Andrew and Shi, Jiakai and Williams, Joseph Jay},
title = {Exploring The Potential of Chatbots to Provide Mental Well-being Support for Computer Science Students},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3576285},
doi = {10.1145/3545947.3576285},
abstract = {Computer Science students are affected by a number of stressors, such as competition, which make it difficult for them to manage their mental well-being and mood. Students are often reluctant to use existing resources for support because they are difficult to access or perceived as ineffective. Conversational agents have shown potential to provide accessible and effective support to improve well-being. In this work, we explore the problem space to identify contexts in which chatbots could be beneficial for students and investigate how different types of chatbot could supplement existing resources provided by universities.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1339},
numpages = {1},
keywords = {chatbots, field study, gpt-3, large language models, mental well-being, stress},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3613904.3642166,
author = {Mack, Kelly Avery and Qadri, Rida and Denton, Remi and Kane, Shaun K. and Bennett, Cynthia L.},
title = {“They only care to show us the wheelchair”: disability representation in text-to-image AI models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642166},
doi = {10.1145/3613904.3642166},
abstract = {This paper reports on disability representation in images output from text-to-image (T2I) generative AI systems. Through eight focus groups with 25 people with disabilities, we found that models repeatedly presented reductive archetypes for different disabilities. Often these representations reflected broader societal stereotypes and biases, which our participants were concerned to see reproduced through T2I. Our participants discussed further challenges with using these models including the current reliance on prompt engineering to reach satisfactorily diverse results. Finally, they offered suggestions for how to improve disability representation with solutions like showing multiple, heterogeneous images for a single prompt and including the prompt with images generated. Our discussion reflects on tensions and tradeoffs we found among the diverse perspectives shared to inform future research on representation-oriented generative AI system evaluation metrics and development processes.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {288},
numpages = {23},
keywords = {AI harms, algorithmic harms, disability representation, generative AI, human-centered AI, text-to-image models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3706468.3706539,
author = {Zhu, Wangda and Xing, Wanli and Lyu, Bailing and Li, Chenglu and Zhang, Fan and Li, Hai},
title = {Bridging the Gender Gap: The Role of AI-Powered Math Story Creation in Learning Outcomes},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706539},
doi = {10.1145/3706468.3706539},
abstract = {Addressing the gender gap in K-12 math education is essential for providing equitable learning opportunities, as historical disparities in engagement, performance, and confidence between male and female students in mathematics are often linked to educational biases. Integrating Generative AI (GAI) into math education shows promise for bridging the gender gap in K12 math learning. This study proposes an innovative pedagogy and platform that enables students to create math stories powered by GAI, enhancing their conceptual understanding of key mathematical ideas. The platform was implemented in two K5 schools to evaluate its effectiveness and mechanism (N = 86). Pre- and post-intervention surveys and usage logs indicated significant improvements in students’ learning outcomes regarding Math Question (MQ) skills and Math Story (MS) skills. Bayes SEM further modeled the mechanism: students’ creating math stories powered by GAI significantly improves MS, which further improves MQ. We further found female students were significantly more engaged in creating stories on this platform and gained more improvement on MQ than male students. The results suggest that AI-powered math story creation can be an effective tool for deepening students’ mathematical learning outcomes and has the potential to mitigate the gender gap.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {918–923},
numpages = {6},
keywords = {Gender gap, Generative AI, Math story, Learning outcomes},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3593342.3593360,
author = {Rajabi, Parsa and Taghipour, Parnian and Cukierman, Diana and Doleck, Tenzin},
title = {Exploring ChatGPT’s impact on post-secondary education: A qualitative study},
year = {2023},
isbn = {9798400707896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593342.3593360},
doi = {10.1145/3593342.3593360},
abstract = {As Chat Generative Pre-trained Transformer (ChatGPT) gains traction, its impact on post-secondary education is increasingly being debated. This qualitative study explores the perception of students and faculty members at a research university in Canada regarding ChatGPT’s use in a post-secondary setting, focusing on how it could be incorporated and what ways instructors can respond to this technology. We present the summary of a discussion that took place in a two-hour focus group session with 40 participants from the computer science and engineering departments, and highlight issues surrounding plagiarism, assessment methods, and the appropriate use of ChatGPT. Findings suggest that students are likely to use ChatGPT, but there is a need for specific guidelines, more classroom assessments, and mandatory reporting of ChatGPT use. The study contributes to the emergent research on ChatGPT in higher education and emphasizes the importance of proactively addressing challenges and opportunities associated with ChatGPT adoption and use.},
booktitle = {Proceedings of the 25th Western Canadian Conference on Computing Education},
articleno = {9},
numpages = {6},
keywords = {post-secondary, higher education, education, conversational AI, assessment, ChatGPT, Artificial Intelligence in education},
location = {Vancouver, BC, Canada},
series = {WCCCE '23}
}

@inproceedings{10.1145/3641555.3705215,
author = {Niousha, Rose and O'Neill, Abigail and Chen, Ethan and Malhotra, Vedansh and Akram, Bita and Norouzi, Narges},
title = {LLM-KCI: Leveraging Large Language Models to Identify Programming Knowledge Components},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705215},
doi = {10.1145/3641555.3705215},
abstract = {Identifying Knowledge Components (KCs) in computer science education improves curriculum design and teaching strategies. We introduce a framework using Large Language Models to identify KCs from programming assignments automatically. Our framework helps educators align assignments with course objectives. GPT-4 identifies relevant KCs well, though there's a low match with expert-generated KCs at the course level. At the problem level, performance is lower, but key KCs are reasonably identified.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1557–1558},
numpages = {2},
keywords = {cs1, knowledge component, large language model},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3714154,
author = {Zamfirescu-Pereira, J.D. and Jun, Eunice and Terry, Michael and Yang, Qian and Hartmann, Bjoern},
title = {Beyond Code Generation: LLM-supported Exploration of the Program Design Space},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714154},
doi = {10.1145/3706598.3714154},
abstract = {In this work, we explore explicit Large Language Model (LLM)-powered support for the iterative design of computer programs. Program design, like other design activity, is characterized by navigating a space of alternative problem formulations and associated solutions in an iterative fashion. LLMs are potentially powerful tools in helping this exploration; however, by default, code-generation LLMs deliver code that represents a particular point solution. This obscures the larger space of possible alternatives, many of which might be preferable to the LLM’s default interpretation and its generated code. We contribute an IDE that supports program design through generating and showing new ways to frame problems alongside alternative solutions, tracking design decisions, and identifying implicit decisions made by either the programmer or the LLM. In a user study, we find that with our IDE, users combine and parallelize design phases to explore a broader design space—but also struggle to keep up with LLM-originated changes to code and other information overload. These findings suggest a core challenge for future IDEs that support program design through higher-level instructions given to LLM-based agents: carefully managing attention and deciding what information agents should surface to program designers and when.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {153},
numpages = {17},
keywords = {Program design, Code generation, Design space exploration, Generative AI, LLMs},
location = {
},
series = {CHI '25}
}

@proceedings{10.1145/3584748,
title = {EBIMCS '22: Proceedings of the 2022 5th International Conference on E-Business, Information Management and Computer Science},
year = {2022},
isbn = {9781450397827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hong Kong, Hong Kong}
}

@inproceedings{10.1145/3631991.3632024,
author = {Chen, Shunxing and Xu, Xiaoshu and Zhang, Huanhuan and Zhang, Yunfeng},
title = {Roles of ChatGPT in virtual teaching assistant and intelligent tutoring system: opportunities and challenges},
year = {2023},
isbn = {9798400708053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631991.3632024},
doi = {10.1145/3631991.3632024},
abstract = {Artificial Intelligence (AI), specifically the Generative Pre-trained Transformer 4 (GPT-4), or ChatGPT, promises to revolutionize Virtual Teaching Assistants (VTAs) and Intelligent Tutoring Systems (ITS). This advanced language model fosters enhanced student engagement and personalized, adaptive learning experiences. However, amidst the substantial benefits, several critical challenges encompassing response reliability, data privacy, algorithmic biases, and interpretability necessitate deliberate scrutiny. The proposed study aims to examine the opportunities and hurdles inherent to the deployment of ChatGPT in the educational landscape. With a focus on high-quality, Google Scholar, Scopus, and Web of Science-indexed literature, the review encompasses a comprehensive exploration of empirical studies, theoretical perspectives, and practical implications related to ChatGPT. Through this literature review, we will shed light on the dynamic intersection of AI and education. The elucidation of nuanced implications will empower educators, policymakers, and AI developers to make informed decisions and devise effective strategies, thereby facilitating an optimized integration of ChatGPT into the educational ecosystem.},
booktitle = {Proceedings of the 2023 5th World Symposium on Software Engineering},
pages = {201–206},
numpages = {6},
keywords = {ChatGPT, challenges, education, intelligent tutoring systems, opportunities, virtual teaching assistants},
location = {Tokyo, Japan},
series = {WSSE '23}
}

@inproceedings{10.1145/3585059.3611445,
author = {Mosaiyebzadeh, Fatemeh and Pouriyeh, Seyedamin and Parizi, Reza and Dehbozorgi, Nasrin and Dorodchi, Mohsen and Mac\^{e}do Batista, Daniel},
title = {Exploring the Role of ChatGPT in Education: Applications and Challenges},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611445},
doi = {10.1145/3585059.3611445},
abstract = {The development of ChatGPT as a sophisticated artificial intelligence technology has impacted numerous sectors, including education and research. The ChatGPT is a powerful large language model that allows students and educators to take advantage of many opportunities, such as personalized learning, lesson planning, and task reduction. While ChatGPT has the potential to streamline pedagogy and research, it poses a variety of challenges, such as allowing cheating on exams and homework, which puts students’ problem-solving skills at risk. Also, ChatGPT creates text that looks like human text, so cheating can be difficult to detect. In this paper, we explore the potential opportunities of ChatGPT in the education sector, as well as its limitations and challenges.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {84–89},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, Education, Large Language Model, OpenAI},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@inproceedings{10.1145/3630106.3658898,
author = {Goetze, Trystan S.},
title = {AI Art is Theft: Labour, Extraction, and Exploitation: Or, On the Dangers of Stochastic Pollocks},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658898},
doi = {10.1145/3630106.3658898},
abstract = {Since the launch of applications such as dall•e, Midjourney, and Stable Diffusion, generative artificial intelligence has been controversial as a tool for creating artwork. Some writers have presented worries about these technologies as harbingers of fully automated futures to come, but more pressing is the impact of generative AI on creative labour in the present. Already, business leaders have begun replacing human artistic labour with AI-generated images. In response, the artistic community has launched a protest movement, which argues that AI image generation is a kind of theft. This paper analyzes, substantiates, and critiques these arguments, concluding that AI image generators involve an unethical kind of labour theft. If correct, many other AI applications also rely upon theft.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {186–196},
numpages = {11},
keywords = {AI ethics, John Locke, automation, computer art, computer ethics, data colonialism, diffusion models, generative AI, intellectual property, labour, philosophy, text-to-image AI},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3663433.3663435,
author = {Behboudi, Atefeh and Adefisayo, Adenike Omolara and Arastoopour Irgens, Golnaz},
title = {Promoting Critical Consciousness in Students through Artifacts Co-creation with GAI},
year = {2024},
isbn = {9798400717222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663433.3663435},
doi = {10.1145/3663433.3663435},
abstract = {The integration of digital technologies in education offers opportunities to foster critical thinking among students. However, their application in fostering critical consciousness remains largely unexplored. This work-in-progress proposes a study to explore the role of Generative Artificial Intelligence (GAI) in promoting critical consciousness, which is the ability to recognize and take action against inequality and injustice, among middle school students.&nbsp; Framed by Constructionism theory, this study will explore designed activities where students will collaboratively use GAI to create meaningful artifacts addressing social issues. Through a curriculum embedded with GAI-driven activities, students will engage in dialogues, collaborative projects, and reflective practices on environmental injustice. The collaboration with GAI will result in the co-creation of artifacts. Qualitative methods centering on reflective interviews will shed light on students’ collaborative co-creative processes to understand how these experiences influence their perspectives and critical thinking abilities.},
booktitle = {Proceedings of the 2024 Symposium on Learning, Design and Technology},
pages = {26–29},
numpages = {4},
keywords = {Co-creation, Critical consciousness, Generative Artificial Intelligence, Technology appropriation},
location = {Delft, Netherlands},
series = {LDT '24}
}

@inproceedings{10.1145/3691620.3695510,
author = {Yan, Chuan and Ren, Ruomai and Meng, Mark Huasong and Wan, Liuhuo and Ooi, Tian Yang and Bai, Guangdong},
title = {Exploring ChatGPT App Ecosystem: Distribution, Deployment and Security},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695510},
doi = {10.1145/3691620.3695510},
abstract = {ChatGPT has enabled third-party developers to create plugins to expand ChatGPT's capabilities. These plugins are distributed through OpenAI's plugin store, making them easily accessible to users. With ChatGPT as the backbone, this app ecosystem has illustrated great business potential by offering users personalized services in a conversational manner. Nonetheless, many crucial aspects regarding app development, deployment, and security of this ecosystem have yet to be thoroughly studied in the research community, potentially hindering a broader adoption by both developers and users. In this work, we conduct the first comprehensive study of the ChatGPT app ecosystem, aiming to illuminate its landscape for our research community. Our study examines the distribution and deployment models in the integration of LLMs and third-party apps, and assesses their security and privacy implications. We uncover an uneven distribution of functionality among ChatGPT plugins, highlighting prevalent and emerging topics. We also identify severe flaws in the authentication and user data protection for third-party app APIs integrated within LLMs, revealing a concerning status quo of security and privacy in this app ecosystem. Our work provides insights for the secure and sustainable development of this rapidly evolving ecosystem.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1370–1382},
numpages = {13},
keywords = {large language model, testing, security, deployment},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3649217.3653626,
author = {Denzler, Benjamin and Vahid, Frank and Pang, Ashley and Salloum, Mariam},
title = {Style Anomalies Can Suggest Cheating in CS1 Programs},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653626},
doi = {10.1145/3649217.3653626},
abstract = {Student cheating on at-home programming assignments is a well- known problem. A key contributor is externally-obtained solutions from websites, contractors, and recently generative AI. In our experience, such externally-obtained solutions often use coding styles that depart from a class' style, which we call "style anomalies," such as using untaught or advanced constructs like pointers or ternary operators, or having different indenting or brace usage from the class style. We developed a tool to auto-count style anomalies. For six labs across four terms in 2021-2022, and 50 sampled students per lab, we found 18% of submissions on average had unusually-high style anomaly counts. Importantly, 8% of submissions on average had a high style anomaly count but were not flagged by a similarity checker, meaning 8% of submissions are suspicious but might have been missed if using similarity checking alone. We repeated a similar analysis for Spring 2023 when generative AI (ChatGPT) was gaining popularity, and the numbers rose to 26% and 18%, respectively. Detailed investigations by instructors led to a majority (but not all) high style anomaly submissions being deemed cheating. Even for high-similarity submissions, counting style anomalies can help instructors focus investigations on the most-likely cheating cases, and can strengthen cases sent to student conduct offices. With the rise of externally-obtained solutions from websites, contractors, and generative AI, counting style anomalies may become an increasingly important complement to similarity checking; in fact, it is now the primary cheat-detection tool in our CS1 at a large state university, with similarity secondary.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {381–387},
numpages = {7},
keywords = {cheating, cs1, plagiarism, program autograders, program style},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3674805.3695401,
author = {Esposito, Matteo and Palagiano, Francesco and Lenarduzzi, Valentina and Taibi, Davide},
title = {Beyond Words: On Large Language Models Actionability in Mission-Critical Risk Analysis},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3695401},
doi = {10.1145/3674805.3695401},
abstract = {Context. Risk analysis assesses potential risks in specific scenarios. Risk analysis principles are context-less; the same methodology can be applied to a risk connected to health and information technology security. Risk analysis requires a vast knowledge of national and international regulations and standards and is time and effort-intensive. A large language model can quickly summarize information in less time than a human and can be fine-tuned to specific tasks. Aim. Our empirical study aims to investigate the effectiveness of Retrieval-Augmented Generation and fine-tuned LLM in Risk analysis. To our knowledge, no prior study has explored its capabilities in risk analysis. Method. We manually curated 193 unique scenarios leading to 1283 representative samples from over 50 mission-critical analyses archived by the industrial context team in the last five years. We compared the base GPT-3.5 and GPT-4 models versus their Retrieval-Augmented Generation and fine-tuned counterparts. We employ two human experts as competitors of the models and three other three human experts to review the models and the former human expert’s analysis. The reviewers analyzed 5,000 scenario analyses. Results and Conclusions. HEs demonstrated higher accuracy, but LLMs are quicker and more actionable. Moreover, our findings show that RAG-assisted LLMs have the lowest hallucination rates, effectively uncovering hidden risks and complementing human expertise. Thus, the choice of model depends on specific needs, with FTMs for accuracy, RAG for hidden risks discovery, and base models for comprehensiveness and actionability. Therefore, experts can leverage LLMs for an effective complementing companion in risk analysis within a condensed timeframe. They can also save costs by averting unnecessary expenses associated with implementing unwarranted countermeasures.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {517–527},
numpages = {11},
keywords = {Actionability, Analysis, Explainability, Fine-Tuning, Generative AI, Human Experts, Large Language Model, Management, Retrieval Augmented Generation, Risk, Security, Standards, XAI},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3706598.3713670,
author = {Glazko, Kate and Cha, JunHyeok and Lewis, Aaleyah and Kosa, Ben and Wimer, Brianna L and Zheng, Andrew and Zheng, Yiwei and Mankoff, Jennifer},
title = {Autoethnographic Insights from Neurodivergent GAI “Power Users”},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713670},
doi = {10.1145/3706598.3713670},
abstract = {Generative AI (AI) has become ubiquitous in both daily and professional life, with emerging research demonstrating its potential as a tool for accessibility. Neurodivergent people, often left out by existing accessibility technologies, develop their own ways of navigating normative expectations. GAI offers new opportunities for access, but it is important to understand how neurodivergent “power users”—successful early adopters—engage with it and the challenges they face. Further, we must understand how marginalization and intersectional identities influence their interactions with GAI. Our autoethnography, enhanced by privacy-preserving GAI-based diaries and interviews, reveals the intricacies of using GAI to navigate normative environments and expectations. Our findings demonstrate how GAI can both support and complicate tasks like code-switching, emotional regulation, and accessing information. We show that GAI can help neurodivergent users to reclaim their agency in systems that diminish their autonomy and self-determination. However, challenges such as balancing authentic self-expression with societal conformity, alongside other risks, create barriers to realizing GAI’s full potential for accessibility.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {274},
numpages = {19},
keywords = {auto-ethnography; generative artificial intelligence; accessibility; neurodivergent people; intersectionality; stigma},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3589335.3652003,
author = {Wei, Zheng and Xu, Xian and Hui, Pan},
title = {Digital Democracy at Crossroads: A Meta-Analysis of Web and AI Influence on Global Elections},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3652003},
doi = {10.1145/3589335.3652003},
abstract = {2024 will be the largest election year in history involving over 50 countries and approximately 4.2 billion people. Since 1996, the Web has been instrumental in political campaigns, enhancing public engagement and creating new communication avenues for elections. Nevertheless, the proliferation of generative AI technologies has made false information dissemination simpler and quicker, posing a substantial threat to election integrity and democratic processes. The 2024 global elections underscore the need to comprehend and tackle the impact of such technologies on democracy. In this paper, we undertake a detailed meta-analysis, scrutinizing 44 papers published in The Web Conference, detailing the influence of the Web on elections. Our research reveals key historical trends on how the Web has impacted elections: first, social media has revolutionized election strategies through direct voter-candidate interactions. Second, big data and algorithm-driven campaigns are commonplace. Third, AI advancements have exacerbated the spread of fake news, risking election fairness. Predominantly from studies published since 2018 among 44 papers, we underscore the necessity for advanced detection tools, policy formulation, and responsible AI use to maintain electoral integrity. This analysis offers an insight into the Web and AI's impact on elections, presenting pointers for addressing challenges and leveraging opportunities in the 2024 and future elections.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1126–1129},
numpages = {4},
keywords = {democratic election, false information, generative ai, social media, the web conference},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1613/jair.1.17175,
author = {Sowa, Konrad and Przegalinska, Aleksandra},
title = {From Expert Systems to Generative Artificial Experts: A New Concept for Human-AI Collaboration in Knowledge Work},
year = {2025},
issue_date = {May 2025},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {82},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.17175},
doi = {10.1613/jair.1.17175},
abstract = {This paper introduces Generative Artificial Experts (GAEs) - a concept of a new type of generative AI agents designed for human-AI collaboration in knowledge work. GAEs have specialized domain expertise, perform tasks within bounded autonomy, include a synthetic persona and possess multimodal generative AI capabilities, among other features. We provide a definition of GAEs which includes seven defining traits, offering a taxonomy which sets them apart from other generative AI systems. We use literature-review based conceptual analysis with abductive reasoning to propose the new concept that addresses identified limitations in existing systems. The paper explores the emergence of GAEs as a leap from expert systems. We name two enablers for GAEs - ongoing development of a research field of human-AI collaboration and growing capabilities of generative artificial intelligence systems. We discuss existing generative AI agents, noting that GAEs as such do not exist yet, but are starting to emerge. Due conceptual nature of this paper we do not explore the technical aspects of GAEs development. Instead, we use illustrative examples to present possible applications of GAEs and their potential role in the future of knowledge work.
This article appears in the AI &amp; Society track.},
journal = {J. Artif. Int. Res.},
month = apr,
numpages = {24},
keywords = {Hybrid Intelligence, Human-Computer Interaction, System Design}
}

@inproceedings{10.1145/3613905.3648110,
author = {Tang, Haoheng and Singha, Mrinalini},
title = {A Mystery for You: A fact-checking game enhanced by large language models (LLMs) and a tangible interface},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3648110},
doi = {10.1145/3613905.3648110},
abstract = {Fact-checking and critical thinking are essential life skills in an age of rampant misinformation. To cultivate these skills in young learners, we have developed ‘A Mystery for You’ – an educational game powered by a large language model (LLM) and a tangible interface. In this game, a player becomes a citizen fact-checker, responding to ‘news alerts’ printed out by the game interface. The player investigates various actors and evidence by inserting cartridge combinations into the game interface. Each move the player makes results in the generation and printing of a follow-up ‘news update,’ which they must use to make an informed verdict about the truth or falsehood of the news. This interactive process sharpens critical thinking skills and enhances familiarity with generative AI’s misinformation capacities. This paper contextualizes the game’s relevance in today’s media and politics, explores game-play mechanics, and critically reflects on incorporating AI generation tools for educational game play.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {631},
numpages = {5},
keywords = {Digital Literacy, Generative AI, Investigation, Misinformation, Role-Playing, Tangible Interface, Young Learners},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3641555.3705132,
author = {Blasco, I\~{n}aki and Mochetti, Karina},
title = {Assessing the Influence of ChatGPT on Student Outcomes in a Models of Computing Course},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705132},
doi = {10.1145/3641555.3705132},
abstract = {This study investigates the impact of ChatGPT on student performance in a Models of Computing course, foundational for the computer science major. Analysing data from 11 pre-lecture quizzes across four terms, we found a decline in average quiz scores, particularly in the latest term. The results suggest a correlation between increased reliance on ChatGPT and decreased student performance, especially on challenging questions where the AI frequently struggled. These findings highlight both the benefits and challenges of integrating AI in education. Our ongoing research aims to explore this further across multiple courses, ultimately promoting responsible AI use to enhance learning outcomes.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1389–1390},
numpages = {2},
keywords = {computing education, llm, student performance},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3701625.3701684,
author = {Oran, Ana Carolina and Montenegro, Let\'{\i}cia Braga and Schuster, Hellmut Alencar and Duarte, Jos\'{e} Carlos and Silva, Williamson and Lima, Rayfran Rocha},
title = {Integrating ChatGPT in Project Management Education: Benefits and Challenges in the Academic Environment},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701684},
doi = {10.1145/3701625.3701684},
abstract = {CONTEXT: Teaching project management is complex, and students often do not feel engaged or motivated. Professors can use many initiatives to improve the teaching and learning process. Tools like ChatGPT, when integrated into education, have generated considerable interest due to their potential to enrich students’ learning experiences. GOAL: This paper analyzes the impacts of using ChatGPT as a complementary tool in teaching Project Management in the Software Engineering course, highlighting its benefits and challenges. METHOD: We performed an exploratory study to identify the effects of using ChatGPT in teaching project management, evaluating learning, productivity, teamwork, student perceptions, and future expectations. RESULTS: The results indicate that ChatGPT contributed to improving content comprehension, developing critical skills, accelerating production, improving collaboration and communication, and increasing student engagement. However, challenges related to misuse and dependence on the tool were also identified. CONCLUSION: The integration of ChatGPT in teaching project management has shown promise, promoting a richer and more collaborative learning experience. The insights obtained provide directions for future implementations and research on the use of AI in project management education.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {596–604},
numpages = {9},
keywords = {Project management education, Software project management, ChatGPT, AI-assisted learning, Software engineering},
location = {
},
series = {SBQS '24}
}

@proceedings{10.1145/3544902,
title = {ESEM '22: Proceedings of the 16th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement},
year = {2022},
isbn = {9781450394277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Helsinki, Finland}
}

@inproceedings{10.1145/3626253.3633418,
author = {Gunawardena, Ananda and Chaturvedi, Naina},
title = {AI Enhanced Learning: Powering Curated Videos with Generative Intelligence},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633418},
doi = {10.1145/3626253.3633418},
abstract = {Instructional videos are becoming increasingly popular among computer science students. Over 78% of students frequently visit YouTube to find videos as supplement to their textbook or classroom instruction[1]. Recent surveys show that on average, 73% of students prefer having their instructors curate a supplemental video library to aid in their learning. Now, the emergence of generative AI is revolutionizing supplemental video instruction, enabling instructors to generate slides, recording scripts, and produce high-quality videos with deep search and embedded interactive activities.Generative AI also takes the student video learning to a new level by providing AI-generated video summaries, on-demand questions, and exploration of topics in greater depth. Integrating AI into standard videos greatly expands the possibilities of video-based learning. This workshop demonstrates how educators can enhance their existing video playlists by incorporating AI to increase student engagement and establish safety measures for AI use in education. By using dynamic dashboards, scheduled content, and gamified questions, instructors can maintain student focus.Drawing on insights from computer science courses taught at Princeton and Rutgers Universities, we will highlight the transformative potential of AI-enhanced videos in promoting active learning, particularly in large classes. We will discuss engagement strategies and real-time data visualizations applicable to any video platform. We will utilize the cubits.ai[2] platform, a Princeton University initiative that enhances the impact of computer science courses. The platform is free, and participants are encouraged to bring their own video playlists to curate them into AI-enabled collections by enhancing the student experience through integrated generative AI.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1898},
numpages = {1},
keywords = {ai generated content, contextualized generative ai, cost-effective videos, customized videos, data-driven insights, instructional videos, video summarization},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3657604.3662031,
author = {Lu, Xinyi and Wang, Xu},
title = {Generative Students: Using LLM-Simulated Student Profiles to Support Question Item Evaluation},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662031},
doi = {10.1145/3657604.3662031},
abstract = {Evaluating the quality of automatically generated question items has been a long standing challenge. In this paper, we leverage LLMs to simulate student profiles and generate responses to multiple-choice questions (MCQs). The generative students' responses to MCQs can further support question item evaluation. We propose Generative Students, a prompt architecture designed based on the KLI framework. A generative student profile is a function of the list of knowledge components the student has mastered, has confusion about or has no evidence of knowledge of. We instantiate the Generative Students concept on the subject domain of heuristic evaluation. We created 45 generative students using GPT-4 and had them respond to 20 MCQs. We found that the generative students produced logical and believable responses that were aligned with their profiles. We then compared the generative students' responses to real students' responses on the same set of MCQs and found a high correlation. Moreover, there was considerable overlap in the difficult questions identified by generative students and real students. A subsequent case study demonstrated that an instructor could improve question quality based on the signals provided by Generative Students.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {16–27},
numpages = {12},
keywords = {generative AI, generative agent, question item evaluation},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3631802.3631845,
author = {Pirttinen, Nea and Leinonen, Juho},
title = {Could ChatGPT Be Used for Reviewing Learnersourced Exercises?},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631845},
doi = {10.1145/3631802.3631845},
abstract = {Large language models and tools based on large language models such as ChatGPT have received intense attention in the past year in computing education. In this work, we explore whether ChatGPT could be used to review learnersourced exercises. One of the major downsides of learnersourcing is the dubious quality of the created content, leading to many systems using peer review for curating the content. Our results suggest that ChatGPT is not yet ready for this task.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {42},
numpages = {2},
keywords = {ChatGPT, LLMs, crowdsourcing, generative AI, large language models, learnersourcing, reviews},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3660829.3660845,
author = {Mattis, Toni and Krebs, Eva and Rinard, Martin C. and Hirschfeld, Robert},
title = {Examples out of Thin Air: AI-Generated Dynamic Context to Assist Program Comprehension by Example},
year = {2024},
isbn = {9798400706349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660829.3660845},
doi = {10.1145/3660829.3660845},
abstract = {Programmers often benefit from the availability of concrete run-time data alongside abstract source code. However, programmers need to manually exercise the program to reach an interesting state or write code that reproducibly executes a functionality with concrete inputs to be able to observe concrete data. This work aims to automate this process by leveraging generative AI. We present a framework and a preliminary Smalltalk-based prototype allowing programmers to obtain and run examples for the currently viewed source code section from a large language model. Our approach demonstrates how locally hosted LLMs can be fine-tuned and used for such a task with reasonable computational effort while minimizing common problems like hallucinations and out-of-date knowledge. The framework has direct applications in example-based live programming, where it can suggest new examples, and in learning settings where novices need to know how to use certain functionality.},
booktitle = {Companion Proceedings of the 8th International Conference on the Art, Science, and Engineering of Programming},
pages = {99–107},
numpages = {9},
keywords = {example-based programming, generative ai, large language models, live programming, smalltalk},
location = {Lund, Sweden},
series = {Programming '24}
}

@inproceedings{10.1145/3613904.3642580,
author = {Lee, Jungeun and Yoon, Suwon and Lee, Kyoosik and Jeong, Eunae and Cho, Jae-Eun and Park, Wonjeong and Yim, Dongsun and Hwang, Inseok},
title = {Open Sesame? Open Salami! Personalizing Vocabulary Assessment-Intervention for Children via Pervasive Profiling and Bespoke Storybook Generation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642580},
doi = {10.1145/3613904.3642580},
abstract = {Children acquire language by interacting with their surroundings. Due to the different language environments each child is exposed to, the words they encounter and need in their life vary. Despite the standard tools for assessment and intervention as per predefined vocabulary sets, speech-language pathologists and parents struggle with the absence of systematic tools for child-specific custom vocabulary, i.e., out-of-standard but personally more important. We propose “Open Sesame? Open Salami! (OSOS)”, a personalized vocabulary assessment and intervention system with pervasive language profiling and targeted storybook generation, collaboratively developed with speech-language pathologists. Melded into a child’s daily life and powered by large language models (LLM), OSOS profiles the child’s language environment, extracts priority words therein, and generates bespoke storybooks naturally incorporating those words. We evaluated OSOS through 4-week-long deployments to 9 families. We report their experiences with OSOS, and its implications in supporting personalization outside standards.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {120},
numpages = {32},
keywords = {generative AI, language assessment and intervention, large language model, storybook generation, vocabulary learning},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3649158.3657043,
author = {Kundu, Ashish},
title = {AI/ML, Graphs and Access Control: Towards Holistic Identity and Access Management},
year = {2024},
isbn = {9798400704918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649158.3657043},
doi = {10.1145/3649158.3657043},
abstract = {Vulnerabilities in identity and access management (IAM) are one of the most common reasons for data breaches leading to adversarial impacts on security, privacy and compliance postures. Account breaches, incorrectly designed access control policies, weaknesses in authentication and credential management, vulnerable session management are some of the several security issues that lead to eventual compromise of the crown jewels leading to data breaches. The lifecycles of subjects and their identities, of objects and re- sources, and of the permissions and authorization policies are in- tertwined in a complex manner for each specific scenario. Often subjects, objects and permissions often are hard to be defined or isolated from each other, especially in the context of machine learn-ing. The evolution of these entities, and how their provenance is analyzed often is essential not only for forensic analysis of a breach but also should be a proactive ongoing process.  In order to manage the security issues and risks thereof, holistic end-to-end identity and access management in a secure and privacy- preserving manner is the need of yesterday, today and of the future. In the past couple of decades, we have encountered this problem time and again in various contexts in the settings of academic and industry research and in development/deployment of products, services and processes.  Three elements are the key ingredients in order to address this problem in a holistic manner: (1) graphs, (2) machine learning, and (3) decentralized computing (i.e., web3, blockchains). Further, with the advent of generative AI and large language models, the question arises about what problems they can help solve, or they can excerbate further, or what new challenges they can introduce. In this talk, I plan to delve into a discussion of the following: (a) the holistic and end-to-end nature of IAM, (b) the interplay between these three elements - graphs, machine learning, Web3 as well as generative AI, and how they can help, and (c) the research challenges that need to be addressed in order to reduce the security, privacy and compliance risks in identity and access management.},
booktitle = {Proceedings of the 29th ACM Symposium on Access Control Models and Technologies},
pages = {1},
numpages = {1},
keywords = {access control, generative ai, identity, machine learning},
location = {San Antonio, TX, USA},
series = {SACMAT 2024}
}

@inproceedings{10.1145/3708359.3712104,
author = {Kazemitabaar, Majeed and Huang, Oliver and Suh, Sangho and Henley, Austin Z and Grossman, Tovi},
title = {Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712104},
doi = {10.1145/3708359.3712104},
abstract = {Novice programmers are increasingly relying on Large Language Models (LLMs) to generate code for learning programming concepts. However, this interaction can lead to superficial engagement, giving learners an illusion of learning and hindering skill development. To address this issue, we conducted a systematic design exploration to develop seven cognitive engagement techniques aimed at promoting deeper engagement with AI-generated code. In this paper, we describe our design process, the initial seven techniques and results from a between-subjects study (N=82). We then iteratively refined the top techniques and further evaluated them through a within-subjects study (N=42). We evaluate the friction each technique introduces, their effectiveness in helping learners apply concepts to isomorphic tasks without AI assistance, and their success in aligning learners’ perceived and actual coding abilities. Ultimately, our results highlight the most effective technique: guiding learners through the step-by-step problem-solving process, where they engage in an interactive dialog with the AI, prompting what needs to be done at each stage before the corresponding code is revealed.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {695–714},
numpages = {20},
keywords = {AI-Assisted Programming, Generative AI, Copilot, ChatGPT, Cognitive Engagement Enhancement, AI-Assisted Learning, Cognitive Forcing Functions, Task Decomposition, Learning Outcomes},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3643991.3645078,
author = {Mohamed, Suad and Parvin, Abdullah and Parra, Esteban},
title = {Chatting with AI: Deciphering Developer Conversations with ChatGPT},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645078},
doi = {10.1145/3643991.3645078},
abstract = {Large Language Models (LLMs) have been widely adopted and are becoming ubiquitous and integral to software development. However, we have little knowledge as to how these tools are being used by software developers beyond anecdotal evidence and word-of-mouth reports. In this work, we present a study toward understanding how developers engage with and utilize LLMs by reporting the results of an empirical study identifying patterns in the conversation that developers have with LLMs. We identified a total of 19 topics describing the purpose of the developers in their conversations with LLMs. Our findings reveal that developers use LLMs to facilitate various aspects of their software development processes (e.g., information-seeking about programming languages and frameworks and soliciting high-level design recommendations) to a similar extent to which they use them for non-development purposes such as writing assistance, general purpose queries, and conducting Turing tests to assess the intrinsic capabilities of the models. This work not only sheds light on the diverse applications of LLMs in software development but also underscores their emerging role as critical tools in enhancing developer productivity and creativity as we move closer to widespread AI-assisted software development.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {187–191},
numpages = {5},
keywords = {large language models, LLM, ChatGPT, software development, empirical study, developer conversations},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@article{10.1145/3649883,
author = {Cheong, Marc and Abedin, Ehsan and Ferreira, Marinus and Reimann, Ritsaart and Chalson, Shalom and Robinson, Pamela and Byrne, Joanne and Ruppanner, Leah and Alfano, Mark and Klein, Colin},
title = {Investigating Gender and Racial Biases in DALL-E Mini Images},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
url = {https://doi.org/10.1145/3649883},
doi = {10.1145/3649883},
abstract = {Generative artificial intelligence systems based on transformers, including both text generators such as GPT-4 and image generators such as DALL-E 3, have recently entered the popular consciousness. These tools, while impressive, are liable to reproduce, exacerbate, and reinforce extant human social biases, such as gender and racial biases. In this article, we systematically review the extent to which DALL-E Mini suffers from this problem. In line with the Model Card published alongside DALL-E Mini by its creators, we find that the images it produces tend to represent dozens of different occupations as populated either solely by men (e.g., pilot, builder, plumber) or solely by women (e.g., hairdresser, receptionist, dietitian). In addition, the images DALL-E Mini produces tend to represent most occupations as populated primarily or solely by White people (e.g., farmer, painter, prison officer, software engineer) and very few by non-White people (e.g., pastor, rapper). These findings suggest that exciting new AI technologies should be critically scrutinized and perhaps regulated before they are unleashed on society.},
journal = {ACM J. Responsib. Comput.},
month = jun,
articleno = {13},
numpages = {20},
keywords = {Gender bias, racial bias, algorithmic bias, generative AI, DALL-E Mini}
}

@inproceedings{10.1145/3706598.3714049,
author = {Qadri, Rida and Mirowski, Piotr and Denton, Remi},
title = {AI and Non-Western Art Worlds: Reimagining Critical AI Futures through Artistic Inquiry and Situated Dialogue},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714049},
doi = {10.1145/3706598.3714049},
abstract = {This paper examines the potential for localized adaptation, appropriation and re-imagination of AI for non-western cultural expression, using the Persian Gulf as a case. Using sociologist Howard Becker’s concept of ‘art worlds’ as a situated lens to evaluate generative AI, we set up an eight week experimentation and dialogue between artists, art historians and curators. Our project reveals how local art worlds 1) can appropriate AI tools to address contextual and cultural needs; 2) develop “hacks” to adapt AI for culturally-specific capabilities; and 3) can be a site for imagining alternative technological trajectories. We thus showcase the importance of expanding the scope of AI evaluations to include the social dynamics AI operates in and its contexts of use. We also reflect on the power that local communities may have to interrupt AI with more culturally-relevant orientations and to offer visions for redesigning AI for non-Western creativity.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {201},
numpages = {17},
keywords = {Generative AI, text-to-image, creativity, art, artists, global south, cultural AI evaluations, design visions, local},
location = {
},
series = {CHI '25}
}

@article{10.5555/3737313.3737340,
author = {Crocetti, Giancarlo and Bak, Seonwoo and Noory, Naqib A. and Vautor-Laplaceliere, Daena D.},
title = {Evaluating the Pedagogical Impact of Large Language Models on Programming Skills in Higher Education},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {This empirical study investigated the impact of Generative AI (GenAI) tools, particularly large language models (LLMs), on college students' Python programming skills in a graduate-level data science course. Using a pretest-posttest methodology and accounting for variables like prior programming experience, the research examined how guided LLM usage affected students' self-assessed programming abilities. The findings revealed that while LLMs positively influenced students' capacity to develop complex applications, work with Python libraries, and write quality code, they had no significant impact on students' grasp of fundamental Python concepts or their general comfort with the language. These results suggest that LLMs serve as effective tools for advancing practical programming skills but cannot substitute for the foundational programming knowledge that must be developed through traditional learning.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {163–177},
numpages = {15}
}

@inproceedings{10.1145/3675669.3675681,
author = {Uesugi, Shiro},
title = {Fostering Critical Thinking on Social Media: Combating AI-Generated Fake Posts Upon Natural Disasters},
year = {2024},
isbn = {9798400717550},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675669.3675681},
doi = {10.1145/3675669.3675681},
abstract = {The social media and, in a wider context, SNS in general, are strong tools when it comes to spreading calls for help in an emergency situation such as a natural disaster where mass media cannot reach. Information posted on SNS is a first-hand source from the epicentre of the disaster and is used even for rescue operations. Historically, however, there has been a lot of harmful postings to SNS whenever a natural disaster occurred. The harmful or misleading posts have been in the form of rumors and fake news. There are extensive researches about analysis of the cause of rumours and countermeasures against those malicious activities including how to recognize fake news even using AI. The proposed countermeasures mostly focus on technological engineering such as identification of sources and analysis of the contents. However, the rapid development and wider use of generative AI make the quality of rumors and fake news harder to tackle with. As generative AI is deployed to generate fake news or Deep Fake, those malicious posts become more convincing. The countermeasures to develop better technologies might lead to an endless arms race. This research envisages that the education of Critical Thinking and Nudging for the users should be the effective countermeasure.},
booktitle = {Proceedings of the 2024 11th Multidisciplinary International Social Networks Conference},
pages = {73–80},
numpages = {8},
keywords = {Deep Fake, Education of Critical Thinking, Education of Ethics, Fake news, Generative AI},
location = {Bali, Indonesia},
series = {MISNC '24}
}

@inproceedings{10.1145/3708359.3712150,
author = {Adamkiewicz, Krzysztof and Wo\'{z}niak, Pawe\l{} W. and Dominiak, Julia and Romanowski, Andrzej and Karolus, Jakob and Frolov, Stanislav},
title = {PromptMap: An Alternative Interaction Style for AI-Based Image Generation},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712150},
doi = {10.1145/3708359.3712150},
abstract = {Recent technological advances popularized the use of image generation among the general public. Crafting effective prompts can, however, be difficult for novice users. To tackle this challenge, we developed PromptMap, a new interaction style for text-to-image AI that allows users to freely explore a vast collection of synthetic prompts through a map-like view with semantic zoom. PromptMap groups images visually by their semantic similarity, allowing users to discover relevant examples. We evaluated PromptMap in a between-subject online study (n = 60) and a qualitative within-subject study (n = 12). We found that PromptMap supported users in crafting prompts by providing them with examples. We also demonstrated the feasibility of using LLMs to create vast example collections. Our work contributes a new interaction style that supports users unfamiliar with prompting in achieving a satisfactory image output.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {1162–1176},
numpages = {15},
keywords = {Generative AI, image generation, interaction methods},
location = {
},
series = {IUI '25}
}

@article{10.1145/3651990,
author = {Cheng, Ruijia and Wang, Ruotong and Zimmermann, Thomas and Ford, Denae},
title = {“It would work for me too”: How Online Communities Shape Software Developers’ Trust in AI-Powered Code Generation Tools},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {2160-6455},
url = {https://doi.org/10.1145/3651990},
doi = {10.1145/3651990},
abstract = {While revolutionary AI-powered code generation tools have been rising rapidly, we know little about how and how to help software developers form appropriate trust in those AI tools. Through a two-phase formative study, we investigate how online communities shape developers’ trust in AI tools and how we can leverage community features to facilitate appropriate user trust. Through interviewing 17 developers, we find that developers collectively make sense of AI tools using the experiences shared by community members and leverage community signals to evaluate AI suggestions. We then surface design opportunities and conduct 11 design probe sessions to explore the design space of using community features to support user trust in AI code generation systems. We synthesize our findings and extend an existing model of user trust in AI technologies with sociotechnical factors. We map out the design considerations for integrating user community into the AI code generation experience.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = may,
articleno = {11},
numpages = {39},
keywords = {Online communities, software engineering, Human-AI interaction, generative AI, trust}
}

@inproceedings{10.1145/3708036.3708165,
author = {Huang, Ling and Deng, Wanqiu and Jiang, Yiling and Zhong, Qinghua},
title = {Development trends of large language models and their applications in green digital intelligence of supply chains},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708165},
doi = {10.1145/3708036.3708165},
abstract = {In recent years, large language models (LLM) have developed rapidly and been widely used in the field of natural language processing, and have made significant progress and been widely used in both academia and industry. Large language models have also shown great potential in promoting the green digital intelligence of the supply chain. The development of language models provides technical support for the green digital intelligence of the supply chain. The model's text analysis capabilities can help companies analyze information such as suppliers' renewable energy usage, carbon footprint, environmental and social responsibility reports, and thus make more informed sourcing and supplier selection decisions. At the same time, the large language model can analyze supply chain data, provide suggestions and optimization plans for energy conservation and emission reduction, predict and manage environmental risks, and promote enterprises to transform into a more sustainable and environmentally friendly supply chain.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {770–774},
numpages = {5},
keywords = {Green digital intelligence of supply chain, Natural Language Processing, large language model},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3613904.3642529,
author = {Kim, Taewook and Han, Hyomin and Adar, Eytan and Kay, Matthew and Chung, John Joon Young},
title = {Authors' Values and Attitudes Towards AI-bridged Scalable Personalization of Creative Language Arts},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642529},
doi = {10.1145/3613904.3642529},
abstract = {Generative AI has the potential to create a new form of interactive media: AI-bridged creative language arts (CLA), which bridge the author and audience by personalizing the author’s vision to the audience’s context and taste at scale. However, it is unclear what the authors’ values and attitudes would be regarding AI-bridged CLA. To identify these values and attitudes, we conducted an interview study with 18 authors across eight genres (e.g., poetry, comics) by presenting speculative but realistic AI-bridged CLA scenarios. We identified three benefits derived from the dynamics between author, artifact, and audience: those that 1) authors get from the process, 2) audiences get from the artifact, and 3) authors get from the audience. We found how AI-bridged CLA would either promote or reduce these benefits, along with authors’ concerns. We hope our investigation hints at how AI can provide intriguing experiences to CLA audiences while promoting authors’ values.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {31},
numpages = {16},
keywords = {Authorial control, Creative language arts, Creative writing, Generative AI, Large language models, Scalable personalization},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3641555.3705252,
author = {Tadimalla, Sri Yash and Maher, Mary Lou},
title = {Sociotechnical AI Education Course Design for CS Majors and Non-Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705252},
doi = {10.1145/3641555.3705252},
abstract = {As generative AI increasingly integrates into society and education, the number of institutions implementing AI usage policies and offering introductory AI courses is rising. These introductory AI courses mustn't replicate the "gateway/weed-out" phenomenon observed in introductory computer science courses like CS1 and CS2. Literature in computer science education suggests that interventions such as summer camps, bridge courses, and socio-technical courses have improved the sense of belonging and retention among students from underrepresented groups, thereby broadening participation in computer science. Building on previous work to create a socio-technical curriculum for all ages and education levels, this paper presents a course for teaching introductory AI concepts that adopts a socio-technical approach, complete with weekly activities and content designed for broad access. The course has been taught as a 1-credit general education course, primarily for freshmen and first-year students from various majors, and a 3-credit course for CS majors at all levels.This paper provides a curriculum and resources to teach a socio-technical introductory AI course. This approach is important because it not only democratizes AI education across diverse student backgrounds but also equips all students with the critical socio-technical multidisciplinary perspective necessary to navigate and shape the future ethical landscape of AI technology.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1631–1632},
numpages = {2},
keywords = {AI curriculum, AI education, intro to AI, socio-technical AI literacy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3632620.3671098,
author = {Padiyath, Aadarsh and Hou, Xinying and Pang, Amy and Viramontes Vargas, Diego and Gu, Xingjian and Nelson-Fromm, Tamara and Wu, Zihan and Guzdial, Mark and Ericson, Barbara},
title = {Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671098},
doi = {10.1145/3632620.3671098},
abstract = {The capability of large language models (LLMs) to generate, debug, and explain code has sparked the interest of researchers and educators in undergraduate programming, with many anticipating their transformative potential in programming education. However, decisions about why and how to use LLMs in programming education may involve more than just the assessment of an LLM’s technical capabilities. Using the social shaping of technology theory as a guiding framework, our study explores how students’ social perceptions influence their own LLM usage. We then examine the correlation of self-reported LLM usage with students’ self-efficacy and midterm performances in an undergraduate programming course. Triangulating data from an anonymous end-of-course student survey (n = 158), a mid-course self-efficacy survey (n=158), student interviews (n = 10), self-reported LLM usage on homework, and midterm performances, we discovered that students’ use of LLMs was associated with their expectations for their future careers and their perceptions of peer usage. Additionally, early self-reported LLM usage in our context correlated with lower self-efficacy and lower midterm scores, while students’ perceived over-reliance on LLMs, rather than their usage itself, correlated with decreased self-efficacy later in the course.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {114–130},
numpages = {17},
keywords = {Generative AI, Large Language Models, Self-Efficacy, Social Shaping Theory, Technology Appropriation Model},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3700297.3700350,
author = {Lin, Daping and Pu, Xianwei},
title = {Effects of Prompts and Time on the Automated Scoring of English Argumentative Essays by ChatGPT 4},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700350},
doi = {10.1145/3700297.3700350},
abstract = {As deep learning technology in computer science develops, generative artificial intelligence (GenAI) has shown great potential in automated essay scoring (AES). Prompts and time are important factors which may influence the performance of GenAI. The study selected 52 English argumentative essays, designed five different prompts, chooses two different time points, and then utilized ChatGPT 4 to explore the effects of prompts and time on AES by GenAI. Besides, possible reasons for large difference between human and GenAI score were discussed.For different prompts, results show that the one-shot prompt performs better in AES compared with the other four prompts. It provides background information and a scoring example to ChatGPT. The scores generated by it do not significantly differ from the human scores. They significantly and positively correlate with human scores (ρ = 0.424). The exact-plus-adjacent agreement (EPAA) rate for one-shot prompt scores reaches 69.23%. For scores generated at different points in time, results reveal that although there is still a significant difference between scores generated after one week and human scores, the ChatGPT-Human EPAA rate becomes higher and the absolute value of mean score difference is smaller.Based on the analysis of selected essays, the major reason for large GenAI-Human score difference is that ChatGPT evaluates essays from limited perspectives to give its score, while human raters can comprehensively assess the quality of an essay. What's more, ChatGPT cannot keep the same scoring criteria during the rating process.The study aims to help people understand how to interact with GenAI more efficiently and take advantage of GenAI to meet the practical needs.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {302–312},
numpages = {11},
keywords = {English argumentative essays, automated essay scoring, generative artificial intelligence, prompts, time},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3681716.3681738,
author = {Ghajargar, Maliheh},
title = {AI and Future-Making: Design, Biases, and Human-Plant Interactions},
year = {2024},
isbn = {9798400718236},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3681716.3681738},
doi = {10.1145/3681716.3681738},
abstract = {Design researchers and practitioners are turning to generative AI (genAI) to support activities such as ideation and concept development in pursuit of preferred futures. At the same time, genAI is known to have biases, which prompts questions about how these biases might adversely affect design practices. In the domain of sustainable HCI, with its recent trends in human-nature interactions and more-than-human design, the question can be further refined into whether and how genAI biases might perpetuate anthropocentric biases that these practices are increasingly seeking to confront. In the present research, we conducted three workshops, focusing on genAI for human-plant interactions; in the first workshop, we created design fiction concerning human-plant interactions in Southern California in the year 2100, building on the second, the third workshop sought to identify and bring into focus relevant units of analysis. Results included the identification of three kinds of AI biases in plant representations that affect design practices of future-making: species, ecologies, and interactions.},
booktitle = {Proceedings of the 27th International Academic Mindtrek Conference},
pages = {24–35},
numpages = {12},
keywords = {AI bias, Design Fiction, Design Methods, Generative AI, Human-nature Interaction},
location = {Tampere, Finland},
series = {Mindtrek '24}
}

@inproceedings{10.1145/3689187.3709611,
author = {Toti, Giulia and Lindner, Peggy and Gao, Alice and Baghban Karimi, Ouldooz and Engineer, Rutwa and Hur, Jinyoung and McNeill, Fiona and Reckinger, Shanon and Robinson, Rebecca and Sollazzo, Anna and Wicentowski, Richard},
title = {Diversity, Equity, and Inclusion in Computing Science: Culture is the Key, Curriculum Contributes},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709611},
doi = {10.1145/3689187.3709611},
abstract = {Undergraduate computer science programs worldwide struggle to attract and retain underrepresented students for many reasons. Culture, stereotype threats, uneven gender and racial representations, lack of role models, and uncertain career prospects for minority groups are among the many reasons behind this situation. Many computer science programs are trying to change course through strategies to foster equity, diversity, and inclusion (EDI), aimed at improving outreach, recruitment, admissions, and retention of underrepresented students. EDI approaches may also include modifications to the undergraduate computer science curriculum. However, if not properly planned, these modifications risk amplifying existing stereotypes rather than producing positive change [38]. In this study, through an extensive literature review, a rigorous curriculum analysis of 49 computer science programs across the globe, and qualitative and quantitative analysis of surveys and interviews bringing in the voices of 613 students and 30 educators participating from around the world, we explore equity, diversity, and inclusion in the computer science curriculum. We highlight the role of inclusive content and course design, discuss program flexibility, and the impact of inclusive courses and program design in attracting and retaining historically marginalized students. Finally, we provide concrete steps to make computing science undergraduate curricula more appealing to a diverse audience.},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {175–225},
numpages = {51},
keywords = {computer science, computing science, diversity, edi, equity, inclusion, undergraduate curriculum},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649217.3653615,
author = {Gardella, Nicholas and Pettit, Raymond and Riggs, Sara L.},
title = {Performance, Workload, Emotion, and Self-Efficacy of Novice Programmers Using AI Code Generation},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653615},
doi = {10.1145/3649217.3653615},
abstract = {Artificial Intelligence-driven Development Environments (AIDEs) offer developers revolutionary computer programming assistance. There is great potential in incorporating AIDEs into Computer Science education; however, the effects of these tools should be fully examined before doing so. Here, a within-subjects study was conducted to compare the programming performance, workload, emotion, and self-efficacy of seventeen novices coding with and without use of the GitHub Copilot AIDE under time pressure. Results showed that using the AIDE significantly increased programming efficiency and reduced effort and mental workload but did not significantly impact emotion or self-efficacy. However, participants' performance improved with more experience using the AI, and their self-efficacy followed. The results suggest that students who try AIDEs will likely be tempted to use them for time-sensitive work. There is no evidence that providing AIDEs will aid struggling students, but there is a clear need for students to practice with AI to become competent and confident using it.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {290–296},
numpages = {7},
keywords = {ai code generators, artificial intelligence-driven development environment, computer science education, cs1, generative ai, github copilot, introductory programming, novice programmers},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@article{10.5555/3722479.3722526,
author = {Xie, Jingnan},
title = {Improving Introductory Java Programming Education Through ChatGPT},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {The realm of introductory computer science (CS) education is swiftly changing, as educators actively pursue inventive strategies to captivate and empower students. This manuscript introduces a fresh methodology for teaching CS1 or CS2 courses, concentrating specifically on the fundamental principles of Java programming. Harnessing the capabilities of ChatGPT, an AI language model, we delve into how integrating conversational AI into the classroom milieu can foster a more dynamic and tailored learning journey. By furnishing a platform for students to pose inquiries, seek elucidation, and promptly receive feedback, ChatGPT functions as a virtual mentor, complementing conventional teaching methodologies. We scrutinize the potential repercussions of this approach on student learning outcomes (SLOs) and juxtapose it with traditional classroom paradigms. Furthermore, we deliberate on the ramifications of employing AI in education and its contribution to molding the trajectory of introductory programming courses.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {140–150},
numpages = {11}
}

@article{10.1145/3702639,
author = {Bevilacqua, Marialena and Oketch, Kezia and Qin, Ruiyang and Stamey, Will and Zhang, Xinyuan and Gan, Yi and Yang, Kai and Abbasi, Ahmed},
title = {When Automated Assessment Meets Automated Content Generation: Examining Text Quality in the Era of GPTs},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/3702639},
doi = {10.1145/3702639},
abstract = {The use of machine learning (ML) models to assess and score textual data has become increasingly pervasive in an array of contexts including natural language processing, information retrieval, search and recommendation, and credibility assessment of online content. A significant disruption at the intersection of ML and text are text-generating large-language models (LLMs) such as generative pre-trained transformers (GPTs). We empirically assess the differences in how ML-based scoring models trained on human content assess the quality of content generated by humans versus GPTs. To do so, we propose an analysis framework that encompasses essay scoring ML models, human- and ML-generated essays, and a statistical model that parsimoniously considers the impact of type of respondent, prompt genre, and the ML model used for assessment model. A rich testbed is utilized that encompasses 18,460 human-generated and GPT-based essays. Results of our benchmark analysis reveal that LLMs and transformer pretrained language models (PLMs) more accurately score human essay quality as compared to CNN/RNN and feature-based ML methods. Interestingly, we find that LLMs and transformer PLMs tend to score GPT-generated text 10–20% higher on average, relative to human-authored documents. Conversely, traditional deep learning and feature-based ML models score human text considerably higher. Further analysis reveals that even though the LLMs and transformer PLMs are exclusively fine-tuned on human text, they more prominently attend to certain tokens appearing only in GPT-generated text, possibly (in part) due to familiarity/overlap in pre-training. Our framework and results have implications for text classification settings where automated scoring of text is likely to be disrupted by generative AI.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
articleno = {43},
numpages = {36},
keywords = {automated essay scoring, text classification, auto-generated text, user-generated content, text quality, generative AI, large language models, LLMs}
}

@inproceedings{10.1145/3636555.3636848,
author = {Cloude, Elizabeth B. and Kumar, Pranshu and Baker, Ryan S. and Fouh, Eric},
title = {Novice programmers inaccurately monitor the quality of their work and their peers’ work in an introductory computer science course},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636848},
doi = {10.1145/3636555.3636848},
abstract = {A student’s ability to accurately evaluate the quality of their work holds significant implications for their self-regulated learning and problem-solving proficiency in introductory programming. A widespread cognitive bias that frequently impedes accurate self- assessment is overconfidence, which often stems from a misjudgment of contextual and task-related cues, including students’ judgment of their peers’ competencies. Little research has explored the role of overconfidence on novice programmers’ ability to accurately monitor their own work in comparison to their peers’ work and its impact on performance in introductory programming courses. The present study examined whether novice programmers exhibited a common cognitive bias called the "hard-easy effect", where students believe their work is better than their peers on easier tasks (overplace) but worse than their peers on harder tasks (underplace). Results showed a reversal of the hard-easy effect, where novices tended to overplace themselves on harder tasks, yet underplace themselves on easier ones. Remarkably, underplacers performed better on an exam compared to overplacers. These findings advance our understanding of relationships between the hard-easy effect, monitoring accuracy across multiple tasks, and grades within introductory programming. Implications of this study can be used to guide instructional decision making and design to improve novices’ metacognitive awareness and performance in introductory programming courses.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {35–45},
numpages = {11},
keywords = {CS1, Hard-easy Effect, Metacognition, Overconfidence},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3640471.3680462,
author = {ElAgroudy, Passant and Gruenerbl, Agnes and Barbareschi, Giulia and Spilski, Jan and Kunze, Kai and Lachmann, Thomas and Lukowicz, Paul},
title = {mobiCHAI - 1st International Workshop on Mobile Cognition-Altering Technologies (CAT) using Human-Centered AI},
year = {2024},
isbn = {9798400705069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640471.3680462},
doi = {10.1145/3640471.3680462},
abstract = {The quest for enhanced cognition has been a driving force behind human advancement, fostering innovation and personal fulfillment. Cognition Altering Technologies (CAT) holds immense promise in elevating the quality of life across diverse domains including education, decision-making, healthcare, and fitness. The current proliferation of Artificial Intelligence (AI), particularly the widespread adoption of Generative AI and foundational models, presents an unprecedented opportunity to prototype new CAT that can augment human capabilities. This workshop aims to unite interdisciplinary research communities to explore the potential of leveraging GenAI and human-centered AI to develop relevant CAT. Taking place at MobileHCI 2024, this one-day workshop invites researchers, practitioners, and designers from fields such as artificial intelligence, ubiquitous computing, human-computer interaction, and social sciences to collaborate and chart the future of cognitive enhancement through technology.},
booktitle = {Adjunct Proceedings of the 26th International Conference on Mobile Human-Computer Interaction},
articleno = {31},
numpages = {5},
keywords = {Human-Centered AI, Hybrid-Human Artificial Intelligence, augmenting human capabilities, cognitive science, generative AI, shaping cognitive and social behavior, ubiquitous technologies},
location = {Melbourne, VIC, Australia},
series = {MobileHCI '24 Adjunct}
}

@inproceedings{10.1145/3616961.3616978,
author = {Oppenlaender, Jonas and Silvennoinen, Johanna and Paananen, Ville and Visuri, Aku},
title = {Perceptions and Realities of Text-to-Image Generation},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616978},
doi = {10.1145/3616961.3616978},
abstract = {Generative artificial intelligence (AI) is a widely popular technology that will have a profound impact on society and individuals. Less than a decade ago, it was thought that creative work would be among the last to be automated&nbsp;– yet today, we see AI encroaching on many creative domains. In this paper, we present the findings of a survey study on people’s perceptions of text-to-image generation. We touch on participants’ technical understanding of the emerging technology, their fears and concerns, and thoughts about risks and dangers of text-to-image generation to the individual and society. We find that while participants were aware of the risks and dangers associated with the technology, only few participants considered the technology to be a personal risk. The risks for others were more easy to recognize for participants. Artists were particularly seen at risk. Interestingly, participants who had tried the technology rated its future importance lower than those who had not tried it. This result shows that many people are still oblivious of the potential personal risks of generative artificial intelligence and the impending societal changes associated with this technology.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {279–288},
numpages = {10},
keywords = {text-to-image generation, generative AI},
location = {Tampere, Finland},
series = {Mindtrek '23}
}

@inproceedings{10.1145/3626252.3630928,
author = {Poulsen, Seth and Sarsa, Sami and Prather, James and Leinonen, Juho and Becker, Brett A. and Hellas, Arto and Denny, Paul and Reeves, Brent N.},
title = {Solving Proof Block Problems Using Large Language Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630928},
doi = {10.1145/3626252.3630928},
abstract = {Large language models (LLMs) have recently taken many fields, including computer science, by storm. Most recent work on LLMs in computing education has shown that they are capable of solving most introductory programming (CS1) exercises, exam questions, Parsons problems, and several other types of exercises and questions. Some work has investigated the ability of LLMs to solve CS2 problems as well. However, it remains unclear how well LLMs fare against more advanced upper-division coursework, such as proofs in algorithms courses. After all, while known to be proficient in many programming tasks, LLMs have been shown to have more difficulties in forming mathematical proofs.In this paper, we investigate the ability of LLMs to solve mathematical proofs by using Proof Blocks, a tool previously shown to efficaciously teach proofs to students. Our results show that GPT-3.5 is almost completely unable to provide correct solutions (11.4%), while GPT-4 shows a significant increase in correctness (64.8%). However, even given this improvement, current models still struggle to correctly order lines in a proof. It remains an open question whether this is a temporary situation or if LLMs will continue to struggle to solve these types of exercises in the future.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1063–1069},
numpages = {7},
keywords = {ai, algorithms, artificial intelligence, chatgpt, code generation, generative ai, gpt-3, gpt-4, large language models, openai, proof blocks, proofs},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630822,
author = {Taylor, Andrew and Vassar, Alexandra and Renzella, Jake and Pearce, Hammond},
title = {dcc --help: Transforming the Role of the Compiler by Generating Context-Aware Error Explanations with Large Language Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630822},
doi = {10.1145/3626252.3630822},
abstract = {In the challenging field of introductory programming, high enrolments and failure rates drive us to explore tools and systems to enhance student outcomes, especially automated tools that scale to large cohorts. This paper presents and evaluates the dcc --help tool, an integration of a Large Language Model (LLM) into the Debugging C Compiler (DCC) to generate unique, novice-focused explanations tailored to each error. dcc --help prompts an LLM with contextual information of compile- and run-time error occurrences, including the source code, error location and standard compiler error message. The LLM is instructed to generate novice-focused, actionable error explanations and guidance, designed to help students understand and resolve problems without providing solutions. dcc --help was deployed to our CS1 and CS2 courses, with 2,565 students using the tool over 64,000 times in ten weeks. We analysed a subset of these error/explanation pairs to evaluate their properties, including conceptual correctness, relevancy, and overall quality. We found that the LLM-generated explanations were conceptually accurate in 90% of compile-time and 75% of run-time cases, but often disregarded the instruction not to provide solutions in code. Our findings, observations and reflections following deployment indicate that dcc --help provides novel opportunities for scaffolding students' introduction to programming.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1314–1320},
numpages = {7},
keywords = {ai in cs1, ai in education, compiler error messages, cs1, debugging, error message enhancement, generative ai, large language models, programming error messages},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649165.3690100,
author = {MacNeil, Stephen and Rogalska, Magdalena and Leinonen, Juho and Denny, Paul and Hellas, Arto and Crosland, Xandria},
title = {Synthetic Students: A Comparative Study of Bug Distribution Between Large Language Models and Computing Students},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690100},
doi = {10.1145/3649165.3690100},
abstract = {Large language models (LLMs) present an exciting opportunity for generating synthetic classroom data. Such data could include code containing a typical distribution of errors, simulated student behavior to address the cold start problem when developing education tools, and synthetic user data when access to authentic data is restricted due to privacy reasons. In this research paper, we conduct a comparative study examining the distribution of bugs generated by LLMs in contrast to those produced by computing students. Leveraging data from two previous large-scale analyses of student-generated bugs, we investigate whether LLMs can be coaxed to exhibit bug patterns that are similar to authentic student bugs when prompted to inject errors into code. The results suggest that unguided, LLMs do not generate plausible error distributions, and many of the generated errors are unlikely to be generated by real students. However, with guidance including descriptions of common errors and typical frequencies, LLMs can be shepherded to generate realistic distributions of errors in synthetic code.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {137–143},
numpages = {7},
keywords = {buggy code, generative ai, gpt-4, llms, synthetic data},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3729605.3729629,
author = {Deng, Jianying and Liu, Chuang and Zhou, Zixin},
title = {An Emotion-Art Prompt Framework for AI-Generated Drawings in Education: System Architecture and Experimental Evaluation},
year = {2025},
isbn = {9798400714405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3729605.3729629},
doi = {10.1145/3729605.3729629},
abstract = {Generative Artificial Intelligence (AI) has propelled a new paradigm in the generation of digital art, bringing new pedagogical practices regarding personalization and emotional growth in the classroom. This paper proposes the Emotion-Art Prompt Framework (EAPF) which provides a systematic link between Plutchik's Wheel of Emotions and L\"{o}vheim's three-dimensional model with basic underlying elements of art — form, color, light/shadow, and composition to facilitate drawing generation in an AI setting. This paper describes a new system architecture that autonomously maps layered emotional descriptors onto structured prompts interfacing with the Tencent Yuanbao AI drawing platform. Through a large-scale experiment involving more than 800 students (aged 10–12) in Shenzhen (China), we assessed quantitative and qualitative data embedded in emotional alignment, creative engagement, and platform suitability. Our findings show that EAPF substantially improves the emotional expressiveness of AI-generated works of art, while offering data-based insights for educators to tailor art teaching to individual student preferences. Thus, this study demonstrates the potential of well-designed prompt engineering to overcome accessibility barriers in traditional art education while enhancing emotional development. Additionally, it proposes a scalable model for integrating AI technologies into K–12 creative learning.},
booktitle = {Proceedings of the 2025 International Conference on Big Data and Informatization Education},
pages = {132–137},
numpages = {6},
keywords = {Generative AI, Prompt Engineering, art education, educational technology, emotional expressiveness},
location = {
},
series = {ICBDIE '25}
}

@inproceedings{10.1145/3657604.3664721,
author = {Lin, Jionghao and Koedinger, Kenneth R.},
title = {HAROR: A System for Highlighting and Rephrasing Open-Ended Responses},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664721},
doi = {10.1145/3657604.3664721},
abstract = {Automated feedback systems are pivotal for scaling personalized learning, especially when dealing with large cohorts of learners. This paper introduces HAROR (Highlighting and Rephrasing Open-ended Responses), a feedback system that utilizes the advanced capabilities of Generative Pre-trained Transformer (GPT) models, including GPT-4 and GPT-3.5, to provide explanatory feedback on learner responses (trainee tutors as learners in our study) to open-ended questions. HAROR can identify desirable and undesirable parts of open-ended responses, offer explanatory feedback, and rephrase the undesired responses into desirable forms, aiming to foster learners' understanding and improvement.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {553–555},
numpages = {3},
keywords = {feedback, generative artificial intelligence, large language models, natural language processing},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.1145/3705300,
author = {Xu, Xiaodan and Ni, Chao and Guo, Xinrong and Liu, Shaoxuan and Wang, Xiaoya and Liu, Kui and Yang, Xiaohu},
title = {Distinguishing LLM-Generated from Human-Written Code by Contrastive Learning},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3705300},
doi = {10.1145/3705300},
abstract = {Large language models (LLMs), such as ChatGPT released by OpenAI, have attracted significant attention from both industry and academia due to their demonstrated ability to generate high-quality content for various tasks. Despite the impressive capabilities of LLMs, there are growing concerns regarding their potential risks in various fields, such as news, education, and software engineering. Recently, several commercial and open source LLM-generated content detectors have been proposed, which, however, are primarily designed for detecting natural language content without considering the specific characteristics of program code. This article aims to fill this gap by proposing a novel ChatGPT-generated code detector, CodeGPTSensor, based on a contrastive learning framework and a semantic encoder built with UniXcoder. To assess the effectiveness of CodeGPTSensor on differentiating ChatGPT-generated code from human-written code, we first curate a large-scale Human and Machine comparison Corpus (HMCorp), which includes 550k pairs of human-written and ChatGPT-generated code (i.e., 288k Python code pairs and 222k Java code pairs). Based on the HMCorp dataset, our qualitative and quantitative analysis of the characteristics of ChatGPT-generated code reveals the challenge and opportunity of distinguishing ChatGPT-generated code from human-written code with their representative features. Our experimental results indicate that CodeGPTSensor can effectively identify ChatGPT-generated code, outperforming all selected baselines.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {91},
numpages = {31},
keywords = {Large Language Model, ChatGPT, AI-generated Code Detection, Contrastive Learning}
}

@article{10.1145/3699738,
author = {Lyu, Yue and Liu, Di and An, Pengcheng and Tong, Xin and Zhang, Huan and Katsuragawa, Keiko and Zhao, Jian},
title = {EMooly: Supporting Autistic Children in Collaborative Social-Emotional Learning with Caregiver Participation through Interactive AI-infused and AR Activities},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699738},
doi = {10.1145/3699738},
abstract = {Children with autism spectrum disorder (ASD) have social-emotional deficits that lead to difficulties in recognizing emotions as well as understanding and responding to social interactions. This study presents EMooly, a tablet game that actively involves caregivers and leverages augmented reality (AR) and generative AI (GenAI) to enhance social-emotional learning for autistic children. Through a year of collaborative effort with five domain experts, we developed EMooly that engages children through personalized social stories, interactive and fun activities, and enhanced caregiver participation, focusing on emotion understanding and facial expression recognition. Compared with a baseline, a controlled study with 24 autistic children and their caregivers showed EMooly significantly improved children's emotion recognition skills and its novel features were preferred and appreciated. EMooly demonstrates the potential of AI and AR in enhancing social-emotional development for autistic children via prompt personalizing and engagement, and highlights the importance of caregiver involvement for optimal learning outcomes.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {203},
numpages = {36},
keywords = {Autism spectrum disorder, augmented reality, generative AI, mobile game, parent-mediated intervention, storytelling}
}

@inproceedings{10.1145/3641554.3701945,
author = {Liu, Rongxin and Zhao, Julianna and Xu, Benjamin and Perez, Christopher and Zhukovets, Yuliia and Malan, David J.},
title = {Improving AI in CS50: Leveraging Human Feedback for Better Learning},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701945},
doi = {10.1145/3641554.3701945},
abstract = {In 2023, we developed and deployed AI-based tools in CS50 at Harvard University to provide students with 24/7 interactive assistance, approximating a 1:1 teacher-to-student ratio. These tools offer code explanations, style suggestions, and responses to course-related inquiries, emulating human educators to foster critical thinking. However, maintaining alignment with instructional goals is challenging, especially with frequent updates to the underlying large language models (LLMs). We thus propose a continuous improvement process for LLM-based systems using a collaborative human-in-the-loop approach. We introduce a systematic evaluation framework for assessing and refining the performance of AI-based tutors, combining human-graded and model-graded evaluations. Using few-shot prompting and fine-tuning, we aim to ensure our AI tools adopt pedagogically sound teaching styles. Fine-tuning with a small, high-quality dataset has shown significant improvements in aligning with teaching goals, as confirmed through multi-turn conversation evaluations. Additionally, our framework includes a model-evaluation backend that teaching assistants periodically review, ensuring the AI system remains effective and aligned with instructional objectives. This paper offers insights into our methods and the impact of these AI tools on CS50 and contributes to the discourse on AI in education, showcasing scalable, personalized learning enhancements.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {715–721},
numpages = {7},
keywords = {ai, artificial intelligence, generative ai, large language models, llms},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3599957.3606244,
author = {Lee, Eun-young and il, Ngagaba Gogo Dae and An, Gi-hong and Lee, Sungchul and Lim, Kiho},
title = {ChatGPT-Based Debate Game Application Utilizing Prompt Engineering},
year = {2023},
isbn = {9798400702280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3599957.3606244},
doi = {10.1145/3599957.3606244},
abstract = {This paper1 focuses on the implementation of a debate game using ChatGPT, aiming to investigate the feasibility of incorporating large language models into the educational domain through prompt engineering. The study explores strategies to elicit desired outputs from the GPT model by employing the prompt engineering methodology, as provided by Microsoft.Specifically, the game implementation involves the customization of ChatGPT's responses to facilitate a natural progression of debates, varying levels of difficulty, and an evaluation system for assessing the quality of discourse. By leveraging the prompt engineering methodology, we demonstrate that providing specific instructions or case-based prompts improves the accuracy and relevance of ChatGPT's answers. The developed application targets teenagers, enabling them to engage in real-time debates with ChatGPT and enhance their literacy skills. Furthermore, the game fosters the development of logical reasoning, persuasive abilities, effective expression, active participation, and attentive listening while expressing personal opinions, ultimately fostering a sense of accomplishment. Moreover, through debate evaluation and personalized advice, ChatGPT is expected to recognize and address its shortcomings, thereby continuously improving its conversational capabilities.Overall, this research contributes to the understanding of how large language models can be harnessed in educational settings and underscores the potential benefits of prompt engineering techniques in optimizing the outputs of such models.},
booktitle = {Proceedings of the 2023 International Conference on Research in Adaptive and Convergent Systems},
articleno = {29},
numpages = {6},
keywords = {Prompt Engineering, Large Language Model, ChatGPT},
location = {Gdansk, Poland},
series = {RACS '23}
}

@inproceedings{10.1145/3675094.3677573,
author = {Wang, Yongfu and Tang, Mingyue and He, Yifan and Tang, Tiffany Y.},
title = {Interactive Design with Autistic Children using LLM and IoT for Personalized Training: The Good, The Bad and The Challenging},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3677573},
doi = {10.1145/3675094.3677573},
abstract = {The advent of generative artificial intelligence technologies, such as Large Language Models (LLMs) and Large Vision Models (LVMs), has shown promising results in both academic and industrial sectors, leading to widespread adoption. However, there has been limited focus on applying these technologies to assist children with special needs like Autism Spectrum Disorder (ASD). Meanwhile, conventional personalized training with interactive design for children with special needs continues to face significant challenges with traditional approaches. This workshop aims to provide a platform for researchers, software developers, medical practitioners, and designers to discuss and evaluate the benefits and drawbacks of using LLMs and the Internet of Things (IoT) for the diagnosis and personalized training of autistic children. Through a series of activities, including oral presentations, demonstrations, and panel discussions, this half-day workshop seeks to foster a network of experts dedicated to improving the lives of children with special needs and to inspire further research on leveraging emerging ubiquitous technologies for these underprivileged users, their caregivers and special education teachers.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1000–1003},
numpages = {4},
keywords = {autism, children, interaction design, large language model (llm), personalized training, ubiquitous computing},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3613905.3650862,
author = {Jung, Yongnam and Chen, Cheng and Jang, Eunchae and Sundar, S. Shyam},
title = {Do We Trust ChatGPT as much as Google Search and Wikipedia?},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650862},
doi = {10.1145/3613905.3650862},
abstract = {Although studies, audits, and anecdotal observations have shown that information generated by ChatGPT is not always accurate, many users tend to show unwarranted trust in this new source. Do they consider ChatGPT to be like any other online information source such as Google and Wikipedia, without realizing that generative AI technology creates content that is not necessarily based on facts? Why do they trust information from ChatGPT? Understanding how users perceive content from generative AI tools is crucial because it can help reduce unwarranted trust in inaccurate information and mitigate the spread of misinformation. A focus group and interview study (N=14) revealed that thankfully not all users trust ChatGPT-generated information as much as Google Search and Wikipedia. It also shed light on the primary psychological considerations when trusting an online information source, namely perceived gatekeeping, and perceived information completeness. In addition, technological affordances such as interactivity and crowdsourcing were also found to be important for trust formation. We discuss theoretical and practical implications for design of generative AI interfaces.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {111},
numpages = {9},
keywords = {ChatGPT, Google, Trust, Wikipedia},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3641555.3705281,
author = {Li, Carol and Park, Su Min and Tsang, Jedidiah and Yan, Lisa},
title = {What Gets Them Talking? Identifying Catalysts for Student Engagement Within a Computing Ethics Course},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705281},
doi = {10.1145/3641555.3705281},
abstract = {The expansion of undergraduate CS programs brings different forms of student identity, sociotechnical perspectives, and intersectionality into the classroom. These background factors affect student understanding of the world, and, consequently, their work in computing ethic classes. Instructors of computing ethics courses therefore must facilitate topics that are not only pertinent to modern technologies but that are also interesting for students from a range of backgrounds. In this work, we introduce a low-overhead, natural language processing tool that can assist instructors in extracting student talking points from over 600 discussion forum posts in a large-scale undergraduate computing ethics course. When compared to large language model approaches, this n-gram-based scripting tool is more effective in selecting popular quotes and summarizing course discussion. This tool is simple in implementation and can be easily adapted by instructors to prepare for classroom discussion.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1521–1522},
numpages = {2},
keywords = {computing ethics, llm-based tool, n-gram-based tool, open pedagogy, student engagement},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3639474.3640062,
author = {Ouhbi, Sofia},
title = {Bridging the Theory-Practice Gap in a Maintenance Programming Course: An Experience Report},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640062},
doi = {10.1145/3639474.3640062},
abstract = {This paper presents our experience in teaching a maintenance programming course with the aim of bridging the gap between theory and practice, a recurring issue in previous course offerings. To achieve this goal, we implemented active learning strategies within an active learning classroom setting and redesigned the project work. Our approach involves peer learning and teamwork activities to cover various aspects of legacy code maintenance. For the project work, we adopted an open-ended approach that allowed students to choose their legacy code projects, which could be open-source software or a previous software project they had worked on. Analysis of students' feedback and project reports highlighted the effectiveness of our approach in bridging the gap between theory and practice. We believe that our approach had the potential to enhance students' engagement and critical thinking abilities, as well as improve practical maintenance skills relevant to their future careers.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {359–367},
numpages = {9},
keywords = {software maintenance, software engineering education, open-ended project, group work, active learning, students engagement, generative AI},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3586183.3606826,
author = {Yan, Zihan and Yang, Chunxu and Liang, Qihao and Chen, Xiang 'Anthony'},
title = {XCreation: A Graph-based Crossmodal Generative Creativity Support Tool},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606826},
doi = {10.1145/3586183.3606826},
abstract = {Creativity Support Tools (CSTs) aid in the efficient and effective composition of creative content, such as picture books. However, many existing CSTs only allow for mono-modal creation, whereas previous studies have become theoretically and technically mature to support multi-modal innovative creations. To overcome this limitation, we introduce XCreation, a novel CST that leverages generative AI to support cross-modal storybook creation. Nevertheless, directly deploying AI models to CSTs can still be problematic as they are mostly black-box architectures that are not comprehensible to human users. Therefore, we integrate an interpretable entity-relation graph to intuitively represent picture elements and their relations, improving the usability of the underlying generative structures. Our between-subject user study demonstrates that XCreation supports continuous plot creation with increased creativity, controllability, usability, and interpretability. XCreation is applicable to various scenarios, including interactive storytelling and picture book creation, thanks to its multimodal nature.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {48},
numpages = {15},
keywords = {Creativity Support Tool, Cross-modality, Generative AI, Graph},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3675585.3675587,
author = {Angeles, Chito Naorbe and Samson, Brylle Dimaano and Mama, Bai Rafsan Zahna Ibad and Luriaga, Ronnie Lucero and Delizo, John Pierre Demata and Ching, Michelle Renee Domingo},
title = {Students'perception of the use of AI Detector System by faculty members in determining the originality of submitted academic requirements},
year = {2024},
isbn = {9798400717659},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675585.3675587},
doi = {10.1145/3675585.3675587},
abstract = {Recent studies revealed an overwhelming concern about the misuse of generative Artificial Intelligence (AI) tools by students in completing academic requirements. The detection of AI-generated content using the naked eye was perceived to be difficult, hence the need for more accurate, reliable, and effective detection methods. As a countermeasure, educators are turning to AI content detectors and plagiarism checkers to ascertain the originality of submitted school requirements, raising concerns from students regarding the accuracy and reliability of these tools and the ethical implications and negative consequences of misclassification of genuinely original works as machine-generated outputs. By employing a holistic case study approach, the authors attempted to determine the perceptions of selected university students on the use of AI detection systems by faculty members in checking the originality and novelty of their academic outputs. Through the lenses of various normative ethical theories, the authors also analyzed the ethical issues and concerns raised by selected students to better understand their sentiments and the factors they believe could influence the faculty members' intention to adopt this emerging technology. The results of the study revealed that students have mixed attitudes and perceptions toward the faculty's intention to use AI detectors. While students perceived it as a means to encourage independent learning and critical thinking, they also expressed valid concerns regarding fairness, accuracy, and reliability, the impact on teacher-student trust, and the responsible use of the technology, among others. The participants also acknowledged the influence of other faculty members and the students' increasing dependence on AI as possible enablers of technology adoption while technological limitations, the teachers’ lack of technological skills, and age as perceived barriers. From an ethical view, the findings of the study highlighted the importance of transparency, fairness, privacy, and the need for a policy to regulate AI use.},
booktitle = {Proceedings of the 2024 8th International Conference on E-Commerce, E-Business, and E-Government},
pages = {56–61},
numpages = {6},
keywords = {AI Detectors, Ethical Theories, Generative AI, TPB},
location = {Ajman, United Arab Emirates},
series = {ICEEG '24}
}

@inproceedings{10.1145/3613905.3647958,
author = {Kim, Munyeong},
title = {GPTs in Mafia-like Game Simulation},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3647958},
doi = {10.1145/3613905.3647958},
abstract = {In this research, we explore the potential of Generative AI models, focusing on their application in role-playing simulations through Spyfall, a renowned mafia-style game. By leveraging GPT-4’s advanced capabilities, the study aimed to showcase the model’s potential in understanding, decision-making, and interaction across scenarios. Comparative analyses between GPT-4 and its predecessor, GPT-3.5-turbo, demonstrated GPT-4’s enhanced adaptability to the environment, with significant improvements in posing questions and forming responses. However, challenges such as the model’s limitations in judging and suspecting actions of other players emerged. Reflections on AI’s future capability and directions were also discussed. The findings suggest that although GPT-4 exhibits promising advancements over earlier models, there is potential for further development through expanding data and training techniques. The findings also underscore the importance of maintaining an inclusive and unbiased approach throughout this process, suggesting immense potential for Generative AI and its application.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {611},
numpages = {5},
keywords = {AI in Gaming, Decision-making, GPT-3.5-turbo, GPT-4, Game Strategy, Generative AI, Limitations of GPT, Natural Language Processing, Role-playing Simulations, Spyfall},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3706598.3713497,
author = {Bhattacharya, Aditya and Stumpf, Simone and De Croon, Robin and Verbert, Katrien},
title = {Explanatory Debiasing: Involving Domain Experts in the Data Generation Process to Mitigate Representation Bias in AI Systems},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713497},
doi = {10.1145/3706598.3713497},
abstract = {Representation bias is one of the most common types of biases in artificial intelligence (AI) systems, causing AI models to perform poorly on underrepresented data segments. Although AI practitioners use various methods to reduce representation bias, their effectiveness is often constrained by insufficient domain knowledge in the debiasing process. To address this gap, this paper introduces a set of generic design guidelines for effectively involving domain experts in representation debiasing. We instantiated our proposed guidelines in a healthcare-focused application and evaluated them through a comprehensive mixed-methods user study with 35 healthcare experts. Our findings show that involving domain experts can reduce representation bias without compromising model accuracy. Based on our findings, we also offer recommendations for developers to build robust debiasing systems guided by our generic design guidelines, ensuring more effective inclusion of domain experts in the debiasing process.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1119},
numpages = {20},
keywords = {Representation Bias, Bias detection, Debiasing, Explainable AI, XAI, Generative AI, GenAI, Responsible AI, Fair AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3689535.3689537,
author = {Stone, Irene},
title = {Investigating the Use of ChatGPT to Support the Learning of Python Programming Among Upper Secondary School Students: A Design-Based Research Study},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689537},
doi = {10.1145/3689535.3689537},
abstract = {This study investigates how ChatGPT can be used to support the learning of Python programming among upper second-level students in an Irish classroom. It addresses critical gaps in the literature, such as the lack of research at secondary level, the need for human-centered studies conducted over time, and the absence of guidelines for integrating ChatGPT into introductory programming education. Employing a design-based research methodology, this study aims to understand student engagement with ChatGPT and investigates how to support their use of prompts when learning to program. The research involves students as co-creators alongside their teacher, who is also the researcher, in developing a pedagogical framework that integrates ChatGPT into Python programming education.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {11},
numpages = {1},
keywords = {AI, CS1, ChatGPT, LLMs, artificial intelligence, design-based research, generative AI, human-centered, novice programming, pedagogical practices, programming, python, student-centered},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3643795.3648393,
author = {Chusap, Krerkkiat and Liu, Chang},
title = {Gauging Tech Community Acceptance of Rapid Prototyping in Unfamiliar Programming Languages using LLM Chatbots},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648393},
doi = {10.1145/3643795.3648393},
abstract = {Large Language Model (LLM) chatbots such as ChatGPT possess information not only about human languages but also computer languages. It is now possible to perform programming and software design tasks with assistance from ChatGPT. We are particularly interested in how the software development community views the use of LLM chatbots in rapid prototyping using unfamiliar programming languages. In four different tech events, several example scenarios of how a tech-savvy engineer could use ChatGPT to prototype apps in unfamiliar programming languages were demonstrated, including a health education app. The four events include an IEEE chapter workshop, an IEEE WIE (Woman In Engineering) meeting, an IEEE joint chapter talk, and a university-level Computer Science class. The responses from the tech audience showed that the majority perceived value in the use of LLM chatbots in these contexts, even though there were subtle differences among different groups. This shows the need for further research on how to effectively incorporate LLM chatbots into traditional software design workflow to better serve the software development community.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {8–13},
numpages = {6},
keywords = {software engineering, software design, rapid prototyping, LLMs, ChatGPT},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3723010.3723036,
author = {B\"{o}hm, Karsten},
title = {Towards a Semantic Representation of Framework Recommendations for Curricular Specifications in Higher Education},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723036},
doi = {10.1145/3723010.3723036},
abstract = {Curricular specifications play an important role in the Higher Education sector and the domain of Computer Science and Software Engineering is characterized by a wide range of education programs with a broad range of topic. Therefore, recommendation frameworks play an important role and their usage is beneficial for a unification of education profiles in a systematic way. This  research is contributing to this development by exploring how a recommendation for the domain of Business Informatics in German speaking countries can be improved by formalizing the recommendations in a semantic model that relies on sophisticated European ontologies in the domain like the European Learning Model (ELM) and related data models. It employs Generative Artificial Intelligence Systems to create semantic models in an experimental way and evaluates the resulting model quality. The results show that a formalization using GenAI has a high potential, but currently also shows deficits in the correctness of the resulting models, requiring human oversight during the model creation.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {154–160},
numpages = {7},
keywords = {Business Informatics, Competence Specification, European Learning Model, Higher Education, Learning Framework, Semantic Web},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3689535.3689546,
author = {Andrei, Oana and Sojtory, Zoltan},
title = {LLM-aided Pair Programming for Algorithm Tracing},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689546},
doi = {10.1145/3689535.3689546},
abstract = {The recent widespread popularity of generative AI models has inspired the development of large-language model (LLM) based tools for educational purposes. We explore the impact of LLM-based tools on pair programming for algorithm tracing with the aim of addressing challenges inherent to pair programming. We designed and developed a GPT-4 based tool, TraceCompanion, that acts as students’ pair programming partner for algorithm tracing. We describe insights gained from running a pilot study to investigate students’ interactions with the tool and their initial perceptions.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {20},
numpages = {1},
keywords = {algorithm tracing, large language models, pair programming},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3613905.3650732,
author = {Yan, Lixiang and Echeverria, Vanessa and Fernandez-Nieto, Gloria Milena and Jin, Yueqiao and Swiecki, Zachari and Zhao, Linxuan and Ga\v{s}evi\'{c}, Dragan and Martinez-Maldonado, Roberto},
title = {Human-AI Collaboration in Thematic Analysis using ChatGPT: A User Study and Design Recommendations},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650732},
doi = {10.1145/3613905.3650732},
abstract = {Generative artificial intelligence (GenAI) offers promising potential for advancing human-AI collaboration in qualitative research. However, existing works focused on conventional machine-learning and pattern-based AI systems, and little is known about how researchers interact with GenAI in qualitative research. This work delves into researchers’ perceptions of their collaboration with GenAI, specifically ChatGPT. Through a user study involving ten qualitative researchers, we found ChatGPT to be a valuable collaborator for thematic analysis, enhancing coding efficiency, aiding initial data exploration, offering granular quantitative insights, and assisting comprehension for non-native speakers and non-experts. Yet, concerns about its trustworthiness and accuracy, reliability and consistency, limited contextual understanding, and broader acceptance within the research community persist. We contribute five actionable design recommendations to foster effective human-AI collaboration. These include incorporating transparent explanatory mechanisms, enhancing interface and integration capabilities, prioritising contextual understanding and customisation, embedding human-AI feedback loops and iterative functionality, and strengthening trust through validation mechanisms.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {191},
numpages = {7},
keywords = {ChatGPT, Generative Artificial Intelligence, Human-AI Collaboration, Qualitative Research, Thematic Analysis},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3654777.3676374,
author = {Xie, Liwenhan and Zheng, Chengbo and Xia, Haijun and Qu, Huamin and Zhu-Tian, Chen},
title = {WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676374},
doi = {10.1145/3654777.3676374},
abstract = {Large language models (LLMs) support data analysis through conversational user interfaces, as exemplified in OpenAI’s ChatGPT (formally known as Advanced Data Analysis or Code Interpreter). Essentially, LLMs produce code for accomplishing diverse analysis tasks. However, presenting raw code can obscure the logic and hinder user verification. To empower users with enhanced comprehension and augmented control over analysis conducted by LLMs, we propose a novel approach to transform LLM-generated code into an interactive visual representation. In the approach, users are provided with a clear, step-by-step visualization of the LLM-generated code in real time, allowing them to understand, verify, and modify individual data operations in the analysis. Our design decisions are informed by a formative study (N=8) probing into user practice and challenges. We further developed a prototype named WaitGPT and conducted a user study (N=12) to evaluate its usability and effectiveness. The findings from the user study reveal that WaitGPT facilitates monitoring and steering of data analysis performed by LLMs, enabling participants to enhance error detection and increase their overall confidence in the results.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {119},
numpages = {14},
keywords = {Code Verification, Conversational Data Analysis, Generative AI, Human-AI Interaction, LLM Agent, Visual Programming},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3673791.3698402,
author = {Kurohashi, Sadao},
title = {From Data Platforms to Knowledge Infrastructure},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673791.3698402},
doi = {10.1145/3673791.3698402},
abstract = {Modern society is facing pressing issues, including environmental challenges, inequality, and regional conflicts. To resolve these complex societal problems, the concept of ''open science'' is essential, as emphasized at last year's G7 meeting. In Japan, starting in 2025, all scientific papers resulting from publicly funded research, along with the associated data, will be required to be immediately accessible through open access.The National Institute of Informatics (NII) has been at the forefront of advancing Japan's academic information infrastructure for many years. In 2017, NII embarked on the development of the NII Research Data Cloud -- a platform for the publication, discovery, and management of academic information -- which became operational in 2021. By 2022, the project evolved into a research data ecosystem, built in collaboration with numerous universities and research institutions. This initiative aims to create a comprehensive environment where papers, data, and computational resources are readily accessible across all fields of research.Recognizing the significant impact of generative AI on society and the need for a hub in Japan where large-scale language models (LLMs) can be developed and studied, NII spearheaded the formation of the LLM-jp study group (https://llm-jp.nii.ac.jp/en/) in May 2023. The group, founded on principles of openness, began with approximately 30 researchers specializing in natural language processing and has since grown to over 1,800 participants from industry, government, and academia.In April 2024, NII further advanced this initiative by establishing the LLM R&amp;D Center. By September 2024, the center had developed and released the world's largest fully open LLM, featuring 172 billion parameters -- on a scale similar to GPT-3.5. The center's ongoing work also focuses on ensuring the reliability and transparency of these models. To address the complex societal challenges mentioned above, it is crucial not only to deepen academic research but also to foster collaboration across various disciplines, creating new cross-disciplinary knowledge. LLMs can play a pivotal role in these processes by interpreting data, interconnecting and systematizing knowledge, and laying the groundwork for a robust knowledge infrastructure.},
booktitle = {Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {114},
numpages = {1},
keywords = {generative ai, knowledge infrastructure, large language models (llms), llm-jp, open science},
location = {Tokyo, Japan},
series = {SIGIR-AP 2024}
}

@inproceedings{10.1145/3678884.3681856,
author = {Rasberry, Nadra and Essandoh, Joshua and Do, Ethan and Ogbonnaya-Ogburu, Ihudiya Finda},
title = {Designing Technology to Support the Hospital Classroom: Preliminary Findings},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678884.3681856},
doi = {10.1145/3678884.3681856},
abstract = {Hospital teachers are state-employed educators who provide K-12 instruction to children in the hospital. We conducted research to understand how technology is used in hospital classrooms, an area which has been relatively underexplored. We conducted semi-structured interviews with five hospital teachers to understand their experience of using technology in and outside the classroom. Our findings revealed that hospital teachers often rely on older curricula given the changing education atmosphere; learning is often assessed through in-classroom observations of mastery; and technology and internet use by students is often restricted, which may inhibit opportunities to use AI and other technical resources in the classroom. We contribute a deeper understanding of technology use in the hospital classroom.},
booktitle = {Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
pages = {228–232},
numpages = {5},
keywords = {curriculum development, generative ai, hospital education, hospital teachers, lesson planning},
location = {San Jose, Costa Rica},
series = {CSCW Companion '24}
}

@inproceedings{10.1145/3699538.3699581,
author = {Vassar, Alexandra and Renzella, Jake and Ross, Emily and Taylor, Andrew},
title = {Fine-Tuning Large Language Models for Better Programming Error Explanations},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699581},
doi = {10.1145/3699538.3699581},
abstract = {This paper investigates supervised fine-tuning of large language models (LLMs) to improve their pedagogical alignment in computing education, addressing concerns that LLMs may hinder learning outcomes. The project utilised a proprietary dataset of 2,500 high quality question/answer pairs from programming course forums, and explores two research questions: the suitability of university course forums in contributing to fine-tuning datasets, and how supervised fine-tuning can improve LLMs’ alignment with educational principles such as constructivism. Initial findings suggest benefits in pedagogical alignment of LLMs, with deeper evaluations required.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {26},
numpages = {2},
keywords = {Programming Error Messages, CS1, AI in CS1, AI in Education, Generative AI, LLM},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3641554.3701974,
author = {P?durean, Victor-Alexandru and Denny, Paul and Singla, Adish},
title = {BugSpotter: Automated Generation of Code Debugging Exercises},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701974},
doi = {10.1145/3641554.3701974},
abstract = {Debugging is an essential skill when learning to program, yet its instruction and emphasis often vary widely across introductory courses. In the era of code-generating large language models (LLMs), the ability for students to reason about code and identify errors is increasingly important. However, students frequently resort to trial-and-error methods to resolve bugs without fully understanding the underlying issues. Developing the ability to identify and hypothesize the cause of bugs is crucial but can be time-consuming to teach effectively through traditional means. This paper introduces BugSpotter, an innovative tool that leverages an LLM to generate buggy code from a problem description and verify the synthesized bugs via a test suite. Students interact with BugSpotter by designing failing test cases, where the buggy code's output differs from the expected result as defined by the problem specification. This not only provides opportunities for students to enhance their debugging skills, but also to practice reading and understanding problem specifications. We deployed BugSpotter in a large classroom setting and compared the debugging exercises it generated to exercises hand-crafted by an instructor for the same problems. We found that the LLM-generated exercises produced by BugSpotter varied in difficulty and were well-matched to the problem specifications. Importantly, the LLM-generated exercises were comparable to those manually created by instructors with respect to student performance, suggesting that BugSpotter could be an effective and efficient aid for learning debugging.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {896–902},
numpages = {7},
keywords = {bugspotter, debugging, exercise generation, generative ai, llms, programming education, test cases},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3600211.3604695,
author = {Edenberg, Elizabeth and Wood, Alexandra},
title = {Disambiguating Algorithmic Bias: From Neutrality to Justice},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604695},
doi = {10.1145/3600211.3604695},
abstract = {As algorithms have become ubiquitous in consequential domains, societal concerns about the potential for discriminatory outcomes have prompted urgent calls to address algorithmic bias. In response, a rich literature across computer science, law, and ethics is rapidly proliferating to advance approaches to designing fair algorithms. Yet computer scientists, legal scholars, and ethicists are often not speaking the same language when using the term ‘bias.’ Debates concerning whether society can or should tackle the problem of algorithmic bias are hampered by conflations of various understandings of bias, ranging from neutral deviations from a standard to morally problematic instances of injustice due to prejudice, discrimination, and disparate treatment. This terminological confusion impedes efforts to address clear cases of discrimination. In this paper, we examine the promises and challenges of different approaches to disambiguating bias and designing for justice. While both approaches aid in understanding and addressing clear algorithmic harms, we argue that they also risk being leveraged in ways that ultimately deflect accountability from those building and deploying these systems. Applying this analysis to recent examples of generative AI, our argument highlights unseen dangers in current methods of evaluating algorithmic bias and points to ways to redirect approaches to addressing bias in generative AI at its early stages in ways that can more robustly meet the demands of justice.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {691–704},
numpages = {14},
keywords = {algorithms, bias, discrimination, fairness, generative AI, justice, large language models, law, philosophy, vision-language models},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

@article{10.5555/3729857.3729874,
author = {Bandi, Ajay and Blackford, Benjamin and Fellah, Aziz and Linville, Diana and Meyer, Trevor C. and Voss, Robert J.},
title = {Prompting Collaboration: Development of an Multidisciplinary Applied AI Minor Program},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {6},
issn = {1937-4771},
abstract = {Artificial Intelligence (AI) has rapidly transformed industries and research, becoming a driving force for technological innovation and development [1]. As AI continues to grow and change, it is reshaping the way we approach problem-solving, decision-making, and creative processes across various sectors. Northwest Missouri State University is developing a new multidisciplinary AI minor open to all undergraduate students on campus. The program is tailored for students from any discipline who want to explore how AI can be utilized and integrated into their fields such as computer science, humanities, business, sciences, healthcare, agriculture, and education, among others. The curriculum integrates topics such as foundational AI concepts, prompt engineering and writing processes, ethical considerations in AI, AI in the workplace, and a capstone project. This program also promotes interdisciplinary collaboration and emphasizes the ethical use of AI.By the end of the program, students will be able to use AI to enhance efficiency and accuracy in tasks, develop and evaluate effective prompts, apply generative AI tools across various input formats, and assess the ethical considerations of AI in real-world applications. The panel members are experts from diverse fields, including management, humanities, technical writing, and computer science. The panel discusses the development of the AI minor curriculum and explores opportunities to extend the AI curriculum by offering AI certificates for undergraduate and graduate online professional students. By attending this panel, the audience will gain valuable insights into developing comprehensive AI programs, fostering cross-disciplinary innovation, and preparing students to use AI ethically and effectively across diverse fields.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {129–132},
numpages = {4}
}

@inproceedings{10.1145/3657604.3662040,
author = {Gabbay, Hagit and Cohen, Anat},
title = {Combining LLM-Generated and Test-Based Feedback in a MOOC for Programming},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662040},
doi = {10.1145/3657604.3662040},
abstract = {In large-scale programming courses, providing learners with immediate and effective feedback is a significant challenge. This study explores the potential of Large Language Models (LLMs) to generate feedback on code assignments and to address the gaps in Automated Test-based Feedback (ATF) tools commonly employed in programming courses. We applied dedicated metrics in a Massive Open Online Course (MOOC) on programming to assess the correctness of feedback generated by two models, GPT-3.5-turbo and GPT-4, using a reliable ATF as a benchmark. The findings point to effective error detection, yet the feedback is often inaccurate, with GPT-4 outperforming GPT-3.5-turbo. We used insights gained from the prompt practices to develop Gipy, an application for submitting course assignments and obtaining LLM-generated feedback. Learners participating in a field experiment perceived the feedback provided by Gipy as moderately valuable, while at the same time recognizing its potential to complement ATF. Given the learners' critique and their awareness of the limitations of LLM-generated feedback, the studied implementation may be able to take advantage of the best of both ATF and LLMs as feedback resources. Further research is needed to assess the impact of LLM-generated feedback on learning outcomes and explore the capabilities of more advanced models.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {177–187},
numpages = {11},
keywords = {MOOC for programming, automated feedback, generative AI, large language models (LLMs), programming education},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3653666.3656075,
author = {Okolo, Chinasa T.},
title = {Beyond AI Hype: A Hands-on Workshop Series for Enhancing AI Literacy in Middle and High School Students},
year = {2024},
isbn = {9798400706264},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653666.3656075},
doi = {10.1145/3653666.3656075},
abstract = {The increasing usage of AI in high-stakes decision-making underscores a pressing need for various stakeholders to understand AI, learn how to identify AI-generated content, and become aware of its societal risks. We detail outcomes from engaging underrepresented secondary school students in a 5-day workshop series consisting of brief lectures, hands-on activities, and short research assignments. We find that the workshop improved students' knowledge about AI and the ethical implications of using these technologies. Our work highlights policy implications and outlines actionable efforts needed to advance AI literacy, with the workshop content being developed into an open-source AI literacy curriculum.},
booktitle = {Proceedings of the 2024 on RESPECT Annual Conference},
pages = {86–93},
numpages = {8},
keywords = {ai literacy, ai pedagogy, computing education, equity, generative ai, human-centered ai, technology ethics},
location = {Atlanta, GA, USA},
series = {RESPECT 2024}
}

@inproceedings{10.1145/3626253.3635483,
author = {Lee Solano, Lorenzo and Renzella, Jake and Vassar, Alexandra},
title = {DCC Sidekick: Helping Novices Solve Programming Errors Through a Conversational Explanation Interface},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635483},
doi = {10.1145/3626253.3635483},
abstract = {Students in introductory computing courses often lack the experience required to effectively identify and resolve errors in their code. For such students, Programming Error Messages (PEMs) are often the first indication of an error, and could provide valuable debugging guidance. However, in many cases, such as with standard C compiler implementations, PEMs are largely unsuitable for novices. Confusing, misleading, and filled with terse language and jargon, these messages instead act as an additional source of difficulty.In this paper, we present DCC Sidekick, which integrates the Debugging C Compiler (DCC) with a Large Language Model (LLM) in a web-based dashboard to produce contextual, accurate guidance conducive to student learning. This dashboard is directly accessible from the output of the compiler, and provides a bird's-eye-view of the program source, compiler output, and a conversational AI interface to help unravel cryptic error messages. We aim to deploy DCC Sidekick to a C-based CS1 cohort at a large higher education institution to investigate how novice students utilise the conversational explanation interface during debugging activities. In this work, we present our experience designing and building DCC Sidekick.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1714–1715},
numpages = {2},
keywords = {ai in education, compiler error messages, cs1, error message enhancement, generative ai},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3706598.3713952,
author = {Zha, Siyu and Liu, Yujia and Zheng, Chengbo and Xu, Jiaqi and Yu, Fuze and Gong, Jiangtao and Xu, Yingqing},
title = {Mentigo: An Intelligent Agent for Mentoring Students in the Creative Problem Solving Process},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713952},
doi = {10.1145/3706598.3713952},
abstract = {Creative Problem-Solving (CPS) promotes creative and critical thinking while enhancing real-world problem-solving skills, making it essential for middle school education. However, providing personalized mentorship in CPS projects at scale is challenging due to resource constraints and diverse student needs. To address this, we developed Mentigo, an AI-driven mentor agent designed to guide middle school students through the CPS process. Using a dataset of real classroom interactions, we encoded CPS task stages, adaptive guidance strategies, and personalized feedback mechanisms to inform Mentigo‘s dynamic mentoring framework powered by large language models (LLMs). A comparative experiment with 12 students and evaluations from five expert educators demonstrated improved student engagement, creativity, and task performance. Our findings highlight design implications for using LLM-based AI mentors to enhance CPS learning in educational environments.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {199},
numpages = {22},
keywords = {Generative AI, Agent, creative problem solving, mentor},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3626252.3630784,
author = {Rogers, Michael P. and Hillberg, Hannah Miller and Groves, Christopher L.},
title = {Attitudes Towards the Use (and Misuse) of ChatGPT: A Preliminary Study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630784},
doi = {10.1145/3626252.3630784},
abstract = {ChatGPT is the front end to a powerful large language model that has garnered widespread attention in many fields of study, including computer science (CS), where it promises to be transformational. As educators, we are just starting to grapple with the ramifications of this new technology, including implications for what we teach, how we teach, and how we grade. The decisions educators make moving forward depend heavily on the prevalence of students' use (and misuse) of ChatGPT in the classroom. Further, predictors of nefarious use could aid educators as well. We conducted an online survey to capture CS student awareness of, experience with, and attitudes toward ChatGPT. Through quantitative and qualitative analysis, we found that awareness of ChatGPT is generally high, and it is more frequently being used as a study tool than to complete students' work for them. Most students are aware of the potential for abuse in academic pursuits, but a notable minority of students admit to using it unscrupulously and to the potential for it to interfere with their learning. We conclude with a discussion of factors to consider as educators modify their approaches and develop guidelines for ChatGPT usage in their classrooms.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1147–1153},
numpages = {7},
keywords = {academic misconduct, artificial intelligence, chatgpt, large language models, student survey},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3639592.3639629,
author = {Diloy, Marlon A. and Comparativo, Cyrix Pearl E. and Reyes, John Carl T. and Eusebio, Berna Jhane M. and Morona, Lance Ian C.},
title = {Exploring the Landscape of AI Tools in Student Learning: An analysis of commonly utilized AI Tools at a university in the Philippines},
year = {2024},
isbn = {9798400716225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639592.3639629},
doi = {10.1145/3639592.3639629},
abstract = {Artificial intelligence (AI) has become a prominent tool within the education sector, which is set to begin an innovative revolution. Researchers aim to analyze what AI tools are commonly utilized by students in consideration of the program they are enrolled to. Thus, providing the university with an opportunity to integrate it into its existing curriculum. It aims to promote a deeper understanding and utilization of AI technologies while also acknowledging and resolving the challenges associated with its use in the academe. The researchers used an electronic survey to gather information on what AI tools are commonly used per school department at a university in the Philippines. The results show that students mostly use AI writing assistant tools, and students believe that their performance was enhanced by using these. Researchers concluded that artificial intelligence should be discussed more in terms of its capabilities in the education sector. Moreover, with the results obtained in this study, the university may consider adjusting its pedagogy, assessment styles, and other policies to ensure that students are compelled to submit their own works and not AI generated, and students are able to use AI confidently and responsibly in their professional future.},
booktitle = {Proceedings of the 2023 6th Artificial Intelligence and Cloud Computing Conference},
pages = {266–271},
numpages = {6},
keywords = {Academe, Artificial Intelligence, Curriculum, Generative AI, Instruction},
location = {Kyoto, Japan},
series = {AICCC '23}
}

@inproceedings{10.1145/3689236.3696039,
author = {Wu, Jing and Guo, Zhenxin and Wang, Zhicheng and Zhang, Haotian and Kang, Xaolin and Ma, Xiaoguang},
title = {Design and Implementation of Embedded Qinghai Tourism Customer Service Question-and-Answer Robot Based on ChatGPT},
year = {2024},
isbn = {9798400718137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689236.3696039},
doi = {10.1145/3689236.3696039},
abstract = {The application of big data technology has brought new impetus and possibilities to the development of tourism. The design of an embedded Q&amp;A robot system for Qinghai tourism customer service based on ChatGPT system aims to provide an intelligent customer service solution to help users obtain information about Qinghai tourism and answer questions. The system uses ChatGPT as the core dialogue model, combines the knowledge and data in the field of Qinghai tourism, and realizes the intelligent answer to user questions. This study application in the field of natural language processing, and analyzes the design requirements and implementation scheme of embedded travel question answering system in detail. The function module includes user login and registration, travel tickets, hotel information query, scenic spot ticket price query and other essential basic function modules of the tourism website. Whether the design is reasonable or not will also directly affect the user experience. The results show that ChatGPT embedded in Qinghai tourism Q&amp;A system can not only provide more intelligent and accurate answers, but also enhance the interactivity and practicability of the system, and provide users with more convenient and personalized tourism information services.},
booktitle = {Proceedings of the 2024 9th International Conference on Cyber Security and Information Engineering},
pages = {871–882},
numpages = {12},
keywords = {ChatGPT, Chatbot, Generative Artificial Intelligence, Qinghai Tourism},
location = {
},
series = {ICCSIE '24}
}

@article{10.1145/3708889,
author = {Boutadjine, Amal and Harrag, Fouzi and Shaalan, Khaled},
title = {Human vs. Machine: A Comparative Study on the Detection of AI-Generated Content},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {2},
issn = {2375-4699},
url = {https://doi.org/10.1145/3708889},
doi = {10.1145/3708889},
abstract = {The surge in advancements in large language models (LLMs) has expedited the generation of synthetic text imitating human writing styles. This, however, raises concerns about the potential misuse of synthetic textual data, which could compromise trust in online content. Against this backdrop, the present research aims to address the key challenges of detecting LLMs-generated texts. In this study, we used ChatGPT (v 3.5) because of its widespread and capability to comprehend and keep conversational context, allowing it to produce meaningful and contextually suitable responses. The problem revolves around the task of discerning between authentic and artificially generated textual content. To tackle this problem, we first created a dataset containing both real and DeepFake text. Subsequently, we employed transfer-learning (TL) and conducted DeepFake-detection utilizing SOTA large pre-trained LLMs. Furthermore, we conducted validation using benchmark datasets comprising unseen data samples to ensure that the model's performance reflects its ability to generalize to new data. Finally, we discussed this study's theoretical contributions, practical implications, limitations and potential avenues for future research, aiming to formulate strategies for identifying and detecting large-generative-models’ produced texts. The results were promising, with accuracy ranging from 94% to 99%. The comparison between automatic detection and the human ability to detect DeepFake text revealed a significant gap in the human capacity for its identification, emphasizing an increasing need for sophisticated automated detectors. The investigation into AI-generated content detection holds central importance in the age of LLMs and technology convergence. This study is both timely and adds value to the ongoing discussion regarding the challenges associated with the pertinent theme of "DeepFake text detection", with a special focus on examining the boundaries of human detection.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = feb,
articleno = {12},
numpages = {26},
keywords = {Language processing, Large Language Models, Generative AI, AI-Generated Content detection, Comparative Study, ChatGPT}
}

@inproceedings{10.1145/3613905.3650763,
author = {Gmeiner, Frederic and Conlin, Jamie Lynn and Tang, Eric Handa and Martelaro, Nikolas and Holstein, Kenneth},
title = {An Evidence-based Workflow for Studying and Designing Learning Supports for Human-AI Co-creation},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650763},
doi = {10.1145/3613905.3650763},
abstract = {Generative artificial intelligence (GenAI) systems introduce new possibilities for enhancing professionals’ workflows, enabling novel forms of human–AI co-creation. However, professionals often struggle to learn to work with GenAI systems effectively. While research has begun to explore the design of interfaces that support users in learning to co-create with GenAI, we lack systematic approaches to investigate the effectiveness of these supports. In this paper, we present a systematic approach for studying how to support learning to co-create with GenAI systems, informed by methods and concepts from the learning sciences. Through an experimental case study, we demonstrate how our approach can be used to study and compare the impacts of different types of learning supports in the context of text-to-image GenAI models. Reflecting on these results, we discuss directions for future work aimed at improving interfaces for human–AI co-creation.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {42},
numpages = {15},
keywords = {Case Study, Generative AI, Human–AI Co-creation, Human–AI Interaction, Learning, Study Method, Support Interfaces},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3706598.3713532,
author = {Chung, Joon Gi and Hong, Soongi and Choi, Junho and Oh, Changhoon},
title = {Understanding the Dynamics in Deploying AI-Based Content Creation Support Tools in Broadcasting Systems - Benefits, Challenges, and Directions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713532},
doi = {10.1145/3706598.3713532},
abstract = {Recent advancements in generative artificial intelligence (AI) are profoundly impacting the broadcasting industry. While generative AI shows promise in supporting broadcasting professionals, its practical workflow integration remains underexplored. In this study, we conducted a user-focused investigation to understand how AI-based content creation support tools are being adopted and perceived in South Korean broadcasting stations. We used the AI Editing Assistant, an AI-powered post-production support tool, as a research probe. Through in-depth interviews with 37 diverse participants—including directors, editors, producers, developers, and executives—we discovered that generative AI significantly enhances production efficiency and unlocks new creative possibilities. However, we identified challenges such as lack of user-centered approach, demanding nature of broadcasting workflows, and professionals’ low trust in AI technologies hinders widespread adoption. Based on our findings, we propose implications, considerations, and guidelines for integrating generative AI into broadcasting practices, emphasizing improved multi-stakeholder communication and collaboration for effective and sustainable AI adoption.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {27},
numpages = {28},
keywords = {AI-based content creation support tools, Human-AI collaboration, Broadcasting systems, User-centered approach, Domain-specific AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3708557.3716158,
author = {Mokryn, Osnat and Shaer, Orit and Geyer, Werner and Maher, Mary Lou and Weisz, Justin D. and Buschek, Daniel and Chilton, Lydia B},
title = {HAI-GEN 2025: 6th Workshop on Human-AI Co-Creation with Generative Models},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716158},
doi = {10.1145/3708557.3716158},
abstract = {Generative Artificial Intelligence (GAI) models capable of complex tasks are revolutionizing areas previously considered to define humanity, such as creativity, design, and knowledge work. Research reports that Human-GAI co-creation processes can enhance creativity and even foster a sense of empowerment. A key innovation is the intent-based outcome specification, where users define desired results through natural language, sketches, or gestures, thus shifting control from users to AI models. This paradigm enables new forms of co-creation while presenting challenges in creating effective and safe outcome specifications.This workshop aims to investigate the design, implementation, and evaluation of intent-based co-creative experiences that boost human creativity in work, play, and education across text, images, audio, code, and video. Key questions focus on how creativity support can guide generative AI development and how to leverage generative models for positive user experiences. By uniting researchers and practitioners from Human-Computer Interaction (HCI) and AI, the workshop seeks to deepen understanding of human-AI co-creative interactions and explore opportunities and challenges in developing meaningful and safe generative systems.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {179–182},
numpages = {4},
keywords = {Generative modeling, artificial intelligence, generative design, user experience, co-creation, collaboration, creativity},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3649217.3653612,
author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Denny, Paul},
title = {Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653612},
doi = {10.1145/3649217.3653612},
abstract = {Large language models (LLMs) have shown great potential for the automatic generation of feedback in a wide range of computing contexts. However, concerns have been voiced around the privacy and ethical implications of sending student work to proprietary models. This has sparked considerable interest in the use of open source LLMs in education, but the quality of the feedback that such open models can produce remains understudied. This is a concern as providing flawed or misleading generated feedback could be detrimental to student learning. Inspired by recent work that has utilised very powerful LLMs, such as GPT-4, to evaluate the outputs produced by less powerful models, we conduct an automated analysis of the quality of the feedback produced by several open source models using a dataset from an introductory programming course. First, we investigate the viability of employing GPT-4 as an automated evaluator by comparing its evaluations with those of a human expert. We observe that GPT-4 demonstrates a bias toward positively rating feedback while exhibiting moderate agreement with human raters, showcasing its potential as a feedback evaluator. Second, we explore the quality of feedback generated by several leading open-source LLMs by using GPT-4 to evaluate the feedback. We find that some models offer competitive performance with popular proprietary LLMs, such as ChatGPT, indicating opportunities for their responsible use in educational settings.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {52–58},
numpages = {7},
keywords = {automatic evaluation, automatic feedback, code llama, generative ai, gpt-4, large language models, llm-as-a-judge, llms, open source, programming feedback, zephyr},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3613905.3636313,
author = {Nebeling, Michael and Oki, Mika and Gelsomini, Mirko and Hayes, Gillian R and Billinghurst, Mark and Suzuki, Kenji and Graf, Roland},
title = {Designing Inclusive Future Augmented Realities},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636313},
doi = {10.1145/3613905.3636313},
abstract = {Augmented and mixed reality technology is rapidly advancing, driven by innovations in display, sensing, and AI technologies. This evolution, particularly in the era of generative AI with large language and text-to-image models such as GPT and Stable Diffusion, has the potential, not only to make it easier to create, but also to adapt and personalize, new content. Our workshop explores the pivotal role of augmented and mixed reality to shape a user’s interactions with their physical surroundings. We aim to explore how inclusive future augmented realities can be designed, with increasing support for automation, such that environments can welcome users with different needs, emphasizing accessibility and inclusion through layers of augmentations. Our aim is not only to remove barriers by providing accommodations, but also to create a sense of belonging by directly engaging users. Our workshop consists of three main activities: (1) Through brainstorming and discussion of examples provided by the workshop organizers and participants, we critically review the landscape of accessible and inclusive design and their vital role in augmented and mixed reality experiences. (2) Through rapid prototyping activities including bodystorming and low-fidelity, mixed-media prototypes, participants explore how augmented and mixed reality can transform physical space into a more personal place, enhancing accessibility and inclusion based on novel interface and interaction techniques that are desirable, but not necessarily technically feasible just yet. In the workshop, we plan to focus on physical space to facilitate rapid prototyping without technical constraints, but techniques developed in the workshop are likely applicable to immersive virtual environments as well. (3) Finally, we collaborate to outline a research agenda for designing future augmented realities that promote equal opportunities, benefiting diverse user populations. Our workshop inspires innovation in augmented and mixed reality, reshaping physical environments to be more accessible and inclusive through immersive design.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {466},
numpages = {6},
keywords = {Spatial computing, accessible and inclusive design., generative AI},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3641237.3691669,
author = {Strubberg, Brandon C and Bennett, Kristin C and Nardone, Carroll Ferguson},
title = {Developing AI Literacy through Discussion and Practice: A Reflection on an AI Seminar},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691669},
doi = {10.1145/3641237.3691669},
abstract = {This experience report reflects on a longitudinal project aimed at determining ways that generative artificial intelligence (gen AI) can be leveraged as a pedagogical tool to assist in professionalizing students’ rhetorical understanding and use of the tool beyond the academy. Since ChatGPT launched, we have studied students’ engagement with gen AI tools to bridge academic and professional uses, believing that knowing when and how to deploy such tools can facilitate the gen AI literacy students need to have upon entering their professional careers. This report posits that students’ participatory design in the pedagogical structure is vital for creating localized practices that translate to tangible forms of AI literacies.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {189–193},
numpages = {5},
keywords = {Generative artificial intelligence, digital literacies, technical communication, writing pedagogy},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@inproceedings{10.1145/3641308.3677403,
author = {Dong, Jiayuan and Gowda, Nikhil and Wang, Yiyuan and Choe, Mungyeong and Alsaid, Areen and Alvarez, Ignacio and Krome, Sven and Jeon, Myounghoon},
title = {Inside Out: Emotion GaRage Vol. V},
year = {2024},
isbn = {9798400705205},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641308.3677403},
doi = {10.1145/3641308.3677403},
abstract = {The rapid advancement of automated vehicles has aroused the curiosity of researchers in the automotive field. Understanding the emotional aspects of this technology is critical to improving human-vehicle interactions. The topics of the proposed workshop will be expanded from internal to external empathetic interface designs of automated vehicles. The workshop will gather researchers and practitioners to brainstorm and design affective internal and external interfaces for automated vehicles, targeting specific use cases within the social context. During the workshop, participants will use an affective design tool and generative AI to prototype affective interface designs in automated vehicles. With this creative approach, we aim to expand the knowledge of affective eHMIs in addition to in-vehicle designs and understand social factors that contribute to the user perceptions of automated vehicles.CCS CONCEPTS •Human-centered computing∼Human computer interaction (HCI)∼HCI theory, concepts and models},
booktitle = {Adjunct Proceedings of the 16th International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
pages = {260–263},
numpages = {4},
keywords = {affective external human-machine interaction designs, emotions, empathic in-vehicle interfaces, generative artificial intelligence},
location = {Stanford, CA, USA},
series = {AutomotiveUI '24 Adjunct}
}

@inproceedings{10.1145/3706598.3713668,
author = {O'Brien, Gabrielle},
title = {How Scientists Use Large Language Models to Program},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713668},
doi = {10.1145/3706598.3713668},
abstract = {Scientists across disciplines write code for critical activities like data collection and generation, statistical modeling, and visualization. As large language models that can generate code have become widely available, scientists may increasingly use these models during research software development. We investigate the characteristics of scientists who are early-adopters of code generating models and conduct interviews with scientists at a public, research-focused university. Through interviews and reviews of user interaction logs, we see that scientists often use code generating models as an information retrieval tool for navigating unfamiliar programming languages and libraries. We present findings about their verification strategies and discuss potential vulnerabilities that may emerge from code generation practices unknowingly influencing the parameters of scientific analyses.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {876},
numpages = {16},
keywords = {Code assistant, Copilot, generative AI, program synthesis, data science, data analysis},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3610978.3640622,
author = {Jokinen, Kristiina and Wilcock, Graham},
title = {Exploring a Japanese Cooking Database},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3640622},
doi = {10.1145/3610978.3640622},
abstract = {The paper describes ongoing work applying Generative AI to a real world application. We use Retrieval Augmented Generation and other GenAI tools that combine large language models with Neo4j knowledge graphs. These tools help a robot to chat in English about Japanese cooking using a knowledge base that is in Japanese.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {578–582},
numpages = {5},
keywords = {Japanese cooking, cypher query language, generative AI, graph databases, knowledge graphs, large language models, retrieval augmented generation, semantic search, social robots},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3706598.3714069,
author = {Alvarado Garcia, Adriana and Candello, Heloisa and Badillo-Urquiola, Karla and Wong-Villacres, Marisol},
title = {Emerging Data Practices: Data Work in the Era of Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714069},
doi = {10.1145/3706598.3714069},
abstract = {Data is one of the foundational aspects of making Artificial Intelligence (AI) work as intended. As large language models (LLMs) become the epicenter of AI, it is crucial to understand better how the datasets that maintain such models are created. The emergent nature of LLMs makes it critical to understand the challenges practitioners developing Gen AI technologies face to design alternatives for better responding to Gen AI’s ethical issues. In this paper, we provide such understanding by reporting on 25 interviews with practitioners who handle data in three distinct development stages of different LLMs. Our contributions are (1) empirical evidence of how uncertainty, data practices, and reliance mechanisms change across LLMs’ development cycle; (2) how the unique qualities of LLMs impact data practices and their implications for the future of Gen AI technologies; and (3) provide three opportunities for HCI researchers interested in supporting practitioners developing Gen AI technologies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {846},
numpages = {21},
keywords = {data work, data practices, AI, LLMs, synthetic data, data governance, AI practitioners, GenAI, generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3657604.3664690,
author = {Salminen, Joni and Jung, Soon-gyo and Medina, Johanne and Aldous, Kholoud and Azem, Jinan and Akhtar, Waleed and Jansen, Bernard J.},
title = {Using Cipherbot: An Exploratory Analysis of Student Interaction with an LLM-Based Educational Chatbot},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664690},
doi = {10.1145/3657604.3664690},
abstract = {Cipherbot, an educational chatbot using large language models to answer student questions concerning learning materials uploaded by the educator, was pilot tested in a classroom setting. Forty-four students used Cipherbot for seven weeks, sending 8077 messages. The average number of messages sent per student was 184 (SD = 80), with an average length of 98 characters (SD = 80). The engagement followed a non-normal distribution, with few power users, implying that most students are still hesitant to adopt tools like Cipherbot. Cipherbot was able to answer 82.5% of the student questions, demonstrating a scalable ability to address students' learning queries, with some room for improvement.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {279–283},
numpages = {5},
keywords = {LLMs, cipherbot, generative AI, student interaction},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3678719.3685691,
author = {Garc\'{\i}a, Boni and Leotta, Maurizio and Ricca, Filippo and Whitehead, Jim},
title = {Use of ChatGPT as an Assistant in the End-to-End Test Script Generation for Android Apps},
year = {2024},
isbn = {9798400711091},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678719.3685691},
doi = {10.1145/3678719.3685691},
abstract = {Automated testing is crucial in software development to ensure that applications perform as intended. However, generating automated End-to-End (E2E) tests can be time-consuming and challenging, especially for junior developers. This study investigates the use of ChatGPT, a popular Generative Artificial Intelligence (GenAI) model, as an assistant in developing automated E2E test scripts for Android apps. We present an empirical study that compares the effort required to create E2E test scripts and the resulting reliability of these tests using two treatments: manually and assisted by ChatGPT. We used Gherkin, a domain-specific language that allows non-technical practitioners to define test scenarios using a human-readable syntax. Our findings indicate that using ChatGPT significantly reduces the time required to develop automated test scripts without compromising the reliability of the scripts. Statistical analysis shows a notable reduction in development time for the ChatGPT-assisted group compared to the manual group, with a large effect size. While the reliability of the tests did not show a significant difference between the two groups, the results suggest practical benefits in terms of efficiency.},
booktitle = {Proceedings of the 15th ACM International Workshop on Automating Test Case Design, Selection and Evaluation},
pages = {5–11},
numpages = {7},
keywords = {Android, E2E Automated Testing, Empirical Study, GenAI},
location = {Vienna, Austria},
series = {A-TEST 2024}
}

@inproceedings{10.1145/3696410.3714640,
author = {Wang, Tianlong and Jiao, Xianfeng and Zhu, Yinghao and Chen, Zhongzhi and He, Yifan and Chu, Xu and Gao, Junyi and Wang, Yasha and Ma, Liantao},
title = {Adaptive Activation Steering: A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714640},
doi = {10.1145/3696410.3714640},
abstract = {Recent studies have indicated that Large Language Models (LLMs) harbor an inherent understanding of truthfulness, yet often fail to consistently express it and generate false statements. This gap between ''knowing'' and ''telling'' poses a challenge for ensuring the truthfulness of generated content. Inspired by recent work on the practice of encoding human-interpretable concepts linearly within large language models, we treat truthfulness as a specially linearly encoded concept within LLMs, and introduce Adaptive Activation Steering (ACT), a tuning-free method that adaptively shifts LLM's activations in the ''truthful'' direction during inference. ACT addresses diverse categories of hallucinations by utilizing diverse truthfulness-related steering vectors and adjusting the steering intensity adaptively. Applied as an add-on across various models, ACT significantly improves truthfulness in LLaMA (↑142%), LLaMA2 (↑24%), Alpaca (↑36%), Vicuna (↑28%), LLaMA2-Chat (↑19%), and LLaMA3(↑34%). Furthermore, we verify ACT's scalability across larger models (13B, 33B, 65B), underscoring the adaptability of ACT to large-scale language models. Our code is available at https://github.com/tianlwang/ACT.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {2562–2578},
numpages = {17},
keywords = {hallucination, large language model, tuning-free},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3638264.3638273,
author = {Ma, Xiangyao and Zhang, Yunlei and Mao, Shaoni and Li, Youcai},
title = {Cross-Platform Network Public Opinion Topic Modeling},
year = {2024},
isbn = {9798400709258},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638264.3638273},
doi = {10.1145/3638264.3638273},
abstract = {This study focuses on cross-platform online public opinion topic modeling and analysis, using popular topics on social media platforms, including Weibo and Zhihu. Through preprocessing, text embedding, dimension reduction, and clustering, we extract keywords related to the topics, and use generative artificial intelligence to convert topic representations into natural language. This study effectively analyzes the topic features implicit in user generated contents. Experimental results indicate that our method outperforms existing one and can effectively model online public opinion topics. The results were analyzed, and the experimental results indicated that proposed method can effectively model online public opinion topics, providing new insights for monitoring and analyzing online public opinion.},
booktitle = {Proceedings of the 2023 International Conference on Mathematics, Intelligent Computing and Machine Learning},
pages = {36–41},
numpages = {6},
keywords = {Cross Platform, Data Mining, Generative AI, Public Opinion, Topic Model},
location = {Chengdu, China},
series = {MICML '23}
}

@inproceedings{10.1145/3711403.3711438,
author = {Zhang, Shaojun and He, Xiangchun and Zhou, Yaxin and Jiang, Ruishuang and Han, Yuqi and Guo, Xue},
title = {Artificial Intelligence Helps Teachers Personalise Their Teaching--Take ChatGPT as an Example},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711438},
doi = {10.1145/3711403.3711438},
abstract = {With the continuous development of science and technology, Artificial Intelligence (AI) has become an important driving force for innovation in the field of education, especially advanced AI language models such as ChatGPT, which shows great potential in assisting teachers to design, implement and evaluate personalised teaching due to its excellent language comprehension and generative ability. Nevertheless, how to use ChatGPT to help teachers carry out personalised teaching has yet to be explored. Therefore, this paper explores and analyses the ways in which ChatGPT can help teachers carry out personalised teaching based on the connotation of ChatGPT and personalised teaching, and discusses the challenges faced when using ChatGPT to assist teachers in carrying out personalised teaching, from the perspective of the three aspects of teaching: lesson planning, instruction, and evaluation and feedback. It also discusses the challenges faced when using ChatGPT to assist teachers in personalised teaching and proposes strategies to address them. The study shows that artificial intelligence can make teachers more scientific, precise, intelligent and diversified in the process of implementing personalised teaching.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {200–205},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, Personalised Teaching},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3610540.3627011,
author = {Zarzycki, Andrzej},
title = {Maintaining agency in AI-generated works of art and design: Deliberate creative processes},
year = {2023},
isbn = {9798400703119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610540.3627011},
doi = {10.1145/3610540.3627011},
abstract = {This paper responds to the unfolding debate on the use of generative AI tools in art and design. As the conversations and technological frameworks remain in their early stages the paper focuses on emerging possibilities and methodologies rather than on broader claims or conclusions. The discussed methods can serve as an effective entry point for education and curricula developments with practical advice and conceptual framing to contextualize emerging AI tools in a broader artistic culture and legacy. While the discussion on autonomous creativity is a significant part of the future of AI system developments and their relationship with humanity, this paper specifically limits its contribution to human-to-AI interactions as an important step in understanding intentionality, agency, and identity in that newly formed landscape.},
booktitle = {SIGGRAPH Asia 2023 Educator's Forum},
articleno = {9},
numpages = {8},
keywords = {Stable Diffusion, Generative AI, Artificial intelligence, AI-based creative process},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@inproceedings{10.1145/3716640.3716655,
author = {W\"{u}nsche, Burkhard Claus and Hooper, Steffan and Whalley, Jacqueline and Straand, Ingjerd and Denny, Paul and Crow, Tyne and Lange-Nawka, Dominik and Luxton-Reilly, Andrew and Thompson, Samuel E. R.},
title = {Leveling up Learning: Serious Games for Computing Education - Long-Term Opportunities and Risks},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716655},
doi = {10.1145/3716640.3716655},
abstract = {Serious games are becoming an increasingly popular tool in education, including computing education, due to their potential to engage learners, practice skills development, stimulate creativity, promote active learning, and cultivate exploration. However, few researchers have discussed the potential long-term implications of using serious games for learning programming and how they can be addressed.This paper investigates opportunities and drawbacks arising from the wider use of serious games in computing education. We look beyond immediate effects, such as the risk of distraction and technological barriers, and consider prospects and risks caused by market forces and the economic realities of the game, education, and software industries. In particular, we discuss how technological advances can increase the benefits of serious games for programming education, but also that there is a risk that an increasing use of serious games might result in market dominance of a few vendors, lack of diversity, cultural bias, inequity, pressure on education funding, and reduced learning outcomes.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {134–143},
numpages = {10},
keywords = {Serious Games, Computing Education, Diversity, Equality, Accessibility, Generative AI, AR/VR, Game Industry},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3661904.3661921,
author = {Serato, Jay Vince Donoso and Sta. Romana, Cherry Lyn},
title = {Development and Utilization of AI-Enabled Automatic Programming Problem Generator Using the CodeRunner Plugin of Moodle},
year = {2024},
isbn = {9798400717895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661904.3661921},
doi = {10.1145/3661904.3661921},
abstract = {Programming instructors provide various kinds of problems that suit their current topics of programming. With the use of Learning Management Systems (LMS) such as Moodle, teachers can create and store their problems in problem banks using a question plugin CodeRunner. However creating and validating programming problems takes significant time and creative effort. With instructors dealing multiple programming languages, it would need mastery not only to solve the problem but also to use a specific language. This paper presents an automation of the programming problem generation using AI. This is effectively an improvement of the CodeRunner plugin of Moodle that allows programming instructors to generate problem descriptions, answers, and testcases of different programming topics in various programming languages with a few clicks. To address the issue of difficulty control, an additional feature is placed to generate an easier or harder problem than what is currently generated. The evaluation of the improved tool showed that the problems generated with AI are similar, correct, and practical that matches the human-generated problems.},
booktitle = {Proceedings of the 2024 10th International Conference on Education and Training Technologies},
pages = {147–152},
numpages = {6},
keywords = {Automatic question generation, Generative AI, Programming learning},
location = {Macau, China},
series = {ICETT '24}
}

@article{10.1145/3735129,
author = {Yang, Boyang and Tian, Haoye and Ren, Jiadong and Zhang, Hongyu and Klein, Jacques and Bissyande, Tegawende and Le Goues, Claire and Jin, Shunfu},
title = {MORepair: Teaching LLMs to Repair Code via Multi-Objective Fine-Tuning},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3735129},
doi = {10.1145/3735129},
abstract = {Within the realm of software engineering, specialized tasks on code, such as program repair, present unique challenges, necessitating fine-tuning Large language models&nbsp;(LLMs) to unlock state-of-the-art performance. Fine-tuning approaches proposed in the literature for LLMs on program repair tasks generally overlook the need to reason about the logic behind code changes, beyond syntactic patterns in the data. High-performing fine-tuning experiments also usually come at very high computational costs. With MORepair, we propose a novel perspective on the learning focus of LLM fine-tuning for program repair: we not only adapt the LLM parameters to the syntactic nuances of the task of code transformation (objective ➊), but we also specifically fine-tune the LLM with respect to the logical reason behind the code change in the training data (objective ➋). Such a multi-objective fine-tuning will instruct LLMs to generate high-quality patches.We apply MORepair to fine-tune four open-source LLMs with different sizes and architectures. Experimental results on function-level and repository-level repair benchmarks show that the implemented fine-tuning effectively boosts LLM repair performance by 11.4% to 56.0%. We further show that our fine-tuning strategy yields superior performance compared to the state-of-the-art approaches, including standard fine-tuning, Fine-tune-CoT, and RepairLLaMA.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Program Repair, Fine-tuning, Large Language Model, Open Source}
}

@article{10.1145/3712006,
author = {Autili, Marco and De Sanctis, Martina and Inverardi, Paola and Pelliccione, Patrizio},
title = {Engineering Digital Systems for Humanity: A Research Roadmap},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712006},
doi = {10.1145/3712006},
abstract = {As testified by new regulations like the European AI Act, worries about the human and societal impact of (autonomous) software technologies are becoming of public concern. Human, societal, and environmental values, alongside traditional software quality, are increasingly recognized as essential for sustainability and long-term well-being. Traditionally, systems are engineered taking into account business goals and technology drivers. Considering the growing awareness in the community, in this article, we argue that engineering of systems should also consider human, societal, and environmental drivers. Then, we identify the macro and technological challenges by focusing on humans and their role while co-existing with digital systems. The first challenge considers humans in a proactive role when interacting with digital systems, i.e., taking initiative in making things happen instead of reacting to events. The second concerns humans having a reactive role in interacting with digital systems, i.e., humans interacting with digital systems as a reaction to events. The third challenge focuses on humans with a passive role, i.e., they experience, enjoy or even suffer the decisions and/or actions of digital systems. The fourth challenge concerns the duality of trust and trustworthiness, with humans playing any role. Building on the new human, societal, and environmental drivers and the macro and technological challenges, we identify a research roadmap of digital systems for humanity. The research roadmap is concretized in a number of research directions organized into four groups: development process, requirements engineering, software architecture and design, and verification and validation.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {130},
numpages = {33},
keywords = {Human values, Societal values, Environmental values, Research directions, Research roadmap, Software engineering}
}

@inproceedings{10.1145/3613905.3636272,
author = {Nacke, Lennart E.},
title = {How to Write Better CHI Papers (with AI)},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636272},
doi = {10.1145/3613905.3636272},
abstract = {Writing and organizing research papers is a valuable skill that can make or break your academic career. Generative artificial intelligence (AI) tools offer unprecedented opportunities for researchers to improve their skills in writing research papers and conducting literature reviews. In the past six years, my writing course has introduced you to everything you wanted to know about writing papers. However, with the arrival of generative AI, our writing process is changing. So, now I offer the opportunity to learn how to leverage generative AI tools to edit your writing, brainstorm, and help you find citations, so that your papers are easy to read and have impact. It is broken up into three 75-minute online units that will help you structure your paper’s research content and use generative AI as assistive research technology. The goal of the course is to learn how to leverage generative AI to help you write a paper that makes a contribution to the field of human-computer interaction and can be understood by other HCI researchers facilitated by the use of generative AI tools.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {599},
numpages = {4},
keywords = {Clarity, LaTeX, Research Methods, Submission Process, Writing},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3641554.3701872,
author = {McDanel, Bradley and Novak, Ed},
title = {Designing LLM-Resistant Programming Assignments: Insights and Strategies for CS Educators},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701872},
doi = {10.1145/3641554.3701872},
abstract = {The rapid advancement of Large Language Models (LLMs) like ChatGPT has raised concerns among computer science educators about how programming assignments should be adapted. This paper explores the capabilities of LLMs (GPT-3.5, GPT-4, and Claude Sonnet) in solving complete, multi-part CS homework assignments from the SIGCSE Nifty Assignments list. Through qualitative and quantitative analysis, we found that LLM performance varied significantly across different assignments and models, with Claude Sonnet consistently outperforming the others. The presence of starter code and test cases improved performance for advanced LLMs, while certain assignments, particularly those involving visual elements, proved challenging for all models. LLMs often disregarded assignment requirements, produced subtly incorrect code, and struggled with context-specific tasks. Based on these findings, we propose strategies for designing LLM-resistant assignments. Our work provides insights for instructors to evaluate and adapt their assignments in the age of AI, balancing the potential benefits of LLMs as learning tools with the need to ensure genuine student engagement and learning.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {756–762},
numpages = {7},
keywords = {ai-resistant assignments, assignment design, cs education, llm code generation, programming pedagogy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649165.3690113,
author = {Kasinidou, Maria and Kleanthous, Styliani and Otterbacher, Jahna},
title = {"We have to learn to work with such systems": Students' Perceptions of ChatGPT After a Short Educational Intervention on NLP},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690113},
doi = {10.1145/3649165.3690113},
abstract = {Natural Language Processing (NLP) is a critical area of AI that is increasingly integrated into everyday life. The public regularly engages with systems such as Siri, Alexa, and more recently, ChatGPT, yet few understand how these systems work. In this paper, we examine how students perceive NLP technologies after completing a unit on NLP within an AI course designed for non-CS majors. We further present our students' perspectives on the banning of ChatGPT in Italy, where the course was delivered. The NLP unit featured a lecture, an interactive session, and a practical assignment wherein students developed a smart assistant responsive to textual commands. Students, after creating their smart assistants, highlighted challenges such as inadequate training datasets and natural language ambiguity. Opinions on ChatGPT's ban varied, with privacy concerns prevailing. However, a consensus emerged in favor of educational efforts to raise awareness about technology limitations, advocating understanding over outright bans in anticipation of their inevitable integration into daily life.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {74–80},
numpages = {7},
keywords = {artificial intelligence, chatgpt, large language models, natural language processing},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3706598.3713192,
author = {Xu, Wenjie and Yu, Zhoutong and Liu, Yikun and Ying, Fangtian},
title = {Accompany Sleep: Using GenAI to Create Bedtime Stories for Mediating Parent-Child Relationships in LBC Families},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713192},
doi = {10.1145/3706598.3713192},
abstract = {Left-Behind Children (LBC) refers to children who lack daily companionship due to their parents working away from home, accounting for approximately one-fifth of all children in China. Due to the lack of communication and emotional support from their parents, LBCs often experience physical and mental health issues. Effective communication is usually limited by time and topics, and the format of mobile devices and video calls is not always suitable. To address this issue, we developed the Accompany Sleep system. Parents upload daily life content through the app, and the system uses ChatGPT4o to create bedtime stories projected to the LBC. To explore the role of Accompany Sleep in family mediation, we conducted a one-month user study involving four families. The results of the study indicated that both parents and children exhibited positive behaviors, the parent-child relationship was effectively strengthened, and GenAI played a crucial role in this process. Based on these findings, this paper discusses how Accompany Sleep facilitated behavioral changes and improved parent-child relationships while expanding the application of GenAI in the family domain.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1037},
numpages = {19},
keywords = {Parent-child relationship, left-behind children, bedtime stories, generative artificial intelligence, emotional connection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713962,
author = {Kamali, Negar and Nakamura, Karyn and Kumar, Aakriti and Chatzimparmpas, Angelos and Hullman, Jessica and Groh, Matthew},
title = {Characterizing Photorealism and Artifacts in Diffusion Model-Generated Images},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713962},
doi = {10.1145/3706598.3713962},
abstract = {Diffusion model-generated images can appear indistinguishable from authentic photographs, but these images often contain artifacts and implausibilities that reveal their AI-generated provenance. Given the challenge to public trust in media posed by photorealistic AI-generated images, we conducted a large-scale experiment measuring human detection accuracy on 450 diffusion-model generated images and 149 real images. Based on collecting 749,828 observations and 34,675 comments from 50,444 participants, we find that scene complexity of an image, artifact types within an image, display time of an image, and human curation of AI-generated images all play significant roles in how accurately people distinguish real from AI-generated images. Additionally, we propose a taxonomy characterizing artifacts often appearing in images generated by diffusion models. Our empirical observations and taxonomy offer nuanced insights into the capabilities and limitations of diffusion models to generate photorealistic images in 2024.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {794},
numpages = {26},
keywords = {photorealism, diffusion models, generative AI, synthetic media, deepfakes, misinformation},
location = {
},
series = {CHI '25}
}

@article{10.5555/3715638.3715656,
author = {Roll, James},
title = {AI as a Learning Tool for Introductory Programming},
year = {2024},
issue_date = {September 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {4},
issn = {1937-4771},
abstract = {The goal of this assignment is to introduce introductory programming students to using generative AI tools like Claude and ChatGPT to help them in learning introductory programming. Students are shown how they can use AI tools to help explain basic programming concepts, decode cryptic error messages, explain why a program isn't working, and find syntax errors in and suggest fixes. Students are also encouraged to avoid using AI Tools to fully write programs at this point in their education, and introduced to the limitations generative AI tools for programming. This version of the assignment was written for an introductory Java programming course, but could easily be adapted to other programming languages.},
journal = {J. Comput. Sci. Coll.},
month = sep,
pages = {45},
numpages = {1}
}

@inproceedings{10.1145/3574318.3574329,
author = {Majumdar, Srijoni and Bandyopadhyay, Ayan and Das, Partha Pratim and Clough, Paul and Chattopadhyay, Samiran and Majumder, Prasenjit},
title = {Can we predict useful comments in source codes? - Analysis of findings from Information Retrieval in Software Engineering Track @ FIRE 2022},
year = {2023},
isbn = {9798400700231},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3574318.3574329},
doi = {10.1145/3574318.3574329},
abstract = {The Information Retrieval in Software Engineering (IRSE) track aims to develop solutions for automated evaluation of code comments in a machine learning framework. In this track, there is a binary classification task to classify comments as useful and not useful. The dataset consists of 9048 code comments and surrounding code snippet pairs extracted from open source github C based projects. Overall 34 experiments have been submitted by 11 teams from various universities and software companies. The submissions have been evaluated quantitatively using the F1-Score and qualitatively based on the type of features developed, the supervised learning model used and their corresponding hyper-parameters. The best performing architectures mostly have employed transformer architectures coupled with a software development related embedding space.},
booktitle = {Proceedings of the 14th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {15–17},
numpages = {3},
keywords = {neural networks, bert, abstract syntax tree, Stanford POS Tagging, GPT-2},
location = {Kolkata, India},
series = {FIRE '22}
}

@inproceedings{10.1145/3626253.3635519,
author = {Denzler, Benjamin and Vahid, Frank and Pang, Ashley},
title = {Style Anomalies Can Suggest Cheating in CS1 Programs},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635519},
doi = {10.1145/3626253.3635519},
abstract = {Student cheating on at-home programming assignments is a well-known problem. A key contributor is externally obtained solutions from websites, contractors, and recently generative AI. In our experience, such externally obtained solutions often use coding styles that depart from a class's style, which we call "style anomalies". Examples of style anomalies include using untaught or advanced constructs like pointers or ternary operators or having different indenting or brace usage from the class style. We developed a tool to automatically count style anomalies in student code submissions. We used this tool to find suspected cheating in student submissions for lab assignments across five terms of CS1. This poster presents our findings: Some student submissions were suspected of cheating due to high style anomaly counts and were not flagged as suspicious by a code similarity checker. With the rise of externally obtained solutions from websites, contractors, and generative AI, style anomalies may become an important complement to similarity checking for detecting cheating.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1624–1625},
numpages = {2},
keywords = {cheating, cs1, plagiarism, program autograders, program style},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3593434.3593468,
author = {Ahmad, Aakash and Waseem, Muhammad and Liang, Peng and Fahmideh, Mahdi and Aktar, Mst Shamima and Mikkonen, Tommi},
title = {Towards Human-Bot Collaborative Software Architecting with ChatGPT},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593434.3593468},
doi = {10.1145/3593434.3593468},
abstract = {Architecting software-intensive systems can be a complex process. It deals with the daunting tasks of unifying stakeholders’ perspectives, designers’ intellect, tool-based automation, pattern-driven reuse, and so on, to sketch a blueprint that guides software implementation and evaluation. Despite its benefits, architecture-centric software engineering (ACSE) suffers from a multitude of challenges. ACSE challenges could stem from a lack of standardized processes, socio-technical limitations, and scarcity of human expertise etc. that can impede the development of existing and emergent classes of software. Software Development Bots (DevBots) trained on large language models can help synergise architects’ knowledge with artificially intelligent decision support to enable rapid architecting in a human-bot collaborative ACSE. An emerging solution to enable this collaboration is ChatGPT, a disruptive technology not primarily introduced for software engineering, but is capable of articulating and refining architectural artifacts based on natural language processing. We detail a case study that involves collaboration between a novice software architect and ChatGPT to architect a service-based software. Future research focuses on harnessing empirical evidence about architects’ productivity and explores socio-technical aspects of architecting with ChatGPT to tackle challenges of ACSE.},
booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
pages = {279–285},
numpages = {7},
keywords = {Software Architecture, Large Language Models, DevBots, ChatGPT},
location = {Oulu, Finland},
series = {EASE '23}
}

@inproceedings{10.1145/3544548.3581318,
author = {Zhou, Jiawei and Zhang, Yixuan and Luo, Qianni and Parker, Andrea G and De Choudhury, Munmun},
title = {Synthetic Lies: Understanding AI-Generated Misinformation and Evaluating Algorithmic and Human Solutions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581318},
doi = {10.1145/3544548.3581318},
abstract = {Large language models have abilities in creating high-volume human-like texts and can be used to generate persuasive misinformation. However, the risks remain under-explored. To address the gap, this work first examined characteristics of AI-generated misinformation (AI-misinfo) compared with human creations, and then evaluated the applicability of existing solutions. We compiled human-created COVID-19 misinformation and abstracted it into narrative prompts for a language model to output AI-misinfo. We found significant linguistic differences within human-AI pairs, and patterns of AI-misinfo in enhancing details, communicating uncertainties, drawing conclusions, and simulating personal tones. While existing models remained capable of classifying AI-misinfo, a significant performance drop compared to human-misinfo was observed. Results suggested that existing information assessment guidelines had questionable applicability, as AI-misinfo tended to meet criteria in evidence credibility, source transparency, and limitation acknowledgment. We discuss implications for practitioners, researchers, and journalists, as AI can create new challenges to the societal problem of misinformation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {436},
numpages = {20},
keywords = {AI-generated misinformation, COVID-19, GPT, generative AI, large language model, misinformation, responsible AI},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3586183.3606735,
author = {Huh, Mina and Peng, Yi-Hao and Pavel, Amy},
title = {GenAssist: Making Image Generation Accessible},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606735},
doi = {10.1145/3586183.3606735},
abstract = {Blind and low vision (BLV) creators use images to communicate with sighted audiences. However, creating or retrieving images is challenging for BLV creators as it is difficult to use authoring tools or assess image search results. Thus, creators limit the types of images they create or recruit sighted collaborators. While text-to-image generation models let creators generate high-fidelity images based on a text description (i.e. prompt), it is difficult to assess the content and quality of generated images. We present GenAssist, a system to make text-to-image generation accessible. Using our interface, creators can verify whether generated image candidates followed the prompt, access additional details in the image not specified in the prompt, and skim a summary of similarities and differences between image candidates. To power the interface, GenAssist uses a large language model to generate visual questions, vision-language models to extract answers, and a large language model to summarize the results. Our study with 12 BLV creators demonstrated that GenAssist enables and simplifies the process of image selection and generation, making visual authoring more accessible to all.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {38},
numpages = {17},
keywords = {Accessibility, Creativity Support Tools, Generative AI, Image Generation},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@article{10.1145/3717067,
author = {Jiang, Shuyu and Chen, Xingshu and Tang, Rui},
title = {Deceiving LLM through Compositional Instruction with Hidden Attacks},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1556-4665},
url = {https://doi.org/10.1145/3717067},
doi = {10.1145/3717067},
abstract = {Recently, large language models (LLMs) have demonstrated promising applications in the autonomous driving (AD) domain, including language-based interactions and decision-making. Ensuring they safely handle harmful inputs is crucial before formal deployment. However, research reveals emerging hand-crafted jailbreak attacks, which pack harmful prompts into harmless instructions, can bypass LLMs’ security mechanisms and elicit harmful responses. To deeply understand such jailbreaks, this paper introduces a Compositional Instruction Attack (CIA) framework to generalize them, and develop two CIA jailbreaking methods to automatically generate tailored jailbreak prompts for each harmful prompt. Then, this paper builds the first CIA question-answering (CIAQA) dataset with 2.7K multiple-choice questions of 900 successful jailbreaks, for assessing LLMs’ ability to identify underlying harmful intents, harmfulness, and task priority in CIA jailbreaks. Combined with experimental analysis on CIAQA and other datasets, this paper concludes three possible reasons for the failure of LLM defenses against CIAs. Finally, we propose an intent-based defense paradigm (IBD), enabling LLMs to defend against CIA by leveraging its capability to identify intents. Experimental results show CIA can achieve attack success rates (ASR) of 95%+ and 85%+ in AD and common harmful scenarios for three well-known LLMs (GPT-4, GPT-3.5, and Llama2-70b-chat), and IBD reduces ASR by 74%+.},
note = {Just Accepted},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = feb,
keywords = {Large language model, autonomous driving, adversarial attack, harmful prompt}
}

@inproceedings{10.1145/3689092.3690042,
author = {Ghosh, Shreya and Cai, Zhixi and Dhall, Abhinav and Kollias, Dimitrios and Goecke, Roland and Gedeon, Tom},
title = {MRAC Track 1: 2nd Workshop on Multimodal, Generative and Responsible Affective Computing},
year = {2024},
isbn = {9798400712036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689092.3690042},
doi = {10.1145/3689092.3690042},
abstract = {With the rapid advancements in multimodal generative technology, Affective Computing research has provoked discussion about the potential consequences of AI systems equipped with emotional intelligence. Affective Computing involves the design, evaluation, and implementation of Emotion AI and related technologies aimed at improving people's lives. Designing a computational model in affective computing requires vast amounts of multimodal data, including RGB images, video, audio, text, and physiological signals. Moreover, Affective Computing research is deeply engaged with ethical considerations at various stages'from training emotionally intelligent models on large-scale human data to deploying these models in specific applications. Fundamentally, the development of any AI system must prioritize its impact on humans, aiming to augment and enhance human abilities rather than replace them, while drawing inspiration from human intelligence in a safe and responsible manner. The MRAC 2024 Track 1 workshop seeks to extend these principles from controlled, small-scale lab environments to real-world, large-scale contexts, emphasizing responsible development. The workshop also aims to highlight the potential implications of generative technology, along with the ethical consequences of its use, to researchers and industry professionals. To the best of our knowledge, this is the first workshop series to comprehensively address the full spectrum of multimodal, generative affective computing from a responsible AI perspective, and this is the second iteration of this workshop. Webpage: https://react-ws.github.io/2024/},
booktitle = {Proceedings of the 2nd International Workshop on Multimodal and Responsible Affective Computing},
pages = {1–6},
numpages = {6},
keywords = {affective computing, generative ai, human computer interaction},
location = {Melbourne VIC, Australia},
series = {MRAC '24}
}

@inproceedings{10.1145/3641554.3701791,
author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Ashraf, Syed and Denny, Paul},
title = {Evaluating Language Models for Generating and Judging Programming Feedback},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701791},
doi = {10.1145/3641554.3701791},
abstract = {The emergence of large language models (LLMs) has transformed research and practice across a wide range of domains. Within the computing education research (CER) domain, LLMs have garnered significant attention, particularly in the context of learning programming. Much of the work on LLMs in CER, however, has focused on applying and evaluating proprietary models. In this article, we evaluate the efficiency of open-source LLMs in generating high-quality feedback for programming assignments and judging the quality of programming feedback, contrasting the results with proprietary models. Our evaluations on a dataset of students' submissions to introductory Python programming exercises suggest that state-of-the-art open-source LLMs are nearly on par with proprietary models in both generating and assessing programming feedback. Additionally, we demonstrate the efficiency of smaller LLMs in these tasks and highlight the wide range of LLMs accessible, even for free, to educators and practitioners.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {624–630},
numpages = {7},
keywords = {automatic evaluation, automatic feedback, generative ai, large language models, llm-as-a-judge, open source, programming feedback},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3670653.3677513,
author = {Hofmann, Paula and Brand, Alexa and Sp\"{a}the, Eva and Lins, Sebastian and Sunyaev, Ali},
title = {AI-based Tools in Higher Education: A Comparative Analysis of University Guidelines},
year = {2024},
isbn = {9798400709982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670653.3677513},
doi = {10.1145/3670653.3677513},
abstract = {Im Bildungswesen werden verst\"{a}rkt KI-basierte Tools wie ChatGPT eingesetzt. Allerdings sind viele Studierende und Lehrende unsicher, ob, wie und in welchem Ma\ss{} sie diese Tools im Hochschulkontext einsetzen d\"{u}rfen. Insgesamt mangelt es in Deutschland an Universit\"{a}ten an Richtlinien zum Umgang mit KI-basierten Tools. Aus diesem Grund f\"{u}hrt diese Studie eine vergleichende Analyse von bereits existierenden Richtlinien durch, um die wichtigsten Empfehlungen f\"{u}r den Umgang zu extrahieren und zu aggregieren. Die Ergebnisse zeigen, dass die Relevanz von Richtlinien hoch ist und dabei insbesondere gekl\"{a}rt werden sollte, unter welchen Bedingungen KI-basierte Tools als Hilfsmittel gelten, welche Verantwortlichkeiten bei den Akteuren liegen und wie Risiken und Herausforderungen begegnet werden k\"{o}nnen, um u.a. die akademische Integrit\"{a}t sicherzustellen. Die Ergebnisse der Arbeit unterst\"{u}tzen bei der Ableitung und Synthese von Richtlinien im Hochschulkontext.},
booktitle = {Proceedings of Mensch Und Computer 2024},
pages = {665–673},
numpages = {9},
keywords = {ChatGPT, Generative AI, Generative KI, Guidelines, Hochschule, Richtlinien, University},
location = {Karlsruhe, Germany},
series = {MuC '24}
}

@inproceedings{10.1145/3696410.3714553,
author = {Chen, Zhiyang and Ma, Yun and Shen, Haiyang and Liu, Mugeng},
title = {WeInfer: Unleashing the Power of WebGPU on LLM Inference in Web Browsers},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714553},
doi = {10.1145/3696410.3714553},
abstract = {Web-based large language model (LLM) has garnered significant attention from both academia and industry as it combines the benefits of on-device computation with the accessibility and portability of Web applications. The advent of WebGPU, a modern browser API that enables Web applications to utilize a device's GPU, has opened up new possibilities for GPU-accelerated LLM inference within browsers. However, our experiment reveals that existing Web-based LLM inference frameworks exhibit inefficiencies in GPU utilization, limiting the inference speed. These inefficiencies primarily arise from underutilizing the full capabilities of WebGPU, particularly in resource management and execution synchronization. To address these limitations, we present WeInfer, an efficient Web-based LLM inference framework specifically designed to unleash the power of WebGPU. WeInfer incorporates two key innovations: 1) buffer reuse strategies that reduce the overhead associated with resource preparation, optimizing the lifecycle management of WebGPU buffers, and 2) an asynchronous pipeline that decouples resource preparation from GPU execution, enabling parallelized computation and deferred result fetching to improve overall efficiency. We conduct extensive evaluations across 9 different LLMs and 5 heterogeneous devices, covering a broad spectrum of model architectures and hardware configurations. The results demonstrate that WeInfer delivers substantial improvements in decoding speed, achieving up to a 3.76\texttimes{} performance boost compared with WebLLM, the state-of-the-art Web-based LLM inference framework.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4264–4273},
numpages = {10},
keywords = {inference acceleration, large language model, webgpu},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3708530,
author = {Zhao, Yanjie and Hou, Xinyi and Wang, Shenao and Wang, Haoyu},
title = {LLM App Store Analysis: A Vision and Roadmap},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708530},
doi = {10.1145/3708530},
abstract = {The rapid growth and popularity of large language model (LLM) app stores have created new opportunities and challenges for researchers, developers, users, and app store managers. As the LLM app ecosystem continues to evolve, it is crucial to understand the current landscape and identify potential areas for future research and development. This article presents a forward-looking analysis of LLM app stores, focusing on key aspects such as data mining, security risk identification, development assistance, and market dynamics. Our comprehensive examination extends to the intricate relationships between various stakeholders and the technological advancements driving the ecosystem’s growth. We explore the ethical considerations and potential societal impacts of widespread LLM app adoption, highlighting the need for responsible innovation and governance frameworks. By examining these aspects, we aim to provide a vision for future research directions and highlight the importance of collaboration among stakeholders to address the challenges and opportunities within the LLM app ecosystem. The insights and recommendations provided in this article serve as a foundation for driving innovation, ensuring responsible development, and creating a thriving, user-centric LLM app landscape.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {125},
numpages = {25},
keywords = {Large Language Model, LLM, LLM App Store, GPT Store}
}

@article{10.1145/3643758,
author = {Wang, Wei and Ning, Huilong and Zhang, Gaowei and Liu, Libo and Wang, Yi},
title = {Rocks Coding, Not Development: A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643758},
doi = {10.1145/3643758},
abstract = {Recently, large language models (LLM) based generative AI has been gaining momentum for their impressive high-quality performances in multiple domains, particularly after the release of the ChatGPT. Many believe that they have the potential to perform general-purpose problem-solving in software development and replace human software developers. Nevertheless, there are in a lack of serious investigation into the capability of these LLM techniques in fulfilling software development tasks. In a controlled 2 \texttimes{} 2 between-subject experiment with 109 participants, we examined whether and to what degree working with ChatGPT was helpful in the coding task and typical software development task and how people work with ChatGPT. We found that while ChatGPT performed well in solving simple coding problems, its performance in supporting typical software development tasks was not that good. We also observed the interactions between participants and ChatGPT and found the relations between the interactions and the outcomes. Our study thus provides first-hand insights into using ChatGPT to fulfill software engineering tasks with real-world developers and motivates the need for novel interaction mechanisms that help developers effectively work with large language models to achieve desired outcomes.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {32},
numpages = {23},
keywords = {controlled experiment, human-AI collaboration, large langauge models, software development task}
}

@inproceedings{10.1145/3641554.3701848,
author = {Ohmann, Peter and Novak, Ed},
title = {A Multi-Institutional Assessment of Oral Exams in Software Courses},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701848},
doi = {10.1145/3641554.3701848},
abstract = {Oral exams are an inviting alternative to traditional paper-and-pencil exams. However, they are largely under-utilized in computer science education. In this report, we describe our design for comprehensive final oral exams in five software engineering class sections, across two different small institutions. We present our exam format and our subjective assessment of the exam format in assessing student knowledge as instructors. We also gather quantitative and qualitative data from student surveys. We surveyed students before and after the oral exam to assess their perceptions of it, including their predicted grade and their subjective opinions and experiences. Our work shows evidence that oral exams are effective and practical mechanisms for software engineering classes of a smaller size (approximately 20 students). Student survey responses indicated favorable feedback for our oral exam format; students viewed oral exams as a good assessment of their knowledge and useful beyond that individual class.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {882–888},
numpages = {7},
keywords = {oral exam, software engineering education, student survey},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3657604.3664677,
author = {Barno, Erin and Albaladejo-Gonz\'{a}lez, Mariano and Reich, Justin},
title = {Scaling Generated Feedback for Novice Teachers by Sustaining Teacher Educators' Expertise: A Design to Train LLMs with Teacher Educator Endorsement of Generated Feedback},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664677},
doi = {10.1145/3657604.3664677},
abstract = {When using simulations to design and implement novice teacher practice, a teacher educator may be concerned about if what is technically possible in terms of generating feedback to novice teachers' responses is educationally purposeful to support their learning. This paper details the design of infrastructure to incorporate user feedback within the Teacher Moments platform that is generated by an AI agent, and how we designed to sustain and scale the expertise of mathematics teacher educators when training a large language model. To best support the learning of novice mathematics teacher users to enact ambitious and equitable mathematics teaching, this paper explains the research design of training a large language model by collaborating with mathematics teacher educators to edit or endorse generated feedback across multiple training cycles. This paper also describes the UI design to explore potential of hosting such processes all within the Teacher Moments platform.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {412–416},
numpages = {5},
keywords = {digital simulations, generative AI, natural language processing, professional learning, teacher education},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3691620.3695591,
author = {Wei, Jialiang and Courbis, Anne-Lise and Lambolais, Thomas and Xu, Binbin and Bernard, Pierre Louis and Dray, Gerard and Maalej, Walid},
title = {Getting Inspiration for Feature Elicitation: App Store- vs. LLM-based Approach},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695591},
doi = {10.1145/3691620.3695591},
abstract = {Over the past decade, app store (AppStore)-inspired requirements elicitation has proven to be highly beneficial. Developers often explore competitors' apps to gather inspiration for new features. With the advance of Generative AI, recent studies have demonstrated the potential of large language model (LLM)-inspired requirements elicitation. LLMs can assist in this process by providing inspiration for new feature ideas. While both approaches are gaining popularity in practice, there is a lack of insight into their differences. We report on a comparative study between AppStore- and LLM-based approaches for refining features into sub-features. By manually analyzing 1,200 sub-features recommended from both approaches, we identified their benefits, challenges, and key differences. While both approaches recommend highly relevant sub-features with clear descriptions, LLMs seem more powerful particularly concerning novel unseen app scopes. Moreover, some recommended features are imaginary with unclear feasibility, which suggests the importance of a human-analyst in the elicitation loop.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {857–869},
numpages = {13},
keywords = {requirements elicitation, app store mining, large language models, data-centered requirements engineering, creativity in SE},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3704289.3704301,
author = {Chang, Chi In and Choi, Wan Chong and Choi, Iek Chong},
title = {A Systematic Literature Review of the Opportunities and Advantages for AIGC (OpenAI ChatGPT, Copilot, Codex) in Programming Course},
year = {2025},
isbn = {9798400716980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704289.3704301},
doi = {10.1145/3704289.3704301},
abstract = {This systematic literature review explored the opportunities and advantages of integrating Artificial Intelligence Generated Content (AIGC) tools like OpenAI's ChatGPT, Copilot, and Codex in programming education. From an initial pool of 1,173 papers, 24 were rigorously selected for detailed analysis. The findings highlighted the dominant use of ChatGPT, particularly versions 3/3.5 and 4, underscoring its effectiveness and accessibility. Python emerged as the most frequently studied language, followed by Java, C, R, and Scala. A notable research gap was identified in block-based programming languages and online/blended learning environments. Key opportunities and advantages identified included enhanced code review, where AIGC tools offer efficient and comprehensive assessments; personalized learning, with ChatGPT providing individualized feedback and improving student comprehension; and increased student engagement and motivation through interactive features. Additionally, AIGC tools significantly improved problem-solving and debugging support, effectively identifying and correcting coding errors. They also supported diverse learning styles by offering varied examples and solutions, facilitated innovative teaching strategies that improved educational outcomes, and reduced teacher workload by automating routine tasks. These insights demonstrated the transformative potential of AIGC tools in revolutionizing programming education.},
booktitle = {Proceedings of the 2024 7th International Conference on Big Data and Education},
pages = {29–35},
numpages = {7},
keywords = {Advantages of AIGC, Artificial intelligence generated content, ChatGPT, Codex, Copilot, Opportunities of AIGC, Programming Course, Systematic literature review},
location = {
},
series = {ICBDE '24}
}

@inproceedings{10.1145/3639478.3643065,
author = {Zhang, Chenyuan and Liu, Hao and Zeng, Jiutian and Yang, Kejing and Li, Yuhong and Li, Hui},
title = {Prompt-Enhanced Software Vulnerability Detection Using ChatGPT},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3643065},
doi = {10.1145/3639478.3643065},
abstract = {With the increase in software vulnerabilities that cause significant economic and social losses, automatic vulnerability detection has become essential in software development and maintenance. Recently, large language models (LLMs) have received considerable attention due to their stunning intelligence, and some studies consider using ChatGPT for vulnerability detection. However, they do not fully consider the characteristics of LLMs, since their designed questions to ChatGPT are simple without a prompt design tailored for vulnerability detection. This paper launches a study on the performance of software vulnerability detection using ChatGPT with different prompt designs. Firstly, we complement previous work by applying various improvements to the basic prompt. Moreover, we incorporate structural and sequential auxiliary information to improve the prompt design. Moreover, we leverage ChatGPT's ability of memorizing multi-round dialogue to design suitable prompts for vulnerability detection. We conduct extensive experiments on two vulnerability datasets to demonstrate the effectiveness of prompt-enhanced vulnerability detection using ChatGPT.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {276–277},
numpages = {2},
keywords = {software vulnerability detection, prompt engineering, large language model, chatgpt},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3706599.3720291,
author = {Jamie, Pooriya and HajiHashemi, Reyhaneh and Alipour, Sharareh},
title = {Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720291},
doi = {10.1145/3706599.3720291},
abstract = {Integrating large language models (LLMs) like ChatGPT into computer science education offers transformative potential for complex courses such as data structures and algorithms (DSA). This study examines ChatGPT as a supplementary tool for teaching assistants (TAs), guided by structured prompts and human oversight, to enhance instruction and student outcomes. A controlled experiment compared traditional TA-led instruction with a hybrid approach where TAs used ChatGPT-4o and ChatGPT o1 to generate exercises, clarify concepts, and provide feedback. Structured prompts emphasized problem decomposition, real-world context, and code examples, enabling tailored support while mitigating over-reliance on AI. Results demonstrated the hybrid approach’s efficacy, with students in the ChatGPT-assisted group scoring 16.50 points higher on average and excelling in advanced topics. However, ChatGPT’s limitations necessitated TA verification. This framework highlights the dual role of LLMs: augmenting TA efficiency while ensuring accuracy through human oversight, offering a scalable solution for human-AI collaboration in education.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {567},
numpages = {7},
keywords = {LLMs, ChatGPT, Teaching Assistant, Data Structures and Algorithms Course, Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3689492.3689816,
author = {Kang, Eunsuk and Shaw, Mary},
title = {tl;dr: Chill, y’all: AI Will Not Devour SE},
year = {2024},
isbn = {9798400712159},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689492.3689816},
doi = {10.1145/3689492.3689816},
abstract = {Social media provide a steady diet of dire warnings that artificial intelligence (AI) will make software engineering (SE) irrelevant or obsolete. To the contrary, the engineering discipline of software is rich and robust; it encompasses the full scope of software design, development, deployment, and practical use; and it has regularly assimilated radical new offerings from AI. Current AI innovations such as machine learning, large language models (LLMs) and generative AI will offer new opportunities to extend the models and methods of SE. They may automate some routine development processes, and they will bring new kinds of components and architectures. If we're fortunate they may force SE to rethink what we mean by correctness and reliability. They will not, however, render SE irrelevant.},
booktitle = {Proceedings of the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {303–315},
numpages = {13},
keywords = {AI-assisted development, software correctness, software engineering principles},
location = {Pasadena, CA, USA},
series = {Onward! '24}
}

@inproceedings{10.1145/3626253.3635600,
author = {Chen, Xi and Liang, Jingsai},
title = {Pair Programming with ChatGPT},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635600},
doi = {10.1145/3626253.3635600},
abstract = {This poster explores the potential of ChatGPT to replace the traditional approach of pair programming in introductory computer science courses. Traditionally, two students collaborate as a driver and a navigator, periodically switching roles. Now, a student can pair up with ChatGPT, which offers an innovative approach to pair programming. This exploratory activity, which emphasizes collaboration and communication, provides step-by-step instructions for effectively interacting with ChatGPT during pair programming.This poster reflects on the advantages and limitations of using ChatGPT in pair programming. The main advantages of using ChatGPT include rapid responses, syntax error-free code generation, and flexibility in handling incomplete pseudocode. The primary limitations include the coding generation style, redundancy in responses, and challenges in understanding the code. Despite the advantages, it may still be valuable to have students work with human partners in certain situations, particularly for learning purposes.This poster proposes that ChatGPT is an invaluable tool for enhancing productivity and emphasizes the importance of becoming proficient in its use during students' college years. It also provides insights into the effective utilization of ChatGPT in pair programming and its preparation for future careers in programming and related fields.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1600–1601},
numpages = {2},
keywords = {chatgpt, pair programming},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641555.3705180,
author = {Brilliantova, Angelina and Butler, Zack and Bez\'{a}kov\'{a}, Ivona},
title = {Exploring ChatGPT as a Qualitative Research Assistant},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705180},
doi = {10.1145/3641555.3705180},
abstract = {In many CS educational research studies, students are surveyed to understand their reactions to a particular pedagogical approach or tool. These surveys, as well as other types of evaluations, often invite students to provide open-ended feedback about their experiences. However, analyzing these comments can prove to be a challenge, especially to CS educators who may not have strong expertise in qualitative research methods. In addition, in a large study, evaluating all of the provided comments can consume a significant amount of researcher time. In this work, we undertook two separate conversations with ChatGPT in which we prompted it to perform qualitative analysis of a set of comments collected in an earlier study. This allowed us to begin to judge how effectively a modern large language model can serve as an assistant in qualitative analysis. We found that with the prompts we used, ChatGPT can reliably build a set of reasonable labels (codes) for a set of comments, but the application of its labels to specific comments may or may not be effective and human researchers still need to use care and their own understanding in interpreting its output.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1397–1398},
numpages = {2},
keywords = {chatgpt, grounded theory, large-language models, qualitative analysis},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701810,
author = {Borela, Rodrigo and Liding, Zhixian and McDaniel, Melinda},
title = {Enhancing CS1 Education through Experiential Learning with Robotics Projects},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701810},
doi = {10.1145/3641554.3701810},
abstract = {To address the challenges of generative AI in CS1 education, especially its misuse by students to bypass coding exercises, which undermines their engagement with foundational learning, CS1 curricula are evolving to emphasize higher-level problem-solving and systems thinking. In response, a novel experiential learning initiative grounded in High-Impact Practices was introduced to a CS1 course over the course of 2 semesters, involving 132 students. This initiative utilized robotics lab assignments to enhance computational thinking across various levels of granularity, from individual functional components to overall system behaviors, bridging conceptual understanding with real-world applications. The approach emphasized project-based learning, extended engagement time, and reflective practices to deepen students' understanding of core computing concepts and scaffold knowledge integration. The curriculum featured both individual and team-based lab assignments to build foundational skills followed by collaborative problem-solving. The initiative's impact was assessed against a control group of 427 students who completed traditional web development lab assignments. Evaluation methods included thematic analyses of student reflections, instructor opinion surveys, and statistical analysis of exam performances across the semester. Results revealed a substantial positive effect on self-efficacy and learning outcomes. Students in the experiential learning group reported increased confidence in applying their computing skills to real-world scenarios, heightened engagement, and greater improvements in technical proficiency. Notably, their exam scores demonstrated a statistically significant improvement compared to the control group. These findings highlight the effectiveness of integrating practical, interactive elements into computer science education to meet the demands of a rapidly evolving technological landscape.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {144–150},
numpages = {7},
keywords = {artificial intelligence, collaborative learning, cs1, experiential learning, robotics},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inbook{10.5555/3716662.3716742,
author = {Lovato, Juniper and Zimmerman, Julia Witte and Smith, Isabelle and Dodds, Peter and Karson, Jennifer L.},
title = {Foregrounding Artist Opinions: A Survey Study on Transparency, Ownership, and Fairness in AI Generative Art},
year = {2025},
publisher = {AAAI Press},
abstract = {Generative AI tools are used to create art-like outputs and sometimes aid in the creative process. These tools have potential benefits for artists, but they also have the potential to harm the art workforce and infringe upon artistic and intellectual property rights. Without explicit consent from artists, Generative AI creators scrape artists' digital work to train Generative AI models and produce art-like outputs at scale. These outputs are now being used to compete with human artists in the marketplace as well as being used by some artists in their generative processes to create art. We surveyed 459 artists to investigate the tension between artists' opinions on Generative AI art's potential utility and harm. This study surveys artists' opinions on the utility and threat of Generative AI art models, fair practices in the disclosure of artistic works in AI art training models, ownership and rights of AI art derivatives, and fair compensation. Results show that a majority of artists believe creators should disclose what art is being used in AI training, that AI outputs should not belong to model creators, and express concerns about AI's impact on the art workforce and who profits from their art. We hope the results of this work will further meaningful collaboration and alignment between the art community and Generative AI researchers and developers.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {905–916},
numpages = {12}
}

@inproceedings{10.1145/3672539.3686338,
author = {Zheng, Chengbo and Huang, Zeyu and Ma, Shuai and Ma, Xiaojuan},
title = {SelfGauge: An Intelligent Tool to Support Student Self-assessment in GenAI-enhanced Project-based Learning},
year = {2024},
isbn = {9798400707186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672539.3686338},
doi = {10.1145/3672539.3686338},
abstract = {Project-based learning (PBL) involves students tackling real-world problems and creating artifacts. With the rise of generative AI (GenAI) tools, assessing students in GenAI-enhanced PBL is challenging. To address this, we designed SelfGauge, a tool that supports student self-assessment by analyzing their GenAI usage and project artifacts. It helps students define criteria, seek feedback, and reflect on their performance, promoting continuous self-improvement.},
booktitle = {Adjunct Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {97},
numpages = {3},
keywords = {AI in Education, Project-based Learning, Reflection},
location = {Pittsburgh, PA, USA},
series = {UIST Adjunct '24}
}

@inproceedings{10.1145/3706598.3713661,
author = {Zhang, Qinshi and Wen, Ruoyu and Hendra, Latisha Besariani and Ding, Zijian and LC, Ray},
title = {Can AI Prompt Humans? Multimodal Agents Prompt Players? Game Actions and Show Consequences to Raise Sustainability Awareness},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713661},
doi = {10.1145/3706598.3713661},
abstract = {Unsustainable behaviors are challenging to prevent due to their long-term, often unclear consequences. Serious games offer a promising solution by creating artificial environments where players can immediately experience the outcomes of their actions. To explore this potential, we developed EcoEcho, a GenAI-powered game leveraging multimodal agents to raise sustainability awareness. These agents engage players in natural conversations, prompting them to take in-game actions that lead to visible environmental impacts. We evaluated EcoEcho using a mixed-methods approach with 23 participants. Results show a significant increase in intended sustainable behaviors post-game, although attitudes towards sustainability had only marginal effects, suggesting that in-game actions likely can motivate intended real world behaviors despite similar opinions on sustainability. This finding highlights multimodal agents and action-consequence mechanics to effectively raising sustainability awareness and the potential of motivating real-world behavioral change.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1044},
numpages = {29},
keywords = {Multimodal Agents, Sustainability Awareness, Generative AI, In-Game Action},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3636555.3636882,
author = {Dunder, Nora and Lundborg, Saga and Wong, Jacqueline and Viberg, Olga},
title = {Kattis vs ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636882},
doi = {10.1145/3636555.3636882},
abstract = {AI-powered education technologies can support students and teachers in computer science education. However, with the recent developments in generative AI, and especially the increasingly emerging popularity of ChatGPT, the effectiveness of using large language models for solving programming tasks has been underexplored. The present study examines ChatGPT’s ability to generate code solutions at different difficulty levels for introductory programming courses. We conducted an experiment where ChatGPT was tested on 127 randomly selected programming problems provided by Kattis, an automatic software grading tool for computer science programs, often used in higher education. The results showed that ChatGPT independently could solve 19 out of 127 programming tasks generated and assessed by Kattis. Further, ChatGPT was found to be able to generate accurate code solutions for simple problems but encountered difficulties with more complex programming tasks. The results contribute to the ongoing debate on the utility of AI-powered tools in programming education.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {821–827},
numpages = {7},
keywords = {Academic Integrity, Automated Grading, ChatGPT, Programming Education},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3712716.3712718,
author = {Wickramasekara, Akila and Densmore, Alanna and Breitinger, Frank and Studiawan, Hudan and Scanlon, Mark},
title = {AutoDFBench: A Framework for AI Generated Digital Forensic Code and Tool Testing and Evaluation},
year = {2025},
isbn = {9798400710766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712716.3712718},
doi = {10.1145/3712716.3712718},
abstract = {Generative AI (GenAI) and Large Language Models (LLMs) show great potential in various domains, including digital forensics. A notable use case of these technologies is automatic code generation, which can reasonably be expected to include digital forensic applications in the not-too-distant future. As with any digital forensic tool, these systems must undergo extensive testing and validation. However, manually evaluating outputs, including generated DF code, remains a challenge. AutoDFBench is an automated framework designed to address this by validating AI-generated code and tools against NIST’s Computer Forensics Tool Testing Program (CFTT) procedures and subsequently calculating an AutoDFBench benchmarking score. The framework operates in four phases: data preparation, API handling, code execution, and result recording with score calculation. It benchmarks generative AI systems, such as LLMs and automated code generation agents, for DF applications. This benchmark can support iterative development or serve as a comparison metric between GenAI DF systems. As a proof of concept, NIST’s forensic string search tests were used, involving more than 24,200 tests with five top-performing code generation LLMs. These tests validated the output of 121 cases, considering two levels of user expertise, two programming languages, and ten iterations per case with varying prompts. The results also highlight the significant limitations of the DF-specific solutions generated by generic LLMs.},
booktitle = {Proceedings of the Digital Forensics Doctoral Symposium},
articleno = {1},
numpages = {7},
keywords = {Digital Forensics, Large Language Models, Investigative Process, Automation, Challenges},
location = {
},
series = {DFDS '25}
}

@inproceedings{10.1145/3657054.3657128,
author = {Tsai, Chun-Hua and Nandy, Gargi and House, Deanna and Carroll, John},
title = {Ensuring Transparency in Using ChatGPT for Public Sentiment Analysis},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657128},
doi = {10.1145/3657054.3657128},
abstract = {The advancement of generative AI, involving the utilization of large language models (LLMs) like ChatGPT to assess public opinion and sentiment, has become increasingly prevalent. However, this upsurge in usage raises significant questions about the transparency and interpretability of the predictions made by these LLM Models. Hence, this paper explores the imperative of ensuring transparency in the application of ChatGPT for public sentiment analysis. To tackle these challenges, we propose using a lexicon-based model as a surrogate to approximate both global and local predictions. Through case studies, we demonstrate how transparency mechanisms, bolstered by the lexicon-based model, can be seamlessly integrated into ChatGPT’s deployment for sentiment analysis. Drawing on the results of our study, we further discuss the implications for future research involving the utilization of LLMs in governmental functions, policymaking, and public engagement.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {627–636},
numpages = {10},
keywords = {AI Ethics and Governance, CDC, COVID, Civic Engagement},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

@inproceedings{10.1145/3706598.3713359,
author = {Fang, Cathy Mengying and Chua, Phoebe and Chan, Samantha W. T. and Leong, Joanne and Bao, Andria and Maes, Pattie},
title = {Leveraging AI-Generated Emotional Self-Voice to Nudge People towards their Ideal Selves},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713359},
doi = {10.1145/3706598.3713359},
abstract = {Emotions, shaped by past experiences, significantly influence decision-making and goal pursuit. Traditional cognitive-behavioral techniques for personal development rely on mental imagery to envision ideal selves, but may be less effective for individuals who struggle with visualization. This paper introduces Emotional Self-Voice (ESV), a novel system combining emotionally expressive language models and voice cloning technologies to render customized responses in the user’s own voice. We investigate the potential of ESV to nudge individuals towards their ideal selves in a study with 60 participants. Across all three conditions (ESV, text-only, and mental imagination), we observed an increase in resilience, confidence, motivation, and goal commitment, and the ESV condition was perceived as uniquely engaging and personalized. We discuss the implications of designing generated self-voice systems as a personalized behavioral intervention for different scenarios.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {58},
numpages = {20},
keywords = {emotion, voice, generative ai, nudging, goals},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641555.3705031,
author = {Diaz, Nicolas and Roy, Saunak and Beltran, Jonathan},
title = {Exploring Undergraduate AI Perceptions: Knowledge, Enthusiasm, and Concerns},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705031},
doi = {10.1145/3641555.3705031},
abstract = {As Artificial Intelligence (AI) develops and grows its presence in society, college students are increasingly interacting with AI and utilizing tools like ChatGPT as part of their education. Particularly in STEM fields, educators themselves are incorporating AI by encouraging its use as an assistive tool for coursework or designing courses that teach about its inner workings. Understanding students' perceptions and knowledge of AI can help educators know whether students will embrace learning in AI-heavy environments, as well as which student concerns they should acknowledge. Our study uses both quantitative and qualitative data from undergraduate CMNS (College of Computer, Mathematical, and Natural Sciences) students at the University of Maryland, College Park to explore students' perceived knowledge, enthusiasm, and concerns over AI. Our data was collected via a survey administered via email to undergraduates and subsequent focus group interviews with these students about their relationship with AI. Survey findings indicated that students were confident in their knowledge of AI and related competencies, as well as enthusiastic about learning and using AI. Students also highly believed in the need for standards and testing for AI systems to curtail risks. There was a positive correlation between perceived knowledge and enthusiasm of AI, but no correlation between knowledge and concerns. In interviews, students' main uses of AI were summarizing information, creating practice problems, and writing assistance. Popular concerns included academic dishonesty, overreliance on AI tools, and fabricated information in outputs.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1753},
numpages = {1},
keywords = {artificial intelligence, generative AI, higher education, learning environments, student perceptions},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3675094.3678991,
author = {Li, Yunjia and Liu, Haiming and Wald, Mike},
title = {DeepVision: Heads-up Computing and AI in Education},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3678991},
doi = {10.1145/3675094.3678991},
abstract = {Heads-up computing together with AI can enhance in-class learning experiences. In this position paper, we propose the development of a multimodal AI system called DeepVision that integrates Automatic Speech Recognition (ASR), Large Language Models (LLM), Large Vision Models (LVM), Information Retrieval (IR) and Inclusive User Experience Design (IUX) to convert real-time lectures into multiple knowledge representations. These will be visualized on heads-up communication devices such as Augmented Reality (AR) and Mixed Reality (MR) devices. The initiative is a collaboration between Habitat Learn Limited (HLL) and the University of Southampton, leveraging HLL's existing software and extensive data repository to address the challenges of traditional and digital learning environments, especially for students with disabilities or language differences.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {627–630},
numpages = {4},
keywords = {ai, ar, heads-up computing, inclusive user experience design, large language model, multimodal information access and retrieval},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3706599.3719860,
author = {Luo, Yalong and Wu, Leyan and Huang, Yirui and Cai, Wanling and Jin, Yucheng},
title = {Exploring the Impacts of AI Technologies on Digital Collage Creation},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719860},
doi = {10.1145/3706599.3719860},
abstract = {AI technology has been increasingly integrated into digital art-making tools to support artistic creation, such as automatically colorizing sketches. Although research on the application of AI in art and creative practices is growing, its role in collage creation has seen limited research attention. To explore the potential of AI in digital collage creation, we followed a human-centered approach and conducted a co-design workshop with eight participants. Through this workshop, we examined how users interact with AI during the creation process, explored the impact of AI on their creation process and experience, and investigated their attitudes toward AI-assisted creation. Our findings offer valuable design implications for the future development of AI-assisted digital collage tools.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {269},
numpages = {6},
keywords = {Digital Collage, Generative AI, Generative Art},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3649405.3659504,
author = {Bernstein, Seth and Denny, Paul and Leinonen, Juho and Littlefield, Matt and Hellas, Arto and MacNeil, Stephen},
title = {Analyzing Students' Preferences for LLM-Generated Analogies},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659504},
doi = {10.1145/3649405.3659504},
abstract = {Introducing students to new concepts in computer science can often be challenging, as these concepts may differ significantly from their existing knowledge and conceptual understanding. To address this, we employed analogies to help students connect new concepts to familiar ideas. Specifically, we generated analogies using large language models (LLMs), namely ChatGPT, and used them to help students make the necessary connections. In this poster, we present the results of our survey, in which students were provided with two analogies relating to different computing concepts, and were asked to describe the extent to which they were accurate, interesting, and useful. This data was used to determine how effective LLM-generated analogies can be for teaching computer science concepts, as well as how responsive students are to this approach.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {812},
numpages = {1},
keywords = {analogies, computer science education, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3641237.3691672,
author = {Thominet, Luke and Acosta, Kristine and Amorim, Jacqueline and Sohan, Vanessa Kraemer},
title = {How Our AI-assisted Qualitative Analysis Failed},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691672},
doi = {10.1145/3641237.3691672},
abstract = {The authors describe how their Generative Artificial Intelligence (GAI)-assisted qualitative research project failed to produce publishable results. Based on this experience, they argue for the value of embracing and reflecting on failure in GAI-assisted qualitative research. To frame this argument, they draw on two theories of generative failure: failing forward, which uses failures to iterate on designs to meet existing criteria, and failing sideways, which reconsiders the criteria for success. Using a fail-forward perspective, the authors describe how they might revise their research methods for data preparation, process documentation, and task delegation to create more reliable results. Then, using a fail-sideways perspective, they reexamine criteria for publishable results to reimagine the study more fundamentally.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {212–216},
numpages = {5},
keywords = {Generative Artificial Intelligence, Generative Failure, Research Methods},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@inproceedings{10.1145/3643795.3648389,
author = {Dingle, Adam and Krulis, Martin},
title = {Tackling Students' Coding Assignments with LLMs},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648389},
doi = {10.1145/3643795.3648389},
abstract = {State-of-the-art large language models (LLMs) have demonstrated an extraordinary ability to write computer code. This ability can be quite beneficial when integrated into an IDE to assist a programmer with basic coding. On the other hand, it may be misused by computer science students for cheating on coding tests or homework assignments. At present, knowledge about the exact capabilities and limitations of state-of-the-art LLMs is still inadequate. Furthermore, their capabilities have been changing quickly with each new release. In this paper, we present a dataset of 559 programming exercises in 10 programming languages collected from a system for evaluating coding assignments at our university. We have experimented with four well-known LLMs (GPT-3.5, GPT-4, Codey, Code Llama) and asked them to solve these assignments. The evaluation results are intriguing and provide insights into the strengths and weaknesses of the models. In particular, GPT-4 (which performed the best) is currently capable of solving 55% of all our exercises and achieved an average score of 86% on exercises from the introductory programming course (using the best of five generated solutions).},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {94–101},
numpages = {8},
keywords = {LLM, large language model, coding, programming, student assignment, teaching},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3631700.3665233,
author = {Biancini, Giorgio and Ferrato, Alessio and Limongelli, Carla},
title = {Multiple-Choice Question Generation Using Large Language Models: Methodology and Educator Insights},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665233},
doi = {10.1145/3631700.3665233},
abstract = {Integrating Artificial Intelligence (AI) in educational settings has brought new learning approaches, transforming the practices of both students and educators. Among the various technologies driving this transformation, Large Language Models (LLMs) have emerged as powerful tools for creating educational materials and question answering, but there are still space for new applications. Educators commonly use Multiple-Choice Questions (MCQs) to assess student knowledge, but manually generating these questions is resource-intensive and requires significant time and cognitive effort. In our opinion, LLMs offer a promising solution to these challenges. This paper presents a novel comparative analysis of three widely known LLMs - Llama 2, Mistral, and GPT-3.5 - to explore their potential for creating informative and challenging MCQs. In our approach, we do not rely on the knowledge of the LLM, but we inject the knowledge into the prompt to contrast the hallucinations, giving the educators control over the test’s source text, too. Our experiment involving 21 educators shows that GPT-3.5 generates the most effective MCQs across several known metrics. Additionally, it shows that there is still some reluctance to adopt AI in the educational field. This study sheds light on the potential of LLMs to generate MCQs and improve the educational experience, providing valuable insights for the future.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {584–590},
numpages = {7},
keywords = {Generative AI, LLMs, Multiple Choice Question},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3613904.3642868,
author = {Wang, Sitong and Menon, Samia and Long, Tao and Henderson, Keren and Li, Dingzeyu and Crowston, Kevin and Hansen, Mark and Nickerson, Jeffrey V and Chilton, Lydia B},
title = {ReelFramer: Human-AI Co-Creation for News-to-Video Translation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642868},
doi = {10.1145/3613904.3642868},
abstract = {Short videos on social media are the dominant way young people consume content. News outlets aim to reach audiences through news reels—short videos conveying news—but struggle to translate traditional journalistic formats into short, entertaining videos. To translate news into social media reels, we support journalists in reframing the narrative. In literature, narrative framing is a high-level structure that shapes the overall presentation of a story. We identified three narrative framings for reels that adapt social media norms but preserve news value, each with a different balance of information and entertainment. We introduce ReelFramer, a human-AI co-creative system that helps journalists translate print articles into scripts and storyboards. ReelFramer supports exploring multiple narrative framings to find one appropriate to the story. AI suggests foundational narrative details, including characters, plot, setting, and key information. ReelFramer also supports visual framing; AI suggests character and visual detail designs before generating a full storyboard. Our studies show that narrative framing introduces the necessary diversity to translate various articles into reels, and establishing foundational details helps generate scripts that are more relevant and coherent. We also discuss the benefits of using narrative framing and foundational details in content retargeting.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {169},
numpages = {20},
keywords = {creativity support tools, generative AI, narratives, scriptwriting, short videos, storyboarding},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3735632,
author = {Li, Jiawei and Gao, Yang and Yang, Yizhe and Bai, Yu and Zhou, Xiaofeng and Li, Yinghao and Sun, Huashan and Liu, Yuhang and Si, Xingpeng and Ye, Yuhao and Wu, Yixiao and Lin, Yiguan and Xu, Bin and Ren, Bowen and Feng, Chong and Huang, Heyan},
title = {Fundamental Capabilities and Applications of Large Language Models: A Survey},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0360-0300},
url = {https://doi.org/10.1145/3735632},
doi = {10.1145/3735632},
abstract = {Large Language Models (LLMs) have demonstrated remarkable effectiveness across various domain-specific applications. However, which fundamental capabilities most contribute to their success in different domains remains unclear. This uncertainty complicates LLM evaluation, as existing benchmark-based assessments often fail to capture their real-world performance, where the required capabilities may differ from those measured in the benchmarks. In this survey, we provide a systematic introduction to LLMs’ fundamental capabilities, encompassing their definitions, formation mechanisms, and practical applications. We further explore the relationships among these capabilities and discuss how they collectively support complex problem-solving in domain-specific applications. Building on this foundation, we review recent advances in LLM-driven applications across nine specific domains: medicine, law, computational biology, finance, social sciences and psychology, computer programming and software engineering, robots and agents, AI for disciplines, and creative work. We analyze how specific capabilities are leveraged for each domain to address unique requirements. This perspective enables us to establish connections between these capabilities and domain requirements, and to evaluate the varying importance of different capabilities across different domains. Based on these insights, we propose evaluation strategies tailored to the essential capabilities required in each domain, offering practical guidance for selecting suitable backbone LLMs in real-world applications.},
note = {Just Accepted},
journal = {ACM Comput. Surv.},
month = may,
keywords = {Large Language Model, Fundamental Capabilities, Applications}
}

@inproceedings{10.1145/3639474.3640052,
author = {Cipriano, Bruno Pereira and Alves, Pedro},
title = {LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard's Capacity to Handle Object-Oriented Programming Assignments},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640052},
doi = {10.1145/3639474.3640052},
abstract = {Large Language Models (LLMs) have emerged as promising tools to assist students while solving programming assignments. However, object-oriented programming (OOP), with its inherent complexity involving the identification of entities, relationships, and responsibilities, is not yet mastered by these tools. Contrary to introductory programming exercises, there exists a research gap with regard to the behavior of LLMs in OOP contexts. In this study, we experimented with three prominent LLMs - GPT-3.5, GPT-4, and Bard - to solve real-world OOP exercises used in educational settings, subsequently validating their solutions using an Automatic Assessment Tool (AAT). The findings revealed that while the models frequently achieved mostly working solutions to the exercises, they often overlooked the best practices of OOP. GPT-4 stood out as the most proficient, followed by GPT-3.5, with Bard trailing last. We advocate for a renewed emphasis on code quality when employing these models and explore the potential of pairing LLMs with AATs in pedagogical settings. In conclusion, while GPT-4 showcases promise, the deployment of these models in OOP education still mandates supervision.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {162–169},
numpages = {8},
keywords = {programming assignments, teaching, object-oriented programming, object-oriented design, OOP best practices, large language models, GPT-3, GPT-4, bard},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@article{10.1145/3722229,
author = {AlOmar, Eman Abdullah},
title = {Nurturing Code Quality: Leveraging Static Analysis and Large Language Models for Software Quality in Education},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
url = {https://doi.org/10.1145/3722229},
doi = {10.1145/3722229},
abstract = {Large Language Models (LLMs), such as ChatGPT, have become widely popular for various software engineering tasks, including programming, testing, code review, and program comprehension. However, their impact on improving software quality in educational settings remains uncertain. This article explores our experience teaching the use of Programming Mistake Detector (PMD) to foster a culture of bug fixing and leverage LLM to improve software quality in the classroom. This article discusses the results of an experiment involving 155 submissions that carried out a code review activity of 1,658 rules. Our quantitative and qualitative analyses reveal that a set of PMD quality issues influences the acceptance or rejection of the issues, and design-related categories that take longer to resolve. Although students acknowledge the potential of using ChatGPT during code review, some skepticism persists. Further, constructing prompts for ChatGPT that possess clarity, complexity, and context nurtures vital learning outcomes, such as enhanced critical thinking, and among the 1,658 issues analyzed, 93% of students indicated that ChatGPT did not identify any additional issues beyond those detected by PMD. Conversations between students and ChatGPT encompass five categories, including ChatGPT’s use of affirmation phrases like “certainly” regarding bug fixing decisions, and apology phrases such as “apologize” when resolving challenges. Through this experiment, we demonstrate that code review can become an integral part of the educational computing curriculum. We envision our findings to enable educators to support students with effective code review strategies, increasing awareness of LLMs, and promoting software quality in education.},
journal = {ACM Trans. Comput. Educ.},
month = may,
articleno = {16},
numpages = {36},
keywords = {large language models, education, bugfix, static analysis, code quality}
}

@inproceedings{10.1145/3626253.3635602,
author = {Akgun, Mahir and Toker, Sacip},
title = {An Investigation on Task Difficulty: Does Task Difficulty Depend on the Technology Used in Task Completion?},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635602},
doi = {10.1145/3626253.3635602},
abstract = {Previous research indicates that task difficulty (i.e., students' judgments on a task's complexity) impacts their task performance. However, whether students' perceived task difficulty changes depending on the technology they use when completing tasks is still under investigation. The present study aims to address this gap in the literature. One hundred twenty-three students completed the study procedures. Students were randomly assigned to one of four groups (one control group and three experimental groups). Students were not allowed to use any technology in the control group. In contrast, those in experimental groups were permitted to use one of the following tools: e-textbook, Google, and ChatGPT. Students in each group completed three tasks with different complexities in the same order. The data was analyzed using repeated-measures ANOVA. The study revealed a significant interaction effect between groups and task difficulty perceptions at three levels. In all groups, perceived difficulty increased as the task complexity increased, but the change in students' perceived task difficulty across three tasks was impacted by the tool used when completing the tasks.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1552–1553},
numpages = {2},
keywords = {generative ai, task difficulty, task performance},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3664476.3670446,
author = {Ohm, Marc and Bungartz, Christian and Boes, Felix and Meier, Michael},
title = {Assessing the Impact of Large Language Models on Cybersecurity Education: A Study of ChatGPT's Influence on Student Performance},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3670446},
doi = {10.1145/3664476.3670446},
abstract = {The popularity of chatbots to facilitate day-to-day business, including students and their study exercises, is on the rise. This paper investigates the extent and effects on the academic performance of students that leverage such tools. While many other approaches are hypothesized and discussed, we measure empirically. We recorded and compared the performance of cybersecurity students in weekly exercises and final exams over a period of three years. This allows us to have three groups with varying degrees of ChatGPT influence, namely no access, uncontrolled access, and controlled access. In an anonymous survey, we found that approximately 80% of our students utilize ChatGPT during the weekly assignments in 2023. However, none of them indicated this on their submission, despite it being a mandatory requirement. Through statistical analysis of achieved points in our sample groups, we identified that students perform similarly on the weekly assignments. However, their performance on the final examination deteriorates.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {104},
numpages = {7},
keywords = {ChatGPT, Education, Teaching},
location = {Vienna, Austria},
series = {ARES '24}
}

@inproceedings{10.1145/3706598.3714261,
author = {Zhu, Yihao and Ye, Zhoutong and Yuan, Yichen and Tang, Wenxuan and Yu, Chun and Shi, Yuanchun},
title = {AutoPBL: An LLM-powered Platform to Guide and Support Individual Learners Through Self Project-based Learning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714261},
doi = {10.1145/3706598.3714261},
abstract = {Self project-based learning (SPBL) is a popular learning style where learners follow tutorials and build projects by themselves. SPBL combines project-based learning’s benefit of being engaging and effective with the flexibility of self-learning. However, insufficient guidance and support during SPBL may lead to unsatisfactory learning experiences and outcomes. While LLM chatbots (e.g., ChatGPT) could potentially serve as SPBL tutors, we have yet to see an SPBL platform with responsible and systematic LLM integration. To address this gap, we present AutoPBL, an interactive learning platform for SPBL learners. We examined human PBL tutors’ roles through formative interviews to inform our design. AutoPBL features an LLM-guided learning process with checkpoint questions and in-context Q&amp;A. In a user study where 29 beginners learned machine learning through entry-level projects, we found that AutoPBL effectively improves learning outcomes and elicits better learning behavior and metacognition by clarifying current priorities and providing timely assistance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {584},
numpages = {26},
keywords = {AI for education, Project-based Learning, Large Language Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3626252.3630874,
author = {Shen, Yiyin and Ai, Xinyi and Soosai Raj, Adalbert Gerald and Leo John, Rogers Jeffrey and Syamkumar, Meenakshi},
title = {Implications of ChatGPT for Data Science Education},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630874},
doi = {10.1145/3626252.3630874},
abstract = {ChatGPT is a conversational AI platform that can produce code to solve problems when provided with a natural language prompt. Prior work on similar AI models has shown that they perform well on typical intro-level Computer Science problems. However, little is known about the performance of such tools on Data Science (DS) problems. In this work, we assess the performance of ChatGPT on assignments from three DS courses with varying difficulty levels. First, we apply the raw assignment prompts provided to the students and find that ChatGPT performs well on assignments with dataset(s) descriptions and progressive question prompts, which divide the programming requirements into sub-problems. Then, we perform prompt engineering on the assignments for which ChatGPT had low performance. We find that the following prompt engineering techniques significantly increased ChatGPT's performance: breaking down abstract questions into steps, breaking down steps into multiple prompts, providing descriptions of the dataset(s), including algorithmic details, adding specific instructions to entice specific actions, and removing extraneous information. Finally, we discuss how our findings suggest potential changes to curriculum design of DS courses.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1230–1236},
numpages = {7},
keywords = {data science education, large language models, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3613905.3650861,
author = {Dunnell, Kevin and Agarwal, Gauri and Pataranutaporn, Pat and Lippman, Andrew and Maes, Pattie},
title = {AI-Generated Media for Exploring Alternate Realities},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650861},
doi = {10.1145/3613905.3650861},
abstract = {This research investigates the potential of AI-generated media in enabling users to create and engage with alternate versions of reality. Drawing inspiration from the speculative design approaches, we propose leveraging modern AI techniques for the procedural generation of text, audio, and video to construct interactive possible futures. As a proof of concept, we developed "OpenOpenAI," a web platform that harnesses AI to depict varying renditions of a hypothetical 2024 keynote address by Sam Altman, CEO of OpenAI, based on user input. Although the platform may not influence the actual direction of the keynote address by Sam Altman and the direction of OpenAI, the system encourages participants to explore and imagine other ways that AI development could go and reminds them of alternate choices and values they could advocate for. Through a pilot user study, we seek to answer two research questions: 1) How might AI-generated media help users expand their perceived range of possible futures? and 2) How might a tool for simulating alternate realities be used to better understand the general public’s opinion on the explored topic? The findings of this study contribute to the growing body of knowledge on the responsible use of AI for exploring speculative futures and understanding public opinion on critical issues such as the development of AI.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {28},
numpages = {8},
keywords = {AI, Alternate Reality, Generative AI, Human-Computer Interaction, LLM},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3649217.3653622,
author = {Ebrahim, Fahad and Joy, Mike},
title = {Semantic Similarity Search for Source Code Plagiarism Detection: An Exploratory Study},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653622},
doi = {10.1145/3649217.3653622},
abstract = {Source code plagiarism detection (SCPD) is a crucial challenge in computer science education that affects academic integrity. It can be considered as an Information Retrieval (IR) task. One of the IR approaches is the Semantic Similarity Search (S-3), which aims to retrieve related results, given a query. It can be applied to SCPD by obtaining the most similar pairs given a large collection of codes.The paper presents an exploratory study that examines the utilisation of S-3 in the context of the SCPD task. So, given the source code reuse dataset (SOCO) written in Java/C++, the task is to retrieve the most similar (potentially plagiarised) pairs of codes. Technically, S-3 is based on vector search. So, embedding vectors generated by the major Code Pre-Trained Models (CodePTMs) were used as features of the conducted experiments. The accuracy of the S-3 approach exceeded the other SOCO-IR baselines in most of the CodePTMs without any training in terms of F1 score. The CodePTMs that incorporated multiple representations produced robust embeddings.For improved accuracy metrics, several experiments were conducted to train the embedding models in both supervised and unsupervised manners. The results concluded that overall performance could improve slightly after supervised training due to the limited training set of the SOCO dataset. Unsupervised training tests had a negative impact on accuracy. The advantage of the S-3 is that it is lightweight and fast with the ability to produce excellent performance.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {360–366},
numpages = {7},
keywords = {code pre-trained models, code similarity, computer science education, information retrieval, software engineering, source code plagiarism detection},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649409.3691092,
author = {de Miranda, Fabio and Ferrao, Rafael Corsi and Soler, Diego Pavan and Vieira Graglia, Marcelo Augusto},
title = {LLM-based Individual Contribution Summarization in Software Projects},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691092},
doi = {10.1145/3649409.3691092},
abstract = {This work in progress is about preliminary results in using a Large Language Model (LLM) to summarize individual student contributions in open-ended software projects. Projects for industry clients are good real-world learning opportunities. Though, if the scope is open and defined based on external clients' needs, each group's project will look unique, what makes a challenge for grading and regular feedback. Distributed code version control systems such as Git and resources such as Git classroom help, but it is still burdensome to have professors and TAs looking at the repositories with a frequency that enables useful, timely feedback for the students. We prototyped a method of summarizing each student's contributions to a project's Git repository using an LLM, indicating how to preprocess and break down repository data in order to get better responses from the system. Each student's contributions were extracted using Pydriller. This technique was tested during a 3-week full-time software development sprint in a class of 28 students. Preliminary results indicate a general agreement of students and faculty with the synthesized summaries and an increase in students' awareness of individual responsibilities within the teams and an improvement in engagement among less active members.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {307–308},
numpages = {2},
keywords = {project assessment, software engineering education, teamwork},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3628034.3628042,
author = {Schuckart, Adrian},
title = {Introduction to work with GenAI},
year = {2024},
isbn = {9798400700408},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628034.3628042},
doi = {10.1145/3628034.3628042},
abstract = {This paper provides an in-depth exploration of the practical applications and capabilities of generative AI technologies, specifically focusing on OpenAI's GPT-3, DALL-E and ChatGPT. It targets individuals who are already acquainted with these technologies but may not fully grasp their extensive potential beyond common use cases. The paper emphasizes the relevance of these technologies across various interdisciplinary fields. Key topics include the strategies for effective prompt construction in text and image generation, the utility of ChatGPT in generating human-like conversational responses for diverse applications and the use of personas to better understand and apply AI in corporate and decision-making contexts. Furthermore, the paper discusses the latest advancements in generative AI, including GPT-4, ChatGPT plugins, enhanced data analysis features and the introduction of DALL-E 3, highlighting their impact on the overall utility and application of these technologies.},
booktitle = {Proceedings of the 28th European Conference on Pattern Languages of Programs},
articleno = {8},
numpages = {16},
location = {Irsee, Germany},
series = {EuroPLoP '23}
}

@inproceedings{10.1145/3586183.3606763,
author = {Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
title = {Generative Agents: Interactive Simulacra of Human Behavior},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606763},
doi = {10.1145/3586183.3606763},
abstract = {Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {2},
numpages = {22},
keywords = {Human-AI interaction, agents, generative AI, large language models},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3576915.3623209,
author = {Yu, Zhiyuan and Zhai, Shixuan and Zhang, Ning},
title = {AntiFake: Using Adversarial Audio to Prevent Unauthorized Speech Synthesis},
year = {2023},
isbn = {9798400700507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576915.3623209},
doi = {10.1145/3576915.3623209},
abstract = {The rapid development of deep neural networks and generative AI has catalyzed growth in realistic speech synthesis. While this technology has great potential to improve lives, it also leads to the emergence of ''DeepFake'' where synthesized speech can be misused to deceive humans and machines for nefarious purposes. In response to this evolving threat, there has been a significant amount of interest in mitigating this threat by DeepFake detection.Complementary to the existing work, we propose to take the preventative approach and introduce AntiFake, a defense mechanism that relies on adversarial examples to prevent unauthorized speech synthesis. To ensure the transferability to attackers' unknown synthesis models, an ensemble learning approach is adopted to improve the generalizability of the optimization process. To validate the efficacy of the proposed system, we evaluated AntiFake against five state-of-the-art synthesizers using real-world DeepFake speech samples. The experiments indicated that AntiFake achieved over 95% protection rate even to unknown black-box models. We have also conducted usability tests involving 24 human participants to ensure the solution is accessible to diverse populations.},
booktitle = {Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
pages = {460–474},
numpages = {15},
keywords = {adversarial machine learning, deepfake defense, generative ai, speech synthesis},
location = {Copenhagen, Denmark},
series = {CCS '23}
}

@inproceedings{10.1145/3652620.3687800,
author = {Aslan O\u{g}uz, Evin and Kuester, Jochen Malte},
title = {A Comparative Analysis of ChatGPT-Generated and Human-Written Use Case Descriptions},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687800},
doi = {10.1145/3652620.3687800},
abstract = {The development of comprehensive use case descriptions is a critical task in software engineering, providing essential insights for requirement analysis and system design. The advent of advanced natural language processing models, such as ChatGPT, has sparked interest in their potential to automate tasks traditionally performed by humans, including the generation of use case descriptions in software engineering. Understanding the capabilities and limitations of ChatGPT in generating use case descriptions is crucial for software engineers. Without a clear understanding of its performance, practitioners may either overestimate its utility, leading to reliance on suboptimal drafts, or underestimate its capabilities, missing opportunities to streamline the drafting process. This paper addresses how well ChatGPT performs in generating use case descriptions, evaluating their quality compared to human-written descriptions. To do so, we employ a structured approach using established quality guidelines and the concept of "bad smells" for use case descriptions. Our study presents the first attempt to bridge the knowledge gap by offering a comparative analysis of ChatGPT-generated and human-written use case descriptions. By providing an approach to objectively assess ChatGPT's performance, we highlight its potential and limitations, offering software engineers insights to effectively integrate AI tools into their workflows.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {533–540},
numpages = {8},
keywords = {use case description, ChatGPT, requirements engineering, quality},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

