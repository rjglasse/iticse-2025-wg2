@inproceedings{10.1145/3626252.3630927,
author = {Kirova, Vassilka D. and Ku, Cyril S. and Laracy, Joseph R. and Marlowe, Thomas J.},
title = {Software Engineering Education Must Adapt and Evolve for an LLM Environment},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630927},
doi = {10.1145/3626252.3630927},
abstract = {In the era of artificial intelligence (AI), generative AI, and Large Language Models (LLMs) in particular, have become increasingly significant in various sectors. LLMs such as GPT expand their applications, from content creation to advanced code completion. They offer unmatched opportunities but pose unique challenges to the software engineering domain. This paper discusses the necessity and urgency for software engineering education to adapt and evolve to prepare software engineers for the emerging LLM environment. While existing literature and social media have investigated AI's integration into various educational spheres, there is a conspicuous gap in examining the specifics of LLMs' implications for software engineering education. We explore the goals of software engineering education, and changes to software engineering, software engineering education, course pedagogy, and ethics. We argue that a holistic approach is needed, combining technical skills, ethical awareness, and adaptable learning strategies. This paper seeks to contribute to the ongoing conversation about the future of software engineering education, emphasizing the importance of adapting and evolving to remain in sync with rapid advancements in AI and LLMs. It is hoped that this exploration will provide valuable insights for educators, curriculum developers, and policymakers in software engineering.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {666–672},
numpages = {7},
keywords = {chatgpt, generative ai, large language models (llms), responsible ai, software engineering, software engineering education, software engineering ethics, software ethics},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3548660.3561332,
author = {Cernau, Laura Diana and Dio\c{s}an, Laura Silvia and undefinederban, Camelia},
title = {A pedagogical approach in interleaving software quality concerns at an artificial intelligence course},
year = {2022},
isbn = {9781450394536},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3548660.3561332},
doi = {10.1145/3548660.3561332},
abstract = {The software engineering industry is an everchanging domain requiring professionals to have a good knowledge base and adaptability skills.Artificial Intelligence (AI) has achieved substantial success in enhancing program analysis techniques and applications, including bug prediction. It is a promising direction by applying advanced Machine Learning techniques into suitable software engineering tasks.  

The main goal of this paper is to propose a pedagogical interdisciplinary approach that pave the path for developing an e-learning platform serving to check the quality of the source code that students wrote by means of Artificial Intelligence techniques. By putting into practice this proposal, we are planning to show the students how to combine concepts learned from two different courses. The first step of this approach would be part of the Advanced Programming Methods, a Software Engineering related course, where students learn about the importance of writing good quality code and use software metrics as a mean of software quality assessment. Then, the following steps will be integrated into the Artificial Intelligence course, where students learn about different Machine Learning algorithms and how to apply them to solve practical problems. Thus, as an applicability in this respect, students use the metric values calculated for their projects developed at Advanced Programming Methods course as lab assignments and also to train (at Artificial Intelligence class) a bug detection model able to estimate the quality of new codebases.  

The proposed approach is helpful for both students and teachers. On one side, it helps the students understand the importance of writing clean, high-quality code. And on the other side, it helps teachers in their evaluation process by giving them time to focus on different aspects of homework than the code quality.},
booktitle = {Proceedings of the 4th International Workshop on Education through Advanced Software Engineering and Artificial Intelligence},
pages = {18–24},
numpages = {7},
keywords = {code quality, software engineering, software metrics},
location = {Singapore, Singapore},
series = {EASEAI 2022}
}

@inproceedings{10.1145/3658271.3658337,
author = {Santos, Patricia de Oliveira and Figueiredo, Allan Chamon and Nuno Moura, Pedro and Diirr, Bruna and Alvim, Adriana C. F. and Santos, Rodrigo Pereira Dos},
title = {Impacts of the Usage of Generative Artificial Intelligence on Software Development Process},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658271.3658337},
doi = {10.1145/3658271.3658337},
abstract = {Context: Over the years, tools have been created to improve the execution of development process activities. The emergence of generative Artificial Intelligence (AI) and, more recently, the launch and dissemination of Copilot, ChatGPT-3 and other generative tools, have broadened the discussion about the possibility of using conversational generative AI tools in diverse development tasks. Problem: There is still a lack of secondary studies to map the literature about how software development process activities can be affected by the usage of generative AI tools. Solution: This study aims to identify in which activities of the software development process Natural Language (NL) generative AI tools have been used and how they can impact requirements specification, design/architecture, development and testing activities. IS Theory: The study was developed under the aegis of the Task Technology Fit theory. Method: This work presents the results of a Systematic Mapping Review (SMR) carried out to collect research results that investigate the application of generative AI tools in the software development process. Results: Results indicate that the main activities affected are development and testing and that, although there are still some issues to be addressed, there are benefits in using AI generative tools compared to using more traditional methods like human-human pair programming and code testing made by software engineering professionals. Contribution: It was possible to collect studies to identify in which activities of the software development process generative AI tools can be applied and what are the impacts of using this technology.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {65},
numpages = {9},
keywords = {ChatGPT, Copilot, Generative AI, Software Engineering, Software Process},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

@inproceedings{10.1145/3643991.3645079,
author = {Zhang, Yue and Meredith, Rachel and Reeves, Wilson and Coriolano, J\'{u}lia and Babar, Muhammad Ali and Rahman, Akond},
title = {Does Generative AI Generate Smells Related to Container Orchestration?: An Exploratory Study with Kubernetes Manifests},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645079},
doi = {10.1145/3643991.3645079},
abstract = {Generative artificial intelligence (AI) technologies, such as ChatGPT have shown promise in solving software engineering problems. However, these technologies have also shown to be susceptible to generating software artifacts that contain quality issues. A systematic characterization of quality issues, such as smells in ChatGPT-generated artifacts can help in providing recommendations for practitioners who use generative AI for container orchestration.We conduct an empirical study with 98 Kubernetes manifests to quantify smells in manifests generated by ChatGPT. Our empirical study shows: (i) 35.8% of the 98 Kubernetes manifests generated include at least one instance of smell; (ii) two types of objects Kubernetes namely, Deployment and Service are impacted by identified smells; and (iii) the most frequently occurring smell is unset CPU and memory requirements. Based on our findings, we recommend practitioners to apply quality assurance activities for ChatGPT-generated Kubernetes manifests prior to using these manifests for container orchestration.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {192–196},
numpages = {5},
keywords = {container orchestration, empirical study, kubernetes, quality, smell},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3632621.3671424,
author = {Mozgovoy, Maxim and Suero Montero, Calkin},
title = {Exploring Students Solutions to Concurrent and Parallel Programming Exercises – Impact of Generative AI},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671424},
doi = {10.1145/3632621.3671424},
abstract = {Background. Concurrent and parallel programming is difficult to teach and learn as the understanding of complex and abstract concepts such as nondeterminism, semaphore, and rare conditions, among others, is required [1, 2, 9], having as a core issue the synchronisation of processes to achieve a common goal [4]. It is well-acknowledged that concurrent and parallel programming skills are fundamental since, nowadays, computing is increasingly handled in a parallel manner [7].Problem and Motivation. Therefore, identifying students’ pitfalls and successes when solving practical concurrent and parallel programming exercises could shed light on the best approaches and strategies that they use [3]. In addition, the advent of large language models, and generative AI applications such as ChatGPT, has prompted intensive research on their use in several areas including programming teaching and learning [8]. Yet, the studies in the literature have focused on issues related to learning to program by novice students in introductory courses (e.g., CS1, CS2) [6]. Less work, however, has been presented on the impact of generative AI tools in advanced programming practices such as concurrent and parallel programming.Methodology. To investigate whether generative AI has had an impact on the submitted concurrent and parallel programming exercises solutions at the University of Aizu, Japan, we performed a comparison analysis of the students’ submissions over 2020–2023. The analysis included five different exercises covering the basis of concurrency through various tasks and scenarios where the implementation of parallel processes is needed as solution. For instance, exercises 2.3 and 2.4 required to create parallel processes and perform independent computations; exercises 3.2 and 3.3, required synchronisation of the parallel processes; and in exercise 3.5 a code template was given for modification. We analysed the submissions of 72 undergraduate 3rd year students (avg. 18 students/year) and labelled the solutions using the following nomenclature: OK, indicating a good solution; OKFeat, a good solution but with unusual features; AdvLib, use of unnecessary advanced library or functionality; BadTool, use of an inappropriate tool when the task definition explicitly required a different tool; CodeErr, general coding error; SyncErr, concurrent programming specific error; N/A, solution not submitted or incomplete.Results and Analysis. Results show a substantial increase in the incidence of use of advance libraries (AdvLib) and the wrong tools (BadTool) among students in 2023 for three out of the five analysed exercises. At the same time the concurrency programming-specific errors (SyncErr) also see a reduction in all the exercises. (Figure 1). This coincides with the availability of generative AI tools such as ChatGPT [5], which warrants further investigations to understand how students, teachers and instructors could harness the affordances of large language models in their concurrent programming learning, teaching, and practice.Contribution and Impact. This paper presents an initial step towards investigating the impact of generative AI on advanced programming topics. This research will continue to uncover strategies for the lecturers and instructors to identify the affordances and use of generative AI and to design exercises that harness these affordances to support students learning of difficult programming concepts.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {533–534},
numpages = {2},
keywords = {Evaluation of students’ exercises, Large language models in advanced programming},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@article{10.1145/3593230,
author = {Brie, Paul and Burny, Nicolas and Slu\"{y}ters, Arthur and Vanderdonckt, Jean},
title = {Evaluating a Large Language Model on Searching for GUI Layouts},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {EICS},
url = {https://doi.org/10.1145/3593230},
doi = {10.1145/3593230},
abstract = {The field of generative artificial intelligence has seen significant advancements in recent years with the advent of large language models, which have shown impressive results in software engineering tasks but not yet in engineering user interfaces. Thus, we raise a specific research question: would an LLM-based system be able to search for relevant GUI layouts? To address this question, we conducted a controlled study evaluating how Instigator, an LLM-based system for searching GUI layouts of web pages by generative pre-trained training, would return GUI layouts that are relevant to a given instruction and what would be the user experience of (N =34) practitioners interacting with Instigator. Our results identify a very high similarity and a moderate correlation between the rankings of the GUI layouts generated by Instigator and the rankings of the practitioners with respect to their relevance to a given design instruction. We highlight the results obtained through thirteen UEQ+ scales that characterize the user experience of the practitioner with Instigator, which we use to discuss perspectives for improving such future tools.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {178},
numpages = {37},
keywords = {generative pre-training, gui design, gui layout, large language model, web pages}
}

@inproceedings{10.1145/3661167.3661273,
author = {Mezzaro, Simone and Gambi, Alessio and Fraser, Gordon},
title = {An Empirical Study on How Large Language Models Impact Software Testing Learning},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661273},
doi = {10.1145/3661167.3661273},
abstract = {Software testing is a challenging topic in software engineering education and requires creative approaches to engage learners. For example, the Code Defenders game has students compete over a Java class under test by writing effective tests and mutants. While such gamified approaches deal with problems of motivation and engagement, students may nevertheless require help to put testing concepts into practice. The recent widespread diffusion of Generative AI and Large Language Models raises the question of whether and how these disruptive technologies could address this problem, for example, by providing explanations of unclear topics and guidance for writing tests. However, such technologies might also be misused or produce inaccurate answers, which would negatively impact learning. To shed more light on this situation, we conducted the first empirical study investigating how students learn and practice new software testing concepts in the context of the Code Defenders testing game, supported by a smart assistant based on a widely known, commercial Large Language Model. Our study shows that students had unrealistic expectations about the smart assistant, “blindly” trusting any output it generated, and often trying to use it to obtain solutions for testing exercises directly. Consequently, students who resorted to the smart assistant more often were less effective and efficient than those who did not. For instance, they wrote 8.6% fewer tests, and their tests were not useful in 78.0% of the cases. We conclude that giving unrestricted and unguided access to Large Language Models might generally impair learning. Thus, we believe our study helps to raise awareness about the implications of using Generative AI and Large Language Models in Computer Science Education and provides guidance towards developing better and smarter learning tools.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {555–564},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, Generative AI, Smart Learning Assistant},
location = {Salerno, Italy},
series = {EASE '24}
}

@article{10.5555/3722479.3722491,
author = {Hegde, Vageesh and Bolar, Supreetha},
title = {Unveiling the Nexus: AI, Environmental Impact, and Cost},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {As we move into 2024, the global landscape is experiencing a significant increase in the adoption of artificial intelligence (AI), which is revolutionizing industries and societies. AI, powered by machine learning (ML) and other advanced programming techniques, represents non-human intelligence capable of learning from large datasets. This transformative technology presents unparalleled opportunities, but also significant challenges, particularly with regards to its environmental impact and economic feasibility. This paper explores the two sides of AI development: Generative AI requires a lot of processing power, leading to high energy consumption and substantial CO2 emissions, affecting its cost-effectiveness and environmental impact. It meticulously examines the complex components contributing to the operational costs of AI models, including computational resources, data storage, energy consumption, and infrastructure requirements. It rigorously analyzes factors influencing these costs, such as model complexity, data volume, and technological infrastructure, to provide a comprehensive framework for cost analysis in AI. Furthermore, the paper explores methodologies for evaluating and quantifying these operational costs, which are essential for calculating return on investment (ROI) in AI initiatives. Real-world case studies illustrate the practical applications of AI, comparing different models to determine their cost-effectiveness and ROI. The paper discusses emerging trends in AI development focused on reducing environmental impact, including green AI initiatives and energy-efficient strategies. It concludes with insights into future research directions, advocating for advancements in cost analysis methodologies and sustainable AI practices to promote responsible AI innovation. In summary, his paper offers a comprehensive analysis of the economic and environmental aspects of AI deployment, providing valuable insights for stakeholders navigating the complexities of AI implementation in a rapidly evolving technological landscape.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {37–38},
numpages = {2}
}

@inproceedings{10.1145/3691620.3695062,
author = {Liu, Fang and Liu, Zhenwei and Zhao, Qianhui and Jiang, Jing and Zhang, Li and Sun, Zian and Li, Ge and Li, Zhongqi and Ma, Yuchi},
title = {FastFixer: An Efficient and Effective Approach for Repairing Programming Assignments},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695062},
doi = {10.1145/3691620.3695062},
abstract = {Providing personalized and timely feedback for student's programming assignments is useful for programming education. Automated program repair (APR) techniques have been used to fix the bugs in programming assignments, where the Large Language Models (LLMs) based approaches have shown promising results. Given the growing complexity of identifying and fixing bugs in advanced programming assignments, current fine-tuning strategies for APR are inadequate in guiding the LLM to identify bugs and make accurate edits during the generative repair process. Furthermore, the autoregressive decoding approach employed by the LLM could potentially impede the efficiency of the repair, thereby hindering the ability to provide timely feedback. To tackle these challenges, we propose FastFixer, an efficient and effective approach for programming assignment repair. To assist the LLM in accurately identifying and repairing bugs, we first propose a novel repair-oriented fine-tuning strategy, aiming to enhance the LLM's attention towards learning how to generate the necessary patch and its associated context. Furthermore, to speed up the patch generation, we propose an inference acceleration approach that is specifically tailored for the program repair task. The evaluation results demonstrate that FastFixer obtains an overall improvement of 20.46% in assignment fixing when compared to the state-of-the-art baseline. Considering the repair efficiency, FastFixer achieves a remarkable inference speedup of 16.67\texttimes{} compared to the autoregressive decoding algorithm.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {669–680},
numpages = {12},
keywords = {automated program repair, large language models, programming education, inference acceleration},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3661167.3661271,
author = {Novielli, Nicole},
title = {Surfing the AI Wave in Software Engineering: Opportunities and Challenges},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661271},
doi = {10.1145/3661167.3661271},
abstract = {The diffusion of generative AI, specifically Large Language Models (LLMs), is profoundly affecting Software Engineering. Thanks to their unprecedented potential for disruptive changes, which mainly reside in their ability to reduce the need for large-scale training data for new tasks and to lower the technical entry barrier, these technologies offer the enormous opportunity to accelerate and enhance software engineering research and practice. Nevertheless, concerns also emerge related to the risks associated to poor results and indiscriminate use. In this evolving landscape, it becomes crucial to assess the opportunities and challenges posed by these emerging technologies. In this talk, I will reflect on the role of research in the era of AI in the hope of triggering a discussion on the shift in paradigm for empirical software engineering.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {6},
numpages = {1},
keywords = {Artificial Intelligence, Human Aspects of Software Engineering, Large Language Models, Software Engineering},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3701625.3701657,
author = {de Almeida, \'{A}gatha and Collins, Eliane and Oran, Ana Carolina},
title = {AI in Service of Software Quality: How ChatGPT and Personas Are Transforming Exploratory Testing},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701657},
doi = {10.1145/3701625.3701657},
abstract = {Context: Exploratory testing is essential in the software validation process as a way to find unexpected and critical failures in a short time, complementing documented functional test cases. However, creating scenarios to explore the software (such as test charters) can be time-consuming, and depending on the team’s experience, it may lack adequate coverage of functionalities and scenarios that target specific user profiles of the application. Objective: This article investigates how AI, through LLMs (Large Language Models), can assist in creating exploratory test charters that reflect the characteristics and needs of different user personas. Method: To achieve this, an experimental study was conducted where personas were used as input in ChatGPT 3.5 to generate exploratory test charters. The effectiveness of the approach was evaluated by Software Engineering students, who analyzed the performance and usefulness of the generated charters through a questionnaire based on the TAM model, supplemented by qualitative and quantitative analyses. Results: Data analysis indicated positive acceptance of ChatGPT 3.5 by the participants, highlighting its ease of use and perceived usefulness. Conclusion: This study contributes to the field of Software Engineering by demonstrating a practical application of artificial intelligence in the automated generation of test charters. ChatGPT 3.5 has proven to be a promising tool to support the creation of personalized exploratory test charters, contributing to software quality improvement. The integration of artificial intelligence techniques with user-centered design methods can significantly optimize the software testing process.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {179–188},
numpages = {10},
keywords = {Exploratory Testing, ChatGPT, Personas, Software Quality, Artificial Intelligence},
location = {
},
series = {SBQS '24}
}

@article{10.1145/3643758,
author = {Wang, Wei and Ning, Huilong and Zhang, Gaowei and Liu, Libo and Wang, Yi},
title = {Rocks Coding, Not Development: A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643758},
doi = {10.1145/3643758},
abstract = {Recently, large language models (LLM) based generative AI has been gaining momentum for their impressive high-quality performances in multiple domains, particularly after the release of the ChatGPT. Many believe that they have the potential to perform general-purpose problem-solving in software development and replace human software developers. Nevertheless, there are in a lack of serious investigation into the capability of these LLM techniques in fulfilling software development tasks. In a controlled 2 \texttimes{} 2 between-subject experiment with 109 participants, we examined whether and to what degree working with ChatGPT was helpful in the coding task and typical software development task and how people work with ChatGPT. We found that while ChatGPT performed well in solving simple coding problems, its performance in supporting typical software development tasks was not that good. We also observed the interactions between participants and ChatGPT and found the relations between the interactions and the outcomes. Our study thus provides first-hand insights into using ChatGPT to fulfill software engineering tasks with real-world developers and motivates the need for novel interaction mechanisms that help developers effectively work with large language models to achieve desired outcomes.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {32},
numpages = {23},
keywords = {controlled experiment, human-AI collaboration, large langauge models, software development task}
}

@inproceedings{10.1145/3701268.3701273,
author = {Conway, Brian and Nolan, Keith and Quille, Keith},
title = {HCAI Block Model: A competence model for Human Centred Artificial Intelligence at K-12},
year = {2024},
isbn = {9798400711596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701268.3701273},
doi = {10.1145/3701268.3701273},
abstract = {Artificial Intelligence (AI) is becoming a common topic within the computing K-12 curricula worldwide. While much of the focus of research is on the use of Generative AI in and for education, AI as a core subject area is still gaining popularity, with much of this research focusing on content and tools that effectively support the teaching of AI. However, as we grow as a field, there is a need currently unmet to provide foundations (in the form of a block model as there exists for programming) to allow researchers to build strong pedagogies and methodologies from, and even a base to design activities and content. Compounding this, as ethics and its relationship to AI in the K-12 classroom grows stronger, there is a further need to provide scaffolding to educators and researchers not only on traditional AI concepts, but also on how they link with ethical knowledge, skills and dispositions. In this paper, the Human Centered Artificial Intelligence (HCAI) Block Model is developed and introduced. This is a competence-based model to guide effective teaching and learning of Human Centered Artificial Intelligence, as well as research in the K-12 space. The HCAI Block model’s foundation is developed/adapted from the programming Block model and has been adapted and developed using two lenses. The first was through the data science lens through interaction with Computational Thinking 2.0 and competency-based learning. The second lens was through a human-centred lens. The outcome was a ground-up K-12 model where traditional and technical AI concepts have been developed from the start, integrating ethical considerations and human-centred approaches.},
booktitle = {Proceedings of the 2024 Conference on Human Centred Artificial Intelligence - Education and Practice},
pages = {22–28},
numpages = {7},
keywords = {Computing Education, Machine Learning, Human-Centered AI, Block Model, Ethics, Computational Thinking 2.0},
location = {
},
series = {HCAIep '24}
}

@article{10.1145/3652154,
author = {Russo, Daniel},
title = {Navigating the Complexity of Generative AI Adoption in Software Engineering},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3652154},
doi = {10.1145/3652154},
abstract = {This article explores the adoption of Generative Artificial Intelligence (AI) tools within the domain of software engineering, focusing on the influencing factors at the individual, technological, and social levels. We applied a convergent mixed-methods approach to offer a comprehensive understanding of AI adoption dynamics. We initially conducted a questionnaire survey with 100 software engineers, drawing upon the Technology Acceptance Model, the Diffusion of Innovation Theory, and the Social Cognitive Theory as guiding theoretical frameworks. Employing the Gioia methodology, we derived a theoretical model of AI adoption in software engineering: the Human-AI Collaboration and Adaptation Framework. This model was then validated using Partial Least Squares–Structural Equation Modeling based on data from 183 software engineers. Findings indicate that at this early stage of AI integration, the compatibility of AI tools within existing development workflows predominantly drives their adoption, challenging conventional technology acceptance theories. The impact of perceived usefulness, social factors, and personal innovativeness seems less pronounced than expected. The study provides crucial insights for future AI tool design and offers a framework for developing effective organizational implementation strategies.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {135},
numpages = {50},
keywords = {Generative AI, large language models, technology adaption, empirical software engineering}
}

@inproceedings{10.1145/3587102.3588815,
author = {Daun, Marian and Brings, Jennifer},
title = {How ChatGPT Will Change Software Engineering Education},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588815},
doi = {10.1145/3587102.3588815},
abstract = {This position paper discusses the potential for using generative AIs like ChatGPT in software engineering education. Currently, discussions center around potential threats emerging from student's use of ChatGPT. For instance, generative AI will limit the usefulness of graded homework dramatically. However, there exist potential opportunities as well. For example, ChatGPT's ability to understand and generate human language allows providing personalized feedback to students, and can thus accompany current software engineering education approaches. This paper highlights the potential for enhancing software engineering education. The availability of generative AI will improve the individualization of education approaches. In addition, we discuss the need to adapt software engineering curricula to the changed profiles of software engineers. Moreover, we point out why it is important to provide guidance for using generative AI and, thus, integrate it in courses rather than accepting the unsupervised use by students, which can negatively impact the students' learning.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {110–116},
numpages = {7},
keywords = {ChatGPT, generative AI, software engineering education},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3613372.3614199,
author = {Font\~{a}o, Awdren and Matsubara, Edson and Mongelli, Henrique and Medeiros, Marcio and Louren\c{c}o, Carlos and Martins, Henrique and Cortez, Igor and Borges, Maria},
title = {Hyacinth macaw: a project-based learning program to develop talents in Software Engineering for Artificial Intelligence},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613372.3614199},
doi = {10.1145/3613372.3614199},
abstract = {Software Engineering for Artificial Intelligence (SE4A) uses SE principles to design and maintain AI systems, requiring analytical thinking for software complexity, while AI demands mathematical knowledge and algorithm adjustment. The IEEE Curriculum Guidelines for Undergraduate Degree Programs in Software Engineering states that extracurricular elements impact students’ preparation. This study focuses on the first module of a project-based learning talent development program involving undergraduate students, two expert professors (in AI and SE), and mentors from sponsoring companies. An exploratory case study with 39 students from four courses was conducted, challenging them to deliver an MVP in machine learning within 1.5 months. Results showed high agreement (87.5%) in applying learned skills to future projects, recognizing SE’s benefits (96.9%) in AI, and acknowledging the connection between SE and AI (78.1%). Participants applied relevant knowledge in ML performance, data analysis, and software architecture for AI. We share strategies used by students to enhance developer experience.},
booktitle = {Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
pages = {312–321},
numpages = {10},
location = {Campo Grande, Brazil},
series = {SBES '23}
}

@inproceedings{10.1145/3643795.3648379,
author = {Rasnayaka, Sanka and Wang, Guanlin and Shariffdeen, Ridwan and Iyer, Ganesh Neelakanta},
title = {An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648379},
doi = {10.1145/3643795.3648379},
abstract = {Large Language Models (LLMs) represent a leap in artificial intelligence, excelling in tasks using human language(s). Although the main focus of general-purpose LLMs is not code generation, they have shown promising results in the domain. However, the usefulness of LLMs in an academic software engineering project has not been fully explored yet. In this study, we explore the usefulness of LLMs for 214 students working in teams consisting of up to six members. Notably, in the academic course through which this study is conducted, students were encouraged to integrate LLMs into their development tool-chain, in contrast to most other academic courses that explicitly prohibit the use of LLMs.In this paper, we analyze the AI-generated code, prompts used for code generation, and the human intervention levels to integrate the code into the code base. We also conduct a perception study to gain insights into the perceived usefulness, influencing factors, and future outlook of LLM from a computer science student's perspective. Our findings suggest that LLMs can play a crucial role in the early stages of software development, especially in generating foundational code structures, and helping with syntax and error debugging. These insights provide us with a framework on how to effectively utilize LLMs as a tool to enhance the productivity of software engineering students, and highlight the necessity of shifting the educational focus toward preparing students for successful human-AI collaboration.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {111–118},
numpages = {8},
keywords = {LLM for code generation, software engineering},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3644815.3644981,
author = {Rahman, Md Tajmilur and Singh, Rahul and Sultan, Mir Yousuf},
title = {Automating Patch Set Generation from Code Reviews Using Large Language Models},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644981},
doi = {10.1145/3644815.3644981},
abstract = {The advent of Large Language Models (LLMs) has revolutionized various domains of artificial intelligence, including the realm of software engineering. In this research, we evaluate the efficacy of pre-trained LLMs in replicating the tasks traditionally performed by developers in response to code review comments. We provide code contexts to five popular LLMs and obtain the suggested code-changes (patch sets) derived from real-world code-review comments. The performance of each model is meticulously assessed by comparing their generated patch sets against the historical data of human-generated patch-sets from the same repositories. This comparative analysis aims to determine the accuracy, relevance, and depth of the LLMs' feedback, thereby evaluating their readiness to support developers in responding to code-review comments. Novelty: This particular research area is still immature requiring a substantial amount of studies yet to be done. No prior research has compared the performance of existing Large Language Models (LLMs) in code-review comments. This in-progress study assesses current LLMs in code review and paves the way for future advancements in automated code quality assurance, reducing context-switching overhead due to interruptions from code change requests.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {273–274},
numpages = {2},
keywords = {large language models, automated code review, software engineering, pull requests, code quality},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3691620.3695306,
author = {Baresi, Luciano and Camilli, Matteo and Dolci, Tommaso and Quattrocchi, Giovanni},
title = {A Conceptual Framework for Quality Assurance of LLM-based Socio-critical Systems},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695306},
doi = {10.1145/3691620.3695306},
abstract = {Recent breakthroughs in Artificial Intelligence (AI) obfuscate the boundaries between digital, physical, and social spaces, a trend expected to continue in the foreseeable future. Traditionally, software engineering has prioritized technical aspects, focusing on functional correctness and reliability while often neglecting broader societal implications. With the rise of software agents enabled by Large Language Models (LLMs) and capable of emulating human intelligence and perception, there is a growing recognition of the need for addressing socio-critical issues. Unlike technical challenges, these issues cannot be resolved through traditional, deterministic approaches due to their subjective nature and dependence on evolving factors such as culture and demographics. This paper dives into this problem and advocates the need for revising existing engineering principles and methodologies. We propose a conceptual framework for quality assurance where AI is not only the driver of socio-critical systems but also a fundamental tool in their engineering process. Such framework encapsulates pre-production and runtime workflows where LLM-based agents, so-called artificial doppelg\"{a}ngers, continuously assess and refine socio-critical systems ensuring their alignment with established societal standards.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2314–2318},
numpages = {5},
keywords = {AI-enabled agents, large language models, quality assurance},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3643787.3648032,
author = {Shome, Arumoy and Cruz, Luis and Van Deursen, Arie},
title = {Towards Automatic Translation of Machine Learning Visual Insights to Analytical Assertions},
year = {2024},
isbn = {9798400705762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643787.3648032},
doi = {10.1145/3643787.3648032},
abstract = {We present our vision for developing an automated tool capable of translating visual properties observed in Machine Learning (ML) visualisations into Python assertions. The tool aims to streamline the process of manually verifying these visualisations in the ML development cycle, which is critical as real-world data and assumptions often change post-deployment. In a prior study, we mined 54, 070 Jupyter notebooks from Github and created a catalogue of 269 semantically related visualisation-assertion (VA) pairs. Building on this catalogue, we propose to build a taxonomy that organises the VA pairs based on ML verification tasks. The input feature space comprises of a rich source of information mined from the Jupyter notebooks---visualisations, Python source code, and associated markdown text. The effectiveness of various AI models, including traditional NLP4Code models and modern Large Language Models, will be compared using established machine translation metrics and evaluated through a qualitative study with human participants. The paper also plans to address the challenge of extending the existing VA pair dataset with additional pairs from Kaggle and to compare the tool's effectiveness with commercial generative AI models like ChatGPT. This research not only contributes to the field of ML system validation but also explores novel ways to leverage AI for automating and enhancing software engineering practices in ML.},
booktitle = {Proceedings of the Third ACM/IEEE International Workshop on NL-Based Software Engineering},
pages = {29–32},
numpages = {4},
keywords = {SE4AI, NLP4Code, ML testing, visualisations, assertions, computational notebooks, automated tool},
location = {Lisbon, Portugal},
series = {NLBSE '24}
}

@inproceedings{10.1145/3597503.3639111,
author = {Dolata, Mateusz and Lange, Norbert and Schwabe, Gerhard},
title = {Development in times of hype: How freelancers explore Generative AI?},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639111},
doi = {10.1145/3597503.3639111},
abstract = {The rise of generative AI has led many companies to hire freelancers to harness its potential. However, this technology presents unique challenges to developers who have not previously engaged with it. Freelancers may find these challenges daunting due to the absence of organizational support and their reliance on positive client feedback. In a study involving 52 freelance developers, we identified multiple challenges associated with developing solutions based on generative AI. Freelancers often struggle with aspects they perceive as unique to generative AI such as unpredictability of its output, the occurrence of hallucinations, and the inconsistent effort required due to trial-and-error prompting cycles. Further, the limitations of specific frameworks, such as token limits and long response times, add to the complexity. Hype-related issues, such as inflated client expectations and a rapidly evolving technological ecosystem, further exacerbate the difficulties. To address these issues, we propose Software Engineering for Generative AI (SE4GenAI) and Hype-Induced Software Engineering (HypeSE) as areas where the software engineering community can provide effective guidance. This support is essential for freelancers working with generative AI and other emerging technologies.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {183},
numpages = {13},
keywords = {generative AI, AI-based systems, challenges, freelancers, hype, SE for generative AI, SE4GenAI, hype-induced SE, hype-SE, fashion, product, paradigm, novelty, qualitative research},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3626253.3635343,
author = {Schroeder, Rebecca and Niu, Jianwei and Malshe, Ashwin and Hum, Sue and Flemming, Siobhan and Thacker, Ian},
title = {Enabling Widespread Engagement in DS and AI: The Generation AI Curriculum Initiative for Community Colleges},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635343},
doi = {10.1145/3626253.3635343},
abstract = {The proposed initiative aims to promote broader engagement in data science and artificial intelligence by encouraging the integration of a research-based Generation AI (GenAI) curriculum within community colleges. The GenAI curriculum encompasses interdisciplinary modules, data sets, and educational content relevant to data science, computer science, and artificial intelligence. Community colleges, being vital conduits to a substantial student demographic (as evidenced by 40% of first-time college freshmen commencing their post-secondary education at these institutions), present an opportune environment for enhancing student diversity and, consequently, diversifying the workforce in data science, computer science, and AI.  The GenAI team at The University of Texas at San Antonio endeavor to develop and implement instructor training and curriculum development workshops tailored for community college faculty. Through collaboration, GenAI and community college faculty will establish faculty learning communities, fostering the creation of novel modules and distinctive instructional materials that will seamlessly integrate into the established computer science and data science curricula. At this nascent stage of the project, our team is eager to receive valuable input regarding potential theoretical frameworks, exploration of pertinent existing approaches, and expressions of interest for collaboration, all of which are pivotal in shaping the design and successful implementation of this initiative.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1938},
numpages = {1},
keywords = {artificial intelligence, community colleges, data science, experiential learning, higher education, underrepresented minorities},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3657604.3664673,
author = {Fung, Sze Ching Evelyn and Wong, Man Fai and Tan, Chee Wei},
title = {Automatic Feedback Generation on K-12 Students' Data Science Education by Prompting Cloud-based Large Language Models},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664673},
doi = {10.1145/3657604.3664673},
abstract = {Since data science is traditionally an advanced field taught at the college or university level, introducing its concepts to K-12 students can present unique learning challenges. As educational environments increasingly adopt data science curricula for K-12 students, the need for scalable, personalized teaching tools becomes critical. While the integration of large language models (LLMs) in educational environments offers significant potential for scalability and automation, it is important to note that the generated language output may not always be highly suitable for K-12 students. In this paper, we introduce the DSRAG, a novel educational automatic feedback generation framework that leverages Retrieval-Augmented Generation (RAG) and cloud-based LLMs to provide automated and personalized feedback for K-12 students engaged in data science education. DSRAG employs Langchain question-answering and RAG systems to manage educational content and generate feedback on the top of GPT-4. We also demonstrate the framework's capability to simplify complex concepts and align its responses to be pedagogically appropriate and understandable for K-12 students.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {255–258},
numpages = {4},
keywords = {large language models, learning technologies, prompt engineering, retrieval-augmented generation},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3585059.3611431,
author = {Zheng, Yong},
title = {ChatGPT for Teaching and Learning: An Experience from Data Science Education},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611431},
doi = {10.1145/3585059.3611431},
abstract = {ChatGPT, an implementation and application of large language models, has gained significant popularity since its initial release. Researchers have been exploring ways to harness the practical benefits of ChatGPT in real-world scenarios. Educational researchers have investigated its potential in various subjects, e.g., programming, mathematics, finance, clinical decision support, etc. However, there has been limited attention given to its application in data science education. This paper aims to bridge that gap by utilizing ChatGPT in a data science course, gathering perspectives from students, and presenting our experiences and feedback on using ChatGPT for teaching and learning in data science education. The findings not only distinguish data science education from other disciplines but also uncover new opportunities and challenges associated with incorporating ChatGPT into the data science curriculum.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {66–72},
numpages = {7},
keywords = {ChatGPT, data analytics, data science, large language model},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@inproceedings{10.1145/3649165.3703623,
author = {Ravi, Prerna and Parks, Robert and Masla, John and Abelson, Hal and Breazeal, Cynthia},
title = {"Data comes from the real world": A Constructionist Approach to Mainstreaming K12 Data Science Education},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3703623},
doi = {10.1145/3649165.3703623},
abstract = {Data science is emerging as a crucial 21st-century competence, influencing professional practices from citing evidence when advocating for social change to developing artificial intelligence (AI) models. For middle and high school students, data science can put formerly decontextualized subjects into real-world scenarios. Many existing curricula, however, lack authenticity and personal relevance for students. A critique of data science courseware cites the lack of "author proximity," in which students do not contribute to the data's production or see their personal experiences reflected in the data. This paper introduces a novel data science curriculum to scaffold middle and high school students in undertaking real-world data science practices. Through project-based learning modules, the curriculum engages students in investigating solutions to community-based problems through visualization and analysis of live sensor data and public data sets. Materials include formative assessments to help educators (especially those from non-math and computing backgrounds) measure their students' abilities to identify statistical patterns, critically evaluate data biases, and make predictions. As we pilot and co-design with teachers, we will look closely at whether the curriculum's resources can successfully support non-technical practitioners engaging in an integrated curriculum.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {271–274},
numpages = {4},
keywords = {computational action, k12 data science, participatory data collection, project-based learning, sensors},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@proceedings{10.1145/3637528,
title = {KDD '24: Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our pleasure to welcome you to the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining---KDD'2024 in Barcelona, Catalonia. This year's conference continues its tradition of being the premier forum for presentation of research results and experience reports on knowledge discovery, data science, and machine learning. The mission of the conference is to provide the best venue for advancement, education, and adoption of the "science" of knowledge discovery and machine learning from all types of data; to share novel methodologies that fulfill the needs of heterogeneous applications and environments and identify new directions for future research and development. These ideas have the potential to shape and impact our society and environment, becoming particularly important with the emergence of AI in all fields. So, KDD provides researchers and practitioners a unique opportunity to share their perspectives with others interested in various aspects of data science and machine learning.KDD'24 has a program of three keynotes (Sanjeev Arora, Tanya Berger-Wolf and Xihong Lin), one panel on generative AI, 411 research track papers, 151 applied data science (ADS) track papers and eight invited talks, 30 workshops, 34 tutorials (nine of them hands-on), nine special days (one online for India), and three KDD cups. We have introduced two new special days, one in Responsible AI and another in European Data Science given the location of the conference. We also added one extra poster session to have more time for posters presentations. For second time we used Openreview for the research and ADS tracks with the goal to further improve the review quality and facilitate the interaction between reviewers and authors. We hope that you will find this program interesting and thought-provoking and that the conference will provide you with a valuable opportunity to share ideas with other researchers and practitioners from institutions around the world.},
location = {Barcelona, Spain}
}

@inproceedings{10.1145/3686852.3686881,
author = {Alhazeem, Ensaf and Alsobeh, Anas and Al-Ahmad, Bilal},
title = {Enhancing Software Engineering Education through AI: An Empirical Study of Tree-Based Machine Learning for Defect Prediction},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3686881},
doi = {10.1145/3686852.3686881},
abstract = {In the rapidly evolving field of information technology education,integrating artificial intelligence (AI) and machine learning (ML) techniques presents opportunities and challenges. This empirical study investigates the application of tree-based ML techniques, specifically Random Forest (RF) and Extreme Gradient Boosting (XGBoost), for software defect prediction in the context of IT education. We analyze nine publicly available NASA software defect datasets to compare the performance of these algorithms across multiple metrics, including accuracy, precision, recall, and ROC area. Our findings demonstrate that XGBoost consistently outperforms Random Forest, achieving near-perfect accuracy across most datasets. The paper explores how these advanced techniques can be responsibly integrated into software engineering (SE) education to enhance student learning while addressing concerns about potential over-reliance on AI tools. We discuss the implications of our results for IT education, emphasizing the need to balance the use of sophisticated AI technologies with the development of fundamental software assurance skills. Furthermore, we examine the role of AI in augmenting SE education, particularly in areas such as software assurance explanations, feature identification, and data augmentation.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {153–156},
numpages = {4},
keywords = {AI in Education, Machine Learning (ML), Random Forest, Software Defect Prediction, Software Engineering, XGBoost},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3626203.3670577,
author = {Nadel, Peter and Maloney, Delilah and Monahan, Kyle},
title = {Enabling access to large-language models (LLMs) at scale for higher education},
year = {2024},
isbn = {9798400704192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626203.3670577},
doi = {10.1145/3626203.3670577},
abstract = {The use of language models, particularly large-language models (LLMs), have been increasingly popular and can be transformative in higher education, by both enabling novel research approaches and providing instructional opportunities for skills needed in data science and engineering. However, running these LLMs traditionally requires access to advanced hardware resources and technical knowledge. To better provide a platform for experimenting with LLMs for users of all skill levels, we developed the Tufts Technology Services (TTS) LLM-Hub, a series of example Jupyter notebooks served through Tufts Open OnDemand (OOD) to setup, configure, and run LLMs automatically. The TTS LLM-Hub enabled quick access to running LLMs, while reducing barriers to compute and enabling users to chat with an LLM in just four clicks. We have used these platforms for support of advanced data science courses, and to enable research computing at Tufts.},
booktitle = {Practice and Experience in Advanced Research Computing 2024: Human Powered Computing},
articleno = {49},
numpages = {4},
keywords = {High-Performance Computing (HPC), Large-Language Models (LLMs), Open OnDemand (OOD)},
location = {Providence, RI, USA},
series = {PEARC '24}
}

@inproceedings{10.1145/3626252.3630928,
author = {Poulsen, Seth and Sarsa, Sami and Prather, James and Leinonen, Juho and Becker, Brett A. and Hellas, Arto and Denny, Paul and Reeves, Brent N.},
title = {Solving Proof Block Problems Using Large Language Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630928},
doi = {10.1145/3626252.3630928},
abstract = {Large language models (LLMs) have recently taken many fields, including computer science, by storm. Most recent work on LLMs in computing education has shown that they are capable of solving most introductory programming (CS1) exercises, exam questions, Parsons problems, and several other types of exercises and questions. Some work has investigated the ability of LLMs to solve CS2 problems as well. However, it remains unclear how well LLMs fare against more advanced upper-division coursework, such as proofs in algorithms courses. After all, while known to be proficient in many programming tasks, LLMs have been shown to have more difficulties in forming mathematical proofs.In this paper, we investigate the ability of LLMs to solve mathematical proofs by using Proof Blocks, a tool previously shown to efficaciously teach proofs to students. Our results show that GPT-3.5 is almost completely unable to provide correct solutions (11.4%), while GPT-4 shows a significant increase in correctness (64.8%). However, even given this improvement, current models still struggle to correctly order lines in a proof. It remains an open question whether this is a temporary situation or if LLMs will continue to struggle to solve these types of exercises in the future.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1063–1069},
numpages = {7},
keywords = {ai, algorithms, artificial intelligence, chatgpt, code generation, generative ai, gpt-3, gpt-4, large language models, openai, proof blocks, proofs},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3643795.3648387,
author = {Li, Zhiming and Cao, Yushi and Xu, Xiufeng and Jiang, Junzhe and Liu, Xu and Teo, Yon Shin and Lin, Shang-Wei and Liu, Yang},
title = {LLMs for Relational Reasoning: How Far are We?},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648387},
doi = {10.1145/3643795.3648387},
abstract = {Large language models (LLMs) have revolutionized many areas (e.g. natural language processing, software engineering, etc.) by achieving state-of-the-art performance on extensive downstream tasks. Aiming to achieve robust and general artificial intelligence, there has been a surge of interest in investigating the reasoning ability of the LLMs. Whereas the textual and numerical reasoning benchmarks adopted by previous works are rather shallow and simple, it is hard to conclude that the LLMs possess strong reasoning ability by merely achieving positive results on these benchmarks. Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks. In this work, we conduct an in-depth assessment of several state-of-the-art LLMs' reasoning ability based on the inductive logic programming (ILP) benchmark, which is broadly recognized as a representative and challenging measurement for evaluating logic program induction/synthesis systems as it requires inducing strict cause-effect logic to achieve robust deduction on independent and identically distributed (IID) and out-of-distribution (OOD) test samples. Our evaluations illustrate that compared with the neural program induction systems which are much smaller in model size, the state-of-the-art LLMs are much poorer in terms of reasoning ability by achieving much lower performance and generalization using either natural language prompting or truth-value matrix prompting1.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {119–126},
numpages = {8},
keywords = {large language models, relational reasoning, program induction},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@article{10.14778/3685800.3685911,
author = {Wang, Jianguo and Hanson, Eric and Li, Guoliang and Papakonstantinou, Yannis and Simhadri, Harsha and Xie, Charles},
title = {Vector Databases: What's Really New and What's Next? (VLDB 2024 Panel)},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685911},
doi = {10.14778/3685800.3685911},
abstract = {Vector databases have recently emerged as a hot topic in the field of databases, especially in industry. This is due to the widespread interest in Large Language Models (LLMs), where vector databases provide the relevant context for LLMs to produce more accurate responses. However, vector data is not new. It has been studied for more than two decades, leading to many efficient algorithms and indexes for vector similarity search. Thus, a natural question is: What is really new and what is next for vector databases? This panel will bring together several leading experts in vector databases to share their insights and experiences from various perspectives. The panel will also discuss the broader role of databases, beyond just vector databases, in the era of generative AI.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4505–4506},
numpages = {2}
}

@inproceedings{10.1145/3652620.3687776,
author = {Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta and Scalera, Michele},
title = {Enhancing Software Modeling Learning with AI-Powered Scaffolding},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687776},
doi = {10.1145/3652620.3687776},
abstract = {This study introduces an innovative AI-powered scaffolding approach aimed at enhancing software modeling learning through UML diagrams. The focus of this research is on defining the principles and functions comprising the scaffolding. Leveraging recent advancements in generative AI, our approach provides a structured educational framework to improve comprehension and proficiency in modeling concepts. We present the initial implementation of the scaffolding, specifically highlighting the feedback function. By integrating theoretical insights with practical applications, this study seeks to advance Model-Driven Software Engineering education and underscores the potential of AI in enhancing instructional methodologies.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {103–106},
numpages = {4},
keywords = {generative AI, education, software modelling, model-driven software engineering, UML, scaffolding},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3636243.3636263,
author = {Feng, Tony Haoran and Denny, Paul and Wuensche, Burkhard and Luxton-Reilly, Andrew and Hooper, Steffan},
title = {More Than Meets the AI: Evaluating the performance of GPT-4 on Computer Graphics assessment questions},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636263},
doi = {10.1145/3636243.3636263},
abstract = {Recent studies have showcased the exceptional performance of LLMs (Large Language Models) on assessment questions across various discipline areas. This can be helpful if used to support the learning process, for example by enabling students to quickly generate and contrast alternative solution approaches. However, concerns about student over-reliance and inappropriate use of LLMs in education are common. Understanding the capabilities of LLMs is essential for instructors to make informed decisions on question choices for learning and assessment tasks. In CS (Computer Science), previous evaluations of LLMs have focused on CS1 and CS2 questions, and little is known about how well LLMs perform for assessment questions in upper-level CS courses such as CG (Computer Graphics), which covers a wide variety of concepts and question types. To address this gap, we compiled a dataset of past assessment questions used in a final-year undergraduate course about introductory CG, and evaluated the performance of GPT-4 on this dataset. We also classified assessment questions and evaluated the performance of GPT-4 for different types of questions. We found that the performance tended to be best for simple mathematical questions, and worst for questions requiring creative thinking, and those with complex descriptions and/or images. We share our benchmark dataset with the community and provide new insights into the capabilities of GPT-4 in the context of CG courses. We highlight opportunities for teaching staff to improve student learning by guiding the use of LLMs for CG questions, and inform decisions around question choices for assessment tasks.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {182–191},
numpages = {10},
keywords = {Artificial Intelligence, Assessment, Computer Graphics, Computing Education, Evaluation, GPT-4, Large Language Models},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@article{10.1145/3680471,
author = {Russo, Daniel},
title = {Navigating the Complexity of Generative AI Adoption in Software Engineering—RCR Report},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {8},
issn = {1049-331X},
url = {https://doi.org/10.1145/3680471},
doi = {10.1145/3680471},
abstract = {This Replicated Computational Results (RCR) report complements the study “Navigating the Complexity of Generative AI Adoption in Software Engineering,” which examines the factors influencing the integration of AI tools in software engineering practices. Employing a mixed-methods approach grounded in the Technology Acceptance Model, Diffusion of Innovation Theory, and Social Cognitive Theory, the study introduces the Human-AI Collaboration and Adaptation Framework (HACAF), validated through PLS-SEM analysis. The replication package detailed herein includes survey instruments, raw data, and analysis scripts essential for reproducing the study's findings. By providing these artifacts, the RCR report aims to support transparency, enable replication, and encourage further research on effective AI tool adoption strategies in software engineering.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {221},
numpages = {5},
keywords = {Generative AI, Large Language Models, Technology Adaption, Empirical Software Engineering}
}

@inproceedings{10.1145/3644815.3644975,
author = {Jedrzejewski, Felix Viktor},
title = {Threat Modeling of ML-intensive Systems: Research Proposal},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644975},
doi = {10.1145/3644815.3644975},
abstract = {Context: The rise of Artificial Intelligence (AI) and Machine Learning (ML) applied in many software-intensive products and services introduces new opportunities but also new security challenges. Motivation: AI and ML will gain even more attention from industry in the future, but threats caused by already discovered attacks specifically targeting ML models are either overseen, ignored, or mishandled. Problem Statement: Current Software Engineering security practices and tools are insufficient to detect and mitigate ML Threats systematically. Contribution: We will develop and evaluate a threat modeling technique for non-security experts assessing ML-intensive systems in close collaboration with industry and academia.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {264–266},
numpages = {3},
keywords = {adversarial machine learning, threat modeling, industry},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3649217.3653584,
author = {Vadaparty, Annapurna and Zingaro, Daniel and Smith IV, David H. and Padala, Mounika and Alvarado, Christine and Gorson Benario, Jamie and Porter, Leo},
title = {CS1-LLM: Integrating LLMs into CS1 Instruction},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653584},
doi = {10.1145/3649217.3653584},
abstract = {The recent, widespread availability of Large Language Models (LLMs) like ChatGPT and GitHub Copilot may impact introductory programming courses (CS1) both in terms of what should be taught and how to teach it. Indeed, recent research has shown that LLMs are capable of solving the majority of the assignments and exams we previously used in CS1. In addition, professional software engineers are often using these tools, raising the question of whether we should be training our students in their use as well. This experience report describes a CS1 course at a large research-intensive university that fully embraces the use of LLMs from the beginning of the course. To incorporate the LLMs, the course was intentionally altered to reduce emphasis on syntax and writing code from scratch. Instead, the course now emphasizes skills needed to successfully produce software with an LLM. This includes explaining code, testing code, and decomposing large problems into small functions that are solvable by an LLM. In addition to frequent, formative assessments of these skills, students were given three large, open-ended projects in three separate domains (data science, image processing, and game design) that allowed them to showcase their creativity in topics of their choosing. In an end-of-term survey, students reported that they appreciated learning with the assistance of the LLM and that they interacted with the LLM in a variety of ways when writing code. We provide lessons learned for instructors who may wish to incorporate LLMs into their course.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {297–303},
numpages = {7},
keywords = {copilot, cs1, generative ai, introductory programming, llm},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3691620.3695058,
author = {Muttillo, Vittoriano and Di Sipio, Claudio and Rubei, Riccardo and Berardinelli, Luca and Dehghani, MohammadHadi},
title = {Towards Synthetic Trace Generation of Modeling Operations using In-Context Learning Approach},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695058},
doi = {10.1145/3691620.3695058},
abstract = {Producing accurate software models is crucial in model-driven software engineering (MDE). However, modeling complex systems is an error-prone task that requires deep application domain knowledge. In the past decade, several automated techniques have been proposed to support academic and industrial practitioners by providing relevant modeling operations. Nevertheless, those techniques require a huge amount of training data that cannot be available due to several factors, e.g., privacy issues. The advent of large language models (LLMs) can support the generation of synthetic data although state-of-the-art approaches are not yet supporting the generation of modeling operations. To fill the gap, we propose a conceptual framework that combines modeling event logs, intelligent modeling assistants, and the generation of modeling operations using LLMs. In particular, the architecture comprises modeling components that help the designer specify the system, record its operation within a graphical modeling environment, and automatically recommend relevant operations. In addition, we generate a completely new dataset of modeling events by telling on the most prominent LLMs currently available. As a proof of concept, we instantiate the proposed framework using a set of existing modeling tools employed in industrial use cases within different European projects. To assess the proposed methodology, we first evaluate the capability of the examined LLMs to generate realistic modeling operations by relying on well-founded distance metrics. Then, we evaluate the recommended operations by considering real-world industrial modeling artifacts. Our findings demonstrate that LLMs can generate modeling events even though the overall accuracy is higher when considering human-based operations. In this respect, we see generative AI tools as an alternative when the modeling operations are not available to train traditional IMAs specifically conceived to support industrial practitioners.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {619–630},
numpages = {12},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3643795.3648375,
author = {Grandel, Skyler and Schmidt, Douglas C. and Leach, Kevin},
title = {Applying Large Language Models to Enhance the Assessment of Parallel Functional Programming Assignments},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648375},
doi = {10.1145/3643795.3648375},
abstract = {Courses in computer science (CS) often assess student programming assignments manually, with the intent of providing in-depth feedback to each student regarding correctness, style, efficiency, and other quality attributes. As class sizes increase, however, it is hard to provide detailed feedback consistently, especially when multiple assessors are required to handle a larger number of assignment submissions. Large language models (LLMs), such as ChatGPT, offer a promising alternative to help automate this process in a consistent, scalable, and minimally-biased manner.This paper explores ChatGPT-4's scalablility and accuracy in assessing programming assignments based on predefined rubrics in the context of a case study we conducted in an upper-level undergraduate and graduate CS course at Vanderbilt University. In this case study, we employed a method that compared assessments generated by ChatGPT-4 against human graders to measure the accuracy, precision, and recall associated with identifying programming mistakes. Our results show that when ChatGPT-4 is used properly (e.g., with appropriate prompt engineering and feature selection) it can improve objectivity and grading efficiency, thereby acting as a complementary tool to human graders for advanced computer science graduate and undergraduate students.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {102–110},
numpages = {9},
keywords = {ChatGPT, education, generative AI, large language models, prompt engineering, automated grading},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3580305.3599199,
author = {Gaur, Manas and Tsamoura, Efthymia and Sreedharan, Sarath and Mittal, Sudip},
title = {KiL 2023 : 3rd International Workshop on Knowledge-infused Learning},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599199},
doi = {10.1145/3580305.3599199},
abstract = {Recent prolific advances in artificial intelligence through the incorporation of domain knowledge have constituted a new paradigm for AI and data mining communities. For example, the human feedback-based language generation in ChatGPT (a large language model (LLM)), the use of Protein Bank in DeepMind's AlphaFold, and the use of 23 rules of safety in DeepMind's Sparrow have demonstrated the success of teaming human knowledge and AI. In addition, the knowledge retrieval-guided language modeling methods have strengthened the association between knowledge and AI. However, translating research methods and resources into practice presents a new challenge for the machine learning and data/knowledge mining communities. For example, in DARPA's Explainable AI seminar, the need for explainable contextual adaptation is seen as the 3rd phase of AI, facilitating the interplay between data and knowledge for explainability, safety, and, eventually, trust. However, policymakers and practitioners assert serious usability and privacy concerns that constrain adoption, notably in high-consequence domains, such as cybersecurity, healthcare, and other social good domains. In addition, limitations in output quality, measurement, and interactive ability, including both the provision of explanations and the acceptance of user preferences, result in low adoption rates in such domains. This workshop aims to accelerate our pace towards creating innovative methods for integrating knowledge into contemporary AI and data science methods and develop metrics for assessing performance in various applications.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5857–5858},
numpages = {2},
keywords = {explainable ai, games, knowledge-infused learning, language models, neurosymbolic ai, programming languages, safe ai},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3674805.3690744,
author = {Steinmacher, Igor and Penney, Jacob Mcauley and Felizardo, Katia Romero and Garcia, Alessandro F. and Gerosa, Marco A.},
title = {Can ChatGPT emulate humans in software engineering surveys?},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690744},
doi = {10.1145/3674805.3690744},
abstract = {Context: There is a growing belief in the literature that large language models (LLMs), such as ChatGPT, can mimic human behavior in surveys. Gap: While the literature has shown promising results in social sciences and market research, there is scant evidence of its effectiveness in technical fields like software engineering. Objective: Inspired by previous work, this paper explores ChatGPT’s ability to replicate findings from prior software engineering research. Given the frequent use of surveys in this field, if LLMs can accurately emulate human responses, this technique could address common methodological challenges like recruitment difficulties, representational shortcomings, and respondent fatigue. Method: We prompted ChatGPT to reflect the behavior of a ‘mega-persona’ representing the demographic distribution of interest. We replicated surveys from 2019 to 2023 from leading SE conferences, examining ChatGPT’s proficiency in mimicking responses from diverse demographics. Results: Our findings reveal that ChatGPT can successfully replicate the outcomes of some studies, but in others, the results were not significantly better than a random baseline. Conclusions: This paper reports our results so far and discusses the challenges and potential research opportunities in leveraging LLMs for representing humans in software engineering surveys.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {414–419},
numpages = {6},
keywords = {Generative AI, Mega-Personas, Replication Study, Survey},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@proceedings{10.1145/3580305,
title = {KDD '23: Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining KDD 2023. This year's conference continues its tradition of being the premier forum for presentation of research results and experience reports on leading edge issues of knowledge discovery, data science, and machine learning. The mission of the conference is to provide the premier forum for advancement, education, and adoption of the "science" of knowledge discovery and machine learning from all types of data; to share novel methodologies that fulfill the needs of heterogeneous applications and environments and identify new directions for future research and development. These ideas have the potential to shape and impact our society and environment, and are becoming particularly important with the emergence of AI in all fields. KDD provides researchers and practitioners a unique opportunity to share their perspectives with others interested in various aspects of data science and machine learning.KDD '23 has a program of three keynotes, 313 research track papers, 184 ADS (Applied Data Science) track papers, 34 workshops, 33 tutorials, nine special days, three panels, and eight ADS invited talks. For the first time, we switched to OpenReview with the mission to further improve the review quality and facilitate the interaction between reviewers and authors. We have introduced several new special days, such as Large Language Model (LLM) Day, Finance Day, AI for Open Society Day, Entertainment, Sports, and Media (ESM) Day, Southern California Data Science; and several new panels, such as AI for Science and LLMs for education &amp; research. The rise of LLMs has been historic and the nature of creativity itself may change. With this in mind, we have emphasized LLMs in our keynotes, special days, and panels. Only time will tell whether we went too far or not far enough!},
location = {Long Beach, CA, USA}
}

@inproceedings{10.1145/3701625.3701687,
author = {Sampaio, Savio Sousa and Lima, M\'{a}rcia Sampaio and de Souza, Eriky Rodrigues and Meireles, Maria Alcimar and Pessoa, Marcela Savia and Conte, Tayana Uchoa},
title = {Exploring the Use of Large Language Models in Requirements Engineering Education: An Experience Report with ChatGPT 3.5},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701687},
doi = {10.1145/3701625.3701687},
abstract = {Large Language Models (LLMs) are becoming common in educational settings. This trend presents a challenge for teachers, who must focus on teaching the proper usage of LLMs. In the context of Software Engineering (SE), ChatGPT can support various software development tasks. This work reports an experience with students using ChatGPT 3.5 to support the Requirements Engineering (RE) phase. We conducted a two-phase study with 42 students. First, the students elicited requirements for systems using RE techniques. Then, the students used ChatGPT 3.5 to generate requirements for the same systems. Finally, they compared both sets of requirements based on equivalence, innovation, and relevance. On average, 65.26% of the requirements generated by ChatGPT were considered equivalents to the requirements the students had elicited. However, students reported that ChatGPT generates broad and non-specific requirements. Students also reported that ChatGPT 3.5 can foster the requirements elicitation, but it is necessary to establish well-defined prompts for generating requirements.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {624–634},
numpages = {11},
keywords = {Requirement Elicitation, ChatGPT 3.5, Software engineering education},
location = {
},
series = {SBQS '24}
}

@article{10.1145/3660767,
author = {Liang, Jenny T. and Badea, Carmen and Bird, Christian and DeLine, Robert and Ford, Denae and Forsgren, Nicole and Zimmermann, Thomas},
title = {Can GPT-4 Replicate Empirical Software Engineering Research?},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660767},
doi = {10.1145/3660767},
abstract = {Empirical software engineering research on production systems has brought forth a better understanding of the software engineering process for practitioners and researchers alike. However, only a small subset of production systems is studied, limiting the impact of this research. While software engineering practitioners could benefit from replicating research on their own data, this poses its own set of challenges, since performing replications requires a deep understanding of research methodologies and subtle nuances in software engineering data. Given that large language models (LLMs), such as GPT-4, show promise in tackling both software engineering- and science-related tasks, these models could help replicate and thus democratize empirical software engineering research.
 

 
In this paper, we examine GPT-4’s abilities to perform replications of empirical software engineering research on new data. We specifically study their ability to surface assumptions made in empirical software engineering research methodologies, as well as their ability to plan and generate code for analysis pipelines on seven empirical software engineering papers. We perform a user study with 14 participants with software engineering research expertise, who evaluate GPT-4-generated assumptions and analysis plans (i.e., a list of module specifications) from the papers. We find that GPT-4 is able to surface correct assumptions, but struggles to generate ones that apply common knowledge about software engineering data. In a manual analysis of the generated code, we find that the GPT-4-generated code contains correct high-level logic, given a subset of the methodology. However, the code contains many small implementation-level errors, reflecting a lack of software engineering knowledge. Our findings have implications for leveraging LLMs for software engineering research as well as practitioner data scientists in software teams.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {60},
numpages = {24},
keywords = {Large language models, empirical software engineering, study replication}
}

@inproceedings{10.1145/3632754.3633480,
author = {Paul, Soumen and Majumdar, Srijoni and Bandyopadhyay, Ayan and Dave, Bhargav and Chattopadhyay, Samiran and Das, Partha and Clough, Paul D and Majumder, Prasenjit},
title = {Efficiency of Large Language Models to scale up Ground Truth: Overview of the IRSE Track at Forum for Information Retrieval 2023},
year = {2024},
isbn = {9798400716324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632754.3633480},
doi = {10.1145/3632754.3633480},
abstract = {The Software Engineering Information Retrieval (IRSE) track aims to devise solutions for the automated evaluation of code comments within a machine learning framework, with labels generated by both humans and large language models. Within this track, there is a binary classification task: discerning comments as either useful or not useful. The dataset includes 9,048 pairs of code comments and surrounding code snippets drawn from open-source C-based projects on GitHub and an additional dataset generated by teams employing large language models. In total, 17 teams representing various universities and software companies have contributed 56 experiments. These experiments were assessed through quantitative metrics, primarily the F1-Score, and qualitative evaluations based on the features developed, the supervised learning models employed, and their respective hyperparameters. It is worth noting that labels generated by large language models introduce bias into the prediction model but lead to less over-fitted results.},
booktitle = {Proceedings of the 15th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {16–18},
numpages = {3},
keywords = {Abstract syntax tree, Bert, GPT-2, Neural networks, Stanford POS Tagging},
location = {Panjim, India},
series = {FIRE '23}
}

@inproceedings{10.1145/3626253.3635356,
author = {AlOmar, Eman Abdullah and Mkaouer, Mohamed Wiem},
title = {How can We Leverage Static Analysis and Large Language Models to Engage Students in Software Quality Improvement},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635356},
doi = {10.1145/3626253.3635356},
abstract = {Static analysis tools are frequently used to scan the source code and detect deviations from the project coding guidelines. Yet, their adoption is challenged by their high false positive rate, which makes them not suitable for students and novice developers. However, Large Language Models (LLMs), such as ChatGPT, have gained widespread popularity and usage in various software engineering tasks, including testing, code review, and program comprehension. Such models represent an opportunity to reduce the ambiguity of static analysis tools and support their adoption. Yet, the effectiveness of using static analysis (i.e., PMD) to detect coding issues, and relying on LLMs (i.e., ChatGPT) to explain and recommend fix, has not yet been explored. In this talk, we aim to shed light on our experience in teaching the use of ChatGPT to cultivate a bugfix culture and leverage LLMs to improve software quality in educational settings. We share our findings to support educators in teaching students better code review strategies, and to increase students' awareness about LLM and promote software quality in education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1930},
numpages = {1},
keywords = {computing, education, large language models, quality},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3627673.3679153,
author = {Zhang, Yanlin and Li, Ning and Gan, Quan and Zhang, Weinan and Wipf, David and Wang, Minjie},
title = {ELF-Gym: Evaluating Large Language Models Generated Features for Tabular Prediction},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679153},
doi = {10.1145/3627673.3679153},
abstract = {Crafting effective features is a crucial yet labor-intensive and domain-specific task within machine learning pipelines. Fortunately, recent advancements in Large Language Models (LLMs) have shown promise in automating various data science tasks, including feature engineering. But despite this potential, evaluations thus far are primarily based on the end performance of a complete ML pipeline, providing limited insight into precisely how LLMs behave relative to human experts in feature engineering. To address this gap, we propose ELF-Gym, a framework for Evaluating LLM-generated Features. We curated a new dataset from historical Kaggle competitions, including 251 golden features used by top-performing teams. ELF-Gym then quantitatively evaluates LLM-generated features by measuring their impact on downstream model performance as well as their alignment with expert-crafted features through semantic and functional similarity assessments. This approach provides a more comprehensive evaluation of disparities between LLMs and human experts, while offering valuable insights into specific areas where LLMs may have room for improvement. For example, using ELF-Gym we empirically demonstrate that, in the best-case scenario, LLMs can semantically capture approximately 56% of the golden features, but at the more demanding implementation level this overlap drops to 13%. Moreover, in other cases LLMs may fail completely, particularly on datasets that require complex features, indicating broad potential pathways for improvement.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5420–5424},
numpages = {5},
keywords = {data science, feature engineering, large language models},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.5555/3665609.3665632,
author = {Lopez, Carla and Messerle, Kyle and Malachowsky, Samuel and Krutz, Daniel E. and Cotler, Jami},
title = {Using the Accessible Learning Labs for Accessibility and Machine Learning Education --- Conference Tutorial},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {8},
issn = {1937-4771},
abstract = {Our Accessible Learning Labs (ALL) project informs participants about how to properly create accessible software and teaches participants about fundamental concepts of Artificial Intelligence and Machine Learning (AI/ML). To enhance readability, we will be using the abbreviation AI/ML to reference these concepts. These interactive learning modules demonstrate the need to create accessible software and provide hands-on experiences that showcase the multifaceted nature of AI's impact. This tutorial will benefit a wide-range of participants in the software engineering community, from students to experienced practitioners who want to further understand the implications of AI/ML in various domains and ensure that they are creating inclusive, accessible software. Complete project material is publicly available on the project website: https://all.rit.edu},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {207–209},
numpages = {3}
}

@inproceedings{10.1109/ASE56229.2023.00174,
author = {Suri, Samdyuti and Das, Sankar Narayan and Singi, Kapil and Dey, Kuntal and Sharma, Vibhu Saujanya and Kaulgud, Vikrant},
title = {Software Engineering Using Autonomous Agents: Are We There Yet?},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00174},
doi = {10.1109/ASE56229.2023.00174},
abstract = {Autonomous agents equipped with Large Language Models (LLMs) are rapidly gaining prominence as a revolutionary technology within the realm of Software Engineering. These intelligent and autonomous systems demonstrate the capacity to perform tasks and make independent decisions, leveraging their intrinsic reasoning and decision-making abilities.This paper delves into the current state of autonomous agents, their capabilities, challenges, and opportunities in Software Engineering practices. By employing different prompts (with or without context), we conclude the advantages of context-rich prompts for autonomous agents. Prompts with context enhance user requirement understanding, avoiding irrelevant details that could hinder task comprehension and degrade model performance, particularly when dealing with complex frameworks such as Spring Boot, Django, Flask, etc.This exploration is conducted using Auto-GPT (v0.3.0), an open-source application powered by GPT-3.5 and GPT-4 which intelligently connects the "thoughts" of Large Language Models (LLMs) to independently accomplish the assigned goals or tasks.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1855–1857},
numpages = {3},
keywords = {autonomous agents, large language models (LLMs), SDLC},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3545945.3569772,
author = {Ma, Ruizhe and Sanusi, Ismaila Temitayo and Mahipal, Vaishali and Gonzales, Joseph E. and Martin, Fred G.},
title = {Developing Machine Learning Algorithm Literacy with Novel Plugged and Unplugged Approaches},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569772},
doi = {10.1145/3545945.3569772},
abstract = {Data science and machine learning should not only be research areas for scientists and researchers but should also be accessible and understandable to the general audience. Enabling students to understand the details behind the technology will support them in becoming aware consumers and encourage them to become active participants. In this paper, we present instructional materials developed for introducing students to two key machine learning algorithms: decision trees and k-nearest neighbors. The materials were tested in a middle school's afterschool artificial intelligence program with four participating students aged 12 to 13. A combination of hands-on activities, innovative technology, and intuitive examples facilitated student learning. With hand-drawn decision trees and penguin species classifications, students used the algorithms to solve problems and anticipate other possible applications. We present the technology used, curriculum materials developed, and classroom structure. Following the guidelines from AI4K12 and introducing foundational machine learning algorithms, we hope to foster student interest in STEM fields.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {298–304},
numpages = {7},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3687123.3698286,
author = {Gramacki, Piotr and Martins, Bruno and Szyma\'{n}ski, Piotr},
title = {Evaluation of Code LLMs on Geospatial Code Generation},
year = {2024},
isbn = {9798400711763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687123.3698286},
doi = {10.1145/3687123.3698286},
abstract = {Software development support tools have been studied for a long time, with recent approaches using Large Language Models (LLMs) for code generation. These models can generate Python code for data science and machine learning applications. LLMs are helpful for software engineers because they increase productivity in daily work. An LLM can also serve as a "mentor" for inexperienced software developers, and be a viable learning support. High-quality code generation with LLMs can also be beneficial in geospatial data science. However, this domain poses different challenges, and code generation LLMs are typically not evaluated on geospatial tasks. Here, we show how we constructed an evaluation benchmark for code generation models, based on a selection of geospatial tasks. We categorised geospatial tasks based on their complexity and required tools. Then, we created a dataset with tasks that test model capabilities in spatial reasoning, spatial data processing, and geospatial tools usage. The dataset consists of specific coding problems that were manually created for high quality. For every problem, we proposed a set of test scenarios that make it possible to automatically check the generated code for correctness. In addition, we tested a selection of existing code generation LLMs for code generation in the geospatial domain. We share our dataset and reproducible evaluation code on a public GitHub repository1, arguing that this can serve as an evaluation benchmark for new LLMs in the future. Our dataset will hopefully contribute to the development new models capable of solving geospatial coding tasks with high accuracy. These models will enable the creation of coding assistants tailored for geospatial applications.},
booktitle = {Proceedings of the 7th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {54–62},
numpages = {9},
keywords = {code generation, geospatial data science, large language models},
location = {Atlanta, GA, USA},
series = {GeoAI '24}
}

@proceedings{10.1145/3548660,
title = {EASEAI 2022: Proceedings of the 4th International Workshop on Education through Advanced Software Engineering and Artificial Intelligence},
year = {2022},
isbn = {9781450394536},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the fourth edition of the International Workshop on Education through Advanced Software Engineering and Artificial Intelligence (EASEAI 2022) to be held virtually on November 18, 2022, as a post-conference workshop of ESEC/FSE 2022. 

 
The development and spread of digital technologies in an accelerated way has deeply affected not only everyday life, but also the educational system. The differences between generations of students are increasing and this presents more challenges for educators in terms of the act of teaching and learning. The EASEAI workshop addresses this challenge by looking at the research fields of software engineering, education, and artificial intelligence to explore how they can be combined. Specifically, this workshop brings together researchers, teachers, and practitioners using advanced software engineering tools and artificial intelligence techniques in education. They discuss the current state of the art and practices to establish new future directions with the aim of favoring efficient learning that will develop students the necessary skills for whatever profession the future will bring.},
location = {Singapore, Singapore}
}

@inproceedings{10.1145/3649165.3690101,
author = {Hellas, Arto and Leinonen, Juho and Lepp\"{a}nen, Leo},
title = {Experiences from Integrating Large Language Model Chatbots into the Classroom},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690101},
doi = {10.1145/3649165.3690101},
abstract = {We provided students access to a state-of-the-art large language model (LLM) chatbot through the online materials of three university-level courses. One of the courses focused on software engineering with LLMs, while the two other courses were not directly related to LLMs. The chatbot used OpenAI GPT-4 without additional filters or system prompts.  Our results suggest that only a minority of students engage with the chatbot in the courses that do not relate to LLMs. At the same time, unsurprisingly, nearly all students in the LLM-focused course leveraged the chatbot. In all courses, the majority of the chatbot usage came from a few superusers, whereas the majority of the students did not heavily use the chatbot even though it effectively provided free access to OpenAI's GPT-4 model (which would have otherwise required a paid subscription at the time of the study). We observe that in addition to students using the chatbot for course-specific purposes, many use the chatbot for their own purposes.  Overall, our results suggest that the worst fears of educators -- all students overrelying on chatbots -- did not materialize. Finally, we discuss potential reasons for low usage, including the need for more tailored and scaffolded chatbot experiences targeted for specific types of use cases.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {46–52},
numpages = {7},
keywords = {chatbots, classroom experiences, experience report, generative ai, large language models, usage analysis},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3661167.3661222,
author = {Mbaka, Winnie Bahati},
title = {New experimental design to capture bias using LLM to validate security threats},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661222},
doi = {10.1145/3661167.3661222},
abstract = {The usage of Large Language Models is already well understood in software engineering and security and privacy. Yet, little is known about the effectiveness of LLMs in threat validation or the possibility of biased output when assessing security threats for correctness. To mitigate this research gap, we present a pilot study investigating the effectiveness of chatGPT in the validation of security threats. One main observation made from the results was that chatGPT assessed bogus threats as realistic regardless of the assumptions provided which negated the feasibility of certain threats occurring.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {458–459},
numpages = {2},
keywords = {ChatGPT, Large Language Models, Security Threat Validation},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3639476.3639776,
author = {Rukmono, Satrio Adi and Ochoa, Lina and Chaudron, Michel},
title = {Deductive Software Architecture Recovery via Chain-of-thought Prompting},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639476.3639776},
doi = {10.1145/3639476.3639776},
abstract = {As software evolves, software architecture recovery techniques can help for effective maintenance. We envision a deductive software architecture recovery approach supported by Large Language Models (LLMs). Unlike existing inductive (bottom-up) recovery techniques, which reconstruct architecture by considering the properties observed at implementation level, our top-down approach starts with architectural properties and seeks their manifestations in the implementation. It employs a known Reference Architecture (RA) and involves two phases: RA definition and code units classification. A proof-of-concept with GPT-4 emulates deductive reasoning via chain-of-thought prompting. It demonstrates the deductive SAR approach, applying it to the Android application K-9 Mail and achieving a 70% accuracy in classifying 54 classes and 184 methods. The future plans focus on evaluating and refining the approach through ground-truth assessments, deeper exploration of reference architectures, and advancing toward automated human-like software architecture explanations. We highlight the potential for LLMs in achieving more comprehensive and explainable software architecture recovery.},
booktitle = {Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {92–96},
numpages = {5},
keywords = {software architecture, software architecture recovery, deductive SAR, chain-of-thought prompting},
location = {Lisbon, Portugal},
series = {ICSE-NIER'24}
}

@inproceedings{10.1145/3643660.3643942,
author = {Eisenreich, Tobias and Speth, Sandro and Wagner, Stefan},
title = {From Requirements to Architecture: An AI-Based Journey to Semi-Automatically Generate Software Architectures},
year = {2024},
isbn = {9798400705632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643660.3643942},
doi = {10.1145/3643660.3643942},
abstract = {Designing domain models and software architectures represents a significant challenge in software development, as the resulting architectures play a vital role in fulfilling the system's quality of service. Due to time pressure, architects often model only one architecture based on their known limited domain understanding, patterns, and experience instead of thoroughly analyzing the domain and evaluating multiple candidates, selecting the best fitting. Existing approaches try to generate domain models based on requirements, but still require time-consuming manual effort to achieve good results. Therefore, in this vision paper, we propose a method to generate software architecture candidates semi-automatically based on requirements using artificial intelligence techniques. We further envision an automatic evaluation and trade-off analysis of the generated architecture candidates using, e.g., the architecture trade-off analysis method combined with large language models and quantitative analyses. To evaluate this approach, we aim to analyze the quality of the generated architecture models and the efficiency and effectiveness of our proposed process by conducting qualitative studies.},
booktitle = {Proceedings of the 1st International Workshop on Designing Software},
pages = {52–55},
numpages = {4},
keywords = {requirements, software architecture, architecture evaluation, LLM},
location = {Lisbon, Portugal},
series = {Designing '24}
}

@inproceedings{10.1145/3650212.3652115,
author = {Zeng, Zhengran and Wang, Yidong and Xie, Rui and Ye, Wei and Zhang, Shikun},
title = {CoderUJB: An Executable and Unified Java Benchmark for Practical Programming Scenarios},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3652115},
doi = {10.1145/3650212.3652115},
abstract = {In the evolving landscape of large language models (LLMs) tailored for software engineering, the need for benchmarks that accurately reflect real-world development scenarios is paramount. Current benchmarks are either too simplistic or fail to capture the multi-tasking nature of software development. To address this, we introduce CoderUJB, a new benchmark designed to evaluate LLMs across diverse Java programming tasks that are executable and reflective of actual development scenarios, acknowledging Java's prevalence in real-world software production. CoderUJB comprises 2,239 programming questions derived from 17 real open-source Java projects and spans five practical programming tasks. Our empirical study on this benchmark investigates the coding abilities of various open-source and closed-source LLMs, examining the effects of continued pre-training in specific programming languages code and instruction fine-tuning on their performance. The findings indicate that while LLMs exhibit strong potential, challenges remain, particularly in non-functional code generation (e.g., test generation and defect detection). Importantly, our results advise caution in the specific programming languages continued pre-training and instruction fine-tuning, as these techniques could hinder model performance on certain tasks, suggesting the need for more nuanced strategies. CoderUJB thus marks a significant step towards more realistic evaluations of programming capabilities in LLMs, and our study provides valuable insights for the future development of these models in software engineering.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {124–136},
numpages = {13},
keywords = {Benchmark, Code Generation, Large Language Models},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3691620.3695066,
author = {Li, Guochang and Zhi, Chen and Chen, Jialiang and Han, Junxiao and Deng, Shuiguang},
title = {Exploring Parameter-Efficient Fine-Tuning of Large Language Model on Automated Program Repair},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695066},
doi = {10.1145/3691620.3695066},
abstract = {Automated Program Repair (APR) aims to fix bugs by generating patches. And existing work has demonstrated that "pre-training and fine-tuning" paradigm enables Large Language Models (LLMs) improve fixing capabilities on APR. However, existing work mainly focuses on Full-Model Fine-Tuning (FMFT) for APR and limited research has been conducted on the execution-based evaluation of Parameter-Efficient Fine-Tuning (PEFT) for APR. Comparing to FMFT, PEFT can reduce computing resource consumption without compromising performance and has been widely adopted to other software engineering tasks.To fill this gap, we enhance the existing APR dataset by employing prompt engineering to create an instruction dataset, APR-Instruction, at first. Secondly, we fine-tune four pre-trained LLMs using four different PEFT methods with APR-Instruction. The best fine-tuned model fixes 58% more bugs than the state-of-the-art LLM-based APR techniques. The results also show that (IA)3 improves the creativity of LLMs more effectively through fine-tuning and achieves the highest fixing capability compared to the other three PEFT methods. Thirdly, we explore the optimal configuration of PEFT hyperparameters, and assess the impact of instruction dataset size, showing that a larger number of parameters and a larger training dataset do not necessarily result in better performance for PEFT. Lastly, we analyze peak memory usage and trainable parameters to show the efficiency of PEFT.This work provides a comprehensive exploration of PEFT on APR and suggests potentially promising directions for extension to other software engineering downstream tasks. APR-Instruction, PEFT weights, and the fine-tuning code are publicly available as open-source resources.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {719–731},
numpages = {13},
keywords = {automated program repair, parameter-effective fine-tuning, large language model, execution-based evaluation},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3660650.3660668,
author = {Rajabi, Parsa},
title = {Experience Report: Adopting AI-Usage Policy in Software Engineering Education},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660668},
doi = {10.1145/3660650.3660668},
abstract = {This report examines the introduction of an AI-usage policy within a Software Engineering course, aiming to overcome the challenges of incorporating generative AI (genAI) tools in academic settings. As the debate around the impact of technologies like ChatGPT in education continues, this policy represents a proactive stance, addressing both the opportunities and risks associated with AI tool usage. With N=86 students, this course implemented a policy that promotes responsible AI use through guidelines and an "AI-usage disclosure" form for coursework submissions. This approach sought to improve AI literacy, ensure academic integrity, and mitigate potential academic misconduct cases. Despite challenges, including adherence to AI disclosures and the evolving definition of AI tools, the policy promoted a more inclusive learning environment and encouraged a deeper understanding of AI’s role and limitations in computer science education. The findings highlight the need for ongoing policy revisions to adapt to technological advancements, emphasizing the pilot as an essential step towards integrating AI responsibly in educational contexts.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {19},
numpages = {2},
keywords = {AI in Education, AI-usage Policy, Academic Integrity, ChatGPT, Software Engineering Education},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3643991.3644895,
author = {Storey, Margaret Anne D},
title = {Questioning the questions we ask about the impact of AI on software engineering},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644895},
doi = {10.1145/3643991.3644895},
abstract = {The recent advent and wide diffusion of generative AI has initiated a fundamental change in how software is developed. This technology is just one innovation along a long arc of disruptions in software engineering that include the internet, high-level programming languages, integrated development environments, open source, agile development, and social coding environments. Disruptive technologies such as these show the potential to augment and accelerate development activities along many socio-technical dimensions, while altering fundamental business processes and paradigms. Yet paradoxically, these innovations have the potential to eventually undermine the very advancements they seek to promote, rendering technologies and methods obsolete [1].When any new disruptive technology emerges, successful software companies that traditionally respond well to incremental innovations often fail when they suffer from inertia to change or don't anticipate how people will interact with the new technology. Similarly, researchers constrained by rigid research discipline can be slow to react, and may fail to recognize important and urgent societal and industrial needs. Researchers and companies alike may struggle in knowing which metrics to use and even how to measure the impact of change, further misleading their efforts to adapt.In this talk, I question the way we select research questions in software engineering and how we study them, particularly in the face of innovations such as generative AI. To provoke a change in our research, I introduce a disruptive playbook to steer us towards broader and more novel research directions. This step-by-step playbook is first illustrated by applying it to a prior disruptive technology, Stack Overflow. I will discuss how the playbook provides a new lens for reflecting on this body of research and how doing so reveals new insights. I then use the playbook, assisted with a customized research playbook GPT, to brainstorm and frame new research directions about the emerging disruptive innovations in software engineering that are being built on top of generative AI.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {530},
numpages = {1},
keywords = {software engineering, disruptive innovations, playbook, research questions},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3626252.3630832,
author = {Sakzad, Amin and Paul, David and Sheard, Judithe and Brankovic, Ljiljana and Skerritt, Matthew P. and Li, Nan and Minagar, Sepehr and Simon and Billingsley, William},
title = {Diverging assessments: What, Why, and Experiences},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630832},
doi = {10.1145/3626252.3630832},
abstract = {In this experience paper, we introduce the concept of 'diverging assessments', process-based assessments designed so that they become unique for each student while all students see a common skeleton. We present experiences with diverging assessments in the contexts of computer networks, operating systems, ethical hacking, and software development. All the given examples allow the use of generative-AI-based tools, are authentic, and are designed to generate learning opportunities that foster students' meta-cognition. Finally, we reflect upon these experiences in five different courses across four universities, showing how diverging assessments enhance students' learning while respecting academic integrity.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1161–1167},
numpages = {7},
keywords = {assessment-as-learning, authentic assessment, diverging assessment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3715602.3715612,
author = {Crandall, Johannah L. and Crandall, Aaron S.},
title = {Large Language Model-Supported Software Testing with the CS Matrix Taxonomy},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {New breakthroughs in code synthesis from Generative Pre-Trained Transformers (GPT) and Large Language Model (LLM) algorithms are driving significant changes to software engineering education. Having algorithms able to generate components of a software project means that software developers will need stronger skills in requirements specification to guide code generation as well as stronger skills in code review, testing, and integration to incorporate AI-generated code into projects. Shifts in industry and classroom practices are already occurring with the availability of inline code generation tools like GitHub's Copilot, which makes discussion of pedagogical strategies in this area a timely topic. Of immediate concern in computer science education is the potential for LLM-generated code and code help to undermine the learning of CS students. In order to avoid such undermining in even intentional uses of LLM-enhanced learning supports, it is necessary to clarify the roles such supports need to play in the pedagogical process. The Computer Science Matrix Taxonomy provides a strong framework for organizing software testing learning outcomes as well as delineating the operational space in which LLM-based feedback tools should operate to support those learning outcomes. In this paper, the authors operationalize the CS Matrix Taxonomy for software testing learning outcomes and illustrate the integration of LLM-generated test strategy suggestions as an extension of the peer coding/testing model. The work includes examples of AI-generated code testing suggestions that students would use to help guide their own code synthesis for assignments or projects.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {49–58},
numpages = {10}
}

@inproceedings{10.1109/ASE56229.2023.00096,
author = {Yan, Dapeng and Gao, Zhipeng and Liu, Zhiming},
title = {A Closer Look at Different Difficulty Levels Code Generation Abilities of ChatGPT},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00096},
doi = {10.1109/ASE56229.2023.00096},
abstract = {Code generation aims to generate source code implementing human requirements illustrated with natural language specifications. With the rapid development of intelligent software engineering, automated code generation has become a hot research topic in both artificial intelligence and software engineering, and researchers have made significant achievements on code generation. More recently, large language models (LLMs) have demonstrated outstanding performance on code generation tasks, such as ChatGPT released by OpenAI presents the fantastic potential on automated code generation. However, the existing studies are limited to exploring LLMs' ability for generating code snippets to solve simple programming problems, the task of competition-level code generation has never been investigated. The specifications of the programming competition are always complicated and require the specific input/output format as well as the high-level algorithmic reasoning ability. In this study, we conduct the first large empirical study to investigate the zero-shot learning ability of ChatGPT for solving competition programming problems. Specifically, we warm up the design of prompts by using the Human-Eval dataset. Then, we apply the well-designed prompt to the competition-level code generation dataset, namely APPS, to further explore the effectiveness of using ChatGPT for solving competition problems. We collect ChatGPT's outputs on 5,000 code competition problems, the evaluation results show that it can successfully pass 25.4% test cases. By further feeding extra information (e.g, test failed information) to ChatGPT, we observe that ChatGPT has the potential to fix partial pass into a fully pass program. Moreover, we investigate the solutions generated by LLMs and the existing solutions, we find that it prefers to directly copy the code instead of re-write when facing more difficult problems. Finally, we evaluate the code quality generated by ChatGPT in terms of "code cleanness", we observe that the generated codes are with small functions and file sizes, which are in line with the standard of clean code.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1887–1898},
numpages = {12},
keywords = {code generation, program competition, Chat-GPT, large language model, clean code},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3664476.3664497,
author = {Zhang, Xinyu and Muralee, Siddharth and Cherupattamoolayil, Sourag and Machiry, Aravind},
title = {On the Effectiveness of Large Language Models for GitHub Workflows},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3664497},
doi = {10.1145/3664476.3664497},
abstract = {GitHub workflows or GitHub CI is a popular continuous integration platform that enables developers to automate various software engineering tasks by specifying them as workflows,&nbsp;i.e., &nbsp;YAML files with a list of jobs. However, engineering valid workflows is tedious. They are also prone to severe security issues, which can result in supply chain vulnerabilities. Recent advancements in&nbsp;Large Language Models (LLMs) have demonstrated their effectiveness in various software development tasks. However,&nbsp;GitHub workflows differ from regular programs in both structure and semantics. We perform the first comprehensive study to understand the effectiveness of&nbsp;Large Language Models (LLMs) on five workflow-related tasks with different levels of prompts. We curated a set of ∼ 400K workflows and generated prompts with varying detail. We also fine-tuned&nbsp;LLMs on&nbsp;GitHub workflow tasks. Our evaluation of three state-of-the-art&nbsp;LLMs and their fine-tuned variants revealed various interesting findings on the current effectiveness and drawbacks of&nbsp;LLMs.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {32},
numpages = {14},
keywords = {GitHub Workflow, Large Language Model, Vulnerability Detection},
location = {Vienna, Austria},
series = {ARES '24}
}

@inproceedings{10.1145/3636243.3636249,
author = {Sheese, Brad and Liffiton, Mark and Savelka, Jaromir and Denny, Paul},
title = {Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636249},
doi = {10.1145/3636243.3636249},
abstract = {Providing personalized assistance at scale is a long-standing challenge for computing educators, but a new generation of tools powered by large language models (LLMs) offers immense promise. Such tools can, in theory, provide on-demand help in large class settings and be configured with appropriate guardrails to prevent misuse and mitigate common concerns around learner over-reliance. However, the deployment of LLM-powered tools in authentic classroom settings is still rare, and very little is currently known about how students will use them in practice and what type of help they will seek. To address this, we examine students’ use of an innovative LLM-powered tool that provides on-demand programming assistance without revealing solutions directly. We deployed the tool for 12 weeks in an introductory computer and data science course&nbsp;(n = 52), collecting more than 2,500 queries submitted by students throughout the term. We manually categorized all student queries based on the type of assistance sought, and we automatically analyzed several additional query characteristics. We found that most queries requested immediate help with programming assignments, whereas fewer requests asked for help on related concepts or for deepening conceptual understanding. Furthermore, students often provided minimal information to the tool, suggesting this is an area in which targeted instruction would be beneficial. We also found that students who achieved more success in the course tended to have used the tool more frequently overall. Lessons from this research can be leveraged by programming educators and institutions who plan to augment their teaching with emerging LLM-powered tools.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {49–57},
numpages = {9},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@article{10.1145/3631504.3631518,
author = {Amer-Yahia, Sihem and Bonifati, Angela and Chen, Lei and Li, Guoliang and Shim, Kyuseok and Xu, Jianliang and Yang, Xiaochun},
title = {From Large Language Models to Databases and Back: A Discussion on Research and Education},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0163-5808},
url = {https://doi.org/10.1145/3631504.3631518},
doi = {10.1145/3631504.3631518},
abstract = {In recent years, large language models (LLMs) have garnered increasing attention from both academia and industry due to their potential to facilitate natural language processing (NLP) and generate highquality text. Despite their benefits, however, the use of LLMs is raising concerns about the reliability of knowledge extraction. The combination of DB research and data science has advanced the state of the art in solving real-world problems, such as merchandise recommendation and hazard prevention [30]. In this discussion, we explore the challenges and opportunities related to LLMs in DB and data science research and education.},
journal = {SIGMOD Rec.},
month = nov,
pages = {49–56},
numpages = {8}
}

@inproceedings{10.1145/3643479.3662055,
author = {Bui, Tuan and Tran, Oanh and Nguyen, Phuong and Ho, Bao and Nguyen, Long and Bui, Thang and Quan, Tho},
title = {Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering System: A Case Study at HCMUT},
year = {2024},
isbn = {9798400705472},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643479.3662055},
doi = {10.1145/3643479.3662055},
abstract = {In today's rapidly evolving landscape of Artificial Intelligence, large language models (LLMs) have emerged as a vibrant research topic. LLMs find applications in various fields and contribute significantly. Despite their powerful language capabilities, similar to pre-trained language models (PLMs), LLMs still face challenges in remembering events, incorporating new information, and addressing domain-specific issues or hallucinations. To overcome these limitations, researchers have proposed Retrieval-Augmented Generation (RAG) techniques, some others have proposed the integration of LLMs with Knowledge Graphs (KGs) to provide factual context, thereby improving performance and delivering more accurate feedback to user queries.Education plays a crucial role in human development and progress. With the technology transformation, traditional education is being replaced by digital or blended education. Therefore, educational data in the digital environment is increasing day by day. Data in higher education institutions are diverse, comprising various sources such as unstructured/structured text, relational databases, web/app-based API access, etc. Constructing a Knowledge Graph from these cross-data sources is not a simple task. This article proposes a method for automatically constructing a Knowledge Graph from multiple data sources and discusses some initial applications (experimental trials) of KG in conjunction with LLMs for question-answering tasks.},
booktitle = {Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia},
pages = {36–43},
numpages = {8},
keywords = {Education, Knowledge Graph, Large language model, Open Intent Discovery, Question-Answering System},
location = {Phuket, Thailand},
series = {AIQAM '24}
}

@article{10.1145/3660809,
author = {Oueslati, Khouloud and Laberge, Gabriel and Lamothe, Maxime and Khomh, Foutse},
title = {Mining Action Rules for Defect Reduction Planning},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660809},
doi = {10.1145/3660809},
abstract = {Defect reduction planning plays a vital role in enhancing software quality and minimizing software maintenance costs. By training a black box machine learning model and “explaining” its predictions, explainable AI for software engineering aims to identify the code characteristics that impact maintenance risks. However, post-hoc explanations do not always faithfully reflect what the original model computes. In this paper, we introduce CounterACT, a Counterfactual ACTion rule mining approach that can generate defect reduction plans without black-box models. By leveraging action rules, CounterACT provides a course of action that can be considered as a counterfactual explanation for the class (e.g., buggy or not buggy) assigned to a piece of code. We compare the effectiveness of CounterACT with the original action rule mining algorithm and six established defect reduction approaches on 9 software projects. Our evaluation is based on (a) overlap scores between proposed code changes and actual developer modifications; (b) improvement scores in future releases; and (c) the precision, recall, and F1-score of the plans. Our results show that, compared to competing approaches, CounterACT’s explainable plans achieve higher overlap scores at the release level (median 95%) and commit level (median 85.97%), and they offer better trade-off between precision and recall (median F1-score 88.12%). Finally, we venture beyond planning and explore leveraging Large Language models (LLM) for generating code edits from our generated plans. Our results show that suggested LLM code edits supported by our plans are actionable and are more likely to pass relevant test cases than vanilla LLM code recommendations.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {102},
numpages = {23},
keywords = {Action rule mining, Counterfactual explanations, Defect reduction planning, Explainability, Software analytics}
}

@inproceedings{10.1145/3611643.3613093,
author = {Cabra-Acela, Laura and Mojica-Hanke, Anamaria and Linares-V\'{a}squez, Mario and Herbold, Steffen},
title = {On Using Information Retrieval to Recommend Machine Learning Good Practices for Software Engineers},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613093},
doi = {10.1145/3611643.3613093},
abstract = {Machine learning (ML) is nowadays widely used for different purposes and with several disciplines. From self-driving cars to automated medical diagnosis, machine learning models extensively support users’ daily activities, and software engineering tasks are no exception. Not embracing good ML practices may lead to pitfalls that hinder the performance of an ML system and potentially lead to unexpected results. Despite the existence of documentation and literature about ML best practices, many non-ML experts turn towards gray literature like blogs and Q&amp;A systems when looking for help and guidance when implementing ML systems. To better aid users in distilling relevant knowledge from such sources, we propose a recommender system that recommends ML practices based on the user’s context. As a first step in creating a recommender system for machine learning practices, we implemented Idaka. A tool that provides two different approaches for retrieving/generating ML best practices: i) an information retrieval (IR) engine and ii) a large language model. The IR-engine uses BM25 as the algorithm for retrieving the practices, and a large language model, in our case Alpaca. The platform has been designed to allow comparative studies of best practices retrieval tools. Idaka is publicly available at  GitHub: https://bit.ly/idaka. Video: https://youtu.be/cEb-AhIPxnM},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {2142–2146},
numpages = {5},
keywords = {Good practices, Information retrieval, Large language models, Machine learning},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3661167.3661202,
author = {De Vito, Gabriele},
title = {Assessing healthcare software built using IoT and LLM technologies},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661202},
doi = {10.1145/3661167.3661202},
abstract = {In the fast-paced world of healthcare technology, combining IoT devices with large language models (LLMs) offers a promising path to transform Clinical Decision-Support Systems (CDSS). This Ph.D. project is designed to tap into IoT’s extensive data collection ability and LLMs’ superior natural language processing skills. It aims to improve clinical decision-making and patient care through a sophisticated DSS that utilizes both technologies’ strengths. The project delves into the software engineering challenges and methodologies required to build an effective DSS. It investigates how to smoothly evaluate and integrate IoT and LLMs into healthcare environments, tackling significant issues like data complexity, privacy concerns, and the necessity for high accuracy in medical settings. It underscores the critical role of thorough evaluation and assessment in developing healthcare technologies.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {476–481},
numpages = {6},
keywords = {Clinical Decision Support System, Healthcare Software Assessment, Large Language Models},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3633053.3633057,
author = {Petrovska, Olga and Clift, Lee and Moller, Faron and Pearsall, Rebecca},
title = {Incorporating Generative AI into Software Development Education},
year = {2024},
isbn = {9798400709326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633053.3633057},
doi = {10.1145/3633053.3633057},
abstract = {This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools “doing the homework”.},
booktitle = {Proceedings of the 8th Conference on Computing Education Practice},
pages = {37–40},
numpages = {4},
keywords = {apprenticeship, assessment, education, generative AI, software engineering},
location = {Durham, United Kingdom},
series = {CEP '24}
}

@article{10.1145/3660788,
author = {Khojah, Ranim and Mohamad, Mazen and Leitner, Philipp and de Oliveira Neto, Francisco Gomes},
title = {Beyond Code Generation: An Observational Study of ChatGPT Usage in Software Engineering Practice},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660788},
doi = {10.1145/3660788},
abstract = {Large Language Models (LLMs) are frequently discussed in academia and the general public as support tools for virtually any use case that relies on the production of text, including software engineering. Currently, there is much debate, but little empirical evidence, regarding the practical usefulness of LLM-based tools such as ChatGPT for engineers in industry. We conduct an observational study of 24 professional software engineers who have been using ChatGPT over a period of one week in their jobs, and qualitatively analyse their dialogues with the chatbot as well as their overall experience (as captured by an exit survey). We find that rather than expecting ChatGPT to generate ready-to-use software artifacts (e.g., code), practitioners more often use ChatGPT to receive guidance on how to solve their tasks or learn about a topic in more abstract terms. We also propose a theoretical framework for how the (i) purpose of the interaction, (ii) internal factors (e.g., the user's personality), and (iii) external factors (e.g., company policy) together shape the experience (in terms of perceived usefulness and trust). We envision that our framework can be used by future research to further the academic discussion on LLM usage by software engineering practitioners, and to serve as a reference point for the design of future empirical LLM research in this domain.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {81},
numpages = {22},
keywords = {Chatbots, Large Language Models (LLMs), Software Development Bots}
}

@inproceedings{10.1145/3639478.3643060,
author = {H. Fard, Fatemeh},
title = {Technical Briefing on Parameter Efficient Fine-Tuning of (Large) Language Models for Code-Intelligence},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3643060},
doi = {10.1145/3639478.3643060},
abstract = {Large Language Models (LLMs) have gained much attention in the Software Engineering (SE) community, specifically for code-related tasks. Though a common approach is to fine-tune these models fully, it is a computationally heavy and time-consuming process that is not accessible to all. More importantly, with billions of parameters in the models, fully fine-tuning them for new tasks or domains is infeasible or inefficient. This technical briefing covers the alternative approach -Parameter Efficient Fine Tuning (PEFT), discussing the state-of-the-art techniques and reflecting on the few studies of using PEFT in Software Engineering and how changing the current PEFT architectures in natural language processing could enhance the performance for code-related tasks.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {434–435},
numpages = {2},
keywords = {parameter efficient fine tuning, code language models, large language models},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3636555.3636853,
author = {Singh, Anjali and Brooks, Christopher and Wang, Xu and Li, Warren and Kim, Juho and Wilson, Deepti},
title = {Bridging Learnersourcing and AI: Exploring the Dynamics of Student-AI Collaborative Feedback Generation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636853},
doi = {10.1145/3636555.3636853},
abstract = {This paper explores the space of optimizing feedback mechanisms in complex domains such as data science, by combining two prevailing approaches: Artificial Intelligence (AI) and learnersourcing. Towards addressing the challenges posed by each approach, this work compares traditional learnersourcing with an AI-supported approach. We report on the results of a randomized controlled experiment conducted with 72 Master’s level students in a data visualization course, comparing two conditions: students writing hints independently versus revising hints generated by GPT-4. The study aimed to evaluate the quality of learnersourced hints, examine the impact of student performance on hint quality, gauge learner preference for writing hints with versus without AI support, and explore the potential of the student-AI collaborative exercise in fostering critical thinking about LLMs. Based on our findings, we provide insights for designing learnersourcing activities leveraging AI support and optimizing students’ learning as they interact with LLMs.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {742–748},
numpages = {7},
keywords = {Data Visualization, Feedback Generation, GPT-4, Learnersourcing},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3495018.3495332,
author = {Duan, Yuanpeng and Gong, Weixin},
title = {Constructing the Mode of "Four-in-One" Software Engineering Master Training Based on Artificial Intelligence},
year = {2022},
isbn = {9781450385046},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3495018.3495332},
doi = {10.1145/3495018.3495332},
abstract = {Building a "Four-in-One" software engineering master's cultivation model based on artificial intelligence is an inevitable requirement of the development of the times and the realization of industrial development. However, due to the outdated cultivation mode of the Master of Artificial Intelligence Software Engineering, there are few or no courses related to artificial intelligence in terms of curriculum setting, and the textbooks are not updated in time, which makes students lack of grasp of cutting-edge knowledge and scientific research methods. In terms of scientific research practice, it is simple in form and low in technology content, which leads to the insufficiency of students' comprehensive engineering application ability, and becomes the bottleneck of the cultivation of senior talents in software engineering under the background of artificial intelligence. With four modules of scientific selection system, multi-module curriculum system, practical training system and school-enterprise cooperation mechanism, the "Four-in-One" training mode is constructed to cultivate high-level, open, compound and international software talents.},
booktitle = {2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture},
pages = {1047–1050},
numpages = {4},
location = {Manchester, United Kingdom},
series = {AIAM2021}
}

@inproceedings{10.1145/3674805.3690743,
author = {Felizardo, Katia Romero and Steinmacher, Igor and Lima, M\'{a}rcia Sampaio and Deizepe, Anderson and Conte, Tayana Uch\^{o}a and Barcellos, Monalessa Perini},
title = {Data extraction for systematic mapping study using a large language model - a proof-of-concept study in software engineering},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690743},
doi = {10.1145/3674805.3690743},
abstract = {Context: Systematic mapping studies (SMS) are adopted in Software Engineering (SE) to select and synthesize relevant literature on a research topic and, thus, support evidence-based decision-making. Performing SMS is effort-demanding and time-consuming. Hence, using tools is beneficial. Large Language Models (LLMs) such as ChatGPT–4.o can potentially accelerate repetitive activities, such as data extraction in SMS, saving time and effort. Goal: We conducted this work to evaluate and provide preliminary evidence on how ChatGPT–4.o can support data extraction in SMS. Method: We performed a proof-of-concept study and assessed the results’ accuracy of using ChatGPT 4.0 to extract data in one SMS compared to the results produced manually. Results: The accuracy of ChatGPT–4.o was 87.83%. Conclusions: Our preliminary findings suggest that entirely replacing the manual data extraction with ChatGPT–4.o is not recommended. However, employing ChatGPT for semi-automated data extraction to aid in evidence synthesis in SMS is promising.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {407–413},
numpages = {7},
keywords = {ChatGPT, Data Extraction, LLM, Mapping Study},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3657604.3664714,
author = {Arif, Taimoor and Asthana, Sumit and Collins-Thompson, Kevyn},
title = {Generation and Assessment of Multiple-Choice Questions from Video Transcripts using Large Language Models},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664714},
doi = {10.1145/3657604.3664714},
abstract = {We present an empirical study evaluating the quality of multiple-choice questions (MCQs) generated by Large Language Models (LLMs) from a corpus of video transcripts of course lectures in an online data science degree program. With our database of thousands of generated questions, we conducted both human and automated judging of question quality on a representative sample using a broad set of criteria, including well-established Item Writing Flaw (IWF) categories. We found the number of average IWFs per MCQ ranged from 1.6 (rule-based verification) to 2.18 (LLM-based). Among the most frequently identified MCQ flaws were lack of enough context (17%) or answer choices with at least one implausible distractor (57%). Both human and automated assessment identified implausible distractors as one of the most frequent flaw categories. Results from our human annotation study were generally more positive (51--65% good items) compared to our automated assessment study results, which tended toward greater flaw identification (15--25% good items), depending on evaluation method.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {530–534},
numpages = {5},
keywords = {educational video, large language models, question generation},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3545947.3569630,
author = {MacNeil, Stephen and Tran, Andrew and Leinonen, Juho and Denny, Paul and Kim, Joanne and Hellas, Arto and Bernstein, Seth and Sarsa, Sami},
title = {Automatically Generating CS Learning Materials with Large Language Models},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3569630},
doi = {10.1145/3545947.3569630},
abstract = {Recent breakthroughs in Large Language Models (LLMs), such as GPT-3 and Codex, now enable software developers to generate code based on a natural language prompt. Within computer science education, researchers are exploring the potential for LLMs to generate code explanations and programming assignments using carefully crafted prompts. These advances may enable students to interact with code in new ways while helping instructors scale their learning materials. However, LLMs also introduce new implications for academic integrity, curriculum design, and software engineering careers. This workshop will demonstrate the capabilities of LLMs to help attendees evaluate whether and how LLMs might be integrated into their pedagogy and research. We will also engage attendees in brainstorming to consider how LLMs will impact our field.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1176},
numpages = {1},
keywords = {code generation, computer science education, copilot, explanations, large language models},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3564721.3565946,
author = {Redmond, Fiona},
title = {With a Rise in Computing Disciplines Comes a Greater Choice of Computing Degrees in Higher Education},
year = {2022},
isbn = {9781450396165},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3564721.3565946},
doi = {10.1145/3564721.3565946},
abstract = {Higher education institutions (HEIs) internationally are increasingly recognising the importance of understanding student study choices. This is especially true in the field of computing in which skills shortages in the labour market are high but so too are student dropout rates. Loss of interest in the computing field has been reported among the reasons for students dropping out. The aim of this study is to offer a fresh perspective of the factors influencing undergraduate student’s interest and choice of specialisation in computing. Previous studies have mainly focused on five ACM-identified computing disciplines: Computer Science, Information Systems, Information Technology, Computer Engineering and Software Engineering. With the ever-growing nature of computing, two more disciplines recently emerged: Cybersecurity and Data Science. HEIs continuously endeavour to expand computing programmes into specialist areas within these disciplines such as machine learning, artificial intelligence, gaming, robotics and creative computing. For prospective students, this maze of options can make for a difficult decision. 137 first-year computing students were invited to participate in a mixed-methods survey to explore their choices around cybersecurity and other newer specialisations. The results of the survey were matched with findings from recent literature, and show that personal interest, family, media, career prospects and prior experiences still influence student choices, with media appearing to have a greater impact compared to earlier studies. HEIs can use this when developing effective recruitment strategies in computing.},
booktitle = {Proceedings of the 22nd Koli Calling International Conference on Computing Education Research},
articleno = {5},
numpages = {11},
keywords = {computing, computing education, disciplines, specialisations, student choices},
location = {Koli, Finland},
series = {Koli Calling '22}
}

@inproceedings{10.1145/3650212.3680328,
author = {Yang, Boyang and Tian, Haoye and Pian, Weiguo and Yu, Haoran and Wang, Haitao and Klein, Jacques and Bissyand\'{e}, Tegawend\'{e} F. and Jin, Shunfu},
title = {CREF: An LLM-Based Conversational Software Repair Framework for Programming Tutors},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680328},
doi = {10.1145/3650212.3680328},
abstract = {With the proven effectiveness of Large Language Models (LLMs) in code-related tasks, researchers have explored their potential for program repair. However, existing repair benchmarks might have influenced LLM training data, potentially causing data leakage. To evaluate LLMs’ realistic repair capabilities, (i) we introduce an extensive, non-crawled benchmark TutorCode, comprising 1,239 C++ defect codes and associated information such as tutor guidance, solution description, failing test cases, and the corrected code. Our work assesses LLM’s repair performance on TutorCode, measuring repair correctness (TOP-5 and AVG-5) and patch precision (RPSR). (ii) We then provide a comprehensive investigation into which types of extra information can help LLMs improve their repair performance. Among these types, tutor guidance was the most effective information. To fully harness LLMs’ conversational capabilities and the benefits of augmented information, (iii) we introduce a novel conversational semi-automatic repair framework CREF assisting human programming tutors. It demonstrates a remarkable AVG-5 improvement of 17.2%-24.6% compared to the baseline, achieving an impressive AVG-5 of 76.6% when utilizing GPT-4. These results highlight the potential for enhancing LLMs’ repair capabilities through tutor interactions and historical conversations. The successful application of CREF in a real-world educational setting demonstrates its effectiveness in reducing tutors’ workload and improving students’ learning experience, showing promise for code review and other software engineering tasks.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {882–894},
numpages = {13},
keywords = {Large Language Model, Open Source, Program Repair},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1109/ASE56229.2023.00010,
author = {Das, Debeshee and Mathews, Noble Saji and Mathai, Alex and Tamilselvam, Srikanth and Sedamaki, Kranthi and Chimalakonda, Sridhar and Kumar, Atul},
title = {COMEX: A Tool for Generating Customized Source Code Representations},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00010},
doi = {10.1109/ASE56229.2023.00010},
abstract = {Learning effective representations of source code is critical for any Machine Learning for Software Engineering (ML4SE) system. Inspired by natural language processing, large language models (LLMs) like Codex and CodeGen treat code as generic sequences of text and are trained on huge corpora of code data, achieving state of the art performance on several software engineering (SE) tasks. However, valid source code, unlike natural language, follows a strict structure and pattern governed by the underlying grammar of the programming language. Current LLMs do not exploit this property of the source code as they treat code like a sequence of tokens and overlook key structural and semantic properties of code that can be extracted from code-views like the Control Flow Graph (CFG), Data Flow Graph (DFG), Abstract Syntax Tree (AST), etc. Unfortunately, the process of generating and integrating code-views for every programming language is cumbersome and time consuming. To overcome this barrier, we propose our tool COMEX - a framework that allows researchers and developers to create and combine multiple code-views which can be used by machine learning (ML) models for various SE tasks. Some salient features of our tool are: (i) it works directly on source code (which need not be compilable), (ii) it currently supports Java and C#, (iii) it can analyze both method-level snippets and program-level snippets by using both intra-procedural and inter-procedural analysis, and (iv) it is easily extendable to other languages as it is built on tree-sitter - a widely used incremental parser that supports over 40 languages. We believe this easy-to-use code-view generation and customization tool will give impetus to research in source code representation learning methods and ML4SE. The source code and demonstration of our tool can be found at https://github.com/IBM/tree-sitter-codeviews and https://youtu.be/GER6U87FVbU, respectively.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2054–2057},
numpages = {4},
keywords = {representation learning, static analysis},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3650105.3652288,
author = {Venkatesh, Ashwin Prasad Shivarpatna and Sabu, Samkutty and Mir, Amir M. and Reis, Sofia and Bodden, Eric},
title = {The Emergence of Large Language Models in Static Analysis: A First Look through Micro-Benchmarks},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650105.3652288},
doi = {10.1145/3650105.3652288},
abstract = {The application of Large Language Models (LLMs) in software engineering, particularly in static analysis tasks, represents a paradigm shift in the field. In this paper, we investigate the role that current LLMs can play in improving callgraph analysis and type inference for Python programs. Using the PyCG, HeaderGen, and TypeEvalPy micro-benchmarks, we evaluate 26 LLMs, including OpenAI's GPT series and open-source models such as LLaMA. Our study reveals that LLMs show promising results in type inference, demonstrating higher accuracy than traditional methods, yet they exhibit limitations in callgraph analysis. This contrast emphasizes the need for specialized fine-tuning of LLMs to better suit specific static analysis tasks. Our findings provide a foundation for further research towards integrating LLMs for static analysis tasks.},
booktitle = {Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
pages = {35–39},
numpages = {5},
location = {Lisbon, Portugal},
series = {FORGE '24}
}

@inproceedings{10.1145/3578527.3581749,
author = {Tiwari, Saurabh and Farooq, Sheikh Umar and Rathore, Santosh Singh},
title = {A Report on the Fifth Workshop on Emerging Software Engineering Education (WESEE 2023)},
year = {2023},
isbn = {9798400700644},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578527.3581749},
doi = {10.1145/3578527.3581749},
abstract = {In this report, we present a pre-organization summary of the fifth workshop on emerging software engineering education (WESEE) to be held on February 23, 2023, co-located with the 16th Innovations in Software Engineering Conference (ISEC 2023), February 23–25, 2023. The 5th edition of WESEE, a half-day workshop, focuses on open discussions and brainstorming sessions on software engineering education. The workshop will discuss “Artificial Intelligence (AI), Human Flourishing, Learning Goals, Collaboration in Software Engineering (SE)". The workshop consists of two invited talks, one hands-on activity, and an open-ended concluding discussion session. The academic faculty members, students (UG &amp; PG), researchers working in SE education, and industry practitioners can attend the workshop.},
booktitle = {Proceedings of the 16th Innovations in Software Engineering Conference},
articleno = {28},
numpages = {2},
keywords = {Software engineering education, computer science training, teaching software development},
location = {Allahabad, India},
series = {ISEC '23}
}

@inproceedings{10.1145/3661167.3661269,
author = {Harman, Mark},
title = {The Role of Software Measurement in Assured LLM-Based Software Engineering},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661269},
doi = {10.1145/3661167.3661269},
abstract = {Assured Large Language Model Software Engineering (Assured LLMSE) addresses the twin challenges: 1. Ensuring LLM-generated code does not regress the properties of the original code 2. Quantifying the improvement over the original archived by the improve code in a verifiable and measurable way. In so doing, the Assured LLMSE approach tackles the problem of LLMs’ tendency to hallucinate, as well as providing confidence that generated code improves an existing code base. Software testing and measurement play critical roles in this improvement process: testing is the guard against regression, while measurement provides the quantifiable assurance of improvement. Assured LLMSE takes its inspiration from previous work on genetic improvement, for which software measurement also plays a central role. In this keynote we outline the Assured LLMSE approach, highlighting the role of software measurement in the provision of quantifiable, verifiable assurances for code that originates from LLM–based inference. This paper is an outline of the content of the keynote by Mark Harman at the 28th International Conference on Evaluation and Assessment in Software Engineering.  This is joint work with Nadia Alshahwan, Andrea Aquino, Jubin Chheda, Anastasia Finegenova, Inna Harper, Mitya Lyubarskiy, Neil Maiden, Alexander Mols, Shubho Sengupta, Rotem Tal, Alexandru Marginean, and Eddy Wang.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {4},
numpages = {1},
keywords = {Automated Code Generation, CodeLlama, Genetic Improvement (GI), Large Language Models (LLMs), Llama, Search Based Software Engineering (SBSE)},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3691620.3695336,
author = {Cinkusz, Konrad and Chudziak, Jaroslaw A.},
title = {Towards LLM-augmented multiagent systems for agile software engineering},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695336},
doi = {10.1145/3691620.3695336},
abstract = {A cognitive multi-agent ecosystem designed for efficient software engineering using Agile methodologies can significantly improve software development processes. Key components include the integration of Multi-Agent Systems (MAS) and Large Language Models (LLMs), utilizing Dynamic Context techniques for agent profiling, and Theory of Mind to enhance collaboration. The CogniSim Ecosystem analyzes problems, proposes solutions, constructs and validates plans, and coordinates specialized agents playing roles such as developers, executors, quality checkers, and methodology reviewers. These agents produce documentation, models, and diagrams (e.g., UML) while adhering to predefined quality and performance measures. The ecosystem also simulates the impact of various team configurations on problem-solving effectiveness, helping organizations identify optimal team structures. Case studies and simulations demonstrate its practical applications.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2476–2477},
numpages = {2},
keywords = {multi-agent systems, large language models, software engineering, collaboration automation, methodologies, SAFe, cognisim},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3593663.3593695,
author = {Dobslaw, Felix and Bergh, Peter},
title = {Experiences with Remote Examination Formats in Light of GPT-4},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593663.3593695},
doi = {10.1145/3593663.3593695},
abstract = {Sudden access to the rapidly improving large language model GPT by OpenAI forces educational institutions worldwide to revisit their exam procedures. In the pre-GPT era, we successfully applied oral and open-book home exams for two courses in the third year of our predominantly remote Software Engineering BSc program. We ask in this paper whether our current open-book exams are still viable or whether a move back to a legally compliant but less scalable oral exam is the only workable alternative. We further compare work-effort estimates between oral and open-book exams and report on differences in throughput and grade distribution over eight years to better understand the impact of examination format on the outcome. Examining GPT-4 on the most recent open-book exams showed that our current Artificial Intelligence and Reactive Programming exams are not GPT v4 proof. Three potential weaknesses of GPT are outlined. We also found that grade distributions have largely been unaffected by the examination format, opening up for a move to oral examinations only if needed. Throughput was higher for open-book exam course instances (73% vs 64%), while fail rates were too (12% vs 7%), with teacher workload increasing even for smaller classes. We also report on our experience regarding effort. Oral examinations are efficient for smaller groups but come with caveats regarding intensity and stress.},
booktitle = {Proceedings of the 5th European Conference on Software Engineering Education},
pages = {220–225},
numpages = {6},
keywords = {ChatGPT, Examination Formats, Oral Examinations, Software Engineering Education},
location = {Seeon/Bavaria, Germany},
series = {ECSEE '23}
}

@inproceedings{10.1145/3597503.3639201,
author = {Choudhuri, Rudrajit and Liu, Dylan and Steinmacher, Igor and Gerosa, Marco and Sarma, Anita},
title = {How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639201},
doi = {10.1145/3597503.3639201},
abstract = {Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {184},
numpages = {13},
keywords = {empirical study, software engineering, generative AI, ChatGPT},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3641525.3663617,
author = {Boufford, Nichole and Wonsil, Joseph and Pocock, Adam and Sullivan, Jack and Seltzer, Margo and Pasquier, Thomas},
title = {Computational Experiment Comprehension using Provenance Summarization},
year = {2024},
isbn = {9798400705304},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641525.3663617},
doi = {10.1145/3641525.3663617},
abstract = {Scientists use complex multistep workflows to analyze data. However, reproducing computational experiments is often difficult as scientists’ software engineering practices are geared towards the science, not the programming. In particular, reproducing a scientific workflow frequently requires information about its execution. This information includes the precise versions of packages and libraries used, the particular processor used to perform floating point computation, and the language runtime used. This can be extracted from data provenance, the formal record of what happened during an experiment. However, data provenance is inherently graph-structured and often large, which makes interpretation challenging. Rather than exposing data provenance through its graphical representation, we propose a textual one and use a large language model to generate it. We develop techniques for prompting large language models to automatically generate textual summaries of provenance data. We conduct a user study to compare the effectiveness of these summaries to the more common node-link diagram representation. Study participants are able to extract useful information from both the textual summaries and node-link diagrams. The textual summaries were particularly beneficial for scientists with low computational expertise. We discuss the qualitative results from our study to motivate future designs for reproducibility tools.},
booktitle = {Proceedings of the 2nd ACM Conference on Reproducibility and Replicability},
pages = {1–19},
numpages = {19},
keywords = {Provenance, Reproducibility, Text Generation, User Study},
location = {Rennes, France},
series = {ACM REP '24}
}

@inproceedings{10.1145/3691620.3695277,
author = {Sahoo, Priyam and Pujar, Saurabh and Nalawade, Ganesh and Genhardt, Richard and Mandel, Louis and Buratti, Luca},
title = {Ansible Lightspeed: A Code Generation Service for IT Automation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695277},
doi = {10.1145/3691620.3695277},
abstract = {The availability of Large Language Models (LLMs) which can generate code, has made it possible to create tools that improve developer productivity. Integrated development environments or IDEs which developers use to write software are often used as an interface to interact with LLMs. Although many such tools have been released, almost all of them focus on general-purpose programming languages. Domain-specific languages, such as those crucial for Information Technology (IT) automation, have not received much attention. Ansible is one such YAML-based IT automation-specific language. Ansible Lightspeed is an LLM-based service designed explicitly to generate Ansible YAML, given natural language prompt.In this paper, we present the design and implementation of the Ansible Lightspeed service. We then evaluate its utility to developers using diverse indicators, including extended utilization, analysis of user edited suggestions, as well as user sentiments analysis. The evaluation is based on data collected for 10,696 real users including 3,910 returning users. The code for Ansible Lightspeed service and the analysis framework is made available for others to use.To our knowledge, our study is the first to involve thousands of users of code assistants for domain-specific languages. We are also the first code completion tool to present N-Day user retention figures, which is 13.66% on Day 30. We propose an improved version of user acceptance rate, called Strong Acceptance rate, where a suggestion is considered accepted only if less than 50% of it is edited and these edits do not change critical parts of the suggestion. By focusing on Ansible, Lightspeed is able to achieve a strong acceptance rate of 49.08% for multi-line Ansible task suggestions. With our findings we provide insights into the effectiveness of small, dedicated models in a domain-specific context. We hope this work serves as a reference for software engineering and machine learning researchers exploring code completion.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2148–2158},
numpages = {11},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@proceedings{10.1145/3694715,
title = {SOSP '24: Proceedings of the ACM SIGOPS 30th Symposium on Operating Systems Principles},
year = {2024},
isbn = {9798400712517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 30th ACM Symposium on Operating Systems Principles (SOSP 2024)! We are delighted to present these 43 papers that reflect today's broad range of topics that comprise modern computer systems research, including file and storage systems, memory systems, distributed systems, verification, security, system support for machine learning, microservices, fault-tolerance and reliability, debugging, and, of course, operating systems.},
location = {Austin, TX, USA}
}

@article{10.1145/3702242,
author = {Sanusi, Ismaila Temitayo and Martin, Fred and Ma, Ruizhe and Gonzales, Joseph E. and Mahipal, Vaishali and Oyelere, Solomon Sunday and Suhonen, Jarkko and Tukiainen, Markku},
title = {AI MyData: Fostering Middle School Students’ Engagement with Machine Learning through an Ethics-Infused AI Curriculum},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {4},
url = {https://doi.org/10.1145/3702242},
doi = {10.1145/3702242},
abstract = {As initiatives on AI education in K-12 learning contexts continues to evolve, researchers have developed curricula among other resources to promote AI across grade levels. Yet, there is a need for more effort regarding curriculum, tools, and pedagogy, as well as assessment techniques to popularize AI at the middle school level. Drawing on prior work, we created original curriculum activities with innovative use of existing technology, a new computational teaching tool, and a series of approaches and assessments to evaluate students’ engagement with the learning resources. Our curriculum called AI MyData comprises elements of ML and data science infused with ethical orientation. In this article, we describe the novel AI curriculum and further discuss how we engaged students in learning and critiquing AI ethical dilemmas. We gathered data from two pilot studies conducted in the Northeast United States, one Artificial Intelligence Afterschool (AIA) program, and one virtual AI summer camp. The AIA program was carried out in a local public school with four middle school students aged 12 to 13; the program consisted of eleven 2-hour sessions. The summer camp consisted of 2-hour sessions over 4 consecutive days, with 18 students aged 12 to 15. We facilitated both pilot programs with hands-on plugged and unplugged activities. The method of capturing data included artifact collection, structured interviews, written assessments, and a pre- to post-questionnaire tapping participants’ dispositions about AI and its societal implication. Participant artifacts, written assessments, survey, observation, and analysis of tasks completed revealed that the children improved in their knowledge of AI. In addition, the AI curriculum units and accompanying approaches developed for this study successfully engaged the participants, even without prior knowledge of related concepts. We also found an indication that introducing ethics of AI to adolescents will help their development as ethically responsive citizens. Our study results also indicate that lessons establishing links with students’ personal lives (e.g., letting students choose personally meaningful datasets) and societal implications using unplugged activities and interactive tools were particularly valuable for promoting AI and the integration of AI in middle school education across the subject domains and settings. Based on these results, we discuss our findings, identify their limitations, and propose future work.},
journal = {ACM Trans. Comput. Educ.},
month = dec,
articleno = {55},
numpages = {37},
keywords = {data science, machine learning, plugged activities, unplugged activities, datasets, middle school}
}

@article{10.5555/3636517.3636522,
author = {Crandall, Aaron S. and Sprint, Gina and Fischer, Bryan},
title = {Generative Pre-Trained Transformer (GPT) Models as a Code Review Feedback Tool in Computer Science Programs},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {1},
issn = {1937-4771},
abstract = {Undergraduate computer science and software engineering students benefit significantly from in-depth reviews of their code early and often in their courses. Performing these reviews is time-consuming for teaching assistants and professors to complete, consequently impacting the timeliness and consistency of the provided feedback. When code feedback is not delivered close to the time of authorship, the utility of the review for students is diminished. Prior work with Automatic Static Analysis Tools has shown promise at using artificial intelligence to automate code reviews, with some success integrating them into classroom environments. To leverage new advances in Generative Pre-Trained Transformer (GPT) models, this work reports on an Automatic Review Tool (ART) to provide timely, automatically generated code reviews. ART was evaluated in a second-semester computer science course by integrating ART into the course's Github-based assignment submission system. A cohort of student volunteers (N = 74) read the ART reviews and provided feedback using a survey spanning two of their course assignments. The results of this pilot study show that students perceived ART was successful at detecting defects and offering style-based suggestions, and students were receptive to receiving future automated reviews of their work.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {38–47},
numpages = {10}
}

@inproceedings{10.1145/3622896.3622906,
author = {Sun, Gang and Shen, Ran and Jin, Liangfeng and Wang, Yifan and Xu, Shiyu and Chen, Jinpeng and Jiang, Weihao},
title = {Instruction Tuning Text-to-SQL with Large Language Models in the Power Grid Domain},
year = {2023},
isbn = {9798400708190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622896.3622906},
doi = {10.1145/3622896.3622906},
abstract = {This paper explores the large language models to address the Text-to-SQL task in real-world scenarios in the electricity domain. To tackle the lack of training data and corresponding databases for vertical domain real-world scenarios, the paper devised specific prompts to leverage ChatGPT for data generation, achieving significant improvements in annotation efficiency through automated data generation. Furthermore, to apply the powerful semantic parsing and generation capabilities of large language models to Text-to-SQL, the paper utilized a large language model for instruction tuning for SQL generation. This model has undergone secondary pre-training with electrical knowledge, tailoring it to the specific SQL generation task. On the power grid test set, the paper’s matching accuracy reached 65.7%, and the execution accuracy reached 80.9%. Additionally, the paper conducted further tests on various general large language models for zero-shot learning and single-sample prompt-based Text-to-SQL. The results indicate that while simple single-table queries can be achieved, meeting the requirements for complex queries remains challenging.},
booktitle = {Proceedings of the 2023 4th International Conference on Control, Robotics and Intelligent System},
pages = {59–63},
numpages = {5},
keywords = {GPT, Instruction Tuning, Large Language Models, Power Grid, Text-To-SQL},
location = {Guangzhou, China},
series = {CCRIS '23}
}

@inproceedings{10.1145/3691621.3694934,
author = {Siddiq, Mohammed Latif and da Silva Santos, Joanna Cecilia and Devareddy, Sajith and Muller, Anna},
title = {SALLM: Security Assessment of Generated Code},
year = {2024},
isbn = {9798400712494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691621.3694934},
doi = {10.1145/3691621.3694934},
abstract = {With the growing popularity of Large Language Models (LLMs) in software engineers' daily practices, it is important to ensure that the code generated by these tools is not only functionally correct but also free of vulnerabilities. Although LLMs can help developers to be more productive, prior empirical studies have shown that LLMs can generate insecure code. There are two contributing factors to the insecure code generation. First, existing datasets used to evaluate LLMs do not adequately represent genuine software engineering tasks sensitive to security. Instead, they are often based on competitive programming challenges or classroom-type coding tasks. In real-world applications, the code produced is integrated into larger codebases, introducing potential security risks. Second, existing evaluation metrics primarily focus on the functional correctness of the generated code while ignoring security considerations. Therefore, in this paper, we described Sallm, a framework to benchmark LLMs' abilities to generate secure code systematically. This framework has three major components: a novel dataset of security-centric Python prompts, configurable assessment techniques to evaluate the generated code, and novel metrics to evaluate the models' performance from the perspective of secure code generation.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering Workshops},
pages = {54–65},
numpages = {12},
keywords = {security evaluation, large language models, pre-trained transformer model, metrics},
location = {Sacramento, CA, USA},
series = {ASEW '24}
}

@inproceedings{10.1145/3644815.3644945,
author = {Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
title = {Seven Failure Points When Engineering a Retrieval Augmented Generation System},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644945},
doi = {10.1145/3644815.3644945},
abstract = {Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {194–199},
numpages = {6},
keywords = {retrieval augmented generation, RAG, SE4AI, case study},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3663533.3676565,
author = {Kula, Raula Gaikovina},
title = {The Ever-Evolving Promises of Data in Software Ecosystems: Models, AI, and Analytics (Keynote)},
year = {2024},
isbn = {9798400706752},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663533.3676565},
doi = {10.1145/3663533.3676565},
abstract = {The year 2024 has sparked extensive discussions about the future of software engineering research, particularly for library dependencies and the software ecosystems they create. In this talk, I will take you on an experiential journey spanning the last decade, beginning in 2013 when I first embarked on my journey, and finally landing in the era of generative AI and augmented reality. We will explore how the landscape of collecting datasets through mining, user studies, and expanding from 3 systems to 3 million systems has evolved, examine what elements have remained constant, and discuss how we can advance with software ecosystems research in the face of these innovations.},
booktitle = {Proceedings of the 20th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {1},
numpages = {1},
location = {Porto de Galinhas, Brazil},
series = {PROMISE 2024}
}

@inproceedings{10.1145/3633083.3633103,
author = {Flammini, Francesco and Marrone, Stefano},
title = {Distance education boosting interdisciplinarity and internationalization: an experience report from “Ethics, Law and Privacy in Data and Analytics” at SUPSI},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633103},
doi = {10.1145/3633083.3633103},
abstract = {The COVID-19 pandemic caused several changes in daily habits and routines. Among all, education faced this problem by massively adopting remote teaching. Despite this constituted, in the initial moment, a wall to climb, several universities keep delivering online or hybrid courses, with the aim of leveraging the benefits of such an approach. On this line, the Bachelor’s degree in Data Science and Artificial Intelligence at the University of Applied Sciences and Arts of Southern Switzerland (SUPSI) has broadened its curriculum with the introduction of “Ethics, Law and Privacy in Data and Analytics” as a mandatory module in the fifth semester. This innovative teaching project, piloted during the academic year 2022/2023, tackled the pedagogical challenge of integrating a multidisciplinary subject into the largely technical field of Data Science and AI. Recognizing the necessity for expertise beyond the Department of Innovative Technologies (DTI), the module was conducted entirely in English and leveraged online delivery to incorporate a diverse range of international specialists in ethics, law, and relevant technology fields. This poster details the module’s structure, highlighting the inclusion of global perspectives to avoid the limitations of a Swiss-centric view and prepare students for a universal professional environment. It also explores the logistics and pedagogical strategies employed to navigate the complexities of online learning, such as interactive lectures, case studies, role-plays, and flipped classroom sessions.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {54},
numpages = {1},
keywords = {Artificial Intelligence, COVID-19, Ethics, Online Teaching},
location = {Dublin, Ireland},
series = {HCAIep '23}
}

@inproceedings{10.1145/3698322.3698324,
author = {Maranh\~{a}o, Jo\~{a}o Jos\'{e} and Guerra, Eduardo Martins},
title = {A Prompt Pattern Sequence Approach to Apply Generative AI in Assisting Software Architecture Decision-making},
year = {2024},
isbn = {9798400716836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698322.3698324},
doi = {10.1145/3698322.3698324},
abstract = {This paper proposes an approach that employs generative AI, specifically GPT models, to enhance decision-making in software architecture through a sequence of prompt patterns. Five prompt patterns are introduced, each targeting software architects’ specific challenges when navigating complex design decisions. Through a structured and context-aware decision flow, we demonstrate how these patterns can mitigate risks, manage uncertainties, and optimize functional and non-functional requirements. The proposed approach is evaluated in two real-world scenarios and one fictional case, illustrating its practical application in optimizing operations and ensuring scalability, security, and performance. While AI demonstrates transformative potential in aiding architectural practices, we also highlight its limitations, emphasizing the importance of human oversight in validating technical assumptions and avoiding over-reliance on automated tools. This paper contributes to the ongoing dialogue on how AI can be integrated into software architecture to foster more efficient, informed, and context-sensitive decision-making processes for architects.},
booktitle = {Proceedings of the 29th European Conference on Pattern Languages of Programs, People, and Practices},
articleno = {1},
numpages = {12},
keywords = {Prompt Engineering, Prompt Patterns Sequence, Design Patterns, Software Architecture, Artificial Intelligence, AI Generative, Architecture Decision-Making},
location = {
},
series = {EuroPLoP '24}
}

@inproceedings{10.1145/3661167.3661207,
author = {S\'{a}godi, Zolt\'{a}n and Antal, G\'{a}bor and Bogenf\"{u}rst, Bence and Isztin, Martin and Hegedundefineds, P\'{e}ter and Ferenc, Rudolf},
title = {Reality Check: Assessing GPT-4 in Fixing Real-World Software Vulnerabilities},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661207},
doi = {10.1145/3661167.3661207},
abstract = {Discovering and mitigating software vulnerabilities is a challenging task. These vulnerabilities are often caused by simple, otherwise (and in other contexts) harmless code snippets (e.g., unchecked path traversal). Large Language Models (LLMs) promise to revolutionize not just human-machine interactions but various software engineering tasks as well, including the automatic repair of vulnerabilities. However, currently, it is hard to assess the performance, robustness, and reliability of these models as most of their evaluation has been done on small, synthetic examples. In our work, we systematically evaluate the automatic vulnerability fixing capabilities of GPT-4, a popular LLM, using a database of real-world Java vulnerabilities, Vul4J. We expect the model to provide fixes for vulnerable methods, which we evaluate manually and based on unit test results included in the Vul4J database. GPT-4 provided perfect fixes consistently for at least 12 out of the total 46 examined vulnerabilities, which could be applied as is. In an additional 5 cases, the provided textual instructions would help to fix the vulnerabilities in a practical scenario (despite the provided code being incorrect). Our findings, similar to others, also show that prompting has a significant effect.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {252–261},
numpages = {10},
keywords = {Automated program repair, GPT, Machine learning, Vulnerability fixing},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3624062.3624614,
author = {Brace, Alexander and Vescovi, Rafael and Chard, Ryan and Saint, Nickolaus D. and Ramanathan, Arvind and Zaluzec, Nestor J. and Foster, Ian},
title = {Linking the Dynamic PicoProbe Analytical Electron-Optical Beam Line / Microscope to Supercomputers},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3624614},
doi = {10.1145/3624062.3624614},
abstract = {The Dynamic PicoProbe at Argonne National Laboratory is undergoing upgrades that will enable it to produce up to 100s of GB of data per day. While this data is highly important for both fundamental science and industrial applications, there is currently limited on-site infrastructure to handle these high-volume data streams. We address this problem by providing a software architecture capable of supporting large-scale data transfers to the neighboring supercomputers at the Argonne Leadership Computing Facility. To prepare for future scientific workflows, we implement two instructive use cases for hyperspectral and spatiotemporal datasets, which include: (i) off-site data transfer, (ii) machine learning/artificial intelligence and traditional data analysis approaches, and (iii) automatic metadata extraction and cataloging of experimental results. This infrastructure supports expected workloads and also provides domain scientists the ability to reinterrogate data from past experiments to yield additional scientific value and derive new insights.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {2140–2146},
numpages = {7},
keywords = {AI, HPC, ML, automated science, data flow},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@inproceedings{10.1145/3576882.3617921,
author = {Prasad, Siddhartha and Greenman, Ben and Nelson, Tim and Krishnamurthi, Shriram},
title = {Generating Programs Trivially: Student Use of Large Language Models},
year = {2023},
isbn = {9798400700484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576882.3617921},
doi = {10.1145/3576882.3617921},
abstract = {Educators have been concerned about the capability of large language models to automatically generate programs in response to textual prompts. However, little is known about whether and how students actually use these tools.In the context of an upper-level formal methods course, we gave students access to large language models. They were told they could use the models freely. We built a Visual Studio Code extension to simplify access to these models. We also paid for an account so students could use the models for free without worrying about cost.In this experience report we analyze the outcomes. We see how students actually do and do not use the models. We codify the different uses they make. Most of all, we notice that students actually do not use them very much at all, and provide insight into the many reasons why not. We believe such experiments can help rebalance some of the public narrative about such tools.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 1},
pages = {126–132},
numpages = {7},
keywords = {formal methods, large language models, properties, testing},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@inproceedings{10.1145/3491140.3529537,
author = {Elhayany, Mohamed and Nair, Ranjiraj-Rajendran and Staubitz, Thomas and Meinel, Christoph},
title = {A Study about Future Prospects of JupyterHub in MOOCs},
year = {2022},
isbn = {9781450391580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491140.3529537},
doi = {10.1145/3491140.3529537},
abstract = {The Hasso Plattner Institute (HPI) has been successfully delivering courses on several MOOC (Massive Open Online Course) platforms for the last 10 years, offering courses on various topics in the context of Artificial Intelligence (AI), Machine Learning (ML), and Data Science. In recent years, Jupyter Notebooks have become one of the most widely used tools for data science applications, a platform for learning and practicing various programming languages. We want to integrate JupyterHub into our learning platform in order to provide students with hands-on experience in AI. We have conducted a survey with a series of research questions in order to understand the needs of instructors in their courses at different institutions. In this paper, we present a detailed analysis of our survey results and we discuss our future approach to using JupyterHub as an infrastructure to solve hands-on programming exercises on our platform. We propose the idea of creating a tool to automate server and environment creation for students to work on. This tool would give instructors a platform to operate from and allow them to customize their courses. Moreover, it would help them automate assignment submissions, grading, and provide feedback to their students.},
booktitle = {Proceedings of the Ninth ACM Conference on Learning @ Scale},
pages = {275–279},
numpages = {5},
keywords = {Jupyterhub, MOOC, automated grading, programming, scheduling},
location = {New York City, NY, USA},
series = {L@S '22}
}

@article{10.5555/3575618.3575622,
author = {Puryear, Ben and Sprint, Gina},
title = {Github copilot in the classroom: learning to code with AI assistance},
year = {2022},
issue_date = {November 2022},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {38},
number = {1},
issn = {1937-4771},
abstract = {Recent advances in deep machine learning have enabled artificial intelligence-driven development environments (AIDEs). AIDEs are programming tools that, given comments or starter code, can generate code solution suggestions. As the accuracy of these tools continues to increase, one particular AIDE from Github, Copilot, has been gaining significant attention for its performance and ease of use. The rise of Copilot suggests that code solution generation tools will soon be commonplace in both the industry and in computer science courses, with expert and novice programmers alike benefiting from using these tools. More specifically for novices, the effects of Copilot on the process of learning to code are mostly unknown. In this paper, we perform initial explorations into these effects. Using introductory computer science and data science courses, we evaluate Copilot-generated programming assignment solutions for correctness, style, skill level appropriateness, grade scores, and potential plagiarism. Our findings indicate Copilot generates mostly unique code that can solve introductory assignments with human-graded scores ranging from 68% to 95%. Based on these results, we provide recommendations for educators to help adapt their courses to incorporate new AIDE-based programming workflows.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {37–47},
numpages = {11}
}

@inproceedings{10.1145/3643991.3648400,
author = {Xiao, Tao and Treude, Christoph and Hata, Hideaki and Matsumoto, Kenichi},
title = {DevGPT: Studying Developer-ChatGPT Conversations},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3648400},
doi = {10.1145/3643991.3648400},
abstract = {This paper introduces DevGPT, a dataset curated to explore how software developers interact with ChatGPT, a prominent large language model (LLM). The dataset encompasses 29,778 prompts and responses from ChatGPT, including 19,106 code snippets, and is linked to corresponding software development artifacts such as source code, commits, issues, pull requests, discussions, and Hacker News threads. This comprehensive dataset is derived from shared ChatGPT conversations collected from GitHub and Hacker News, providing a rich resource for understanding the dynamics of developer interactions with ChatGPT, the nature of their inquiries, and the impact of these interactions on their work. DevGPT enables the study of developer queries, the effectiveness of ChatGPT in code generation and problem solving, and the broader implications of AI-assisted programming. By providing this dataset, the paper paves the way for novel research avenues in software engineering, particularly in understanding and improving the use of LLMs like ChatGPT by developers.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {227–230},
numpages = {4},
keywords = {ChatGPT, LLM, generative AI, dataset},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3661167.3661183,
author = {Watanabe, Miku and Kashiwa, Yutaro and Lin, Bin and Hirao, Toshiki and Yamaguchi, Ken'Ichi and Iida, Hajimu},
title = {On the Use of ChatGPT for Code Review: Do Developers Like Reviews By ChatGPT?},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661183},
doi = {10.1145/3661167.3661183},
abstract = {Code review is a critical but time-consuming process for ensuring code quality in modern software engineering. To alleviate the effort of reviewing source code, recent studies have investigated the possibility of automating the review process. Moreover, tools based on large language models such as ChatGPT are playing an increasingly important role in this vision. Understanding how these tools are used during code review can provide valuable insights for code review automation. This study investigates for what purposes developers use ChatGPT during code review and how developers react to the information and suggestions provided by ChatGPT. We manually analyze 229 review comments in 205 pull requests from 179 projects. We find that developers often use ChatGPT for outsourcing their work as frequently as asking for references. Moreover, we observe that only 30.7% of responses to the answers provided by ChatGPT are negative. We further analyze the reasons behind the negative reactions. Our results provide valuable insights for improving the effectiveness of LLMs in code reviews.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {375–380},
numpages = {6},
keywords = {ChatGPT, Code Review, Empirical Study},
location = {Salerno, Italy},
series = {EASE '24}
}

@article{10.1145/3695988,
author = {Hou, Xinyi and Zhao, Yanjie and Liu, Yue and Yang, Zhou and Wang, Kailong and Li, Li and Luo, Xiapu and Lo, David and Grundy, John and Wang, Haoyu},
title = {Large Language Models for Software Engineering: A Systematic Literature Review},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {8},
issn = {1049-331X},
url = {https://doi.org/10.1145/3695988},
doi = {10.1145/3695988},
abstract = {Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a Systematic Literature Review (SLR) on LLM4SE, with a particular focus on understanding how LLMs can be exploited to optimize processes and outcomes. We selected and analyzed 395 research articles from January 2017 to January 2024 to answer four key Research Questions (RQs). In RQ1, we categorize different LLMs that have been employed in SE tasks, characterizing their distinctive features and uses. In RQ2, we analyze the methods used in data collection, pre-processing, and application, highlighting the role of well-curated datasets for successful LLM for SE implementation. RQ3 investigates the strategies employed to optimize and evaluate the performance of LLMs in SE. Finally, RQ4 examines the specific SE tasks where LLMs have shown success to date, illustrating their practical contributions to the field. From the answers to these RQs, we discuss the current state-of-the-art and trends, identifying gaps in existing research, and highlighting promising areas for future study. Our artifacts are publicly available at .},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {220},
numpages = {79},
keywords = {Software Engineering, Large Language Model, Survey}
}

@inproceedings{10.1145/3644815.3644946,
author = {Li, Ziyu and Shin, Donghwan},
title = {Mutation-based Consistency Testing for Evaluating the Code Understanding Capability of LLMs},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644946},
doi = {10.1145/3644815.3644946},
abstract = {Large Language Models (LLMs) have shown remarkable capabilities in processing both natural and programming languages, which have enabled various applications in software engineering, such as requirement engineering, code generation, and software testing. However, existing code generation benchmarks do not necessarily assess the code understanding performance of LLMs, especially for the subtle inconsistencies that may arise between code and its semantics described in natural language.In this paper, we propose a novel method, called Mutation-based Consistency Testing (MCT), to systematically assess the code understanding performance of LLMs, particularly focusing on subtle differences between code and its descriptions, by introducing code mutations to existing code generation datasets. Code mutations are small changes that alter the semantics of the original code, creating a mismatch with the natural language description. MCT uses different types of code mutations, such as operator replacement and statement deletion, to generate inconsistent code-description pairs. MCT then uses these pairs to test the ability of LLMs to detect the inconsistencies correctly.We conduct a case study on the two popular LLMs, GPT-3.5 and GPT-4, using the state-of-the-art code generation benchmark, HumanEval-X, which consists of 164 programming problems written in six programming languages (Python, C++, Java, Go, JavaScript, and Rust). The results show that the LLMs have significant variations in their code understanding performance and that they have different strengths and weaknesses depending on the mutation type and language. We further explain conditions under which the LLMs result in correct answers using input characteristics (e.g., number of tokens) and investigate to what extent the test results can be improved using one-shot prompts (i.e., providing an additional example). Our MCT method and the case study results provide valuable implications for future research and development of LLM-based software engineering.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {150–159},
numpages = {10},
keywords = {large language models, software engineering, mutation analysis},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3643991.3645069,
author = {Wu, Liangxuan and Zhao, Yanjie and Hou, Xinyi and Liu, Tianming and Wang, Haoyu},
title = {ChatGPT Chats Decoded: Uncovering Prompt Patterns for Superior Solutions in Software Development Lifecycle},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645069},
doi = {10.1145/3643991.3645069},
abstract = {The advent of Large Language Models (LLMs) like ChatGPT has markedly transformed software development, aiding tasks from code generation to issue resolution with their human-like text generation. Nevertheless, the effectiveness of these models greatly depends on the nature of the prompts given by developers. Therefore, this study delves into the DevGPT dataset, a rich collection of developer-ChatGPT dialogues, to unearth the patterns in prompts that lead to effective problem resolutions. The underlying motivation for this research is to enhance the collaboration between human developers and AI tools, thereby improving productivity and problem-solving efficacy in software development. Utilizing a combination of textual analysis and data-driven approaches, this paper seeks to identify the attributes of prompts that are associated with successful interactions, providing crucial insights for the strategic employment of ChatGPT in software engineering environments.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {142–146},
numpages = {5},
keywords = {data mining, large language model, LLM, ChatGPT},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3545947.3576275,
author = {Mahipal, Vaishali and Ghosh, Srija and Sanusi, Ismaila Temitayo and Ma, Ruizhe and Gonzales, Joseph E. and Martin, Fred G.},
title = {DoodleIt: A Beginner's Tool for Understanding Image Recognition},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3576275},
doi = {10.1145/3545947.3576275},
abstract = {In this poster we present "DoodleIt,'' an interactive web application that performs sketch recognition and an afterschool curriculum that teaches students the key concepts of convolutional neural network (CNN). With DoodleIt, students make simple line drawings on a canvas area and a previously-trained CNN identifies the object drawn. The application visualizes the different layers that are involved in the process of CNN, including a display of kernels, the resulting feature maps, and the percentage of match at output neurons. We used DoodleIt as a part of 18-hour curriculum to introduce students to artificial intelligence, machine learning, and data science. Our findings indicate that students were able to understand the functionality of the kernels and feature maps involved in the CNN to perform rudimentary image recognition.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1329},
numpages = {1},
keywords = {artificial intelligence, convolution neural networks, feature maps, image recognition, k-12 students, kernels, middle school students},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3643915.3644088,
author = {Li, Jialong and Zhang, Mingyue and Li, Nianyu and Weyns, Danny and Jin, Zhi and Tei, Kenji},
title = {Exploring the Potential of Large Language Models in Self-adaptive Systems},
year = {2024},
isbn = {9798400705854},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643915.3644088},
doi = {10.1145/3643915.3644088},
abstract = {Large Language Models (LLMs), with their abilities in knowledge acquisition and reasoning, can potentially enhance the various aspects of Self-adaptive Systems (SAS). Yet, the potential of LLMs in SAS remains largely unexplored and ambiguous, due to the lack of literature from flagship conferences or journals in the field, such as SEAMS and TAAS. The interdisciplinary nature of SAS suggests that drawing and integrating ideas from related fields, such as software engineering and autonomous agents, could unveil innovative research directions for LLMs within SAS. To this end, this paper reports the results of a literature review of studies in relevant fields, summarizes and classifies the studies relevant to SAS, and outlines their potential to specific aspects of SAS. Literature classification: www.github.com/545659928/LLM4SAS},
booktitle = {Proceedings of the 19th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {77–83},
numpages = {7},
keywords = {large language model, self-adaptive systems, survey},
location = {Lisbon, AA, Portugal},
series = {SEAMS '24}
}

@inproceedings{10.1145/3478432.3499152,
author = {Qasem, Apan and Bunde, David},
title = {Heterogeneous Computing for Undergraduates: Introducing the ToUCH Module Repository},
year = {2022},
isbn = {9781450390712},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3478432.3499152},
doi = {10.1145/3478432.3499152},
abstract = {The need for increased performance per watt, coupled with the demands of processing diverse workloads, has triggered an industry shift towards heterogeneous computing systems. Integration of high-performance CPUs with energy-efficient GPUs is now common in HPC. Architectural heterogeneity has also permeated other domains such as mobile processing, cloud computing, and the Internet of Things. Machine learning practitioners routinely use accelerators in both training and inference. The move towards heterogeneity presents a significant educational challenge since few current curricula include much about heterogeneous computing except possibly in upper-division electives. The NSF-funded initiative ToUCH: Teaching Undergraduates Collaborative and Heterogeneous computing was conceived to confront this impending challenge (https://touch.cs.txstate.edu). The ToUCH project has several ongoing initiatives to promote and encourage teaching of heterogeneous computing. These include summer bootcamps, faculty training workshops and the design, implementation, and integration of a collection of teaching modules on heterogenous computing. In this workshop, we present modules from the ToUCH repository to incorporate heterogeneous computing into core CS courses taken by all majors (e.g., CS 1, CS 2, Computer Organization, Operating Systems). Attendees will have time to work through lab exercises, assignments and tutorials associated with the modules while we assist. We will provide post-workshop support for instructors interested in adopting the modules. In addition, we will solicit feedback from them to help guide our future module development.},
booktitle = {Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 2},
pages = {1201},
numpages = {1},
keywords = {heterogeneous computing, parallel computing},
location = {Providence, RI, USA},
series = {SIGCSE 2022}
}

@inproceedings{10.1145/3671016.3674821,
author = {Liang, Wenjun and Xiao, Guanping},
title = {An Exploratory Evaluation of Large Language Models Using Empirical Software Engineering Tasks},
year = {2024},
isbn = {9798400707056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671016.3674821},
doi = {10.1145/3671016.3674821},
abstract = {In empirical software engineering (EMSE), various activities require human participation, such as data collection, processing, analysis, and comprehension. On one hand, these processes are time-consuming and labor-intensive. On the other hand, human participation may introduce bias. With the rise of large language models (LLMs) like ChatGPT, the potential for these models to enhance productivity has become apparent. However, the auxiliary capabilities and effectiveness of LLMs in EMSE tasks have rarely been explored. To fill this gap, in this paper, we evaluate the performance of LLMs by using scenarios of human participation in EMSE tasks, i.e., EMSEBench. We conduct replication experiments using four LLMs (ChatGPT4.0, ERNIE Bot4.0, Gemini3.0, and ChatGLM4.0), evaluating the difference in performance across seven scenarios collected from papers published in top SE venues. In the experiments, we perform three types of prompts, i.e., zero-shot, one-shot, and optimized one-shot. Besides, we leverage the concept of multi-agent workflow to explore the performance improvement and limitations of LLMs. Our study summarizes six findings, which facilitate the understanding of the auxiliary of LLMs in EMSE tasks.},
booktitle = {Proceedings of the 15th Asia-Pacific Symposium on Internetware},
pages = {31–40},
numpages = {10},
keywords = {empirical software engineering tasks, evaluation benchmark, large language models},
location = {Macau, China},
series = {Internetware '24}
}

@inproceedings{10.1145/3644815.3644973,
author = {Wagner, Matthias},
title = {Continuous Quality Assurance and ML Pipelines under the AI Act},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644973},
doi = {10.1145/3644815.3644973},
abstract = {More than ever, Machine Learning (ML) as a subfield of Artificial Intelligence (AI) is on the rise and is finding its way into safety-critical software applications. However, when it comes to quality assurance (QA) and trustworthiness, integrating ML models into software comes with challenges that may not be apparent at first glance. The European Union (EU) aims to tackle this problem with new regulatory requirements in the form of harmonized rules on AI (AI Act). It is a risk-based approach with extensive requirements for high-risk systems as well as for foundation models that can be used in various downstream AI systems. Reliable software engineering processes in the form of ML-enabled automated pipelines are likely to become a discerning factor for legally compliant ML systems. Our research project aims to contribute to the field by establishing an empirically grounded foundation on how to achieve trustworthy AI Act compliant ML systems. Both a literature review and an interview study are ongoing. At a later stage, concrete tools shall be developed, ideally in cooperation with an industry partner, possibly by utilizing the concept of regulatory sandboxes.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {247–249},
numpages = {3},
keywords = {software engineering, quality assurance, AI act},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3675812.3675873,
author = {Yang, Yi and Yu, Dekuang},
title = {Concept, Construction, and Practice of Innovation-oriented Case Teaching in the Context of New Engineering},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675873},
doi = {10.1145/3675812.3675873},
abstract = {The construction of new engineering disciplines has entered the stage of promotion and implementation. Innovation is the essential attribute of engineering education. Introducing practical engineering into engineering education through case teaching helps to cultivate students' ability to solve complex engineering problems and achieve the personnel cultivation goals of engineering education. Due to the traditional case teaching mainly serving the knowledge system and being far from practice, and the difficulty of most actual engineering projects being relatively high, the teaching effect of engineering case teaching is not ideal. Based on the pain points of engineering case teaching, this article takes the case teaching of software engineering courses in the era of artificial intelligence as an example. Starting from the answer to "How to improve the effectiveness of engineering case teaching", the concept of innovative oriented engineering cases is proposed, and a framework for constructing a "Project application Style" case library is constructed. Completed the construction of an industry case library, enabling students to have a comprehensive understanding of project cases in the industry. In case teaching, emphasis is placed on cultivating self-directed learning ability and expanding teaching to competitions, scientific research, innovation, and entrepreneurship, cultivating top-notch personnel with innovative spirit and strong sense of social responsibility. Practice has shown that this new model has achieved good personnel cultivation results.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {418–423},
numpages = {6},
keywords = {Case teaching, Innovation oriented, New engineering, Project application style, Software engineering},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3643916.3644435,
author = {Sergeyuk, Agnia and Lvova, Olga and Titov, Sergey and Serova, Anastasiia and Bagirov, Farid and Kirillova, Evgeniia and Bryksin, Timofey},
title = {Reassessing Java Code Readability Models with a Human-Centered Approach},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644435},
doi = {10.1145/3643916.3644435},
abstract = {To ensure that Large Language Models (LLMs) effectively support user productivity, they need to be adjusted. Existing Code Readability (CR) models can guide this alignment. However, there are concerns about their relevance in modern software engineering since they often miss the developers' notion of readability and rely on outdated code. This research assesses existing Java CR models for LLM adjustments, measuring the correlation between their and developers' evaluations of AI-generated Java code. Using the Repertory Grid Technique with 15 developers, we identified 12 key code aspects influencing CR that were consequently assessed by 390 programmers when labeling 120 AI-generated snippets. Our findings indicate that when AI generates concise and executable code, it's often considered readable by CR models and developers. However, a limited correlation between these evaluations underscores the importance of future research on learning objectives for adjusting LLMs and on the aspects influencing CR evaluations included in predictive models.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {225–235},
numpages = {11},
keywords = {code readability, code readability models, repertory grid technique, AI-generated code, human-computer interaction},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3674805.3690741,
author = {De Bari, Daniele and Garaccione, Giacomo and Coppola, Riccardo and Torchiano, Marco and Ardito, Luca},
title = {Evaluating Large Language Models in Exercises of UML Class Diagram Modeling},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690741},
doi = {10.1145/3674805.3690741},
abstract = {Large Language Models (LLM) have rapidly affirmed in the latest years as a means to support or substitute human actors in a variety of tasks. LLM agents can generate valid software models, because of their inherent ability in evaluating textual requirements provided to them in the form of prompts. The goal of this work is to evaluate the capability of LLM agents to correctly generate UML class diagrams in activities of Requirements Modeling in the field of Software Engineering. Our aim is to evaluate LLMs in an educational setting, i.e., understanding how valuable are the results of LLMs when compared to results made by human actors, and how valuable can LLM be to generate sample solutions to provide to students. For that purpose, we collected 20 exercises from a diverse set of web sources and compared the models generated by a human and an LLM solver in terms of syntactic, semantic, pragmatic correctness, and distance from a provided reference solution. Our results show that the solutions generated by an LLM solver typically present a significantly higher number of errors in terms of semantic quality and textual difference against the provided reference solution, while no significant difference is found in syntactic and pragmatic quality. We can therefore conclude that, with a limited amount of errors mostly related to the textual content of the solution, UML diagrams generated by LLM agents have the same level of understandability as those generated by humans, and exhibit the same frequency in violating rules of UML Class Diagrams.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {393–399},
numpages = {7},
keywords = {Artificial Intelligence, Class Diagrams, Large Language Models, Software Modeling},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3663529.3663818,
author = {Jaccheri, Letizia and Duc, Anh Nguyen},
title = {Software Engineering and Gender: A Tutorial},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663818},
doi = {10.1145/3663529.3663818},
abstract = {Software runs the world and should provide equal rights and opportunities to all genders. However, the gender gap exists in the software engineering workforce and many software products are still gender biased. Recently, AI systems, including modern large language models are shown to be related to gender bias issues. Many efforts have been devoted to understanding the problem and investigating solutions. The tutorial aims to present a set of scientific studies based on qualitative and quantitative research methods. The authors have a long record of research leadership in interdisciplinary projects with a focus on gender and software engineering. The issues with team diversity in software development and AI engineering will be presented to highlight the importance of fostering inclusive and diverse software development teams.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {704–706},
numpages = {3},
keywords = {Software engineering, bias, gender, research methods},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@article{10.1145/3672089.3672101,
author = {Arnedo-Moreno, Joan and Cooper, Kendra M. L. and Lin, Dayi},
title = {Emerging Advanced Technologies for Game Engineering},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/3672089.3672101},
doi = {10.1145/3672089.3672101},
abstract = {In this paper, the outcomes of the 8th International Workshop on Games and Software Engineering (GAS 2024)1 are reported. The one-day workshop has been held as part of the 46th International Conference on Software Engineering (ICSE 2024) in Lisbon, Portugal on April 14, 2024. The workshop programme includes two exciting keynotes discussing topics related to harnessing video game simulations to generate content and locate bugs, and the experience of maintaining a popular FOSS library, raylib. There are three research paper sessions. The first relates to automation in game engineering; the second explores testing and quality assurance; and the third discusses specification and quality of service. The conclusion of the workshop is anchored by a panel of four researchers, educators, and practitioners discussing the current strengths and limitations of large language models in game engineering.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jul,
pages = {37–41},
numpages = {5}
}

@inproceedings{10.1145/3643991.3645081,
author = {AlOmar, Eman Abdullah and Venkatakrishnan, Anushkrishna and Mkaouer, Mohamed Wiem and Newman, Christian and Ouni, Ali},
title = {How to refactor this code? An exploratory study on developer-ChatGPT refactoring conversations},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645081},
doi = {10.1145/3643991.3645081},
abstract = {Large Language Models (LLMs), like ChatGPT, have gained widespread popularity and usage in various software engineering tasks, including refactoring, testing, code review, and program comprehension. Despite recent studies delving into refactoring documentation in commit messages, issues, and code review, little is known about how developers articulate their refactoring needs when interacting with ChatGPT. In this paper, our goal is to explore conversations between developers and ChatGPT related to refactoring to better understand how developers identify areas for improvement in code and how ChatGPT addresses developers' needs. Our approach relies on text mining refactoring-related conversations from 17,913 ChatGPT prompts and responses, and investigating developers' explicit refactoring intention. Our results reveal that (1) developer-ChatGPT conversations commonly involve generic and specific terms/phrases; (2) developers often make generic refactoring requests, while ChatGPT typically includes the refactoring intention; and (3) various learning settings when prompting ChatGPT in the context of refactoring. We envision that our findings contribute to a broader understanding of the collaboration between developers and AI models.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {202–206},
numpages = {5},
keywords = {refactoring documentation, ChatGPT, mining software repositories},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3626203.3670588,
author = {Stevens, Cody and Anderson, Sean and Carlson, Adam},
title = {Integrating High Performance Computing into Higher Education and the Pedagogy of Cluster Computing},
year = {2024},
isbn = {9798400704192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626203.3670588},
doi = {10.1145/3626203.3670588},
abstract = {Despite the exponential growth in demand for advanced computational skills driven by big data, machine learning, and artificial intelligence, higher education institutions still face a significant shortage of dedicated course offerings pertaining to High Performance Computing (HPC). This educational deficiency not only hampers the preparedness of undergraduate students for cutting-edge postgraduate programs but also impairs their readiness to enter a dynamic workforce increasingly reliant on sophisticated computational capabilities. Integrating comprehensive HPC courses at the undergraduate level is critical for equipping students with expertise to effectively utilize modern computing technologies, and also for bridging the growing gap between academic preparation and industry demands. At Wake Forest University (WFU), we, members of the HPC Team, are actively working to address the educational gap in HPC by integrating the WFU HPC Facility[4] into higher-level elective courses across various disciplines. Recognizing the foundational importance of these skills, we have developed an introductory course specifically designed to equip students with the knowledge to excel in advanced courses, in graduate and research programs, and to meet the demands of the modern workforce. By integrating the WFU HPC Facility into our curriculum, the University is committed to pioneering a comprehensive educational pathway that empowers students to leverage the full potential of computing technologies in their future careers. WFU is an R-2 liberal arts institution with around 9,000 students[6] that actively supports undergraduate research through a multitude of departments and programs. Undergraduate research is so paramount to the University mission, that WFU has a dedicated center, the Undergraduate Research and Creative Activities (URECA) Center, just for this purpose. Many students engage in research projects that leverage the resources of the WFU HPC Facility. The facility’s main asset, the Distributed Environment for Academic Computing (DEAC) Cluster, contains approximately 4000 CPU cores and 20TB of RAM, and is a true interdisciplinary tool; in 2023 it was utilized by 15 departments and 500 active users to submit over 1.5 million computational tasks on a vast array of research topics. The interdisciplinary nature of the DEAC Cluster played an instrumental role in developing an introductory course in HPC that caters to students from a diverse number of majors. Having supported a wide range of researchers, we designed the course to bridge concepts and applications from Computer Science, Engineering, Data Science, and the Natural Sciences to their respective academic domains. By enabling students from multiple disciplines to access foundational HPC skills, we foster a versatile educational environment where collaborative and interdisciplinary learning thrives. One way that we ensure our introductory course is accessible to all students is that we do not require any prerequisite classes to enroll in the course. Students are also not expected to have any prior experience in programming. We have chosen Python as the primary programming language for the course, as it is one of the most versatile and widely-used languages in the fields of data science and machine learning, and can easily interface with parallel frameworks such as MPI and OpenMP. Students gain hands-on experience by developing asynchronous workflows, which are then executed on the DEAC Cluster. This practical focus not only demystifies complex computational concepts but also empowers students to apply their learning in real-world scenarios. HPC serves as a cornerstone for two distinct user groups, each integral to its advancement and application. The first encompasses those who enable and optimize HPC systems, including Computer Scientists, Computer Engineers, Systems Administrators, and Cyberinfrastructure Professionals, who enhance computational efficiency and build the underlying hardware infrastructure. The second group comprises scientists and researchers across diverse fields such as Statistics, Chemistry, Biology, Physics, Engineering, and more, who leverage HPC as a powerful tool for simulating complex phenomena, analyzing large datasets, and researching novel problems in their respective domains. While current course offerings at other institutions seem to prioritize the first group and educate students on how to build and enable an HPC cluster, we have chosen to prioritize curriculum for the second group as the skills they gain through our course’s curriculum will help them as they continue their academic career in higher level electives and independent research projects with faculty advisors. We choose to offer our course during the Spring semester in order to prepare students who may want to pursue research during the summer session. The first half of the course serves as foundational cluster training, familiarizing students with essential skills to work within an HPC environment. In this segment, students delve into the Linux command line interface (CLI) using Bashcrawl[3] and explore the intricacies of the Linux filesystem and environment modules. A significant focus is placed on understanding and utilizing job schedulers, such as the Slurm resource manager[2]. Another unique feature of this segment is the guided tour of the Wake Forest datacenter. This tour provides students with a tangible understanding of how the theoretical concepts discussed in class are implemented in a real-world HPC cluster. To further provide a reference to the resources requested for their jobs through Slurm, the tour concludes with students disassembling retired compute nodes to learn about the different components that comprise modern servers. The midterm assessment challenges students to submit multiple jobs, analyzing the effects of varying input sizes and the use of multiple CPU processors on calculation speed. Upon completion of this initial phase, students are fully equipped to engage in research activities under an advisor and effectively utilize an HPC cluster outside the confines of the classroom. Many apply for summer grants through the aforementioned URECA program with a faculty advisor. In the latter half of the course, the curriculum shifts towards more advanced topics, focusing on parallel computing frameworks and technologies. Students are introduced to MPI and OpenMP, which are essential for developing parallel applications that can run efficiently on today’s multi-processor systems. Additionally, the course delves into high-speed interconnects, crucial for optimizing communication between different parts of an HPC cluster. One of our final topics covers GPU computing, with a particular emphasis on using NVIDIA GPUs and the CUDA programming platform, enabling students to harness the power of graphical processing for computational tasks. As an example from our Spring 2024 semester, students built a “chatbot” using Meta’s Llama 2 model[5] on both CPU and GPU using LLaMA C++[1], and compared its performance to ChatGPT while interacting freely with it. Our course is designed to complement other specialized courses found in Computer Science or in Computer Engineering programs, such as Parallel Algorithms, Computer Vision, or Deep Learning. It aims to introduce these critical computational concepts and provide a solid foundation that prepares students for these more advanced electives. By the end of the course, students are not only familiar with the basic principles of HPC but are also primed to tackle more specialized studies and research in their future academic and professional pursuits. It is not uncommon that a course may require students to use a specific programming language or software. While there are tools such as Google Colab and zyBooks that provide a browser-based interface to computing resources, those tools can be very limited in what resources they can provide. A faculty member might then want students to install software locally on their laptop, but this can be challenging when students bring their own device to the classroom as they may be running different operating systems or may have different hardware platforms. This can cause the software to behave differently or it may not even be available on that given platform. Courses with significant computational demands are better served utilizing a unified computing environment, and an HPC facility is ideally equipped to provide a consistent learning environment where each student has access to the same software and computing resources. A primary challenge in integrating HPC resources into coursework is instructing students on the use of schedulers for asynchronous workloads. Our introductory HPC course effectively bridges this gap by providing the necessary training and context, enabling students to engage with advanced topics more efficiently, without the steep initial learning curve typically associated with these environments. Our HPC facility has proven instrumental in enhancing educational experiences across a variety of disciplines, demonstrating significant benefits in classes such as Statistics, Natural Language Processing, Parallel Algorithms, Computer Vision, Physics Laboratory, Cancer Biology, Environmental Physics, Computational Modeling, and more. Moreover, students in fields like Finance and Business and Enterprise Management have also successfully leveraged our HPC resources, and have performed analysis on client data that was protected under a nondisclosure agreement which prevented students from storing the data locally on their laptop or with commercial cloud providers. This integration not only facilitates sophisticated computational tasks, but also allows students and faculty to easily share and store large datasets that the students may need to access without having to consume space on their local device. One of our primary goals is to promote diversity and interdisciplinary collaboration within this course, and this semester attracted a notably diverse group of students, with majors ranging from Biology and Statistics to Applied Mathematics, Economics, and Computer Science. Although the course is currently catalogued under the Computer Science department, we recognize that associating it with any single discipline could potentially limit its appeal and accessibility. The diverse enrollment underscores the interdisciplinary relevance of HPC skills across various fields of study. We are leveraging the current success and broad interest in the course as a foundation to establish a new academic program dedicated to High Performance Computing. This new program will serve as a hub for integrating computational skills across different disciplines, fostering a broader understanding and application of HPC in various scientific and economic sectors. The HPC team’s commitment to High Performance Computing education extends beyond traditional academic structures. While we are not developing a new major, minor, certificate track, or concentration in HPC, our objective is to make HPC education accessible and applicable across various disciplines without the constraints of a single departmental bias. This approach allows students from any field to engage with HPC skills as an integral part of their academic and professional development. To achieve this, we are actively collaborating with multiple academic departments to ensure that our HPC course offerings are recognized as fulfilling degree requirements across a range of programs. One way we collaborate with these departments is by altering activities and projects to use different languages and software, such as R and MATLAB, for the Statistics and Engineering departments, while still maintaining the same learning goals we achieve with Python. This strategy not only enhances the versatility of our course but also promotes a more comprehensive integration of the university’s HPC facilities into the curriculum. By doing so, we allow faculty in different departments to integrate our projects into their courses and utilize our HPC facility, even if it is for only one or two projects throughout the semester. Our efforts are focused on fostering a collaborative academic environment where the HPC facility is not just an isolated resource used for research but a central part of our educational infrastructure. By working across disciplines, we hope to catalyze a deeper engagement with HPC technologies throughout the university, enhancing both teaching and research capacities across departments. In conclusion, the escalating demand for big data, machine learning, and artificial intelligence is not only transforming industries but also reshaping educational requirements. As these fields expand, the need for substantial computational resources becomes increasingly critical. The HPC facility at Wake Forest University is exceptionally well-equipped to meet these demands, by providing a unified computing environment that supports an array of academic endeavors. Our initiative to develop introductory HPC courses is a strategic response to this need, preparing students to proficiently utilize HPC resources in higher-level electives and beyond. These courses are pivotal in bridging the gap between conventional academic programs and the rigorous computational needs of modern disciplines. Looking forward, the necessity for such educational offerings will only intensify as the reliance on advanced computational technologies grows. By anticipating and responding to these educational demands, Wake Forest University’s HPC academic program not only enhances student readiness for future challenges but also positions the university at the forefront of academic innovation in the computational sciences.},
booktitle = {Practice and Experience in Advanced Research Computing 2024: Human Powered Computing},
articleno = {106},
numpages = {3},
location = {Providence, RI, USA},
series = {PEARC '24}
}

@inproceedings{10.1109/ASE56229.2023.00182,
author = {Dey, Swarnava and Ghose, Avik and Das, Soumik},
title = {Challenges of Accurate and Efficient AutoML},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00182},
doi = {10.1109/ASE56229.2023.00182},
abstract = {Embedded Artificial Intelligence (AI) is becoming increasingly important in the field of healthcare where such AI enabled devices are utilized to assist physicians, clinicians, and surgeons in their diagnosis, rehabilitation and therapy planning. However, it is still a challenging task to come up with an accurate and efficient machine learning model for resource-limited devices that work 24 \texttimes{} 7. It requires both intuition and experience. This dependence on human expertise and reliance on trial-and-error-based design methods create impediments to the standard processes of effort estimation, design phase planning, and generating service-level agreements for projects that involve AI-enabled MedTech devices.In this paper, we present AutoML search from an algorithmic perspective, instead of a more prevalent optimization or blackbox tool view. We briefly present and point to case studies that demonstrate the efficacy of the automation approach in terms of productivity improvements. We believe that our proposed method can make AutoML more amenable to the applications of software engineering principles and also accelerate biomedical device engineering, where there is a high dependence on skilled human resources.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1834–1839},
numpages = {6},
keywords = {automation, software engineering, IoT, deep learning, AutoML},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3511808.3557201,
author = {Han, Siqi and Li, Wanting and Zhang, En and Shi, Jilin and Wang, Wei and Lu, Xuesong},
title = {MLadder: An Online Training System for Machine Learning and Data Science Education},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557201},
doi = {10.1145/3511808.3557201},
abstract = {Education on machine learning and data science has drawn a lot of attention in both higher education and vocational training. Although various tools and services such as Jupyter Notebook and Google Cloud's AI have been developed for building and training models, they are not suitable for direct use in educational settings. For example, teachers expect a platform where they can easily distribute and grade programming assignments, and students want to quickly start coding and training models without the burden of setting up an environment. To this end, we develop MLadder, an online training system for machine learning and data science education. Specifically, we seamlessly integrate two open-source software, CodaLab and Jupyter Notebook, which are used for hosting assignments and building models, respectively. Moreover, we devise several methods to make the system lightweight and scalable, so that it can be deployed on-premises even with limited resources. We have used MLadder in the machine learning and data science courses in our school and facilitated both teaching and learning.},
booktitle = {Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management},
pages = {4862–4866},
numpages = {5},
keywords = {educational support, kubernetes, machine learning education, online systems},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@inproceedings{10.1145/3674805.3690746,
author = {Almeida, Aylton and Xavier, Laerte and Valente, Marco Tulio},
title = {Automatic Library Migration Using Large Language Models: First Results},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690746},
doi = {10.1145/3674805.3690746},
abstract = {Despite being introduced only a few years ago, Large Language Models (LLMs) are already widely used by developers for code generation. However, their application in automating other Software Engineering activities remains largely unexplored. Thus, in this paper, we report the first results of a study in which we are exploring the use of ChatGPT to support API migration tasks, an important problem that demands manual effort and attention from developers. Specifically, in the paper, we share our initial results involving the use of ChatGPT to migrate a client application to use a newer version of SQLAlchemy, an ORM (Object Relational Mapping) library widely used in Python. We evaluate the use of three types of prompts (Zero-Shot, One-Shot, and Chain Of Thoughts) and show that the best results are achieved by the One-Shot prompt, followed by the Chain Of Thoughts. Particularly, with the One-Shot prompt we were able to successfully migrate all columns of our target application and upgrade its code to use new functionalities enabled by SQLAlchemy’s latest version, such as Python’s asyncio and typing modules, while preserving the original code behavior.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {427–433},
numpages = {7},
keywords = {API Migration, ChatGPT, Large Language Models, Python, SQLAlchemy},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3643691.3648589,
author = {Scantamburlo, Teresa and Falcarin, Paolo and Veneri, Alberto and Fabris, Alessandro and Gallese, Chiara and Billa, Valentina and Rotolo, Francesca and Marcuzzi, Federico},
title = {Software Systems Compliance with the AI Act: Lessons Learned from an International Challenge},
year = {2024},
isbn = {9798400705724},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643691.3648589},
doi = {10.1145/3643691.3648589},
abstract = {In this experience paper, we present the lessons learned from the First University of St. Gallen Grand Challenge 2023, a competition involving interdisciplinary teams tasked with assessing the legal compliance of real-world AI-based systems with the European Union's Artificial Intelligence Act (AI Act). The AI Act is the very first attempt in the world to regulate AI systems and its potential impact is huge. The competition provided firsthand experience and practical knowledge regarding the AI Act's requirements. It also highlighted challenges and opportunities for the software engineering and AI communities.},
booktitle = {Proceedings of the 2nd International Workshop on Responsible AI Engineering},
pages = {44–51},
numpages = {8},
keywords = {AI act, requirements engineering, legal compliance, requirements validation, conformity assessment},
location = {Lisbon, Portugal},
series = {RAIE '24}
}

@inproceedings{10.1145/3576123.3576127,
author = {Mahipal, Vaishali and Ghosh, Srija and Sanusi, Ismaila Temitayo and Ma, Ruizhe and Gonzales, Joseph E. and Martin, Fred G.},
title = {DoodleIt: A Novel Tool and Approach for Teaching How CNNs Perform Image Recognition},
year = {2023},
isbn = {9781450399418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576123.3576127},
doi = {10.1145/3576123.3576127},
abstract = {To introduce middle school students to key concepts in image recognition, we created an interactive web application that performs sketch recognition and an afterschool curriculum for its use. Our app, called DoodleIt, was inspired by Google’s Quick, Draw!, and makes use of its accompanying open-source sketch library. With DoodleIt, students make simple line drawings on a canvas area and a previously-trained convolutional neural network (CNN) identifies the object drawn. The application dynamically visualizes the different layers that are involved in the process of CNNs, including a display of kernels, the resulting feature maps, and the percentage of match at output neurons. We used DoodleIt in an 18-hour curriculum to introduce middle school students to artificial intelligence, machine learning, and data science. Four hours of content were related to image recognition and the ethics of using AI. Here, we describe the design of the DoodleIt application, the approach we used to introduce the associated ideas to the students, and how we assessed student learning. Qualitative data collected from students are presented and discussed. Our findings indicate that students were able to understand the functionality of the kernels and feature maps involved in the CNN to perform rudimentary image recognition.},
booktitle = {Proceedings of the 25th Australasian Computing Education Conference},
pages = {31–38},
numpages = {8},
keywords = {Artificial Intelligence, Convolution Neural Networks, Feature Maps, Image Recognition, K-12 Students, Kernels, Middle School Students},
location = {Melbourne, VIC, Australia},
series = {ACE '23}
}

@inproceedings{10.1145/3644032.3644443,
author = {El Haji, Khalid and Brandt, Carolin and Zaidman, Andy},
title = {Using GitHub Copilot for Test Generation in Python: An Empirical Study},
year = {2024},
isbn = {9798400705885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644032.3644443},
doi = {10.1145/3644032.3644443},
abstract = {Writing unit tests is a crucial task in software development, but it is also recognized as a time-consuming and tedious task. As such, numerous test generation approaches have been proposed and investigated. However, most of these test generation tools produce tests that are typically difficult to understand. Recently, Large Language Models (LLMs) have shown promising results in generating source code and supporting software engineering tasks. As such, we investigate the usability of tests generated by GitHub Copilot, a proprietary closed-source code generation tool that uses an LLM. We evaluate GitHub Copilot's test generation abilities both within and without an existing test suite, and we study the impact of different code commenting strategies on test generations.Our investigation evaluates the usability of 290 tests generated by GitHub Copilot for 53 sampled tests from open source projects. Our findings highlight that within an existing test suite, approximately 45.28% of the tests generated by Copilot are passing tests; 54.72% of generated tests are failing, broken, or empty tests. Furthermore, if we generate tests using Copilot without an existing test suite in place, we observe that 92.45% of the tests are failing, broken, or empty tests. Additionally, we study how test method comments influence the usability of test generations.},
booktitle = {Proceedings of the 5th ACM/IEEE International Conference on Automation of Software Test (AST 2024)},
pages = {45–55},
numpages = {11},
location = {Lisbon, Portugal},
series = {AST '24}
}

@article{10.1145/3638247,
author = {Cheng, Yu and Chen, Jieshan and Huang, Qing and Xing, Zhenchang and Xu, Xiwei and Lu, Qinghua},
title = {Prompt Sapper: A LLM-Empowered Production Tool for Building AI Chains},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3638247},
doi = {10.1145/3638247},
abstract = {The emergence of foundation models, such as large language models (LLMs) GPT-4 and text-to-image models DALL-E, has opened up numerous possibilities across various domains. People can now use natural language (i.e., prompts) to communicate with AI to perform tasks. While people can use foundation models through chatbots (e.g., ChatGPT), chat, regardless of the capabilities of the underlying models, is not a production tool for building reusable AI services. APIs like LangChain allow for LLM-based application development but require substantial programming knowledge, thus posing a barrier. To mitigate this, we systematically review, summarise, refine and extend the concept of AI chain by incorporating the best principles and practices that have been accumulated in software engineering for decades into AI chain engineering, to systematize AI chain engineering methodology. We also develop a no-code integrated development environment, , which embodies these AI chain engineering principles and patterns naturally in the process of building AI chains, thereby improving the performance and quality of AI chains. With Prompt Sapper, AI chain engineers can compose prompt-based AI services on top of foundation models through chat-based requirement analysis and visual programming. Our user study evaluated and demonstrated the efficiency and correctness of Prompt Sapper.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {124},
numpages = {24},
keywords = {AI chain engineering, visual programming, large language models, No/Low code, SE for AI}
}

@inproceedings{10.1145/3631802.3631830,
author = {Liffiton, Mark and Sheese, Brad E and Savelka, Jaromir and Denny, Paul},
title = {CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631830},
doi = {10.1145/3631802.3631830},
abstract = {Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students’ usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {8},
numpages = {11},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3626252.3630854,
author = {Neyem, Andres and Sandoval Alcocer, Juan Pablo and Mendoza, Marcelo and Centellas-Claros, Leonardo and Gonzalez, Luis A. and Paredes-Robles, Carlos},
title = {Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630854},
doi = {10.1145/3626252.3630854},
abstract = {StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {951–957},
numpages = {7},
keywords = {capstone courses, chatgpt, generative ai, large language models, software engineering education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3597503.3639194,
author = {Tanzil, Minaoar Hossain and Khan, Junaed Younus and Uddin, Gias},
title = {ChatGPT Incorrectness Detection in Software Reviews},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639194},
doi = {10.1145/3597503.3639194},
abstract = {We conducted a survey of 135 software engineering (SE) practitioners to understand how they use Generative AI-based chatbots like ChatGPT for SE tasks. We find that they want to use ChatGPT for SE tasks like software library selection but often worry about the truthfulness of ChatGPT responses. We developed a suite of techniques and a tool called CID (ChatGPT Incorrectness Detector) to automatically test and detect the incorrectness in ChatGPT responses. CID is based on the iterative prompting to ChatGPT by asking it contextually similar but textually divergent questions (using an approach that utilizes metamorphic relationships in texts). The underlying principle in CID is that for a given question, a response that is different from other responses (across multiple incarnations of the question) is likely an incorrect response. In a benchmark study of library selection, we show that CID can detect incorrect responses from ChatGPT with an F1-score of 0.74 -- 0.75.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {180},
numpages = {12},
keywords = {large language model, chatGPT, hallucination, testing},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3701268.3701275,
author = {Barber, Gillian L. and Grehan, Laura and Dunne, Jane and Davis, Brian and Qadeer, Hamza},
title = {Towards an educational framework for integrating AI education into second-level education in Ireland: Preliminary insights from a national workshop series on AI ethics and privacy (Work in Progress)},
year = {2024},
isbn = {9798400711596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701268.3701275},
doi = {10.1145/3701268.3701275},
abstract = {As Artificial Intelligence (AI) becomes increasingly pervasive in our lives, it is vital to enhance the AI literacy of all citizens. Young adults, for example, must be equipped with adequate understanding of AI to prepare them for the responsible use of AI now and into the future. We offer insights from the national pilot of ‘AI in My Life’, an education program designed to help young people across Ireland navigate the Age of AI safely and effectively. Targeted at Transition Year secondary school students (typically aged 15-16 years), the project is a teacher-led modular workshop series focused on the interplay of AI, ethics, and privacy in students’ lives. The program aims to embolden and empower students and teachers to learn about AI and reflect on how it affects them and others. We outline participants’ perceptions of the program’s Student Ambassador feature, which sees AI researchers and undergraduate Data Science students visit schools to deliver taster modules. Our initial evaluation, combined with strong interest and uptake among schools, suggests that our program can help meet the substantial untapped need for AI literacy resources among Irish second-level schools.},
booktitle = {Proceedings of the 2024 Conference on Human Centred Artificial Intelligence - Education and Practice},
pages = {29–33},
numpages = {5},
keywords = {Artificial Intelligence, AI Pedagogy, AI Curriculum Development},
location = {
},
series = {HCAIep '24}
}

@inproceedings{10.1145/3641822.3641870,
author = {Sera, Rie and Washizaki, Hironori and Chen, Junyan and Fukazawa, Yoshiaki and Taga, Masahiro and Nakagawa, Kazuyuki and Sakai, Yusuke and Honda, Kiyoshi},
title = {Development of Data-driven Persona Including User Behavior and Pain Point through Clustering with User Log of B2B Software},
year = {2024},
isbn = {9798400705335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641822.3641870},
doi = {10.1145/3641822.3641870},
abstract = {Persona --- fictional user profiles --- are used to identify user requirements in software engineering. However, methods targeting revisions, especially for existing B2B services, remain sparse. This paper proposes a method that integrates several models, including k-means clustering, term frequency-inverse document frequency (TF-IDF), and generative AI. Users' behavior tendencies, pain points, and other attributes are output solely from clickstream log data, bypassing the traditional survey-based approaches of previous studies. Clickstreams are vectorized and categorized, whereas users are further analyzed on the basis of time and content of their clickstreams. A case study was conducted with evaluations carried out both quantitatively and qualitatively. The results suggest that, although some parameters still need improvement, fairly rated persona outcomes were attained.},
booktitle = {Proceedings of the 2024 IEEE/ACM 17th International Conference on Cooperative and Human Aspects of Software Engineering},
pages = {85–90},
numpages = {6},
keywords = {persona, data-driven design, pain point, clustering, user experience, user behavior, user analytics, machine learning, data science},
location = {Lisbon, Portugal},
series = {CHASE '24}
}

@inproceedings{10.1145/3678884.3687137,
author = {Zheng, Qingxiao and Lu, Xi and Jin, Qiao and Jain, Jitesh and Meadan-Kaplansky, Hedda and Shi, Humphrey and Xiong, Jinjun and Huang, Yun},
title = {Towards Responsible Use of Large Multi-modal AI to Analyze Human Social Behaviors},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678884.3687137},
doi = {10.1145/3678884.3687137},
abstract = {This SIG is primarily designed for researchers and practitioners interested in exploring the utilization of multimodal artificial intelligence (AI) to understand and analyze human behaviors across various domains. It will particularly benefit professionals in UX design and research, cognitive science, education, psychology, and data science who are pursuing innovative ways to integrate multimodal data with AI to gain deeper behavioral insights. The session will focus on using AI to track, visualize, and generate insights around both verbal and non-verbal social interactions for various purposes, such as video question-answering. Discussions will cover practical applications in settings such as online learning environments, telecommunication, and social media platforms. This SIG will also provoke reflection on the ethical stewardship of AI, highlighting the importance of responsible usage to mitigate concerns such as algorithmic bias and data privacy.},
booktitle = {Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
pages = {663–665},
numpages = {3},
keywords = {ai, generative ai, human social behaviors, large multimodal models (lmms), video analysis},
location = {San Jose, Costa Rica},
series = {CSCW Companion '24}
}

@inproceedings{10.1145/3626252.3630815,
author = {Newman, Pax and Opdahl, Tyanin and Liu, Yudong and Wehrwein, Scott and Elglaly, Yasmine N.},
title = {Crafting Disability Fairness Learning in Data Science: A Student-Centric Pedagogical Approach},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630815},
doi = {10.1145/3626252.3630815},
abstract = {Ensuring the fairness of machine learning (ML) systems for individuals with disabilities is crucial. Proactive measures are required to identify and mitigate biases in data and models, thereby preventing potential harm or bias against people with disabilities. While previous research on ML fairness education primarily concentrated on gender and race fairness, the domain of disability fairness has received comparatively little attention. Addressing this gap, we adopted a student-centric approach to craft a disability fairness teaching intervention. A focus group of students experienced in ML and accessible computing underscored the significance of engagement and scaffolding strategies for effectively learning intricate topics. Consequently, we crafted a disability fairness hands-on programming assignment that delves into uncovering disability bias with a lens that takes intersectionality into account. The assignment was tailored for an introductory undergraduate data science (DS) course. We employed reflective questions and surveys to gauge the effectiveness of our approach. The findings indicate the success of our approach in promoting a deeper understanding of disability fairness within the context of DS education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {944–950},
numpages = {7},
keywords = {cs education, data science, disability, fairness, machine learning},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3606431.3606440,
author = {Colmenares, Eduardo},
title = {Programming Many-Core Architectures (GPUs) Using CUDA},
year = {2023},
issue_date = {April 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {38},
number = {7},
issn = {1937-4771},
abstract = {Many-core devices also known as Graphical Processing Units (GPUs) have dominated the floating point race since 2013 and their benefits have been fueling the current artificial intelligence (AI), machine learning (ML), deep learning (DL), and data science (DS) revolution. Many of these fields benefit from the use of specialized frameworks, such as Tensor Flow, Keras, etc. Although extremely helpful for AI, ML, DL and DS related purposes, the use of these frameworks does not provide the user any knowledge about how to harness the potential of the underlying hardware for different applications or different fields to those mentioned above. This tutorial intends to provide interested students and faculty a basic, but strong hands-on programming foundation regarding good practices and potential capabilities of modern GPUs. The tutorial focuses on GPU programming and not AI Frameworks.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {85},
numpages = {1}
}

@inproceedings{10.1145/3643916.3645030,
author = {Khajezade, Mohamad and Wu, Jie JW and Fard, Fatemeh Hendijani and Rodriguez-Perez, Gema and Shehata, Mohamed Sami},
title = {Investigating the Efficacy of Large Language Models for Code Clone Detection},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3645030},
doi = {10.1145/3643916.3645030},
abstract = {Large Language Models (LLMs) have demonstrated remarkable success in various natural language processing and software engineering tasks, such as code generation. The LLMs are mainly utilized in the prompt-based zero/few-shot paradigm to guide the model in accomplishing the task. GPT-based models are one of the popular ones studied for tasks such as code comment generation or test generation. These tasks are 'generative' tasks. However, there is limited research on the usage of LLMs for 'non-generative' tasks such as classification using the prompt-based paradigm. In this preliminary exploratory study, we investigated the applicability of LLMs for Code Clone Detection (CCD), a non-generative task. By building a mono-lingual and cross-lingual CCD dataset derived from CodeNet, we first investigated two different prompts using ChatGPT to detect Type-4 code clones in Java-Java and Java-Ruby pairs in a zero-shot setting. We then conducted an analysis to understand the strengths and weaknesses of ChatGPT in CCD. ChatGPT surpasses the baselines in cross-language CCD attaining an F1-score of 0.877 and achieves comparable performance to fully fine-tuned models for mono-lingual CCD, with an F1-score of 0.878. Also, the prompt and the difficulty level of the problems has an impact on the performance of ChatGPT. Finally, we provide insights and future directions based on our initial analysis1.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {161–165},
numpages = {5},
keywords = {large language models, code clone detection, zero-shot learning, few-shot learning},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3597503.3639585,
author = {Imran, Mia Mohammad and Chatterjee, Preetha and Damevski, Kostadin},
title = {Shedding Light on Software Engineering-specific Metaphors and Idioms},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639585},
doi = {10.1145/3597503.3639585},
abstract = {Use of figurative language, such as metaphors and idioms, is common in our daily-life communications, and it can also be found in Software Engineering (SE) channels, such as comments on GitHub. Automatically interpreting figurative language is a challenging task, even with modern Large Language Models (LLMs), as it often involves subtle nuances. This is particularly true in the SE domain, where figurative language is frequently used to convey technical concepts, often bearing developer affect (e.g., 'spaghetti code). Surprisingly, there is a lack of studies on how figurative language in SE communications impacts the performance of automatic tools that focus on understanding developer communications, e.g., bug prioritization, incivility detection. Furthermore, it is an open question to what extent state-of-the-art LLMs interpret figurative expressions in domain-specific communication such as software engineering. To address this gap, we study the prevalence and impact of figurative language in SE communication channels. This study contributes to understanding the role of figurative language in SE, the potential of LLMs in interpreting them, and its impact on automated SE communication analysis. Our results demonstrate the effectiveness of fine-tuning LLMs with figurative language in SE and its potential impact on automated tasks that involve affect. We found that, among three state-of-the-art LLMs, the best improved fine-tuned versions have an average improvement of 6.66% on a GitHub emotion classification dataset, 7.07% on a GitHub incivility classification dataset, and 3.71% on a Bugzilla bug report prioritization dataset.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {207},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3537674.3554748,
author = {Zheng, Yong and Liu, Arnold and Zheng, Shuaiqi},
title = {Pressure Test: Finding Appropriate Data Size for Practice in Data Science Education},
year = {2022},
isbn = {9781450393911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3537674.3554748},
doi = {10.1145/3537674.3554748},
abstract = {Data science, such as data analytics, data mining, machine learning, became one popular curriculum in information technology educations. The lectures on these topics cannot stand alone without coding practice on real-world data sets. Some instructors prefer to utilize small data sets for practice in classroom or assignments, which limits experimental experiences and may even bring misleading experiences to students. Others may try to assign large data sets to students, but students may not be able to bear with the running time due to the efficiency issue raised by several factors (e.g., data size, algorithm complexity, computing power, etc.). In this paper, we first learned students’ preferences on the scalability of data sets for practice in data science courses, and performed experimental analysis by running different data science algorithms over both student laptops and personal/office computers, in order to deliver a suggestion about the appropriate data size for practice in multiple scenarios (e.g., in-class practice, assignments, class projects, research projects, etc.). We believe that our findings are valuable to help instructors prepare and assign real-world data sets to students in data science curriculum.},
booktitle = {Proceedings of the 23rd Annual Conference on Information Technology Education},
pages = {142–149},
numpages = {8},
keywords = {data science, data size, experimental analysis, information technology education, running efficiency, scalability},
location = {Chicago, IL, USA},
series = {SIGITE '22}
}

@inproceedings{10.1145/3652620.3687807,
author = {Yang, Yujing and Chen, Boqi and Chen, Kua and Mussbacher, Gunter and Varr\'{o}, D\'{a}niel},
title = {Multi-step Iterative Automated Domain Modeling with  Large Language Models},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687807},
doi = {10.1145/3652620.3687807},
abstract = {Domain modeling, which represents the concepts and relationships in a problem domain, is an essential part of software engineering. As large language models (LLMs) have recently exhibited remarkable ability in language understanding and generation, many approaches are designed to automate domain modeling with LLMs. However, these approaches usually formulate all input information to the LLM in a single step. Our previous single-step approach resulted in many missing modeling elements and advanced patterns. This paper introduces a novel framework designed to enhance fully automated domain model generation. The proposed multi-step automated domain modeling approach extracts model elements (e.g., classes, attributes, and relationships) from problem descriptions. The approach includes instructions and human knowledge in each step and uses an iterative process to identify complex patterns, repeatedly extracting the pattern from various instances and then synthesizing these extractions into a summarized overview. Furthermore, the framework incorporates a self-reflection mechanism. This mechanism assesses each generated model element, offering self-feedback for necessary modifications or removals, and integrates the domain model with the generated self-feedback. The proposed approach is assessed in experiments, comparing it with a baseline single-step approach from our earlier work. Experiments demonstrate a significant improvement over our earlier work, with a 22.71% increase in the F1-score for identifying classes, 75.18% for relationships, and a 10.39% improvement for identifying the player-role pattern, with comparable performance for attributes. Our approach, dataset, and evaluation provide valuable insight for future research in automated LLM-based domain modeling.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {587–595},
numpages = {9},
keywords = {domain modeling, large language models, few-shot learning, prompt engineering},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@article{10.1145/3686150,
author = {Cao, Longbing and Liu, Qing},
title = {COVID-19 Modeling: A Review},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3686150},
doi = {10.1145/3686150},
abstract = {The SARS-CoV-2 viruses and their triggered COVID-19 pandemic have fundamentally reshaped the world in almost every aspect, their evolution and influences remain. While over a million of literature have been produced on these unprecedented, overwhelming global disaster, one critical question is open: How has COVID-19 been quantified globally? This further inspires many other questions: What COVID-19 problems have been modeled? How have modeling methods in areas such as epidemiology, artificial intelligence (AI), data science, machine learning, deep learning, mathematics and social science played their roles in characterizing COVID-19? Where are the gaps and issues of these COVID-19 modeling studies? What are the lessons for quantifying future disasters? Answering these questions involves the analysis of a very broad spectrum of literature across different disciplines and domains. Distinguishing from specific efforts, this review takes the first attempt to generate a systematic, structured and contrastive landscape and taxonomy of global COVID-19 modeling. First, the surveyed problems span over a full range of COVID-19, including epidemic transmission processes, case identification and tracing, infection diagnosis and medical treatments, non-pharmaceutical interventions and their influence, drug and vaccine development, psychological, economic and social influence and impact, and misinformation, and so on. Second, the reviewed modeling methods traverse all relevant disciplines, from statistic modeling to epidemic modeling, medical analysis, biomedical analysis, AI, deep and machine learning, analytics, and simulation. Critical analyses further identify significant issues and gaps, for example, simple techniques and similar problems have been overwhelmingly addressed everywhere, while intrinsic and foundational issues and deep insights have been overlooked. The review discloses significant opportunities for more deeply, effectively and uniquely quantifying COVID-19-like global disasters from their intrinsic working mechanisms, interactions and dynamics.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {10},
numpages = {42},
keywords = {COVID-19, SARS-CoV-2, coronavirus, pandemic, COVID-19 modeling, epidemic transmission, artificial intelligence (AI), data science, machine learning, deep learning, modeling, epidemiological modeling, forecasting, prediction, biomedical analysis, statistical modeling, mathematical modeling, data-driven discovery, domain-driven modeling, simulation, influence analysis, impact modeling}
}

@inproceedings{10.1145/3510454.3517067,
author = {d'Aloisio, Giordano},
title = {Quality-driven machine learning-based data science pipeline realization: a software engineering approach},
year = {2022},
isbn = {9781450392235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510454.3517067},
doi = {10.1145/3510454.3517067},
abstract = {The recently wide adoption of data science approaches to decision making in several application domains (such as health, business and even education) open new challenges in engineering and implementation of this systems. Considering the big picture of data science, Machine learning is the wider used technique and due to its characteristics, we believe that a better engineering methodology and tools are needed to realize innovative data-driven systems able to satisfy the emerging quality attributes (such as, debias and fariness, explainability, privacy and ethics, sustainability). This research project will explore the following three pillars: i) identify key quality attributes, formalize them in the context of data science pipelines and study their relationships; ii) define a new software engineering approach for data-science systems development that assures compliance with quality requirements; iii) implement tools that guide IT professionals and researchers in the realization of ML-based data science pipelines since the requirement engineering. Moreover, in this paper we also presents some details of the project showing how the feature models and model-driven engineering can be leveraged to realize our project.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
pages = {291–293},
numpages = {3},
keywords = {machine learning, model-driven, pipelines, product-line architecture, software quality},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@article{10.1145/3650114,
author = {Ning, Zheng and Tian, Yuan and Zhang, Zheng and Zhang, Tianyi and Li, Toby Jia-Jun},
title = {Insights into Natural Language Database Query Errors: from Attention Misalignment to User Handling Strategies},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {2160-6455},
url = {https://doi.org/10.1145/3650114},
doi = {10.1145/3650114},
abstract = {Querying structured databases with natural language (NL2SQL) has remained a difficult problem for years. Recently, the advancement of machine learning (ML), natural language processing (NLP), and large language models (LLM) have led to significant improvements in performance, with the best model achieving ∼85% percent accuracy on the benchmark Spider dataset. However, there is a lack of a systematic understanding of the types, causes, and effectiveness of error-handling mechanisms of errors for erroneous queries nowadays. To bridge the gap, a taxonomy of errors made by four representative NL2SQL models was built in this work, along with an in-depth analysis of the errors. Second, the causes of model errors were explored by analyzing the model-human attention alignment to the natural language query. Last, a within-subjects user study with 26 participants was conducted to investigate the effectiveness of three interactive error-handling mechanisms in NL2SQL. Findings from this article shed light on the design of model structure and error discovery and repair strategies for natural language data query interfaces in the future.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = dec,
articleno = {25},
numpages = {32},
keywords = {Empirical study, human-computer interaction, error handling, database systems}
}

@inproceedings{10.1145/3661167.3661172,
author = {Huotala, Aleksi and Kuutila, Miikka and Ralph, Paul and M\"{a}ntyl\"{a}, Mika},
title = {The Promise and Challenges of Using LLMs to Accelerate the Screening Process of Systematic Reviews},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661172},
doi = {10.1145/3661167.3661172},
abstract = {Context: Systematic review (SR) is a popular research method in software engineering (SE). However, conducting an SR takes an average of 67 weeks. Thus, automating any step of the SR process could reduce the effort associated with SRs. Objective: Our objective is to investigate the extent to which Large Language Models (LLMs) can accelerate title-abstract screening by (1) simplifying abstracts for human screeners, and (2) automating title-abstract screening entirely. Method: We performed an experiment where human screeners performed title-abstract screening for 20 papers with both original and simplified abstracts from a prior SR. The experiment with human screeners was reproduced by instructing GPT-3.5 and GPT-4 LLMs to perform the same screening tasks. We also studied whether different prompting techniques (Zero-shot (ZS), One-shot (OS), Few-shot (FS), and Few-shot with Chain-of-Thought (FS-CoT) prompting) improve the screening performance of LLMs. Lastly, we studied if redesigning the prompt used in the LLM reproduction of title-abstract screening leads to improved screening performance. Results: Text simplification did not increase the screeners’ screening performance, but reduced the time used in screening. Screeners’ scientific literacy skills and researcher status predict screening performance. Some LLM and prompt combinations perform as well as human screeners in the screening tasks. Our results indicate that a more recent LLM (GPT-4) is better than its predecessor LLM (GPT-3.5). Additionally, Few-shot and One-shot prompting outperforms Zero-shot prompting. Conclusion: Using LLMs for text simplification in the screening process does not significantly improve human performance. Using LLMs to automate title-abstract screening seems promising, but current LLMs are not significantly more accurate than human screeners. To recommend the use of LLMs in the screening process of SRs, more research is needed. We recommend future SR studies to publish replication packages with screening data to enable more conclusive experimenting with LLM screening.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {262–271},
numpages = {10},
keywords = {ChatGPT, GPT-3.5, GPT-4, LLMs, Screening Process of Systematic Reviews, Text Simplification},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3597503.3639223,
author = {Imran, Mia Mohammad and Chatterjee, Preetha and Damevski, Kostadin},
title = {Uncovering the Causes of Emotions in Software Developer Communication Using Zero-shot LLMs},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639223},
doi = {10.1145/3597503.3639223},
abstract = {Understanding and identifying the causes behind developers' emotions (e.g., Frustration caused by 'delays in merging pull requests') can be crucial towards finding solutions to problems and fostering collaboration in open-source communities. Effectively identifying such information in the high volume of communications across the different project channels, such as chats, emails, and issue comments, requires automated recognition of emotions and their causes. To enable this automation, large-scale software engineering-specific datasets that can be used to train accurate machine learning models are required. However, such datasets are expensive to create with the variety and informal nature of software projects' communication channels.In this paper, we explore zero-shot LLMs that are pre-trained on massive datasets but without being fine-tuned specifically for the task of detecting emotion causes in software engineering: ChatGPT, GPT-4, and flan-alpaca. Our evaluation indicates that these recently available models can identify emotion categories when given detailed emotions, although they perform worse than the top-rated models. For emotion cause identification, our results indicate that zero-shot LLMs are effective at recognizing the correct emotion cause with a BLEU-2 score of 0.598. To highlight the potential use of these techniques, we conduct a case study of the causes of Frustration in the last year of development of a popular open-source project, revealing several interesting insights.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {182},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3522664.3528610,
author = {Borges, Olimar and Lenarduzzi, Valentina and Prikladnicki, Rafael},
title = {Preliminary insights to enable automation of the software development process in software StartUps: an investigation study from the use of artificial intelligence and machine learning},
year = {2022},
isbn = {9781450392754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3522664.3528610},
doi = {10.1145/3522664.3528610},
abstract = {Artificial Intelligence (AI) and Machine Learning (ML) tools and techniques have increasingly effectively supported Software Engineering (SE) tasks, whether for requirements classification, software refactoring, defect prediction, and many others. In the context of software StartUps, where innovative and scalable software products are developed, dealing with the pressure of fast delivery of a working solution becomes a challenging factor. We aim to investigate AI and ML techniques used by SE practitioners and entrepreneurs to support their Software Development Processes (SDP) and thus enable their use by software StartUps. We seek to identify this information through the application of an online Survey instrument, mainly disseminated in Brazil and Finland. This preliminary study provides insights that can support improving the SDP in StartUps.},
booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
pages = {37–38},
numpages = {2},
keywords = {SWEBOK, StartUp, artificial intelligence, development process, machine learning},
location = {Pittsburgh, Pennsylvania},
series = {CAIN '22}
}

@inproceedings{10.1109/ASE51524.2021.9678580,
author = {Tantithamthavorn, Chakkrit (Kla) and Jiarpakdee, Jirayus},
title = {Explainable AI for software engineering},
year = {2022},
isbn = {9781665403375},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE51524.2021.9678580},
doi = {10.1109/ASE51524.2021.9678580},
abstract = {The success of software engineering projects largely depends on complex decision-making. For example, which tasks should a developer do first, who should perform this task, is the software of high quality, is a software system reliable and resilient enough to deploy, etc. However, erroneous decision-making for these complex questions is costly in terms of money and reputation. Thus, Artificial Intelligence/Machine Learning (AI/ML) techniques have been widely used in software engineering for developing software analytics tools and techniques to improve decision-making, developer productivity, and software quality. However, the predictions of such AI/ML models for software engineering are still not practical (i.e., coarse-grained), not explainable, and not actionable. These concerns often hinder the adoption of AI/ML models in software engineering practices. In addition, many recent studies still focus on improving the accuracy, while a few of them focus on improving explainability. Are we moving in the right direction? How can we better improve the SE community (both research and education)?In this tutorial, we first provide a concise yet essential introduction to the most important aspects of Explainable AI and a hands-on tutorial of Explainable AI tools and techniques. Then, we introduce the fundamental knowledge of defect prediction (an example application of AI for Software Engineering). Finally, we demonstrate three successful case studies on how Explainable AI techniques can be used to address the aforementioned challenges by making the predictions of software defect prediction models more practical, explainable, and actionable. The materials are available at https://xai4se.github.io.},
booktitle = {Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1–2},
numpages = {2},
keywords = {explainable AI, software engineering},
location = {Melbourne, Australia},
series = {ASE '21}
}

@inproceedings{10.1145/3701625.3701695,
author = {Cabral, Raphael and Kalinowski, Marcos},
title = {Investigating the Impact of SOLID Design Principles on Machine Learning Code Understanding},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701695},
doi = {10.1145/3701625.3701695},
abstract = {[Context] Applying design principles has long been acknowledged as beneficial for understanding and maintainability in traditional software projects. These benefits may similarly hold for Machine Learning (ML) projects, which involve iterative experimentation with data, models, and algorithms. However, ML components are often developed by data scientists with diverse educational backgrounds, potentially resulting in code that doesn’t adhere to software design best practices. [Goal] To better understand this phenomenon, we investigated the impact of the SOLID design principles on ML code understanding. [Method] We conducted a controlled experiment with three independent trials involving 100 data scientists. We restructured real industrial ML code that did not use SOLID principles. Within each trial, one group was presented with the original ML code, while the other was presented with ML code incorporating SOLID principles. Participants of both groups were asked to analyze the code and fill out a questionnaire that included both open-ended and closed-ended questions on their understanding. [Results] The dissertation results provide statistically significant evidence that adopting the SOLID design principles can improve code understanding within ML projects. [Conclusion] We put forward that software engineering design principles should be spread within the data science community and considered for enhancing the quality and maintainability of ML code.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {703–705},
numpages = {3},
keywords = {SOLID Design Principles, Machine Learning, Code Understanding},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1109/ASE56229.2023.00206,
author = {Le, Van-Hoang and Zhang, Hongyu},
title = {Log Parsing: How Far Can ChatGPT Go?},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00206},
doi = {10.1109/ASE56229.2023.00206},
abstract = {Software logs play an essential role in ensuring the reliability and maintainability of large-scale software systems, as they are often the sole source of runtime information. Log parsing, which converts raw log messages into structured data, is an important initial step towards downstream log analytics. In recent studies, ChatGPT, the current cutting-edge large language model (LLM), has been widely applied to a wide range of software engineering tasks. However, its performance in automated log parsing remains unclear. In this paper, we evaluate ChatGPT's ability to undertake log parsing by addressing two research questions. (1) Can ChatGPT effectively parse logs? (2) How does ChatGPT perform with different prompting methods? Our results show that ChatGPT can achieve promising results for log parsing with appropriate prompts, especially with few-shot prompting. Based on our findings, we outline several challenges and opportunities for ChatGPT-based log parsing.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1699–1704},
numpages = {6},
keywords = {log analytics, log parsing, large language model, ChatGPT},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3643661.3643952,
author = {Astekin, Merve and Hort, Max and Moonen, Leon},
title = {An Exploratory Study on How Non-Determinism in Large Language Models Affects Log Parsing},
year = {2024},
isbn = {9798400705649},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643661.3643952},
doi = {10.1145/3643661.3643952},
abstract = {Most software systems used in production generate system logs that provide a rich source of information about the status and execution behavior of the system. These logs are commonly used to ensure the reliability and maintainability of software systems. The first step toward automated log analysis is generally log parsing, which aims to transform unstructured log messages into structured log templates and extract the corresponding parameters.Recently, Large Language Models (LLMs) such as ChatGPT have shown promising results on a wide range of software engineering tasks, including log parsing. However, the extent to which non-determinism influences log parsing using LLMs remains unclear. In particular, it is important to investigate whether LLMs behave consistently when faced with the same log message multiple times.In this study, we investigate the impact of non-determinism in state-of-the-art LLMs while performing log parsing. Specifically, we select six LLMs, including both paid proprietary and free-to-use models, and evaluate their non-determinism on 16 system logs obtained from a selection of mature open-source projects. The results of our study reveal varying degrees of non-determinism among models. Moreover, they show that there is no guarantee for deterministic results even with a temperature of zero.},
booktitle = {Proceedings of the ACM/IEEE 2nd International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering},
pages = {13–18},
numpages = {6},
keywords = {log parsing, large language model, robustness, non-determinism, consistency},
location = {Lisbon, Portugal},
series = {InteNSE '24}
}

@inproceedings{10.1145/3664646.3664778,
author = {Biyani, Param and Bajpai, Yasharth and Radhakrishna, Arjun and Soares, Gustavo and Gulwani, Sumit},
title = {RUBICON: Rubric-Based Evaluation of Domain-Specific Human AI Conversations},
year = {2024},
isbn = {9798400706851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664646.3664778},
doi = {10.1145/3664646.3664778},
abstract = {Evaluating conversational assistants, such as GitHub Copilot Chat, poses a significant challenge for tool builders in the domain of Software Engineering. These assistants rely on language models and chat-based user experiences, rendering their evaluation with respect to the quality of the Human-AI conversations complicated. Existing general-purpose metrics for measuring conversational quality found in literature are inadequate for appraising domain-specific dialogues due to their lack of contextual sensitivity.
 
In this paper, we present RUBICON, a technique for evaluating domain-specific Human-AI conversations. RUBICON leverages large language models to generate candidate rubrics for assessing conversation quality and employs a selection process to choose the subset of rubrics based on their performance in scoring conversations. In our experiments, RUBICON effectively learns to differentiate conversation quality, achieving higher accuracy and yield rates than existing baselines.},
booktitle = {Proceedings of the 1st ACM International Conference on AI-Powered Software},
pages = {161–169},
numpages = {9},
keywords = {AI-assisted Programming, Conversation Evaluation, Conversational AI, Evaluation Metrics, Human-AI interaction, User Satisfaction},
location = {Porto de Galinhas, Brazil},
series = {AIware 2024}
}

@inproceedings{10.1145/3639477.3639719,
author = {Di, Peng and Li, Jianguo and Yu, Hang and Jiang, Wei and Cai, Wenting and Cao, Yang and Chen, Chaoyu and Chen, Dajun and Chen, Hongwei and Chen, Liang and Fan, Gang and Gong, Jie and Gong, Zi and Hu, Wen and Guo, Tingting and Lei, Zhichao and Li, Ting and Li, Zheng and Liang, Ming and Liao, Cong and Liu, Bingchang and Liu, Jiachen and Liu, Zhiwei and Lu, Shaojun and Shen, Min and Wang, Guangpei and Wang, Huan and Wang, Zhi and Xu, Zhaogui and Yang, Jiawei and Ye, Qing and Zhang, Gehao and Zhang, Yu and Zhao, Zelin and Zheng, Xunjin and Zhou, Hailian and Zhu, Lifu and Zhu, Xianying},
title = {CodeFuse-13B: A Pretrained Multi-lingual Code Large Language Model},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639719},
doi = {10.1145/3639477.3639719},
abstract = {Code Large Language Models (Code LLMs) have gained significant attention in the industry due to their wide applications in the full lifecycle of software engineering. However, the effectiveness of existing models in understanding non-English inputs for multi-lingual code-related tasks is still far from well studied. This paper introduces CodeFuse-13B, an open-sourced pre-trained code LLM 2. It is specifically designed for code-related tasks with both English and Chinese prompts and supports over 40 programming languages. CodeFuse achieves its effectiveness by utilizing a high-quality pre-training dataset that is carefully filtered by program analyzers and optimized during the training process. Extensive experiments are conducted using real-world usage scenarios, the industry-standard benchmark HumanEval-x, and the specially designed CodefuseEval for Chinese prompts. To assess the effectiveness of CodeFuse, we actively collected valuable human feedback from the AntGroup's software development process where CodeFuse has been successfully deployed. The results demonstrate that CodeFuse-13B achieves a HumanEval pass@1 score of 37.10%, positioning it as one of the top multi-lingual code LLMs with similar parameter sizes. In practical scenarios, such as code generation, code translation, code comments, and testcase generation, CodeFuse performs better than other models when confronted with Chinese prompts.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {418–429},
numpages = {12},
keywords = {code large language models, multi-lingual, chinese prompts},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@inproceedings{10.1145/3593434.3593458,
author = {Valov\'{y}, Marcel},
title = {Psychological Aspects of Pair Programming: A Mixed-methods Experimental Study},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593434.3593458},
doi = {10.1145/3593434.3593458},
abstract = {With the recent advent of artificially intelligent pairing partners in software engineering, it is interesting to renew the study of the psychology of pairing. Pair programming provides an attractive way of teaching software engineering to university students. Its study can also lead to a better understanding of the needs of professional software engineers in various programming roles and for the improvement of the concurrent pairing software. [Objective] This preliminary study aimed to gain quantitative and qualitative insights into pair programming, especially students’ attitudes towards its specific roles and what they require from the pairing partners. The research's goal is to use the findings to design further studies on pairing with artificial intelligence. [Method] Using a mixed-methods and experimental approach, we distinguished the effects of the pilot, navigator, and solo roles on (N = 35) students’ intrinsic motivation. Four experimental sessions produced a rich data corpus in two software engineering university classrooms. It was quantitatively investigated using the Shapiro-Wilk normality test and one-way analysis of variance (ANOVA) to confirm the relations and significance of variations in mean intrinsic motivation in different roles. Consequently, seven semi-structured interviews were conducted with the experiment's participants. The qualitative data excerpts were subjected to the thematic analysis method in an essentialist way. [Results] The systematic coding interview transcripts elucidated the research topic by producing seven themes for understanding the psychological aspects of pair programming and for its improvement in university classrooms. Statistical analysis of 612 self-reported intrinsic motivation inventories confirmed that students find programming in pilot-navigator roles more interesting and enjoyable than programming simultaneously. [Conclusion] The executed experimental settings are viable for inspecting the associations between students’ attitudes and the distributed cognition practice. The preliminary results illuminate the psychological aspects of the pilot-navigator roles and reveal many areas for improvement. The results also provide a strong basis for conducting further studies with the same design involving the big five personality and intrinsic motivation on using artificial intelligence in pairing and to allow comparison of those results with results of pairing with human partners.},
booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
pages = {210–216},
numpages = {7},
keywords = {Agile development, Intrinsic motivation, Pair programming, Software engineering, Thematic analysis},
location = {Oulu, Finland},
series = {EASE '23}
}

@inproceedings{10.1145/3603273.3631191,
author = {Tang, Zhu and Cui, YiChuan and Peng, SiYong and Dai, GuangHua and Yang, JianJun and Duan, YanHong},
title = {Research on the Design of Sensor Intelligent Defense System},
year = {2024},
isbn = {9798400708268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603273.3631191},
doi = {10.1145/3603273.3631191},
abstract = {This paper analyzes the necessity of building an intelligent defense system for sensors, systematically designs the intelligent defense system from three aspects: hardware composition, Software architecture and information flow interaction, and puts forward six key support technologies for system design, namely, integrated management and control technology, Internet of Things technology, Big data and cloud computing technology, artificial intelligence technology, intelligent planning technology, and auxiliary decision-making technology, which have important application value.},
booktitle = {Proceedings of the 2023 International Conference on Advances in Artificial Intelligence and Applications},
pages = {354–358},
numpages = {5},
keywords = {intelligent defense, sensor, system design},
location = {Wuhan, China},
series = {AAIA '23}
}

@inproceedings{10.1145/3701625.3701700,
author = {de Lima, Vitor Mesaque Alves and Marcacini, Ricardo Marcondes},
title = {Opinion Mining for App Reviews: Identifying and Prioritizing Emerging Issues for Software Maintenance and Evolution},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701700},
doi = {10.1145/3701625.3701700},
abstract = {Opinion mining for app reviews aims to analyze user comments on app stores to support software engineering activities, primarily software maintenance and evolution. One of the main challenges in maintaining software quality is promptly identifying emerging issues, such as bugs. However, manually analyzing these comments is challenging due to the large amount of textual data. Methods based on machine learning have been employed to automate opinion mining and address this issue. Gap. While recent methods have achieved promising results in extracting and categorizing issues from users’ opinions, existing studies mainly focus on assisting software engineers in exploring users’ historical behavior regarding app functionalities and do not explore mechanisms for trend detection and risk classification of emerging issues. Furthermore, these studies do not cover the entire issue analysis process through an unsupervised approach. Contribution. This work advances state of the art in opinion mining for app reviews by proposing an entire automated issue analysis approach to identify, prioritize, and monitor the risk of emerging issues. Our proposal introduces a two-fold approach that (i) identifies possible defective software requirements and trains predictive models for anticipating requirements with a higher probability of negative evaluation and (ii) detect issues in reviews, classifies them in a risk matrix with prioritization levels, and monitors their evolution over time. Additionally, we present a risk matrix construction approach from app reviews using the recent Large Language Models (LLMs). We introduce an analytical data exploration tool that allows engineers to browse the risk matrix, time series, heat map, issue tree, alerts, and notifications. Our goal is to minimize the time between the occurrence of an issue and its correction, enabling the quick identification of problems. Results. We processed over 6.6 million reviews across 20 domains to evaluate our proposal, identifying and ranking the risks associated with nearly 270,000 issues. The results demonstrate the competitiveness of our unsupervised approach compared to existing supervised models. Conclusions. We have proven that opinions extracted from user reviews provide crucial insights into app issues and risks and can be identified early to mitigate their impact. Our opinion mining process implements an entire automated issue analysis with risk-based prioritization and temporal monitoring.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {687–696},
numpages = {10},
keywords = {opinion mining, app reviews, issue detection, issue prioritization, software maintenance and evolution},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3568812.3603483,
author = {Brock, Janet and Gransbury, Isabella and Catet\'{e}, Veronica and Barnes, Tiffany and Grover, Shuchi and Ledeczi, Akos},
title = {Student Attitudes During the Pilot of the Computer Science Frontiers Course},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603483},
doi = {10.1145/3568812.3603483},
abstract = {Motivation. We have created a modular project-based learning curriculum, Computer Science Frontiers (CSF) [1, 8], for secondary students in attempts to increase the persistence of computer science (CS) students in higher education. The CSF course is divided into four different modules (Distributed Computing, Internet of Things, Artificial Intelligence, and Software Engineering), each centered around a topic typically introduced to students only in higher education. Using the block-based programming environment NetsBlox [4], students are able to access various Application Programming Interfaces related to their interests [2, 3]. The goal of this course is to increase student interest in CS during high school - when first career choices occur [7] - in hopes they will persist in CS during their undergraduate studies. Research question. The research question for this study was: How does the Computer Science Frontiers course affect student attitudes towards computer science?Research Methods. We conducted over 20 interviews with students throughout a CSF pilot course that took place over the 2022-2023 school year. Interviews were conducted with at least five students at the end of every module. Two researchers have conducted thematic analysis with student responses from the first two modules [5]: Distributed Computing (DC) and Internet of Things (IoT). First, the two researchers developed a norm by tagging one interview together [6]. Next, the researchers independently coded the rest of the interviews for each module. After completing a single module’s interviews, the researchers met to rectify any discrepancies. Finally, the tags were grouped together based on common themes. Through this process, we found a total of seven themes. Results. The themes found through thematic analysis include: computer science, attitudes towards course, student wants, student struggles, attitudes towards projects, collaboration, and student progression. As a result of this study, we have identified different needs for secondary students with varying background in CS when studying more advanced CS topics, such as IoT. For example, a need of students who have less prior CS knowledge than others may be to review programming concepts in order to be successful in the course. We have also identified a positive change in student’s attitudes towards computer science after the first two modules. These insights provide the CS education community with ways to engage students with concepts that they have not been exposed to and how to increase their interest in CS. Implications. The CSF curriculum is currently online, and is available to computer science instructors. Each module is separated into eight to nine units which are accompanied by activities and teaching guides. This curriculum provides educators with materials and activities to introduce students to more advanced CS topics, either through individual modules or as an entire course. In future research, we plan to use CSF in an outreach program and implement the course in two secondary classrooms in the 2023-2024 school year.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {24–25},
numpages = {2},
keywords = {block-based learning, collaborative learning environment, education research, project-based learning, secondary, socially relevant examples},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@article{10.1145/3672458,
author = {Huang, Qing and Luo, Zhiwen and Xing, Zhenchang and Zeng, Jinshan and Chen, Jieshan and Xu, Xiwei and Chen, Yong},
title = {Revealing the Unseen: AI Chain on LLMs for Predicting Implicit Dataflows to Generate Dataflow Graphs in Dynamically Typed Code},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {7},
issn = {1049-331X},
url = {https://doi.org/10.1145/3672458},
doi = {10.1145/3672458},
abstract = {Dataflow graphs (DFGs) capture definitions (defs) and uses across program blocks, which is a fundamental program representation for program analysis, testing and maintenance. However, dynamically typed programming languages like Python present implicit dataflow issues that make it challenging to determine def-use flow information at compile time. Static analysis methods like Soot and WALA are inadequate for handling these issues, and manually enumerating comprehensive heuristic rules is impractical. Large pre-trained language models (LLMs) offer a potential solution, as they have powerful language understanding and pattern matching abilities, allowing them to predict implicit dataflow by analyzing code context and relationships between variables, functions, and statements in code. We propose leveraging LLMs’ in-context learning ability to learn implicit rules and patterns from code representation and contextual information to solve implicit dataflow problems. To further enhance the accuracy of LLMs, we design a five-step chain of thought (CoT) and break it down into an Artificial Intelligence (AI) chain, with each step corresponding to a separate AI unit to generate accurate DFGs for Python code. Our approach’s performance is thoroughly assessed, demonstrating the effectiveness of each AI unit in the AI Chain. Compared to static analysis, our method achieves 82% higher def coverage and 58% higher use coverage in DFG generation on implicit dataflow. We also prove the indispensability of each unit in the AI Chain. Overall, our approach offers a promising direction for building software engineering tools by utilizing foundation models, eliminating significant engineering and maintenance effort, but focusing on identifying problems for AI to solve.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {183},
numpages = {29},
keywords = {Dataflow graph, AI chain, Large Language Models}
}

@proceedings{10.1145/3627673,
title = {CIKM '24: Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2024 ACM International Conference on Information and Knowledge Management (CIKM 2024). CIKM is traditionally held once a year at different locations all over the world and this year it returns to the United States, hosted in Boise (Idaho) on October 21-25, 2024. Situated along the beautiful foothills of the Rocky Mountains, Boise, Idaho's vibrant capital, is emerging as a hub for technological innovation, offering a dynamic setting for researchers and practitioners to explore new frontiers in information science. After two years of fully virtual conference and two hybrid conference editions due to the COVID19 pandemic, CIKM 2024 is finally hosted again as a full physical conference at the Boise Centre convention center in the heart of Boise downtown.CIKM 2024 is the 33rd running of the conference, which remains the only conference that focuses on the management of both structured and unstructured data, accepting research papers covering databases, information retrieval, and knowledge management sub-disciplines of Computer Science. CIKM 2024 also accepts papers from general areas of data science, machine learning, and artificial intelligence, covering both foundational work and applications. Like the last editions, this one also includes an Industry Day (a full-day event) and one AnalytiCup competition. Papers are solicited in five tracks: full research papers, short research papers, applied research papers, resource papers, and demonstration papers. Besides the presentations of all the accepted papers in the above tracks, the whole conference program includes 12 tutorials, 10 workshops, and three keynote talks. Additionally, a PhD Symposium will bring together senior researchers with PhD students to discuss the exciting work of these early-career researchers who will contribute to shaping tomorrow's research landscape.},
location = {Boise, ID, USA}
}

@inproceedings{10.1145/3478431.3499397,
author = {Skripchuk, James and Shi, Yang and Price, Thomas},
title = {Identifying Common Errors in Open-Ended Machine Learning Projects},
year = {2022},
isbn = {9781450390705},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3478431.3499397},
doi = {10.1145/3478431.3499397},
abstract = {Machine learning (ML) is one of the fastest growing subfields in Computer Science, and it is important to identify ways to improve ML education. A key way to do so is by understanding the common errors that students make when writing ML programs, so they can be addressed. Prior work investigating ML errors has focused on an instructor perspective, but has not looked at student programming artifacts, such as projects and code submissions to understand how these errors occur and which are most common. To address this, we qualitatively coded over 2,500 cells of code from 19 final team projects (63 students) in an upper-division machine learning course. By isolating and codifying common errors and misconceptions across projects, we can identify what ML errors students struggle with. In our results, we found that library usage, hyperparameter tuning, and misusing test data were among the most common errors, and we give examples of how and when they occur. We then provide suggestions on why these misconceptions may occur, and how instructors and software designers can possibly mitigate these errors.},
booktitle = {Proceedings of the 53rd ACM Technical Symposium on Computer Science Education - Volume 1},
pages = {216–222},
numpages = {7},
keywords = {computer science education, data science, machine learning},
location = {Providence, RI, USA},
series = {SIGCSE 2022}
}

@article{10.1145/3638243,
author = {Oakes, Bentley James and Famelis, Michalis and Sahraoui, Houari},
title = {Building Domain-Specific Machine Learning Workflows: A Conceptual Framework for the State of the Practice},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3638243},
doi = {10.1145/3638243},
abstract = {Domain experts are increasingly employing machine learning to solve their domain-specific problems. This article presents to software engineering researchers the six key challenges that a domain expert faces in addressing their problem with a computational workflow, and the underlying executable implementation. These challenges arise out of our conceptual framework which presents the “route” of transformations that a domain expert may choose to take while developing their solution.To ground our conceptual framework in the state of the practice, this article discusses a selection of available textual and graphical workflow systems and their support for the transformations described in our framework. Example studies from the literature in various domains are also examined to highlight the tools used by the domain experts as well as a classification of the domain specificity and machine learning usage of their problem, workflow, and implementation.The state of the practice informs our discussion of the six key challenges, where we identify which challenges and transformations are not sufficiently addressed by available tools. We also suggest possible research directions for software engineering researchers to increase the automation of these tools and disseminate best-practice techniques between software engineering and various scientific domains.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {91},
numpages = {50},
keywords = {Computational workflow, workflow composition, domain experts, machine learning, machine learning pipelines, software engineering framework}
}

@article{10.5555/3581625.3581631,
author = {Chandrasekar, Prashant and Fox, Edward A.},
title = {Teaching the Design and Development of a Modern Information Retrieval (IR) System},
year = {2022},
issue_date = {November 2022},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {38},
number = {5},
issn = {1937-4771},
abstract = {We report on our research on aspects of computing education related to teaching the design and development of a modern information retrieval (IR) system (i.e., about search engines, supporting exploration, and using text analytics). We show the success of a new methodology that integrates concepts from human-computer interaction, artificial intelligence (AI), and software engineering, with information systems. We describe how problem-based learning can be successfully applied, enabled by having each of the five teams, that collaborate to build a next generation IR system, guided by a researcher who further motivates them in this graduate course. The methodology brings together concepts from User-eXperience (UX) research, and ideas central to building a service-oriented architecture. We show that the methodology is easy to learn and easy to use. The students rate the overall system solution highly, and explain how the methodology is a key reason.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {65–74},
numpages = {10}
}

@inproceedings{10.1145/3583780.3615317,
author = {Shah, Chirag},
title = {Generative AI and the Future of Information Access},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615317},
doi = {10.1145/3583780.3615317},
abstract = {The prominent model of retrieving, evaluating, and using relevant information from databases, collections, and the web is going through a significant transformation. This is largely due to wide-scale availability of various generative AI systems that can take in natural language inputs and generate highly customized natural language text, images, audio, and videos. This transformation in how people seek and access information will have profound impacts on users, developers, and policymakers. It is already changing many sectors including education, health, and commerce. But the hopes and hypes of generative AI are often not clear as we get swept up by either the current capabilities and limitations of this technology in the short term or fear from speculative future in the long term. Instead, I believe we need to approach this area pragmatically and with scientific curiosity, scholarly rigor, and societal responsibility. In this talk, I will highlight some of the opportunities and challenges for information access stemming from recent advancements in generative AI. For instance, there are new possibilities now for addressing accessibility, low-resource domains, and bias in training data using generative AI tools. On the other hand, there are new challenges concerning hallucination, toxicity, and information provenance. It is clear that we want to benefit from what AI systems are capable of, but how do we do that while curbing some of these problems? I will argue that the solution is multifaceted and complex -- some will require technical advancements and others will call for policy changes. We will need to not only build information systems with fairness, transparency, and accountability in mind, but also train a new generation of developers, policymakers, and of course the users. The goal here is to cut through both hype and fear and think pragmatically about the future of information access.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {3},
numpages = {1},
keywords = {generative AI, information access},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00098,
author = {Chimalakonda, Sridhar and Das, Debeshee and Mathai, Alex and Tamilselvam, Srikanth and Kumar, Atul},
title = {The Landscape of Source Code Representation Learning in AI-Driven Software Engineering Tasks},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00098},
doi = {10.1109/ICSE-Companion58688.2023.00098},
abstract = {Appropriate representation of source code and its relevant properties form the backbone of Artificial Intelligence (AI)/ Machine Learning (ML) pipelines for various software engineering (SE) tasks such as code classification, bug prediction, code clone detection, and code summarization. In the literature, researchers have extensively experimented with different kinds of source code representations (syntactic, semantic, integrated, customized) and ML techniques such as pre-trained BERT models. In addition, it is common for researchers to create hand-crafted and customized source code representations for an appropriate SE task. In a 2018 survey [1], Allamanis et al. listed nearly 35 different ways of of representing source code for different SE tasks like Abstract Syntax Trees (ASTs), customized ASTs, Control Flow Graphs (CFGs), Data Flow Graphs (DFGs) and so on. The main goal of this tutorial is two-fold (i) Present an overview of the state-of-the-art of source code representations and corresponding ML pipelines with an explicit focus on the merits and demerits of each of the representations (ii) Practical challenges in infusing different code-views in the state-of-the-art ML models and future research directions.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {342–343},
numpages = {2},
keywords = {code representation, machine learning},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3611643.3613892,
author = {Jin, Matthew and Shahriar, Syed and Tufano, Michele and Shi, Xin and Lu, Shuai and Sundaresan, Neel and Svyatkovskiy, Alexey},
title = {InferFix: End-to-End Program Repair with LLMs},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613892},
doi = {10.1145/3611643.3613892},
abstract = {Software development life cycle is profoundly influenced by bugs; their introduction, identification, and eventual resolution account for a significant portion of software development cost. This has motivated software engineering researchers and practitioners to propose different approaches for automating the identification and repair of software defects. Large Language Models (LLMs) have been adapted to the program repair task through few-shot demonstration learning and instruction prompting, treating this as an infilling task. However, these models have only focused on learning general bug-fixing patterns for uncategorized bugs mined from public repositories. In this paper, we propose : a transformer-based program repair framework paired with a state-of-the-art static analyzer to fix critical security and performance bugs.  combines a Retriever – transformer encoder model pretrained via contrastive learning objective, which aims at searching for semantically equivalent bugs and corresponding fixes; and a Generator – an LLM (12 billion parameter Codex Cushman model) finetuned on supervised bug-fix data with prompts augmented via adding bug type annotations and semantically similar fixes retrieved from an external non-parametric memory. To train and evaluate our approach, we curated , a novel, metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories. Our evaluation demonstrates that  outperforms strong LLM baselines, with a top-1 accuracy of 65.6% for generating fixes in C# and 76.8% in Java. We discuss the deployment of  alongside Infer at Microsoft which offers an end-to-end solution for detection, classification, and localization of bugs, as well as fixing and validation of candidate patches, integrated in the continuous integration (CI) pipeline to automate the software development workflow.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1646–1656},
numpages = {11},
keywords = {Program repair, finetuning, prompt augmentation, static analyses},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3650105.3652301,
author = {Macedo, Marcos and Tian, Yuan and Cogo, Filipe and Adams, Bram},
title = {Exploring the Impact of the Output Format on the Evaluation of Large Language Models for Code Translation},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650105.3652301},
doi = {10.1145/3650105.3652301},
abstract = {Code translation between programming languages is a long-existing and critical task in software engineering, facilitating the modernization of legacy systems, ensuring cross-platform compatibility, and enhancing software performance. With the recent advances in large language models (LLMs) and their applications to code translation, there is an increasing need for comprehensive evaluation of these models. In this study, we empirically analyze the generated outputs of eleven popular instruct-tuned LLMs with parameters ranging from 1B up to 46.7B on 3,820 translation pairs across five languages, including C, C++, Go, Java, and Python. Our analysis found that between 26.4% and 73.7% of code translations produced by our evaluated LLMs necessitate post-processing, as these translations often include a mix of code, quotes, and text rather than being purely source code. Overlooking the output format of these models can inadvertently lead to underestimation of their actual performance. This is particularly evident when evaluating them with execution-based metrics such as Computational Accuracy (CA). Our results demonstrate that a strategic combination of prompt engineering and regular expression can effectively extract the source code from the model generation output. In particular, our method can help eleven selected models achieve an average Code Extraction Success Rate (CSR) of 92.73%. Our findings shed light on and motivate future research to conduct more reliable benchmarks of LLMs for code translation.},
booktitle = {Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
pages = {57–68},
numpages = {12},
keywords = {code translation, output format, large language model, LLM, software engineering, benchmarking, evaluation, empirical study, case study},
location = {Lisbon, Portugal},
series = {FORGE '24}
}

@inproceedings{10.1145/3674805.3695391,
author = {Ayora, Clara and Garc\'{\i}a, Arturo S. and de la Vara, Jose Luis},
title = {Edge-AI Assurance in the REBECCA Project},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3695391},
doi = {10.1145/3674805.3695391},
abstract = {In critical domains, assurance corresponds to the set of activities to provide confidence that a system can be deemed dependable, e.g., safe and secure. This essential systems and software engineering process are usually conducted according to standards. For novel applications running at the edge and containing artificial intelligence, and for their corresponding platforms, how to conduct assurance in a systematic way is still undefined. This paper introduces the work in the large-scale REBECCA EU project to contribute to filling this gap. A new assurance framework will be defined, addressing the management of compliance, assurance cases, and assurance evidence. The assurance framework will be based on the results of a systematic study to characterize Edge-AI assurance needs, and four systems will be used to validate the framework via case study research. The assurance framework will provide guidance about what needs to be considered for safety and security assurance of Edge-AI applications, and how.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {594–597},
numpages = {4},
keywords = {Artificial Intelligence, Assurance, Compliance, Edge},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3624062.3625541,
author = {B\"{u}cker, H. Martin and Corrado, Jeremiah and Fedorin, Daniel and Garc\'{\i}a-\'{A}lvarez, Diego and Gonzalez-Escribano, Arturo and Li, John and Pantoja, Maria and Pautsch, Erik and Plesske, Marieke and Ponce, Marcelo and Rizzi, Silvio and Saule, Erik and Schoder, Johannes and Thiruvathukal, George and Van Zon, Ramses and Weber, Wolf and Bunde, David P.},
title = {Peachy Parallel Assignments (EduHPC 2023)},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3625541},
doi = {10.1145/3624062.3625541},
abstract = {Peachy Parallel Assignments are model assignments for teaching parallel computing concepts. They are competitively selected for being adoptable by other instructors and “cool and inspirational” for students. Thus, they allow instructors to easily add high-quality assignments that will engage students to their classes. This group of Peachy assignments features six new assignments. Students completing them will use k-Nearest Neighbor for classification, cluster using k-means, implement a data science pipeline of their choice, model traffic jams, apply parallel language features to solve the heat equation, and speed up a machine learning classification system.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {366–373},
numpages = {8},
keywords = {Chapel programming language, Data sciende pipeline, Distributed processing, MapReduce, MapReduce MPI, Nagel-Schreckenberg traffic model, Parallel computing education, Parallel programming, Peachy Parallel Assignment, Spark, ensemble classification, heat equation, k-Nearest Neighbor, k-means clustering, random numbers, reproducibility},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@article{10.14778/3611540.3611634,
author = {Halevy, Alon and Choi, Yejin and Floratou, Avrilia and Franklin, Michael J. and Noy, Natasha and Wang, Haixun},
title = {Will LLMs Reshape, Supercharge, or Kill Data Science? (VLDB 2023 Panel)},
year = {2023},
issue_date = {August 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3611540.3611634},
doi = {10.14778/3611540.3611634},
abstract = {Large language models (LLMs) have recently taken the world by storm, promising potentially game changing opportunities in multiple fields. Naturally, there is significant promise in applying LLMs to the management of structured data, or more generally, to the processes involved in data science. At the very least, LLMs have the potential to provide substantial advancements in long-standing challenges that our community has been tackling for decades. On the other hand, they may introduce completely new capabilities that we have only dreamed of thus far. This panel will bring together a few leading experts who have been thinking about these opportunities from various perspectives and fielding them in research prototypes and even in commercial applications.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4114–4115},
numpages = {2}
}

@article{10.5555/3637068.3637077,
author = {Adams, Kyle and Vilkomir, Aleksei and Hills, Mark},
title = {A Comparison of Machine Learning Code Quality in Python Scripts and Jupyter Notebooks},
year = {2023},
issue_date = {November 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {5},
issn = {1937-4771},
abstract = {Jupyter notebooks are currently one of the most popular environments for Python development, especially in domains such as data science. Existing studies have shown that notebooks may promote bad coding habits, leading to poor code quality and challenges with replicating notebook results. In this paper, we compare the code quality of Python machine learning code found in Jupyter notebooks to that found in regular Python scripts. The goal of this work is to better understand how the machine learning code created in Jupyter notebooks differs both from machine learning code provided in scripts and from the larger body of Python code, with the aim of creating tools to better support both data science students and practitioners.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {96–108},
numpages = {13}
}

@inproceedings{10.1145/3639478.3641226,
author = {Ibrahimzada, Ali Reza},
title = {Program Decomposition and Translation with Static Analysis},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3641226},
doi = {10.1145/3639478.3641226},
abstract = {The rising popularity of Large Language Models (LLMs) has motivated exploring their use in code-related tasks. Code LLMs with more than millions of parameters are trained on a massive amount of code in different Programming Languages (PLs). Such models are used for automating various Software Engineering (SE) tasks using prompt engineering. However, given the very large size of industry-scale project files, a major issue of these LLMs is their limited context window size, motivating the question of "Can these LLMs process very large files and can we effectively perform prompt engineering?". Code translation aims to convert source code from one PL to another. In this work, we assess the effect of method-level program decomposition on context window of LLMs and investigate how this approach can enable translation of very large files which originally could not be done due to out-of-context issue. Our observations from 20 well-known java projects and approximately 60K methods suggest that method-level program decomposition significantly improves the limited context window problem of LLMs by 99.5%. Furthermore, our empirical analysis indicate that with method-level decomposition, each input fragment on average only consumes 5% of the context window, leaving more context space for prompt engineering and the output. Finally, we investigate the effectiveness of a Call Graph (CG) approach for translating very large files when doing method-level program decomposition.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {453–455},
numpages = {3},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3597503.3639219,
author = {Du, Xueying and Liu, Mingwei and Wang, Kaixin and Wang, Hanlin and Liu, Junwei and Chen, Yixuan and Feng, Jiayi and Sha, Chaofeng and Peng, Xin and Lou, Yiling},
title = {Evaluating Large Language Models in Class-Level Code Generation},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639219},
doi = {10.1145/3597503.3639219},
abstract = {Recently, many large language models (LLMs) have been proposed, showing advanced proficiency in code generation. Meanwhile, many efforts have been dedicated to evaluating LLMs on code generation benchmarks such as HumanEval. Although being very helpful for comparing different LLMs, existing evaluation focuses on a simple code generation scenario (i.e., function-level or statement-level code generation), which mainly asks LLMs to generate one single code unit (e.g., a function or a statement) for the given natural language description. Such evaluation focuses on generating independent and often small-scale code units, thus leaving it unclear how LLMs perform in real-world software development scenarios.To fill this knowledge gap, we make the first attempt to evaluate LLMs in a more challenging code generation scenario, i.e., class-level code generation. Compared with existing code generation benchmarks, it better reflects real-world software development scenarios due to it comprising broader contextual dependencies and multiple, interdependent units of code. We first manually construct the first class-level code generation benchmark ClassEval of 100 class-level Python code generation tasks with approximately 500 person-hours. Based on the new benchmark ClassEval, we then perform the first study of 11 state-of-the-art LLMs on class-level code generation. Based on our results, we find that all LLMs perform much worse on class-level code generation compared to the method-level. While GPT models still dominate other LLMs on class-level code generation, the performance rankings of other models on method-level code generation no longer holds for class-level code generation. Besides, most models (except GPT models) perform better when generating the class method by method; and they have the limited ability of generating dependent code. Based on our findings, we call for software engineering (SE) researchers' expertise to build more LLM benchmarks based on practical and complicated software development scenarios.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {81},
numpages = {13},
keywords = {class-level code generation, large language model, benchmark},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3644815.3644957,
author = {Cabral, Raphael and Kalinowski, Marcos and Baldassarre, Maria Teresa and Villamizar, Hugo and Escovedo, Tatiana and Lopes, H\'{e}lio},
title = {Investigating the Impact of SOLID Design Principles on Machine Learning Code Understanding},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644957},
doi = {10.1145/3644815.3644957},
abstract = {[Context] Applying design principles has long been acknowledged as beneficial for understanding and maintainability in traditional software projects. These benefits may similarly hold for Machine Learning (ML) projects, which involve iterative experimentation with data, models, and algorithms. However, ML components are often developed by data scientists with diverse educational backgrounds, potentially resulting in code that doesn't adhere to software design best practices. [Goal] In order to better understand this phenomenon, we investigated the impact of the SOLID design principles on ML code understanding. [Method] We conducted a controlled experiment with three independent trials involving 100 data scientists. We restructured real industrial ML code that did not use SOLID principles. Within each trial, one group was presented with the original ML code, while the other was presented with ML code incorporating SOLID principles. Participants of both groups were asked to analyze the code and fill out a questionnaire that included both open-ended and closed-ended questions on their understanding. [Results] The study results provide statistically significant evidence that the adoption of the SOLID design principles can improve code understanding within the realm of ML projects. [Conclusion] We put forward that software engineering design principles should be spread within the data science community and considered for enhancing the maintainability of ML code.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {7–17},
numpages = {11},
keywords = {SOLID design principles, machine learning, code understanding},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@article{10.1145/3643757,
author = {Bairi, Ramakrishna and Sonwane, Atharv and Kanade, Aditya and C., Vageesh D. and Iyer, Arun and Parthasarathy, Suresh and Rajamani, Sriram and Ashok, B. and Shet, Shashank},
title = {CodePlan: Repository-Level Coding using LLMs and Planning},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643757},
doi = {10.1145/3643757},
abstract = {Software engineering activities such as package migration, fixing error reports from static analysis or testing, and adding type annotations or other specifications to a codebase, involve pervasively editing the entire repository of code.     We formulate these activities as repository-level coding tasks.         Recent tools like GitHub Copilot, which are powered by Large Language Models (LLMs), have succeeded in offering high-quality solutions to localized coding problems.     Repository-level coding tasks are more involved and cannot be solved directly using LLMs, since code within a repository is inter-dependent and the entire repository may be too large to fit into the prompt.     We frame repository-level coding as a planning problem and present a task-agnostic, neuro-symbolic framework called CodePlan to solve it.     CodePlan synthesizes a multi-step chain-of-edits (plan), where each step results in a call to an LLM on a code location with context derived from the entire repository, previous code changes and task-specific instructions.     CodePlan is based on a novel combination of an incremental dependency analysis, a change may-impact analysis and an adaptive planning algorithm (symbolic components) with the neural LLMs.         We evaluate the effectiveness of CodePlan on two repository-level tasks: package migration (C#) and temporal code edits (Python). Each task is evaluated on multiple code repositories, each of which requires inter-dependent changes to many files (between 2–97 files).     Coding tasks of this level of complexity have not been automated using LLMs before. Our results show that CodePlan has better match with the ground truth compared to baselines.     CodePlan is able to get 5/7 repositories to pass the validity checks (i.e., to build without errors and make correct code edits) whereas the baselines (without planning but with the same type of contextual information as CodePlan) cannot get any of the repositories to pass them.     We provide our (non-proprietary) data, evaluation scripts and supplementary material at https://github.com/microsoft/codeplan.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {31},
numpages = {24},
keywords = {Automated coding, LLMs, chain of edits, neuro-symbolic AI, plan, repositories, static analysis}
}

@inproceedings{10.1145/3478432.3499176,
author = {Posner, Michael A. and Kerby-Helm, April},
title = {You Teach WHAT in Your Data Science Course?!?},
year = {2022},
isbn = {9781450390712},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3478432.3499176},
doi = {10.1145/3478432.3499176},
abstract = {Data scientists - practitioners, researchers, and educators - often disagree on the definition of data science. Data science courses are taught by faculty in departments of computer science, statistics, and business analytics as well allied fields. Some data scientists create scalable dashboards, others employ and (hopefully) explain machine learning models, most (but not all) demand data wrangling and visualization skills, and some require theoretical knowledge to develop novel algorithmic and/or analytic techniques. How, then, do we determine what content should be covered in an introductory college-level data science course? Some serve as prerequisites while others are terminal experiences for non-majors (who we secretly hope to entice into the field). Some courses require prior knowledge of statistical methods, databases, or programming, uniting heterogeneous populations of students and demanding flexibility regarding programming language(s) utilized or allowed. Realistically, we often make expeditious choices because competing demands leave us hard-pressed to keep up-to-date with current skills and practices. BoF participants will share their decision processes and choices about content for an introductory data science course. Information will be shared, from participants and disseminated material, on resources and curriculum guides from various professional organizations. We welcome new and experienced data science instructors, educators planning on or interested in teaching such a course, and industrial practitioners experienced in working with or hiring undergraduates.},
booktitle = {Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 2},
pages = {1186},
numpages = {1},
keywords = {data science, tools and tool use, undergraduate instruction, undergraduate studies},
location = {Providence, RI, USA},
series = {SIGCSE 2022}
}

@inproceedings{10.1145/3701625.3701684,
author = {Oran, Ana Carolina and Montenegro, Let\'{\i}cia Braga and Schuster, Hellmut Alencar and Duarte, Jos\'{e} Carlos and Silva, Williamson and Lima, Rayfran Rocha},
title = {Integrating ChatGPT in Project Management Education: Benefits and Challenges in the Academic Environment},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701684},
doi = {10.1145/3701625.3701684},
abstract = {CONTEXT: Teaching project management is complex, and students often do not feel engaged or motivated. Professors can use many initiatives to improve the teaching and learning process. Tools like ChatGPT, when integrated into education, have generated considerable interest due to their potential to enrich students’ learning experiences. GOAL: This paper analyzes the impacts of using ChatGPT as a complementary tool in teaching Project Management in the Software Engineering course, highlighting its benefits and challenges. METHOD: We performed an exploratory study to identify the effects of using ChatGPT in teaching project management, evaluating learning, productivity, teamwork, student perceptions, and future expectations. RESULTS: The results indicate that ChatGPT contributed to improving content comprehension, developing critical skills, accelerating production, improving collaboration and communication, and increasing student engagement. However, challenges related to misuse and dependence on the tool were also identified. CONCLUSION: The integration of ChatGPT in teaching project management has shown promise, promoting a richer and more collaborative learning experience. The insights obtained provide directions for future implementations and research on the use of AI in project management education.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {596–604},
numpages = {9},
keywords = {Project management education, Software project management, ChatGPT, AI-assisted learning, Software engineering},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3663649.3664368,
author = {Aerts, Willem and Fletcher, George and Miedema, Daphne},
title = {A Feasibility Study on Automated SQL Exercise Generation with ChatGPT-3.5},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664368},
doi = {10.1145/3663649.3664368},
abstract = {SQL is the standard for database query languages and is taught in most introductory database courses. Query languages are illustrated and tested through toy examples: small, accessible, instances of databases. These are not always engaging, but coming up with new examples and questions is time-consuming. Existing research in Computer Science Education has shown that Large Language Models (LLMs) can generate coding exercises. However, this has not been demonstrated for SQL yet but could save teachers much time. In this paper, we study whether it is feasible to have ChatGPT-3.5 generate database schemas and associated SQL questions for teachers through a two-part study. Through a survey of educators, we found that creating a story and database schema for the SQL part is more time-consuming than the questions themselves. In our prompt engineering study, we identified prompts that were successful at creating database schemas, mock data, and exercises. However, although ChatGPT could help reduce the time required to create exams, some participants indicated that they are skeptical about using LLMs.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {13–19},
numpages = {7},
keywords = {Assessment, ChatGPT, Education, LLM, SQL},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{10.1145/3584371.3613016,
author = {Oduro-Afriyie, Joel and Jamil, Hasan M},
title = {Enabling the Informed Patient Paradigm with Secure and Personalized Medical Question Answering},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3613016},
doi = {10.1145/3584371.3613016},
abstract = {Quality patient care is a complex and multifaceted problem requiring the integration of data from multiple sources. We propose Medicient, a knowledge-graph-based question answering system that processes heterogeneous data sources, including patient health records, drug databases, and medical literature, into a unified knowledge graph with zero training. The knowledge graph is then utilized to provide personalized recommendations for treatment or medication. The system leverages the power of large language models for question understanding and natural language response generation, while hiding sensitive patient information. We compare our system to a large language model (ChatGPT), which does not have access to patient health records, and show that our system provides better recommendations. This study contributes to a growing body of research on knowledge graphs and their applications in healthcare.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {33},
numpages = {6},
keywords = {knowledge graphs, large language models, semantic graph search, data integration, personal health library, informed patients},
location = {Houston, TX, USA},
series = {BCB '23}
}

@inproceedings{10.1145/3545945.3569838,
author = {Pahi, Kritish and Phan, Vinhthuy},
title = {A Cloud-Based Technology for Conducting In-class Exercises in Data Science and Machine Learning Courses},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569838},
doi = {10.1145/3545945.3569838},
abstract = {Teaching data science can be challenging partly due to a diverse student population and the difficulty of providing a hands-on coding experience on complex topics. To address these challenges, we introduce a software package that facilitates active learning in the form of in-class coding exercises. This approach provides a much-needed hands-on experience in courses with a diverse student population and a highly technical content. Utilizing a popular cloud-based technology, JupyterHub, this approach enables in-class exercises with personalized feedback from the instructor. We report a classroom experience of using the technology for the first time in a graduate-level Machine Learning course, consisting of a mix of Data Science and Computer Science students. We found that, to a great extent, the course instructor could conduct complex in-class exercises within 10-15 minutes of class time. The instructor was able to understand students' abilities and challenges better and provide them with meaningful personalized feedback as well as group feedback. Students felt that the experience provided valuable hands-on practice, helped them figure out coding mistakes, and prepared them better for homework assignments.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {868–874},
numpages = {7},
keywords = {active learning, in-class exercise, jupyter notebook, jupyterhub},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@article{10.14778/3611540.3611573,
author = {Pei, Jian and Fernandez, Raul Castro and Yu, Xiaohui},
title = {Data and AI Model Markets: Opportunities for Data and Model Sharing, Discovery, and Integration},
year = {2023},
issue_date = {August 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3611540.3611573},
doi = {10.14778/3611540.3611573},
abstract = {The markets for data and AI models are rapidly emerging and increasingly significant in the realm and the practices of data science and artificial intelligence. These markets are being studied from diverse perspectives, such as e-commerce, economics, machine learning, and data management. In light of these developments, there is a pressing need to present a comprehensive and forward-looking survey on the subject to the database and data management community. In this tutorial, we aim to provide a comprehensive and interdisciplinary introduction to data and AI model markets. Unlike a few recent surveys and tutorials that concentrate only on the economics aspect, we take a novel perspective and examine data and AI model markets as grand opportunities to address the long-standing problem of data and model sharing, discovery, and integration. We motivate the importance of data and model markets using practical examples, present the current industry landscape of such markets, and explore the modules and options of such markets from multiple dimensions, including assets in the markets (e.g., data versus models), platforms, and participants. Furthermore, we summarize the latest advancements and examine the future directions of data and AI model markets as mechanisms for enabling and facilitating sharing, discovery, and integration.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {3872–3873},
numpages = {2}
}

@inproceedings{10.1145/3506860.3506917,
author = {Tavakoli, Mohammadreza and Faraji, Abdolali and Molavi, Mohammadreza and T. Mol, Stefan and Kismih\'{o}k, G\'{a}bor},
title = {Hybrid Human-AI Curriculum Development for Personalised Informal Learning Environments},
year = {2022},
isbn = {9781450395731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506860.3506917},
doi = {10.1145/3506860.3506917},
abstract = {Informal learning procedures have been changing extremely fast over the recent decades not only due to the advent of online learning, but also due to changes in what humans need to learn to meet their various life and career goals. Consequently, online, educational platforms are expected to provide personalized, up-to-date curricula to assist learners. Therefore, in this paper, we propose an Artificial Intelligence (AI) and Crowdsourcing based approach to create and update curricula for individual learners. We show the design of this curriculum development system prototype, in which contributors receive AI-based recommendations to be able to define and update high-level learning goals, skills, and learning topics together with associated learning content. This curriculum development system was also integrated into our personalized online learning platform. To evaluate our prototype we compared experts’ opinion with our system’s recommendations, and resulted in 89%, 79%, and 93% F1-scores when recommending skills, learning topics, and educational materials respectively. Also, we interviewed eight senior level experts from educational institutions and career consulting organizations. Interviewees agreed that our curriculum development method has high potential to support authoring activities in dynamic, personalized learning environments.},
booktitle = {LAK22: 12th International Learning Analytics and Knowledge Conference},
pages = {563–569},
numpages = {7},
keywords = {Artificial Intelligence, Crowdsourcing, Curriculum Development, Informal Learning},
location = {Online, USA},
series = {LAK22}
}

@inproceedings{10.1145/3649405.3659529,
author = {Miedema, Daphne and Taipalus, Toni and Ajanovski, Vangel V. and Alawini, Abdussalam and Goodfellow, Martin and Liut, Michael and Peltsverger, Svetlana and Young, Tiffany},
title = {Curriculum Analysis for Data Systems Education},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659529},
doi = {10.1145/3649405.3659529},
abstract = {The field of data systems has seen quick advances due to the popularization of data science, machine learning, and real-time analytics. In industry contexts, system features such as recommendation systems, chatbots and reverse image search require efficient infrastructure and data management solutions. Due to recent advances, it remains unclear (i) which topics are recommended to be included in data systems studies in higher education, (ii) which topics are a part of data systems courses and how they are taught, and (iii) which data-related skills are valued for roles such as software developers, data engineers, and data scientists. This working group aims to answer these points to explain the state of data systems education today and to uncover knowledge gaps and possible discrepancies between recommendations, course implementations, and industry needs. We expect the results to be applicable in tailoring various data systems courses to better cater to the needs of industry, and for teachers to share best practices.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {761–762},
numpages = {2},
keywords = {curriculum, data systems, database, education, industry, knowledge gap, skill set, student},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3689942.3694745,
author = {Hallajiyan, Mohammadreza and Dharmalingam, Athish Pranav and Mitra, Gargi and Alemzadeh, Homa and Iqbal, Shahrear and Pattabiraman, Karthik},
title = {SAM: Foreseeing Inference-Time False Data Injection Attacks on ML-enabled Medical Devices},
year = {2024},
isbn = {9798400712388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689942.3694745},
doi = {10.1145/3689942.3694745},
abstract = {The increasing use of machine learning (ML) in medical systems necessitates robust security measures to mitigate potential threats. Current research often overlooks the risk of adversaries injecting false inputs through peripheral devices at inference time, leading to mispredictions in patients' conditions. These risks are hard to foresee and mitigate during the design phase since the system is assembled by end users at the time of use. To address this gap, we introduce SAM, a technique that enables security analysts to perform System Theoretic Process Analysis for Security (STPA-Sec) on ML-enabled medical devices during the design phase. SAM models the medical system as a control structure, with the ML engine as the controller and peripheral devices as potential points for false data injection. It interfaces with state-of-the-art vulnerability databases and Large Language Models (LLMs) to automate the discovery of vulnerabilities and generate a list of possible attack paths. We demonstrate the usefulness of SAM through case studies on two FDA-cleared medical devices: a blood glucose management system and a bone mineral density measurement software. SAM allows security analysts to expedite the security assessment of ML-enabled medical devices at the design phase. This proactive approach mitigates potential patient harm and reduces costs associated with post-deployment security measures.},
booktitle = {Proceedings of the 2024 Workshop on Cybersecurity in Healthcare},
pages = {77–84},
numpages = {8},
keywords = {ML-enabled medical devices, STPA-Sec, false data injection, security assessment},
location = {Salt Lake City, UT, USA},
series = {HealthSec '24}
}

@article{10.1145/3555141,
author = {Mathur, Varoon and Lustig, Caitlin and Kaziunas, Elizabeth},
title = {Disordering Datasets: Sociotechnical Misalignments in AI-Mediated Behavioral Health},
year = {2022},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {CSCW2},
url = {https://doi.org/10.1145/3555141},
doi = {10.1145/3555141},
abstract = {The application of artificial intelligence (AI) to the behavioral health domain has led to a growing interest in the use of machine learning (ML) techniques to identify patterns in people's personal data with the goal of detecting-and even predicting-conditions such as depression, bipolar disorder, and schizophrenia. This paper investigates the data science practices and design narratives that underlie AI-mediated behavioral health through the situational analysis of three natural language processing (NLP) training datasets. Examining datasets as a sociotechnical system inextricably connected to particular social worlds, discourses, and infrastructural arrangements, we identify several misalignments between the technical project of dataset construction and benchmarking (a current focus of AI research in the behavioral health domain) and the social complexity of behavioral health. Our study contributes to a growing critical CSCW literature of AI systems by articulating the sensitizing concept ofdisordering datasets that aims to productively trouble dominant logics of AI/ML applications in behavioral health, and also support researchers and designers in reflecting on their roles and responsibilities working within this emerging and sensitive design space.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {416},
numpages = {33},
keywords = {artificial intelligence, behavioral health, critical data studies, datasets, healthcare, machine learning, mental health, reflexivity, situational analysis, training data}
}

@inproceedings{10.1145/3671151.3671204,
author = {Fan, Yingbing and Sun, Lina and Huang, Zhenxu and Lu, Bozhang and Hu, Tianyu and Geng, Yunfei},
title = {Investigation and Analysis of Influencing Factors of Innovation Quality of Data Science Students Based on Machine Learning},
year = {2024},
isbn = {9798400718106},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671151.3671204},
doi = {10.1145/3671151.3671204},
abstract = {The successful navigation of the intricate data landscape and its challenges demands data science students to possess a requisite level of innovative thinking and problem-solving skills. However, the imperative task of nurturing the innovative capacity of students within this discipline has emerged as a pressing concern in the contemporary educational milieu. This paper conducts a comprehensive review of research pertaining to factor analysis and machine learning techniques aimed at bolstering the innovation quality strategy of data science students [1]. It delves into the examination of diverse factors such as total factor score, personal aptitude and learning environment assessment, experience evaluation, practice proficiency, and gender disparity score to derive pertinent histograms, linear regression expressions, and other analytical tools. Furthermore, it advances strategies tailored towards enhancing individual capabilities and practical experiences that underpin innovative qualities. These proficiencies encompass effective communication skills, adeptness in learning, mastery of domain-specific knowledge, and the cultivation of critical thinking prowess [2]. Sequential recommendations are delineated to elucidate how each of these competencies can be honed and refined.},
booktitle = {Proceedings of the 5th International Conference on Computer Information and Big Data Applications},
pages = {290–294},
numpages = {5},
location = {Wuhan, China},
series = {CIBDA '24}
}

@inproceedings{10.1109/ASE56229.2023.00157,
author = {Zhou, Xin and Kim, Kisub and Xu, Bowen and Liu, Jiakun and Han, DongGyun and Lo, David},
title = {The Devil is in the Tails: How Long-Tailed Code Distributions Impact Large Language Models},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00157},
doi = {10.1109/ASE56229.2023.00157},
abstract = {Learning-based techniques, especially advanced Large Language Models (LLMs) for code, have gained considerable popularity in various software engineering (SE) tasks. However, most existing works focus on designing better learning-based models and pay less attention to the properties of datasets. Learning-based models, including popular LLMs for code, heavily rely on data, and the data's properties (e.g., data distribution) could significantly affect their behavior. We conducted an exploratory study on the distribution of SE data and found that such data usually follows a skewed distribution (i.e., long-tailed distribution) where a small number of classes have an extensive collection of samples, while a large number of classes have very few samples. We investigate three distinct SE tasks and analyze the impacts of long-tailed distribution on the performance of LLMs for code. Our experimental results reveal that the long-tailed distribution has a substantial impact on the effectiveness of LLMs for code. Specifically, LLMs for code perform between 30.0% and 254.0% worse on data samples associated with infrequent labels compared to data samples of frequent labels. Our study provides a better understanding of the effects of long-tailed distributions on popular LLMs for code and insights for the future development of SE automation.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {40–52},
numpages = {13},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3593434.3593468,
author = {Ahmad, Aakash and Waseem, Muhammad and Liang, Peng and Fahmideh, Mahdi and Aktar, Mst Shamima and Mikkonen, Tommi},
title = {Towards Human-Bot Collaborative Software Architecting with ChatGPT},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593434.3593468},
doi = {10.1145/3593434.3593468},
abstract = {Architecting software-intensive systems can be a complex process. It deals with the daunting tasks of unifying stakeholders’ perspectives, designers’ intellect, tool-based automation, pattern-driven reuse, and so on, to sketch a blueprint that guides software implementation and evaluation. Despite its benefits, architecture-centric software engineering (ACSE) suffers from a multitude of challenges. ACSE challenges could stem from a lack of standardized processes, socio-technical limitations, and scarcity of human expertise etc. that can impede the development of existing and emergent classes of software. Software Development Bots (DevBots) trained on large language models can help synergise architects’ knowledge with artificially intelligent decision support to enable rapid architecting in a human-bot collaborative ACSE. An emerging solution to enable this collaboration is ChatGPT, a disruptive technology not primarily introduced for software engineering, but is capable of articulating and refining architectural artifacts based on natural language processing. We detail a case study that involves collaboration between a novice software architect and ChatGPT to architect a service-based software. Future research focuses on harnessing empirical evidence about architects’ productivity and explores socio-technical aspects of architecting with ChatGPT to tackle challenges of ACSE.},
booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
pages = {279–285},
numpages = {7},
keywords = {ChatGPT, DevBots, Large Language Models, Software Architecture},
location = {Oulu, Finland},
series = {EASE '23}
}

@inproceedings{10.1145/3630106.3658984,
author = {Wang, Ruotong and Cheng, Ruijia and Ford, Denae and Zimmermann, Thomas},
title = {Investigating and Designing for Trust in AI-powered Code Generation Tools},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658984},
doi = {10.1145/3630106.3658984},
abstract = {Trust is a crucial factor for the adoption and responsible usage of generative AI tools in complex tasks such as software engineering. However, we have a limited understanding of how software developers evaluate the trustworthiness of AI-powered code generation tools in real-world settings. To address this gap, we conducted Study 1, an interview study with 17 developers who use AI-powered code generation tools in professional or personal settings. We found that developers’ trust is rooted in the AI tool’s perceived ability, integrity, and benevolence, and is situational, varying according to the context of usage. Existing AI code generation tools lack the affordances for developers to efficiently and effectively evaluate the trustworthiness of AI-powered code generation tools. To explore designs that can augment the existing interface of AI-powered code generation tools, we explored three sets of design concepts (suggestion quality indicators, usage stats, and control mechanisms) that derived from Study 1 findings. In Study 2, a design probe study with 12 developers, we investigated the potential of these design concepts to help developers make effective trust judgments. We discuss the implication of our findings on the design of AI-powered code generation tools and future research on trust in AI.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1475–1493},
numpages = {19},
keywords = {generative AI, human-AI interaction, software engineering tooling, trust in AI},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@article{10.1145/3579607,
author = {Lin, Cindy Kaiying and Jackson, Steven J.},
title = {From Bias to Repair: Error as a Site of Collaboration and Negotiation in Applied Data Science Work},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW1},
url = {https://doi.org/10.1145/3579607},
doi = {10.1145/3579607},
abstract = {Managing error has become an increasingly central and contested arena within data science work. While recent scholarship in artificial intelligence and machine learning has focused on limiting and eliminating error, practitioners have long used error as a site of collaboration and learning vis-\`{a}-vis labelers, domain experts, and the worlds data scientists seek to model and understand. Drawing from work in CSCW, STS, HCML, and repair studies, as well as from multi-sited ethnographic fieldwork within a government institution and a non-profit organization, we move beyond the notion of error as an edge case or anomaly to make three basic arguments. First, error discloses or calls to attention existing structures of collaboration unseen or underappreciated under 'working' systems. Second, error calls into being new forms and sites of collaboration (including, sometimes, new actors). Third, error redeploys old sites and actors in new ways, often through restructuring relations of hierarchy and expertise which recenter or devalue the position of different actors. We conclude by discussing how an artful living with error can better support the creative strategies of negotiation and adjustment which data scientists and their collaborators engage in when faced with disruption, breakdown, and friction in their work.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {131},
numpages = {32},
keywords = {AI ethics, critical data studies, data science, error, machine learning, repair}
}

@inproceedings{10.1145/3632621.3671429,
author = {Potriasaeva, Anna and Dzialets, Katsiaryna and Golubev, Yaroslav and Birillo, Anastasiia},
title = {Using a Low-Code Environment to Teach Programming in the Era of LLMs},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671429},
doi = {10.1145/3632621.3671429},
abstract = {LLMs change the landscape of software engineering, and the question arises: “How can we combine LLMs with traditional teaching approaches in computer science?”. In this work, we propose to teach students in a low-code environment of code generation, developing not only their coding but also decomposition and prompting skills.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {542–543},
numpages = {2},
keywords = {Generative AI, LLMs, MOOC, Programming Education},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3637528.3671478,
author = {Goldenberg, Dmitri and Meir Lador, Shir and Sokolova, Elena and Cheong, Lin Lee and Sukhwani, Mohak and Potdar, Saloni},
title = {The Third Workshop on Applied Machine Learning Management},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671478},
doi = {10.1145/3637528.3671478},
abstract = {Machine learning applications are rapidly adopted by industry leaders in any field. The growth of investment in AI-driven solutions,including the emerging field of General AI (GenAI), has created new challenges in managing Data Science and ML resources, people and projects as a whole. The discipline of managing applied machine learning teams, requires a healthy mix between agile product development tool-set and a long term research oriented mindset. The abilities of investing in deep research while at the same time connecting the outcomes to significant business results create a large knowledge based on management methods and best practices in the field. The Third KDD Workshop on Applied Machine Learning Management brings together applied research managers from various fields to share methodologies and case-studies on management of ML teams, products, and projects, achieving business impact with advanced AI-methods.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6714–6715},
numpages = {2},
keywords = {data science management, genai and compliance, machine learning management, ml product development},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3657604.3664663,
author = {Wang, Tianjia and Ramanujan, Ramaraja and Lu, Yi and Mao, Chenyu and Chen, Yan and Brown, Chris},
title = {DevCoach: Supporting Students in Learning the Software Development Life Cycle at Scale with Generative Agents},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664663},
doi = {10.1145/3657604.3664663},
abstract = {Supporting novice computer science students in learning the software development life cycle (SDLC) at scale is vital for ensuring the quality of future software systems. However, this presents unique challenges, including the need for effective interactive collaboration and access to diverse skill sets of members in the software development team. To address these problems, we present ''DevCoach'', an online system designed to support students learning the SDLC at scale by interacting with generative agents powered by large language models simulating members with different roles in a software development team. Our preliminary user study results reveal that DevCoach improves the experiences and outcomes for students, with regard to learning concepts in SDLC's ''Plan and Design'' and ''Develop'' phases. We aim to use our findings to enhance DevCoach to support the entire SDLC workflow by incorporating additional simulated roles and enabling students to choose their project topics. Future studies will be conducted in an online Software Engineering class at our institution, aiming to explore and inspire the development of intelligent systems that provide comprehensive SDLC learning experiences to students at scale.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {351–355},
numpages = {5},
keywords = {computer science education, generative ai, software development life cycle, software engineering},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.1145/3708532,
author = {H\"{a}m\"{a}l\"{a}inen, Joonas and Das, Teerath and Mikkonen, Tommi},
title = {A Systematic Literature Review of Multi-Label Learning in Software Engineering},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708532},
doi = {10.1145/3708532},
abstract = {In this paper, we provide the first systematic literature review of the intersection of two research areas, Multi-Label Learning (MLL) and Software Engineering (SE). We refer to this intersection as MLL4SE. In recent years, MLL problems have increased in many applications and research areas because real-world datasets often have a multi-label nature. For multi-label data, simplifying the assumption of traditional classification approaches that an instance can only be associated with one class only leads to worse accuracy. Thus, a better match of methods and assumptions about the data is required. We identified 50 primary studies in our systematic literature review in the MLL4SE domain. Based on this review, we identified six main SE application domains where MLL has been applied. These domains include Software Requirement Engineering, Issue Tracking and Management, Community and Knowledge Management, API Usage and Management, Code Quality and Maintenance, and Mobile Application Development. We summarized the methods used and the data nature of the MLL4SE applications. Moreover, we separately provide taxonomies of future work directions from machine learning and software engineering perspectives. In general, we highlight current trends, research gaps, and shortcomings.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {Machine Learning, Multi-Label Learning, Software Engineering, Systematic Literature Review, Software Development Life Cycle (SDLC) Activities}
}

@inproceedings{10.1145/3540250.3560883,
author = {Shanbhag, Shriram and Chimalakonda, Sridhar},
title = {Exploring the under-explored terrain of non-open source data for software engineering through the lens of federated learning},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3560883},
doi = {10.1145/3540250.3560883},
abstract = {The availability of open source projects on platforms like GitHub has led to the wide use of the artifacts from these projects in software engineering research. These publicly available artifacts have been used to train artificial intelligence models used in various empirical studies and the development of tools. However, these advancements have missed out on the artifacts from non-open source projects due to the unavailability of the data. A major cause for the unavailability of the data from non-open source repositories is the issue concerning data privacy. In this paper, we propose using federated learning to address the issue of data privacy to enable the use of data from non-open source to train AI models used in software engineering research. We believe that this can potentially enable industries to collaborate with software engineering researchers without concerns about privacy. We present the preliminary evaluation of the use of federated learning to train a classifier to label bug-fix commits from an existing study to demonstrate its feasibility. The federated approach achieved an F1 score of 0.83 compared to a score of 0.84 using the centralized approach. We also present our vision of the potential implications of the use of federated learning in software engineering research.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1610–1614},
numpages = {5},
keywords = {data privacy, federated learning, non-open source data, software engineering research},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@article{10.1145/3649453,
author = {Langford, Michael Austin and Zilberman, Sol and Cheng, Betty},
title = {Anunnaki: A Modular Framework for Developing Trusted Artificial Intelligence},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1556-4665},
url = {https://doi.org/10.1145/3649453},
doi = {10.1145/3649453},
abstract = {Trustworthy artificial intelligence (Trusted AI) is of utmost importance when learning-enabled components (LECs) are used in autonomous, safety-critical systems. When reliant on deep learning, these systems need to address the reliability, robustness, and interpretability of learning models. In addition to developing strategies to address these concerns, appropriate software architectures are needed to coordinate LECs and ensure they deliver acceptable behavior even under uncertain conditions. This work describes Anunnaki, a model-driven framework comprising loosely-coupled modular services designed to monitor and manage LECs with respect to Trusted AI assurance concerns when faced with different sources of uncertainty. More specifically, the Anunnaki framework supports the composition of independent, modular services to assess and improve the resilience and robustness of AI systems. The design of Annunaki was guided by several key software engineering principles (e.g., modularity, composability, and reusability) in order to facilitate its use and maintenance to support different aggregate monitoring and assurance analysis tools for LESs and their respective data sets. We demonstrate Anunnaki on two autonomous platforms, a terrestrial rover, and an unmanned aerial vehicle. Our studies show how Anunnaki can be used to manage the operations of different autonomous learning-enabled systems with vision-based LECs while exposed to uncertain environmental conditions.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = sep,
articleno = {17},
numpages = {34},
keywords = {Software engineering, models at run time, self-adaptive systems, artificial intelligence, deep learning}
}

@inproceedings{10.1145/3617553.3617887,
author = {Fulcini, Tommaso and Torchiano, Marco},
title = {Is ChatGPT Capable of Crafting Gamification Strategies for Software Engineering Tasks?},
year = {2023},
isbn = {9798400703737},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617553.3617887},
doi = {10.1145/3617553.3617887},
abstract = {Gamification has gained significant attention in the last decade for its potential to enhance engagement and motivation in various domains. During the last year ChatGPT, a state-of-the-art large language model has received even more attention both in the field of scientific research and in common use by individuals or companies.  
In this study, we investigate the possibility of adopting ChatGPT as a tool for designing gamification platforms in the Software Engineering domain. Leveraging the capabilities of ChatGPT, we assess how good is it at generating effective suggestions and ideas for designers or developers.  
To evaluate ChatGPT's potential as a gamification platform creator we narrowed the context to one particular Software Engineering activity, asking for possible aspects of the activity to be gamified. Each proposed aspect was subsequently unraveled by ChatGPT both asking in a shared and separate context, first following the conversational nature of the model, then applying a validated design framework. The study assesses ChatGPT's ability to select and integrate game elements to build a thriving gamification environment by framing the design of the platform to a state-of-the-art conceptual framework. To evaluate the goodness of the design choices made we relied both on the Octalysis framework and on personal experience.  
The findings of the papers show that ChatGPT can only create simple playful experiences not very effective. Although, by instructing the model with more specific desired mechanics and dynamics, it is possible to guide it toward the application of the ideas suggested. We argue that ChatGPT is not capable of building a gamified environment on its own, but it could still be used to build the foundation of a gamification platform as long as the designers refine and rough out the advice gained from a user-centered solution.},
booktitle = {Proceedings of the 2nd International Workshop on Gamification in Software Development, Verification, and Validation},
pages = {22–28},
numpages = {7},
keywords = {Artificial Intelligence, Gamification, Large Language Model, Software Engineering, Software Lifecycle},
location = {San Francisco, CA, USA},
series = {Gamify 2023}
}

@article{10.1145/3660773,
author = {Hossain, Soneya Binta and Jiang, Nan and Zhou, Qiang and Li, Xiaopeng and Chiang, Wen-Hao and Lyu, Yingjun and Nguyen, Hoan and Tripp, Omer},
title = {A Deep Dive into Large Language Models for Automated Bug Localization and Repair},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660773},
doi = {10.1145/3660773},
abstract = {Large language models (LLMs) have shown impressive effectiveness in various software engineering tasks,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
including automated program repair (APR). In this study, we take a deep dive into automated bug localization
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
and repair utilizing LLMs. In contrast to many deep learning-based APR methods that assume known bug
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
locations, rely on line-level localization tools, or address bug prediction and fixing in one step, our approach
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
uniquely employs LLMs to predict bug location at the token level and subsequently utilizes them for bug
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
fixing. This methodological separation of bug localization and fixing using different LLMs enables effective
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
integration of diverse contextual information and improved incorporation of inductive biases. We introduce
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Toggle: Token-Granulated Bug Localization and Repair, a comprehensive program repair framework
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
that integrates a bug localization model, an adjustment model to address tokenizer inconsistencies, and a
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
bug-fixing model. Toggle takes a buggy function as input and generates a complete corrected function. We
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
investigate various styles of prompting to the bug fixing model to identify the most effective prompts that
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
better utilize the inductive bias and significantly outperform others. Toggle achieves the new state-of-the-art
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(SOTA) performance on the CodeXGLUE code refinement benchmark, and exhibits better and comparable
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
performance on several other widely-used APR datasets, including Defects4J. In the Defects4J benchmark, our
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
approach consistently ranks above other methods, achieving superior results in the Top-10, Top-30, Top-50,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
and Top-100 metrics. Besides examining Toggle’s generalizability to unseen data, evaluating the effectiveness
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
of various prompts, we also investigate the impact of additional contextual information such as buggy lines
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
and code comments on bug localization, and explore the importance of the adjustment model. Our extensive
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
experiments offer valuable insights and answers to critical research questions.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {66},
numpages = {23},
keywords = {Automated Bug Localization and Reapir, Large Language Models}
}

@inproceedings{10.5555/3615924.3615927,
author = {Nascimento, Nathalia and Alencar, Paulo and Cowan, Donald},
title = {Artificial Intelligence vs. Software Engineers: An Empirical Study on Performance and Efficiency using ChatGPT},
year = {2023},
publisher = {IBM Corp.},
address = {USA},
abstract = {In the realm of Software Engineering (SE), automation has become a tangible reality. Artificial Intelligence (AI) has suc-cessfully addressed challenges in project management, mod-eling, testing, and development. Among the latest innova-tions is ChatGPT, an ML-infused chatbot capable of gen-erating programming codes and software testing strategies. Although there is speculation that AI-based computation can boost productivity and even substitute software engineers in software development, empirical evidence supporting such claims is lacking. Moreover, questions remain about their po-tential to address overlooked evaluation metrics like energy efficiency, vulnerability, fairness (i.e., human bias), and safety. This paper probes into these issues with an empirical study, comparing ChatGPT with both novice and expert program-mers using LeetCode contest problems. The investigation focuses on performance and memory-efficiency, while also acknowledging the need for a broader assessment of non-functional requirements. The results suggest that ChatGPT is better than beginners at solving easy and medium prob-lems, but it is not yet proven to beat expert programmers. This paper posits that a comprehensive comparison of soft-ware engineers and AI-based solutions, considering various evaluation criteria, is pivotal in fostering human-machine collaboration, enhancing the reliability of AI-based meth-ods, and understanding task suitability for humans or AI. Furthermore, it facilitates the effective implementation of co-operative work structures and human-in-the-loop processes.},
booktitle = {Proceedings of the 33rd Annual International Conference on Computer Science and Software Engineering},
pages = {24–33},
numpages = {10},
keywords = {Software Engineering, AI-based solutions, Performance Evaluation, ChatGPT, Machine Learning},
location = {Las Vegas, NV, USA},
series = {CASCON '23}
}

@inproceedings{10.1145/3639478.3639792,
author = {Rodriguez-Cardenas, Daniel},
title = {Beyond Accuracy and Robustness Metrics for Large Language Models for Code},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3639792},
doi = {10.1145/3639478.3639792},
abstract = {In recent years, Large Language Models for code (LLMc) have transformed the landscape of software engineering (SE), demonstrating significant efficacy in tasks such as code completion, summarization, review, tracing, translation, test case generation, clone detection, and bug fixing. Notably, GitHub Copilot [31] and Google's CodeBot [21] exemplify how LLMc contributes to substantial time and effort savings in software development. However, despite their widespread use, there is a growing need to thoroughly assess LLMc, as current evaluation processes heavily rely on accuracy and robustness metrics, lacking consensus on additional influential factors in code generation. This gap hinders a holistic understanding of LLMc performance, impacting interpretability, efficiency, bias, fairness, and robustness. The challenges in benchmarking and data maintenance compound this issue, underscoring the necessity for a comprehensive evaluation approach. To address these issues, this dissertation proposes the development of a benchmarking infrastructure, named HolBench, aimed at overcoming gaps in evaluating LLMc quality. The goal is to standardize testing scenarios, facilitate meaningful comparisons across LLMc, and provide multi-metric measurements beyond a sole focus on accuracy. This approach aims to decrease the costs associated with advancing LLMc research, enhancing their reliability for adoption in academia and industry.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {159–161},
numpages = {3},
keywords = {deep learning, code generation, interpretability, transformers},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@article{10.1145/3543847,
author = {Idowu, Samuel and Str\"{u}ber, Daniel and Berger, Thorsten},
title = {Asset Management in Machine Learning: State-of-research and State-of-practice},
year = {2022},
issue_date = {July 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {7},
issn = {0360-0300},
url = {https://doi.org/10.1145/3543847},
doi = {10.1145/3543847},
abstract = {Machine learning components are essential for today’s software systems, causing a need to adapt traditional software engineering practices when developing machine-learning-based systems. This need is pronounced due to many development-related challenges of machine learning components such as asset, experiment, and dependency management. Recently, many asset management tools addressing these challenges have become available. It is essential to understand the support such tools offer to facilitate research and practice on building new management tools with native supports for machine learning and software engineering assets. This article positions machine learning asset management as a discipline that provides improved methods and tools for performing operations on machine learning assets. We present a feature-based survey of 18 state-of-practice and 12 state-of-research tools supporting machine-learning asset management. We overview their features for managing the types of assets used in machine learning experiments. Most state-of-research tools focus on tracking, exploring, and retrieving assets to address development concerns such as reproducibility, while the state-of-practice tools also offer collaboration and workflow-execution-related operations. In addition, assets are primarily tracked intrusively from the source code through APIs and managed via web dashboards or command-line interfaces (CLIs). We identify asynchronous collaboration and asset reusability as directions for new tools and techniques.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {144},
numpages = {35},
keywords = {Machine learning, experiment management tools, SE4AI}
}

@inproceedings{10.1145/3674912.3674919,
author = {Andreeva, Anna and Lekova, Anna and Tsvetkova, Paulina and Simonska, Miglena},
title = {Expanding the Capabilities of Robot NAO to Enable Human-Like Communication with Children with Speech and Language Disorders},
year = {2024},
isbn = {9798400716843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674912.3674919},
doi = {10.1145/3674912.3674919},
abstract = {The humanoid robot NAO is widely used in therapy scenarios for children with neurodevelopmental disorders, however it has poor speech recognition and dialog based on a predefined lexicon that results in limited vocabulary and limited number of predefined dialog scenarios. The integration of Conversational Artificial Intelligence (AI) in NAO can significantly enhance and expand the robot's capabilities for intensive speech and listening exercises for children with speech and language disorders. Applying design-based research, the authors present the ongoing effective iteration in the building-testing cycles of a software architecture for Conversational AI in the robot NAO by integrating different AI cloud services for NLP into NAO's native software. Examining the aims and methods of stakeholders interested in integrating Conversational AI in NAO for speech and language therapy, we revealed several technical and ethical challenges. These challenges were successfully addressed with solutions implemented in the Node-RED platform, such as achieving more accurate and speech recognition, generating human-like text based on a context, and implementing multilingual text-to-speech synthesis. Additionally, implementation raises ethical considerations for both developers and therapists, especially regarding the assessment of risks linked with AI systems. We followed the guidelines set in the European AI Act, which categorizes AI systems according to their associated risk levels.},
booktitle = {Proceedings of the International Conference on Computer Systems and Technologies 2024},
pages = {63–68},
numpages = {6},
location = {Ruse, Bulgaria},
series = {CompSysTech '24}
}

@inproceedings{10.1145/3597465.3605228,
author = {Zhao, Jinjin and Gal, Avigdor and Krishnan, Sanjay},
title = {Data Makes Better Data Scientists},
year = {2023},
isbn = {9798400702167},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597465.3605228},
doi = {10.1145/3597465.3605228},
abstract = {With the goal of identifying common practices in data science projects, this paper proposes a framework for logging and understanding incremental code executions in Jupyter notebooks. This framework aims to allow reasoning about how insights are generated in data science and extract key observations into best data science practices in the wild. In this paper, we show an early prototype of this framework and ran an experiment to log a machine learning project for 25 undergraduate students.},
booktitle = {Proceedings of the Workshop on Human-In-the-Loop Data Analytics},
articleno = {12},
numpages = {3},
location = {Seattle, WA, USA},
series = {HILDA '23}
}

@inproceedings{10.1145/3691621.3694946,
author = {Hao, Huizi and Tian, Yuan},
title = {Engaging with AI: An Exploratory Study on Developers' Sharing and Reactions to ChatGPT in GitHub Pull Requests},
year = {2024},
isbn = {9798400712494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691621.3694946},
doi = {10.1145/3691621.3694946},
abstract = {ChatGPT, as a representative Foundation Model (FM)-powered tool, has demonstrated significant potential in assisting developers with various software engineering tasks, such as code generation, program repair, and test creation. However, the timing of developers seeking assistance from ChatGPT and their perceptions of ChatGPT-generated content remain underexplored. In this paper, we analyze a dataset comprising 211 developers' shared conversations with ChatGPT within GitHub Pull Requests (PRs). Our study investigates the events in the GitHub PR timeline that precede these shared conversations, the sentiments expressed by developers when sharing these conversations, and the reactions from other developers to PR comments and descriptions that include shared conversations with ChatGPT. Our key findings are: (1) Shared conversations with ChatGPT are posted after seven distinct types of pull request timeline events, with the most frequent being comments added, PR creation, and review requests. (2) Positive sentiment is the most prevalent among developers when sharing these conversations, followed by neutral and negative sentiments. Developer reactions to comments and PR descriptions containing shared conversations are generally sparse; when they do occur, the most common reactions are (thumbs up), (heart), and (eyes). These findings provide new insights into how developers incorporate FM-powered tools into their collaborative software development workflows.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering Workshops},
pages = {156–160},
numpages = {5},
keywords = {knowledge sharing, conversations with chatgpt, chatgpt in collaborative coding, foundation model, pull requests},
location = {Sacramento, CA, USA},
series = {ASEW '24}
}

@inproceedings{10.1109/ASE51524.2021.9678873,
author = {Sivasothy, Shangeetha},
title = {DSInfoSearch: supporting experimentation process of data scientists},
year = {2022},
isbn = {9781665403375},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE51524.2021.9678873},
doi = {10.1109/ASE51524.2021.9678873},
abstract = {Experimentation plays an important role in the work of data scientists to explore unfamiliar problem domains, to answer questions from data, and to develop diverse machine learning applications. Good experimentation requires creativity, is based on prior results and informed from the literature. However, finding relevant information from online sources to guide experimentation causes inefficiencies for data scientists. The objective of this research is to help data scientists through the presentation of context aware ranked data science experiments, considering problem domain, development task and learning task. Data science experiments for this study were extracted from publicly available interactive notebooks and were manually annotated based on a taxonomy of data science techniques and a meta model of a data science experiment. Further, the ranking algorithm was developed for data science experiments for given problem domain and development task. As a result, a tool was developed to demonstrate context aware ranked data science experiments for given problem domains such as natural language processing, computer vision and time series and for development stages such as feature engineering and model selection. This study shows that tools and techniques can be designed to be aware of the data science context, in fact, much more so than for software engineering tools. This study supports these efforts by providing knowledge that can improve experimentation process of data scientists.},
booktitle = {Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1033–1037},
numpages = {5},
keywords = {data scientists, experiment, information search, notebooks},
location = {Melbourne, Australia},
series = {ASE '21}
}

@inproceedings{10.1145/3510454.3517055,
author = {Quaranta, Luigi},
title = {Assessing the quality of computational notebooks for a frictionless transition from exploration to production},
year = {2022},
isbn = {9781450392235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510454.3517055},
doi = {10.1145/3510454.3517055},
abstract = {The massive trend of integrating data-driven AI capabilities into traditional software systems is rising new intriguing challenges. One of such challenges is achieving a smooth transition from the explorative phase of Machine Learning projects - in which data scientists build prototypical models in the lab - to their production phase - in which software engineers translate prototypes into production-ready AI components. To narrow down the gap between these two phases, tools and practices adopted by data scientists might be improved by incorporating consolidated software engineering solutions. In particular, computational notebooks have a prominent role in determining the quality of data science prototypes. In my research project, I address this challenge by studying the best practices for collaboration with computational notebooks and proposing proof-of-concept tools to foster guidelines compliance.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
pages = {256–260},
numpages = {5},
keywords = {artificial intelligence, computational notebooks, data science, linters, machine learning, software engineering, static analysis tools},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@article{10.1145/3643678,
author = {Hu, Qiang and Guo, Yuejun and Xie, Xiaofei and Cordy, Maxime and Ma, Lei and Papadakis, Mike and Le Traon, Yves},
title = {Test Optimization in DNN Testing: A Survey},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3643678},
doi = {10.1145/3643678},
abstract = {This article presents a comprehensive survey on test optimization in deep neural network&nbsp;(DNN) testing. Here, test optimization refers to testing with low data labeling effort. We analyzed 90 papers, including 43 from the software engineering (SE) community, 32 from the machine learning (ML) community, and 15 from other communities. Our study: (i) unifies the problems as well as terminologies associated with low-labeling cost testing, (ii) compares the distinct focal points of SE and ML communities, and (iii) reveals the pitfalls in existing literature. Furthermore, we highlight the research opportunities in this domain.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {111},
numpages = {42},
keywords = {Test optimization, DNN testing, low-labeling cost}
}

@inproceedings{10.1145/3663529.3663811,
author = {Duran, Pau and Casta\~{n}o, Joel and G\'{o}mez, Cristina and Mart\'{\i}nez-Fern\'{a}ndez, Silverio},
title = {GAISSALabel: A Tool for Energy Labeling of ML Models},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663811},
doi = {10.1145/3663529.3663811},
abstract = {The increasing environmental impact of Information Technologies, particularly in Machine Learning (ML), highlights the need for sustainable practices in software engineering. The escalating complexity and energy consumption of ML models need tools for assessing and improving their energy efficiency. This paper introduces GAISSALabel, a web-based tool designed to evaluate and label the energy efficiency of ML models. GAISSALabel is a technology transfer development from a former research on energy efficiency classification of ML, consisting of a holistic tool for assessing both the training and inference phases of ML models, considering various metrics such as power draw, model size efficiency, CO2e emissions and more. GAISSALabel offers a labeling system for energy efficiency, akin to labels on consumer appliances, making it accessible to ML stakeholders of varying backgrounds. The tool's adaptability allows for customization in the proposed labeling system, ensuring its relevance in the rapidly evolving ML field. GAISSALabel represents a significant step forward in sustainable software engineering, offering a solution for balancing high-performance ML models with environmental impacts. The tool's effectiveness and market relevance will be further assessed through planned evaluations using the Technology Acceptance Model.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {622–626},
numpages = {5},
keywords = {Green AI, Green Software, Software Engineering, Sustainability},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3606094.3606101,
author = {Vargas-Murillo, Alfonso Renato and Pari-Bedoya, Ilda Nadia Monica de la Asuncion and Guevara-Soto, Francisco de Jesus},
title = {The Ethics of AI Assisted Learning: A Systematic Literature Review on the Impacts of ChatGPT Usage in Education},
year = {2023},
isbn = {9798400700422},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3606094.3606101},
doi = {10.1145/3606094.3606101},
abstract = {This systematic literature review explores how gamification in legal education might be In recent years, ChatGPT has become a noteworthy subject in the educational field due to the popularity it gained amongst students across different levels of education all over the world, who use this technology to assess their academic homework, transforming ChatGPT in some sort of auxiliary tool that aids them with the completion of certain tasks that would take more time to complete, such as research and data comparison, to name a few examples; but this form of AI assisted learning, as it were, has also become a problematic subject. This artificial intelligence chatbot is, undeniably, a remarkable advancement in AI regarding the improvements it presents compared to other similar technologies, and it clearly paves the way for future applications not only in education, but also at a social level, in a world more driven towards the development and optimization of digital tools with the help of machine learning. Nevertheless, this sort of technology should be question ed when its application permeates deeply in the performance and development of students and their learning process, especially when taking in consideration the level of accessibility that ChatGPT has worldwide. Students should have an ethical standpoint on whether they use ChatGPT to complement their learning process and how much input is this technology having in their academic work, so they learn to use it more effectively and avoid the abuse of ChatGPT usage, in order to seize the benefits that this AI may have on education. This study's objective is to analyze the current literature around the use of ChatGPT in education, for which we conducted a Systematic Literature Review (SLR) across multiple journal databases such as Scopus, ScienceDirect, ProQuest, IEEE Xplore and ACM Digital Library.},
booktitle = {Proceedings of the 2023 8th International Conference on Distance Education and Learning},
pages = {8–13},
numpages = {6},
keywords = {Artificial Intelligence, Assisted Learning, Ethics, Systematic Literature Review},
location = {Beijing, China},
series = {ICDEL '23}
}

@inproceedings{10.1145/3611643.3613082,
author = {Hu, Boyue Caroline and Chechik, Marsha},
title = {Towards Feature-Based Analysis of the Machine Learning Development Lifecycle},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613082},
doi = {10.1145/3611643.3613082},
abstract = {The safety and trustworthiness of systems with components that are based on Machine Learning (ML) require an in-depth understanding and analysis of all stages in its Development Lifecycle (MLDL). High-level abstractions of desired functionalities, model behaviour, and data are called features, and they have been studied by different communities across all MLDL stages. In this paper, we propose to support Software Engineering analysis of the MLDL through features, calling it feature-based analysis of the MLDL. First, to achieve a shared understanding of features among different experts, we establish a taxonomy of existing feature definitions currently used in various MLDL stages. Through this taxonomy, we map features from different stages to each other, discover gaps and future research directions and identify areas of collaboration between Software Engineering and other MLDL experts.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {2087–2091},
numpages = {5},
keywords = {Features, Machine Learning, Software Analysis},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3641822.3641877,
author = {Melegati, Jorge and Nascimento, Nicolas and Chanin, Rafael and Sales, Afonso and Wiese, Igor},
title = {Exploring potential implications of intelligent tools for human aspects of software engineering},
year = {2024},
isbn = {9798400705335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641822.3641877},
doi = {10.1145/3641822.3641877},
abstract = {Background. The emergence of tools based on artificial intelligence (AI) to support software development suggests an overhaul on how developers program and interact among themselves. This disruption might bring challenges regarding human and social aspects of the software development process. Objective. This paper is a first exploration of the consequences of AI-based tools for software development teams and their members. Method. We conducted a social science fiction exercise, a sort of thought experiment, narrating two fictional stories about a futuristic software company employing AI-based tools. Then, we evaluated the plausibility of one of the scenarios through a qualitative experiment with 38 students to observe their perception regarding the use of AI-based tools. Results. The stories suggest potential challenges related to the adoption of these tools: a change on how developers perceive themselves, a clash between quantitative and qualitative worker contribution assessment, and the training of future developers to handle the imminent changes on their profession. In the qualitative experiment, we collected evidence supporting negative feelings, such as lack of trust and control and fear of being replaced. We also identified other attitudes and perceptions of developers, such as positive feelings towards AI-based tools. Conclusion. We identified several aspects that might influence the adoption of AI-based tools and their implications for individuals involved. They should be further investigated and represent a challenge for the research on human aspects of software engineering. We also demonstrated the use of social science fiction to explore novel research problems.},
booktitle = {Proceedings of the 2024 IEEE/ACM 17th International Conference on Cooperative and Human Aspects of Software Engineering},
pages = {121–132},
numpages = {12},
keywords = {AI for SE, social science fiction, human aspects of software development, qualitative experiment},
location = {Lisbon, Portugal},
series = {CHASE '24}
}

@inproceedings{10.1145/3571473.3571488,
author = {Bezerra, Carla and Coutinho, Emanuel},
title = {Teaching software processes from different application domains},
year = {2023},
isbn = {9781450399999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571473.3571488},
doi = {10.1145/3571473.3571488},
abstract = {In a current application development scenario in different environments, technologies and contexts, such as IoT, Blockchain, Machine Learning and Cloud Computing, there is a need for particular solutions for domain-specific software development processes. The proper definition of software processes requires understanding the involved teams and organization’s particularities and specialized technical knowledge in Software Engineering. Although it is an essential part of Software Engineering, many university curricula do not dedicate as much effort to teach software processes, focusing more on the basic principles of Software Engineering, such as requirements, architecture and programming languages. Another important aspect of software processes is modeling. The modeling of a software process provides a basis for managing, automating and supporting the software process improvement. In this context, teaching software process modeling becomes challenging, mainly due to the great emphasis on theory and few practices. This work presents an experience report teaching the definition and modeling of software processes in different domains. We applied in the discipline of software processes a practice for defining and modeling processes in various application domains, such as: IoT, cloud, mobile, critical systems, self-adaptive systems and games. The processes were modeled in the Eclipse Process Framework (EPF) Composer tool based on references from the literature for each domain. In the end, we evaluated the process modeling practice with the students. We concluded that the modeling tool and the maturity in the domain are essential for the good performance of the process.},
booktitle = {Proceedings of the XXI Brazilian Symposium on Software Quality},
articleno = {29},
numpages = {10},
keywords = {education., software process, systems domain},
location = {Curitiba, Brazil},
series = {SBQS '22}
}

@inproceedings{10.1145/3607720.3607794,
author = {Haman, Samia and Tajmout, Yasser and El Bouzekri El Idrissi, Youn\`{e}s and El Bhiri, Brahim and Moumen, Aniss},
title = {Adoption of advanced technologies in industrial companies: A bibliometric analysis},
year = {2023},
isbn = {9798400700194},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607720.3607794},
doi = {10.1145/3607720.3607794},
abstract = {Recently, supply chain has undergone major changes that increased its complexity. In this sense, we have seen a growing interest in applying industry 4.0 technologies. Indeed, recent advances made companies interested in adopting this new concept and be part of the fourth industrial revolution, especially machine learning and artificial intelligence. It is essential to study the adoption of those new technologies by companies. This study aims to provide a list of the most recurrent technology adoption models, identify the theoretical and empirical approaches, and the sample size of the studies by analyzing the current literature. To elaborate this bibliometric study we used scientific databases: Scopus and web of science, where we have found 183 references, that we extracted using Zotero.},
booktitle = {Proceedings of the 6th International Conference on Networking, Intelligent Systems &amp; Security},
articleno = {65},
numpages = {5},
keywords = {Bibliometric analysis, Industry 4.0, Industry 4.0 technologies, Supply chain, Technology adoption},
location = {Larache, Morocco},
series = {NISS '23}
}

@inproceedings{10.1145/3644815.3644986,
author = {Husen, Jati H. and Runpakprakun, Jomphon and Chang, Sun and Washizaki, Hironori and Tun, Hnin Thandar and Yoshioka, Nobukazu and Fukazawa, Yoshiaki},
title = {Evaluation of The Generality of Multi-view Modeling Framework for ML Systems},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644986},
doi = {10.1145/3644815.3644986},
abstract = {Multi-View Modeling Framework for ML Systems (M3S) provides a framework to synchronize the experimental nature of machine learning and the deterministic side of traditional software engineering. However, understanding the framework's generality and limitations still requires further investigation. This paper compares the existing validation case study to a new case study of the OCT image diagnosis support system. The comparison between the two case studies shows M3S capability to handle variations in the nature of ML system analysis. However, the framework's capability to handle different ML tasks other than multi-class classification still requires further investigation.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {284–285},
numpages = {2},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3597503.3608130,
author = {Arteaga Garcia, Emily Judith and Nicolaci Pimentel, Jo\~{a}o Felipe and Feng, Zixuan and Gerosa, Marco and Steinmacher, Igor and Sarma, Anita},
title = {How to Support ML End-User Programmers through a Conversational Agent},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3608130},
doi = {10.1145/3597503.3608130},
abstract = {Machine Learning (ML) is increasingly gaining significance for enduser programmer (EUP) applications. However, machine learning end-user programmers (ML-EUPs) without the right background face a daunting learning curve and a heightened risk of mistakes and flaws in their models. In this work, we designed a conversational agent named "Newton" as an expert to support ML-EUPs. Newton's design was shaped by a comprehensive review of existing literature, from which we identified six primary challenges faced by ML-EUPs and five strategies to assist them. To evaluate the efficacy of Newton's design, we conducted a Wizard of Oz within-subjects study with 12 ML-EUPs. Our findings indicate that Newton effectively assisted ML-EUPs, addressing the challenges highlighted in the literature. We also proposed six design guidelines for future conversational agents, which can help other EUP applications and software engineering activities.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {53},
numpages = {12},
keywords = {end-user programming, conversational agent, wizard of Oz},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3663529.3663857,
author = {Kim, Dong Jae and Locke, Steven and Chen, Tse-Hsun (Peter) and Toma, Andrei and Sajedi, Sarah and Sporea, Steve and Weinkam, Laura},
title = {Decoding Anomalies! Unraveling Operational Challenges in Human-in-the-Loop Anomaly Validation},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663857},
doi = {10.1145/3663529.3663857},
abstract = {Artificial intelligence has been driving new industrial solutions for challenging problems in recent years, with many companies leveraging AI to enhance business processes and products. Automated anomaly detection emerges as one of the top priorities in AI adoption, sought after by numerous small to large-scale enterprises. Extending beyond domain-specific applications like software log analytics, where anomaly detection has perhaps garnered the most interest in software engineering, we find that very little research effort has been devoted to post-anomaly detection, such as validating anomalies. For example, validating anomalies requires human-in-the-loop interaction, though working with human experts is challenging due to uncertain requirements on how to elicit valuable feedback from them, posing formidable operationalizing challenges. In this study, we provide an experience report delving into a more holistic view of the complexities of adopting effective anomaly detection models from a requirement engineering perspective. We address challenges and provide solutions to mitigate challenges associated with operationalizing anomaly detection from diverse perspectives: inherent issues in dynamic datasets, diverse business contexts, and the dynamic interplay between human expertise and AI guidance in the decision-making process. We believe our experience report will provide insights for other companies looking to adopt anomaly detection in their own business settings.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {382–387},
numpages = {6},
keywords = {Anomaly Validation, Requirement Engineering},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3603555.3608564,
author = {Liu, Shi and Schulz, Thimo and Toreini, Peyman and Maedche, Alexander},
title = {An Immersive Learning Factory for AI &amp; Data Literacy: An Exploratory Study in the Wild},
year = {2023},
isbn = {9798400707711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603555.3608564},
doi = {10.1145/3603555.3608564},
abstract = {Artificial Intelligence (AI) has already made a strong impact on business and private life. Nonetheless, understanding how AI works and which role data plays in this context still remains unclear for many people. We argue that students with non-technical backgrounds should build up AI &amp; data literacy to understand the key concepts of AI &amp; data and leverage its potential in their field of study and research. For this purpose, we present the concept of an immersive learning factory, where students can explore AI &amp; data concepts with interactive and immersive technologies. In this paper, we demonstrate our overarching idea, as well as the results of our exploratory evaluation with industrial engineering &amp; management students from a data science lecture. Our main contribution includes the conceptual framework of the immersive learning factory, as well as design guidelines for creating immersive learning experiences concluded from the evaluation.},
booktitle = {Proceedings of Mensch Und Computer 2023},
pages = {349–353},
numpages = {5},
keywords = {AI literacy, learning factory, mixed reality},
location = {Rapperswil, Switzerland},
series = {MuC '23}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00065,
author = {Mojica-Hanke, Anamaria},
title = {Towards Machine Learning Guided by Best Practices},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00065},
doi = {10.1109/ICSE-Companion58688.2023.00065},
abstract = {Nowadays, machine learning (ML) is being used in software systems with multiple application fields, from medicine to software engineering (SE). On the one hand, the popularity of ML in the industry can be seen in the statistics showing its growth and adoption. On the other hand, its popularity can also be seen in research, particularly in SE, where multiple studies related to the use of Machine Learning in Software Engineering have been published in conferences and journals. At the same time, researchers and practitioners have shown that machine learning has some particular challenges and pitfalls. In particular, research has shown that ML-enabled systems have a different development process than traditional software, which also describes some of the challenges of ML applications. In order to mitigate some of the identified challenges and pitfalls, white and gray literature has proposed a set of recommendations based on their own experiences and focused on their domain (e.g., biomechanics), but for the best of our knowledge, there is no guideline focused on the SE community. This thesis aims to reduce the gap of not having clear guidelines in the SE community by using possible sources of practices such as question-and-answer communities and also previous research studies. As a result, we will present a set of practices with an SE perspective, for researchers and practitioners, including a tool for searching them.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {240–244},
numpages = {5},
keywords = {machine learning, good practices, software engineering},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3540250.3569444,
author = {Gulwani, Sumit},
title = {AI-assisted programming: applications, user experiences, and neuro-symbolic techniques (keynote)},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3569444},
doi = {10.1145/3540250.3569444},
abstract = {AI can enhance programming experiences for a diverse set of programmers: from professional developers and data scientists (proficient programmers) who need help in software engineering and data wrangling, all the way to spreadsheet users (low-code programmers) who need help in authoring formulas, and students (novice programmers) who seek hints when stuck with their programming homework. To communicate their need to AI, users can express their intent explicitly—as input-output examples or natural-language specification—or implicitly—where they encounter a bug (and expect AI to suggest a fix), or simply allow AI to observe their last few lines of code or edits (to have it suggest the next steps).  

The task of synthesizing an intended program snippet from the user’s intent is both a search and a ranking problem. Search is required to discover candidate programs that correspond to the (often ambiguous) intent, and ranking is required to pick the best program from multiple plausible alternatives. This creates a fertile playground for combining symbolic-reasoning techniques, which model the semantics of programming operators, and machine-learning techniques, which can model human preferences in programming. Recent advances in large language models like Codex offer further promise to advance such neuro-symbolic techniques.  

Finally, a few critical requirements in AI-assisted programming are usability, precision, and trust; and they create opportunities for innovative user experiences and interactivity paradigms. In this talk, I will explain these concepts using some existing successes, including the Flash Fill feature in Excel, Data Connectors in PowerQuery, and IntelliCode/CoPilot in Visual Studio. I will also describe several new opportunities in AI-assisted programming, which can drive the next set of foundational neuro-symbolic advances.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1},
numpages = {1},
keywords = {Interactive Programming, Machine Learning, Program Synthesis, Symbolic Reasoning},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3661304.3661901,
author = {Sequeda, Juan and Allemang, Dean and Jacob, Bryon},
title = {A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases},
year = {2024},
isbn = {9798400706530},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661304.3661901},
doi = {10.1145/3661304.3661901},
abstract = {Enterprise applications of Large Language Models (LLMs) hold promise for question answering on enterprise SQL databases. However, the extent to which LLMs can accurately respond to enterprise questions in such databases remains unclear, given the absence of suitable Text-to-SQL benchmarks tailored to enterprise settings. Additionally, the potential of Knowledge Graphs (KGs) to enhance LLM-based question answering by providing business context is not well understood. This study aims to evaluate the accuracy of LLM-powered question answering systems in the context of enterprise questions and SQL databases, while also exploring the role of knowledge graphs in improving accuracy. To achieve this, we introduce a benchmark comprising an enterprise SQL schema in the insurance domain, a range of enterprise queries encompassing reporting to metrics, and a contextual layer incorporating an ontology and mappings that define a knowledge graph. Our primary finding reveals that question answering using GPT-4, with zero-shot prompts directly on SQL databases, achieves an accuracy of 16%. Notably, this accuracy increases to 54% when questions are posed over a Knowledge Graph representation of the enterprise SQL database. Therefore, investing in Knowledge Graph provides higher accuracy for LLM powered question answering systems.},
booktitle = {Proceedings of the 7th Joint Workshop on Graph Data Management Experiences &amp; Systems (GRADES) and Network Data Analytics (NDA)},
articleno = {5},
numpages = {12},
location = {Santiago, AA, Chile},
series = {GRADES-NDA '24}
}

@inproceedings{10.1145/3658271.3658342,
author = {Albuquerque, Beatriz Ventorini Lins de and Cunha, Antonio Fernando Souza da and Souza, Leonardo and Siqueira, Sean Wolfgand Matsui and Santos, Rodrigo Pereira dos},
title = {Generating and Reviewing Programming Codes with Large Language Models: A Systematic Mapping Study},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658271.3658342},
doi = {10.1145/3658271.3658342},
abstract = {Context: The proliferation of technologies based on Large Language Models (LLM) is reshaping various domains, also impacting on programming code creation and review. Problem: The decision-making process in adopting LLM in software development demands an understanding of associated challenges and diverse application possibilities. Solution: This study addresses the identified challenges linked to LLM utilization in programming code processes. It explores models, utilization strategies, challenges, and coping mechanisms, focusing on the perspectives of researchers in software development. IS Theory: Drawing on Task-Technology Fit (TTF) theory, the research examines the alignment between task characteristics in code generation and review, and LLM technology attributes to discern performance impacts and utilization patterns. Method: Employing the Systematic Mapping of the Literature method, the research analyzes 19 selected studies from digital databases—IEEE Digital Library, Compendex Engineering Village, and Scopus—out of 1,257 retrieved results. Summary of Results: The research reveals 23 models, 13 utilization strategies, 15 challenges, and 14 coping mechanisms associated with LLM in programming code processes, offering a comprehensive understanding of the application landscape. Contributions to IS: Contributing to the Information Systems (IS) field, This study provides valuable insights into the utilization of LLM in programming code generation and review. The identified models, strategies, challenges, and coping mechanisms offer practical guidance for decision-making processes related to LLM technology adoption. The research aims to support the IS community in effectively navigating the complexities of integrating large language models into the dynamic software development lifecycle.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {70},
numpages = {10},
keywords = {Code Generation, LLM, automatic refactoring, code auto-suggestion, code completion, natural language models, neural network, systematic mapping study, transformer architecture},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

@inproceedings{10.1145/3663649.3664375,
author = {Yang, Jun and Gilad, Amir and Hu, Yihao and Meng, Hanze and Miao, Zhengjie and Roy, Sudeepa and Stephens-Martinez, Kristin},
title = {What Teaching Databases Taught Us about Researching Databases: Extended Talk Abstract},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664375},
doi = {10.1145/3663649.3664375},
abstract = {Declarative querying is a cornerstone of the success and longevity of database systems, yet it is challenging for novice learners accustomed to different coding paradigms. The transition is further hampered by a lack of query debugging tools compared to the plethora available for programming languages. The paper samples several systems that we build at Duke University to help students learn and debug database queries. These systems have not only helped scale up teaching and improve learning, but also inspired interesting research on databases. Furthermore, with the rise of generative AI, we argue that there is a heightened need for skills in scrutinizing and debugging AI-generated queries, and we outline several ongoing and future work directions aimed at addressing this challenge.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {1–6},
numpages = {6},
keywords = {Database Education, Query Debugging, Query Verification, Relational Algebra, SQL},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{10.1145/3626252.3630874,
author = {Shen, Yiyin and Ai, Xinyi and Soosai Raj, Adalbert Gerald and Leo John, Rogers Jeffrey and Syamkumar, Meenakshi},
title = {Implications of ChatGPT for Data Science Education},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630874},
doi = {10.1145/3626252.3630874},
abstract = {ChatGPT is a conversational AI platform that can produce code to solve problems when provided with a natural language prompt. Prior work on similar AI models has shown that they perform well on typical intro-level Computer Science problems. However, little is known about the performance of such tools on Data Science (DS) problems. In this work, we assess the performance of ChatGPT on assignments from three DS courses with varying difficulty levels. First, we apply the raw assignment prompts provided to the students and find that ChatGPT performs well on assignments with dataset(s) descriptions and progressive question prompts, which divide the programming requirements into sub-problems. Then, we perform prompt engineering on the assignments for which ChatGPT had low performance. We find that the following prompt engineering techniques significantly increased ChatGPT's performance: breaking down abstract questions into steps, breaking down steps into multiple prompts, providing descriptions of the dataset(s), including algorithmic details, adding specific instructions to entice specific actions, and removing extraneous information. Finally, we discuss how our findings suggest potential changes to curriculum design of DS courses.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1230–1236},
numpages = {7},
keywords = {data science education, large language models, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3632366.3632373,
author = {Marino, Roberto and Carnevale, Lorenzo and Fazio, Maria and Villari, Massimo},
title = {Make Federated Learning a Standard in Robotics by Using ROS2},
year = {2024},
isbn = {9798400704734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632366.3632373},
doi = {10.1145/3632366.3632373},
abstract = {The use of the Federated Learning paradigm could be disruptive in robotics, where data are naturally distributed among teams of agents and centralizing them would increase latency and break privacy. Unfortunately there are a lack of robot oriented framework for federated learning that use state of the art machine learning libraries. ROS2 (Robot Operating Systems) is a standard de-facto in robotics for building up teams of robots in a multi-node fully distributed manner. In this paper we presents the integration of ROS2 with PyTorch allowing an easy training of a global machine learning model starting from a set of local datasets. We present the architecture, the used methodology and finally we discuss the experimentation results over a well-known public dataset.},
booktitle = {Proceedings of the IEEE/ACM 10th International Conference on Big Data Computing, Applications and Technologies},
articleno = {20},
numpages = {6},
keywords = {federated learning, robotics, ROS, PyTorch, distributed intelligence, machine learning},
location = {Taormina (Messina), Italy},
series = {BDCAT '23}
}

@inproceedings{10.1145/3551349.3559564,
author = {Zhang, Yifan},
title = {Leveraging Artificial Intelligence on Binary Code Comprehension},
year = {2023},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551349.3559564},
doi = {10.1145/3551349.3559564},
abstract = {Understanding binary code is an essential but complex software engineering task for reverse engineering, malware analysis, and compiler optimization. Unlike source code, binary code has limited semantic information, which makes it challenging for human comprehension. At the same time, compiling source to binary code, or transpiling among different programming languages (PLs) can provide a way to introduce external knowledge into binary comprehension. We propose to develop Artificial Intelligence (AI) models that aid human comprehension of binary code. Specifically, we propose to incorporate domain knowledge from large corpora of source code (e.g., variable names, comments) to build AI models that capture a generalizable representation of binary code. Lastly, we will investigate metrics to assess the performance of models that apply to binary code by using human studies of comprehension.},
booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
articleno = {125},
numpages = {3},
location = {Rochester, MI, USA},
series = {ASE '22}
}

@inproceedings{10.1145/3700297.3700362,
author = {Wang, Yaping and Hanafi Zaid, Yasmin and Li, Jimei and Pan, Ying},
title = {Opportunities and Challenges of Using ChatGPT as a Teaching Assistant in English Language Teaching: A Systematic Literature Review},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700362},
doi = {10.1145/3700297.3700362},
abstract = {With the development of artificial intelligence (AI) technology, particularly the widespread application of ChatGPT in the field of natural language processing, the education sector has gradually recognized its potential in enhancing the effectiveness of English language teaching (ELT). Although there are numerous relevant studies, there has yet to be a comprehensive analysis of this topic through a systematic literature review (SLR). Therefore, this study adopts the method of systematic literature review, selecting relevant literature from the Scopus and Web of Science (WoS) databases, and rigorously evaluating and screening studies that meet the criteria, to systematically analyze the current state of ChatGPT's application in ELT. Through analyzing the publication trends, geographical distribution, opportunities, and challenges, as well as the most frequent keywords, this study provides valuable insights for scholars, educators, and policymakers, particularly regarding how to more effectively utilize ChatGPT to enhance the quality of ELT. The study also proposes future research directions, including: (1) increasing attention to the potential opportunities of ChatGPT in ELT, (2) deepening the analysis of the challenges encountered in its application, and (3) offering specific teaching suggestions for the integration of ChatGPT into teaching practices. Although research in this field is still in its initial development stages, with ongoing technological advancements and changing educational needs, this field holds significant potential for future research and application. ChatGPT is poised to bring groundbreaking progress and innovation, offering new pathways and tools for the reform and optimization of ELT.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {375–382},
numpages = {8},
keywords = {AI, ChatGPT, ELT, opportunities and challenges, teaching suggestions},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3629479.3629514,
author = {Silva, Sara and De Fran\c{c}a, Breno Bernard Nicolau},
title = {A Case Study on Data Science Processes in an Academia-Industry Collaboration},
year = {2023},
isbn = {9798400707865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629479.3629514},
doi = {10.1145/3629479.3629514},
abstract = {Data Science (DS) is emerging in major software development projects and often needs to follow software development practices. Therefore, DS processes will likely continue to attract Software Engineering (SE) practices and vice-versa. This case study aims to map and describe a software development process for Machine Learning(ML)-enabled applications and associated practices used in a real DS project at the Recod.ai laboratory in collaboration with an industrial partner. The focus was to analyze the process and identify the strengths and primary challenges, considering their expertise in robust ML practices and how they can contribute to general software quality. To achieve this, we conducted semi-structured interviews and analyzed them using procedures from the Straussian Grounded Theory. The results showed that the DS development process is iterative, with feedback between activities, which differs from the processes in the literature. Additionally, this process presents a greater involvement of domain experts. Besides, the team prioritizes software quality characteristics (attributes) in these DS projects to ensure some aspects of the final product’s quality, i.e., functional correctness and robustness. To achieve those, they use regular accuracy metrics and include explainability and data leakage as quality metrics during training. Finally, the software engineer’s role and its responsibilities differ from those of a traditional industry software engineer, as s/he is involved in most of the process steps. These characteristics can contribute to high-quality models achieving the partner needs and, consequently, relevant contributions to the intersection between SE and DS.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Software Quality},
pages = {1–10},
numpages = {10},
keywords = {case study, data science, machine learning, software processes},
location = {Bras\'{\i}lia, Brazil},
series = {SBQS '23}
}

@article{10.1145/3498326,
author = {Robe, Peter and Kuttal, Sandeep Kaur},
title = {Designing PairBuddy—A Conversational Agent for Pair Programming},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {4},
issn = {1073-0516},
url = {https://doi.org/10.1145/3498326},
doi = {10.1145/3498326},
abstract = {From automated customer support to virtual assistants, conversational agents have transformed everyday interactions, yet despite phenomenal progress, no agent exists for programming tasks. To understand the design space of such an agent, we prototyped PairBuddy—an interactive pair programming partner—based on research from conversational agents, software engineering, education, human-robot interactions, psychology, and artificial intelligence. We iterated PairBuddy’s design using a series of Wizard-of-Oz studies. Our pilot study of six programmers showed promising results and provided insights toward PairBuddy’s interface design. Our second study of 14 programmers was positively praised across all skill levels. PairBuddy’s active application of soft skills—adaptability, motivation, and social presence—as a navigator increased participants’ confidence and trust, while its technical skills—code contributions, just-in-time feedback, and creativity support—as a driver helped participants realize their own solutions. PairBuddy takes the first step towards an Alexa-like programming partner.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = may,
articleno = {34},
numpages = {44},
keywords = {Conversational agents, pair programming, user centered design, Wizard of Oz}
}

@inproceedings{10.1145/3639478.3643530,
author = {Monjezi, Verya and Kumar, Ashish and Tan, Gang and Trivedi, Ashutosh and Tizpaz-Niari, Saeid},
title = {Causal Graph Fuzzing for Fair ML Sofware Development},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3643530},
doi = {10.1145/3639478.3643530},
abstract = {Machine learning (ML) is increasingly used in high-stakes areas like autonomous driving, finance, and criminal justice. However, it often unintentionally perpetuates biases against marginalized groups. To address this, the software engineering community has developed fairness testing and debugging methods, establishing best practices for fair ML software. These practices focus on training model design, including the selection of sensitive and non-sensitive attributes and hyperparameter configuration. However, the application of these practices across different socio-economic and cultural contexts is challenging, as societal constraints vary.Our study proposes a search-based software engineering approach to evaluate the robustness of these fairness practices. We formulate these practices as the first-order logic properties and search for two neighborhood datasets where the practice satisfies in one dataset, but fail in the other one. Our key observation is that these practices should be general and robust to various uncertainty such as noise, faulty labeling, and demographic shifts. To generate datasets, we sift to the causal graph representations of datasets and apply perturbations over the causal graphs to generate neighborhood datasets. In this short paper, we show our methodology using an example of predicting risks in the car insurance application.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {402–403},
numpages = {2},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3689935.3690394,
author = {Reti, Daniel and Becker, Norman and Angeli, Tillmann and Chattopadhyay, Anasuya and Schneider, Daniel and Vollmer, Sebastian and Schotten, Hans D.},
title = {Act as a Honeytoken Generator! An Investigation into Honeytoken Generation with Large Language Models},
year = {2024},
isbn = {9798400712319},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689935.3690394},
doi = {10.1145/3689935.3690394},
abstract = {With the increasing prevalence of security incidents, the adoption of deception-based defense strategies has become pivotal in cybersecurity. This work addresses the challenge of scalability in designing honeytokens, a key component of such defense mechanism. The manual creation of honeytokens is a tedious task. Although automated generators exists, they often lack versatility, being specialized for specific types of honeytokens, and heavily rely on suitable training datasets. To overcome these limitations, this work systematically investigates the approach of utilizing Large Language Models (LLMs) to create a variety of honeytokens. Out of the seven different honeytoken types created in this work, such as configuration files, databases, and log files, two were used to evaluate the optimal prompt. The generation of robots.txt files and honeywords was used to systematically test 210 different prompt structures, based on 16 prompt building blocks. Furthermore, all honeytokens were tested across different state-of-the-art LLMs to assess the varying performance of different models. Prompts performing optimally on one LLM do not necessarily generalize well to another. Honeywords generated by GPT-3.5 were found to be less distinguishable from real passwords compared to previous methods of automated honeyword generation.Overall, the findings of this work demonstrate that generic LLMs are capable of creating a wide array of honeytokens using the presented prompt structures.},
booktitle = {Proceedings of the 11th ACM Workshop on Adaptive and Autonomous Cyber Defense},
pages = {1–12},
numpages = {12},
keywords = {cyber deception, gpt, honeytoken, honeywords, large language models, llm, network security},
location = {Salt Lake City, UT, USA},
series = {AACD '24}
}

@inproceedings{10.1145/3624062.3624100,
author = {Hall, Mary and Gopalakrishnan, Ganesh and Eide, Eric and Cohoon, Johanna and Phillips, Jeff and Zhang, Mu and Elhabian, Shireen and Bhaskara, Aditya and Dam, Harvey and Yadrov, Artem and Kataria, Tushar and Tavakkoli, Amir Mohammad and Joshi, Sameeran and Karanam, Mokshagna Sai Teja},
title = {An NSF REU Site Based on Trust and Reproducibility of Intelligent Computation: Experience Report},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3624100},
doi = {10.1145/3624062.3624100},
abstract = {This paper presents an overview of an NSF Research Experience for Undergraduate (REU) Site on Trust and Reproducibility of Intelligent Computation, delivered by faculty and graduate students in the Kahlert School of Computing at University of Utah. The chosen themes bring together several concerns for the future in producing computational results that can be trusted: secure, reproducible, based on sound algorithmic foundations, and developed in the context of ethical considerations. The research areas represented by student projects include machine learning, high-performance computing, algorithms and applications, computer security, data science, and human-centered computing. In the first four weeks of the program, the entire student cohort spent their mornings in lessons from experts in these crosscutting topics, and used one-of-a-kind research platforms operated by the University of Utah, namely NSF-funded CloudLab and POWDER facilities; reading assignments, quizzes, and hands-on exercises reinforced the lessons. In the subsequent five weeks, lectures were less frequent, as students branched into small groups to develop their research projects. The final week focused on a poster presentation and final report. Through describing our experiences, this program can serve as a model for preparing a future workforce to integrate machine learning into trustworthy and reproducible applications.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {343–349},
numpages = {7},
keywords = {HPC, ML, artifact evaluation, networking, undergraduate education},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@inproceedings{10.1145/3672758.3672763,
author = {Peng, Li and Fu, Bihan},
title = {Development and Research of Generative Animation Based on AIGC},
year = {2024},
isbn = {9798400716942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672758.3672763},
doi = {10.1145/3672758.3672763},
abstract = {AIGC is the automatic generation of relevant content from a large number of models and databases based on the input of relevant instructions. This paper mainly discusses the development of artificial intelligence generation technology in animation in the form of images. With the rapid development of artificial intelligence technology, generative animation content has become an important way of animation production and production in modern society. Artificial intelligence-based generative animation is taking up an increasing proportion of the film, game, advertising and other industries, AIGC has been rapidly developed by virtue of its lower production cost and higher production efficiency, which constantly impacts the development of the animation industry and attracts the widespread attention of animation creators. This paper analyses the Generative Adversarial Network and Diffusion Model through the deep learning principle of AIGC technology, and explores the important impact of AIGC technology on the form of generative animation. Using computer discipline thinking to analyse the type of AIGC model for animation creation, and according to the model simulation results of AIGC technology used in generative animation production of technology, market aspects of its development prospects are summarised.},
booktitle = {Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering},
pages = {22–28},
numpages = {7},
location = {Xi' an, China},
series = {CAICE '24}
}

@inproceedings{10.1109/ASE56229.2023.00089,
author = {Li, Tsz-On and Zong, Wenxi and Wang, Yibo and Tian, Haoye and Wang, Ying and Cheung, Shing-Chi and Kramer, Jeff},
title = {Nuances Are the Key: Unlocking ChatGPT to Find Failure-Inducing Tests with Differential Prompting},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00089},
doi = {10.1109/ASE56229.2023.00089},
abstract = {Automated detection of software failures is an important but challenging software engineering task. It involves finding in a vast search space the failure-inducing test cases that contain an input triggering the software fault and an oracle asserting the incorrect execution. We are motivated to study how far this outstanding challenge can be solved by recent advances in large language models (LLMs) such as ChatGPT. However, our study reveals that ChatGPT has a relatively low success rate (28.8%) in finding correct failure-inducing test cases for buggy programs. A possible conjecture is that finding failure-inducing test cases requires analyzing the subtle differences (nuances) between the tokens of a program's correct version and those for its buggy version. When these two versions have similar sets of tokens and attentions, ChatGPT is weak in distinguishing their differences.We find that ChatGPT can successfully generate failure-inducing test cases when it is guided to focus on the nuances. Our solution is inspired by an interesting observation that ChatGPT could infer the intended functionality of buggy code if it is similar to the correct version. Driven by the inspiration, we develop a novel technique, called Differential Prompting, to effectively find failure-inducing test cases with the help of the compilable code synthesized by the inferred intention. Prompts are constructed based on the nuances between the given version and the synthesized code. We evaluate Differential Prompting on Quixbugs (a popular benchmark of buggy programs) and recent programs published at Codeforces (a popular programming contest portal, which is also an official benchmark of ChatGPT). We compare Differential Prompting with two baselines constructed using conventional ChatGPT prompting and Pynguin (the state-of-the-art unit test generation tool for Python programs). Our evaluation results show that for programs of Quixbugs, Differential Prompting can achieve a success rate of 75.0% in finding failure-inducing test cases, outperforming the best baseline by 2.6X. For programs of Codeforces, Differential Prompting's success rate is 66.7%, outperforming the best baseline by 4.0X.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {14–26},
numpages = {13},
keywords = {failure-inducing test cases, large language models, program intention inference, program generation},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00064,
author = {Melo, Glaucia},
title = {Designing Adaptive Developer-Chatbot Interactions: Context Integration, Experimental Studies, and Levels of Automation},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00064},
doi = {10.1109/ICSE-Companion58688.2023.00064},
abstract = {The growing demand for software developers and the increasing development complexity have emphasized the need for support in software engineering projects. This is especially relevant in light of advancements in artificial intelligence, such as conversational systems. A significant contributor to the complexity of software development is the multitude of tools and methods used, creating various contexts in which software developers must operate. Moreover, there has been limited investigation into the interaction between context-based chatbots and software developers through experimental user studies. Assisting software developers in their work becomes essential. In particular, understanding the context surrounding software development and integrating this context into chatbots can lead to novel insight into what software developers expect concerning these human-chatbot interactions and their levels of automation. In my research, I study the design of context-based adaptive interactions between software developers and chatbots to foster solutions and knowledge to support software developers at work.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {235–239},
numpages = {5},
keywords = {software engineering, context, chatbot, levels of automation, autonomous systems, interactions},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3576050.3576064,
author = {Lin, Jionghao and Dai, Wei and Lim, Lisa-Angelique and Tsai, Yi-Shan and Mello, Rafael Ferreira and Khosravi, Hassan and Gasevic, Dragan and Chen, Guanliang},
title = {Learner-centred Analytics of Feedback Content in Higher Education},
year = {2023},
isbn = {9781450398657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576050.3576064},
doi = {10.1145/3576050.3576064},
abstract = {Feedback is an effective way to assist students in achieving learning goals. The conceptualisation of feedback is gradually moving from feedback as information to feedback as a learner-centred process. To demonstrate feedback effectiveness, feedback as a learner-centred process should be designed to provide quality feedback content and promote student learning outcomes on the subsequent task. However, it remains unclear how instructors adopt the learner-centred feedback framework for feedback provision in the teaching practice. Thus, our study made use of a comprehensive learner-centred feedback framework to analyse feedback content and identify the characteristics of feedback content among student groups with different performance changes. Specifically, we collected the instructors’ feedback on two consecutive assignments offered by an introductory to data science course at the postgraduate level. On the basis of the first assignment, we used the status of student grade changes (i.e., students whose performance increased and those whose performance did not increase on the second assignment) as the proxy of the student learning outcomes. Then, we engineered and extracted features from the feedback content on the first assignment using a learner-centred feedback framework and further examined the differences of these features between different groups of student learning outcomes. Lastly, we used the features to predict student learning outcomes by using widely-used machine learning models and provided the interpretation of predicted results by using the SHapley Additive exPlanations (SHAP) framework. We found that 1) most features from the feedback content presented significant differences between the groups of student learning outcomes, 2) the gradient boost tree model could effectively predict student learning outcomes, and 3) SHAP could transparently interpret the feature importance on predictions.},
booktitle = {LAK23: 13th International Learning Analytics and Knowledge Conference},
pages = {100–110},
numpages = {11},
keywords = {Content Analysis, Feedback, Interpretability, Learning Analytics},
location = {Arlington, TX, USA},
series = {LAK2023}
}

@inproceedings{10.1145/3605098.3636056,
author = {Idowu, Samuel and Sens, Yorick and Berger, Thorsten and Krueger, Jacob and Vierhauser, Michael},
title = {A Large-Scale Study of ML-Related Python Projects},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636056},
doi = {10.1145/3605098.3636056},
abstract = {The rise of machine learning (ML) for solving current and future problems increased the production of ML-enabled software systems. Unfortunately, standardized tool chains for developing, employing, and maintaining such projects are not yet mature, which can mainly be attributed to a lack of understanding of the properties of ML-enabled software. For instance, it is still unclear how to manage and evolve ML-specific assets together with other software-engineering assets. In particular, ML-specific tools and processes, such as those for managing ML experiments, are often perceived as incompatible with practitioners' software engineering tools and processes. To design new tools for developing ML-enabled software, it is crucial to understand the properties and current problems of developing these projects by eliciting empirical data from real projects, including the evolution of the different assets involved. Moreover, while studies in this direction have recently been conducted, identifying certain types of ML-enabled projects (e.g., experiments, libraries and software systems) remains a challenge for researchers. We present a large-scale study of over 31,066 ML projects found on GitHub, with an emphasis on their development stages and evolution. Our contributions include a dataset, together with empirical data providing an overview of the existing project types and analysis of the projects' properties and characteristics, especially regarding the implementation of different ML development stages and their evolution. We believe that our results support researchers, practitioners, and tool builders conduct follow-up studies and especially build novel tools for managing ML projects, ideally unified with traditional software-engineering tools.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {1272–1281},
numpages = {10},
keywords = {machine learning, ml-enabled systems, evolution, mining study, open-source projects, large-scale study, tensorflow, scikit-learn},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3580305.3599563,
author = {Zhong, Zhiqiang and Mottin, Davide},
title = {Knowledge-augmented Graph Machine Learning for Drug Discovery: From Precision to Interpretability},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599563},
doi = {10.1145/3580305.3599563},
abstract = {Conventional Artificial Intelligence models are heavily limited in handling complex biomedical structures (such as 2D or 3D protein and molecule structures) and providing interpretations for outputs, which hinders their practical application. Graph Machine Learning (GML) has gained considerable attention for its exceptional ability to model graph-structured biomedical data and investigate their properties and functional relationships. Despite extensive efforts, GML methods still suffer from several deficiencies, such as the limited ability to handle supervision sparsity and provide interpretability in learning and inference processes and their ineffectiveness in utilising relevant domain knowledge. In response, recent studies have proposed integrating external biomedical knowledge into the GML pipeline to realise more precise and interpretable drug discovery with limited training instances.This tutorial presents a comprehensive overview of long-standing drug discovery principles, provides the foundational concepts and cutting-edge techniques for graph-structured data and knowledge databases, and formally summarises Knowledge-augmented Graph Machine Learning (KaGML) for drug discovery. We have recently completed a survey of KaGML works that organises the outstanding approaches into four categories following a novel-defined taxonomy. This tutorial will present the result of this scholarly work. To encourage audience participation and facilitate research in this promptly emerging field, we also share valuable practical resources for intelligent drug discovery and provide an in-depth discussion of the potential avenues for future advancements.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5841–5842},
numpages = {2},
keywords = {artificial intelligence, deep learning, drug discovery., graph machine learning, knowledge-augmented methods, machine learning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3571697.3571707,
author = {Mavrogiorgou, Argyro and Koukos, Vasileios and Kouremenou, Eleftheria and Kiourtis, Athanasios and Raikos, Alexandros and Manias, George and Kyriazis, Dimosthenis},
title = {A Cross-domain Data Marketplace for Data Sharing},
year = {2023},
isbn = {9781450397308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571697.3571707},
doi = {10.1145/3571697.3571707},
abstract = {In recent years, vast amounts of data are generated from a plethora of devices, systems, and platforms, covering a wide range of domains. This data increase generates the necessity to access a wide range of technical and technological resources enabling efficient and ready-to-use data analysis solutions, including resources for training and learning in addition to data infrastructure elements, as well as Artificial Intelligence (AI)/Machine Learning (ML) techniques. Current solutions are siloed, and instead of being structured, integrated, and openly accessible from a single-entry point, they still tend to be fragmented and proprietary. To address this gap, the concept of data marketplaces has been generated including a plethora of solutions, in the form of data assets, for offering an access point to the aforementioned services. Though, current data marketplaces lack of genericity since they are tailored and implemented under specific domains, not being able to fully offer a single-entry point towards interdisciplinary ready-to-use data management solutions and assets. This paper describes a cross-domain Data Marketplace, as a unified web-based platform that offers to its users various ready-to-use data management solutions, supporting different kinds of cross-sector assets including datasets, software components, data science notebooks, as well as multimedia content of software solutions among others. Moreover, it showcases how this Data Marketplace has been designed and specified based on existing marketplaces, while it demonstrates the way that its users are able to search and retrieve assets for resolving their business issues, or achieving some of their educational/research/personal goals.},
booktitle = {Proceedings of the 2022 European Symposium on Software Engineering},
pages = {72–79},
numpages = {8},
keywords = {Data Assets, Data Marketplace, INFINITECH, Open Data, PolicyCLOUD},
location = {Rome, Italy},
series = {ESSE '22}
}

@inproceedings{10.1145/3580305.3599206,
author = {Goldenberg, Dmitri and Ross, Chana and Meir Lador, Shir and Cheong, Lin Lee and Xu, Panpan and Sokolova, Elena and Mandelbaum, Amit and Vasilinetc, Irina and Jain, Ankit and Weil Modlinger, Amit and Potdar, Saloni},
title = {The Second Workshop on Applied Machine Learning Management},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599206},
doi = {10.1145/3580305.3599206},
abstract = {Machine learning applications are rapidly adopted by industry leaders in any field. The growth of investment in AI-driven solutions created new challenges in managing Data Science and ML resources, people and projects as a whole. The discipline of managing applied machine learning teams, requires a healthy mix between agile product development tool-set and a long term research oriented mindset. The abilities of investing in deep research while at the same time connecting the outcomes to significant business results create a large knowledge based on management methods and best practices in the field. The Second KDD Workshop on Applied Machine Learning Management brings together applied research managers from various fields to share methodologies and case-studies on management of ML teams, products, and projects, achieving business impact with advanced AI-methods.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5859–5860},
numpages = {2},
keywords = {data science management, machine learning management, ml product development},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3488162.3488209,
author = {Ribeiro de Oliveira, Taina and Moura da Silva, Matheus and Nepomuceno Spinasse, Rafael Antonio and Giesen Ludke, Gabriel and Ruy Soares Gaudio, Mateus and Iglesias Rocha Gomes, Guilherme and Guio Cotini, Luan and Vargens, Daniel and QUEIROZ SCHIMIDT, MARCELO and Varejao Andreao, Rodrigo and Mestria, Mario},
title = {Systematic Review of Virtual Reality Solutions Employing Artificial Intelligence Methods},
year = {2022},
isbn = {9781450395526},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3488162.3488209},
doi = {10.1145/3488162.3488209},
abstract = {This paper first presents a systematic literature review of artificial intelligence (AI) methods used in virtual reality (VR) solutions. Based on the systematic literature review, a methodology for locating existing studies, selecting and evaluating contributions, performing analyses, and synthesizing data was proposed. We used search engines, such as Google Scholar and databases such as Elsevier's Scopus, ACM Digital Library, and IEEE Xplore Digital Library. A set of inclusion and exclusion criteria was used to select documents. The results showed that the AI scientific technique most applied in VR applications is machine learning. The findings revealed several fields adopting real-world applications that employ AI in VR: human–robot interaction, emotion interaction and behavior recognition, education, agriculture, transport, manufacturing, and health.},
booktitle = {Proceedings of the 23rd Symposium on Virtual and Augmented Reality},
pages = {42–55},
numpages = {14},
keywords = {Artificial intelligence, Industry 4.0, Intelligent virtual environments, Literature review, Virtual reality},
location = {Virtual Event, Brazil},
series = {SVR '21}
}

@inproceedings{10.1145/3664646.3676276,
author = {Cai, Jiahao},
title = {Agents for Data Science: From Raw Data to AI-Generated Notebooks using LLMs and Code Execution (Invited Talk)},
year = {2024},
isbn = {9798400706851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664646.3676276},
doi = {10.1145/3664646.3676276},
abstract = {Data science tasks involve a complex interplay of datasets, code and code outputs for answering questions, deriving insights, or building models from data. Tasks and chosen methods may require specialized data domain or scientific domain knowledge. Queries range from high-level (low-code) or highly technical (high-code). Code execution results, such as plots and tables are artifacts used by data scientists to interpret and reason about the current and future states of a solution towards completing the task. This presents unique challenges in designing, deploying and evaluating LLM-based agents for automating data science workflows. In this talk we will introduce an end-to-end, autonomous Data Science Agent (DSA) built around Gemini and available as an experiment at labs.google/code. DSA leverages agentic flows, planning and orchestration to tackle open-ended data science explorations. It uses LLMs for planning, task decomposition, code generation, reasoning and error-correction through code execution. DSA is designed to streamline the entire data science process, enabling users to query data in natural language, and get from a dataset and prompt to a fully AI-generated, populated notebook. We’ll discuss design choices (prompting, SFT, orchestration), iterative development cycles, evaluation, lessons learned and future challenges. Where applicable, we will showcase real-world case studies demonstrating how DSA can assist with bootstrapping the analysis of data from complex scientific domains.},
booktitle = {Proceedings of the 1st ACM International Conference on AI-Powered Software},
pages = {181},
numpages = {1},
location = {Porto de Galinhas, Brazil},
series = {AIware 2024}
}

@article{10.1145/3565020,
author = {Ribeiro de Oliveira, Tain\~{a} and Biancardi Rodrigues, Brenda and Moura da Silva, Matheus and Antonio N. Spinass\'{e}, Rafael and Giesen Ludke, Gabriel and Ruy Soares Gaudio, Mateus and Iglesias Rocha Gomes, Guilherme and Guio Cotini, Luan and da Silva Vargens, Daniel and Queiroz Schimidt, Marcelo and Varej\~{a}o Andre\~{a}o, Rodrigo and Mestria, M\'{a}rio},
title = {Virtual Reality Solutions Employing Artificial Intelligence Methods: A Systematic Literature Review},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {10},
issn = {0360-0300},
url = {https://doi.org/10.1145/3565020},
doi = {10.1145/3565020},
abstract = {Although there are methods of artificial intelligence (AI) applied to virtual reality (VR) solutions, there are few studies in the literature. Thus, to fill this gap, we performed a systematic literature review of these methods. In this review, we apply a methodology proposed in the literature that locates existing studies, selects and evaluates contributions, analyses, and synthesizes data. We used Google Scholar and databases such as Elsevier's Scopus, ACM Digital Library, and IEEE Xplore Digital Library. A set of inclusion and exclusion criteria were used to select documents. The results showed that when AI methods are used in VR applications, the main advantages are high efficiency and precision of algorithms. Moreover, we observe that machine learning is the most applied AI scientific technique in VR applications. In conclusion, this paper showed that the combination of AI and VR contributes to new trends, opportunities, and applications for human-machine interactive devices, education, agriculture, transport, 3D image reconstruction, and health. We also concluded that the usage of AI in VR provides potential benefits in other fields of the real world such as teleconferencing, emotion interaction, tourist services, and image data extraction.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {214},
numpages = {29},
keywords = {Virtual reality, artificial intelligence, Industry 4.0, literature review}
}

@inproceedings{10.1145/3540250.3569451,
author = {Pezz\`{e}, Mauro},
title = {Machine learning and natural language processing for automating software testing (tutorial)},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3569451},
doi = {10.1145/3540250.3569451},
abstract = {In this tutorial, we see how natural language processing and machine learning can help us address the open challenges of software testing. We overview the open challenges of testing autonomous and self-adaptive software systems, discuss the leading-edge technologies that can address the core issues, and see the latest progresses and future prospective of natural language processing and machine learning to cope with core problems.  

Automating test case and oracle generation are still largely open issues. Autonomous and self-adaptive systems, like self-driving cars, smart cities, and smart buildings, raise new issues that further toughen the already challenging scenarios. In the tutorial we understand the growing importance of field testing to address failures that emerge in production, the role of dynamic analysis and deep learning in revealing failure-prone scenarios, the need of symbolic fuzzing to explore unexpected scenarios, and the potentiality of reinforcement learning and natural language processing to generate test cases and oracles. We see in details state-of-the-art approaches that exploit natural language processing to automatically generate executable test oracles, as well as semantic matching, deep and reinforcement learning to automatically generate test cases and reveal failure-prone scenarios in production.  

The tutorial is designed for both researchers, whose research roadmap focuses on software testing and applications of natural language processing and machine learning to software engineering, and practitioners, who see important professional opportunities from autonomous and self-adaptive systems. It is particularly well suited to PhD students and postdoctoral researchers who aim to address new challenges with novel technologies. The tutorial is self-contained, and is designed for a software engineering audience, who many not have a specific background in natural language processing and machine learning.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1821},
numpages = {1},
keywords = {Machine Learning, Natural Language Processing, Software Testing},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.5555/3566055.3566061,
author = {Njomou, Aquilas Tchanjou and Fokaefs, Marios and Silatchom Kamga, Dimitry Fumtim and Adams, Bram},
title = {On the Challenges of Migrating to Machine Learning Life Cycle Management Platforms},
year = {2022},
publisher = {IBM Corp.},
address = {USA},
abstract = {Given the lack of targeted services for Machine Learning software by traditional Version Control systems (VCS), many platforms for Machine Learning Life Cycle Management (MLLCM) and config­uration have emerged. These tools leverage software engineering and DevOps practices to improve the way developers build, operate and maintain Machine Learning applications. This study aims to identify the main challenges that developers face when adopting and/or migrating existing projects to these platforms. Through an experimental and statistical analysis, we explore a generic mi­gration methodology and record the different challenges faced at each stage of the migration. Based on our own experience, we also recommend potential solutions to overcome these challenges and propose some steps that developers can take when building ML projects in order to ease any future migration to MLLCM platforms.},
booktitle = {Proceedings of the 32nd Annual International Conference on Computer Science and Software Engineering},
pages = {42–51},
numpages = {10},
keywords = {MLOps, machine learning, ML versioning, data versioning, DevOps, version control},
location = {Toronto, Canada},
series = {CASCON '22}
}

@inproceedings{10.1145/3588015.3589190,
author = {Kuang, Peng and S\"{o}derberg, Emma and Niehorster, Diederick C. and H\"{o}st, Martin},
title = {Applying Machine Learning to Gaze Data in Software Development: a Mapping Study},
year = {2023},
isbn = {9798400701504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588015.3589190},
doi = {10.1145/3588015.3589190},
abstract = {Eye tracking has been used as part of software engineering and computer science research for a long time, and during this time new techniques for machine learning (ML) have emerged. Some of those techniques are applicable to the analysis of eye-tracking data, and to some extent have been applied. However, there is no structured summary available on which ML techniques are used for analysis in different types of eye-tracking research studies. In this paper, our objective is to summarize the research literature with respect to the application of ML techniques to gaze data in the field of software engineering. To this end, we have conducted a systematic mapping study, where research articles are identified through a search in academic databases and analyzed qualitatively. After identifying 10 relevant articles, we found that the most common software development activity studied so far with eye-tracking and ML is program comprehension, and Support Vector Machines and Decision Trees are the most commonly used ML techniques. We further report on limitations and challenges reported in the literature and opportunities for future work.},
booktitle = {Proceedings of the 2023 Symposium on Eye Tracking Research and Applications},
articleno = {83},
numpages = {7},
keywords = {eye-tracking, machine learning, software development},
location = {Tubingen, Germany},
series = {ETRA '23}
}

@article{10.1145/3557785.3557786,
author = {Karpatne, Anuj and Yao, Ziyu},
title = {Welcome to AI matters 8(2)},
year = {2022},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3557785.3557786},
doi = {10.1145/3557785.3557786},
abstract = {Welcome to the second issue of this year's AI Matters Newsletter. We open with a conference report by Louise Dennis, followed by a summary of events happening during 2022-2023 by Dilini Samarasinghe. This third article is a collection of responses to blue sky questions about AI education from the AAAI/ACM SIGAI New and Future AI Educator Program. Finally, the last issue by Register et al. discusses the pillars of joy and justice for AI, Machine Learning, and Data Science education.},
journal = {AI Matters},
month = nov,
pages = {3},
numpages = {1}
}

@inproceedings{10.1145/3643991.3644903,
author = {Colavito, Giuseppe and Lanubile, Filippo and Novielli, Nicole and Quaranta, Luigi},
title = {Leveraging GPT-like LLMs to Automate Issue Labeling},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644903},
doi = {10.1145/3643991.3644903},
abstract = {Issue labeling is a crucial task for the effective management of software projects. To date, several approaches have been put forth for the automatic assignment of labels to issue reports. In particular, supervised approaches based on the fine-tuning of BERT-like language models have been proposed, achieving state-of-the-art performance. More recently, decoder-only models such as GPT have become prominent in SE research due to their surprising capabilities to achieve state-of-the-art performance even for tasks they have not been trained for. To the best of our knowledge, GPT-like models have not been applied yet to the problem of issue classification, despite the promising results achieved for many other software engineering tasks. In this paper, we investigate to what extent we can leverage GPT-like LLMs to automate the issue labeling task. Our results demonstrate the ability of GPT-like models to correctly classify issue reports in the absence of labeled data that would be required to fine-tune BERT-like LLMs.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {469–480},
numpages = {12},
keywords = {LLM, issue labeling, GPT, software maintenance and evolution, labeling unstructured data},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3639475.3640098,
author = {Dehal, Ramandeep Singh and Sharma, Mehak and de Souza Santos, Ronnie},
title = {Exposing Algorithmic Discrimination and Its Consequences in Modern Society: Insights from a Scoping Study},
year = {2024},
isbn = {9798400704994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639475.3640098},
doi = {10.1145/3639475.3640098},
abstract = {Algorithmic discrimination is a condition that arises when data-driven software unfairly treats users based on attributes like ethnicity, race, gender, sexual orientation, religion, age, disability, or other personal characteristics. Nowadays, as machine learning gains popularity, cases of algorithmic discrimination are increasingly being reported in several contexts. This study delves into various studies published over the years reporting algorithmic discrimination. We aim to support software engineering researchers and practitioners in addressing this issue by discussing key characteristics of the problem.LAY ABSTRACT. In recent years, data bias has posed significant challenges for minority groups, leading to systems and algorithms discriminating against Women, Black communities, people with disabilities, and LGBTQIA+ individuals. Recognizing this bias is the crucial first step toward devising solutions. This study maps and discusses instances of algorithmic discrimination across various societal domains.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Society},
pages = {69–73},
numpages = {5},
keywords = {algorithmic discrimination, software development, machine learning},
location = {Lisbon, Portugal},
series = {ICSE-SEIS'24}
}

@inproceedings{10.1145/3524842.3528447,
author = {Grotov, Konstantin and Titov, Sergey and Sotnikov, Vladimir and Golubev, Yaroslav and Bryksin, Timofey},
title = {A large-scale comparison of Python code in Jupyter notebooks and scripts},
year = {2022},
isbn = {9781450393034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524842.3528447},
doi = {10.1145/3524842.3528447},
abstract = {In recent years, Jupyter notebooks have grown in popularity in several domains of software engineering, such as data science, machine learning, and computer science education. Their popularity has to do with their rich features for presenting and visualizing data, however, recent studies show that notebooks also share a lot of drawbacks: high number of code clones, low reproducibility, etc. In this work, we carry out a comparison between Python code written in Jupyter Notebooks and in traditional Python scripts. We compare the code from two perspectives: structural and stylistic. In the first part of the analysis, we report the difference in the number of lines, the usage of functions, as well as various complexity metrics. In the second part, we show the difference in the number of stylistic issues and provide an extensive overview of the 15 most frequent stylistic issues in the studied mediums. Overall, we demonstrate that notebooks are characterized by the lower code complexity, however, their code could be perceived as more entangled than in the scripts. As for the style, notebooks tend to have 1.4 times more stylistic issues, but at the same time, some of them are caused by specific coding practices in notebooks and should be considered as false positives. With this research, we want to pave the way to studying specific problems of notebooks that should be addressed by the development of notebook-specific tools, and provide various insights that can be useful in this regard.},
booktitle = {Proceedings of the 19th International Conference on Mining Software Repositories},
pages = {353–364},
numpages = {12},
location = {Pittsburgh, Pennsylvania},
series = {MSR '22}
}

@inproceedings{10.1145/3627673.3679713,
author = {Liang, Yuanyuan and Tan, Keren and Xie, Tingyu and Tao, Wenbiao and Wang, Siyuan and Lan, Yunshi and Qian, Weining},
title = {Aligning Large Language Models to a Domain-specific Graph Database for NL2GQL},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679713},
doi = {10.1145/3627673.3679713},
abstract = {Graph Databases (Graph DB) find extensive application across diverse domains such as finance, social networks, and medicine. Yet, the translation of Natural Language (NL) into the Graph Query Language (GQL), referred to as NL2GQL, poses significant challenges owing to its intricate and specialized nature. Some approaches have sought to utilize Large Language Models (LLMs) to address analogous tasks like text2SQL. Nonetheless, in the realm of NL2GQL tasks tailored to a particular domain, the absence of domain-specific NL-GQL data pairs adds complexity to aligning LLMs with the graph DB. To tackle this challenge, we present a well-defined pipeline. Initially, we use ChatGPT to generate NL-GQL data pairs, leveraging the provided graph DB and two mutual verification self-instruct methods which ensure consistency between NL and GQL. Subsequently, we employ the generated data to fine-tune LLMs, ensuring alignment between LLMs and the graph DB. Moreover, we find the importance of relevant schema in efficiently generating accurate GQLs. Thus, we introduce a method to extract relevant schema as the input context. We evaluate our method using two carefully constructed datasets derived from graph DBs in the finance and medicine domains, named FinGQL and MediGQL. Experimental results reveal that our approach significantly outperforms a set of baseline methods, with improvements of 5.90 and 6.36 absolute points on EM, and 6.00 and 7.09 absolute points on EX for FinGQL and MediGQL, respectively},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {1367–1377},
numpages = {11},
keywords = {graph databases, graph query language, large language models, natural language to graph query language},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3555228.3555269,
author = {Santos, Geanderson and Veloso, Adriano and Figueiredo, Eduardo},
title = {Understanding Thresholds of Software Features for Defect Prediction},
year = {2022},
isbn = {9781450397353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555228.3555269},
doi = {10.1145/3555228.3555269},
abstract = {Software defect prediction is a subject of study involving the interplay of the software engineering and machine learning areas. The current literature proposed numerous machine learning models to predict software defects from software data, such as commits and code metrics. However, existing machine learning models are more valuable when we can understand the prediction. Otherwise, software developers cannot reason why a machine learning model made such predictions, generating many questions about the model’s applicability in software projects. As explainable machine learning models for the defect prediction problem remain a recent research topic, it leaves room for exploration. In this paper, we propose a preliminary analysis of an extensive dataset to predict software defects. The dataset includes 47,618 classes from 53 open-source projects and covers 66 software features related to numerous features of the code. Therefore, we offer contributions on explaining how each selected software feature favors the prediction of software defects in Java projects. Our initial results suggest that developers should keep the values of some specific software features small to avoid software defects. We hope our approach can guide more discussions about explainable machine learning for defect prediction and its impact on software development.},
booktitle = {Proceedings of the XXXVI Brazilian Symposium on Software Engineering},
pages = {305–310},
numpages = {6},
keywords = {defect prediction, explainable machine learning, software features for defect prediction},
location = {Virtual Event, Brazil},
series = {SBES '22}
}

@inproceedings{10.1145/3632620.3671112,
author = {Skripchuk, James and Bacher, John and Price, Thomas},
title = {An Investigation of the Drivers of Novice Programmers' Intentions to Use Web Search and GenAI},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671112},
doi = {10.1145/3632620.3671112},
abstract = {External help resources are frequently used by novice programmers solving classwork in undergraduate computing courses. Traditionally, these tools consisted of web resources such as tutorial websites and Q&amp;A forums. With the rise of Generative AI (GenAI), there has been increasing concern and research about how external resources should be used in the classroom. However, little work has directly contrasted student beliefs and perceptions of web resources with GenAI, has grounded these beliefs in prior psychological theory, and has investigated how demographic factors and student backgrounds influence these beliefs and intentions. We administered a vignette-style survey across two courses required for a CS major at an R1 University, a freshman (n = 152) and senior capstone course (n = 44). Students responded to likert questions aiming to measure behavioral factors related to these tools, such as intention to use, perceived attitudes, peer perceptions, and their own perceived tool competency. We primarily investigate the results of an introductory course, finding that novices have a wide range of opinions on both resources, but overall find them slightly useful and have a tendency to prefer web-search. We compare this with seniors, who have more positive perceptions of these tools, and discuss possible reasons and implications for this difference. We constructed two path models to investigate which factors strongly influence novices’ intention to use resources and find the primary factor to be their general attitudes in how these tools will result in a positive or negative outcome (e.g. perceived benefits, justifiability). We also measure the effects of student background on intention to use these resources. Finally, we discuss implications and suggestions on how instructors can use this information to approach, address, and influence resource usage in their classrooms.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {487–501},
numpages = {15},
keywords = {CS Education, GenAI, Help-seeking, student perspectives, web-search},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3654522.3654561,
author = {Nguyen, Dien Thanh and Do, Nhon Van and Tran, Tung Hoang},
title = {A Model of Topic for Document Retrieval Systems in the Field of Artificial Intelligence for Information Technology students},
year = {2024},
isbn = {9798400716713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654522.3654561},
doi = {10.1145/3654522.3654561},
abstract = {This article proposes a topic definition, topic modeling and document search techniques related to topics in the field of artificial intelligence, thereby building a document search application based on topic. Document warehouse includes ebooks and papers. The application will serve the need to search for documents by topic for information technology students during the learning and research process, to solve that problem. Realizing that Ontology and document search techniques are a suitable and powerful approach for organizing the knowledge base as well as solving the problem of retrieving documents by topic with high efficiency. From there, the following databases are built: the Ebook and Paper database is stored in a structured form, the topic database is to store a set of topics in the field of artificial intelligence, Ontology database for ebooks and papers, keyphrase graph database to store topic and document representations and semantic similarity matching techniques between documents and topics.},
booktitle = {Proceedings of the 2024 9th International Conference on Intelligent Information Technology},
pages = {376–385},
numpages = {10},
keywords = {Additional Key Words and Phrases: Topic definition, domain ontology, graph matching, topic modeling, topic representation},
location = {Ho Chi Minh City, Vietnam},
series = {ICIIT '24}
}

@article{10.1145/3616372,
author = {Amalfitano, Domenico and Faralli, Stefano and Hauck, Jean Carlo Rossa and Matalonga, Santiago and Distante, Damiano},
title = {Artificial Intelligence Applied to Software Testing: A Tertiary Study},
year = {2023},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3616372},
doi = {10.1145/3616372},
abstract = {Context: Artificial intelligence (AI) methods and models have extensively been applied to support different phases of the software development lifecycle, including software testing (ST). Several secondary studies investigated the interplay between AI and ST but restricted the scope of the research to specific domains or sub-domains within either area.Objective: This research aims to explore the overall contribution of AI to ST, while identifying the most popular applications and potential paths for future research directions.Method: We executed a tertiary study following well-established guidelines for conducting systematic literature mappings in software engineering and for answering nine research questions.Results: We identified and analyzed 20 relevant secondary studies. The analysis was performed by drawing from well-recognized AI and ST taxonomies and mapping the selected studies according to them. The resulting mapping and discussions provide extensive and detailed information on the interplay between AI and ST.Conclusion: The application of AI to support ST is a well-consolidated and growing interest research topic. The mapping resulting from our study can be used by researchers to identify opportunities for future research, and by practitioners looking for evidence-based information on which AI-supported technology to possibly adopt in their testing processes.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {58},
numpages = {38},
keywords = {Artificial intelligence, Software testing, Taxonomy, Tertiary study, Systematic literature review, Systematic mapping study}
}

@inproceedings{10.1145/3643690.3648236,
author = {Hamza, Muhammad and Siemon, Dominik and Akbar, Muhammad Azeem and Rahman, Tahsinur},
title = {Human-AI Collaboration in Software Engineering: Lessons Learned from a Hands-On Workshop},
year = {2024},
isbn = {9798400705717},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643690.3648236},
doi = {10.1145/3643690.3648236},
abstract = {This paper investigates the dynamics of human-AI collaboration in software engineering, focusing on the use of ChatGPT. Through a thematic analysis of a hands-on workshop in which 22 professional software engineers collaborated for three hours with ChatGPT, we explore the transition of AI from a mere tool to a collaborative partner. The study identifies key themes such as the evolving nature of human-AI interaction, the capabilities of AI in software engineering tasks, and the challenges and limitations of integrating AI in this domain. The findings show that while AI, particularly ChatGPT, improves the efficiency of code generation and optimization, human oversight remains crucial, especially in areas requiring complex problem-solving and security considerations. This research contributes to the theoretical understanding of human-AI collaboration in software engineering and provides practical insights for effectively integrating AI tools into development processes. It highlights the need for clear role allocation, effective communication, and balanced AI-human collaboration to realize the full potential of AI in software engineering.},
booktitle = {Proceedings of the 7th ACM/IEEE International Workshop on Software-Intensive Business},
pages = {7–14},
numpages = {8},
keywords = {generative AI, ChatGPT, software engineering, workshop, empirical investigation},
location = {Lisbon, Portugal},
series = {IWSiB '24}
}

@inproceedings{10.1145/3698587.3701484,
author = {Cui, Xuefeng},
title = {Cutting-Edge Algorithms in Genomics: From Theory to Practice},
year = {2024},
isbn = {9798400713026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698587.3701484},
doi = {10.1145/3698587.3701484},
abstract = {Recent advancements in genomics have been propelled by the development of novel computational algorithms designed to solve complex problems in bioinformatics and precision medicine. This workshop, "Cutting-Edge Algorithms in Genomics: From Theory to Practice," brings together leading researchers and practitioners to present and discuss the latest breakthroughs in genomic data analysis. The workshop will focus on state-of-the-art methods in metagenomics, machine learning for gene expression quantification, contig binning, disease risk prediction, and missense mutation effect prediction.Key presentations include innovative approaches to metagenomic function prediction and contig binning, such as *MetaBinner* and *COMEBin*, which utilize ensemble learning and contrastive multi-view representation learning to tackle the heterogeneity of metagenomic data. Other highlights feature the *Med-PRSIMD* model for enhancing complex disease prediction by integrating multi-type data, including genetic variants and medical history records, and a novel method for ultra-fast gene expression quantification using sparse K-mer queries, tailored for diverse populations like the Collaborative Cross mouse model. Additionally, an optimized framework for missense mutation effect prediction, combining categorical boosting and the Sparrow Search Algorithm, demonstrates significant improvements in pathogenic mutation detection using sequence and structural data.This workshop is co-organized with the China Computer Federation (CCF) Technical Committee of Bioinformatics (TCBI). As a multidisciplinary field blending information science and biology, bioinformatics leverages advanced technologies, such as computational algorithms, databases, machine learning, and artificial intelligence, to solve complex biological problems. With the arrival of the era of biological big data, the CCF TCBI was established to pool research talent in bioinformatics, elevate China's research capabilities and international influence, and promote academic exchange and collaboration. The committee also fosters close ties between academia and industry, explores innovative educational models in bioinformatics, and cultivates high-level talent with interdisciplinary backgrounds and innovative capacities. Through the efforts of CCF TCBI, China is making groundbreaking advancements at the intersection of computational and life sciences, contributing significantly to human health and life science development.This workshop provides an opportunity for attendees to explore cutting-edge algorithms that are shaping the future of genomics, with an emphasis on practical applications in clinical and research settings. Participants will gain insights into the theoretical underpinnings of these methods and their real-world impact on genomic data analysis, disease prediction, and personalized medicine.},
booktitle = {Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {96},
numpages = {1},
keywords = {Code, Correct, Do, Not, Paper, Put, Terms, This, Us, Your, for, the},
location = {Shenzhen, China},
series = {BCB '24}
}

@inproceedings{10.1145/3583780.3615506,
author = {Maiorino, Antonio and Padgett, Zoe and Wang, Chun and Yakubovskiy, Misha and Jiang, Peng},
title = {Application and Evaluation of Large Language Models for the Generation of Survey Questions},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615506},
doi = {10.1145/3583780.3615506},
abstract = {Generative Language Models have shown promising results in various domains, and some of the most successful applications are related to "concept expansion", which is the task of generating extensive text based on concise instructions provided through a "seed" prompt. In this presentation we will discuss the recent work conducted by the Data Science team at SurveyMonkey, where we have recently introduced a new feature that harnesses Generative AI models to streamline the survey design process. With this feature users can effortlessly initiate this process by specifying their desired objectives through a prompt, allowing them to automate the creation of surveys that include the critical aspects they wish to investigate.We will share our findings regarding some of the challenges encountered during the development of this feature. These include techniques for conditioning the model outputs, integrating generated text with industry-standard questions, fine-tuning Language Models using semi-synthetic Data Generation techniques, and more. Moreover, we will showcase the Evaluation Methodology that we have developed to measure the quality of the generated surveys across several dimensions. This evaluation process is crucial in ensuring that the generated surveys align well with user expectations and serve their intended purpose effectively. Our goal is to demonstrate the promising potential of Generative Language Models in the context of Survey Research, and we believe that sharing our learnings on these challenges and how we addressed them will be useful for practitioners working with Language Models on similar problems.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {5244–5245},
numpages = {2},
keywords = {generative AI, survey research, text evaluation},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3669754.3669786,
author = {Mekni, Mehdi and Barone, Charles},
title = {Instant User Insight: Dynamic Activity Profiling},
year = {2024},
isbn = {9798400717055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669754.3669786},
doi = {10.1145/3669754.3669786},
abstract = {Continuous authentication ensures ongoing verification of a user’s identity during an active session, removing the necessity for one-time logins. Real-time user activity fingerprinting, an effective method within continuous authentication, examines behaviors like keystroke patterns, mouse movements, and browsing habits to craft a distinctive user profile or "fingerprint." This approach boasts advantages over traditional authentication methods such as passwords or tokens, enhancing security by complicating imitation of user behavior while also streamlining the login process. This paper introduces Gargoyle, an intelligent software solution that we design, develop, and integrate. Additionally, we present a comprehensive software development methodology covering requirement analysis, software architecture, and design. Gargoyle employs a machine learning (ML) model that we develop, train, and validate. This ML model dynamically evaluates the smart continuous authentication system’s performance, assessing error rates and accuracy factors.},
booktitle = {Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence},
pages = {216–221},
numpages = {6},
keywords = {Machine Learning, Real-Time User Activity Fingerprinting, Software Engineering},
location = {Bali Island, Indonesia},
series = {ICCAI '24}
}

@article{10.1145/3654768.3654771,
author = {Gamage, Bhanuka},
title = {AI-Enabled Smart Glasses for People with Severe Vision Impairments},
year = {2024},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
number = {137},
issn = {1558-2337},
url = {https://doi.org/10.1145/3654768.3654771},
doi = {10.1145/3654768.3654771},
abstract = {Over the last decade, there has been significant research on how smart assistive devices with artificial intelligence (AI) built into them can assist people with severe vision impairments to comprehend their surroundings. These devices come in various forms such as smartphone applications, smart-glasses, and smart canes. Smart glasses have gained popularity lately due to recent technological advancements, as well as their natural position in front of the user's eyes. However, there has been limited research to understand how people with severe vision impairments would prefer to interact with them. The objective of this project is to investigate the use of AI-enabled smart-glasses to aid individuals with severe vision impairments. The research aims to comprehend the differences between the types of research conducted by researchers and the needs and desires of the community. The study will utilise a Design Thinking approach and involve vision-impaired users throughout the project by utilising co-design methods. The research will involve the development of smart-glass application prototypes through iterative case studies with individuals who are blind, have low-vision, and have cerebral vision impairment (CVI). The goal is to understand the users' preferred interaction model from their lived experiences. The outcome of the research will also be a software architecture that enables people with severe vision impairments to seamlessly access information about their surroundings.},
journal = {SIGACCESS Access. Comput.},
month = mar,
articleno = {3},
numpages = {1}
}

@inproceedings{10.1145/3674805.3686670,
author = {Nguyen, Anh The and Le, Triet Huynh Minh and Babar, M. Ali},
title = {Automated Code-centric Software Vulnerability Assessment: How Far Are We? An Empirical Study in C/C++},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3686670},
doi = {10.1145/3674805.3686670},
abstract = {Background: The C/C++ languages hold significant importance in Software Engineering research because of their widespread use in practice. Numerous studies have utilized Machine Learning (ML) and Deep Learning (DL) techniques to detect software vulnerabilities (SVs) in the source code written in these languages. However, the application of these techniques in function-level SV assessment has been largely unexplored. SV assessment is increasingly crucial as it provides detailed information on the exploitability, impacts, and severity of security defects, thereby aiding in their prioritization and remediation. Aims: We conduct the first empirical study to investigate and compare the performance of ML and DL models, many of which have been used for SV detection, for function-level SV assessment in C/C++. Method: Using 9,993 vulnerable C/C++ functions, we evaluated the performance of six multi-class ML models and five multi-class DL models for the SV assessment at the function level based on the Common Vulnerability Scoring System (CVSS). We further explore multi-task learning, which can leverage common vulnerable code to predict all SV assessment outputs simultaneously in a single model, and compare the effectiveness and efficiency of this model type with those of the original multi-class models. Results: We show that ML has matching or even better performance compared to the multi-class DL models for function-level SV assessment with significantly less training time. Employing multi-task learning allows the DL models to perform significantly better, with an average of 8–22% increase in Matthews Correlation Coefficient (MCC), than the multi-class models. Conclusions: We distill the practices of using data-driven techniques for function-level SV assessment in C/C++, including the use of multi-task DL to balance efficiency and effectiveness. This can establish a strong foundation for future work in this area.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {72–83},
numpages = {12},
keywords = {Deep Learning, Machine Learning, Mining Software Repositories, Security Vulnerability, Vulnerability Assessment},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.5555/3631672.3631680,
author = {Washizaki, Hironori and Khomh, Foutse and Gu\'{e}h\'{e}neuc, Yann-Ga\"{e}l},
title = {Software Engineering Patterns for Machine Learning Applications (SEP4MLA) - Part 4 - ML Gateway Routing Architecture},
year = {2023},
isbn = {9781941652183},
publisher = {The Hillside Group},
address = {USA},
abstract = {Machine learning (ML) researchers study the best practices to develop and support ML-based applications to ensure quality and determine the constraints applied to their application pipelines. Such practices are often formalized as software patterns. We discovered software-engineering design patterns for machine-learning applications by thoroughly searching the available literature on the subject. Among the ML patterns found, we describe in this paper one ML topology pattern, "ML Gateway Routing Architecture", in the standard pattern format so that practitioners can (re)use it in their contexts and benefits. The pattern addresses the problem of tight coupling among ML-related services and non-ML business logic as well as the front-end client by installing a gateway that routes requests.},
booktitle = {Proceedings of the 29th Conference on Pattern Languages of Programs},
articleno = {6},
numpages = {8},
keywords = {machine learning patterns},
location = {Virtual Event},
series = {PLoP '22}
}

@article{10.1145/3572905,
author = {Kotti, Zoe and Galanopoulou, Rafaila and Spinellis, Diomidis},
title = {Machine Learning for Software Engineering: A Tertiary Study},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3572905},
doi = {10.1145/3572905},
abstract = {Machine learning (ML) techniques increase the effectiveness of software engineering (SE) lifecycle activities. We systematically collected, quality-assessed, summarized, and categorized 83 reviews in ML for SE published between 2009 and 2022, covering 6,117 primary studies. The SE areas most tackled with ML are software quality and testing, while human-centered areas appear more challenging for ML. We propose a number of ML for SE research challenges and actions, including conducting further empirical validation and industrial studies on ML, reconsidering deficient SE methods, documenting and automating data collection and pipeline processes, reexamining how industrial practitioners distribute their proprietary data, and implementing incremental ML approaches.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {256},
numpages = {39},
keywords = {Tertiary study, machine learning, software engineering, systematic literature review}
}

@inproceedings{10.1145/3641237.3691693,
author = {Kasierski, Benjamin and Fagnano, Emma},
title = {Optimizing the Grant Writing Process: A Framework for Creating a Grant Writing Assistant Using ChatGPT 4},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691693},
doi = {10.1145/3641237.3691693},
abstract = {This extended abstract explores prompt engineering strategies and usability testing that can be applied to create a grant writing assistant using ChatGPT 4. Utilizing scholarly literature from the past 3 years concerning LLM development, AI integration, and prompt engineering, along with White et al's experimental prompt pattern catalog [13] for software engineering, and previously accepted grants from a given institution, ChatGPT 4 can be applied to create a transferable template that streamlines the grant writing process. By following the frameworks outlined in the literature and guidelines for potential applications, we propose that grant writers can integrate a more efficient grant writing process that reduces confusion in understanding NSF's guidelines and criteria, helps to articulate clear and achievable objectives, and improves proposal alignment with NSF's strategic priorities.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {286–291},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, NSF, National Science Foundation, grant writing, large language models},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@inproceedings{10.1145/3663533.3664037,
author = {Dey, Tapajit and Loungani, Jonathan and Ivers, James},
title = {Smarter Project Selection for Software Engineering Research},
year = {2024},
isbn = {9798400706752},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663533.3664037},
doi = {10.1145/3663533.3664037},
abstract = {Open Source Software (OSS) hosting platforms like GitHub also contain many non-software projects that should be excluded from the dataset for most software engineering research studies. However, due to the lack of obvious indicators, researchers have to spend considerable manual effort to find suitable projects or rely on convenience sampling or heuristics for selecting projects for their research. Moreover, the diverse nature of OSS projects often poses further challenges in selecting projects aligned with study objectives, especially when the study intends to identify projects based on semantic information like intended use, which is not easy to discern solely based on the project characteristics that are available through the search APIs like GitHub's. 
 
 
 
Our goals are to establish a robust method of identifying software projects from the population of repositories hosted in social coding platforms and to categorize the software projects based on who the target users are and how those projects are meant to be used. 
 
 
 
Using data from 35,621 projects in the World of Code dataset, we employed a combination of machine learning techniques, including Doc2Vec and Random Forest, to identify the software projects and to categorize them as standalone applications, libraries, or plug-ins. 
 
 
 
Furthermore, our findings highlight the risks of selecting projects solely based on filtering by commonly used project criteria like the number of contributors, commits, or stars as even after using similar filtering, 16.6% of projects were found to be non-software projects.
 
 
 
Our research should aid software engineering researchers in project selection, benefiting both industry and academia. We also envision our work inspiring further research in this domain.},
booktitle = {Proceedings of the 20th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {12–21},
numpages = {10},
keywords = {Application, Doc2Vec, GitHub, Library, OSS projects, Open Source, Plug-in, categorization, machine learning, multi-class classification, random forest},
location = {Porto de Galinhas, Brazil},
series = {PROMISE 2024}
}

@inproceedings{10.1145/3627673.3679890,
author = {Li, Ruien and Wang, Yanhao and Mathioudakis, Michael},
title = {Coresets for Deletion-Robust k-Center Clustering},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679890},
doi = {10.1145/3627673.3679890},
abstract = {The k-center clustering problem is of fundamental importance for a broad range of machine learning and data science applications. In this paper, we study the deletion-robust version of the problem. Specifically, we aim to extract a small subset of a given data set, referred to as a coreset, that contains a provably good set of k centers even after an adversary deletes up to z arbitrarily chosen points from the data set. We propose a 4-approximation algorithm that provides a coreset of size O(kz). To our knowledge, this is the first algorithm for deletion-robust k-center clustering with a theoretical guarantee. Moreover, we accompany our theoretical results with extensive experiments, demonstrating that our algorithm achieves significantly better robustness than non-trivial baselines against three heuristic gray-box and white-box adversarial deletion attacks.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3877–3881},
numpages = {5},
keywords = {coreset, deletion robustness, k-center clustering},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@proceedings{10.1145/3617232,
title = {ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
year = {2024},
isbn = {9798400703720},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
abstract = {Welcome to the first volume of ASPLOS'24: the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. For the second year, ASPLOS employs a model of three submission deadlines - spring, summer and fall - along with a major revision mechanism, which, as an alternative to rejection, gives the authors of some submissions the opportunity to fix a list of problems and then resubmit their work to the subsequent review cycle.We introduced several notable changes to ASPLOS this year. Briefly, these include significantly increasing the program committee size to over 220 members (more than twice the size of last year), foregoing synchronous PC meetings and instead making all decisions online, and overhauling the review assignment process. The overhaul includes comparing the textual contents of submissions to the contents of papers authored by the reviewers and using a metric that quantifies the goodness of the match to guide the assignment of reviewers to submissions. The overhaul additionally involves asking reviewers to predict the expertise of their future reviews for a subset of the submissions and using this input as well, among others, for the assignment process.Key statistics of the ASPLOS'24 spring cycle include: 173 submissions were finalized (nearly double last year's spring count), with 47 (27%) related to machine learning, 41 to storage/memory, 39 to accelerators/FPGAs/GPUs, and 27 to security; 87 (51%) submissions were promoted to the second review round; 28 (16.2%) papers were accepted, with 16, 13, and 9 awarded artifact evaluation badges of "available," "functional," and "reproduced," respectively; 27 (15.6%) submissions were allowed to submit major revisions, of which 22 were subsequently accepted during the summer cycle; 762 reviews were uploaded; and 2,868 comments were generated during online discussions.Another change we introduced this year is asking authors to specify their per-submission most-related broader areas of research, which revealed that 54%, 42%, and 25% of the submissions are associated with architecture, operating systems, and programming languages, respectively, with only 21% being interdisciplinary. The full details are available in the PDF of the front matter.},
location = {La Jolla, CA, USA}
}

@article{10.5555/3648699.3648868,
author = {Li, Xuechan and Sung, Anthony D. and Xie, Jichun},
title = {DART: distance assisted recursive testing},
year = {2023},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {Multiple testing is a commonly used tool in modern data science. Sometimes, the hypotheses are embedded in a space; the distances between the hypotheses reflect their co-null/coalternative patterns. Properly incorporating the distance information in testing will boost testing power. Hence, we developed a new multiple testing framework named Distance Assisted Recursive Testing (DART). DART features in joint artificial intelligence (AI) and statistics modeling. It has two stages. The first stage uses AI models to construct an aggregation tree that reflects the distance information. The second stage uses statistical models to embed the testing on the tree and control the false discovery rate. Theoretical analysis and numerical experiments demonstrated that DART generates valid, robust, and powerful results. We applied DART to a clinical trial in the allogeneic stem cell transplantation study to identify the gut microbiota whose abundance was impacted by post-transplant care.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {169},
numpages = {41},
keywords = {multiple testing, hierarchical testing, aggregation tree, false discovery rate, auxiliary information}
}

@article{10.1145/3572885.3572886,
author = {Diana, Emily and Niu, Mingzi and Noarov, Georgy},
title = {SIGecom winter meeting 2022 highlights},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1},
url = {https://doi.org/10.1145/3572885.3572886},
doi = {10.1145/3572885.3572886},
abstract = {Emily Diana is a rising fifth year Ph.D. student in Statistics and Data Science at the Wharton School, University of Pennsylvania, where she is advised by Michael Kearns and Aaron Roth. Her research focuses on the intersection of ethical algorithm design and socially aware machine learning, and she is honored to have been recognized as both a Rising Star in EECS by MIT and a Future Leader in Data Science by the University of Michigan. Before Penn, she received a B.A. in Applied Mathematics from Yale and an M.S. in Statistics from Stanford, and she spent two years as a software developer at Lawrence Livermore National Laboratory.Mingzi Niu is a rising fifth year Ph.D. student in Economics at Rice University, where she is advised by Mallesh Pai and H\"{u}lya Eraslan. Her research interest are primarily in microeconomic theory, with a focus on mechanism design, information theory and behavioral economics. Before Rice, she received a B.A. in Finance and Banking and a B.S. in Mathematics and Statistics at Peking University, and a M.A. in Economics at Duke University.Georgy Noarov is a rising third year PhD student in Computer and Information Science at the University of Pennsylvania, advised by Michael Kearns and Aaron Roth. Previously, he graduated from Princeton University with a B.A. in Mathematics. His research interests span across the fields of uncertainty quantification, online learning, fairness in machine learning, and algorithmic game theory.},
journal = {SIGecom Exch.},
month = nov,
pages = {3–23},
numpages = {21}
}

@inproceedings{10.1145/3643660.3643947,
author = {Diaz-Pace, Jorge Andres and Garlan, David},
title = {The Architect in the Maze: On the Effective Usage of Automated Design Exploration},
year = {2024},
isbn = {9798400705632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643660.3643947},
doi = {10.1145/3643660.3643947},
abstract = {Designing a software architecture that satisfies a set of quality-attribute requirements has traditionally been a challenging activity for human architects, as it involves the exploration and assessment of alternative design decisions. The development of automated optimization tools for the architecture domain has opened new opportunities, because these tools are able to explore a large space of alternatives, and thus extend the architect's capabilities. In this context, however, architects need to efficiently navigate through a large space and understand the main relations between design decisions and feasible quality-attribute tradeoffs in a maze of possible alternatives. Although Machine Learning (ML) techniques can help to reduce the complexity of the task by sifting through the data generated by the tools, the standard techniques often fall short because they cannot offer architectural insights or relevant answers to the architect's questions. In this paper, and based on previous experiences, we argue that ML techniques should be adapted to the architecture domain, and propose a conceptual framework towards that goal. Furthermore, we show how the framework can be instantiated by adapting clustering techniques to answer architectural questions regarding a client-server design space.},
booktitle = {Proceedings of the 1st International Workshop on Designing Software},
pages = {9–14},
numpages = {6},
keywords = {design exploration, automated tools, applied machine learning, quality attributes, explainability},
location = {Lisbon, Portugal},
series = {Designing '24}
}

@inproceedings{10.1145/3691720.3691766,
author = {Jin, Sheng and Yu, Zengyi and Chen, Xinyu and Dai, Jian},
title = {The Application Landscape and Research Status of Artificial Intelligence in Teacher Education: A Systematic Literature Review},
year = {2024},
isbn = {9798400710230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691720.3691766},
doi = {10.1145/3691720.3691766},
abstract = {The integration of Artificial Intelligence (AI) has become a key driver in the evolution and transformation of teacher education. However, there has been no comprehensive review of AI applications in this field. In light of this, our study employs a systematic literature review, selecting 45 relevant articles from databases such as Web of Science, EBSCO, and Scopus, aiming to present a comprehensive overview of the field's development, key research themes, and propose a valuable future agenda. Findings are as follows: 1) In the realm of AI applications in teacher education, the United States emerges as a core contributor. Regarding the types of research, theoretical and empirical studies are equally prevalent; there has been a surge in publications in this field since 2021. 2) The research in this field primarily revolves around three themes: Performance Evaluation of AI Technology in Teacher Education, AI Technology's Role in Enhancing Teachers' Core Skills, and AI Assistance in Teacher Education. 3) Based on the literature review, this study offers a meaningful future agenda from both theoretical and practical perspectives. Theoretically, it involves strengthening research in teacher training and professional development, and enhancing educational decision support systems. Practically, it entails developing specialized AI applications for teacher education and promoting AI-assisted educational development.},
booktitle = {Proceedings of the 2nd International Conference on Educational Knowledge and Informatization},
pages = {275–280},
numpages = {6},
location = {Shanghai, China},
series = {EKI '24}
}

@inproceedings{10.1145/3607947.3608090,
author = {Bhatt, Arpita Jadhav and Agarwal, Parul},
title = {Statistical Detection of Malicious iOS Apps through Ensemble and Active Learning},
year = {2023},
isbn = {9798400700224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607947.3608090},
doi = {10.1145/3607947.3608090},
abstract = {iOS is one of the most broadly used mobile operating systems after Android. In today's era, smartphones are widely used to perform several tasks such as net banking, GPS tracking, ordering products, etc. One of the main features of smartphones is that their capabilities can be expanded by installing third-party apps. However, these apps pose privacy threats to the user as they contain a lot of user's personal information, which may be vulnerable to attackers. Background studies have identified that a lot of user's personal and sensitive data is stored on smartphones and thus, they have become a perfect target for privacy threats in the whole mobile ecosystem. Machine learning techniques to detect malware apps have offered promising results for the Android platform whereas nominal work has been done for the iOS platform. In this paper, we are incorporating various machine learning techniques to detect malicious iOS apps from several categories. Some of the ensemble learning techniques with different classification algorithms are inculcated to enhance the precision of classifiers. A weighted average method on active and ensemble learning has been proposed which proved to be more efficient as compared to other machine learning techniques in most of the categories. Our empirical analysis has demonstrated that the proposed technique is statistically significant than active and ensemble learning.},
booktitle = {Proceedings of the 2023 Fifteenth International Conference on Contemporary Computing},
pages = {716–721},
numpages = {6},
location = {Noida, India},
series = {IC3-2023}
}

@inproceedings{10.1145/3594671.3594690,
author = {Moin, Armin and Badii, Atta and Challenger, Moharram},
title = {Model-Driven Quantum Federated Learning (QFL)},
year = {2023},
isbn = {9798400707551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594671.3594690},
doi = {10.1145/3594671.3594690},
abstract = {Recently, several studies have proposed frameworks for Quantum Federated Learning (QFL). For instance, the Google TensorFlow Quantum (TFQ) and TensorFlow Federated (TFF) libraries have been deployed for realizing QFL. However, developers, in the main, are not as yet familiar with Quantum Computing (QC) libraries and frameworks. A Domain-Specific Modeling Language (DSML) that provides an abstraction layer over the underlying QC and Federated Learning (FL) libraries would be beneficial. This could enable practitioners to carry out software development and data science tasks efficiently while deploying the state of the art in Quantum Machine Learning (QML). In this position paper, we propose extending existing domain-specific Model-Driven Engineering (MDE) tools for Machine Learning (ML) enabled systems, such as MontiAnna, ML-Quadrat, and GreyCat, to support QFL.},
booktitle = {Companion Proceedings of the 7th International Conference on the Art, Science, and Engineering of Programming},
pages = {111–113},
numpages = {3},
keywords = {federated machine learning, model-driven engineering, quantum computing},
location = {Tokyo, Japan},
series = {Programming '23}
}

@inproceedings{10.1145/3640544.3645228,
author = {Guo, Jiajing and Mohanty, Vikram and Hao, Hongtao and Gou, Liang and Ren, Liu},
title = {Can LLMs Infer Domain Knowledge from Code Exemplars? A Preliminary Study},
year = {2024},
isbn = {9798400705090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640544.3645228},
doi = {10.1145/3640544.3645228},
abstract = {As organizations recognize the potential of Large Language Models (LLMs), bespoke domain-specific solutions are emerging, which inherently face challenges of knowledge gaps and contextual accuracy. Prompt engineering techniques such as chain-of-thoughts and few-shot prompting have been proposed to enhance LLMs’ capabilities by dynamically presenting relevant exemplars. Are LLMs able to infer domain knowledge from code exemplars involving similar domain concepts and analyze the data correctly? To investigate this, we curated a synthetic dataset containing 45 tabular databases, each has domain concepts and definitions, natural language data analysis queries, and responses in the form of Python code, visualizations, and insights. Using this dataset, we conducted a within-subjects experiment to evaluate the effectiveness of domain-specific exemplars versus randomly selected, generic exemplars. Our study underscores the significance of tailored exemplars in enhancing LLMs’ accuracy and contextual understanding in domain-specific tasks, paving the way for more intuitive and effective data analysis solutions.},
booktitle = {Companion Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {95–100},
numpages = {6},
keywords = {LLM, LLM evaluation, domain-specific data analysis, large language model, prompt engineering},
location = {Greenville, SC, USA},
series = {IUI '24 Companion}
}

@inproceedings{10.1145/3643916.3644434,
author = {Li, Jiliang and Zhang, Yifan and Karas, Zachary and McMillan, Collin and Leach, Kevin and Huang, Yu},
title = {Do Machines and Humans Focus on Similar Code? Exploring Explainability of Large Language Models in Code Summarization},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644434},
doi = {10.1145/3643916.3644434},
abstract = {Recent language models have demonstrated proficiency in summarizing source code. However, as in many other domains of machine learning, language models of code lack sufficient explainability --- informally, we lack a formulaic or intuitive understanding of what and how models learn from code. Explainability of language models can be partially provided if, as the models learn to produce higher-quality code summaries, they also align in deeming the same code parts important as those identified by human programmers. In this paper, we report negative results from our investigation of explainability of language models in code summarization through the lens of human comprehension. We measure human focus on code using eye-tracking metrics such as fixation counts and duration in code summarization tasks. To approximate language model focus, we employ a state-of-the-art model-agnostic, black-box, perturbation-based approach, SHAP (SHapley Additive exPlanations), to identify which code tokens influence that generation of summaries. Using these settings, we find no statistically significant relationship between language models' focus and human programmers' attention. Furthermore, alignment between model and human foci in this setting does not seem to dictate the quality of the LLM-generated summaries. Our study highlights an inability to align human focus with SHAP-based model focus measures. This result calls for future investigation of multiple open questions for explainable language models for code summarization and software engineering tasks in general, including the training mechanisms of language models for code, whether there is an alignment between human and model attention on code, whether human attention can improve the development of language models, and what other model focus measures are appropriate for improving explainability.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {47–51},
numpages = {5},
keywords = {neural code summarization, language models, explainable AI, SHAP, human attention, eye-tracking},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3663529.3663860,
author = {\"{O}qvist, Karl and Messinger, Jacob and Wohlrab, Rebekka},
title = {Supporting Early Architectural Decision-Making through Tradeoff Analysis: A Study with Volvo Cars},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663860},
doi = {10.1145/3663529.3663860},
abstract = {As automotive companies increasingly move operations to the cloud, they need to carefully make architectural decisions. Currently, architectural decisions are made ad-hoc and depend on the experience of the involved architects. Recent research has proposed the use of data-driven techniques that help humans to understand complex design spaces and make thought-through decisions. This paper presents a design science study in which we explored the use of such techniques in collaboration with architects at Volvo Cars. We show how a software architecture can be simulated to make more principled design decisions and allow for architectural tradeoff analysis. Concretely, we apply machine learning-based techniques such as Principal Component Analysis, Decision Tree Learning, and clustering. Our findings show that the tradeoff analysis performed on the data from simulated architectures gave important insights into what the key tradeoffs are and what design decisions shall be taken early on to arrive at a high-quality architecture.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {411–416},
numpages = {6},
keywords = {architectural analysis, cloud systems, design decisions, principal component analysis, software architecture, tradeoff analysis},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@article{10.1145/3635712,
author = {Ferrari, Alessio and Huichapa, Thaide and Spoletini, Paola and Novielli, Nicole and Fucci, Davide and Girardi, Daniela},
title = {Using Voice and Biofeedback to Predict User Engagement during Product Feedback Interviews},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3635712},
doi = {10.1145/3635712},
abstract = {Capturing users’ engagement is crucial for gathering feedback about the features of a software product. In a market-driven context, current approaches to collecting and analyzing users’ feedback are based on techniques leveraging information extracted from product reviews and social media. These approaches are hardly applicable in contexts where online feedback is limited, as for the majority of apps, and software in general. In such cases, companies need to resort to face-to-face interviews to get feedback on their products. In this article, we propose to utilize biometric data, in terms of physiological and voice features, to complement product feedback interviews with information about the engagement of the user on product-relevant topics. We evaluate our approach by interviewing users while gathering their physiological data (i.e., biofeedback) using an Empatica E4 wristband, and capturing their voice through the default audio-recorder of a common laptop. Our results show that we can predict users’ engagement by training supervised machine learning algorithms on biofeedback and voice data, and that voice features alone can be sufficiently effective. The best configurations evaluated achieve an average F1 ∼ 70% in terms of classification performance, and use voice features only. This work is one of the first studies in requirements engineering in which biometrics are used to identify emotions. Furthermore, this is one of the first studies in software engineering that considers voice analysis. The usage of voice features can be particularly helpful for emotion-aware feedback collection in remote communication, either performed by human analysts or voice-based chatbots, and can also be exploited to support the analysis of meetings in software engineering research.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {87},
numpages = {36},
keywords = {Software engineering, requirements engineering, emotion detection, voice analysis, speech analysis, biofeedback analysis, affective requirements engineering}
}

@inproceedings{10.1145/3663529.3663831,
author = {Stradowski, Szymon and Madeyski, Lech},
title = {Costs and Benefits of Machine Learning Software Defect Prediction: Industrial Case Study},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663831},
doi = {10.1145/3663529.3663831},
abstract = {Context: Our research is set in the industrial context of Nokia 5G and the introduction of Machine Learning Software Defect Prediction (ML SDP) to the existing quality assurance process within the company. Objective: We aim to support or undermine the profitability of the proposed ML SDP solution designed to complement the system-level black-box testing at Nokia, as cost-effectiveness is the main success criterion for further feasibility studies leading to a potential commercial introduction. Method: To evaluate the expected cost-effectiveness, we utilize one of the available cost models for software defect prediction formulated by previous studies on the subject. Second, we calculate the standard Return on Investment (ROI) and Benefit-Cost Ratio (BCR) financial ratios to demonstrate the profitability of the developed approach based on real-world, business-driven examples. Third, we build an MS Excel-based tool to automate the evaluation of similar scenarios that other researchers and practitioners can use. Results: We considered different periods of operation and varying efficiency of predictions, depending on which of the two proposed scenarios were selected (lightweight or advanced). Performed ROI and BCR calculations have shown that the implemented ML SDP can have a positive monetary impact and be cost-effective in both scenarios. Conclusions: The cost of adopting new technology is rarely analyzed and discussed in the existing scientific literature, while it is vital for many software companies worldwide. Accordingly, we bridge emerging technology (machine learning software defect prediction) with a software engineering domain (5G system-level testing) and business considerations (cost efficiency) in an industrial environment of one of the leaders in 5G wireless technology.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {92–103},
numpages = {12},
keywords = {case study, cost-benefit analysis, industry, machine learning, software defect prediction, software testing},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3613372.3614189,
author = {Albonico, Michel and Varela, Paulo J\'{u}nior},
title = {A Report on the Use of ChatGPT in Software Engineering and Systems Analysis Courses},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613372.3614189},
doi = {10.1145/3613372.3614189},
abstract = {ChatGPT is a natural language model that works as a virtual chat assistant. It has the potential to be used for fostering classroom discussions and addressing student needs when the professor is not accessible. Although it is still early to assess the impact of ChatGPT and similar technologies, there is a considerable discussion on social media and blogs regarding the aspirations and opportunities of utilizing ChatGPT in the software industry and education. The main perception is that ChatGPT can serve as a support tool but should not completely replace interpersonal interaction, as face-to-face dialogue remains crucial for the development of interpersonal skills and a deeper understanding of concepts. This article reports a recent classroom experience in the subjects of Software Engineering and Systems Analysis, while also analyzing ChatGPT’s responses to student inquiries.},
booktitle = {Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
pages = {303–311},
numpages = {9},
keywords = {ChatGPT, Software Engineering, Student Support, System Analysis},
location = {Campo Grande, Brazil},
series = {SBES '23}
}

@inproceedings{10.1145/3534678.3542914,
author = {Goldenberg, Dmitri and Sokolova, Elena and Meir Lador, Shir and Mandelbaum, Amit and Vasilinetc, Irina and Jain, Ankit},
title = {Workshop on Applied Machine Learning Management},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3542914},
doi = {10.1145/3534678.3542914},
abstract = {Machine learning applications are rapidly adopted by industry leaders in any field. The growth of investment in AI-driven solutions created new challenges in managing Data Science and ML resources, people and projects as a whole. The discipline of managing applied machine learning teams, requires a healthy mix between agile product development tool-set and a long term research oriented mindset. The abilities of investing in deep research while at the same time connecting the outcomes to significant business results create a large knowledge based on management methods and best practices in the field. The Workshop on Applied Machine Learning Management brings together applied research managers from various fields to share methodologies and case-studies on management of ML teams, products, and projects, achieving business impact with advanced AI-methods.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4874–4875},
numpages = {2},
keywords = {data science management, machine learning management, ml product development},
location = {Washington DC, USA},
series = {KDD '22}
}

@proceedings{10.1145/3620665,
title = {ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
year = {2024},
isbn = {9798400703850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
abstract = {Welcome to the second volume of ASPLOS'24: the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. This document is dedicated to the 2024 summer review cycle.We introduced several notable changes to ASPLOS this year, many of which were discussed in the previous message from program chairs in Volume 1. Here, to avoid repetition, we assume that readers have already read the latter message and will only describe differences between the current cycle and the previous one. These include: (1) developing and utilizing an automated format violation identifier script focused on uncovering disallowed vertical space manipulations that "squeeze" space; (2) incorporating authors-declared best-matching topics into our review assignment process; (3) introducing the new ASPLOS role of Program Vice Chairs to cope with the increased number of submissions and the added load caused by foregoing synchronous program committee (PC) meetings, which necessitated additional managerial involvement in online dissensions; and (4) characterizing a systematic problem that ASPLOS is facing in reviewing quantum computing submissions, describing how we addressed it, and highlighting how we believe that it should be handled in the future.Key statistics of the ASPLOS'24 summer cycle include: 409 submissions were finalized (about 1.5x more than last year's summer count and nearly 2.4x more than our spring cycle), with 107 related to accelerators/FPGAs/GPUs, 97 to machine learning, 88 to storage/memory, 80 to security, and 69 to datacenter/cloud; 179 (44%) submissions were promoted to the second review round; 54 (13.2%) papers were accepted (with 20 awarded one or more artifact evaluation badges); 33 (8.1%) submissions were allowed to submit major revisions, of which 27 were subsequently accepted during the fall cycle (with 13 awarded one or more artifact evaluation badges); 1,499 reviews were uploaded; and 5,557 comments were generated during online discussions.Analyzing the per-submission most-related broader areas of research, which we asked authors to associate with their work in the submission form, revealed that 71%, 47%, and 28% of the submissions are categorized by their authors as related to architecture, operating systems, and programming languages, respectively, with about 45% being "interdisciplinary" submissions (associated with more than one area). The full details are available in the PDF of the front matter.},
location = {La Jolla, CA, USA}
}

@inproceedings{10.1145/3603163.3610575,
author = {De Luca, Ernesto William and Fiorelli, Manuel and Picca, Davide and Stellato, Armando and Wehnert, Sabine},
title = {Legal Information Retrieval meets Artificial Intelligence (LIRAI)},
year = {2023},
isbn = {9798400702327},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603163.3610575},
doi = {10.1145/3603163.3610575},
abstract = {The Legal Information Retrieval meets Artificial Intelligence (LIRAI) workshop series aims to provide a venue hosting discussion of novel ideas, evaluations, and success stories concerning the application of Artificial Intelligence (AI) and Information Retrieval (IR) to the legal domain. All around the world, lawmakers, legal professionals, and citizens must cope with the sheer amount of legal knowledge present in legal documents. These documents can be norms, regulations, directives, legal cases, and other relevant material for legal practitioners, such as legal commentary. The continuous evolution of legal documents is a challenging setting, with implicit relationships playing an important role beyond explicit references. Recently, the adoption of shared machine-readable formats and FAIR principles, as well as methods and practices from the Semantic Web, have certainly improved the accessibility of legal knowledge and its interoperability. Still, retrieving legal knowledge and making sense of it are not solved problems. The legal community often has special requirements for retrieval systems (e.g., high recall, explainability). Artificial Intelligence (AI) is positioned as a lever to enhance our ability to find, understand, and correlate legal information, and to comprehend its relationship to reality, in terms of compliance evaluation and risk/benefit analysis. We call contributions on these topics in the form of papers, which will be collected in an open-access proceedings published on CEURWS.org and thus indexed by Scopus, DBLP, Google Scholar, and other citation databases.},
booktitle = {Proceedings of the 34th ACM Conference on Hypertext and Social Media},
articleno = {46},
numpages = {4},
keywords = {Explainable AI, FAIRness, High-Recall Retrieval, Legal Compliance, Legal Informatics, Legal Information Retrieval, Legal Knowledge Representation, Legal Text Mining, Linguistic Legal Linked Open Data, Semantic Web},
location = {Rome, Italy},
series = {HT '23}
}

@article{10.1145/3704991.3704995,
author = {Varde, Aparna S.},
title = {HaaS in Environmental Computing: Hadoop-as-a-Service for Big Data Mining in Environmental Computing Applications},
year = {2024},
issue_date = {Autumn 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2024},
number = {Autumn},
issn = {1931-1745},
url = {https://doi.org/10.1145/3704991.3704995},
doi = {10.1145/3704991.3704995},
abstract = {This article addresses the importance of HaaS (Hadoop-as-a-Service) in cloud technologies, with specific reference to its usefulness in big data mining for environmental computing applications. The term environmental computing refers to computational analysis within environmental science and management, encompassing a myriad of techniques, especially in data mining and machine learning. As is well-known, the classical MapReduce has been adapted within many applications for big data storage and information retrieval. Hadoop based tools such as Hive and Mahout are broadly accessible over the cloud and can be helpful in data warehousing and data mining over big data in various domains. In this article, we explore HaaS technologies, mainly based on Apache's Hive and Mahout for applications in environmental computing, considering publicly available data on the Web. We dwell upon interesting applications such as automated text classification for energy management, recommender systems for ecofriendly products, and decision support in urban planning. We briefly explain the classical paradigms of MapReduce, Hadoop and Hive, further delve into data mining and machine learning over the MapReduce framework, and explore techniques such as Na\"{\i}ve Bayes and Random Forests using Apache Mahout with respect to the targeted applications. Hence, the paradigm of Hadoop-as-a-Service, popularly referred to as HaaS, is emphasized here as per its benefits in a domain-specific context. The studies in environmental computing, as presented in this article, can be useful in other domains as well, considering similar applications. This article can thus be interesting to professionals in web technologies, cloud computing, environmental management, as well as AI and data science in general.},
journal = {SIGWEB Newsl.},
month = dec,
articleno = {4},
numpages = {18}
}

@inproceedings{10.1145/3652620.3687800,
author = {Aslan O\u{g}uz, Evin and Kuester, Jochen Malte},
title = {A Comparative Analysis of ChatGPT-Generated and Human-Written Use Case Descriptions},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687800},
doi = {10.1145/3652620.3687800},
abstract = {The development of comprehensive use case descriptions is a critical task in software engineering, providing essential insights for requirement analysis and system design. The advent of advanced natural language processing models, such as ChatGPT, has sparked interest in their potential to automate tasks traditionally performed by humans, including the generation of use case descriptions in software engineering. Understanding the capabilities and limitations of ChatGPT in generating use case descriptions is crucial for software engineers. Without a clear understanding of its performance, practitioners may either overestimate its utility, leading to reliance on suboptimal drafts, or underestimate its capabilities, missing opportunities to streamline the drafting process. This paper addresses how well ChatGPT performs in generating use case descriptions, evaluating their quality compared to human-written descriptions. To do so, we employ a structured approach using established quality guidelines and the concept of "bad smells" for use case descriptions. Our study presents the first attempt to bridge the knowledge gap by offering a comparative analysis of ChatGPT-generated and human-written use case descriptions. By providing an approach to objectively assess ChatGPT's performance, we highlight its potential and limitations, offering software engineers insights to effectively integrate AI tools into their workflows.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {533–540},
numpages = {8},
keywords = {use case description, ChatGPT, requirements engineering, quality},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3510003.3510049,
author = {Ahmed, Toufique and Devanbu, Premkumar},
title = {Multilingual training for software engineering},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510049},
doi = {10.1145/3510003.3510049},
abstract = {Well-trained machine-learning models, which leverage large amounts of open-source software data, have now become an interesting approach to automating many software engineering tasks. Several SE tasks have all been subject to this approach, with performance gradually improving over the past several years with better models and training methods. More, and more diverse, clean, labeled data is better for training; but constructing good-quality datasets is time-consuming and challenging. Ways of augmenting the volume and diversity of clean, labeled data generally have wide applicability. For some languages (e.g., Ruby) labeled data is less abundant; in others (e.g., JavaScript) the available data maybe more focused on some application domains, and thus less diverse. As a way around such data bottlenecks, we present evidence suggesting that human-written code in different languages (which performs the same function), is rather similar, and particularly preserving of identifier naming patterns; we further present evidence suggesting that identifiers are a very important element of training data for software engineering tasks. We leverage this rather fortuitous phenomenon to find evidence that available multilingual training data (across different languages) can be used to amplify performance. We study this for 3 different tasks: code summarization, code retrieval, and function naming. We note that this data-augmenting approach is broadly compatible with different tasks, languages, and machine-learning models.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {1443–1455},
numpages = {13},
keywords = {code search, code summarization, deep learning, method name prediction},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3674805.3686695,
author = {Abdellatif, Ahmad and Badran, Khaled and Costa, Diego Elias and Shihab, Emad},
title = {A Transformer-based Approach for Augmenting Software Engineering Chatbots Datasets},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3686695},
doi = {10.1145/3674805.3686695},
abstract = {Background: The adoption of chatbots into software development tasks has become increasingly popular among practitioners, driven by the advantages of cost reduction and acceleration of the software development process. Chatbots understand users’ queries through the Natural Language Understanding component (NLU). To yield reasonable performance, NLUs have to be trained with extensive, high-quality datasets, that express a multitude of ways users may interact with chatbots. However, previous studies show that creating a high-quality training dataset for software engineering chatbots is expensive in terms of both resources and time. Aims: Therefore, in this paper, we present an automated transformer-based approach to augment software engineering chatbot datasets. Method: Our approach combines traditional natural language processing techniques with the BART transformer to augment a dataset by generating queries through synonym replacement and paraphrasing. We evaluate the impact of using the augmentation approach on the Rasa NLU’s performance using three software engineering datasets. Results: Overall, the augmentation approach shows promising results in improving the Rasa’s performance, augmenting queries with varying sentence structures while preserving their original semantics. Furthermore, it increases Rasa’s confidence in its intent classification for the correctly classified intents. Conclusions: We believe that our study helps practitioners improve the performance of their chatbots and guides future research to propose augmentation techniques for SE chatbots.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {359–370},
numpages = {12},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3551349.3556918,
author = {Yang, Chenyang and Brower-Sinning, Rachel A and Lewis, Grace and K\"{A}Stner, Christian},
title = {Data Leakage in Notebooks: Static Detection and Better Processes},
year = {2023},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551349.3556918},
doi = {10.1145/3551349.3556918},
abstract = {Data science pipelines to train and evaluate models with machine learning may contain bugs just like any other code. Leakage between training and test data can lead to overestimating the model’s accuracy during offline evaluations, possibly leading to deployment of low-quality models in production. Such leakage can happen easily by mistake or by following poor practices, but may be tedious and challenging to detect manually. We develop a static analysis approach to detect common forms of data leakage in data science code. Our evaluation shows that our analysis accurately detects data leakage and that such leakage is pervasive among over 100,000 analyzed public notebooks. We discuss how our static analysis approach can help both practitioners and educators, and how leakage prevention can be designed into the development process.},
booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
articleno = {30},
numpages = {12},
location = {Rochester, MI, USA},
series = {ASE '22}
}

@inproceedings{10.1145/3610969.3611132,
author = {Petrovska, Olga and Clift, Lee and Moller, Faron},
title = {Generative AI in Software Development Education: Insights from a Degree Apprenticeship Programme},
year = {2023},
isbn = {9798400708763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610969.3611132},
doi = {10.1145/3610969.3611132},
abstract = {We describe insights gained from incorporating ChatGPT into assignments for our Software Engineering Degree Apprenticeship programme, including attitudes expressed by the learners and their employers regarding our approach.},
booktitle = {Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {19},
numpages = {1},
keywords = {Apprenticeships, Education, Generative AI, Software Engineering},
location = {Swansea, Wales Uk},
series = {UKICER '23}
}

@inproceedings{10.1145/3665601.3669844,
author = {Huang, Zezhou},
title = {Disambiguate Entity Matching using Large Language Models through Relation Discovery},
year = {2024},
isbn = {9798400706943},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665601.3669844},
doi = {10.1145/3665601.3669844},
abstract = {Entity matching is a critical problem in data integration, central to tasks like fuzzy joins for tuple enrichment. Traditional approaches have focused on overcoming fuzzy term representations through methods such as edit distance, Jaccard similarity, and more recently, embeddings and deep neural networks, including advancements from large language models (LLMs) like GPT. However, when integrating with external databases, the core challenge in entity matching extends beyond term fuzziness to the ambiguity in defining what constitutes a "match". This is because external databases contain tuples with varying levels of detail and granularity among entities, and an "exact match" in traditional entity matching rarely happens. As a result, understanding how entities are related and the potential nuances is critical, especially for high-stake tasks for responsible AI. In this work, we study a case problem of entity matching for ESG reporting. We propose a novel approach that shifts focus from purely identifying semantic similarities to understanding and defining the "relations" between entities for resolving ambiguities in matching, with a human-in-the-loop process to make the final decision. By pre-defining a set of relations relevant to the task at hand, our method allows analysts to navigate the spectrum of similarity more effectively, from exact matches to conceptually related entities, and responsibly perform downstream tasks.},
booktitle = {Proceedings of the Conference on Governance, Understanding and Integration of Data for Effective and Responsible AI},
pages = {36–39},
numpages = {4},
keywords = {Data Integration, Entity Matching, Large Language Models},
location = {Santiago, AA, Chile},
series = {GUIDE-AI '24}
}

@inproceedings{10.1145/3639477.3639732,
author = {Song, Yewei and Ezzini, Saad and Tang, Xunzhu and Lothritz, Cedric and Klein, Jacques and Bissyande, Tegawende and Boytsov, Andrey and Ble, Ulrick and Goujon, Anne},
title = {Enhancing Text-to-SQL Translation for Financial System Design},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639732},
doi = {10.1145/3639477.3639732},
abstract = {Text-to-SQL, the task of translating natural language questions into SQL queries, is part of various business processes. Its automation, which is an emerging challenge, will empower software practitioners to seamlessly interact with relational databases using natural language, thereby bridging the gap between business needs and software capabilities.In this paper, we consider Large Language Models (LLMs), which have achieved state of the art for various NLP tasks. Specifically, we benchmark Text-to-SQL performance, the evaluation methodologies, as well as input optimization (e.g., prompting). In light of the empirical observations that we have made, we propose two novel metrics that were designed to adequately measure the similarity between SQL queries.Overall, we share with the community various findings, notably on how to select the right LLM on Text-to-SQL tasks. We further demonstrate that a tree-based edit distance constitutes a reliable metric for assessing the similarity between generated SQL queries and the oracle for benchmarking Text2SQL approaches. This metric is important as it relieves researchers from the need to perform computationally expensive experiments such as executing generated queries as done in prior works. Our work implements financial domain use cases and, therefore contributes to the advancement of Text2SQL systems and their practical adoption in this domain.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {252–262},
numpages = {11},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@inproceedings{10.1145/3477314.3507200,
author = {Chew, Michelle Y. and Cheng, Yi J. and Mahan, Oliver and Islam, Md Rakibul},
title = {A comparative study of name entity recognition techniques in software engineering texts},
year = {2022},
isbn = {9781450387132},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477314.3507200},
doi = {10.1145/3477314.3507200},
abstract = {Named Entity Recognition (NER) is an essential sub-task for many important tasks in software engineering (SE), such as automated requirement analysis, opinion mining, question answering, knowledge base construction, and information retrieval. As existing domain-independent NER approaches perform low when applied in the SE domain, we observe the development of different tools and techniques for NER in this domain recently. Despite those developments, we lack our understanding of the effectiveness of the deep learning based state-of-the-art models and existing popular machine learning based tools for NER in SE texts.Thus, in this study, we quantitatively evaluate the performances of seven versions of machine learning and deep learning based tools and techniques in detecting name entities from SE texts. This study will advance our understanding on the effectiveness of the NER techniques in the SE domain.},
booktitle = {Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing},
pages = {1611–1614},
numpages = {4},
keywords = {BERT, CRF, NER, name entity recognition, software engineering},
location = {Virtual Event},
series = {SAC '22}
}

@techreport{10.1145/3592625,
author = {Caspersen, Michael E. and Diethelm, Ira and Gal-Ezer, Judith and McGettrick, Andrew and Nardelli, Enrico and Passey, Don and Rovan, Branislav and Webb, Mary},
title = {Informatics Reference Framework for School},
year = {2022},
isbn = {979-8-4007-0884-8},
publisher = {National Science Foundation},
address = {USA},
abstract = {The contribution that informatics has made since the last century has fuelled innovative and signifi-cant technological advances and vice versa. It makes fundamental contributions to current economic, educational, industrial and social development.Informatics importantly has the capacity to support and augment human reasoning and potential. Education systems have a responsibility to recognise this and to ensure that young people are equipped to be able to drive forward, judge innovation and take part in the development of a just and fair society.To properly embrace this development by society in general, informatics has to be seen as an essential aspect of the education of all pupils. The present report, which outlines an informatics reference framework for all young people, bears that in mind. It is intended to offer high-level guidance that may be used by, and indeed stimulate, curriculum designers to review their focus and approach to the subject of informatics.Following the introductory sections, the heart of the reference framework is described in section 4. A set of aims and objectives for informatics educa-tion for all young people is provided in section 4.2 followed by a set of core concepts and an accompa-nying brief description of these in Table 1 of section 4.3; this conveys a robust structure and a general architecture, which captures an essential view of informatics as a discipline in general education. To complement the general architecture, a contem-porary and outward facing view of informatics is offered in section 4.4; this includes discussion of modern developments that relate to topics such as data science and artificial intelligence, as well as at-tention to related ethical concerns.Annex A.1 presents a brief description of infor-matics as a discipline. Annex A.2 presents a limited number of examples of how high-level learning out-comes could be described in a concrete curriculum at three levels that reflect indicators of outcomes after primary, lower secondary and upper secondary education.}
}

@inproceedings{10.1145/3616480.3616484,
author = {Liao, Yuan-Hsun and Li, Hsiao-Hui and Chang, Po-Chun and Hsu, Chiao-Ti and Wang, Ruo-An},
title = {Design an Intelligent Candy Inspection System with AIoT},
year = {2023},
isbn = {9798400708855},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616480.3616484},
doi = {10.1145/3616480.3616484},
abstract = {In the global community, countries are paying more and more attention to the monitoring and control of food safety. The food industry is investing more resources in the production chain to improve the process. Food products may be affected by disturbances or contamination during production, processing, storage, and transportation. This causes a variety of defects in the food, which can damage the quality of the food. Food defects are classified as problems with the contents and appearance, mostly changes in food substances or damage. If the food is affected by pathogenic microorganisms and deteriorates, it will also change the appearance of the food. The problematic food will bring damage to the health of customers. Through appropriate inspection mechanisms, it is possible to prevent and reduce product recalls and processing costs. As well as satisfying consumer expectations and needs. The cost savings to the food industry are substantial. To overcome this important problem, this study utilizes artificial intelligence (AI), artificial intelligent Internet of Things (AIoT), software engineering, and data analysis techniques to build a software and hardware system with an intelligent fondant inspection system. The original manual inspection mechanism is further upgraded to an intelligent inspection system. We designed the inspection machine according to the needs of the production line and designed it as a platform for self-training. In addition to saving more manpower for manufacturers, the system will continue to grow through self-training and tuning model functions. We hope to achieve higher inspection accuracy and contribute to food safety.},
booktitle = {Proceedings of the 2023 5th International Electronics Communication Conference},
pages = {22–26},
numpages = {5},
keywords = {Artificial Intelligence of Things, Defect Detection, Intelligence Candy Inspection System},
location = {Osaka City, Japan},
series = {IECC '23}
}

@article{10.1145/3654992,
author = {Wu, Yang and Wan, Yao and Zhang, Hongyu and Sui, Yulei and Wei, Wucai and Zhao, Wei and Xu, Guandong and Jin, Hai},
title = {Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654992},
doi = {10.1145/3654992},
abstract = {The Natural Language to Visualization (NL2Vis) task aims to transform natural-language descriptions into visual representations for a grounded table, enabling users to gain insights from vast amounts of data. Recently, many deep learning-based approaches have been developed for NL2Vis. Despite the considerable efforts made by these approaches, challenges persist in visualizing data sourced from unseen databases or spanning multiple tables. Taking inspiration from the remarkable generation capabilities of Large Language Models (LLMs), this paper conducts an empirical study to evaluate their potential in generating visualizations, and explore the effectiveness of in-context learning prompts for enhancing this task. In particular, we first explore the ways of transforming structured tabular data into sequential text prompts, as to feed them into LLMs and analyze which table content contributes most to the NL2Vis. Our findings suggest that transforming structured tabular data into programs is effective, and it is essential to consider the table schema when formulating prompts. Furthermore, we evaluate two types of LLMs: finetuned models (e.g., T5-Small) and inference-only models (e.g., GPT-3.5), against state-of-the-art methods, using the NL2Vis benchmarks (i.e., nvBench). The experimental results reveal that LLMs outperform baselines, with inference-only models consistently exhibiting performance improvements, at times even surpassing fine-tuned models when provided with certain few-shot demonstrations through in-context learning. Finally, we analyze when the LLMs fail in NL2Vis, and propose to iteratively update the results using strategies such as chain-of-thought, role-playing, and code-interpreter. The experimental results confirm the efficacy of iterative updates and hold great potential for future study.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {115},
numpages = {28},
keywords = {code generation, data analysis, data visualization, exploratory study, large language models, natural language processing}
}

@inproceedings{10.1145/3510454.3522680,
author = {Pontillo, Valeria},
title = {Static test flakiness prediction},
year = {2022},
isbn = {9781450392235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510454.3522680},
doi = {10.1145/3510454.3522680},
abstract = {The problem of flakiness occurs when a test case is non-deterministic and exhibits both a passing and failing behavior when run against the same code. Over the last years, the software engineering research community has been working toward defining approaches for detecting and addressing test flakiness, but most of these approaches suffer from scalability issues. Recently, this limitation has been targeted through machine learning solutions that could predict flaky tests using various features, both static and dynamic. Unfortunately, the proposed solutions involve features that could be costly to compute. In this paper, I perform a step forward and predict test flakiness only using statically computable metrics. I conducted an experiment on 18 Java projects coming from the FlakeFlagger dataset. First, I statistically assess the differences between flaky and non-flaky tests in terms of 25 static metrics in an individual and combined way. Then, I experimented with a machine learning approach that predicts flakiness based on the previously evaluated factors. The results show that static features can be used to characterize flaky tests: this is especially true for metrics and smells connected to source code complexity. In addition, this new static approach has performance comparable to the machine learning models already in the literature in terms of F-Measure.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
pages = {325–327},
numpages = {3},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3580305.3599180,
author = {Ghani, Rayid and Rodolfa, Kit T. and Saleiro, Pedro and Jesus, S\'{e}rgio},
title = {Addressing Bias and Fairness in Machine Learning: A Practical Guide and Hands-on Tutorial},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599180},
doi = {10.1145/3580305.3599180},
abstract = {As data science and machine learning (ML) increasingly shape our society, the importance of developing fair algorithmic decision-making systems becomes paramount. There is a pressing need to train data scientists and practitioners on handling bias and fairness in real-world scenarios, from early stages of a data science project to maintaining ML systems in production. Existing resources are mostly academic and cover the ML training and optimization aspects of bias mitigation, leaving practitioners without comprehensive frameworks for making decisions throughout a real-world project lifecycle. This tutorial aims to bridge the gap between research and practice, providing an in-depth exploration of algorithmic fairness, encompassing metrics and definitions, practical case studies, data bias understanding, bias mitigation and model fairness audits using the Aequitas toolkit. Participants will be equipped to engage in conversations about bias, assist decision-makers in understanding options and trade-offs, evaluate project scoping aspects influencing fairness outcomes, and define actions and interventions based on model predictions. They will also learn to identify cohorts, target variables, evaluation metrics, and establish bias and fairness goals for different groups. Moreover, participants will gain insights into auditing and mitigating model bias, and implementing continuous monitoring to assess retraining needs. The tutorial addresses the current lack of practical training materials, methodologies, and tools for researchers and developers working on real-world algorithmic decision-making systems. By the conclusion of this hands-on tutorial, attendees will be well-versed in navigating bias-related issues, selecting appropriate metrics, and applying bias audit and mitigation frameworks and tools for informed design decisions in real-world data science systems.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5779–5780},
numpages = {2},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3491102.3501998,
author = {Cambo, Scott Allen and Gergle, Darren},
title = {Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501998},
doi = {10.1145/3491102.3501998},
abstract = {Data science and machine learning provide indispensable techniques for understanding phenomena at scale, but the discretionary choices made when doing this work are often not recognized. Drawing from qualitative research practices, we describe how the concepts of positionality and reflexivity can be adapted to provide a framework for understanding, discussing, and disclosing the discretionary choices and subjectivity inherent to data science work. We first introduce the concepts of model positionality and computational reflexivity that can help data scientists to reflect on and communicate the social and cultural context of a model’s development and use, the data annotators and their annotations, and the data scientists themselves. We then describe the unique challenges of adapting these concepts for data science work and offer annotator fingerprinting and position mining as promising solutions. Finally, we demonstrate these techniques in a case study of the development of classifiers for toxic commenting in online communities.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {572},
numpages = {19},
keywords = {Computational reflexivity, annotator fingerprinting, critical data studies, data science, human-centered data science, human-centered machine learning, model positionality, position mining},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3606305.3606321,
author = {Ivanova, Tatyana Ivanova},
title = {Semi-automatic ontology development for supporting personalized tutoring},
year = {2023},
isbn = {9798400700477},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3606305.3606321},
doi = {10.1145/3606305.3606321},
abstract = {Many researches have working the last two decades on ontology learning, using NLP, data mining, and machine learning, but experiments show, that every ontology learning method have his precision and recall less than 1, and automatically developed ontologies need from human evaluation and modification. So, participation of experts is a must in ontology development to guarantee high quality and the semi-automatic ontology development is the only approach having potential to ensure cheaper development of high-quality ontologies. In this research we will discuss semi-automatic support of ontology engineering process, based on automated knowledge extraction from text, semi-structured or structured sources. Most of automated ontology development methods and algorithms are domain – dependent. We analyze specifics of semi-automatic ontology development in the e-learning domain and propose software architecture of semi-automatic ontology development framework for educational ontologies.},
booktitle = {Proceedings of the 24th International Conference on Computer Systems and Technologies},
pages = {180–185},
numpages = {6},
location = {Ruse, Bulgaria},
series = {CompSysTech '23}
}

@inproceedings{10.1145/3551349.3559510,
author = {Wei, Chenhao and Xiao, Lu and Yu, Tingting and Chen, Xinyu and Wang, Xiao and Wong, Sunny and Clune, Abigail},
title = {Automatically Tagging the “AAA” Pattern in Unit Test Cases Using Machine Learning Models},
year = {2023},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551349.3559510},
doi = {10.1145/3551349.3559510},
abstract = {The AAA pattern, i.e. the Arrangement, Action, and Assertion, is a common and nature layout to create a test case. Following this pattern in test cases may benefit comprehension, debugging, and maintenance. The AAA structure of real-life test cases may not be explicit due to its high complexity. Manually labeling AAA statements in test cases is tedious. Thus, an automated approach for labeling AAA statements in existing test cases could benefit new developers and projects that practice collective code ownership and test driven development. This study contributes an automatic approach based on machine learning models. The “secret sauce” of this approach is a set of three learning features that are based on the semantic, syntax, and context information in test cases, derived from the manual tagging process. Thus, our approach mimics how developers may manually tag the AAA pattern of a test case. We assess the precision, recall, and F-1 score of our approach based on 449 test cases, containing about 16,612 statements, across 4 Apache open source projects. For achieving the best performance in our approach, we explore the usage of six machine learning models; the contribution of the SMOTE data balancing technique; the comparison of the three learning features; and the comparison of five different methods for calculating the semantic feature. The results show our approach is able to identify Arrangement, Action, and Assertion statements with a precision upwards of 92%, and recall up to 74%. Our experiments also provide empirical insights regarding how to best leverage machine learning for software engineering tasks.},
booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
articleno = {194},
numpages = {3},
keywords = {AAA pattern, Feature engineering, Machine Learning, Natural language processing, Software testing, Unit testing},
location = {Rochester, MI, USA},
series = {ASE '22}
}

@inproceedings{10.1145/3583780.3614748,
author = {Yin, Biao and Josselyn, Nicholas and Zhang, Ziming and Rundensteiner, Elke A. and Considine, Thomas A. and Kelley, John V. and Rinderspacher, Berend C. and Jensen, Robert E. and Snyder, James F.},
title = {MOSS: AI Platform for Discovery of Corrosion-Resistant Materials},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614748},
doi = {10.1145/3583780.3614748},
abstract = {Amid corrosion degradation of metallic structures causing expenses nearing 3 trillion or 4% of the GDP annually along with major safety risks, the adoption of AI technologies for accelerating the materials science life-cycle for developing materials with better corrosive properties is paramount. While initial machine learning models for corrosion assessment are being proposed in the literature, their incorporation into end-to-end tools for field experimentation by corrosion scientists remains largely unexplored. To fill this void, our university data science team in collaboration with the materials science unit at the Army Research Lab have jointly developed MOSS, an innovative AI-based digital platform to support material science corrosion research. MOSS features user-friendly iPadOS app for in-field corrosion progression data collection, deep-learning corrosion assessor, robust data repository system for long-term experimental data modeling, and visual analytics web portal for material science research. In this demonstration, we showcase the key innovations of the MOSS platform via use cases supporting the corrosion exploration processes, with the promise of accelerating the discovery of new materials. We open a MOSS video demo at: https://www.youtube.com/watch?v=CzcxMMRsxkE},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {5128–5132},
numpages = {5},
keywords = {automatic assessment, corrosion science, deep learning},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3528227.3528569,
author = {Lakshman, Shashank Bangalore and Eisty, Nasir U.},
title = {Software engineering approaches for TinyML based IoT embedded vision: a systematic literature review},
year = {2023},
isbn = {9781450393324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3528227.3528569},
doi = {10.1145/3528227.3528569},
abstract = {Internet of Things (IoT) has catapulted human ability to control our environments through ubiquitous sensing, communication, computation, and actuation. Over the past few years, IoT has joined forces with Machine Learning (ML) to embed deep intelligence at the far edge. TinyML (Tiny Machine Learning) has enabled the deployment of ML models for embedded vision on extremely lean edge hardware, bringing the power of IoT and ML together. However, TinyML powered embedded vision applications are still in a nascent stage, and they are just starting to scale to widespread real-world IoT deployment. To harness the true potential of IoT and ML, it is necessary to provide product developers with robust, easy-to-use software engineering (SE) frameworks and best practices that are customized for the unique challenges faced in TinyML engineering. Through this systematic literature review, we aggregated the key challenges reported by TinyML developers and identified state-of-art SE approaches in large-scale Computer Vision, Machine Learning, and Embedded Systems that can help address key challenges in TinyML based IoT embedded vision. In summary, our study draws synergies between SE expertise that embedded systems developers and ML developers have independently developed to help address the unique challenges in the engineering of TinyML based IoT embedded vision.},
booktitle = {Proceedings of the 4th International Workshop on Software Engineering Research and Practice for the IoT},
pages = {33–40},
numpages = {8},
keywords = {IoT, TinyML, embedded vision, software engineering, systematic literature review},
location = {Pittsburgh, Pennsylvania},
series = {SERP4IoT '22}
}

@inproceedings{10.1145/3665939.3665958,
author = {Ordonez, Carlos and Varghese, Robin and Phan, Nguyen and Macyna, Wojciech},
title = {Growing a FLOWER: Building a Diagram Unifying Flow and ER Notation for Data Science},
year = {2024},
isbn = {9798400706936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665939.3665958},
doi = {10.1145/3665939.3665958},
abstract = {An ER diagram is a fundamental visual abstraction to design a database. Modern ER notation has evolved with UML symbols to represent both entities (logical level) and relational tables (physical level). On the other hand, flow diagrams (flowcharts, process flow) remain an important mechanism to visualize the main steps of a data processing pipeline. However, in modern data science projects there is a significant fraction of data that does not come from databases or data that is exported outside the database system, being processed by Python code, without any data model whatsoever. In this paper, we present a novel diagram which is built from source code and its associated browser-based GUI for collaborating on data integration and data preprocessing, mixing diverse data sources and diverse programming languages (mainly Python and SQL). Specifically, our targets are data integration, data cleaning and data transformation, which are needed to derive data sets that can be used as input for a machine learning model. We present a couple of target applications and a preliminary GUI, which partially automates diagram creation. We show our diagram has promise understanding, extending and reusing both data preparation source code and data sets.},
booktitle = {Proceedings of the 2024 Workshop on Human-In-the-Loop Data Analytics},
pages = {1–8},
numpages = {8},
keywords = {diagram, Python, ER, database model, SQL, source code},
location = {Santiago, AA, Chile},
series = {HILDA  24}
}

@inproceedings{10.1145/3529320.3529326,
author = {Sutton, Jr., Stanley M.},
title = {The Corporation as an Artificial Cognitive Entity},
year = {2022},
isbn = {9781450396745},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3529320.3529326},
doi = {10.1145/3529320.3529326},
abstract = {The purpose of this paper is to advance the idea that corporations can be regarded as artificial cognitive entities. Viewed as black boxes, corporations can be seen as widely and frequently regulated, regarded, and active in the same ways as conscious, thinking human beings. Viewed as white boxes, corporations can be seen to incorporate structures and functions analogous to those in the human mind that give rise to awareness and cognition, and they may possess other features that contribute to the realization of cognition in ways not found in humans. While there are certainly differences between humans and corporations in the basis and expression of cognition, the study of cognition in corporations is interesting and instructive and can be pursued as a field of inquiry in its own right. The relevance of software and systems process to corporate cognition is fundamental. Put directly, cognition is a process and corporate cognition is programmable. Thus, what we know from software engineering, process programming, and software and systems process engineering should be directly applicable to the programming (broadly construed) of corporate cognitive systems. An assessment framework such as CMMI (perhaps with a grounding on key cognitive capabilities) should remain broadly applicable to corporate cognitive processes and should serve as a guide to applying best practices in an organization. The study of corporations as artificial cognitive entities should lead to results of scientific interest and practical consequence in many areas, including codification and quantification of measures of corporate cognition, better understanding of corporate cognitive mechanisms, identification of best cognitive practices for corporations, broadening of the discipline of cognitive science, and opportunities for synergism with artificial intelligence applications in corporations. The results may be broadly applicable in society in areas of regulation; investing; employment; business contracting, mergers, and acquisitions; and with respect to ESG (Environmental, Social, and Governance) concerns.},
booktitle = {Proceedings of the International Conference on Software and System Processes and International Conference on Global Software Engineering},
pages = {50–55},
numpages = {6},
keywords = {Artificial cognition, cognitive engineering, cognitive process programming, corporate cognition, corporate cognitive assessment},
location = {Pittsburgh, PA, USA},
series = {ICSSP '22}
}

@inproceedings{10.1145/3691620.3695503,
author = {Huang, Junjie and Guo, Daya and Wang, Chenglong and Gu, Jiazhen and Lu, Shuai and Inala, Jeevana Priya and Yan, Cong and Gao, Jianfeng and Duan, Nan and Lyu, Michael R.},
title = {Contextualized Data-Wrangling Code Generation in Computational Notebooks},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695503},
doi = {10.1145/3691620.3695503},
abstract = {Data wrangling, the process of preparing raw data for further analysis in computational notebooks, is a crucial yet time-consuming step in data science. Code generation has the potential to automate the data wrangling process to reduce analysts' overhead by translating user intents into executable code. Precisely generating data wrangling code necessitates a comprehensive consideration of the rich context present in notebooks, including textual context, code context and data context. However, notebooks often interleave multiple non-linear analysis tasks into linear sequence of code blocks, where the contextual dependencies are not clearly reflected. Directly training models with source code blocks fails to fully exploit the contexts for accurate wrangling code generation.To bridge the gap, we aim to construct a high quality datasets with clear and rich contexts to help training models for data wrangling code generation tasks. In this work, we first propose an automated approach, CoCoMine to mine data-wrangling code generation examples with clear multi-modal contextual dependency. It first adopts data flow analysis to identify the code blocks containing data wrangling codes. Then, CoCoMine extracts the contextualized data-wrangling code examples through tracing and replaying notebooks. With CoCoMine, we construct CoCoNote, a dataset containing 58,221 examples for Contextualized Data-wrangling Code generation in Notebooks. To demonstrate the effectiveness of our dataset, we finetune a range of pretrained code models and prompt various large language models on our task. Furthermore, we also propose Data-Coder, which encodes data context and code&amp;textual contexts separately to enhance code generation. Experiment results demonstrate the significance of incorporating data context in data-wrangling code generation and the effectiveness of our model. We release code and data at https://github.com/Jun-jie-Huang/CoCoNote.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1282–1294},
numpages = {13},
keywords = {code generation, data wrangling, computational notebooks, large language models},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3701625.3701696,
author = {Villamizar, Hugo and Kalinowski, Marcos},
title = {Identifying Concerns When Specifying Machine Learning-Enabled Systems: A Perspective-Based Approach},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701696},
doi = {10.1145/3701625.3701696},
abstract = {Engineering successful machine learning (ML)-enabled systems poses various challenges from both a theoretical and a practical side. Among those challenges are how to effectively address unrealistic expectations of ML capabilities from customers, managers and even other team members, and how to connect business value to engineering and data science activities composed by interdisciplinary teams. In this thesis, we studied the state of the practice and literature of requirements engineering (RE) for ML to propose&nbsp;PerSpecML, a perspective-based approach for specifying ML-enabled systems that helps practitioners identify which attributes, including ML and non-ML components, are important to contribute to the overall system’s quality. The approach involves analyzing 60 concerns related to 28 tasks that practitioners typically face in ML projects, grouping them into five perspectives: system objectives, user experience, infrastructure, model, and data. The conception of &nbsp;PerSpecML involved a series of validations conducted in different contexts: (i) in academia, (ii) with industry representatives, and (iii) in two real industrial case studies. As a result of the diverse validations and continuous improvements,&nbsp;PerSpecML showed a positive impact to the specification of ML-enabled systems, particularly helping to specify key quality components that would have been otherwise missed without using&nbsp;PerSpecML.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {673–675},
numpages = {3},
keywords = {Requirements Specification, Machine Learning, Software Quality},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3550355.3552421,
author = {Saini, Rijul and Mussbacher, Gunter and Guo, Jin L. C. and Kienzle, J\"{o}rg},
title = {Machine learning-based incremental learning in interactive domain modelling},
year = {2022},
isbn = {9781450394666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550355.3552421},
doi = {10.1145/3550355.3552421},
abstract = {In domain modelling, practitioners manually transform informal requirements written in natural language (problem descriptions) to more concise and analyzable domain models expressed with class diagrams. With automated domain modelling support using existing approaches, manual modifications may still be required in extracted domain models and problem descriptions to make them more accurate and concise. For example, educators teaching software engineering courses at universities usually use an incremental approach to build modelling exercises to restrict students in using intended modelling patterns. These modifications result in the evolution of domain modelling exercises over time. To assist practitioners in this evolution, a synergy between interactive support and automated domain modelling is required. In this paper, we propose a bot-assisted approach to allow practitioners perform domain modelling quickly and interactively. Furthermore, we provide an incremental learning strategy empowered by machine learning to improve the accuracy of the bot's suggestions and extracted domain models by analyzing practitioners' decisions over time. We evaluate the performance of our bot using test problem descriptions which shows that practitioners can expect to get useful support from the bot when applied to exercises of similar size and complexity, with precision, recall, and F2 scores over 85%. Finally, we evaluate our incremental learning strategy where we observe a reduction in the required manual modifications by 70% and an improvement of F2 scores of extracted domain models by 4.2% when using our proposed approach and learning strategy together.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems},
pages = {176–186},
numpages = {11},
keywords = {bot, decisions, domain models, evolution, incremental learning, machine learning (ML), natural language processing (NLP)},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3589334.3645520,
author = {Duan, Moming and Li, Qinbin and He, Bingsheng},
title = {ModelGo: A Practical Tool for Machine Learning License Analysis},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645520},
doi = {10.1145/3589334.3645520},
abstract = {Productionizing machine learning projects is inherently complex, involving a multitude of interconnected components that are assembled like LEGO blocks and evolve throughout development lifecycle. These components encompass software, databases, and models, each subject to various licenses governing their reuse and redistribution. However, existing license analysis approaches for Open Source Software (OSS) are not well-suited for this context. For instance, some projects are licensed without explicitly granting sublicensing rights, or the granted rights can be revoked, potentially exposing their derivatives to legal risks. Indeed, the analysis of licenses in machine learning projects grows significantly more intricate as it involves interactions among diverse types of licenses and licensed materials. To the best of our knowledge, no prior research has delved into the exploration of license conflicts within this domain. In this paper, we introduce ModelGo, a practical tool for auditing potential legal risks in machine learning projects to enhance compliance and fairness. With ModelGo, we present license assessment reports based on five use cases with diverse model-reusing scenarios, rendered by real-world machine learning components. Finally, we summarize the reasons behind license conflicts and provide guidelines for minimizing them. Our code is publicly available at https://github.com/Xtra-Computing/ModelGo.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1158–1169},
numpages = {12},
keywords = {ai licensing, license analysis, model mining},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1145/3511896,
author = {Liu, Hao and Guo, Qingyu and Zhu, Hengshu and Zhuang, Fuzhen and Yang, Shenwen and Dou, Dejing and Xiong, Hui},
title = {Who will Win the Data Science Competition? Insights from KDD Cup 2019 and Beyond},
year = {2022},
issue_date = {October 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {5},
issn = {1556-4681},
url = {https://doi.org/10.1145/3511896},
doi = {10.1145/3511896},
abstract = {Data science competitions are becoming increasingly popular for enterprises collecting advanced innovative solutions and allowing contestants to sharpen their data science skills. Most existing studies about data science competitions have a focus on improving task-specific data science techniques, such as algorithm design and parameter tuning. However, little effort has been made to understand the data science competition itself. To this end, in this article, we shed light on the team’s competition performance, and investigate the team’s evolving performance in the crowd-sourcing competitive innovation context. Specifically, we first acquire and construct multi-sourced datasets of various data science competitions, including the KDD Cup 2019 machine learning competition and beyond. Then, we conduct an empirical analysis to identify and quantify a rich set of features that are significantly correlated with teams’ future performances. By leveraging team’s rank as a proxy, we observe “the stronger, the stronger” rule; that is, top-ranked teams tend to keep their advantages and dominate weaker teams for the rest of the competition. Our results also confirm that teams with diversified backgrounds tend to achieve better performances. After that, we formulate the team’s future rank prediction problem and propose the Multi-Task Representation Learning&nbsp;(MTRL) framework to model both static features and dynamic features. Extensive experimental results on four real-world data science competitions demonstrate the team’s future performance can be well predicted by using MTRL. Finally, we envision our study will not only help competition organizers to understand the competition in a better way, but also provide strategic implications to contestants, such as guiding the team formation and designing the submission strategy.},
journal = {ACM Trans. Knowl. Discov. Data},
month = apr,
articleno = {98},
numpages = {24},
keywords = {Data science competition prediction, deep representation learning, multi-task learning}
}

@inproceedings{10.1145/3586183.3606731,
author = {Wu, Zhiyuan and Li, Jiening and Ma, Kevin and Kambhamettu, Hita and Head, Andrew},
title = {FFL: A Language and Live Runtime for Styling and Labeling Typeset Math Formulas},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606731},
doi = {10.1145/3586183.3606731},
abstract = {As interest grows in learning math concepts in fields like data science and machine learning, it is becoming more important to help broad audiences engage with math notation. In this paper, we explore how authoring tools can help authors better style and label formulas to support their readability. We introduce a markup language for augmenting formulas called FFL, or “Formula Formatting Language,” which aims to lower the threshold to stylize and diagram formulas. The language is designed to be concise, writable, readable, and integrable into web-based document authoring environments. It was developed with an accompanying runtime that supports live application of augmentations to formulas. Our lab study shows that FFL improves the speed and ease of editing augmentation markup, and the readability of augmentation markup compared to baseline LaTeX tools. These results clarify the role tooling can play in supporting the explanation of math notation.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {90},
numpages = {16},
keywords = {colors, formulas, interactive typesetting, labels, liveness},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3643664.3648202,
author = {Minetto Napole\~{a}o, Bianca and Sarkar, Ritika and Hall\'{e}, Sylvain and Petrillo, Fabio and Kalinowski, Marcos},
title = {Emerging Results on Automated Support for Searching and Selecting Evidence for Systematic Literature Review Updates},
year = {2024},
isbn = {9798400705670},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643664.3648202},
doi = {10.1145/3643664.3648202},
abstract = {Context: The constant growth of primary evidence and Systematic Literature Reviews (SLRs) publications in the Software Engineering (SE) field leads to the need for SLR Updates. However, searching and selecting evidence for SLR updates demands significant effort from SE researchers. Objective: We present emerging results on an automated approach to support searching and selecting studies for SLR updates in SE. Method: We developed an automated tool prototype to perform the snowballing search technique and to support the selection of relevant studies for SLR updates using Machine Learning (ML) algorithms. We evaluated our automation proposition through a small-scale evaluation with a reliable dataset from an SLR replication and its update. Results: Effectively automating snowballing-based search strategies showed feasibility with minor losses, specifically related to papers without Digital Object Identifier (DOI). The ML algorithm giving the highest performance to select studies for SLR updates was Linear Support Vector Machine with approximately 74% recall and 15% precision. The use of such algorithms with conservative thresholds to minimize the risk of missing papers can already significantly reduce evidence selection efforts. Conclusion: The preliminary results of our evaluation point in promising directions, indicating the potential of automating snowballing search efforts and of reducing the number of papers to be manually analyzed by about 2.5 times when selecting evidence for updating SLRs in SE.},
booktitle = {Proceedings of the 1st IEEE/ACM International Workshop on Methodological Issues with Empirical Studies in Software Engineering},
pages = {34–41},
numpages = {8},
keywords = {systematic review update, SLR update, searching for evidence, selecting evidence},
location = {Lisbon, Portugal},
series = {WSESE '24}
}

@inproceedings{10.1145/3583131.3590379,
author = {Applis, Leonhard and Panichella, Annibale and Marang, Ruben},
title = {Searching for Quality: Genetic Algorithms and Metamorphic Testing for Software Engineering ML},
year = {2023},
isbn = {9798400701191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583131.3590379},
doi = {10.1145/3583131.3590379},
abstract = {More machine learning (ML) models are introduced to the field of Software Engineering (SE) and reached a stage of maturity to be considered for real-world use; But the real world is complex, and testing these models lacks often in explainability, feasibility and computational capacities. Existing research introduced meta-morphic testing to gain additional insights and certainty about the model, by applying semantic-preserving changes to input-data while observing model-output. As this is currently done at random places, it can lead to potentially unrealistic datapoints and high computational costs. With this work, we introduce genetic search as an aid for metamorphic testing in SE ML. Exploiting the delta in output as a fitness function, the evolutionary intelligence optimizes the transformations to produce higher deltas with less changes. We perform a case study minimizing F1 and MRR for Code2Vec on a representative sample from java-small with both genetic and random search. Our results show that within the same amount of time, genetic search was able to achieve a decrease of 10% in F1 while random search produced 3% drop.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1490–1498},
numpages = {9},
location = {Lisbon, Portugal},
series = {GECCO '23}
}

@inproceedings{10.1145/3549206.3549283,
author = {Agrawal, Shrishtee and Singh, Abhishek and Tiwari, Abhishek and Mishra, Anushri and Tripathi, Abhinandan},
title = {A Systematic Survey on COVID 19 Detection and Diagnosis by Utilizing Deep Learning Techniques and Modalities of Radiology},
year = {2022},
isbn = {9781450396752},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549206.3549283},
doi = {10.1145/3549206.3549283},
abstract = {One of the most difficult aspects of the present COVID19 pandemic is early identification and diagnosis of COVID19, as well as exact segregation of non-COVID19 individuals at low cost and the sickness is in its early stages. Despite their widespread use in diagnostic centres, diagnostic approaches based solely on radiological imaging have flaws given the disease's novelty. As a result, to evaluate radiological pictures, healthcare practitioners and computer scientists frequently use machine learning and deep learning models. Based on a search strategy, from November 2019 to July 2020, researchers scanned the three different databases of Scopus, PubMed, and Web of Science for this study. Machine learning and deep learning are well-established artificial intelligence domains for data mining, analysis, and pattern recognition. Deep learning in which data is passed through many layers and automatically learning the composition of each layer from large dataset and it enables a new way that evaluates the complete image without human guidance to discern which insights are valuable, with applications ranging from object detection to medical image. Deep learning with CNN may have a significant effect on the automatic recognition and extraction of crucial features from X-ray and CT Scan images related to Covid19 analysis. According to the results, models based on deep learning possess amazing abilities to offer a precise and systematic system for detecting and diagnosing COVID19. In the field of COVID19 radiological imaging, deep learning software decreases false positive and false negative errors in the identification and diagnosis of the disease. It is providing a once-in-a-lifetime opportunity to provide patients with quick, inexpensive, and safe diagnostic services while also reducing the epidemic's impact on nursing and medical staff.},
booktitle = {Proceedings of the 2022 Fourteenth International Conference on Contemporary Computing},
pages = {446–452},
numpages = {7},
keywords = {Additional Key Words and Phrases— Chest X-ray, CNN, CT Scan, Covid-19, Deep Learning, Machine Learning},
location = {Noida, India},
series = {IC3-2022}
}

@inproceedings{10.1145/3653081.3653102,
author = {Yang, Shanglin and Zhu, Jialin and Wang, Jialin and Xu, Xiaohan and Shao, Zihang and Yao, Liwei and Zheng, Benchang and Huang, Hu},
title = {Retrieval-Augmented Generation with Quantized Large Language Models: A Comparative Analysis},
year = {2024},
isbn = {9798400716485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653081.3653102},
doi = {10.1145/3653081.3653102},
abstract = {Large language models have demonstrated emergent intelligence and ability to handle a wide array of tasks. However, the reliability of these models in terms of factual accuracy and timely knowledge acquisition remains a challenge. Researchers explore the implementation of retrieval-augmented generation methods, aiming to enhance the authenticity and specificity in knowledge-intensive tasks. This paper discusses the practical application in industrial settings, particularly in assisting design personnel with navigating complex standards and quality manuals. Utilizing an open-source model with 6 billion parameters, the study employs quantization technology for local deployment, addressing computational challenges. The retrieval-augmented generation framework is analyzed, emphasizing the integration of document parsing, vector databases, and text embedding models. Experimental results compare models at different quantization levels, revealing trade-offs between response time, model size, and performance metrics. The findings suggest that 4-bit integer quantization is optimal for standard document retrieval and question-answering tasks, highlighting practical considerations for CPU inference. The paper concludes with insights into hyper-parameter tuning, model comparisons, and future optimizations for enhanced performance in edge device deployments of large language models.},
booktitle = {Proceedings of the 2023 5th International Conference on Internet of Things, Automation and Artificial Intelligence},
pages = {120–124},
numpages = {5},
location = {Nanchang, China},
series = {IoTAAI '23}
}

@article{10.1145/3639279,
author = {Dargahi Nobari, Arash and Rafiei, Davood},
title = {DTT: An Example-Driven Tabular Transformer for Joinability by Leveraging Large Language Models},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
url = {https://doi.org/10.1145/3639279},
doi = {10.1145/3639279},
abstract = {Many organizations rely on data from government and third-party sources, and those sources rarely follow the same data formatting. This introduces challenges in integrating data from multiple sources or aligning external sources with internal databases. Commercial database systems do not offer adequate support for integrating data from heterogeneous sources, and manual integration is both time-consuming and inefficient. State-of-the-art data integration approaches that rely on similarity functions and textual transformations often fail to handle challenging cases where multiple mappings are required, or the mappings go beyond simple textual transformations.In this paper, we study the potentials of deep neural models for transforming tables for joinability. In particular, we cast the problem as a prediction task and develop a framework that leverages large deep-learning language models to transform tabular data from a source formatting to a desired target representation. Our framework can efficiently learn the patterns for mapping a source formatting into an expected target using just a few examples, which can then be used for tasks such as table joining, filling in missing values, and error detection. Compared to state-of-the-art mapping and joining approaches, our framework delivers noticeably more accurate and scalable performance on both real-world and synthetic datasets. Our experimental evaluation also shows that the performance of the proposed framework using our fine-tuned model is at par or better than large language models such as GPT-3, despite the significant difference in size, and that using large language models within our framework improves their performance.},
journal = {Proc. ACM Manag. Data},
month = mar,
articleno = {24},
numpages = {24},
keywords = {data integration, language models, table transformation, unequal join}
}

@inproceedings{10.1145/3663529.3663841,
author = {Roy, Devjeet and Zhang, Xuchao and Bhave, Rashi and Bansal, Chetan and Las-Casas, Pedro and Fonseca, Rodrigo and Rajmohan, Saravan},
title = {Exploring LLM-Based Agents for Root Cause Analysis},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663841},
doi = {10.1145/3663529.3663841},
abstract = {The growing complexity of cloud based software systems has resulted in incident management becoming an integral part of the software development lifecycle. Root cause analysis (RCA), a critical part of the incident management process, is a demanding task for on-call engineers, requiring deep domain knowledge and extensive experience with a team’s specific services. Automation of RCA can result in significant savings of time, and ease the burden of incident management on on-call engineers. Recently, researchers have utilized Large Language Models (LLMs) to perform RCA, and have demonstrated promising results. However, these approaches are not able to dynamically collect additional diagnostic information such as incident related logs, metrics or databases, severely restricting their ability to diagnose root causes. In this work, we explore the use of LLM based agents for RCA to address this limitation. We present a thorough empirical evaluation of a ReAct agent equipped with retrieval tools, on an out-of-distribution dataset of production incidents collected at a large IT corporation. Results show that ReAct performs competitively with strong retrieval and reasoning baselines, but with highly increased factual accuracy. We then extend this evaluation by incorporating discussions associated with incident reports as additional inputs for the models, which surprisingly does not yield significant performance improvements. Lastly, we conduct a case study with a team at Microsoft to equip the ReAct agent with tools that give it access to external diagnostic services that are used by the team for manual RCA. Our results show how agents can overcome the limitations of prior work, and practical considerations for implementing such a system in practice.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {208–219},
numpages = {12},
keywords = {AIOps, Cloud Computing, Incident Management, Root Cause Analysis},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@article{10.1145/3506696,
author = {Lin, Zehao and Li, Guodun and Zhang, Jingfeng and Deng, Yue and Zeng, Xiangji and Zhang, Yin and Wan, Yao},
title = {XCode: Towards Cross-Language Code Representation with Large-Scale Pre-Training},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3506696},
doi = {10.1145/3506696},
abstract = {Source code representation learning is the basis of applying artificial intelligence to many software engineering tasks such as code clone detection, algorithm classification, and code summarization. Recently, many works have tried to improve the performance of source code representation from various perspectives, e.g., introducing the structural information of programs into latent representation. However, when dealing with rapidly expanded unlabeled cross-language source code datasets from the Internet, there are still two issues. Firstly, deep learning models for many code-specific tasks still suffer from the lack of high-quality labels. Secondly, the structural differences among programming languages make it more difficult to process multiple languages in a single neural architecture.To address these issues, in this article, we propose a novel Cross-language Code representation with a large-scale pre-training (XCode) method. Concretely, we propose to use several abstract syntax trees and ELMo-enhanced variational autoencoders to obtain multiple pre-trained source code language models trained on about 1.5 million code snippets. To fully utilize the knowledge across programming languages, we further propose a Shared Encoder-Decoder (SED) architecture which uses the multi-teacher single-student method to transfer knowledge from the aforementioned pre-trained models to the distilled SED. The pre-trained models and SED will cooperate to better represent the source code. For evaluation, we examine our approach on three typical downstream cross-language tasks, i.e., source code translation, code clone detection, and code-to-code search, on a real-world dataset composed of programming exercises with multiple solutions. Experimental results demonstrate the effectiveness of our proposed approach on cross-language code representations. Meanwhile, our approach performs significantly better than several code representation baselines on different downstream tasks in terms of multiple automatic evaluation metrics.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {52},
numpages = {44},
keywords = {Deep learning, neural networks, code representation, cross-language, pre-training}
}

@article{10.1145/3699711,
author = {Shiri Harzevili, Nima and Boaye Belle, Alvine and Wang, Junjie and Wang, Song and Jiang, Zhen Ming (Jack) and Nagappan, Nachiappan},
title = {A Systematic Literature Review on Automated Software Vulnerability Detection Using Machine Learning},
year = {2024},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3699711},
doi = {10.1145/3699711},
abstract = {In recent years, numerous Machine Learning (ML) models, including Deep Learning (DL) and classic ML models, have been developed to detect software vulnerabilities. However, there is a notable lack of comprehensive and systematic surveys that summarize, classify, and analyze the applications of these ML models in software vulnerability detection. This absence may lead to critical research areas being overlooked or under-represented, resulting in a skewed understanding of the current state of the art in software vulnerability detection. To close this gap, we propose a comprehensive and systematic literature review that characterizes the different properties of ML-based software vulnerability detection systems using six major Research Questions (RQs).Using a custom web scraper, our systematic approach involves extracting a set of studies from four widely used online digital libraries: ACM Digital Library, IEEE Xplore, ScienceDirect, and Google Scholar. We manually analyzed the extracted studies to filter out irrelevant work unrelated to software vulnerability detection, followed by creating taxonomies and addressing RQs. Our analysis indicates a significant upward trend in applying ML techniques for software vulnerability detection over the past few years, with many studies published in recent years. Prominent conference venues include the International Conference on Software Engineering (ICSE), the International Symposium on Software Reliability Engineering (ISSRE), the Mining Software Repositories (MSR) conference, and the ACM International Conference on the Foundations of Software Engineering (FSE), whereas Information and Software Technology (IST), Computers &amp; Security (C&amp;S), and Journal of Systems and Software (JSS) are the leading journal venues.Our results reveal that 39.1% of the subject studies use hybrid sources, whereas 37.6% of the subject studies utilize benchmark data for software vulnerability detection. Code-based data are the most commonly used data type among subject studies, with source code being the predominant subtype. Graph-based and token-based input representations are the most popular techniques, accounting for 57.2% and 24.6% of the subject studies, respectively. Among the input embedding techniques, graph embedding and token vector embedding are the most frequently used techniques, accounting for 32.6% and 29.7% of the subject studies. Additionally, 88.4% of the subject studies use DL models, with recurrent neural networks and graph neural networks being the most popular subcategories, whereas only 7.2% use classic ML models. Among the vulnerability types covered by the subject studies, CWE-119, CWE-20, and CWE-190 are the most frequent ones. In terms of tools used for software vulnerability detection, Keras with TensorFlow backend and PyTorch libraries are the most frequently used model-building tools, accounting for 42 studies for each. In addition, Joern is the most popular tool used for code representation, accounting for 24 studies.Finally, we summarize the challenges and future directions in the context of software vulnerability detection, providing valuable insights for researchers and practitioners in the field.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {55},
numpages = {36},
keywords = {Source code, software security, software vulnerability detection, software bug detection, machine learning, deep learning}
}

@inproceedings{10.1145/3637528.3672194,
author = {Lin, Xihong},
title = {Empower an End-to-end Scalable and Interpretable Data Science Ecosystem using Statistics, AI and Domain Science},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672194},
doi = {10.1145/3637528.3672194},
abstract = {The data science ecosystem encompasses data fairness, statistical, ML and AI methods and tools, interpretable data analysis and results, and trustworthy decision-making. Rapid advancements in AI have revolutionized data utilization and enabled machines to learn from data more effectively. Statistics, as the science of learning from data while accounting for uncertainty, plays a pivotal role in addressing complex real-world problems and facilitating trustworthy decision-making. In this talk, I will discuss the challenges and opportunities involved in building an end-to-end scalable and interpretable data science ecosystem using the analysis of whole genome sequencing studies and biobanks that integrates statistics, ML/AI, and genomic and health science as an example. Biobanks collect whole genome data, electronic health records and epidemiological data. I will illustrate key points using the analysis of multi-ancestry whole genome sequencing studies and biobanks by discussing a few scalable and interpretable statistical and ML/AI methods, tools and data science resources.Specifically, first, data fairness and diversity is a critical pillar of a trustworthy data science ecosystem. About 85+% of genome wide association study samples in the last 15 years are European, resulting in disparity in genetic research. I will discuss the community effort on improving diversity in genetic studies in the last 10 years. I will present trans-ancestry polygenic risk scores (PRS) using millions of common genetic variants across the genome by leveraging large GWAS sample sizes of European and smaller sample sizes of under-represented populations for predicting disease risk using transfer learning and genetic association summary statistics. The performance of deep learning methods for PRS will also be discussed. Second, scalability in cloud platforms is critical for large scale affordable analysis for multi-ancestry biobanks and whole genome studies. I will discuss improving scalability in cloud-computing using interpretable sparsity via FastSparseGRM.To build an interpretable and powerful end-to-end ecosystem of rare variant analysis of large scale whole genome sequencing studies and biobanks, I will first introduce FAVOR, a multi-faceted variant functional annotation database and portal of all possible 9 billions of variants across the whole genome. I will discuss FAVOR-GPT, a LLM interface of the FAVOR functional annotation database to improve user experience for navigating FAVOR and performing variant functional annotation query and variant functional summary statistics calculations. I will also discuss FAVORannotator which can be used to functionally annotate any whole genome sequencing studies. I will also discuss STAAR and STAAR and STAARpipeline, the WGS rare variant analysis pipeline that boosts the power of WGS rare variant association analysis by dynamically incorporating multi-faceted variant functional annotations. Extension of incorporating single-cell data in WGS analysis will also be discussed. I will also discuss ensemble methods that improve the power of rare variant association tests.Cloud-deployment of these resources and tools in several ecosystems will be presented, such as RAP for the UK biobank, AnVIL for the NHGRI Genome Sequencing Program and All of Us, and BioData Catalyst for the NHLBI Trans-omics Precision Medine Program (TOPMed). This talk aims to ignite proactive and thought-provoking discussions, foster collaboration, and cultivate open-minded approaches to advance scientific discovery.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3–4},
numpages = {2},
keywords = {ai, annotation, biobanks, electronic health records, ensemble methods, gpt, integrative analysis, interpretability, machine learning, scalability, sparsity, statistics, summary statistics, whole genome sequencing studies},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3597503.3639079,
author = {Ma, Yimeng and Huang, Yu and Leach, Kevin},
title = {Breaking the Flow: A Study of Interruptions During Software Engineering Activities},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639079},
doi = {10.1145/3597503.3639079},
abstract = {In software engineering, interruptions during tasks can have significant implications for productivity and well-being. While previous studies have investigated the effect of interruptions on productivity, to the best of our knowledge, no prior work has yet distinguished the effect of different types of interruptions on software engineering activities.This study explores the impact of interruptions on software engineering tasks, analyzing in-person and on-screen interruptions with different levels of urgency and dominance. Participants completed code writing, code comprehension, and code review tasks while experiencing interruptions. We collect physiological data using the Empatica EmbracePlus wristband and self-perceived evaluations through surveys. Results show that on-screen interruptions with high dominance of requester significantly increase time spent on code comprehension. In-person and on-screen interruptions combined significantly affect the time spent on code review, with varied effects based on specific interruption combinations. Both interruption type and task significantly influence stress measures, with code comprehension and review tasks associated with lower stress measures compared to code writing. Interestingly, in-person interruptions present a positive impact on physiological measures, indicating reduced stress measures. However, participants' self-perceived stress scores do not align with physiological data, with higher stress reported during in-person interruptions despite lower physiological stress measures. These findings shed light on and emphasize the potential importance of considering the complex relationship between interruptions, objective measures, and subjective experiences in software development. We discuss insights that we hope can inform interruption management and implications on stress among software engineers. (ChatGPT was used to revise and shorten paragraphs in this manuscript.)},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {185},
numpages = {12},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@article{10.1109/TASLP.2024.3477291,
author = {Delgado, Pablo M. and Herre, J\"{u}rgen},
title = {Towards Improved Objective Perceptual Audio Quality Assessment - Part 1: A Novel Data-Driven Cognitive Model},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3477291},
doi = {10.1109/TASLP.2024.3477291},
abstract = {Efficient audioquality assessment is vital for streamlining audio codec development. Objective assessment tools have been developed over time to algorithmically predict quality ratings from subjective assessments, the gold standard for quality judgment. Many of these tools use perceptual auditory models to extract audio features that are mapped to a basic audio quality score prediction using machine learning algorithms and subjective scores as training data. However, existing tools struggle with generalization in quality prediction, especially when faced with unknown signal and distortion types. This is particularly evident in the presence of signals coded using non-waveform-preserving parametric techniques. Addressing these challenges, this two-part work proposes extensions to the Perceptual Evaluation of Audio Quality (PEAQ - ITU-R BS.1387-1) recommendation. Part 1 focuses on increasing generalization, while Part 2 targets accurate spatial audio quality measurement in audio coding. To enhance prediction generalization, this paper (Part 1) introduces a novel machine learning approach that uses subjective data to model cognitive aspects of audio quality perception. The proposed method models the perceived severity of audible distortions by adaptively weighting different distortion metrics. The weights are determined using an interaction cost function that captures relationships between distortion salience and cognitive effects. Compared to other machine learning methods and established tools, the proposed architecture achieves higher prediction accuracy on large databases of previously unseen subjective quality scores. The perceptually-motivated model offers a more manageable alternative to general-purpose machine learning algorithms, allowing potential extensions and improvements to multi-dimensional quality measurement without complete retraining.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {4661–4675},
numpages = {15}
}

@article{10.1145/3591867,
author = {Hutiri, Wiebke (Toussaint) and Ding, Aaron Yi and Kawsar, Fahim and Mathur, Akhil},
title = {Tiny, Always-on, and Fragile: Bias Propagation through Design Choices in On-device Machine Learning Workflows},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {6},
issn = {1049-331X},
url = {https://doi.org/10.1145/3591867},
doi = {10.1145/3591867},
abstract = {Billions of distributed, heterogeneous, and resource constrained IoT devices deploy on-device machine learning (ML) for private, fast, and offline inference on personal data. On-device ML is highly context dependent and sensitive to user, usage, hardware, and environment attributes. This sensitivity and the propensity toward bias in ML makes it important to study bias in on-device settings. Our study is one of the first investigations of bias in this emerging domain and lays important foundations for building fairer on-device ML. We apply a software engineering lens, investigating the propagation of bias through design choices in on-device ML workflows. We first identify reliability bias as a source of unfairness and propose a measure to quantify it. We then conduct empirical experiments for a keyword spotting task to show how complex and interacting technical design choices amplify and propagate reliability bias. Our results validate that design choices made during model training, like the sample rate and input feature type, and choices made to optimize models, like light-weight architectures, the pruning learning rate, and pruning sparsity, can result in disparate predictive performance across male and female groups. Based on our findings, we suggest low effort strategies for engineers to mitigate bias in on-device ML.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {155},
numpages = {37},
keywords = {Bias, on-device machine learning, embedded machine learning, design choices, fairness, audio keyword spotting, personal data}
}

@inproceedings{10.1145/3656650.3656676,
author = {Bisante, Alba and Datla, Venkata Srikanth Varma and Panizzi, Emanuele and Trasciatti, Gabriella and Zeppieri, Stefano},
title = {Enhancing Interface Design with AI: An Exploratory Study on a ChatGPT-4-Based Tool for Cognitive Walkthrough Inspired Evaluations},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3656676},
doi = {10.1145/3656650.3656676},
abstract = {This paper introduces CWGPT, a ChatGPT-4-based tool designed for Cognitive Walkthrough (CW) inspired evaluations of web interfaces. The primary goal is to assist users, particularly students and inexperienced designers, in evaluating web interfaces. Our tool, operating as a conversational agent, provides detailed evaluations of a user-specified task by intelligently guessing the subtasks and actions required to accomplish them, answering the standard CW questions, and providing helpful feedback and practical suggestions to improve the usability of the analyzed interface. For our study, we selected a group of web applications designed by students from a Web and Software Architecture course. We compare the outcome of the CWs we executed on ten web apps against the corresponding CWGPT analyses. We then describe the study we conducted involving five author-students to assess the tool’s efficacy in helping them recognize and solve usability issues. In addition to introducing a novel adaptation of ChatGPT, the outcomes of the described experience underscore the promising potential of AI in usability evaluations.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {41},
numpages = {5},
keywords = {AI, ChatGPT, Cognitive Walkthrough, GPT, HCI},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}

@inproceedings{10.1145/3510455.3512779,
author = {Dey, Sangeeta and Lee, Seok-Won},
title = {Are we training with the right data? evaluating collective confidence in training data using Dempster Shafer theory},
year = {2022},
isbn = {9781450392242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510455.3512779},
doi = {10.1145/3510455.3512779},
abstract = {The latest trend of incorporating various data-centric machine learning (ML) models in software-intensive systems has posed new challenges in the quality assurance practice of software engineering, especially in a high-risk environment. ML experts are now focusing on explaining ML models to assure the safe behavior of ML-based systems. However, not enough attention has been paid to explain the inherent uncertainty of the training data. The current practice of ML-based system engineering lacks transparency in the systematic fitness assessment process of the training data before engaging in the rigorous ML model training. We propose a method of assessing the collective confidence in the quality of a training dataset by using Dempster Shafer theory and its modified combination rule (Yager's rule). With the example of training datasets for pedestrian detection of autonomous vehicles, we demonstrate how the proposed approach can be used by the stakeholders with diverse expertise to combine their beliefs in the quality arguments and evidences about the data. Our results open up a scope of future research on data requirements engineering that can facilitate evidence-based data assurance for ML-based safety-critical systems.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {11–15},
numpages = {5},
keywords = {Dempster Shafer theory, data uncertainty, machine learning, safety},
location = {Pittsburgh, Pennsylvania},
series = {ICSE-NIER '22}
}

@inproceedings{10.1145/3622780.3623648,
author = {Kuramitsu, Kimio and Obara, Yui and Sato, Miyu and Obara, Momoka},
title = {KOGI: A Seamless Integration of ChatGPT into Jupyter Environments for Programming Education},
year = {2023},
isbn = {9798400703904},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622780.3623648},
doi = {10.1145/3622780.3623648},
abstract = {The impact of ChatGPT has brought both anxiety and anticipation to schools and universities. Exploring a positive method to improve programming skills with ChatGPT is a new and pressing challenge.  
In pursuit of this goal, we have developed KOGI, a learning support system that integrates ChatGPT into the Jupyter environment. This paper demonstrates how KOGI enables students to receive timely advice from ChatGPT in response to errors and other questions they encounter.  

We immediately introduced KOGI in our two introductory courses: Algorithms and Data Science. The introduction of KOGI resulted in a significant decrease in the number of unresolved student errors. In addition, we report on student trends observed in the classroom regarding the type and frequency of help requested. Although our findings are preliminary, they are informative for programming instructors interested in using ChatGPT.},
booktitle = {Proceedings of the 2023 ACM SIGPLAN International Symposium on SPLASH-E},
pages = {50–59},
numpages = {10},
keywords = {ChatGPT, LLM, classroom experience, programming education},
location = {Cascais, Portugal},
series = {SPLASH-E 2023}
}

@article{10.1145/3492762,
author = {Sobhy, Dalia and Minku, Leandro and Bahsoon, Rami and Kazman, Rick},
title = {Continuous and Proactive Software Architecture Evaluation: An IoT Case},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3492762},
doi = {10.1145/3492762},
abstract = {Design-time evaluation is essential to build the initial software architecture to be deployed. However, experts’ assumptions made at design-time are unlikely to remain true indefinitely in systems that are characterized by scale, hyperconnectivity, dynamism, and uncertainty in operations (e.g. IoT). Therefore, experts’ design-time decisions can be challenged at run-time. A continuous architecture evaluation that systematically assesses and intertwines design-time and run-time decisions is thus necessary. This paper proposes the first proactive approach to continuous architecture evaluation of the system leveraging the support of simulation. The approach evaluates software architectures by not only tracking their performance over time, but also forecasting their likely future performance through machine learning of simulated instances of the architecture. This enables architects to make cost-effective informed decisions on potential changes to the architecture. We perform an IoT case study to show how machine learning on simulated instances of architecture can fundamentally guide the continuous evaluation process and influence the outcome of architecture decisions. A series of experiments is conducted to demonstrate the applicability and effectiveness of the approach. We also provide the architect with recommendations on how to best benefit from the approach through choice of learners and input parameters, grounded on experimentation and evidence.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
articleno = {46},
numpages = {54},
keywords = {Continuous evaluation, software architecture evaluation, time series forecasting, IoT}
}

@inproceedings{10.1145/3644815.3644965,
author = {Barreto Simedo Pacheco, Lorena and Rahman, Musfiqur and Rabbi, Fazle and Fathollahzadeh, Pouya and Abdellatif, Ahmad and Shihab, Emad and Chen, Tse-Hsun (Peter) and Yang, Jinqiu and Zou, Ying},
title = {DVC in Open Source ML-development: The Action and the Reaction},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644965},
doi = {10.1145/3644815.3644965},
abstract = {Machine Learning (ML) systems are gaining popularity, reshaping various domains ranging from customer services to software engineering. The effectiveness of ML systems is dependent on the quality of their training data. Therefore, practitioners invest substantial time experimenting with different data, parameters, and models to guarantee the quality of the end system. Prior work highlighted unique challenges of developing ML systems, particularly concerning versioning data and models. Recently, various tools such as DVC and MLFlow have emerged to aid developers in the storage and tracking of data. Despite their growing popularity, very little is known about their usage patterns and impact on open-source software (OSS) systems. To address this gap, we conducted an empirical study on 56 GitHub OSS projects that use DVC to understand the DVC usage pattern and the impact of using DVC on the software development process. We found that Versioning and tracking is the most adopted DVC feature, being utilized by all 56 projects and being the only adopted feature in 85.7% of them. Furthermore, we found that DVC has a significant impact on the software development process indicators such as the number of created pull requests (PRs), and the number of bug-fix commits. For instance, our findings showed that DVC causes a peak in the number of commits and PRs at the moment of the adoption, followed by a long-term decrease. We believe that our findings can assist practitioners in tailoring tools to better meet user requirements and help organizations realize potential outcomes of adopting such tools.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {75–80},
numpages = {6},
keywords = {empirical software engineering, data version control, software evolution, SE4AI},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3639233.3639339,
author = {Rillera, Ryan Tabayoyong and Alejandro, Leonard},
title = {Web Based Signature Authenticity Application},
year = {2024},
isbn = {9798400709227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639233.3639339},
doi = {10.1145/3639233.3639339},
abstract = {Our signatures are very important to our daily lives, as they anchor the agreement to a legally binding, enforceable, and actionable reality. The old-style purpose of a signature is to permanently affix to a document a person's uniquely personal, undeniable self-identification as physical evidence of that person's personal witness and certification of the content of all, or a specified part, of the document. The purpose of the proposed capstone project is to determine the authenticity of a signature in an important document, namely, certificates, checks, legal documents, letters, and receipts. Automatically identifies a signature without human intervention. The overall objective of the proposed capstone project is to have immediate and accurate results of an investigation whether the signature is legitimate or counterfeit. The conclusion of the study shows that image recognition is the core development of the project, with the use of Artificial Intelligence, feeding the database with images will have a higher accuracy rate in authenticating signatures.},
booktitle = {Proceedings of the 2023 7th International Conference on Natural Language Processing and Information Retrieval},
pages = {299–303},
numpages = {5},
keywords = {Bio-metrics, Front-end, Mobile Browser, Stroke Analysis},
location = {Seoul, Republic of Korea},
series = {NLPIR '23}
}

@inproceedings{10.1145/3611643.3616354,
author = {Zou, Deqing and Feng, Siyue and Wu, Yueming and Suo, Wenqi and Jin, Hai},
title = {Tritor: Detecting Semantic Code Clones by Building Social Network-Based Triads Model},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616354},
doi = {10.1145/3611643.3616354},
abstract = {Code clone detection refers to finding the functional similarities between two code fragments, which is becoming increasingly important with the evolution of software engineering. It is reasonable because code cloning can increase maintenance costs and even cause the propagation of vulnerabilities, which can have a negative impact on software security. Numbers of code clone detection methods have been proposed, including tree-based methods that are capable of detecting semantic code clones. However, since tree structure is complex, these methods are difficult to apply to large-scale clone detection. In this paper, we propose a scalable semantic code clone detector based on semantically enhanced abstract syntax tree. Specifically, we add the control flow and data flow details into the original tree and regard the enhanced tree as a social network. Then we build a social network-based triads model to collect the similarity features between the two methods by analyzing different types of triads within the network. After obtaining all features, we use them to train a machine learning-based code clone detector (i.e., Tritor). Our comparative experimental results show that Tritor is superior to SourcererCC, RtvNN, Deckard, ASTNN, TBCNN, CDLH, and SCDetector, are equally good with DeepSim and FCCA. As for scalability, Tritor is about 39 times faster than another current state-of-the-art tree-based code clone detector ASTNN.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {771–783},
numpages = {13},
keywords = {Abstract Syntax Tree, Semantic Clones, Social Network, Triads},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3524501.3527605,
author = {Winchester, Hana and Boyd, Alicia E. and Johnson, Brittany},
title = {An exploration of intersectionality in software development and use},
year = {2022},
isbn = {9781450392945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524501.3527605},
doi = {10.1145/3524501.3527605},
abstract = {The growing ubiquity of machine learning technologies has led to concern and concentrated efforts at improving data-centric research and practice. While much work has been done on addressing equity concerns with respect to unary identities (e.g., race or gender), little to no work in Software Engineering has studied intersectionality to determine how we can provide equitable outcomes for complex, overlapping social identities in data-driven tech. To this end, we designed a survey to learn the landscape of intersectional identities in tech, where these populations contribute data, and how marginalized populations feel about the impact technology has on their day to day lives. Our data thus far, collected from 12 respondents and composed mostly of white and male identities, further highlights the lack of representation in modern data sets and need for contributions that explicitly explore how to support data-driven research and development.},
booktitle = {Proceedings of the Third Workshop on Gender Equality, Diversity, and Inclusion in Software Engineering},
pages = {67–70},
numpages = {4},
location = {Pittsburgh, Pennsylvania},
series = {GE@ICSE '22}
}

@article{10.1145/3533274.3533277,
author = {Zhao, Xiangyu},
title = {Adaptive and automated deep recommender systems},
year = {2022},
issue_date = {Spring 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2022},
number = {Spring},
issn = {1931-1745},
url = {https://doi.org/10.1145/3533274.3533277},
doi = {10.1145/3533274.3533277},
abstract = {Dr. Xiangyu Zhao is an assistant professor of the school of data science at City University of Hong Kong (CityU). Prior to CityU, he completed his PhD (2021) at MSU under the advisory of Dr. Jiliang Tang, MS (2017) at USTC and BEng (2014) at UESTC. His current research interests include data mining and machine learning, especially (1) Personalization, Recommender System, Online Advertising, Search Engine, and Information Retrieval; (2) Urban Computing, Smart City, and GeoAI; (3) Deep Reinforcement Learning, AutoML, and Multimodal ML; and (4) AI for Social Computing, Finance, Education, Ecosystem, and Healthcare. He has published more than 30 papers in top conferences (e.g., KDD, WWW, AAAI, SIGIR, ICDE, CIKM, ICDM, WSDM, RecSys, ICLR) and journals (e.g., TOIS, SIGKDD, SIGWeb, EPL, APS). His research received ICDM'21 Best-ranked Papers, Global Top 100 Chinese New Stars in AI, CCF-Tencent Open Fund, Criteo Research Award, Bytedance Research Award and MSU Dissertation Fellowship. He serves as top data science conference (senior) program committee members and session chairs (e.g., KDD, AAAI, IJCAI, ICML, ICLR, CIKM), and journal reviewers (e.g., TKDE, TKDD, TOIS, CSUR). He serves as the organizers of DRL4KDD@KDD'19, DRL4IR@SIGIR'20, 2nd DRL4KD@WWW'21, 2nd DRL4IR@SIGIR'21, and a lead tutor at WWW'21/22 and IJCAI'21. He also serves as the founding academic committee members of MLNLP, the largest AI community in China with 800,000 members/followers. The models and algorithms from his research have been launched in the online system of many companies.},
journal = {SIGWEB Newsl.},
month = may,
articleno = {3},
numpages = {4}
}

@inproceedings{10.1145/3626246.3654680,
author = {Luo, Xuan and Pei, Jian},
title = {Applications and Computation of the Shapley Value in Databases and Machine Learning},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3654680},
doi = {10.1145/3626246.3654680},
abstract = {Recently, the Shapley value, a concept rooted in cooperative game theory, has found more and more applications in databases and machine learning. Due to its combinatoric nature, the computation of the Shapley value is #P-hard. To address this challenge, numerous studies are actively engaged in developing efficient computation methods or exploring alternative solutions in specific application contexts. Applications of the Shapley value in databases and machine learning as well as fast computation or approximation of the Shapley value in those applications are becoming a new research frontier in the database community. This tutorial presents a comprehensive and systematic overview of Shapley value applications and computation within both database and machine learning domains. We survey the existing methods from a unique perspective that diverges from the current literature. Unlike most reviews, which mainly focus on applications, our approach focuses on the underlying algorithmic mechanisms and application specific assumptions in these methods. This approach allows us to highlight the similarities and differences among the various Shapley value applications and computation techniques more effectively. Our tutorial categorizes these methods based on their intrinsic processes, cutting across different applications. The tutorial begins with an introduction to the Shapley value and its diverse applications in databases and machine learning. Subsequently, it delves into the computational challenges of the Shapley value, presents cutting-edge solutions for its efficient computation, and explores alternative solutions.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {630–635},
numpages = {6},
keywords = {Shapley value, cooperative game theory, data market, databases, machine learning},
location = {Santiago AA, Chile},
series = {SIGMOD '24}
}

@inproceedings{10.1145/3643667.3648223,
author = {Guo, Xiaoyu and Zhao, Jianjun and Zhao, Pengzhan},
title = {On Repairing Quantum Programs Using ChatGPT},
year = {2024},
isbn = {9798400705700},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643667.3648223},
doi = {10.1145/3643667.3648223},
abstract = {Automated Program Repair (APR) is a vital area in software engineering that generates automatic patches for vulnerable programs. While numerous techniques have been proposed for repairing classical programs, quantum programming lacks a comparable automated repair technique. In this initial exploration, we investigate the use of ChatGPT for quantum program repair and evaluate its performance on Bugs4Q, a benchmark suite of quantum program bugs. Our findings demonstrate the feasibility of employing ChatGPT for quantum program repair. Specifically, we assess ChatGPT's ability to address bugs within the Bugs4Q benchmark, revealing its success in repairing 29 out of 38 bugs. This research represents a promising step towards automating the repair process for quantum programs.},
booktitle = {Proceedings of the 5th ACM/IEEE International Workshop on Quantum Software Engineering},
pages = {9–16},
numpages = {8},
keywords = {automatic program repair, quantum programming, debugging},
location = {Lisbon, Portugal},
series = {Q-SE 2024}
}

@inproceedings{10.1145/3688268.3688271,
author = {Chaiya, Supap and Songpan, Wararat},
title = {Prediction of Undergraduate Success Through Machine Learning Models},
year = {2024},
isbn = {9798400718038},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3688268.3688271},
doi = {10.1145/3688268.3688271},
abstract = {The aim of this study is to investigate the factors that affect the graduation rates of undergraduates at Khon Kaen University. The focus is on students who were admitted through the direct admission test in 2018 and graduated in 2022. The university has recently implemented a new direct admission testing system, which has led to the need for a passing level score for university entrance. To address this issue, the study uses a management-by-fact approach, utilizing data from admissions and registration databases that are analyzed using machine learning models. The research categorizes the influencing factors into three main groups: 1) personal factors, including gender, family income, and parents' occupations; 2) educational factors, such as total admission scores, first-year grade point averages (GPA) for both semesters, and English admission scores; and 3) university service-related factors, including teacher and overall class evaluation scores by students. The study found that the GPAs of the first and second semesters in the first year (GPA1 and GPA2, respectively) had a significant impact on the graduation rates of students. The comparison of ten models showed that logistic regression was the most effective, achieving 88.05% accuracy in predicting outcomes. This finding highlights the potential of machine learning in educational settings, offering valuable insights for strategic planning and interventions aimed at improving graduation rates.},
booktitle = {Proceedings of the 2024 12th International Conference on Computer and Communications Management},
pages = {12–18},
numpages = {7},
keywords = {logistic regression model, predictive model, strategic planning, success factors},
location = {
},
series = {ICCCM '24}
}

@article{10.1145/3528667,
author = {Wang, Hui and Zhou, Kun and Zhao, Xin and Wang, Jingyuan and Wen, Ji-Rong},
title = {Curriculum Pre-training Heterogeneous Subgraph Transformer for Top-N Recommendation},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/3528667},
doi = {10.1145/3528667},
abstract = {To characterize complex and heterogeneous side information in recommender systems, the heterogeneous information network (HIN) has shown superior performance and attracted much research attention. In HIN, the rich entities, relations, and paths can be utilized to model the correlations of users and items; such a task setting is often called HIN-based recommendation. Although HIN provides a general approach to modeling rich side information, it lacks special consideration on the goal of the recommendation task. The aggregated context from the heterogeneous graph is likely to incorporate irrelevant information, and the learned representations are not specifically optimized according to the recommendation task. Therefore, there is a need to rethink how to leverage the useful information from HIN to accomplish the recommendation task. To address the above issues, we propose a Curriculum pre-training based HEterogeneous Subgraph Transformer (called CHEST) with new data characterization, representation model, and learning algorithm. Specifically, we consider extracting useful information from HIN to compose the interaction-specific heterogeneous subgraph, containing highly relevant context information for recommendation. Then, we capture the rich semantics (e.g., graph structure and path semantics) within the subgraph via a heterogeneous subgraph Transformer, where we encode the subgraph into multi-slot sequence representations. Besides, we design a curriculum pre-training strategy to provide an elementary-to-advanced learning process. The elementary course focuses on capturing local context information within the subgraph, and the advanced course aims to learn global context information. In this way, we gradually capture useful semantic information from HIN for modeling user-item interactions. Extensive experiments conducted on four real-world datasets demonstrate the superiority of our proposed method over a number of competitive baselines, especially when only limited training data is available.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
articleno = {19},
numpages = {28},
keywords = {Curriculum pre-training, heterogeneous information network, recommender systems}
}

@article{10.1145/3636509,
author = {Wang, Angelina and Kapoor, Sayash and Barocas, Solon and Narayanan, Arvind},
title = {Against Predictive Optimization: On the Legitimacy of Decision-making Algorithms That Optimize Predictive Accuracy},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3636509},
doi = {10.1145/3636509},
abstract = {We formalize predictive optimization, a category of decision-making algorithms that use machine learning (ML) to predict future outcomes of interest about individuals. For example, pre-trial risk prediction algorithms such as COMPAS use ML to predict whether an individual will re-offend in the future. Our thesis is that predictive optimization raises a distinctive and serious set of normative concerns that cause it to fail on its own terms. To test this, we review 387 reports, articles, and web pages from academia, industry, non-profits, governments, and data science contests, and we find many real-world examples of predictive optimization. We select eight particularly consequential examples as case studies. Simultaneously, we develop a set of normative and technical critiques that challenge the claims made by the developers of these applications—in particular, claims of increased accuracy, efficiency, and fairness. Our key finding is that these critiques apply to each of the applications, are not easily evaded by redesigning the systems, and thus challenge whether these applications should be deployed. We argue that the burden of evidence for justifying why the deployment of predictive optimization is not harmful should rest with the developers of the tools. Based on our analysis, we provide a rubric of critical questions that can be used to deliberate or contest specific predictive optimization applications.1},
journal = {ACM J. Responsib. Comput.},
month = mar,
articleno = {9},
numpages = {45},
keywords = {Automated decision-making, validity, machine learning, optimization}
}

@inproceedings{10.5555/3511065.3511077,
author = {Washizaki, Hironori and Khomh, Foutse and Gu\'{e}h\'{e}neuc, Yann-Ga\"{e}l and Takeuchi, Hironori and Okuda, Satoshi and Natori, Naotake and Shioura, Naohisa},
title = {Software engineering patterns for machine learning applications (SEP4MLA): part 2},
year = {2022},
isbn = {9781941652169},
publisher = {The Hillside Group},
address = {USA},
abstract = {Practitioners and researchers study best practices to develop and maintain ML application systems and software to address quality and constraint problems. Such practices are often formalized as software patterns. We discovered software-engineering design patterns for machine-learning applications by doing a thorough search of the literature available on the subject. Among the ML patterns found, we describe three ML patterns in the standard pattern format so that practitioners can (re)use them in their contexts: "Different Workloads in Different Computing Environments", "Encapsulate ML Models Within Rule-base Safeguards", and "Data Flows Up, Model Flows Down"},
booktitle = {Proceedings of the 27th Conference on Pattern Languages of Programs},
articleno = {9},
numpages = {10},
keywords = {machine learning patterns},
location = {Virtual Event},
series = {PLoP '20}
}

@inproceedings{10.1145/3558489.3559070,
author = {Al-Sabbagh, Khaled and Staron, Miroslaw and Hebig, Regina},
title = {Predicting build outcomes in continuous integration using textual analysis of source code commits},
year = {2022},
isbn = {9781450398602},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3558489.3559070},
doi = {10.1145/3558489.3559070},
abstract = {Machine learning has been increasingly used to solve various software engineering tasks. One example of its usage is to predict the outcome of builds in continuous integration, where a classifier is built to predict whether new code commits will successfully compile.  
The aim of this study is to investigate the effectiveness of fifteen software metrics in building a classifier for build outcome prediction. Particularly, we implemented an experiment wherein we compared the effectiveness of a line-level metric and fourteen other traditional software metrics on 49,040 build records that belong to 117 Java projects. We achieved an average precision of 91% and recall of 80% when using the line-level metric for training, compared to 90% precision and 76% recall for the next best traditional software metric. In contrast, using file-level metrics was found to yield a higher predictive quality (average MCC for the best software metric= 68%) than the line-level metric (average MCC= 16%) for the failed builds. We conclude that file-level metrics are better predictors of build outcomes for the failed builds, whereas the line-level metric is a slightly better predictor of passed builds.},
booktitle = {Proceedings of the 18th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {42–51},
numpages = {10},
keywords = {Build Prediction, Continuous Integration, Textual Analysis},
location = {Singapore, Singapore},
series = {PROMISE 2022}
}

@inproceedings{10.1145/3611643.3616320,
author = {Vegas, Sira and Elbaum, Sebastian},
title = {Pitfalls in Experiments with DNN4SE: An Analysis of the State of the Practice},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616320},
doi = {10.1145/3611643.3616320},
abstract = {Software engineering (SE) techniques are increasingly relying on deep learning approaches to support many SE tasks, from bug triaging to code generation. To assess the efficacy of such techniques researchers typically perform controlled experiments. Conducting these experiments, however, is particularly challenging given the complexity of the space of variables involved, from specialized and intricate architectures and algorithms to a large number of training hyper-parameters and choices of evolving datasets, all compounded by how rapidly the machine learning technology is advancing, and the inherent sources of randomness in the training process. In this work we conduct a mapping study, examining 194 experiments with techniques that rely on deep neural networks (DNNs) appearing in 55 papers published in premier SE venues to provide a characterization of the state of the practice, pinpointing experiments’ common trends and pitfalls. Our study reveals that most of the experiments, including those that have received ACM artifact badges, have fundamental limitations that raise doubts about the reliability of their findings. More specifically, we find: 1) weak analyses to determine that there is a true relationship between independent and dependent variables (87% of the experiments), 2) limited control over the space of DNN relevant variables, which can render a relationship between dependent variables and treatments that may not be causal but rather correlational (100% of the experiments), and 3) lack of specificity in terms of what are the DNN variables and their values utilized in the experiments (86% of the experiments) to define the treatments being applied, which makes it unclear whether the techniques designed are the ones being assessed, or how the sources of extraneous variation are controlled. We provide some practical recommendations to address these limitations.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {528–540},
numpages = {13},
keywords = {deep learning, machine learning for software engineering, software engineering experimentation},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@article{10.1145/3568429,
author = {Akgun, Ibrahim Umit and Aydin, Ali Selman and Burford, Andrew and McNeill, Michael and Arkhangelskiy, Michael and Zadok, Erez},
title = {Improving Storage Systems Using Machine Learning},
year = {2023},
issue_date = {February 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1553-3077},
url = {https://doi.org/10.1145/3568429},
doi = {10.1145/3568429},
abstract = {Operating systems include many heuristic algorithms designed to improve overall storage performance and throughput. Because such heuristics cannot work well for all conditions and workloads, system designers resorted to exposing numerous tunable parameters to users—thus burdening users with continually optimizing their own storage systems and applications. Storage systems are usually responsible for most latency in I/O-heavy applications, so even a small latency improvement can be significant. Machine learning (ML) techniques promise to learn patterns, generalize from them, and enable optimal solutions that adapt to changing workloads. We propose that ML solutions become a first-class component in OSs and replace manual heuristics to optimize storage systems dynamically. In this article, we describe our proposed ML architecture, called KML. We developed a prototype KML architecture and applied it to two case studies: optimizing readahead and NFS read-size values. Our experiments show that KML consumes less than 4 KB of dynamic kernel memory, has a CPU overhead smaller than 0.2%, and yet can learn patterns and improve I/O throughput by as much as 2.3\texttimes{} and 15\texttimes{} for two case studies—even for complex, never-seen-before, concurrently running mixed workloads on different storage devices.},
journal = {ACM Trans. Storage},
month = jan,
articleno = {9},
numpages = {30},
keywords = {Operating systems, storage systems, Machine Learning, storage performance optimization}
}

@inproceedings{10.1145/3590837.3590919,
author = {Chauhan, Aman Singh and Reddy, Basireddy Chinna Ankalugari Vamsidhar and Arora, Mamta and Pandey, Mrinal},
title = {NIFTY Banking Sector Closing Price Prediction Using Deep Learning},
year = {2023},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590837.3590919},
doi = {10.1145/3590837.3590919},
abstract = {In this time of data science and machine learning, predicting different feature values of the stock market is getting more popular among young people and people who are connected to technology. For our study we used 5 years of real data from Indian Bank Nifty and applied artificial neural network techniques LSTM, Bi-LSTM, GRU, and standard ANN. As our data contained the null values, we preprocessed the data. We also visualize different aspects of our dataset to have deep knowledge of data before applying any algorithm on it. The results which we got from different algorithms were good and loss factors were also very low. We predicted the close price of stocks which was our target and then also compared with the actual values and found that they are very similar to actual values. The system achieves overall success which was expected. And finally we observed that our model was predicting daily stock price closing price well and is very useful for financial and technical industries.},
booktitle = {Proceedings of the 4th International Conference on Information Management &amp; Machine Intelligence},
articleno = {82},
numpages = {6},
location = {Jaipur, India},
series = {ICIMMI '22}
}

@inproceedings{10.1109/ICSE48619.2023.00206,
author = {Jiang, Wenxin and Synovic, Nicholas and Hyatt, Matt and Schorlemmer, Taylor R. and Sethi, Rohan and Lu, Yung-Hsiang and Thiruvathukal, George K. and Davis, James C.},
title = {An Empirical Study of Pre-Trained Model Reuse in the Hugging Face Deep Learning Model Registry},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00206},
doi = {10.1109/ICSE48619.2023.00206},
abstract = {Deep Neural Networks (DNNs) are being adopted as components in software systems. Creating and specializing DNNs from scratch has grown increasingly difficult as state-of-the-art architectures grow more complex. Following the path of traditional software engineering, machine learning engineers have begun to reuse large-scale pre-trained models (PTMs) and fine-tune these models for downstream tasks. Prior works have studied reuse practices for traditional software packages to guide software engineers towards better package maintenance and dependency management. We lack a similar foundation of knowledge to guide behaviors in pre-trained model ecosystems.In this work, we present the first empirical investigation of PTM reuse. We interviewed 12 practitioners from the most popular PTM ecosystem, Hugging Face, to learn the practices and challenges of PTM reuse. From this data, we model the decision-making process for PTM reuse. Based on the identified practices, we describe useful attributes for model reuse, including provenance, reproducibility, and portability. Three challenges for PTM reuse are missing attributes, discrepancies between claimed and actual performance, and model risks. We substantiate these identified challenges with systematic measurements in the Hugging Face ecosystem. Our work informs future directions on optimizing deep learning ecosystems by automated measuring useful attributes and potential attacks, and envision future research on infrastructure and standardization for model registries.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {2463–2475},
numpages = {13},
keywords = {software reuse, empirical software engineering, machine learning, deep learning, software supply chain, engineering decision making, cybersecurity, trust},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@article{10.1145/3555768,
author = {Candello, Heloisa and Pinhanez, Claudio and Muller, Michael and Wessel, Mairieli},
title = {Unveiling Practices of Customer Service Content Curators of Conversational Agents},
year = {2022},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {CSCW2},
url = {https://doi.org/10.1145/3555768},
doi = {10.1145/3555768},
abstract = {Conversational interfaces require two types of curation: data curation by data science workers and content curation by domain experts. Recent years have seen the possibilities for content curators to instruct conversational machines in the customer service domain (i.e., Machine Teaching). The activities of curating specialized data are time-consuming. These activities have a learning curve for the domain expert, and they rely on collaborators beyond the domain experts, including product owners, technology expert curators, management, marketing, and communication employees. However, recent research has looked at making this task easier for domain experts with a lack of knowledge in the Machine Learning system, and few papers have investigated the work practices and collaborations involved in this role. This paper aims to fill this gap, presenting and unveiling practices extracted from eleven semi-structured interviews and four design workshops with experts in Banking, Technical support, Humans Resources, Telecommunications, and Automotive sectors. First, we investigate the articulation work of the content curators and tech curators in training conversational machines. Second, we inspect the curatorial and collaboration strategies they use, which are not afforded by current conversational platforms. Third, we draw the design implications and possibilities to support individual and collaboration curating practices. We reflect on how those practices rely on self and collaboration with others for curation, trust, and data tracking and ownership.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {348},
numpages = {33},
keywords = {articulation of work, content curators, conversational systems, work practices}
}

@inproceedings{10.1109/ASE56229.2023.00033,
author = {Li, Jingyang and Li, Guoqiang},
title = {HOBAT: Batch Verification for Homogeneous Structural Neural Networks},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00033},
doi = {10.1109/ASE56229.2023.00033},
abstract = {The rapid development of deep learning has significantly transformed the ecology of the software engineering field. As new data continues to grow and evolve at an explosive rate, the challenge of iteratively updating software built on neural networks has become a critical issue. While the continuous learning paradigm enables networks to incorporate new data and update accordingly without losing previous memories, resulting in a batch of new networks as candidates for software updating, these approaches merely select from these networks by empirically testing their accuracy; they lack formal guarantees for such a batch of networks, especially in the presence of adversarial samples. Existing verification techniques, based on constraint solving, interval propagation, and linear approximation, provide formal guarantees but are designed to verify the properties of individual networks rather than a batch of networks. To address this issue, we analyze the batch verification problem corresponding to several non-traditional machine learning paradigms and further propose a framework named HOBAT (BATch verification for HOmogeneous structural neural networks) to enhance batch verification under reasonable assumptions about the representation of homogeneous structure neural networks, increasing scalability in practical applications. Our method involves abstracting the neurons at the same position in a batch of networks into a single neuron, followed by an iterative refinement process on the abstracted neuron to restore the precision until the desired properties for verification are met. Our method is orthogonal to boundary propagation verification on a single neural network. To assess our methodology, we integrate it with boundary propagation verification and observe significant improvements compared to the vanilla approach. Our experiments demonstrate the enormous potential for verifying large batches of networks in the era of big data.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1276–1287},
numpages = {12},
keywords = {batch verification, neural networks, homogeneous structure, abstraction},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3526073.3527584,
author = {Kolltveit, Ask Berstad and Li, Jingyue},
title = {Operationalizing machine learning models: a systematic literature review},
year = {2023},
isbn = {9781450393195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526073.3527584},
doi = {10.1145/3526073.3527584},
abstract = {Deploying machine learning (ML) models to production with the same level of rigor and automation as traditional software systems has shown itself to be a non-trivial task, requiring extra care and infrastructure to deal with the additional challenges. Although many studies focus on adapting ML software engineering (SE) approaches and techniques, few studies have summarized the status and challenges of operationalizing ML models. Model operationalization encompasses all steps after model training and evaluation, including packaging the model in a format appropriate for deployment, publishing to a model registry or storage, integrating the model into a broader software system, serving, and monitoring. This study is the first systematic literature review investigating the techniques, tools, and infrastructures to operationalize ML models. After reviewing 24 primary studies, the results show that there are a number of tools for most use cases to operationalize ML models and cloud deployment in particular. The review also revealed several research opportunities, such as dynamic model-switching, continuous model-monitoring, and efficient edge ML deployments.},
booktitle = {Proceedings of the 1st Workshop on Software Engineering for Responsible AI},
pages = {1–8},
numpages = {8},
keywords = {MLOps, deployment, machine learning, operationalization, systematic literature review},
location = {Pittsburgh, Pennsylvania},
series = {SE4RAI '22}
}

@inproceedings{10.1145/3534678.3539379,
author = {Liu, Chengchang and Bi, Shuxian and Luo, Luo and Lui, John C.S.},
title = {Partial-Quasi-Newton Methods: Efficient Algorithms for Minimax Optimization Problems with Unbalanced Dimensionality},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539379},
doi = {10.1145/3534678.3539379},
abstract = {This paper studies the strongly-convex-strongly-concave minimax optimization with unbalanced dimensionality. Such problems contain several popular applications in data science such as few shot learning and fairness-aware machine learning task. The design of conventional iterative algorithm for minimax optimization typically focuses on reducing the total number of oracle calls, which ignores the unbalanced computational cost for accessing the information from two different variables in minimax. We propose a novel second-order optimization algorithm, called Partial-Quasi-Newton (PQN) method, which takes the advantage of unbalanced structure in the problem to establish the Hessian estimate efficiently. We theoretically prove our PQN method converges to the saddle point faster than existing minimax optimization algorithms. The numerical experiments on real-world applications show the proposed PQN performs significantly better than the state-of-the-art methods.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1031–1041},
numpages = {11},
keywords = {fairness, few-shot learning, minimax optimization, quasi-newton},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3580305.3599803,
author = {Elmougy, Youssef and Liu, Ling},
title = {Demystifying Fraudulent Transactions and Illicit Nodes in the Bitcoin Network for Financial Forensics},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599803},
doi = {10.1145/3580305.3599803},
abstract = {Blockchain provides the unique and accountable channel for financial forensics by mining its open and immutable transaction data. A recent surge has been witnessed by training machine learning models with cryptocurrency transaction data for anomaly detection, such as money laundering and other fraudulent activities. This paper presents a holistic applied data science approach to fraud detection in the Bitcoin network with two original contributions. First, we contribute the Elliptic++dataset, which extends the Elliptic transaction dataset to include over 822k Bitcoin wallet addresses (nodes), each with 56 features, and 1.27M temporal interactions. This enables both the detection of fraudulent transactions and the detection of illicit addresses (actors) in the Bitcoin network by leveraging four types of graph data: (i) the transaction-to-transaction graph, representing the money flow in the Bitcoin network, (ii) the address-to-address interaction graph, capturing the types of transaction flows between Bitcoin addresses, (iii) the address-transaction graph, representing the bi-directional money flow between addresses and transactions (BTC flow from input address to one or more transactions and BTC flow from a transaction to one or more output addresses), and (iv) the user entity graph, capturing clusters of Bitcoin addresses representing unique Bitcoin users. Second, we perform fraud detection tasks on all four graphs by using diverse machine learning algorithms. We show that adding enhanced features from the address-to-address and the address-transaction graphs not only assists in effectively detecting both illicit transactions and illicit addresses, but also assists in gaining in-depth understanding of the root cause of money laundering vulnerabilities in cryptocurrency transactions and the strategies for fraud detection and prevention. The Elliptic++ dataset is released at https://www.github.com/git-disl/EllipticPlusPlus.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3979–3990},
numpages = {12},
keywords = {anomaly detection, blockchain, financial forensics},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3597503.3623313,
author = {Chen, Liuqing and Chen, Yunnong and Xiao, Shuhong and Song, Yaxuan and Sun, Lingyun and Zhen, Yankun and Zhou, Tingting and Chang, Yanfang},
title = {EGFE: End-to-end Grouping of Fragmented Elements in UI Designs with Multimodal Learning},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623313},
doi = {10.1145/3597503.3623313},
abstract = {When translating UI design prototypes to code in industry, automatically generating code from design prototypes can expedite the development of applications and GUI iterations. However, in design prototypes without strict design specifications, UI components may be composed of fragmented elements. Grouping these fragmented elements can greatly improve the readability and maintainability of the generated code. Current methods employ a two-stage strategy that introduces hand-crafted rules to group fragmented elements. Unfortunately, the performance of these methods is not satisfying due to visually overlapped and tiny UI elements. In this study, we propose EGFE, a novel method for automatically End-to-end Grouping Fragmented Elements via UI sequence prediction. To facilitate the UI understanding, we innovatively construct a Transformer encoder to model the relationship between the UI elements with multi-modal representation learning. The evaluation on a dataset of 4606 UI prototypes collected from professional UI designers shows that our method outperforms the state-of-the-art baselines in the precision (by 29.75%), recall (by 31.07%), and F1-score (by 30.39%) at edit distance threshold of 4. In addition, we conduct an empirical study to assess the improvement of the generated front-end code. The results demonstrate the effectiveness of our method on a real software engineering application. Our end-to-end fragmented elements grouping method creates opportunities for improving UI-related software engineering tasks.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {11},
numpages = {12},
keywords = {UI elements grouping, fragmented elements grouping, end-to-end pipeline, multi-modal transformer},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3522664.3528601,
author = {Paleyes, Andrei and Cabrera, Christian and Lawrence, Neil D.},
title = {An empirical evaluation of flow based programming in the machine learning deployment context},
year = {2022},
isbn = {9781450392754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3522664.3528601},
doi = {10.1145/3522664.3528601},
abstract = {As use of data driven technologies spreads, software engineers are more often faced with the task of solving a business problem using data-driven methods such as machine learning (ML) algorithms. Deployment of ML within large software systems brings new challenges that are not addressed by standard engineering practices and as a result businesses observe high rate of ML deployment project failures. Data Oriented Architecture (DOA) is an emerging approach that can support data scientists and software developers when addressing such challenges. However, there is a lack of clarity about how DOA systems should be implemented in practice. This paper proposes to consider Flow-Based Programming (FBP) as a paradigm for creating DOA applications. We empirically evaluate FBP in the context of ML deployment on four applications that represent typical data science projects. We use Service Oriented Architecture (SOA) as a baseline for comparison. Evaluation is done with respect to different application domains, ML deployment stages, and code quality metrics. Results reveal that FBP is a suitable paradigm for data collection and data science tasks, and is able to simplify data collection and discovery when compared with SOA. We discuss the advantages of FBP as well as the gaps that need to be addressed to increase FBP adoption as a standard design paradigm for DOA.},
booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
pages = {54–64},
numpages = {11},
keywords = {flow-based programming, machine learning, service-oriented architecture, software engineering},
location = {Pittsburgh, Pennsylvania},
series = {CAIN '22}
}

@inproceedings{10.1145/3594315.3594365,
author = {Zhang, Deqing and Zhang, Cuoling},
title = {Research on Text Sentiment Analysis of Movie Reviews Based on BERT Model},
year = {2023},
isbn = {9781450399029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594315.3594365},
doi = {10.1145/3594315.3594365},
abstract = {With the rapid development of machine learning technology, more and more industries pay attention to the research and application of data science. In recent years, many industries such as e-commerce, service, movie and television, news and so on have begun to attach great importance to and deeply analyze the sentimental tendency of user comments in the network. Sentiment analysis is an important branch of NLP. This paper takes the movie reviews dataset published by Stanford as the research object, and uses the bert-base-uncased pre-training model in BERT to study the text sentiment classification of the dataset. In the fine tune phase of the model, Adam and CrossEntropyloss are selected as the optimizer and loss function, and at the same time, the influence of parameters learning_rate and batch_size on the accuracy of text classification is studied. The experimental results show that learning_rate and batch_size has a certain impact on classification accuracy. When learning_rate=2e-5, the classification accuracy of the model on this dataset can reach up to 87%, achieving a relatively ideal classification effect.},
booktitle = {Proceedings of the 2023 9th International Conference on Computing and Artificial Intelligence},
pages = {511–514},
numpages = {4},
location = {Tianjin, China},
series = {ICCAI '23}
}

@proceedings{10.1145/3620666,
title = {ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
abstract = {Welcome to the third volume of ASPLOS'24: the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. This document is mostly dedicated to the 2024 fall cycle but also provides some statistics summarizing all three cycles.We introduced several notable changes to ASPLOS this year, most of which were discussed in our previous messages from program chairs in Volume 1 and 2, including: (1) significantly increasing the program committee size to over 220 members (more than twice the size of last year); (2) foregoing synchronous program committee (PC) meetings and instead making all decisions online; (3) overhauling the review assignment process; (4) developing an automated submission format violation identifier script that uncovers, e.g., disallowed vertical space manipulations that "squeeze" space; (5) introducing the new ASPLOS role of Program Vice Chairs to cope with the increased number of submissions and the added load caused by foregoing synchronous program committee; and (6) characterizing a systematic problem that ASPLOS is facing in reviewing quantum computing submissions, describing how we addressed it and highlighting how we believe that it should be handled in the future.Assuming readers have read our previous messages, here, we will only describe differences between the current cycle and the previous ones. These include: (1) Finally unifying submission and acceptance paper formatting instructions (forgoing the `jpaper' class) to rid authors of accepted papers from the need to reformat; (2) Describing the methodology we employed to select best papers, which we believe ensures quality and hope will persist; and (3) Reporting the ethical incidents we encountered and how we handled them. In the final, fourth volume, when the outcome of the ASPLOS'24 fall major revisions will become known, we plan to conduct a broader analysis of all the data we have gathered throughout the year.Following are some key statistics of the fall cycle: 340 submissions were finalized (43% more than last year's fall count and 17% less than our summer cycle) of which 111 are related to accelerators/FPGAs/GPUs, 105 to machine learning, 54 to security, 50 to datacenter/cloud and 50 to storage/memory; 183 (54%) submissions were promoted to the second review round; 39 (11.5%) papers were accepted (of which 19 were awarded artifact evaluation badges); 33 (9.7%) submissions were allowed to submit major revisions and are currently under review (these will be addressed in the fourth volume of ASPLOS'24 and will be presented in ASPLOS'25 if accepted); 1,368 reviews were uploaded; and 4,949 comments were generated during online discussions, of which 4,070 were dedicated to the submissions that made it to the second review round.This year, in the submission form, we asked authors to specify which of the three ASPLOS research areas are related to their submitted work. Analyzing this data revealed that 80%, 39%, and 29% of the submissions are categorized by their authors as related to architecture, operating systems, and programming languages, respectively, generating the highest difference we have observed across the cycles between architecture and the other two. About 46% of the fall submissions are "interdisciplinary," namely, were associated with two or more of the three areas.Overall, throughout all the ASPLOS'24 cycles, we received 922 submissions, constituting a 1.54x increase compared to last year. Our reviewers submitted a total of 3,634 reviews containing more than 2.6 million words, and we also generated 12,655 online comments consisting of nearly 1.2 million words. As planned, PC members submitted an average of 15.7 reviews and a median of 15, and external review committee (ERC) members submitted an average of 4.7 and a median of 5.We accepted 170 papers thus far, written by 1100 authors, leading to an 18.4% acceptance rate, with the aforementioned 33 major revisions still under review. Assuming that the revision acceptance rate will be similar to that of previous cycles, we estimate that ASPLOS'24 will accept nearly 200 (!) papers, namely, 21%–22% of the submissions.The ASPLOS'24 program consists of 193 papers: the 170 papers we accepted thus far and, in addition, 23 major revisions from the fall cycle of ASPLOS'23, which were re-reviewed and accepted. The full details are available in the PDF of the front matter.},
location = {La Jolla, CA, USA}
}

@inproceedings{10.1145/3703187.3703270,
author = {Deng, Ruihai and Wu, Aihua},
title = {MANN: Multi-head Attention Network Model for Estimating Cardinality in Multi-model Databases},
year = {2024},
isbn = {9798400707254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703187.3703270},
doi = {10.1145/3703187.3703270},
abstract = {In database query optimization, cardinality estimation is the key to determine the efficiency of query planning. Traditional methods often encounter accuracy challenges when processing complex queries, prompting researchers to explore machine learning techniques to enhance estimation quality. Numerous studies have shown that machine learning methods can effectively solve the problem of cardinality estimation, but in the field of multi model databases, research on machine learning based cardinality estimation is still in its infancy. This article focuses on the problem of query cardinality estimation on multi model databases and applies a multi head attention mechanism to construct a neural network model, namely Multi head Attention Neural Network (MANN), which can effectively capture complex relationships between tables or predicates, thereby improving estimation accuracy. MANN decomposes query statements into multiple sub query sets based on table names, and normalizes the query features within each set. It uses multi head attention mechanism to train, recognize, and learn the correlations between tables or predicates. This model supports SQL and Arango Query Language (AQL) queries and is suitable for multi model databases such as ArangoDB. Experiments were conducted on the synthetic dataset UniBench and the real dataset IMDb, and the results showed that MANN exhibited higher accuracy and efficiency in handling cardinality estimation problems compared to existing techniques. Its performance was particularly outstanding in handling high predicate relevance queries, with the median error 39% better than existing state-of-the-art methods.},
booktitle = {Proceedings of the 2024 7th International Conference on Computer Information Science and Artificial Intelligence},
pages = {490–497},
numpages = {8},
keywords = {Cardinality estimation, Machine learning, Multi-head attention, Multi-model database},
location = {
},
series = {CISAI '24}
}

@article{10.1145/3563332,
author = {Muduli, Sujit Kumar and Roy, Subhajit},
title = {Satisfiability modulo fuzzing: a synergistic combination of SMT solving and fuzzing},
year = {2022},
issue_date = {October 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3563332},
doi = {10.1145/3563332},
abstract = {Programming languages and software engineering tools routinely encounter components that are difficult to reason on via formal techniques or whose formal semantics are not even available—third-party libraries, inline assembly code, SIMD instructions, system calls, calls to machine learning models, etc. However, often access to these components is available as input-output oracles—interfaces are available to query these components on certain inputs to receive the respective outputs. We refer to such functions as closed-box functions. Regular SMT solvers are unable to handle such closed-box functions. We propose Sundefineddhak, a solver for SMT theories modulo closed-box functions. Our core idea is to use a synergistic combination of a fuzzer to reason on closed-box functions and an SMT engine to solve the constraints pertaining to the SMT theories. The fuzz and the SMT engines attempt to converge to a model by exchanging a rich set of interface constraints that are relevant and interpretable by them. Our implementation, Sundefineddhak, demonstrates a significant advantage over the only other solver that is capable of handling such closed-box constraints: Sundefineddhak solves 36.45% more benchmarks than the best-performing mode of this state-of-the-art solver and has 5.72x better PAR-2 score; on the benchmarks that are solved by both tools, Sundefineddhak is (on an average) 14.62x faster.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {169},
numpages = {28},
keywords = {Closed-Box Function, Conflict-Driven Fuzz Loop, Fuzzing, SMT}
}

@inproceedings{10.1145/3540250.3549127,
author = {Robe, Peter and Kuttal, Sandeep K. and AuBuchon, Jake and Hart, Jacob},
title = {Pair programming conversations with agents vs. developers: challenges and opportunities for SE community},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3549127},
doi = {10.1145/3540250.3549127},
abstract = {Recent research has shown feasibility of an interactive pair-programming conversational agent, but implementing such an agent poses three challenges: a lack of benchmark datasets, absence of software engineering specific labels, and the need to understand developer conversations. To address these challenges, we conducted a Wizard of Oz study with 14 participants pair programming with a simulated agent and collected 4,443 developer-agent utterances. Based on this dataset, we created 26 software engineering labels using an open coding process to develop a hierarchical classification scheme. To understand labeled developer-agent conversations, we compared the accuracy of three state-of-the-art transformer-based language models, BERT, GPT-2, and XLNet, which performed interchangeably. In order to begin creating a developer-agent dataset, researchers and practitioners need to conduct resource intensive Wizard of Oz studies. Presently, there exists vast amounts of developer-developer conversations on video hosting websites. To investigate the feasibility of using developer-developer conversations, we labeled a publicly available developer-developer dataset (3,436 utterances) with our hierarchical classification scheme and found that a BERT model trained on developer-developer data performed ~10% worse than the BERT trained on developer-agent data, but when using transfer-learning, accuracy improved. Finally, our qualitative analysis revealed that developer-developer conversations are more implicit, neutral, and opinionated than developer-agent conversations. Our results have implications for software engineering researchers and practitioners developing conversational agents.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {319–331},
numpages = {13},
keywords = {Classification, Conversational agents, Datasets, Labels, Language models, Pair programming conversations, Pair programming questions},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3522664.3528594,
author = {Meesters, Marcel and Heck, Petra and Serebrenik, Alexander},
title = {What is an AI engineer? an empirical analysis of job ads in The Netherlands},
year = {2022},
isbn = {9781450392754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3522664.3528594},
doi = {10.1145/3522664.3528594},
abstract = {Recently, the job market for Artificial Intelligence (AI) engineers has exploded. Since the role of AI engineer is relatively new, limited research has been done on the requirements as set by the industry. Moreover, the definition of an AI engineer is less established than for a data scientist or a software engineer. In this study we explore, based on job ads, the requirements from the job market for the position of AI engineer in The Netherlands. We retrieved job ad data between April 2018 and April 2021 from a large job ad database, Jobfeed from TextKernel. The job ads were selected with a process similar to the selection of primary studies in a literature review. We characterize the 367 resulting job ads based on meta-data such as publication date, industry/sector, educational background and job titles. To answer our research questions we have further coded 125 job ads manually.The job tasks of AI engineers are concentrated in five categories: business understanding, data engineering, modeling, software development and operations engineering. Companies ask for AI engineers with different profiles: 1) data science engineer with focus on modeling, 2) AI software engineer with focus on software development, 3) generalist AI engineer with focus on both models and software. Furthermore, we present the tools and technologies mentioned in the selected job ads, and the soft skills.Our research helps to understand the expectations companies have for professionals building AI-enabled systems. Understanding these expectations is crucial both for prospective AI engineers and educational institutions in charge of training those prospective engineers. Our research also helps to better define the profession of AI engineering. We do this by proposing an extended AI engineering life-cycle that includes a business understanding phase.},
booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
pages = {136–144},
numpages = {9},
keywords = {AI engineer, ML engineer, data science, job ad, job market, software engineering},
location = {Pittsburgh, Pennsylvania},
series = {CAIN '22}
}

@inproceedings{10.1145/3549843.3549859,
author = {Lee, Angela S.H and Bengeri, Atul and Kan, Chong Chin},
title = {Artificial Intelligence Adoption in QSR Industry},
year = {2022},
isbn = {9781450397216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549843.3549859},
doi = {10.1145/3549843.3549859},
abstract = {According to research conducted by Allied Market Research (Kale and Deshmukh, 2020), the Quick-service restaurant (QSR) industry has been enjoying significant growth over the last several years and the trend is expected to continue at least over the next five years. This is due to the agility of most QSR brands in adapting to consumer needs, quality food products and service innovation. Offering the convenience of brands reach for their consumers such as a restaurant within the reach of the customer, as well as providing online ordering and food delivery convenience.The convenience of the omnichannel digital services offered by typical QSR restaurant brands to their customer provides convenience for service delivery and at the same time provides an opportunity to collect, collate, check, consume and analyse the data to examine, explore and provide hindsight, insight and foresight for the QSR industry to be ahead of the competition.Not only are these digital customer channels a great way of providing a better customer experience, but they also help QSR operators in capturing massive data such as sales transactions, customer details, product performance, and daypart (breakfast, lunch and dinner) sales insights.With the ability to analyse and perform analytics on the data and from a data strategy perspective, it is paramount to have a robust big data platform, data warehouse and ability to consolidate data from all the IT systems. This is to enable the development of BI/dashboards to provide better business insights, such as real-time and daypart product sales. Data could also be used to develop new digital products for more positive customer engagements such as upselling and loyalty programmes or for implementing of “smart kitchen” that is able to connect various datasets for maximum kitchen efficiency and cost optimisation.Due to a lack of data science approach and machine learning capability, most QSR brands are missing this sales uplifting opportunity.To develop an effective A.I. and machine learning in the QSR business, there is a need to evaluate and select the best machine learning techniques to address the business challenges.Our objective is to explore and recommend the various machine learning techniques that can be applied to the QSR industry to gain insights and provide the necessary analysis and analytics to ensure quality service and also address changing business challenges in the competitive and ever-changing market by deploying various machine learning models for prediction and pattern analysis through classification and association approaches.},
booktitle = {Proceedings of the 2022 6th International Conference on E-Education, E-Business and E-Technology},
pages = {102–110},
numpages = {9},
keywords = {Association, Big Data, Classification, Data Analytics, Data Management, Data Warehousing, Information systems applications Data Mining, Machine Learning, Prediction},
location = {Beijing, China},
series = {ICEBT '22}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00077,
author = {Ding, Zishuo},
title = {Towards Utilizing Natural Language Processing Techniques to Assist in Software Engineering Tasks},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00077},
doi = {10.1109/ICSE-Companion58688.2023.00077},
abstract = {Machine learning-based approaches have been widely used to address natural language processing (NLP) problems. Considering the similarity between natural language text and source code, researchers have been working on applying techniques from NLP to deal with code. On the other hand, source code and natural language are by nature different. For example, code is highly structured and executable. Thus, directly applying the NLP techniques may not be optimal, and how to effectively optimize these NLP techniques to adapt to software engineering (SE) tasks remains a challenge. Therefore, to tackle the challenge, in this dissertation, we focus on two research directions: 1) distributed code representations, and 2) logging statements, which are two important intersections between the natural language and source code. For distributed code representations, we first discuss the limitations of existing code embedding techniques, and then, we propose a novel approach to learn more generalizable code embeddings in a task-agnostic manner. For logging statements, we first propose an automated deep learning-based approach to automatically generate accurate logging texts by translating the related source code into short textual descriptions. Then, we make the first attempt to comprehensively study the temporal relations between logging and its corresponding source code, which is later used to detect issues in logging statements. We anticipate that our study can provide useful suggestions and support to developers in utilizing NLP techniques to assist in SE tasks.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {286–290},
numpages = {5},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3597503.3639075,
author = {Serafini, Raphael and Otto, Clemens and Horstmann, Stefan Albert and Naiakshina, Alena},
title = {ChatGPT-Resistant Screening Instrument for Identifying Non-Programmers},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639075},
doi = {10.1145/3597503.3639075},
abstract = {To ensure the validity of software engineering and IT security studies with professional programmers, it is essential to identify participants without programming skills. Existing screening questions are efficient, cheating robust, and effectively differentiate programmers from non-programmers. However, the release of ChatGPT raises concerns about their continued effectiveness in identifying non-programmers. In a simulated attack, we showed that Chat-GPT can easily solve existing screening questions. Therefore, we designed new ChatGPT-resistant screening questions using visual concepts and code comprehension tasks. We evaluated 28 screening questions in an online study with 121 participants involving programmers and non-programmers. Our results showed that questions using visualizations of well-known programming concepts performed best in differentiating between programmers and non-programmers. Participants prompted to use ChatGPT struggled to solve the tasks. They considered ChatGPT ineffective and changed their strategy after a few screening questions. In total, we present six ChatGPT-resistant screening questions that effectively identify non-programmers. We provide recommendations on setting up a ChatGPT-resistant screening instrument that takes less than three minutes to complete by excluding 99.47% of non-programmers while including 94.83% of programmers.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {181},
numpages = {13},
keywords = {chatgpt, programmer screening, developer study, study protection},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3626772.3657877,
author = {Leventidis, Aristotelis and Christensen, Martin Pek\'{a}r and Lissandrini, Matteo and Di Rocco, Laura and Hose, Katja and Miller, Ren\'{e}e J.},
title = {A Large Scale Test Corpus for Semantic Table Search},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657877},
doi = {10.1145/3626772.3657877},
abstract = {Table search aims to answer a query with a ranked list of tables. Unfortunately, current test corpora have focused mostly on needle-in-the-haystack tasks, where only a few tables are expected to exactly match the query intent. Instead, table search tasks often arise in response to the need for retrieving new datasets or augmenting existing ones, e.g., for data augmentation within data science or machine learning pipelines. Existing table repositories and benchmarks are limited in their ability to test retrieval methods for table search tasks. Thus, to close this gap, we introduce a novel dataset for query-by-example Semantic Table Search. This novel dataset consists of two snapshots of the large-scale Wikipedia tables collection from 2013 and 2019 with two important additions: (1) a page and topic aware ground truth relevance judgment and (2) a large-scale DBpedia entity linking annotation. Moreover, we generate a novel set of entity-centric queries that allows testing existing methods under a novel search scenario: semantic exploratory search. The resulting resource consists of 9,296 novel queries, 610,553 query-table relevance annotations, and 238,038 entity-linked tables from the 2013 snapshot. Similarly, on the 2019 snapshot, the resource consists of 2,560 queries, 958,214 relevance annotations, and 457,714 total tables. This makes our resource the largest annotated table-search corpus to date (97 times more queries and 956 times more annotated tables than any existing benchmark). We perform a user study among domain experts and prove that these annotators agree with the automatically generated relevance annotations. As a result, we can re-evaluate some basic assumptions behind existing table search approaches identifying their shortcomings along with promising novel research directions.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1142–1151},
numpages = {10},
keywords = {benchmark, query-by-example, semantic search, table search},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3607720.3607777,
author = {El Ansari, Rachid and El Bouhadioui, Mohamed and Aboutafail, Moulay othman and Mejjad, Nezha and Jamil, Hicham and Jamal, Elhassan and Rissouni, Youssef and Zouiten, Mohammed and Boutracheh, Hicham and Moumen, Aniss},
title = {A review of Machine learning models and parameters for groundwater issues},
year = {2023},
isbn = {9798400700194},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607720.3607777},
doi = {10.1145/3607720.3607777},
abstract = {Groundwater is an essential source of freshwater to meet the growing water needs of agricultural, industrial, and domestic activities. the management of these resources is of crucial importance to ensure their sustainability and abundance over time and space. this major challenge requires extensive research for the prediction and simulation of groundwater level variationsThe new approach used in the field of hydrology and hydrogeology for the simulation and prediction of groundwater levels is based on machine learning techniques; these techniques are essential to improve the planning and management of groundwater resources.In this context, several researchers in this field have developed machine learning models capable of estimating the fluctuation of groundwater levels to protect these aquifers.This study launched word queries in several databases: Scopus, Science Direct, and IEEE; we selected 155 references and after the realization of the word clouds we find many topics: piezometer; groundwater; machine learning models, and parameters. In addition, the most recurrent machine learning models used by researchers in this field are Random Forest (RF), Decision Tree (DT), Support vector regression (SVM), artificial neural network (ANN), and SVR. But each of these researchers has based on some number of parameters as inputs; the most common are temperature; precipitation and groundwater level history. In this paper, we present a comparison of the most common machine learning models and parameters for assessing and predicting groundwater fluctuation.},
booktitle = {Proceedings of the 6th International Conference on Networking, Intelligent Systems &amp; Security},
articleno = {54},
numpages = {7},
keywords = {Machine learning models, aquifer, groundwater levels, machine learning parameters, precipitation, temperature},
location = {Larache, Morocco},
series = {NISS '23}
}

@inproceedings{10.1145/3478432.3499045,
author = {Rahman, Farzana and Billionniere, Elodie and Subhedar, Vaishnavi Prashant},
title = {Diversifying the Face of Computing through Re-entry Initiatives for Returning Women},
year = {2022},
isbn = {9781450390712},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3478432.3499045},
doi = {10.1145/3478432.3499045},
abstract = {Recruitment, retention, and graduation of women in science, technology, engineering, and mathematics (STEM) training are critical needs in our nation [1, 2]. Within STEM, the computing and tech industry, specifically some niches, are expected to grow job opportunities more quickly than others. Emerging Technology (EmTech) concentrations like cybersecurity, data science, mobile development, machine learning, and cloud computing will have thousands of jobs in the next decade which will require a large pool of technical professionals. EmTech can use the largest untapped talent pool of women and returning women to fill the gap in the workforce. Hence, to understand the barriers and challenges faced by returning women to (re-) enter computing and tech fields, a three-day virtual conference, NSF RESET, was organized in March 2021. In this poster, we present the preliminary results on conference attendees' satisfaction level and effectiveness in facilitating resources to (re-)enter EmTech educational and professional pipeline.},
booktitle = {Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 2},
pages = {1145},
numpages = {1},
keywords = {computing, diversity, emerging technology, returning women},
location = {Providence, RI, USA},
series = {SIGCSE 2022}
}

@article{10.1145/3552490.3552496,
author = {Psallidas, Fotis and Zhu, Yiwen and Karlas, Bojan and Henkel, Jordan and Interlandi, Matteo and Krishnan, Subru and Kroth, Brian and Emani, Venkatesh and Wu, Wentao and Zhang, Ce and Weimer, Markus and Floratou, Avrilia and Curino, Carlo and Karanasos, Konstantinos},
title = {Data Science Through the Looking Glass: Analysis of Millions of GitHub Notebooks and ML.NET Pipelines},
year = {2022},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/3552490.3552496},
doi = {10.1145/3552490.3552496},
abstract = {The recent success of machine learning (ML) has led to an explosive growth of systems and applications built by an ever-growing community of system builders and data science (DS) practitioners. This quickly shifting panorama, however, is challenging for system builders and practitioners alike to follow. In this paper, we set out to capture this panorama through a wide-angle lens, performing the largest analysis of DS projects to date, focusing on questions that can advance our understanding of the field and determine investments. Specifically, we download and analyze (a) over 8M notebooks publicly available on GITHUB and (b) over 2M enterprise ML pipelines developed within Microsoft. Our analysis includes coarse-grained statistical characterizations, finegrained analysis of libraries and pipelines, and comparative studies across datasets and time. We report a large number of measurements for our readers to interpret and draw actionable conclusions on (a) what system builders should focus on to better serve practitioners and (b) what technologies should practitioners rely on.},
journal = {SIGMOD Rec.},
month = jul,
pages = {30–37},
numpages = {8}
}

@inproceedings{10.1109/ICSE48619.2023.00192,
author = {Yang, Xu and Wang, Shaowei and Li, Yi and Wang, Shaohua},
title = {Does Data Sampling Improve Deep Learning-Based Vulnerability Detection? Yeas! and Nays!},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00192},
doi = {10.1109/ICSE48619.2023.00192},
abstract = {Recent progress in Deep Learning (DL) has sparked interest in using DL to detect software vulnerabilities automatically and it has been demonstrated promising results at detecting vulnerabilities. However, one prominent and practical issue for vulnerability detection is data imbalance. Prior study observed that the performance of state-of-the-art (SOTA) DL-based vulnerability detection (DLVD) approaches drops precipitously in real world imbalanced data and a 73% drop of F1-score on average across studied approaches. Such a significant performance drop can disable the practical usage of any DLVD approaches. Data sampling is effective in alleviating data imbalance for machine learning models and has been demonstrated in various software engineering tasks. Therefore, in this study, we conducted a systematical and extensive study to assess the impact of data sampling for data imbalance problem in DLVD from two aspects: i) the effectiveness of DLVD, and ii) the ability of DLVD to reason correctly (making a decision based on real vulnerable statements). We found that in general, oversampling outperforms undersampling, and sampling on raw data outperforms sampling on latent space, typically random oversampling on raw data performs the best among all studied ones (including advanced one SMOTE and OSS). Surprisingly, OSS does not help alleviate the data imbalance issue in DLVD. If the recall is pursued, random undersampling is the best choice. Random oversampling on raw data also improves the ability of DLVD approaches for learning real vulnerable patterns. However, for a significant portion of cases (at least 33% in our datasets), DVLD approach cannot reason their prediction based on real vulnerable statements. We provide actionable suggestions and a roadmap to practitioners and researchers.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {2287–2298},
numpages = {12},
keywords = {vulnerability detection, deep learning, data sampling, interpretable AI},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3524842.3528456,
author = {Ma, Wei and Zhao, Mengjie and Soremekun, Ezekiel and Hu, Qiang and Zhang, Jie M. and Papadakis, Mike and Cordy, Maxime and Xie, Xiaofei and Traon, Yves Le},
title = {GraphCode2Vec: generic code embedding via lexical and program dependence analyses},
year = {2022},
isbn = {9781450393034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524842.3528456},
doi = {10.1145/3524842.3528456},
abstract = {Code embedding is a keystone in the application of machine learning on several Software Engineering (SE) tasks. To effectively support a plethora of SE tasks, the embedding needs to capture program syntax and semantics in a way that is generic. To this end, we propose the first self-supervised pre-training approach (called GraphCode2Vec) which produces task-agnostic embedding of lexical and program dependence features. GraphCode2Vec achieves this via a synergistic combination of code analysis and Graph Neural Networks. GraphCode2Vec is generic, it allows pre-training, and it is applicable to several SE downstream tasks. We evaluate the effectiveness of GraphCode2Vec on four (4) tasks (method name prediction, solution classification, mutation testing and overfitted patch classification), and compare it with four (4) similarly generic code embedding baselines (Code2Seq, Code2Vec, CodeBERT, Graph-CodeBERT) and seven (7) task-specific, learning-based methods. In particular, GraphCode2Vec is more effective than both generic and task-specific learning-based baselines. It is also complementary and comparable to GraphCodeBERT (a larger and more complex model). We also demonstrate through a probing and ablation study that GraphCode2Vec learns lexical and program dependence features and that self-supervised pre-training improves effectiveness.},
booktitle = {Proceedings of the 19th International Conference on Mining Software Repositories},
pages = {524–536},
numpages = {13},
keywords = {code analysis, code embedding, code representation},
location = {Pittsburgh, Pennsylvania},
series = {MSR '22}
}

@proceedings{10.1145/3673176,
title = {SummerSchool '19: 3rd ACM Europe Summer School on Data Science},
year = {2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 3rd ACM Europe Summer School on Data Science was completed successfully and left memorable impressions to students and lecturers alike. The Summer School took place in Athens, Greece, from 11 to 17 of July 2019, in Athens Marriott Hotel.Fifty five young computer science researchers and engineers from all Continents, young faculty, postdocs, PhD candidates and MSc students, arrived in Athens to attend an intense week of lectures, hands-on sessions and keynote talks from eight distinguished scientists.Six subjects in Data Science, Data Management and Analysis, Machine Learning, Data Mining, Visual Analytics and Ethics were selected to offer students the chance to develop skills and expertise, broaden their international experience and capitalize on this great knowledge opportunity.},
location = {Athens, Greece}
}

@inproceedings{10.1145/3557915.3560935,
author = {Amagata, Daichi and Arai, Yusuke and Fujita, Sumio and Hara, Takahiro},
title = {Learned k-NN distance estimation},
year = {2022},
isbn = {9781450395298},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3557915.3560935},
doi = {10.1145/3557915.3560935},
abstract = {Big data mining is well known to be an important task for data science, because it can provide useful observations and new knowledge hidden in given large datasets. Proximity-based data analysis is particularly utilized in many real-life applications. In such analysis, the distances to k nearest neighbors are usually employed, thus its main bottleneck is derived from data retrieval. Much efforts have been made to improve the efficiency of these analyses. However, they still incur large costs, because they essentially need many data accesses. To avoid this issue, we propose a machine-learning technique that quickly and accurately estimates the k-NN distances (i.e., distances to the k nearest neighbors) of a given query. We train a fully connected neural network model and utilize pivots to achieve accurate estimation. Our model is designed to have useful advantages: it infers distances to the k-NNs at a time, its inference time is O(1) (no data accesses are incurred), but it keeps high accuracy. Our experimental results and case studies on real datasets demonstrate the efficiency and effectiveness of our solution.},
booktitle = {Proceedings of the 30th International Conference on Advances in Geographic Information Systems},
articleno = {1},
numpages = {4},
keywords = {k-NN query, machine learning, spatial data},
location = {Seattle, Washington},
series = {SIGSPATIAL '22}
}

@inproceedings{10.1145/3643991.3644917,
author = {Koyanagi, Kei and Wang, Dong and Noguchi, Kotaro and Kondo, Masanari and Serebrenik, Alexander and Kamei, Yasutaka and Ubayashi, Naoyasu},
title = {Exploring the Effect of Multiple Natural Languages on Code Suggestion Using GitHub Copilot},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644917},
doi = {10.1145/3643991.3644917},
abstract = {GitHub Copilot is an AI-enabled tool that automates program synthesis. It has gained significant attention since its launch in 2021. Recent studies have extensively examined Copilot's capabilities in various programming tasks, as well as its security issues. However, little is known about the effect of different natural languages on code suggestion. Natural language is considered a social bias in the field of NLP, and this bias could impact the diversity of software engineering. To address this gap, we conducted an empirical study to investigate the effect of three popular natural languages (English, Japanese, and Chinese) on Copilot. We used 756 questions of varying difficulty levels from AtCoder contests for evaluation purposes. The results highlight that the capability varies across natural languages, with Chinese achieving the worst performance. Furthermore, regardless of the type of natural language, the performance decreases significantly as the difficulty of questions increases. Our work represents the initial step in comprehending the significance of natural languages in Copilot's capability and introduces promising opportunities for future endeavors.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {481–486},
numpages = {6},
keywords = {code suggestion, GitHub copilot, empirical study},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3637528.3671602,
author = {Liu, Xuanqing and Wang, Runhui and Song, Yang and Kong, Luyang},
title = {GRAM: Generative Retrieval Augmented Matching of Data Schemas in the Context of Data Security},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671602},
doi = {10.1145/3637528.3671602},
abstract = {Schema matching constitutes a pivotal phase in the data ingestion process for contemporary database systems. Its objective is to discern pairwise similarities between two sets of attributes, each associated with a distinct data table. This challenge emerges at the initial stages of data analytics, such as when incorporating a third-party table into existing databases to inform business insights. Given its significance in the realm of database systems, schema matching has been under investigation since the 2000s. This study revisits this foundational problem within the context of large language models. Adhering to increasingly stringent data security policies, our focus lies on the zero-shot and few-shot scenarios: the model should analyze only a minimal amount of customer data to execute the matching task, contrasting with the conventional approach of scrutinizing the entire data table. We emphasize that the zero-shot or few-shot assumption is imperative to safeguard the identity and privacy of customer data, even at the potential cost of accuracy. The capability to accurately match attributes under such stringent requirements distinguishes our work from previous literature in this domain.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5476–5486},
numpages = {11},
keywords = {generative modeling, retrieval augmented generation, schema matching},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3589342,
author = {Gangwar, Arvind Kumar and Kumar, Sandeep},
title = {Concept Drift in Software Defect Prediction: A Method for Detecting and Handling the Drift},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3589342},
doi = {10.1145/3589342},
abstract = {Software Defect Prediction (SDP) is crucial towards software quality assurance in software engineering. SDP analyzes the software metrics data for timely prediction of defect prone software modules. Prediction process is automated by constructing defect prediction classification models using machine learning techniques. These models are trained using metrics data from historical projects of similar types. Based on the learned experience, models are used to predict defect prone modules in currently tested software. These models perform well if the concept is stationary in a dynamic software development environment. But their performance degrades unexpectedly in the presence of change in concept (Concept Drift). Therefore, concept drift (CD) detection is an important activity for improving the overall accuracy of the prediction model. Previous studies on SDP have shown that CD may occur in software defect data and the used defect prediction model may require to be updated to deal with CD. This phenomenon of handling the CD is known as CD adaptation. It is observed that still efforts need to be done in this direction in the SDP domain. In this article, we have proposed a pair of paired learners (PoPL) approach for handling CD in SDP. We combined the drift detection capabilities of two independent paired learners and used the paired learner (PL) with the best performance in recent time for next prediction. We experimented on various publicly available software defect datasets garnered from public data repositories. Experimentation results showed that our proposed approach performed better than the existing similar works and the base PL model based on various performance measures.},
journal = {ACM Trans. Internet Technol.},
month = may,
articleno = {31},
numpages = {28},
keywords = {Concept drift, paired learning, software defect prediction, software quality assurance}
}

@inproceedings{10.1145/3580305.3599214,
author = {Purushotham, Sanjay and Song, Dongjin and Wen, Qingsong and Huan, Jun and Shen, Cong and Nevmyvaka, Yuriy},
title = {The 9th SIGKDD International Workshop on Mining and Learning from Time Series},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599214},
doi = {10.1145/3580305.3599214},
abstract = {Time series data has become pervasive across domains such as finance, transportation, retail, entertainment, and healthcare. This shift towards continuous monitoring and recording, fueled by advancements in sensing technologies, necessitates the development of new tools and solutions. Despite extensive study, the importance of time series analysis continues to increase. However, modern time series data present challenges to existing techniques, including irregular sampling and spatiotemporal structures. Time series mining research is both challenging and rewarding as it connects diverse disciplines and requires interdisciplinary solutions. The goals of this workshop are to (1) highlight the significant challenges that underpin learning and mining from time series data (e.g., irregular sampling, spatiotemporal structure, uncertainty quantification), (2) discuss recent algorithmic, theoretical, statistical, or systems-based developments for tackling these problems, and (3) to synergize the research activities and discuss both new and open problems in time series analysis and mining. In summary, our workshop will focus on both the theoretical and practical aspects of time series data analysis and will provide a platform for researchers and practitioners from academia and industry to discuss potential research directions and critical technical issues and present solutions to tackle related issues in practical applications. We will invite researchers and practitioners from the related areas of AI, machine learning, data science, statistics, and many others to contribute to this workshop.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5876–5877},
numpages = {2},
keywords = {deep forecasting, temporal data mining, time-series analysis},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3543873.3587309,
author = {Xu, Canwen and McAuley, Julian and Wang, Penghan},
title = {Mirror: A Natural Language Interface for Data Querying, Summarization, and Visualization},
year = {2023},
isbn = {9781450394192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543873.3587309},
doi = {10.1145/3543873.3587309},
abstract = {We present Mirror, an open-source platform for data exploration and analysis powered by large language models. Mirror offers an intuitive natural language interface for querying databases, and automatically generates executable SQL commands to retrieve relevant data and summarize it in natural language. In addition, users can preview and manually edit the generated SQL commands to ensure the accuracy of their queries. Mirror also generates visualizations to facilitate understanding of the data. Designed with flexibility and human input in mind, Mirror is suitable for both experienced data analysts and non-technical professionals looking to gain insights from their data.1},
booktitle = {Companion Proceedings of the ACM Web Conference 2023},
pages = {49–52},
numpages = {4},
keywords = {automatic data analysis, natural language interface, pretrained language model, semantic parsing},
location = {Austin, TX, USA},
series = {WWW '23 Companion}
}

@article{10.1145/3603254,
author = {Romberg, Julia and Escher, Tobias},
title = {Making Sense of Citizens’ Input through Artificial Intelligence: A Review of Methods for Computational Text Analysis to Support the Evaluation of Contributions in Public Participation},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
url = {https://doi.org/10.1145/3603254},
doi = {10.1145/3603254},
abstract = {Public sector institutions that consult citizens to inform decision-making face the challenge of evaluating the contributions made by citizens. This evaluation has important democratic implications but at the same time, consumes substantial human resources. However, until now the use of artificial intelligence such as computer-supported text analysis has remained an under-studied solution to this problem. We identify three generic tasks in the evaluation process that could benefit from natural language processing (NLP). Based on a systematic literature search in two databases on computational linguistics and digital government, we provide a detailed review of existing methods and their performance. While some promising approaches exist, for instance to group data thematically and to detect arguments and opinions, we show that there remain important challenges before these could offer any reliable support in practice. These include the quality of results, the applicability to non-English language corpuses and making algorithmic models available to practitioners through software. We discuss a number of avenues that future research should pursue that can ultimately lead to solutions for practice. The most promising of these bring in the expertise of human evaluators, for example through active learning approaches or interactive topic modeling.},
journal = {Digit. Gov.: Res. Pract.},
month = mar,
articleno = {3},
numpages = {30},
keywords = {Policy analytics, citizen participation, computational linguistics}
}

@inproceedings{10.5555/3566055.3566058,
author = {Sendyk, Nicholas and Davies, Curtis and Priscu, Titus and Sutherland, Miles and Madi, Atallah and Dick, Kevin and Khalil, Hoda and Abu Alkheir, Ala and Wainer, Gabriel},
title = {A Task-Agnostic Machine Learning Framework for Dynamic Knowledge Graphs},
year = {2022},
publisher = {IBM Corp.},
address = {USA},
abstract = {Many applications require well-structured and current information to enable downstream tasks. Knowledge graphs are a type of knowl-edge representation that effectively organize current information capturing elements and the relationships between them such that they can be queried and/or reasoned over in more advanced applica-tions. A particular challenge is ensuring that an application-specific knowledge graph is both comprehensive and contains the most current representation, achieved through dynamic updating. Some available software frameworks for managing information as part of a data science pipeline are effective in collecting, labelling, and analysing textual data using natural language processing. Despite the utility of these frameworks, they can nonetheless be daunting for use by industry professionals and/or researchers who may not be familiar with the specifics of each tool. In this work, we present a generalized task-agnostic supervised machine learning frame-work that serves as a streamlined methodology for the creation and dynamic updating of knowledge graphs. A user needs only to define task-specific parameters allowing the tool to scrape data from the internet, generating a candidate corpus. The user may then provide sample annotations from the corpus to train task-specific natural language processing models to extract the relevant knowl-edge graph elements and the relationships connecting them. We demonstrate the utility of this framework for a case study seeking to build knowledge graph representations of merger and acquisition events between companies from scraped online articles reporting these instances. Our task-specific machine learning models achieve upwards of 99.2% F1 score evaluation metric on candidate web page classification and 81.5% F1 score on sentence-level extraction of entity relationships, demonstrating the promise of this framework. Our framework is freely available at: github.com/Checktr/tadkg.},
booktitle = {Proceedings of the 32nd Annual International Conference on Computer Science and Software Engineering},
pages = {22–31},
numpages = {10},
keywords = {fault injection attack, software vulnerability detection, machine learning, software fault injection, software fault model},
location = {Toronto, Canada},
series = {CASCON '22}
}

@inproceedings{10.1145/3510003.3510091,
author = {Li, Yanhui and Meng, Linghan and Chen, Lin and Yu, Li and Wu, Di and Zhou, Yuming and Xu, Baowen},
title = {Training data debugging for the fairness of machine learning software},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510091},
doi = {10.1145/3510003.3510091},
abstract = {With the widespread application of machine learning (ML) software, especially in high-risk tasks, the concern about their unfairness has been raised towards both developers and users of ML software. The unfairness of ML software indicates the software behavior affected by the sensitive features (e.g., sex), which leads to biased and illegal decisions and has become a worthy problem for the whole software engineering community.According to the "data-driven" programming paradigm of ML software, we consider the root cause of the unfairness as biased features in training data. Inspired by software debugging, we propose a novel method, Linear-regression based Training Data Debugging (LTDD), to debug feature values in training data, i.e., (a) identify which features and which parts of them are biased, and (b) exclude the biased parts of such features to recover as much valuable and unbiased information as possible to build fair ML software. We conduct an extensive study on nine data sets and three classifiers to evaluate the effect of our method LTDD compared with four baseline methods. Experimental results show that (a) LTDD can better improve the fairness of ML software with less or comparable damage to the performance, and (b) LTDD is more actionable for fairness improvement in realistic scenarios.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {2215–2227},
numpages = {13},
keywords = {ML software, debugging, fairness, training data},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3555776.3577592,
author = {Da Silva, Nayara Cristina and Albertini, Marcelo Keese and Backes, Andre Ricardo and Pena, Georgia das Gra\c{c}as},
title = {Prediction of readmissions in hospitalized children and adolescents by machine learning},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577592},
doi = {10.1145/3555776.3577592},
abstract = {Pediatric hospital readmission involves greater burdens for the patient and their family network, and for the health system. Machine learning can be a good strategy to expand knowledge in this area and to assist in the identification of patients at readmission risk. The objective of the study was to develop a predictive model to identify children and adolescents at high risk of potentially avoidable 30-day readmission using a machine learning approach. Retrospective cohort study with patients under 18 years old admitted to a tertiary university hospital. We collected demographic, clinical, and nutritional data from electronic databases. We apply machine learning techniques to build the predictive models. The 30-day hospital readmissions rate was 9.50%. The accuracy for CART model with bagging was 0.79, the sensitivity, and specificity were 76.30% and 64.40%, respectively. Machine learning approaches can predict avoidable 30-day pediatric hospital readmission into tertiary assistance.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {1088–1091},
numpages = {4},
keywords = {machine learning, data analysis, hospital readmission, children health, adolescents health},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@inproceedings{10.1145/3524086.3524095,
author = {Muramamatsu, Chisako and Nishio, Mizuho and Oiwa, Mikinao and Yakami, Masahiro and Kubo, Takeshi and Fujita, Hiroshi},
title = {Investigation on continual training of computer-aided diagnosis systems by semi-supervised learning},
year = {2022},
isbn = {9781450396202},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524086.3524095},
doi = {10.1145/3524086.3524095},
abstract = {Medical image analysis systems can help radiologists in reading images accurately and promptly. The systems are expected to be robust to images obtained with any imaging systems by different vendors and at different facilities. However, because of the prevalence of diseases and difficulty of collecting samples with various characteristics, the systems may not apply well to all the images. Artificial intelligence-powered systems are expected to learn from experience and be improved continuously. In this study, we investigated whether continual training with local samples can improve system performance using mammography and lung CT databases. Different training strategies using unlabeled data are compared.},
booktitle = {2022 4th International Conference on Intelligent Medicine and Image Processing},
pages = {58–62},
numpages = {5},
keywords = {computer-aided diagnosis, continual learning, image classification, lung CT, mammography},
location = {Tianjin, China},
series = {IMIP 2022}
}

@inproceedings{10.1145/3674805.3686666,
author = {Felizardo, Katia Romero and Lima, M\'{a}rcia Sampaio and Deizepe, Anderson and Conte, Tayana Uch\^{o}a and Steinmacher, Igor},
title = {ChatGPT application in Systematic Literature Reviews in Software Engineering: an evaluation of its accuracy to support the selection activity},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3686666},
doi = {10.1145/3674805.3686666},
abstract = {Context: The Systematic Literature Review (SLR) process involves searching, selecting, and synthesizing relevant literature on a specific research topic for evidence-based decision-making in Software Engineering (SE). Due to the time-consuming of the SLR process, tool support is essential. Gap: ChatGPT is a significant advancement in Natural Language Processing (NLP), and it can potentially accelerate time-consuming and propone-error activities, such as the selection activity of the SLR process. Therefore, having a tool to assist in the selection process appears beneficial, and we argue that ChatGPT can facilitate the analysis of extensive studies, saving time and effort. Objective: We aim to evaluate the accuracy (i.e., studies correctly classified) of using ChatGPT–4.0 in SLR in SE, particularly to support the first stage, based on the title, abstract, and keywords. Method: We assessed the accuracy of utilizing ChatGPT for selecting studies, the first stage, to be included in two SLRs (SLR1 and SLR2), in contrast to the conventional method of reading the title and abstract. Results: The accuracy of ChatGPT supporting the initial selection activity was 75.3% (SLR1 – 101 correct selections: 48 inclusions and 53 exclusions; 33 incorrect selections: 17 inclusions and 16 exclusions) and 86.1% (SLR2 – 386 correct selections: 113 inclusions and 273 exclusions; 62 incorrect selections: 27 inclusions and 35 exclusions). Conclusions: Our accuracy results indicate that it is not advisable to completely outsource the selection process to ChatGPT. However, it could be valuable as a support tool, aiding novice researchers or even experienced ones when they are in doubt.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {25–36},
numpages = {12},
keywords = {ChatGPT, Selection of studies, Software Engineering, Systematic literature review},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@article{10.5555/3606402.3606430,
author = {Char, Bruce and Dougherty, John P.},
title = {A Study of the Perception of Mathematics as a Learning Tool for Computer Science Undergraduates},
year = {2023},
issue_date = {April 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {38},
number = {8},
issn = {1937-4771},
abstract = {Most programs in computer science undergraduate programs have evolved from a mathematics program, an engineering program, or some other combination. In computer science education, we will often exploit problems from mathematics with computational solutions to introduce and develop a deep understanding of computational concepts and skills related to program development and analysis. However, it needs to be clarified the degree to which students in undergraduate computer science programs see this connection between what they are learning and the role that mathematics can play in increasing the understanding of that learning. Do they view the mathematics they encounter as one of the unavoidable burdens that the major makes them endure to get a degree but will not need much after graduation? Or do they see mathematical learning and inventive thinking as something that they will need to do on a continuing basis even after graduation? The authors developed an instrument that could be used to gather evidence to understand better how our students look at the role of mathematics in their computer science courses and projects. Beginning in the fall of 2021 a survey instrument was developed and administered to students primarily at Haverford College. Students who completed the initial prototype survey were enrolled in an accelerated CS1-CS2 course where they had experience with programming before attending college. It is also assumed that they have been exposed to mathematics throughout their education. It should also be clear that in this context mathematics is defined expansively to include algebraic and other numerical manipulations of data, as well as problem-solving techniques to divide and conquer complicated problems, appreciating and understanding the use of abstraction [2], reasoning about the state of various parts of computation through the out the execution process, as well as this distinction between verification by proof versus testing. At Drexel University, students in computer science are required to complete courses in calculus. Meanwhile, at Haverford College students are required to complete a course in discrete mathematics as well as one of two choices between analysis of algorithms and theory of computation. At each school, other courses either directly or tangentially related to mathematics are taken by students to increase their understanding and prepare them for courses that apply to computing. The obvious fields are computer science and mathematics, but also include machine learning, data science, scientific computing, and computational linguistics. Perhaps we should have expected, responses to the prototype to have indicated that students have a variety of impressions about the role of mathematics in their studies for computer science. Some of them may impact the development of persistent robust self-regulated mathematical thinking and learning even after entry into the workforce. We suspect that students in computer science do not perceive how mathematics is used in the field and thus either delay or avoid mathematics or leave the field of computer science. Perhaps students find mathematics irrelevant, unengaging, we're simply too difficult, our goal with this project is to identify first if this disconnect between math and computer science exists we're not. Our intention is to identify obstacles and suggests approaches to help computer science educators provide this mathematical foundation for computer science students [3]. We plan to continue this study to get a clearer picture of how students look at the role of mathematics. We believe that a sound foundation in math contributes positively to those in computer science [1, 4].},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {222–223},
numpages = {2}
}

@inproceedings{10.1145/3618305.3623587,
author = {Ribeiro, Francisco},
title = {Large Language Models for Automated Program Repair},
year = {2023},
isbn = {9798400703843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3618305.3623587},
doi = {10.1145/3618305.3623587},
abstract = {This paper introduces two methods for automated program repair (APR) utilizing pre-trained language models. The first method demonstrates program repair as a code completion task and is validated on a dataset of Java programs. The second method, Mentat, leverages OCaml’s parser and type system as fault localization techniques to generate prompts for GPT-3, producing candidate patches. Evaluation results show promising repair rates, with 27% and 39.2% effectiveness, respectively. For OCaml, a comparative study employing an automated validation strategy is presented in which the technique outperforms other tools. Language models are effective at APR, enhancing bug fixing and freeing developers to focus on other critical aspects of software engineering.},
booktitle = {Companion Proceedings of the 2023 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
pages = {7–9},
numpages = {3},
keywords = {automated program repair, code generation, fault localization, type systems},
location = {Cascais, Portugal},
series = {SPLASH 2023}
}

@inproceedings{10.1145/3551349.3561147,
author = {Aryendu, Ishan and Wang, Ying and Elkourdi, Farah and Alomar, Eman Abdullah},
title = {Intelligent Code Review Assignment for Large Scale Open Source Software Stacks},
year = {2023},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551349.3561147},
doi = {10.1145/3551349.3561147},
abstract = {In the process of developing software, code review is crucial. By identifying problems before they arise in production, it enhances the quality of the code. Finding the best reviewer for a code change, however, is extremely challenging especially in large scale, especially open source software stacks with cross functioning designs and collaborations among multiple developers and teams. Additionally, a review by someone who lacks knowledge and understanding of the code can result in high resource consumption and technical errors. The reviewers who have the specialty in both functioning (domain knowledge) and non-functioning areas of a commit are considered as the most qualified reviewer to look over any changes to the code. Quality attributes serve as the connection among the user requirements, delivered function description, software architecture and implementation through put the entire software stack cycle. In this study, we target on auto reviewer assignment in large scale software stacks and aim to build a self-learning, and self-correct platform for intelligently matching between a commit based on its quality attributes and the skills sets of reviewers. To achieve this, quality attributes are classified and abstracted from the commit messages and based on which, the commits are assigned to the reviewers with the capability in reviewing the target commits. We first designed machine learning schemes for abstracting quality attributes based on historical data from the OpenStack repository. Two models are built and trained for automating the classification of the commits based on their quality attributes using the manual labeling of commits and multi-class classifiers. We then positioned the reviewers based on their historical data and the quality attributes characteristics. Finally we selected the recommended reviewer based on the distance between a commit and candidate reviewers. In this paper, we demonstrate how the models can choose the best quality attributes and assign the code review to the most qualified reviewers. With a comparatively small training dataset, the models are able to achieve F-1 scores of 77% and 85.31%, respectively.},
booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
articleno = {221},
numpages = {6},
keywords = {Code Review, Commit Classification, Large-scale, MPNet, Machine Learning, Open-source},
location = {Rochester, MI, USA},
series = {ASE '22}
}

@inproceedings{10.1145/3578338.3593535,
author = {Lu, Haoran and Zhao, Qingchuan and Chen, Yongliang and Liao, Xiaojing and Lin, Zhiqiang},
title = {Detecting and Measuring Aggressive Location Harvesting in Mobile Apps via Data-flow Path Embedding},
year = {2023},
isbn = {9798400700743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578338.3593535},
doi = {10.1145/3578338.3593535},
abstract = {Today, location-based services have become prevalent in the mobile platform, where mobile apps provide specific services to a user based on his or her location. Unfortunately, mobile apps can aggressively harvest location data with much higher accuracy and frequency than they need because the coarse-grained access control mechanism currently implemented in mobile operating systems (e.g., Android) cannot regulate such behavior. This unnecessary data collection violates the data minimization policy, yet no previous studies have investigated privacy violations from this perspective, and existing techniques are insufficient to address this violation. To fill this knowledge gap, we take the first step toward detecting and measuring this privacy risk in mobile apps at scale. Particularly, we annotate and release the first dataset to characterize those aggressive location harvesting apps and understand the challenges of automatic detection and classification. Next, we present a novel system, LocationScope, to address these challenges by (i) uncovering how an app collects locations and how to use such data through a fine-tuned value set analysis technique, (ii) recognizing the fine-grained location-based services an app provides via embedding data-flow paths, which is a combination of program analysis and machine learning techniques, extracted from its location data usages, and (iii) identifying aggressive apps with an outlier detection technique achieving a precision of 97% in aggressive app detection. Our technique has further been applied to millions of free Android apps from Google Play as of 2019 and 2021. Highlights of our measurements on detected aggressive apps include their growing trend from 2019 to 2021 and the app generators' significant contribution of aggressive location harvesting apps.},
booktitle = {Abstract Proceedings of the 2023 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {45–46},
numpages = {2},
keywords = {aggressive location harvesting, location privacy, location-based service},
location = {Orlando, Florida, United States},
series = {SIGMETRICS '23}
}

@inproceedings{10.1145/3673971.3673973,
author = {Alsaify, Abdel Rahman and Siam, Aisha and Hassan, Hudhaifa and Alzubaidi, Mahmood and Househ, Mowafa},
title = {The Use of Deep Learning in the Diagnosis and Prediction of Heart Failure: A scoping review},
year = {2024},
isbn = {9798400716874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673971.3673973},
doi = {10.1145/3673971.3673973},
abstract = {This scoping review presents a comprehensive analysis of the current implementation of deep learning techniques in heart failure diagnosis and prediction. We investigated the use of various deep learning models, focusing on their application in analyzing medical images and electronic health records. A thorough search across four electronic databases yielded 503 prospective studies, with 17 meeting our inclusion criteria. These studies predominantly originated from the United States and China and were primarily journal articles. Our review identified two main categories of deep learning models: those processing medical images and those analyzing clinical parameters from electronic health records. The most commonly used models were recurrent neural networks (RNN) for prediction and convolutional neural networks (CNN) and natural language processing (NLP) for diagnosis. The studies demonstrated a wide range of imaging modalities, with electrocardiograms being the most prevalent. Additionally, the review highlighted a variety of clinical parameters used for prediction and diagnosis, emphasizing the significance of artificial intelligence in medical research. Despite the promise shown by these models, challenges such as inconsistent performance, lack of detailed methodology, and limited geographical diversity in study sources were identified. Our findings underscore the potential of deep learning in enhancing heart failure diagnosis and prediction, but also point towards the need for more rigorous and diversified research to fully realize this technology's capabilities in healthcare.},
booktitle = {Proceedings of the 2024 8th International Conference on Medical and Health Informatics},
pages = {186–192},
numpages = {7},
keywords = {Deep Learning, Health informatic, Heart Failure, Multimodal},
location = {Yokohama, Japan},
series = {ICMHI '24}
}

@inproceedings{10.1145/3569551.3569558,
author = {Khan, Md. Sohel Aman and Farabi, Ahmad Rahman and Iqbal, Anindya},
title = {What Do Firebase Developers Discuss About? An Empirical Study on Stack Overflow Posts},
year = {2022},
isbn = {9781450399036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569551.3569558},
doi = {10.1145/3569551.3569558},
abstract = {Firebase is the leading Platform-as-a-Service (PaaS) solution in the application development industry. It is globally used by millions of mobile applications and websites. Being a very popular and robust development platform, Firebase has introduced and developed many features and components over the years. Various services and modules are being added to the platform. So, the developers who use Firebase in their applications, need to have versatile knowledge of the platform. It is difficult to acquire an overview of the trends and discussions of any vast and dynamic platform such as Firebase. Therefore, learners, enthusiasts, and often developers have to put in a lot of effort to figure out topics they should explore and focus on. As a large number of application developers frequently use it and engage in various discussions about it in popular community discussion forums for developers, it has become a very promising source for identifying the topics and trends related to Firebase. Stack Overflow is the most popular community for developers’ discussions. It has grown to be a vast ocean of knowledge to explore. In this study, a systematic approach is followed to explore, extract, and analyze Stack Overflow discussions on Firebase to present an overview of the platform. Natural language processing and machine learning methods were used for extracting information from Stack Overflow data. Information collected was reviewed, analyzed, and compiled into this paper by the research group who have practical experiences in the Firebase platform and other relevant software engineering fields.},
booktitle = {Proceedings of the 9th International Conference on Networking, Systems and Security},
pages = {63–74},
numpages = {12},
keywords = {Firebase, LDA, Stack Overflow, mining, natural language processing, software engineering, topic modeling},
location = {Cox's Bazar, Bangladesh},
series = {NSysS '22}
}

@inproceedings{10.1145/3652037.3663897,
author = {Xing, Yangang and Kar, Purna and J. Bird, Jordan and Sumich, Alex and Carpenter Van Barthold, Benedict and Knight, Andrew and Lotfl, Ahmad},
title = {Exploring Machine Learning Applications for Biophilic Art Displays to Promote Health and Well-being},
year = {2024},
isbn = {9798400717604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652037.3663897},
doi = {10.1145/3652037.3663897},
abstract = {Research has shown that the use of biophilic elements in public or private spaces is effective in alleviating stress, improving mental well-being, and increasing innovativeness in the general public. Studies reveal that exposure to Biophilic art can improve an individual’s mental well-being. Many urban settings have few natural representations hence, the goal of our research is to use machine learning algorithms to develop a novel digital biophilic art categorization and display system to promote mental health and well-being. An initial survey conducted indicates a strong correlation between biophilia and positive emotions. We applied classification algorithms to develop an artwork recommendation system based on self-reported emotional responses to biophilic art pieces. Initial findings suggest a reduction in negative emotions and an increase in positive emotions, whilst using the system. This supports machine learning for the categorization and recommendation of biophilic art. It is in line with the importance of the integration of nature into built environments, and advocates the expansion of biophilic art databases, using more inclusive, emotionally responsive art recommendation systems.},
booktitle = {Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {329–336},
numpages = {8},
keywords = {Art, Biophilia, Intelligent Building, Machine Learning, Mental health, Recommender system.},
location = {Crete, Greece},
series = {PETRA '24}
}

@article{10.1145/3579447,
author = {Lu, Haoran and Zhao, Qingchuan and Chen, Yongliang and Liao, Xiaojing and Lin, Zhiqiang},
title = {Detecting and Measuring Aggressive Location Harvesting in Mobile Apps via Data-flow Path Embedding},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
url = {https://doi.org/10.1145/3579447},
doi = {10.1145/3579447},
abstract = {Today, location-based services have become prevalent in the mobile platform, where mobile apps provide specific services to a user based on his or her location. Unfortunately, mobile apps can aggressively harvest location data with much higher accuracy and frequency than they need because the coarse-grained access control mechanism currently implemented in mobile operating systems (e.g., Android) cannot regulate such behavior. This unnecessary data collection violates the data minimization policy, yet no previous studies have investigated privacy violations from this perspective, and existing techniques are insufficient to address this violation. To fill this knowledge gap, we take the first step toward detecting and measuring this privacy risk in mobile apps at scale. Particularly, we annotate and release thefirst dataset to characterize those aggressive location harvesting apps and understand the challenges of automatic detection and classification. Next, we present a novel system, LocationScope, to address these challenges by(i) uncovering how an app collects locations and how to use such data through a fine-tuned value set analysis technique,(ii) recognizing the fine-grained location-based services an app provides via embedding data-flow paths, which is a combination of program analysis and machine learning techniques, extracted from its location data usages, and(iii) identifying aggressive apps with an outlier detection technique achieving a precision of 97% in aggressive app detection. Our technique has further been applied to millions of free Android apps from Google Play as of 2019 and 2021. Highlights of our measurements on detected aggressive apps include their growing trend from 2019 to 2021 and the app generators' significant contribution of aggressive location harvesting apps.},
journal = {Proc. ACM Meas. Anal. Comput. Syst.},
month = mar,
articleno = {18},
numpages = {27},
keywords = {aggressive location harvesting, location privacy, location-based service}
}

@inproceedings{10.1145/3530019.3530039,
author = {Openja, Moses and Majidi, Forough and Khomh, Foutse and Chembakottu, Bhagya and Li, Heng},
title = {Studying the Practices of Deploying Machine Learning Projects on Docker},
year = {2022},
isbn = {9781450396134},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3530019.3530039},
doi = {10.1145/3530019.3530039},
abstract = {Docker is a containerization service that allows for convenient deployment of websites, databases, applications’ APIs, and machine learning (ML) models with a few lines of code. Studies have recently explored the use of Docker for deploying general software projects with no specific focus on how Docker is used to deploy ML-based projects. In this study, we conducted an exploratory study to understand how Docker is being used to deploy ML-based projects. As the initial step, we examined the categories of ML-based projects that use Docker. We then examined why and how these projects use Docker, and the characteristics of the resulting Docker images. Our results indicate that six categories of ML-based projects use Docker for deployment, including ML Applications, MLOps/ AIOps, Toolkits, DL Frameworks, Models, and Documentation. We derived the taxonomy of 21 major categories representing the purposes of using Docker, including those specific to models such as model management tasks (e.g., testing, training). We then showed that ML engineers use Docker images mostly to help with the platform portability, such as transferring the software across the operating systems, runtimes such as GPU, and language constraints. However, we also found that more resources may be required to run the Docker images for building ML-based software projects due to the large number of files contained in the image layers with deeply nested directories. We hope to shed light on the emerging practices of deploying ML software projects using containers and highlight aspects that should be improved.},
booktitle = {Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering},
pages = {190–200},
numpages = {11},
keywords = {Deep Neural Network, Deployment, Docker, Machine Learning},
location = {Gothenburg, Sweden},
series = {EASE '22}
}

@article{10.1145/3654990,
author = {Su, Yongye and Sun, Yinqi and Zhang, Minjia and Wang, Jianguo},
title = {Vexless: A Serverless Vector Data Management System Using Cloud Functions},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654990},
doi = {10.1145/3654990},
abstract = {Cloud functions, exemplified by AWS Lambda and Azure Functions, are emerging as a new computing paradigm in the cloud. They provide elastic, serverless, and low-cost cloud computing, making them highly suitable for bursty and sparse workloads, which are quite common in practice. Thus, there is a new trend in designing data systems that leverage cloud functions. In this paper, we focus on vector databases, which have recently gained significant attention partly due to large language models. In particular, we investigate how to use cloud functions to build high-performance and cost-efficient vector databases. This presents significant challenges in terms of how to perform sharding, how to reduce communication overhead, and how to minimize cold-start times.In this paper, we introduce Vexless, the first vector database system optimized for cloud functions. We present three optimizations to address the challenges. To perform sharding, we propose a global coordinator (orchestrator) that assigns workloads to Cloud function instances based on their available hardware resources. To overcome communication overhead, we propose the use of stateful cloud functions, eliminating the need for costly communications during synchronization. To minimize cold-start overhead, we introduce a workload-aware Cloud function lifetime management strategy. Vexless has been implemented using Azure Functions. Experimental results demonstrate that Vexless can significantly reduce costs, especially on bursty and sparse workloads, compared to cloud VM instances, while achieving similar or higher query performance and accuracy.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {187},
numpages = {26},
keywords = {cloud functions, serverless computing, serverless databases, vector databases}
}

@article{10.1145/3632173,
author = {Manimaran, A. and Syed, Mohammad Haider and Kumar, M. Siva and Selvanayaki, S. and Sunitha, Gurram and Manna, Asmita},
title = {Enhancing Asian Indigenous Language Processing through Deep Learning-based Handwriting Recognition and Optimization Techniques},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {8},
issn = {2375-4699},
url = {https://doi.org/10.1145/3632173},
doi = {10.1145/3632173},
abstract = {Asian&nbsp;indigenous language or autochthonous language is a language which is native to a region and spoken by indigenous people in Asia. This language is a linguistically different community created in the region. Recently, researchers in handwriting detection studies comparing with indigenous languages have attained important internet amongst the research community. A new development of artificial intelligence (AI), natural language processing (NLP), cognitive analytics, and computational linguistics (CL) find it helpful in the analysis of regional low-resource languages. It can be obvious in the obtainability of effectual machine detection methods and open access handwritten databases. Tamil is the most ancient Indian language that is mostly exploited in the Southern part of India, Sri Lanka, and Malaysia. Tamil handwritten Character Recognition (HCR) is a critical procedure in optical character detection. Therefore, this study designs a Henry Gas Solubility Optimization with Deep Learning-based Handwriting Recognition Model (HGSODL-HRM) for Asian Indigenous Language Processing. The proposed HGSODL-HRM technique relies on computer vision and DL concepts for automated handwriting recognition in the Tamil language, which is one of the popular indigenous languages in Asia. To accomplish this, the HGSODL-HRM technique employs a capsule network (CapsNet) model for feature vector generation with the HGSO algorithm as a hyperparameter optimizer. For the recognition of handwritten characters, wavelet neural network (WNN) model is exploited. Finally, the WNN parameters can be optimally chosen by sail fish optimizer (SFO) algorithm. To demonstrate the promising results of the HGSODL-HRM system, an extensive range of simulations can be implemented. The simulation outcomes stated the betterment of the HGSODL-HRM system compared to recent DL models.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = aug,
articleno = {119},
numpages = {20},
keywords = {Natural language processing, Cognitive Analytics, Asian&nbsp;indigenous language, Handwriting recognition, Deep Learning}
}

@inproceedings{10.1109/ASE51524.2021.9678889,
author = {Zhu, Chenguang and Saha, Ripon K. and Prasad, Mukul R. and Khurshid, Sarfraz},
title = {Restoring the executability of jupyter notebooks by automatic upgrade of deprecated APIs},
year = {2022},
isbn = {9781665403375},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE51524.2021.9678889},
doi = {10.1109/ASE51524.2021.9678889},
abstract = {Data scientists typically practice exploratory programming using computational notebooks, to comprehend new data and extract insights. To do this they iteratively refine their code, actively trying to re-use and re-purpose solutions created by other data scientists, in real time. However, recent studies have shown that a vast majority of publicly available notebooks cannot be executed out of the box. One of the prominent reasons is the deprecation of data science APIs used in such notebooks, due to the rapid evolution of data science libraries. In this work we propose RELANCER, an automatic technique that restores the executability of broken Jupyter Notebooks, in near real time, by upgrading deprecated APIs. Relancer employs an iterative runtime-error-driven approach to identify and fix one API issue at a time. This is supported by a machine-learned model which uses the runtime error message to predict the kind of API repair needed - an update in the API or package name, a parameter, or a parameter value. Then Relancer creates a search space of candidate repairs by combining knowledge from API migration examples on GitHub as well as the API documentation and employs a second machine-learned model to rank this space of candidate mappings. An evaluation of Relancer on a curated dataset of 255 un-executable Jupyter Notebooks from Kaggle shows that RELANCER can successfully restore the executability of 56% of the subjects, while baselines relying on just GitHub examples and just API documentation can only fix 38% and 36% of the subjects respectively. Further, pursuant to its real-time use case, Relancer can restore execution to 49% of subjects, within a 5 minute time limit, while a baseline lacking its machine learning models can only fix 24%.},
booktitle = {Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering},
pages = {240–252},
numpages = {13},
keywords = {API migration, data science, software evolution},
location = {Melbourne, Australia},
series = {ASE '21}
}

@inproceedings{10.1145/3558100.3563850,
author = {Wu, Jian and Hiltabrand, Ryan and So\'{o}s, Dominik and Giles, C. Lee},
title = {Scholarly big data quality assessment: a case study of document linking and conflation with S2ORC},
year = {2022},
isbn = {9781450395441},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3558100.3563850},
doi = {10.1145/3558100.3563850},
abstract = {Recently, the Allen Institute for Artificial Intelligence released the Semantic Scholar Open Research Corpus (S2ORC), one of the largest open-access scholarly big datasets with more than 130 million scholarly paper records. S2ORC contains a significant portion of automatically generated metadata. The metadata quality could impact downstream tasks such as citation analysis, citation prediction, and link analysis. In this project, we assess the document linking quality and estimate the document conflation rate for the S2ORC dataset. Using semi-automatically curated ground truth corpora, we estimated that the overall document linking quality is high, with 92.6% of documents correctly linking to six major databases, but the linking quality varies depending on subject domains. The document conflation rate is around 2.6%, meaning that about 97.4% of documents are unique. We further quantitatively compared three near-duplicate detection methods using the ground truth created from S2ORC. The experiments indicated that locality-sensitive hashing was the best method in terms of effectiveness and scalability, achieving high performance (F1=0.960) and a much reduced runtime. Our code and data are available at https://github.com/lamps-lab/docconflation.},
booktitle = {Proceedings of the 22nd ACM Symposium on Document Engineering},
articleno = {16},
numpages = {4},
keywords = {data quality, deduplication, document conflation, document linking, scholarly big data},
location = {San Jose, California},
series = {DocEng '22}
}

@article{10.14778/3685800.3685839,
author = {Xu, Quanqing and Yang, Chuanhui and Zhou, Aoying},
title = {Native Distributed Databases: Problems, Challenges and Opportunities},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685839},
doi = {10.14778/3685800.3685839},
abstract = {Native distributed databases, crucial for scalable applications, offer transactional and analytical prowess but face data intricacies and network challenges. Under the CAP theorem's constraints, latency and replication issues necessitate creative approaches to maintenance, security, and upgrades. Progress in consistency algorithms, network technology, automation, and machine learning for optimization presents significant potential. Embracing hybrid transactional/analytical processing (HTAP), these databases represent an evolutionary leap in data management, aiming to reconcile performance with the complexities inherent in distributed environments. OceanBase is introduced as a case study, and its strong TPC-C and TPC-H benchmark performances underscore Ocean-Base as a top-tier distributed database. We also discuss possible opportunities for native distributed databases.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4217–4220},
numpages = {4}
}

@article{10.1145/3517190,
author = {Ribeiro, Matheus A. O. and Nunes, F\'{a}tima L. S.},
title = {Left Ventricle Segmentation in Cardiac MR: A Systematic Mapping of the Past Decade},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {11s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3517190},
doi = {10.1145/3517190},
abstract = {Left ventricle segmentation in short-axis cardiac magnetic resonance images is important to diagnose heart disease. However, repetitive manual segmentation of these images requires considerable human effort and can decrease diagnostic accuracy. In recent years, several fully and semi-automatic approaches have been proposed, mainly using image-based, atlas, graph, deformable model, and artificial intelligence methods. This article presents a systematic mapping on left ventricle segmentation, considering 74 studies published in the past decade. The main contributions of this review are definition of the main segmentation challenges in these images; proposal of a new schematization, dividing the segmentation process into stages; categorization and analysis of the segmentation methods, including hybrid combinations; and analysis of the evaluation process, metrics, and databases. The performance of the methods in the most used public database is assessed, and the main limitations, weaknesses, and strengths of each method category are presented. Finally, trends, challenges, and research opportunities are discussed. The analysis indicates that methods from all categories can achieve good performance, and hybrid methods combining deep learning and deformable models obtain the best results. Methods still fail in specific slices, segment wrong regions, and produce anatomically impossible segmentations.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {241},
numpages = {38},
keywords = {Left ventricle, cardiac magnetic resonance imaging}
}

@article{10.14778/3611540.3611637,
author = {Gonzalez, Joseph E. and Low, Yucheng},
title = {The Story of GraphLab - From Scaling Machine Learning to Shaping Graph Systems Research (VLDB 2023 Test-of-Time Award Talk)},
year = {2023},
issue_date = {August 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3611540.3611637},
doi = {10.14778/3611540.3611637},
abstract = {The GraphLab project spanned almost a decade and had profound academic and industrial impact on large-scale machine learning and graph processing systems. There were numerous papers written describing the innovations in GraphLab including the original vertex-centric [8] and edge-centric [3] programming abstractions, high-performance asynchronous execution engines [9], out-of-core graph computation [6], tabular graph-systems [4], and even new statistical inference algorithms [2] enabled by the GraphLab project. This work became the basis of multiple PhD theses [1, 5, 7]. The GraphLab open-source project had broad academic and industrial adoption and ultimately lead to the launch of Turi.In this talk, we tell the story of GraphLab, how it began and the key ideas behind it. We will focus on the approach to achieving scalable asynchronous systems in machine learning. During our talk, we will explore the impact that GraphLab has had on the development of graph processing systems, graph databases, and AI/ML; Additionally, we will share our insights and opinions into where we see the future of these fields heading. In the process, we highlight some of the lessons we learned and provide guidance for future students.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4138},
numpages = {1}
}

@article{10.5555/3586589.3586907,
author = {Calder, Jeff and Ettehad, Mahmood},
title = {Hamilton-Jacobi equations on graphs with applications to semi-supervised learning and data depth},
year = {2022},
issue_date = {January 2022},
publisher = {JMLR.org},
volume = {23},
number = {1},
issn = {1532-4435},
abstract = {Shortest path graph distances are widely used in data science and machine learning, since they can approximate the underlying geodesic distance on the data manifold. However, the shortest path distance is highly sensitive to the addition of corrupted edges in the graph, either through noise or an adversarial perturbation. In this paper we study a family of Hamilton-Jacobi equations on graphs that we call the p-eikonal equation. We show that the p-eikonal equation with p = 1 is a provably robust distance-type function on a graph, and the p → ∞ limit recovers shortest path distances. While the p-eikonal equation does not correspond to a shortest-path graph distance, we nonetheless show that the continuum limit of the p-eikonal equation on a random geometric graph recovers a geodesic density weighted distance in the continuum. We consider applications of the p-eikonal equation to data depth and semi-supervised learning, and use the continuum limit to prove asymptotic consistency results for both applications. Finally, we show the results of experiments with data depth and semi-supervised learning on real image datasets, including MNIST, FashionMNIST and CIFAR-10, which show that the p-eikonal equation offers significantly better results compared to shortest path distances.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {318},
numpages = {62},
keywords = {data depth, graph learning, Hamilton-Jacobi equation, robust statistics, semi-supervised learning, viscosity solutions, discrete to continuum limits, partial differential equations}
}

@inproceedings{10.1145/3678884.3681842,
author = {Tranfield, Wynn and Caldwell, Christy},
title = {Navigating Machine-Driven Research Landscapes: A Comparative Approach},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678884.3681842},
doi = {10.1145/3678884.3681842},
abstract = {The growth of scientific literature poses a significant challenge for researchers and librarians. It is part of many librarians' core responsibilities to be able to identify and utilize appropriate research tools and databases to assist and advise scholars engaged in research. The recent proliferation of machine learning supported tools has created a tremendous gap in literature addressing the actual efficacy of these new tools, even as compared to conventional library databases. This work aims to build knowledge of these new tools (Scite, Elicit, SciSpace, Epsilon) by comparing search results within defined parameters, and evaluating results for format, topic relevance and uniqueness. By understanding the strengths and limitations of these tools, researchers will be better positioned to make informed decisions about their literature search.},
booktitle = {Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
pages = {141–146},
numpages = {6},
keywords = {academic research, artificial intelligence, bibliographic evaluation, citation analysis, digital libraries, information seeking},
location = {San Jose, Costa Rica},
series = {CSCW Companion '24}
}

@inproceedings{10.1145/3569192.3569218,
author = {Barbosa, Luis C. N. and Moreira, Antonio H. J. and Carvalho, Vitor and Vila\c{c}a, Jo\~{a}o L. and Morais, Pedro},
title = {Biosignal Databases for Training of Artificial Intelligent Systems},
year = {2023},
isbn = {9781450396868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569192.3569218},
doi = {10.1145/3569192.3569218},
abstract = {Coronavirus disease (COVID-19) is an infectious disease caused by the SARS-CoV-2 virus. Most people infected with the virus will have mild to moderate respiratory diseases, however, the elderly population is the most vulnerable, becoming seriously ill, requiring continuous medical follow-up. In this sense, technologies were developed that allow continuous and individual monitoring of patients, in a home environment, namely through wearable devices, thus avoiding continuous hospitalization. Thus, these devices allow great improvements in data analysis methods since they can continuously acquire the physiological signals of an individual and process them in real-time through artificial intelligence (AI) methods. However, training of AI methods is not straightforward, requiring a large amount of data. In this study, we review the most common biosignal databases available in the literature. A total of thirteen databases were selected. Most of the databases (9 databases) were related to ECG signal, as well as 4 databases containing signals from SPO2, Heart Rate, Blood Pressure, etc. Characteristics were described, namely: the population of the databases, data resolution, sampling rates, sample time, number of signal samples, annotated classes, data acquisition conditions, among other aspects. Overall, this study summarizes and described the public biosignals databases available in the literature, which may be important in the implementation of intelligent classification methods.},
booktitle = {Proceedings of the 9th International Conference on Bioinformatics Research and Applications},
pages = {74–81},
numpages = {8},
keywords = {Artificial Intelligence, Biosignals Databases, ECG Databases, Wearable Devices},
location = {Berlin, Germany},
series = {ICBRA '22}
}

@inproceedings{10.1145/3584371.3613038,
author = {Viet-Nhi, Nguyen-Kieu and Quoc Khanh, Le Nguyen and Truc, Vu Cong and Nguyen, Thi Thuy and Anh Duy, Tran Nguyen and Thai Bao, Nguyen Tu and Tseng, How and Hung, Shih-Han},
title = {Predicting Tumor Mutational Burden and Survival in Head and Neck Squamous Cancer Patients Using Machine Learning and Bioinformatics Approaches},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3613038},
doi = {10.1145/3584371.3613038},
abstract = {Head and neck squamous cancer (HNSC) is a prevalent malignancy with a complex genetic profile. Tumor Mutational Burden (TMB) is an emerging biomarker associated with prognostic and therapeutic implications. In this study, we aimed to develop machine-learning models for predicting TMB and patient survival using RNA sequencing data and clinical features.Methods: We collected RNA sequencing data and clinical information of HNSC patients from Gene Expression Omnibus (GEO) (GSE142083) and The Cancer Genome Atlas (TCGA) databases. Machine learning models, including Random Forest, Support Vector Machine (SVM), k-Nearest Neighbors (kNN), and Logistic Regression, were built to predict TMB levels based on patient gene expression profiles. The top 100 important features (genes) were selected from these models to create a survival prediction model.Results: Among the tested models, Random Forest showed the highest accuracy (0.8011), followed by SVM (0.796), kNN (0.777), and logistic regression (0.704). Using the top 100 important genes, we developed a model to predict HNSC patient survival (under 3 years, 3--5 years, and over 5 years). Random forest achieved an accuracy of 0.70, while SVM and kNN reached 0.65. We identified five genes (KRT14, KRT6B, COL1A1, FN1, KRT6C) most closely related to TMB and patient survival. Through KEGG pathway analysis and neural network approaches, we discovered that these genes play a significant role in three pathways: PI3K-Akt signaling pathway, Human papillomavirus infection, and Bacterial invasion of epithelial cells.In Conclusion, our study highlights the potential of machine learning in integrating bioinformatics for predicting TMB and patient survival in HNSC. The identified genes (KRT14, KRT6B, COL1A1, FN1, KRT6C) and related pathways may serve as potential biomarkers and therapeutic targets in HNSC treatment and prognosis.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {87},
numpages = {1},
keywords = {tumor mutational burden, survival, head and neck squamous cancer, machine learning, bioinformatics},
location = {Houston, TX, USA},
series = {BCB '23}
}

@inproceedings{10.1145/3654777.3676368,
author = {Tian, Yuan and Kummerfeld, Jonathan K. and Li, Toby Jia-Jun and Zhang, Tianyi},
title = {SQLucid: Grounding Natural Language Database Queries with Interactive Explanations},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676368},
doi = {10.1145/3654777.3676368},
abstract = {Though recent advances in machine learning have led to significant improvements in natural language interfaces for databases, the accuracy and reliability of these systems remain limited, especially in high-stakes domains. This paper introduces SQLucid, a novel user interface that bridges the gap between non-expert users and complex database querying processes. SQLucid addresses existing limitations by integrating visual correspondence, intermediate query results, and editable step-by-step SQL explanations in natural language to facilitate user understanding and engagement. This unique blend of features empowers users to understand and refine SQL queries easily and precisely. Two user studies and one quantitative experiment were conducted to validate SQLucid’s effectiveness, showing significant improvement in task completion accuracy and user confidence compared to existing interfaces. Our code is available at https://github.com/magic-YuanTian/SQLucid.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {12},
numpages = {20},
keywords = {Databases, Explanations, Natural Language Interfaces},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3597503.3639142,
author = {Liu, Zhongxin and Tang, Zhijie and Zhang, Junwei and Xia, Xin and Yang, Xiaohu},
title = {Pre-training by Predicting Program Dependencies for Vulnerability Analysis Tasks},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639142},
doi = {10.1145/3597503.3639142},
abstract = {Vulnerability analysis is crucial for software security. Inspired by the success of pre-trained models on software engineering tasks, this work focuses on using pre-training techniques to enhance the understanding of vulnerable code and boost vulnerability analysis. The code understanding ability of a pre-trained model is highly related to its pre-training objectives. The semantic structure, e.g., control and data dependencies, of code is important for vulnerability analysis. However, existing pre-training objectives either ignore such structure or focus on learning to use it. The feasibility and benefits of learning the knowledge of analyzing semantic structure have not been investigated. To this end, this work proposes two novel pre-training objectives, namely Control Dependency Prediction (CDP) and Data Dependency Prediction (DDP), which aim to predict the statement-level control dependencies and token-level data dependencies, respectively, in a code snippet only based on its source code. During pre-training, CDP and DDP can guide the model to learn the knowledge required for analyzing fine-grained dependencies in code. After pre-training, the pre-trained model can boost the understanding of vulnerable code during fine-tuning and can directly be used to perform dependence analysis for both partial and complete functions. To demonstrate the benefits of our pre-training objectives, we pre-train a Transformer model named PDBERT with CDP and DDP, fine-tune it on three vulnerability analysis tasks, i.e., vulnerability detection, vulnerability classification, and vulnerability assessment, and also evaluate it on program dependence analysis. Experimental results show that PDBERT benefits from CDP and DDP, leading to state-of-the-art performance on the three downstream tasks. Also, PDBERT achieves F1-scores of over 99% and 94% for predicting control and data dependencies, respectively, in partial and complete functions.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {151},
numpages = {13},
keywords = {source code pre-training, program dependence analysis, vulnerability detection, vulnerability classification, vulnerability assessment},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3584202.3584248,
author = {Kurolov, Maksud Obitovich},
title = {A systematic mapping study of using digital marketing technologies in health care: the state of the art of digital healthcare marketing},
year = {2023},
isbn = {9781450399050},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584202.3584248},
doi = {10.1145/3584202.3584248},
abstract = {People are getting smarter and more selective to use quality healthcare services concerning with sustainability of their mental and physical health. Understanding the behavioral patterns of those smart customers requires careful consideration of digital marketing strategies so that healthcare businesses can maximize the awareness and loyalty of the customers for their healthcare service. Thus, updating the digital healthcare marketing plan with current advances in digital healthcare marketing research becomes a key commitment of health care business managers who must implement adequate healthcare marketing strategies for the sustainability and survival of their business in highly changing and fiercely competitive health care markets. This study aims to systematize the literature of digital healthcare marketing through content taxonomy and logical generalization, thereby addressing the current state of the art. Relevant studies from four academic databases were reviewed, analyzed, and categorized concerning research questions. The research findings highlight connected and cognitive devices and blockchain as the most common categories of the usage of digital marketing technologies in human care services. The systematic mapping study proves that digital marketing is today an integral part of the promotion of medical business in the network, revealing the future research directions where insufficient understanding of the correct use of the cutting-edge technology applications such as artificial intelligence exists.},
booktitle = {Proceedings of the 6th International Conference on Future Networks &amp; Distributed Systems},
pages = {318–323},
numpages = {6},
location = {Tashkent, TAS, Uzbekistan},
series = {ICFNDS '22}
}

@article{10.1145/3616385,
author = {Balaji, Bharathan and Vunnava, Venkata Sai Gargeya and Domingo, Nina and Gupta, Shikhar and Gupta, Harsh and Guest, Geoffrey and Srinivasan, Aravind},
title = {Flamingo: Environmental Impact Factor Matching for Life Cycle Assessment with Zero-shot Machine Learning},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
url = {https://doi.org/10.1145/3616385},
doi = {10.1145/3616385},
abstract = {Consumer products contribute to more than 75% of global greenhouse gas (GHG) emissions, primarily through indirect contributions from the supply chain. Measurement of GHG emissions associated with products is a crucial step toward quantifying the impact of GHG emission abatement actions. Life cycle assessment (LCA), the scientific discipline for measuring GHG emissions, estimates the environmental impact associated with each stage of a product from raw material extraction to its disposal. Scaling LCA to millions of products is challenging as it requires extensive manual analysis by domain experts. To avoid repetitive analysis, environmental impact factors (EIFs) of common materials and products are published for use by LCA experts. However, finding appropriate EIFs for even a single product under study can require hundreds of hours of manual work, especially for complex products. We present Flamingo, an algorithm that leverages natural language machine learning (ML) models to automatically identify an appropriate EIF given a text description. A key challenge in automation is that EIF databases are incomplete. Flamingo uses industry sector classification as an intermediate layer to identify when there are no good matches in the database. On a dataset of 664 products, our method achieves an EIF matching precision of 75%.},
journal = {ACM J. Comput. Sustain. Soc.},
month = dec,
articleno = {11},
numpages = {23},
keywords = {Environmental impact factor, life cycle assessment, carbon footprint, semantic matching, natural language processing, HS codes, Flamingo}
}

@inproceedings{10.1145/3569551.3569561,
author = {Rahman, Md. Atiqur and Islam, A. B. M. Alim Al},
title = {Cri-Astrologer: Predicting Demography of Involved Criminals based on Historical Data},
year = {2022},
isbn = {9781450399036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569551.3569561},
doi = {10.1145/3569551.3569561},
abstract = {Because of the rapid advancement in computer technology, police enforcement agencies are now able to keep enormous databases that contain specific information about crimes. These databases can be utilized to analyze crime patterns, criminal characteristics, and the demographics of both criminals and victims. Through the application of various machine learning algorithms to these datasets, it is possible to generate decision-aid systems that can assist in the conduct of police investigations. When there is a large amount of data accessible, several data-driven deep learning approaches can also be utilized. Within the scope of this investigation, our primary objective is to create a tool that may be utilized during the standard investigative process. To forecast criminal demographic profiles using crime evidence data and victim demographics, we present a deep factorization machine-based DNN architecture. We evaluate the performance of our architecture in comparison to that of traditional machine learning algorithms and deep learning algorithms, and we provide our findings in a comparative study.},
booktitle = {Proceedings of the 9th International Conference on Networking, Systems and Security},
pages = {92–102},
numpages = {11},
keywords = {criminal profiling, datasets, deep learning},
location = {Cox's Bazar, Bangladesh},
series = {NSysS '22}
}

@inproceedings{10.1109/ICSE48619.2023.00181,
author = {Mastropaolo, Antonio and Pascarella, Luca and Guglielmi, Emanuela and Ciniselli, Matteo and Scalabrino, Simone and Oliveto, Rocco and Bavota, Gabriele},
title = {On the Robustness of Code Generation Techniques: An Empirical Study on GitHub Copilot},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00181},
doi = {10.1109/ICSE48619.2023.00181},
abstract = {Software engineering research has always being concerned with the improvement of code completion approaches, which suggest the next tokens a developer will likely type while coding. The release of GitHub Copilot constitutes a big step forward, also because of its unprecedented ability to automatically generate even entire functions from their natural language description. While the usefulness of Copilot is evident, it is still unclear to what extent it is robust. Specifically, we do not know the extent to which semantic-preserving changes in the natural language description provided to the model have an effect on the generated code function. In this paper we present an empirical study in which we aim at understanding whether different but semantically equivalent natural language descriptions result in the same recommended function. A negative answer would pose questions on the robustness of deep learning (DL)-based code generators since it would imply that developers using different wordings to describe the same code would obtain different recommendations. We asked Copilot to automatically generate 892 Java methods starting from their original Javadoc description. Then, we generated different semantically equivalent descriptions for each method both manually and automatically, and we analyzed the extent to which predictions generated by Copilot changed. Our results show that modifying the description results in different code recommendations in ~46% of cases. Also, differences in the semantically equivalent descriptions might impact the correctness of the generated code (±28%).},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {2149–2160},
numpages = {12},
keywords = {empirical study, recommender systems},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3635138.3654762,
author = {Arenas, Marcelo},
title = {A Data Management Approach to Explainable AI},
year = {2024},
isbn = {9798400704833},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635138.3654762},
doi = {10.1145/3635138.3654762},
abstract = {In recent years, there has been a growing interest in developing methods to explain individual predictions made by machine learning models. This has led to the development of various notions of explanation and scores to justify a model's classification. However, instead of struggling with the increasing number of such notions, one can turn to an old tradition in databases and develop a declarative query language for interpretability tasks, which would allow users to specify and test their own explainability queries. Not surprisingly, logic is a suitable declarative language for this task, as it has a well-understood syntax and semantics, and there are many tools available to study its expressiveness and the complexity of the query evaluation problem. In this talk, we will discuss some recent work on developing such a logic for model interpretability.},
booktitle = {Companion of the 43rd Symposium on Principles of Database Systems},
pages = {1–3},
numpages = {3},
keywords = {explainability language, explainable artificial intelligence, query language},
location = {Santiago AA, Chile},
series = {PODS '24}
}

@article{10.1145/3643732,
author = {Zhang, Yifan and Li, Jiliang and Karas, Zachary and Bansal, Aakash and Li, Toby Jia-Jun and McMillan, Collin and Leach, Kevin and Huang, Yu},
title = {EyeTrans: Merging Human and Machine Attention for Neural Code Summarization},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643732},
doi = {10.1145/3643732},
abstract = {Neural code summarization leverages deep learning models to automatically generate brief natural language summaries of code snippets. The development of Transformer models has led to extensive use of attention during model design. While existing work has primarily and almost exclusively focused on static properties of source code and related structural representations like the Abstract Syntax Tree (AST), few studies have considered human attention — that is, where programmers focus while examining and comprehending code. In this paper, we develop a method for incorporating human attention into machine attention to enhance neural code summarization. To facilitate this incorporation and vindicate this hypothesis, we introduce EyeTrans, which consists of three steps: (1) we conduct an extensive eye-tracking human study to collect and pre-analyze data for model training, (2) we devise a data-centric approach to integrate human attention with machine attention in the Transformer architecture, and (3) we conduct comprehensive experiments on two code summarization tasks to demonstrate the effectiveness of incorporating human attention into Transformers. Integrating human attention leads to an improvement of up to 29.91% in Functional Summarization and up to 6.39% in General Code Summarization performance, demonstrating the substantial benefits of this combination. We further explore performance in terms of robustness and efficiency by creating challenging summarization scenarios in which EyeTrans exhibits interesting properties. We also visualize the attention map to depict the simplifying effect of machine attention in the Transformer by incorporating human attention. This work has the potential to propel AI research in software engineering by introducing more human-centered approaches and data.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {6},
numpages = {22},
keywords = {Code Summarization, Eye-tracking, Human Attention, Machine Attention, Transformer}
}

@article{10.14778/3594512.3594516,
author = {Augustine, Eriq and Getoor, Lise},
title = {Collective Grounding: Applying Database Techniques to Grounding Templated Models},
year = {2023},
issue_date = {April 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {8},
issn = {2150-8097},
url = {https://doi.org/10.14778/3594512.3594516},
doi = {10.14778/3594512.3594516},
abstract = {The process of instantiating, or "grounding", a first-order model is a fundamental component of reasoning in logic. It has been widely studied in the context of theorem proving, database theory, and artificial intelligence. Within the relational learning community, the concept of grounding has been expanded to apply to models that use more general templates in the place of first-order logical formulae. In order to perform inference, grounding of these templates is required for instantiating a distribution over possible worlds. However, because of the complex data dependencies stemming from instantiating generalized templates with interconnected data, grounding is often the key computational bottleneck to relational learning. While we motivate our work in the context of relational learning, similar issues arise in probabilistic databases, particularly those that do not make strong tuple independence assumptions. In this paper, we investigate how key techniques from relational database theory can be utilized to improve the computational efficiency of the grounding process. We introduce the notion of collective grounding which treats logical programs not as a collection of independent rules, but instead as a joint set of interdependent workloads that can be shared. We introduce the theoretical concept of collective grounding, the components necessary in a collective grounding system, implementations of these components, and show how to use database theory to speed up these components. We demonstrate collective groundings effectiveness on seven popular datasets, and show up to a 70% reduction in runtime using collective grounding. Our results are fully reproducible and all code, data, and experimental scripts are included.},
journal = {Proc. VLDB Endow.},
month = apr,
pages = {1843–1855},
numpages = {13}
}

@article{10.1145/3569934,
author = {Gong, Lina and Zhang, Jingxuan and Wei, Mingqiang and Zhang, Haoxiang and Huang, Zhiqiu},
title = {What Is the Intended Usage Context of This Model? An Exploratory Study of Pre-Trained Models on Various Model Repositories},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3569934},
doi = {10.1145/3569934},
abstract = {There is a trend of researchers and practitioners to directly apply pre-trained models to solve their specific tasks. For example, researchers in software engineering (SE) have successfully exploited the pre-trained language models to automatically generate the source code and comments. However, there are domain gaps in different benchmark datasets. These data-driven (or machine learning based) models trained on one benchmark dataset may not operate smoothly on other benchmarks. Thus, the reuse of pre-trained models introduces large costs and additional problems of checking whether arbitrary pre-trained models are suitable for the task-specific reuse or not. To our knowledge, software engineers can leverage code contracts to maximize the reuse of existing software components or software services. Similar to the software reuse in the SE field, reuse SE could be extended to the area of pre-trained model reuse. Therefore, according to the model card’s and FactSheet’s guidance for suppliers of pre-trained models on what information they should be published, we propose model contracts including the pre- and post-conditions of pre-trained models to enable better model reuse. Furthermore, many non-trivial yet challenging issues have not been fully investigated, although many pre-trained models are readily available on the model repositories. Based on our model contract, we conduct an exploratory study of 1908 pre-trained models on six mainstream model repositories (i.e., the TensorFlow Hub, PyTorch Hub, Model Zoo, Wolfram Neural Net Repository, Nvidia, and Hugging Face) to investigate the gap between necessary pre- and post-condition information and actual specifications. Our results clearly show that (1) the model repositories tend to provide confusing information of the pre-trained models, especially the information about the task’s type, model, training set, and (2) the model repositories cannot provide all of our proposed pre/post-condition information, especially the intended use, limitation, performance, and quantitative analysis. On the basis of our new findings, we suggest that (1) the developers of model repositories shall provide some necessary options (e.g., the training dataset, model algorithm, and performance measures) for each of pre/post-conditions of pre-trained models in each task type, (2) future researchers and practitioners provide more efficient metrics to recommend suitable pre-trained model, and (3) the suppliers of pre-trained models should report their pre-trained models in strict accordance with our proposed pre/post-condition and report their models according to the characteristics of each condition that has been reported in the model repositories.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {69},
numpages = {57},
keywords = {Software engineering for artificial intelligence, pre-trained models, model reuse, model contract}
}

@inproceedings{10.1145/3589883.3589888,
author = {Qorib, Miftahul and Gizaw, Rahel S and Kim, Junwhan},
title = {Impact of Sentiment Analysis for the 2020 U.S. Presidential Election on Social Media Data},
year = {2023},
isbn = {9781450398329},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589883.3589888},
doi = {10.1145/3589883.3589888},
abstract = {The increased number of social media platforms allows different groups of people around the globe to express their thoughts and sentiments on such media. Such ideas and opinions might implicate the user's social and political perspectives. Those perspectives are subject-specific inputs that have been useful to data science researchers to do community detection and sentiment analysis studies. Research studies utilize the rich information from social media, such as Twitter, to gain a better knowledge of public opinion in societies. In our study, we proposed a machine learning-based algorithm to predict and classify the textual data from Twitter about the 2020 US election campaign. The opinion poll of the presidential elections might be inaccurate or bias, resulting in providing significant negative effects with voters. The dataset was collected during the 2020 presidential election campaign toward the voting day. In addition to the original tweets, we generated fake tweets added to the dataset. Before organizing the comprehensive data and validation, we have done data cleaning and screening to get a reasonable and sensible correlation. For comparison, we used a total of five classification algorithms, such as Linear Support Vector Classification (LSVC), Random Forest (RF), Decision Tree (DT), Logistic Regression, and Naive Bayes. The study found that Trump was more popular than Biden on Twitter. Even though he was more famous than his rival, the study suggested that Joe Biden has a higher average percentage of positive sentiments than Donald Trump nationally. On the other hand, Donald Trump has a higher average percentage of negative sentiments than Joe Biden. In favor of Joe Biden compared to Donald Trump during the 2020 US presidential election, which led to the prediction that Joe Biden would outperform Donald Trump in the 2020 election. Furthermore, adding fake tweets into the dataset has slightly decreased Naive Bayes, Decision Tree, and LinearSVC model performances, but it slightly improved the Logistics Regression model classifier. Retrospectively, the Twitter data could have successfully predicted the US presidential election outcome by factoring in the proportion of positive and negative sentiment for the leading candidates. The study concludes that social media data-based sentiment analysis provides an accurate prediction model for American presidential elections.},
booktitle = {Proceedings of the 2023 8th International Conference on Machine Learning Technologies},
pages = {28–34},
numpages = {7},
keywords = {2020 U.S. Election, Fake Tweet, Predicting Election, Twitter},
location = {Stockholm, Sweden},
series = {ICMLT '23}
}

@article{10.1109/TCBB.2022.3197320,
author = {Ye, Cheng and Swiers, Rowan and Bonner, Stephen and Barrett, Ian},
title = {A Knowledge Graph-Enhanced Tensor Factorisation Model for Discovering Drug Targets},
year = {2022},
issue_date = {Nov.-Dec. 2022},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {19},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2022.3197320},
doi = {10.1109/TCBB.2022.3197320},
abstract = {The drug discovery and development process is a long and expensive one, costing over 1 billion USD on average per drug and taking 10-15 years. To reduce the high levels of attrition throughout the process, there has been a growing interest in applying machine learning methodologies to various stages of drug discovery and development in the recent decade, especially at the earliest stage – identification of druggable disease genes. In this paper, we have developed a new tensor factorisation model to predict potential drug targets (genes or proteins) for treating diseases. We created a three-dimensional data tensor consisting of 1,048 gene targets, 860 diseases and 230,011 evidence attributes and clinical outcomes connecting them, using data extracted from the Open Targets and PharmaProjects databases. We enriched the data with gene target representations learned from a drug discovery-oriented knowledge graph and applied our proposed method to predict the clinical outcomes for unseen gene target and disease pairs. We designed three evaluation strategies to measure the prediction performance and benchmarked several commonly used machine learning classifiers together with Bayesian matrix and tensor factorisation methods. The result shows that incorporating knowledge graph embeddings significantly improves the prediction accuracy and that training tensor factorisation alongside a dense neural network outperforms all other baselines. In summary, our framework combines two actively studied machine learning approaches to disease target identification, namely tensor factorisation and knowledge graph representation learning, which could be a promising avenue for further exploration in data-driven drug discovery.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = aug,
pages = {3070–3080},
numpages = {11}
}

@article{10.5555/3648699.3648804,
author = {Fatemi, Bahare and Taslakian, Perouz and Vazquez, David and Poole, David},
title = {Knowledge hypergraph embedding meets relational algebra},
year = {2023},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {Relational databases are a successful model for data storage, and rely on query languages for information retrieval. Most of these query languages are based on relational algebra, a mathematical formalization at the core of relational models. Knowledge graphs are flexible data storage structures that allow for knowledge completion using machine learning techniques. Knowledge hypergraphs generalize knowledge graphs by allowing multi-argument relations. This work studies knowledge hypergraph completion through the lens of relational algebra and its core operations. We explore the space between relational algebra foundations and machine learning techniques for knowledge completion. We investigate whether such methods can capture high-level abstractions in terms of relational algebra operations. We propose a simple embedding-based model called Relational Algebra Embedding (ReAlE) that performs link prediction in knowledge hypergraphs. We show theoretically that ReAlE is fully expressive and can represent the relational algebra operations of renaming, projection, set union, selection, and set difference. We verify experimentally that ReAlE outperforms state-of-the-art models in knowledge hypergraph completion, and in representing each of these primitive relational algebra operations. For the latter experiment, we generate a synthetic knowledge hypergraph, for which we design an algorithm based on the Erd\H{o}s-R\'{e}nyi model for generating random graphs.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {105},
numpages = {34},
keywords = {knowledge hypergraphs, relational algebra, knowledge hypergraph completion}
}

@inproceedings{10.1145/3703847.3703865,
author = {Zhang, Yiyuan},
title = {Systematic Evaluation of Machine Learning-Based Predictive Model for Diabetes},
year = {2024},
isbn = {9798400709746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703847.3703865},
doi = {10.1145/3703847.3703865},
abstract = {The paper aims to systematically evaluate the prediction model for diabetes based on machine learning (ML). It conducted literature research in Baidu Scholar, National Library of China, Web of Weipu, CNKI, and Wanfang databases for literature on prediction models for diabetes constructed by ML, and the search period spanned from January 2018 to February 2023. The paper completed literature screening and data extraction independently and used predictive models to construct a research data extraction and quality evaluation checklist (CHARMS) to evaluate the quality of the included literature and screened high-quality literature for discussion. Results: A total of 13 high-quality studies were collected, including 5 ML models, with an area under the ROC curve ranging from 0.720 to 0.97. Laboratory indicators such as age, BMI, blood sugar concentration, waistline, and diabetes history are the main predictive factors. Conclusions: Diabetes prediction models constructed using ML can accurately identify the risk of diabetes, and their predictive performance is superior to traditional risk prediction models. The available literature on the topic exhibits a low overall risk of bias, however, the applicability level of the prediction model is considered average.},
booktitle = {Proceedings of the 2024 International Conference on Smart Healthcare and Wearable Intelligent Devices},
pages = {99–103},
numpages = {5},
keywords = {Diabetes, Machine Learning, Prediction Model},
location = {
},
series = {SHWID '24}
}

@inproceedings{10.1145/3627535.3638478,
author = {Li, Yifei and Zhou, Bole and Zhang, Jiejing and Wei, Xuechao and Li, Yinghan and Chen, Yingda},
title = {POSTER: RadiK: Scalable Radix Top-K Selection on GPUs},
year = {2024},
isbn = {9798400704352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627535.3638478},
doi = {10.1145/3627535.3638478},
abstract = {By identifying the k largest or smallest elements in a set of data, top-k selection is critical for modern high-performance databases and machine learning systems, especially with large data volumes. However, previous studies on its GPU implementation are mostly merge-based and rely heavily on the high-speed but size-limited on-chip memory, thereby resulting in a restricted upper bound on k. This paper introduces RadiK, a highly optimized GPU-parallel radix top-k selection that is scalable with k, input length, and batch size. With a carefully designed optimization framework targeting high memory bandwidth and resource utilization, RadiK supports far larger k than the prior art, achieving up to 2.5\texttimes{} speedup for non-batch queries and up to 4.8\texttimes{} speedup for batch queries. We also propose a lightweight refinement that strengthens the robustness of RadiK against skewed distributions by adaptively scaling the input elements.},
booktitle = {Proceedings of the 29th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming},
pages = {472–474},
numpages = {3},
keywords = {Top-K, radix select, GPU-parallel algorithm},
location = {Edinburgh, United Kingdom},
series = {PPoPP '24}
}

@article{10.1145/3694782,
author = {Lin, Ruyan and Fu, Yulong and Yi, Wei and Yang, Jincheng and Cao, Jin and Dong, Zhiqiang and Xie, Fei and Li, Hui},
title = {Vulnerabilities and Security Patches Detection in OSS: A Survey},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3694782},
doi = {10.1145/3694782},
abstract = {Over the past decade, Open Source Software (OSS) has experienced rapid growth and widespread adoption, attributed to its openness and editability. However, this expansion has also brought significant security challenges, particularly introducing and propagating software vulnerabilities. Despite the use of machine learning and formal methods to tackle these issues, there remains a notable gap in comprehensive surveys that summarize and analyze both Vulnerability Detection (VD) and Security Patch Detection (SPD) in OSS. This article seeks to bridge this gap through an extensive survey that evaluates 127 technical studies published between 2014 and 2023, structured around the Vulnerability-Patch lifecycle. We begin by delineating the six critical events that constitute the Vulnerability-Patch lifecycle, leading to an in-depth exploration of the Vulnerability-Patch ecosystem. We then systematically review the databases commonly used in VD and SPD, and analyze their characteristics. Subsequently, we examine existing VD methods, focusing on traditional and deep learning based approaches. Additionally, we organize current security patch identification methods by kernel type and discuss techniques for detecting the presence of security patches. Based on our comprehensive review, we identify open research questions and propose future research directions that merit further exploration.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {23},
numpages = {37},
keywords = {Open source software, vulnerability detection, security patch detection, software security, AI security}
}

@article{10.1145/3583067,
author = {Govers, Jarod and Feldman, Philip and Dant, Aaron and Patros, Panos},
title = {Down the Rabbit Hole: Detecting Online Extremism, Radicalisation, and Politicised Hate Speech},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {14s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3583067},
doi = {10.1145/3583067},
abstract = {Social media is a modern person’s digital voice to project and engage with new ideas and mobilise communities—a power shared with extremists. Given the societal risks of unvetted content-moderating algorithms for Extremism, Radicalisation, and Hate speech (ERH) detection, responsible software engineering must understand the who, what, when, where, and why such models are necessary to protect user safety and free expression. Hence, we propose and examine the unique research field of ERH context mining to unify disjoint studies. Specifically, we evaluate the start-to-finish design process from socio-technical definition-building and dataset collection strategies to technical algorithm design and performance. Our 2015–2021 51-study Systematic Literature Review (SLR) provides the first cross-examination of textual, network, and visual approaches to detecting extremist affiliation, hateful content, and radicalisation towards groups and movements. We identify consensus-driven ERH definitions and propose solutions to existing ideological and geographic biases, particularly due to the lack of research in Oceania/Australasia. Our hybridised investigation on Natural Language Processing, Community Detection, and visual-text models demonstrates the dominating performance of textual transformer-based algorithms. We conclude with vital recommendations for ERH context mining researchers and propose an uptake roadmap with guidelines for researchers, industries, and governments to enable a safer cyberspace.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {319},
numpages = {35},
keywords = {Extremism, radicalisation, machine learning, community detection, Natural Language Processing, neural networks, hate speech, sociolinguistics}
}

@inproceedings{10.1145/3665689.3665757,
author = {Liu, Yang and Chen, Teng},
title = {Identification of Key Genes in the Colorectal Cancer Immune Microenvironment Through Integrated Analysis of Immune Infiltration Algorithms and Single-Cell Transcriptomics},
year = {2024},
isbn = {9798400716645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665689.3665757},
doi = {10.1145/3665689.3665757},
abstract = {Objective: This study aims to employ bioinformatics methods and single-cell sequencing technology to identify and analyze characteristic genes of the immune microenvironment in colorectal cancer (CRC), deepening the understanding of CRC pathogenesis and providing new perspectives and potential targets for personalized immunotherapy. Methods: We used single-sample gene set enrichment analysis (ssGSEA) to identify common differentially infiltrating immune cells from the TCGA and GEO databases. Employing two machine learning algorithms, we selected key immune cell subgroups with significant impact in normal and CRC tissues, playing vital roles in the CRC immune microenvironment. We then applied weighted gene co-expression network analysis (WGCNA) in the GEO and TCGA cohorts to identify gene modules significantly related to seven immune cell types. Using the single-cell sequencing dataset GSE225857, we extracted differentially expressed genes within key immune cell subgroups and integrated them with important WGCNA modules to identify key immune predictive genes. An immune-related analysis of these key genes was conducted to explore their potential as characteristic genes of the CRC immune microenvironment. Results: Through ssGSEA and the selection of 28 immune infiltration scores by two machine learning algorithms, we identified seven key immune cells impacting the CRC immune microenvironment: activated B cells, activated CD4 T cells, effector memory CD4 T cells, mast cells, memory B cells, bright natural killer cells, and natural killer T cells. Combined single-cell transcriptomics and WGCNA analysis revealed that Regulator of G Protein Signaling 1 (RGS1) varied in expression among different immune cell subtypes and was included in the WGCNA immune-related module. Immune-related analysis of RGS1 indicated its high expression in immune cell subtypes, along with high tumor microenvironment (TME) scores and high immune function scores. Furthermore, RGS1 expression correlated with various immune function scores (such as Type II IFN Response, APC co-inhibition, MHC class I), indicating its multifaceted role in the CRC immune microenvironment. Conclusion: This study identified key immune cell subgroups impacting the CRC immune microenvironment, with RGS1 emerging as a significant regulatory factor. RGS1 may play a critical role in modulating immune responses, influencing tumor immune evasion mechanisms, and drug sensitivity. Therefore, targeting RGS1 may provide a new strategic direction for CRC immunotherapy.},
booktitle = {Proceedings of the 2024 4th International Conference on Bioinformatics and Intelligent Computing},
pages = {408–413},
numpages = {6},
location = {Beijing, China},
series = {BIC '24}
}

@inproceedings{10.1145/3611643.3616291,
author = {Gao, Haoyu and Treude, Christoph and Zahedi, Mansooreh},
title = {Evaluating Transfer Learning for Simplifying GitHub READMEs},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616291},
doi = {10.1145/3611643.3616291},
abstract = {Software documentation captures detailed knowledge about a software product, e.g., code, technologies, and design. It plays an important role in the coordination of development teams and in conveying ideas to various stakeholders. However, software documentation can be hard to comprehend if it is written with jargon and complicated sentence structure. In this study, we explored the potential of text simplification techniques in the domain of software engineering to automatically simplify GitHub README files. We collected software-related pairs of GitHub README files consisting of 14,588 entries, aligned difficult sentences with their simplified counterparts, and trained a Transformer-based model to automatically simplify difficult versions. To mitigate the sparse and noisy nature of the software-related simplification dataset, we applied general text simplification knowledge to this field. Since many general-domain difficult-to-simple Wikipedia document pairs are already publicly available, we explored the potential of transfer learning by first training the model on the Wikipedia data and then fine-tuning it on the README data. Using automated BLEU scores and human evaluation, we compared the performance of different transfer learning schemes and the baseline models without transfer learning. The transfer learning model using the best checkpoint trained on a general topic corpus achieved the best performance of 34.68 BLEU score and statistically significantly higher human annotation scores compared to the rest of the schemes and baselines. We conclude that using transfer learning is a promising direction to circumvent the lack of data and drift style problem in software README files simplification and achieved a better trade-off between simplification and preservation of meaning.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1548–1560},
numpages = {13},
keywords = {GitHub, Software Documentation, Text Simplification, Transfer Learning},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3539618.3591773,
author = {Yuan, Ye and Ma, Delong and Wu, Anbiao and Qin, Jianbin},
title = {Subgraph Search over Neural-Symbolic Graphs},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591773},
doi = {10.1145/3539618.3591773},
abstract = {In this paper, we propose neural-symbolic graph databases (NSGDs) that extends traditional graph data with content and structural embeddings in every node. The content embeddings can represent unstructured data (e.g., images, videos, and texts), while structural embeddings can be used to deal with incomplete graphs. We can advocate machine learning models (e.g., deep learning) to transform unstructured data and graph nodes to these embeddings. NSGDs can support a wide range of applications (e.g., online recommendation and natural language question answering) in social-media networks, multi-modal knowledge graphs and etc. As a typical search over graphs, we study subgraph search over a large NSGD, called neural-symbolic subgraph matching (NSMatch) that includes a novel ranking search function. Specifically, we develop a general algorithmic framework to process NSMatch efficiently. Using real-life multi-modal graphs, we experimentally verify the effectiveness, scalability and efficiency of NSMatch.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {612–621},
numpages = {10},
keywords = {embedding, neural-symbolic, subgraph search},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3627673.3679700,
author = {Chen, Haitian and Chen, Xu and Liang, Zibo and Feng, Xiushi and Xie, Jiandong and Su, Han and Zheng, Kai},
title = {Towards Online and Safe Configuration Tuning with Semi-supervised Anomaly Detection},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679700},
doi = {10.1145/3627673.3679700},
abstract = {The performance of modern database management systems highly relies on hundreds of adjustable knobs. Traditionally, these knobs are manually adjusted by database administrators, a process that is both inefficient and ineffective for tuning large-scale databases in cloud environments. Recent research has explored the use of machine learning techniques to enable the automatic tuning of database configurations. Although most existing learning-based methods achieve satisfactory results on static workloads, they often experience performance degradation and low sampling efficiency in real-world environments. According to our study, this is primarily due to a lack of safety guarantees during the configuration sampling process. To address the aforementioned issues, we propose SafeTune, an online tuning system that adapts to dynamic workloads. Our core idea is to filter out a large number of configurations with potential risks during the configuration sampling process. We employ a two-stage filtering approach: The first stage utilizes a semi-supervised outlier ensemble with feature learning to achieve high-quality feature representation. The second stage employs a ranking-based classifier to refine the filtering process. In addition, to alleviate the cold-start problem, we leverage the historical tuning experience to provide high-quality initial samples during the initialization phase. We conducted comprehensive evaluations on static and dynamic workloads. In comparison to offline baseline methods, SafeTune reduces 95.6%-98.6% unsafe configuration suggestions. In contrast with state-of-the-art methods, SafeTune has improved cumulative performance by 10.5%-46.6% and tuning speed by 15.1%-35.4%.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {218–227},
numpages = {10},
keywords = {cloud database, configuration tuning, online tuning, safety},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3491211,
author = {Uddin, Gias and Gu\'{e}h\'{e}nuc, Yann-Ga\"{e}l and Khomh, Foutse and Roy, Chanchal K.},
title = {An Empirical Study of the Effectiveness of an Ensemble of Stand-alone Sentiment Detection Tools for Software Engineering Datasets},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3491211},
doi = {10.1145/3491211},
abstract = {Sentiment analysis in software engineering (SE) has shown promise to analyze and support diverse development activities. Recently, several tools are proposed to detect sentiments in software artifacts. While the tools improve accuracy over off-the-shelf tools, recent research shows that their performance could still be unsatisfactory. A more accurate sentiment detector for SE can help reduce noise in analysis of software scenarios where sentiment analysis is required. Recently, combinations, i.e., hybrids of stand-alone classifiers are found to offer better performance than the stand-alone classifiers for fault detection. However, we are aware of no such approach for sentiment detection for software artifacts. We report the results of an empirical study that we conducted to determine the feasibility of developing an ensemble engine by combining the polarity labels of stand-alone SE-specific sentiment detectors. Our study has two phases. In the first phase, we pick five SE-specific sentiment detection tools from two recently published papers by Lin et&nbsp;al.&nbsp;[29, 30], who first reported negative results with stand alone sentiment detectors and then proposed an improved SE-specific sentiment detector, POME&nbsp;[29]. We report the study results on 17,581 units (sentences/documents) coming from six currently available sentiment benchmarks for software engineering. We find that the existing tools can be complementary to each other in 85-95% of the cases, i.e., one is wrong but another is right. However, a majority voting-based ensemble of those tools fails to improve the accuracy of sentiment detection. We develop Sentisead, a supervised tool by combining the polarity labels and bag of words as features. Sentisead improves the performance (F1-score) of the individual tools by 4% (over Senti4SD&nbsp;[5]) – 100% (over POME&nbsp;[29]). The initial development of Sentisead occurred before we observed the use of deep learning models for SE-specific sentiment detection. In particular, recent papers show the superiority of advanced language-based pre-trained transformer models (PTM) over rule-based and shallow learning models. Consequently, in a second phase, we compare and improve Sentisead infrastructure using the PTMs. We find that a Sentisead infrastructure with RoBERTa as the ensemble of the five stand-alone rule-based and shallow learning SE-specific tools from Lin et&nbsp;al.&nbsp;[29, 30] offers the best F1-score of 0.805 across the six datasets, while a stand-alone RoBERTa shows an F1-score of 0.801.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {48},
numpages = {38},
keywords = {Sentiment analysis, machine learning, ensemble classifier}
}

@inproceedings{10.1145/3478432.3499054,
author = {Meysenburg, Mark M.},
title = {The CCLA: Cultivating a Culture of Computing at a Small Liberal Arts University},
year = {2022},
isbn = {9781450390712},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3478432.3499054},
doi = {10.1145/3478432.3499054},
abstract = {The Doane University Center for Computing in the Liberal Arts (CCLA) provides a collaborative and supportive environment for Doane students, faculty, and staff, who are interested in incorporating computing into their schoolwork, projects, or research. Our operating analogy is that the CCLA is like a Writing Center, but for computing instead of prose. Ultimately, the CCLA aims to foster a culture of computing at Doane -- all of Doane. Therefore, the CCLA supports any academic discipline on campus: STEM disciplines, Business, Art, Social Sciences, Theater, and so on. Likewise, the CCLA supports a wide range of computing skills, from spreadsheets and word processing through databases and programming and into more advanced technologies such as machine learning and high-performance computing. The CCLA's mission is to be available to help any student, faculty, or staff member with any computer-related problem-solving task. Creating this culture of computing at the university will help equip our students with the computing skills necessary to become outstanding contributors and leaders in both the public and private sectors.},
booktitle = {Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 2},
pages = {1080},
numpages = {1},
keywords = {education resources, undergraduate education, workforce development},
location = {Providence, RI, USA},
series = {SIGCSE 2022}
}

@article{10.1145/3583743,
author = {Zhang, Brian J. and Fitter, Naomi T.},
title = {Nonverbal Sound in Human-Robot Interaction: A Systematic Review},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
url = {https://doi.org/10.1145/3583743},
doi = {10.1145/3583743},
abstract = {Nonverbal sound offers great potential to enhance robots’ interactions with humans, and a growing body of research has begun to explore nonverbal sound for tasks such as sound source localization, explicit communication, and improving sociability. However, nonverbal sound has a broad interpretation and design space that can draw from areas such as machine learning, music theory, and foley. We sought to identify and compare use cases and approaches for nonverbal sound in human-robot interaction through a systematic review. A search of sound and robotics-related publisher databases yielded 148 peer-reviewed articles presenting systems, studies, and taxonomies. Differences in taxonomy and overlap of terminology with adjacent research fields such as speech, gaze, and gesture posed difficulties for the search, which we attempted to address through a multi-stage search process. Based on the reviewed articles, we developed a pair of taxonomies using scientific communication principles and analyzed study designs and measures for the creation of nonverbal robot sound. We discuss recommendations for the field, including the use of the new taxonomies; methods for design, generation, and validation; and paths for future research. Roboticists may benefit from incorporating nonverbal sound as a key component in multimodal human-robot interaction.},
journal = {J. Hum.-Robot Interact.},
month = dec,
articleno = {46},
numpages = {46},
keywords = {Nonverbal sound, human-robot interaction, systematic review}
}

@article{10.1145/3654994,
author = {Li, Jiajun and Lei, Runlin and Wang, Sibo and Wei, Zhewei and Ding, Bolin},
title = {Learning-based Property Estimation with Polynomials},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654994},
doi = {10.1145/3654994},
abstract = {The problem of estimating data properties using sampling frequency histograms has attracted extensive interest in the area of databases. The properties include the number of distinct values (NDV), entropy, and so on. In the field of databases, property estimation is fundamental to complex applications. For example, NDV estimation is the foundation of query optimization, and entropy estimation is the foundation of data compression. Among them, methods originating from statistics exhibit desirable theoretical guarantees but rely on specific assumptions about the distribution of data, resulting in poor performance in real-world applications. Learning-based methods, which use information from training data, are adaptable in the real world but often lack theoretical guarantees or explainability. In addition, a unified framework for estimating these frequency-based estimators with machine learning is lacking. Given the aforementioned challenges, it is natural to wonder if a unified framework with theoretical guarantees can be established for property estimation. The recent literature has presented theoretical studies that propose estimation frameworks based on polynomials. These studies also prove estimation errors with respect to the sample size. Motivated by the above polynomial estimation framework, we propose a learning-based estimation framework with polynomial approximation, which aims to learn the coefficients of the polynomial, providing theoretical guarantees to the learning framework. Through comprehensive experiments on both synthetic and real-world datasets for estimating various data properties like NDV, entropy, and power sum, our results show the superiority of our algorithms over previous estimators.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {148},
numpages = {27},
keywords = {entropy, learning, number of distinct values, polynomial, property estimation}
}

@article{10.1145/3597204,
author = {Liu, Xuanzhe and Gu, Diandian and Chen, Zhenpeng and Wen, Jinfeng and Zhang, Zili and Ma, Yun and Wang, Haoyu and Jin, Xin},
title = {Rise of Distributed Deep Learning Training in the Big Model Era: From a Software Engineering Perspective},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {6},
issn = {1049-331X},
url = {https://doi.org/10.1145/3597204},
doi = {10.1145/3597204},
abstract = {Deep learning (DL) has become a key component of modern software. In the “big model” era, the rich features of DL-based software (i.e., DL software) substantially rely on powerful DL models, e.g., BERT, GPT-3, and the recently emerging GPT-4, which are trained on the powerful cloud with large datasets. Hence, training effective DL models has become a vital stage in the whole software lifecycle. When training deep learning models, especially those big models, developers need to parallelize and distribute the computation and memory resources amongst multiple devices (e.g., a cluster of GPUs) in the training process, which is known as distributed deep learning training, or distributed training for short. However, the unique challenges that developers encounter in distributed training process have not been studied in the software engineering community. Given the increasingly heavy dependence of current DL-based software on distributed training, this paper aims to fill in the knowledge gap and presents the first comprehensive study on developers’ issues in distributed training. To this end, we focus on popular DL frameworks that support distributed training (including TensorFlow, PyTorch, Keras, and Horovod) and analyze 1,131 real-world developers’ issues about using these frameworks reported on Stack Overflow and GitHub. We construct a fine-grained taxonomy consisting of 30 categories regarding the fault symptoms and summarize common fix patterns for different symptoms. We find that: (1) many distributed-specific faults and non-distributed-specific faults inherently share the same fault symptoms, making it challenging to debug; (2) most of the fault symptoms have frequent fix patterns; (3) about half of the faults are related to system-level configurations. Based on the results, we suggest actionable implications on research avenues that can potentially facilitate the distributed training to develop DL-based software, such as focusing on the frequent and common fix patterns when designing testing or debugging tools, developing efficient testing and debugging techniques for communication configuration along with the synthesis of network configuration analysis, designing new multi-device checkpoint-and-replay techniques to help reproduction, and designing serverless APIs for cloud platforms.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {156},
numpages = {26},
keywords = {Empirical study, distributed training, software engineering}
}

@article{10.14778/3636218.3636235,
author = {Zhao, Yue and Li, Zhaodonghui and Cong, Gao},
title = {A Comparative Study and Component Analysis of Query Plan Representation Techniques in ML4DB Studies},
year = {2023},
issue_date = {December 2023},
publisher = {VLDB Endowment},
volume = {17},
number = {4},
issn = {2150-8097},
url = {https://doi.org/10.14778/3636218.3636235},
doi = {10.14778/3636218.3636235},
abstract = {Query plan is widely used as input in machine learning for databases (ML4DB) research, with query plan representation as a critical step. However, existing studies typically focus on one task, and propose a novel design to represent query plans along with a ML4DB framework, without comparing with other representation methods designed for a different task. This raises a critical question: How do we select a query plan representation method in a ML4DB system?To address this question, we perform a comparative study on ten representation methods on three distinct ML4DB tasks: cost estimation, index selection and query optimization. Our extensive experiments not only verify the interchangeability of representation methods across different tasks, but also identify consistently high-performing models. Further, we dissect the query plan representation into two core components: feature encoding and tree model, and evaluate the impact of design choices for each in different scenarios. Our results show that the findings for tasks optimizing absolute errors are different from findings for tasks optimizing relative errors. Some findings challenge widely-held assumptions, i.e., one finding shows that tree models do not significantly impact cost estimation results, but only play a significant role to optimize relative performance. Practical guidelines and future directions are provided based on the findings of the study.},
journal = {Proc. VLDB Endow.},
month = dec,
pages = {823–835},
numpages = {13}
}

@inproceedings{10.1145/3529190.3529199,
author = {Talha, Muhammad and Soomro, Hasan Ali and Naeem, Nadeem and Ali, Ehsan and Kyrarini, Maria},
title = {Human Identification Using a Smartphone Motion Sensor and Gait Analysis},
year = {2022},
isbn = {9781450396318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3529190.3529199},
doi = {10.1145/3529190.3529199},
abstract = {This research focuses on the modeling of human gait in order to recognize a human by their walking style. Gait analysis is a very important parameter, especially for biometric systems and also for healthcare applications. In this research, human gait is captured by using only a single Inertial Measurement Unit (IMU) sensor, which is positioned on top of the ankle. MATLAB mobile application is used to access the IMU sensor. A small study of 30 participants was conducted and two databases are then developed with different features. The first database contains only IMU sensor data, while the second database contains information on the height and gender of each participant. Both databases are used to train and test four different machine learning algorithms and their performances are compared. The experimental results show that the acquired setup performs well for classification purposes. Results from both databases are comparable and provide sufficient accuracy in the recognition task.},
booktitle = {Proceedings of the 15th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {197–202},
numpages = {6},
keywords = {Gait Analysis, Human Motion Analysis, Inertial Measurement Unit (IMU), Machine Learning, Motion Sensors},
location = {Corfu, Greece},
series = {PETRA '22}
}

@inproceedings{10.1145/3581641.3584067,
author = {Ning, Zheng and Zhang, Zheng and Sun, Tianyi and Tian, Yuan and Zhang, Tianyi and Li, Toby Jia-Jun},
title = {An Empirical Study of Model Errors and User Error Discovery and Repair Strategies in Natural Language Database Queries},
year = {2023},
isbn = {9798400701061},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581641.3584067},
doi = {10.1145/3581641.3584067},
abstract = {Recent advances in machine learning (ML) and natural language processing (NLP) have led to significant improvement in natural language interfaces for structured databases (NL2SQL). Despite the great strides, the overall accuracy of NL2SQL models is still far from being perfect (∼ 75% on the Spider benchmark). In practice, this requires users to discern incorrect SQL queries generated by a model and manually fix them when using NL2SQL models. Currently, there is a lack of comprehensive understanding about the common errors in auto-generated SQLs and the effective strategies to recognize and fix such errors. To bridge the gap, we (1) performed an in-depth analysis of errors made by three state-of-the-art NL2SQL models; (2) distilled a taxonomy of NL2SQL model errors; and (3) conducted a within-subjects user study with 26 participants to investigate the effectiveness of three representative interactive mechanisms for error discovery and repair in NL2SQL. Findings from this paper shed light on the design of future error discovery and repair strategies for natural language data query interfaces.},
booktitle = {Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {633–649},
numpages = {17},
keywords = {Empirical study, database systems, human-computer interaction},
location = {Sydney, NSW, Australia},
series = {IUI '23}
}

@article{10.1109/TCBB.2022.3148382,
author = {Kuang, Mengmeng and Zhang, Yong and Lam, Tak-Wah and Ting, Hing-Fung},
title = {MLProbs: A Data-Centric Pipeline for Better Multiple Sequence Alignment},
year = {2022},
issue_date = {Jan.-Feb. 2023},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {20},
number = {1},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2022.3148382},
doi = {10.1109/TCBB.2022.3148382},
abstract = {In this paper, we explore using the data-centric approach to tackle the Multiple Sequence Alignment (MSA) construction problem. Unlike the algorithm-centric approach, which reduces the construction problem to a combinatorial optimization problem based on an abstract mathematical model, the data-centric approach explores using classification models trained from existing benchmark data to guide the construction. We identified two simple classifications to help us choose a better alignment tool and determine whether and how much to carry out realignment. We show that shallow machine-learning algorithms suffice to train sensitive models for these classifications. Based on these models, we implemented a new multiple sequence alignment pipeline, called MLProbs. Compared with 10 other popular alignment tools over four benchmark databases (namely, BAliBASE, OXBench, OXBench-X and SABMark), MLProbs consistently gives the highest TC score. More importantly, MLProbs shows non-trivial improvement for protein families with low similarity; in particular, when evaluated against the 1,356 protein families with similarity &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$leq$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mo&gt;≤&lt;/mml:mo&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="kuang-ieq1-3148382.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; 50%, MLProbs achieves a TC score of 56.93, while the next best three tools are in the range of [55.41, 55.91] (increased by more than 1.8%). We also compared the performance of MLProbs and other MSA tools in two real-life applications – Phylogenetic Tree Construction Analysis and Protein Secondary Structure Prediction – and MLProbs also had the best performance. In our study, we used only shallow machine-learning algorithms to train our models. It would be interesting to study whether deep-learning methods can help make further improvements, so we suggest some possible research directions in the conclusion section.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = feb,
pages = {524–533},
numpages = {10}
}

@inproceedings{10.1145/3655693.3656546,
author = {Cali, Umit and Gourisetti, Sri Nikhil Gupta and Sebastian-Cardenas, David Jonathan and Catak, Ferhat Ozgur and Lee, Annabelle and Zeger, Linda M. and Ustun, Taha Selim and Dynge, Marthe Fogstad and Rao, Sreedhar and Ramirez, Javier E.},
title = {Emerging Technologies for Privacy Preservation in Energy Systems},
year = {2024},
isbn = {9798400716515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3655693.3656546},
doi = {10.1145/3655693.3656546},
abstract = {This landscape paper explores the intersection of digitalization and privacy within the energy sector, focusing on the emerging challenges and opportunities presented by integrating distributed energy resources and other edge-level technologies such as Electric Vehicles or Advanced Metering Infrastructure. The need for robust digital privacy measures has become crucial as the energy industry evolves toward a more decentralized, digitalized, and decarbonized future. This study delves into four cutting-edge privacy-preserving technologies — Homomorphic Encryption, Secure Multiparty Computation, Differential Privacy, and Federated Learning — as potential tools to improve privacy in the energy domain. Through a detailed examination of these methods, the study explains how each technology operates, its applications within the energy sector, and the specific privacy challenges it addresses. Homomorphic Encryption allows for secure computations on encrypted data, enabling data analysis without compromising privacy. Secure Multiparty Computation enables collaborative data analysis across different entities while protecting the confidentiality of the inputs. Differential Privacy introduces randomness into the assembled data set, preventing the identification of individual records in statistical databases. Lastly, Federated Learning offers a paradigm shift in data analysis, where machine learning models are trained at the edge, minimizing the centralization of sensitive data. The research underscores the significance of implementing these privacy-enhancing technologies (PETs) to comply with strict data protection regulations, foster consumer trust, and enhance the security of current and future grid applications. By providing a comprehensive overview of these methodologies and their practical implications for the energy sector, this study aims to contribute to the ongoing discourse on digital privacy, offering insights into how the energy industry can navigate the complex landscape.},
booktitle = {Proceedings of the 2024 European Interdisciplinary Cybersecurity Conference},
pages = {163–170},
numpages = {8},
keywords = {Advanced Metering Infrastructure, Differential Privacy, Digital privacy in the energy sector, Distributed Energy Resources (DERs), Federated Learning, Homomorphic Encryption, Secure Multiparty Computation, data protection},
location = {Xanthi, Greece},
series = {EICC '24}
}

@inproceedings{10.1145/3594315.3594373,
author = {Iipinge, Vilho James and Hu, Mengting},
title = {Automated Methodology for Classifying Non-functional Requirements: Challenges, Validation Aspects &amp; New Research Directions},
year = {2023},
isbn = {9781450399029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594315.3594373},
doi = {10.1145/3594315.3594373},
abstract = {The development of higher-quality software is thought to be greatly influenced by non-functional requirements or software quality traits. How to classify non-functional requirements automatically and efficiently has become the top priority. This systematic review aims to outline the cutting-edge automated approaches, methodologies, and systems for detecting and classifying non-functional requirements or quality attributes. Moreover, this study seeks to identify the methods used to validate the proposed non-functional requirement evaluation approaches, highlight limitations in the proposed non-functional requirement evaluation approaches, and offer new research recommendations. The suitable articles are extracted from leading citation databases specifically, IEEE Xplore, ScienceDirect, and Web of science. Directed by three research questions, a total of 66 studies were carefully reviewed. Supervised learning algorithms are the most popular, and cross-validation with ten folds is widely used to validate the results of the approaches. Precision and recall are the most used matrices to measure the performance of these approaches. This systematic review calls for close cooperation between non-requirement analysis, and machine learning researchers to address the need for the development of real-time automated tools.},
booktitle = {Proceedings of the 2023 9th International Conference on Computing and Artificial Intelligence},
pages = {568–575},
numpages = {8},
location = {Tianjin, China},
series = {ICCAI '23}
}

@inproceedings{10.1145/3577148.3577150,
author = {Tan, Yuyang and Teoh Teik, Toe},
title = {Pneumonia image classification method based on improved convolutional neural network},
year = {2023},
isbn = {9781450397124},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3577148.3577150},
doi = {10.1145/3577148.3577150},
abstract = {This is an exploration of the recognition technology of pneumonia pictures based on convolutional neural network technology. Among them, the recognition model used is based on the study of hundreds of real X-rays of lung pictures database, which contains not only lung pictures of real pneumonia patients, but also lung pictures of normal people. This article describes the most popular techniques of the moment, convolutional neural networks, which are widely used in areas such as image recognition or machine learning and are recognized by most people. This paper analyzes the specific implementation techniques of convolutional neural networks used, and uses some new methods to optimize and implement this algorithm, so as to achieve a better model structure and accuracy. Among them, with regard to the pooling layer, working between the convolutional layer and the final output layer, this paper compares various pooling methods and finally yields the maximum pooled neural network is more stable, and the average pooled neural network is more effective for large databases. The final use, pooling the resulting model accuracy is about 95% by maximum pooled neural network.},
booktitle = {Proceedings of the 2022 5th International Conference on Sensors, Signal and Image Processing},
pages = {6–12},
numpages = {7},
location = {Nanjing, China},
series = {SSIP '22}
}

@inproceedings{10.1145/3524610.3527921,
author = {Sharma, Rishab and Chen, Fuxiang and Fard, Fatemeh and Lo, David},
title = {An exploratory study on code attention in BERT},
year = {2022},
isbn = {9781450392983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524610.3527921},
doi = {10.1145/3524610.3527921},
abstract = {Many recent models in software engineering introduced deep neural models based on the Transformer architecture or use transformer-based Pre-trained Language Models (PLM) trained on code. Although these models achieve the state of the arts results in many downstream tasks such as code summarization and bug detection, they are based on Transformer and PLM, which are mainly studied in the Natural Language Processing (NLP) field. The current studies rely on the reasoning and practices from NLP for these models in code, despite the differences between natural languages and programming languages. There is also limited literature on explaining how code is modeled.Here, we investigate the attention behavior of PLM on code and compare it with natural language. We pre-trained BERT, a Transformer based PLM, on code and explored what kind of information it learns, both semantic and syntactic. We run several experiments to analyze the attention values of code constructs on each other and what BERT learns in each layer. Our analyses show that BERT pays more attention to syntactic entities, specifically identifiers and separators, in contrast to the most attended token [CLS] in NLP. This observation motivated us to leverage identifiers to represent the code sequence instead of the [CLS] token when used for code clone detection. Our results show that employing embeddings from identifiers increases the performance of BERT by 605% and 4% F1-score in its lower layers and the upper layers, respectively. When identifiers' embeddings are used in CodeBERT, a code-based PLM, the performance is improved by 21--24% in the F1-score of clone detection. The findings can benefit the research community by using code-specific representations instead of applying the common embeddings used in NLP, and open new directions for developing smaller models with similar performance.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension},
pages = {437–448},
numpages = {12},
keywords = {BERT, CodeBERT, attention, pre-trained language models},
location = {Virtual Event},
series = {ICPC '22}
}

@inproceedings{10.1109/ICSE48619.2023.00024,
author = {Guan, Hao and Xiao, Ying and Li, Jiaying and Liu, Yepang and Bai, Guangdong},
title = {A Comprehensive Study of Real-World Bugs in Machine Learning Model Optimization},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00024},
doi = {10.1109/ICSE48619.2023.00024},
abstract = {Due to the great advance in machine learning (ML) techniques, numerous ML models are expanding their application domains in recent years. To adapt for resource-constrained platforms such as mobile and Internet of Things (IoT) devices, pre-trained models are often processed to enhance their efficiency and compactness, using optimization techniques such as pruning and quantization. Similar to the optimization process in other complex systems, e.g., program compilers and databases, optimizations for ML models can contain bugs, leading to severe consequences such as system crashes and financial loss. While bugs in training, compiling and deployment stages have been extensively studied, there is still a lack of systematic understanding and characterization of model optimization bugs (MOBs).In this work, we conduct the first empirical study to identify and characterize MOBs. We collect a comprehensive dataset containing 371 MOBs from TensorFlow and PyTorch, the most extensively used open-source ML frameworks, covering the entire development time span of their optimizers (May 2019 to August 2022). We then investigate the collected bugs from various perspectives, including their symptoms, root causes, life cycles, detection and fixes. Our work unveils the status quo of MOBs in the wild, and reveals their features on which future detection techniques can be based. Our findings also serve as a warning to the developers and the users of ML frameworks, and an appeal to our research community to enact dedicated countermeasures.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {147–158},
numpages = {12},
keywords = {machine learning, model optimization, bugs},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3514221.3517912,
author = {Deutch, Daniel and Frost, Nave and Kimelfeld, Benny and Monet, Mika\"{e}l},
title = {Computing the Shapley Value of Facts in Query Answering},
year = {2022},
isbn = {9781450392495},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3514221.3517912},
doi = {10.1145/3514221.3517912},
abstract = {The Shapley value is a game-theoretic notion for wealth distribution that is nowadays extensively used to explain complex data-intensive computation, for instance, in network analysis or machine learning. Recent theoretical works show that query evaluation over relational databases fits well in this explanation paradigm. Yet, these works fall short of providing practical solutions to the computational challenge inherent to the Shapley computation. We present in this paper two practically effective solutions for computing Shapley values in query answering. We start by establishing a tight theoretical connection to the extensively studied problem of query evaluation over probabilistic databases, which allows us to obtain a polynomial-time algorithm for the class of queries for which probability computation is tractable. We then propose a first practical solution for computing Shapley values that adopts tools from probabilistic query evaluation. In particular, we capture the dependence of query answers on input database facts using Boolean expressions (data provenance), and then transform it, via Knowledge Compilation, into a particular circuit form for which we devise an algorithm for computing the Shapley values. Our second practical solution is a faster yet inexact approach that transforms the provenance to a Conjunctive Normal Form and uses a heuristic to compute the Shapley values. Our experiments on TPC-H and IMDB demonstrate the practical effectiveness of our solutions.},
booktitle = {Proceedings of the 2022 International Conference on Management of Data},
pages = {1570–1583},
numpages = {14},
keywords = {knowledge compilation, provenance, shapley value},
location = {Philadelphia, PA, USA},
series = {SIGMOD '22}
}

@inproceedings{10.1145/3511095.3531282,
author = {Salimzadeh, Sara and Gadiraju, Ujwal and Hauff, Claudia and van Deursen, Arie},
title = {Exploring the Feasibility of Crowd-Powered Decomposition of Complex User Questions in Text-to-SQL Tasks},
year = {2022},
isbn = {9781450392334},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511095.3531282},
doi = {10.1145/3511095.3531282},
abstract = {Natural Language Interfaces to Databases (NLIDB), also known as Text-to-SQL models, enable users with different levels of knowledge in Structured Query Language (SQL) to access relational databases without any programming effort. By translating natural languages into SQL query, not only do NLIDBs minimize the burden of memorizing the schema of databases and writing complex SQL queries, but they also allow non-experts to acquire information from databases in natural languages. However, existing NLIDBs largely fail to translate natural languages to SQL when they are complex, preventing them from being deployed in real-world scenarios and generalizing across unseen complex databases. In this paper, we explored the feasibility of decomposing complex user questions into multiple sub-questions — each with a reduced complexity — as a means to circumvent the problem of complex SQL generation. We investigated the feasibility of decomposing complex user questions in a manner that each sub-question is simple enough for existing NLIDBs to generate correct SQL queries, using non-expert crowd workers in juxtaposition with SQL experts. Through an empirical study on an NLIDB benchmark dataset, we found that crowd-powered decomposition of complex user questions led to an accuracy boost of an existing Text-to-SQL pipeline from 30% to 59% (96% accuracy boost). Similarly, decomposition by SQL experts resulted in boosting the accuracy to 76% (153% accuracy boost). Our findings suggest that crowd-powered decomposition can be a scalable alternative to producing the training data necessary to build machine learning models that can automatically decompose complex user questions, thereby improving Text-to-SQL pipelines.},
booktitle = {Proceedings of the 33rd ACM Conference on Hypertext and Social Media},
pages = {154–165},
numpages = {12},
keywords = {Corpus Annotation, Crowdsourcing, Human Computation, Natural Language Interface to Databases, Semantic Parsing, Text-to-SQL},
location = {Barcelona, Spain},
series = {HT '22}
}

@inproceedings{10.1145/3607947.3607980,
author = {Gupta, Vishu and Lyu, Yuhui and Suarez, Derick and Mao, Yuwei and Liao, Wei-Keng and Choudhary, Alok and Liu, Wing Kam and Cusatis, Gianluca and Agrawal, Ankit},
title = {Physics-based Data-Augmented Deep Learning for Enhanced Autogenous Shrinkage Prediction on Experimental Dataset},
year = {2023},
isbn = {9798400700224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607947.3607980},
doi = {10.1145/3607947.3607980},
abstract = {Prediction of the autogenous shrinkage referred to as the reduction of apparent volume of concrete under seal and isothermal conditions is of great significance in the service life analysis and design of durable concrete structures, especially with the increasing use of concrete with low water-to-cement ratios. However, due to the highly complex mechanism of autogenous shrinkage, it is hard to design accurate mechanistic models for it. Existing state-of-the-art models for autogenous shrinkage do not perform well for several reasons such as not being able to capture faster shrinkage change at early ages (swelling), coefficients used are derived using statistical optimization methods to fit certain databases only, and mechanism to identify the most influencing factors on autogenous shrinkage is not present. Moreover, it is also challenging to deploy a machine learning framework directly to perform predictive analysis due to the sparse and noisy nature of the available experimental dataset. In this paper, we study and propose a method to combine the physics-based knowledge and the predictive ability of deep regression neural networks to mitigate the shortcomings of the existing models. We introduce a novel data augmentation technique that utilizes physics based knowledge to improve the accuracy while maintaining the characteristics of autogenous shrinkage in its predictions simultaneously. Using state-of-the-art B4 model, a genetic algorithm, and a deep neural network trained using raw data for comparison, we show that the proposed methods help improve the accuracy of the model as compared to other methods. We also observe that the proposed method is able to successfully learn and predict the swelling component of the shrinkage strain curve as well, which cannot be predicted using the existing state-of-the-art models.},
booktitle = {Proceedings of the 2023 Fifteenth International Conference on Contemporary Computing},
pages = {188–197},
numpages = {10},
keywords = {Autogenous Shrinkage, Deep Learning, Deep Regression, Physics Based Data Augmentation, Predictive Modeling},
location = {Noida, India},
series = {IC3-2023}
}

@inproceedings{10.1145/3640794.3665559,
author = {Dregger, Alexander and Seifermann, Maximilian and Oberweis, Andreas},
title = {Language Cues for Expressing Artificial Personality: A Systematic Literature Review for Conversational Agents},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640794.3665559},
doi = {10.1145/3640794.3665559},
abstract = {Users attribute artificial personality (AP) to conversational agents (CAs) based on perceived language respectively verbal cues. This review synthesizes studies on this topic, encompassing research not only on chat- and voicebots but also on social robots, drawing from interdisciplinary databases. This approach led to an identification of 200 verbal signals, nearly four times more as in previous reviews. The signals were classified according to the personality dimensions of the BFM as well as its facets. Besides, the relevance of theories of personality other than the BFM are discussed. Furthermore, six methodological challenges in the empirical study of verbal cues expressing AP are identified. Practical implications include providing practitioners an overview of verbal signals, while offering opportunities for research improvement based on identified challenges. Enhanced understanding of verbal signals related to AP aids in evaluating implementation quality, not only in rule-based CAs but also in LLM-based systems.},
booktitle = {Proceedings of the 6th ACM Conference on Conversational User Interfaces},
articleno = {22},
numpages = {17},
keywords = {Anthropomorphism, Artificial Personality, Artificial Personality Model, Chatbot Personality, Conversational Agents, Literature Review, Personality, Personality of Robot, Robots},
location = {Luxembourg, Luxembourg},
series = {CUI '24}
}

@inproceedings{10.1145/3597503.3639202,
author = {Sun, Jiamou and Chen, Jieshan and Xing, Zhenchang and Lu, Qinghua and Xu, Xiwei and Zhu, Liming},
title = {Where is it? Tracing the Vulnerability-relevant Files from Vulnerability Reports},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639202},
doi = {10.1145/3597503.3639202},
abstract = {With the widely usage of open-source software, supply-chain-based vulnerability attacks, including SolarWind and Log4Shell, have posed significant risks to software security. Currently, people rely on vulnerability advisory databases or commercial software bill of materials (SBOM) to defend against potential risks. Unfortunately, these datasets do not provide finer-grained file-level vulnerability information, compromising their effectiveness. Previous works have not adequately addressed this issue, and mainstream vulnerability detection methods have their drawbacks that hinder resolving this gap. Driven by the real needs, we propose a framework that can trace the vulnerability-relevant file for each disclosed vulnerability. Our approach uses NVD descriptions with metadata as the inputs, and employs a series of strategies with a LLM model, search engine, heuristic-based text matching method and a deep learning classifier to recommend the most likely vulnerability-relevant file, effectively enhancing the completeness of existing NVD data. Our experiments confirm that the efficiency of the proposed framework, with CodeBERT achieving 0.92 AUC and 0.85 MAP, and our user study proves our approach can help with vulnerability-relevant file detection effectively. To the best of our knowledge, our work is the first one focusing on tracing vulnerability-relevant files, laying the groundwork of building finer-grained vulnerability-aware software bill of materials.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {200},
numpages = {13},
keywords = {vulnerability-relevant file, security, software supply chain},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3552469.3555714,
author = {You, Junyong and Korhonen, Jari},
title = {Simulating Visual Mechanisms by Sequential Spatial-Channel Attention for Image Quality Assessment},
year = {2022},
isbn = {9781450394994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3552469.3555714},
doi = {10.1145/3552469.3555714},
abstract = {As a subjective concept, image quality assessment (IQA) is significantly affected by perceptual mechanisms. Two mutually influenced mechanisms, namely spatial attention and contrast sensitivity, are particularly important for IQA. This paper aims to explore a deep learning approach based on transformer for the two mechanisms. By converting contrast sensitivity to attention representation, a unified multi-head attention module is performed on spatial and channel features in transformer encoder to simulate the two mechanisms in IQA. Sequential spatial-channel self-attention is proposed to avoid expensive computation in the classical Transformer model. In addition, as image rescaling can potentially affect perceived quality, zero-padding and masking with assigning special attention weights are performed to handle arbitrary image resolutions without requiring image rescaling. The evaluation results on publicly available large-scale IQA databases have demonstrated outstanding performance and generalization of the proposed IQA model.},
booktitle = {Proceedings of the 2nd Workshop on Quality of Experience in Visual Multimedia Applications},
pages = {13–21},
numpages = {9},
keywords = {contrast sensitivity, image quality assessment (iqa), sequential spatial-channel attention (ssca), spatial attention, transformer},
location = {Lisboa, Portugal},
series = {QoEVMA '22}
}

@article{10.1109/TCBB.2022.3155453,
author = {Yang, Jingbo and Zhang, Denan and Cai, Yiyang and Yu, Kexin and Li, Mingming and Liu, Lei and Chen, Xiujie},
title = {Computational Prediction of Drug Phenotypic Effects Based on Substructure-Phenotype Associations},
year = {2022},
issue_date = {Jan.-Feb. 2023},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {20},
number = {1},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2022.3155453},
doi = {10.1109/TCBB.2022.3155453},
abstract = {Identifying drug phenotypic effects, including therapeutic effects and adverse drug reactions (ADRs), is an inseparable part for evaluating the potentiality of new drug candidates (NDCs). However, current computational methods for predicting phenotypic effects of NDCs are mainly based on the overall structure of an NDC or a related target. These approaches often lead to inconsistencies between the structures and functions and limit the prediction space of NDCs. In this study, first, we constructed quantitative associations of substructure-domain, domain-ADR, and domain-ATC (Anatomical Therapeutic Chemical Classification System code) through L1LOG and L1SVM machine learning models. These associations represent relationships between phenotypes (ADRs and ATCs) and local structures of drugs and proteins. Then, based on these established associations, substructure-phenotype relationships were constructed which were utilized to quantify drug-phenotype relationships. Thus, this approach could achieve high-throughput and effective evaluations of the druggability of NDCs by referring to the established substructure-phenotype relationships and structural information of NDCs without additional prior knowledge. Using this computational pipeline, 83,205 drug-ATC relationships (including 1,479 drugs and 178 ATCs) and 306,421 drug-ADR relationships (including 1,752 drugs and 454 ADRs) were predicted in total. The prediction results were validated at four levels: five-fold cross validation, public databases, literature, and molecular docking. Furthermore, three case studies demonstrated the feasibility of our method. 79 ATCs and 269 ADRs were predicted to be related to Maraviroc, an approved drug, including the existing antiviral effect in clinical use. Additionally, we also found risk substructures of severe ADRs, for example, SUB215 (&gt;= 1, saturated or only aromatic carbon ring size 7) can result in shock. And we analyzed the mechanism of action (MOA) of interested drugs based on the established drug-substructure-domain-protein associations. In a word, this approach through establishing drug-substructure-phenotype relationships can achieve quantitative prediction of phenotypes for a given NDC or drug without any prior knowledge except its structure information. Using that way, we can directly obtain the relationships between substructure and phenotype of a compound, which is more convenient to analyze the phenotypic mechanism of drugs and accelerate the process of rational drug design.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = mar,
pages = {256–265},
numpages = {10}
}

@article{10.1145/3643817,
author = {Zhang, Zicheng and Sun, Wei and Wu, Haoning and Zhou, Yingjie and Li, Chunyi and Chen, Zijian and Min, Xiongkuo and Zhai, Guangtao and Lin, Weisi},
title = {GMS-3DQA: Projection-Based Grid Mini-patch Sampling for 3D Model Quality Assessment},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {6},
issn = {1551-6857},
url = {https://doi.org/10.1145/3643817},
doi = {10.1145/3643817},
abstract = {Nowadays, most three-dimensional model quality assessment (3DQA) methods have been aimed at improving accuracy. However, little attention has been paid to the computational cost and inference time required for practical applications. Model-based 3DQA methods extract features directly from the 3D models, which are characterized by their high degree of complexity. As a result, many researchers are inclined towards utilizing projection-based 3DQA methods. Nevertheless, previous projection-based 3DQA methods directly extract features from multi-projections to ensure quality prediction accuracy, which calls for more resource consumption and inevitably leads to inefficiency. Thus, in this article, we address this challenge by proposing a no-reference (NR) projection-based Grid Mini-patch Sampling 3D Model Quality Assessment (GMS-3DQA) method. The projection images are rendered from six perpendicular viewpoints of the 3D model to cover sufficient quality information. To reduce redundancy and inference resources, we propose a multi-projection grid mini-patch sampling strategy (MP-GMS), which samples grid mini-patches from the multi-projections and forms the sampled grid mini-patches into one quality mini-patch map (QMM). The Swin-Transformer tiny backbone is then used to extract quality-aware features from the QMMs. The experimental results show that the proposed GMS-3DQA outperforms existing state-of-the-art NR-3DQA methods on the point cloud quality assessment databases for both accuracy and efficiency. The efficiency analysis reveals that the proposed GMS-3DQA requires far less computational resources and inference time than other 3DQA competitors. The code is available at .},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = mar,
articleno = {178},
numpages = {19},
keywords = {3D model quality assessment, no-reference, projection-based, mini-patch, efficient}
}

@article{10.1145/3635716,
author = {Yang, Jifan and Wang, Zhongyuan and Wang, Guangcheng and Huang, Baojin and Yang, Yuhong and Tu, Weiping},
title = {Auxiliary Information Guided Self-attention for Image Quality Assessment},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {4},
issn = {1551-6857},
url = {https://doi.org/10.1145/3635716},
doi = {10.1145/3635716},
abstract = {Image quality assessment (IQA) is an important problem in computer vision with many applications. We propose a transformer-based multi-task learning framework for the IQA task. Two subtasks: constructing an auxiliary information error map and completing image quality prediction, are jointly optimized using a shared feature extractor. We use visual transformers (ViT) as a feature extractor for feature extraction and guide ViT to focus on image quality-related features by building auxiliary information error map subtask. In particular, we propose a fusion network that includes a channel focus module. Unlike the fusion methods commonly used in previous IQA methods, we use the fusion network, including the channel attention module, to fuse the auxiliary information error map features with the image features, which facilitates the model to mine the image quality features for more accurate image quality assessment. And by jointly optimizing the two subtasks, ViT focuses more on extracting image quality features and building a more precise mapping from feature representation to quality score. With slight adjustments to the model, our approach can be used in both no-reference (NR) and full-reference (FR) IQA environments. We evaluate the proposed method in multiple IQA databases, showing better performance than state-of-the-art FR and NR IQA methods.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = jan,
articleno = {119},
numpages = {23},
keywords = {Transformer, image quality assessment, multi-task learning, full-reference, no-reference}
}

@article{10.1145/3597434,
author = {Tang, Zhenjun and Chen, Zhiyuan and Li, Zhixin and Zhong, Bineng and Zhang, Xianquan and Zhang, Xinpeng},
title = {Unifying Dual-Attention and Siamese Transformer Network for Full-Reference Image Quality Assessment},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {6},
issn = {1551-6857},
url = {https://doi.org/10.1145/3597434},
doi = {10.1145/3597434},
abstract = {Image Quality Assessment (IQA) is a critical task of computer vision. Most Full-Reference (FR) IQA methods have limitation in the accurate prediction of perceptual qualities of the traditional distorted images and the Generative Adversarial Networks (GANs) based distorted images. To address this issue, we propose a novel method by Unifying Dual-Attention and Siamese Transformer Network (UniDASTN) for FR-IQA. An important contribution is the spatial attention module composed of a Siamese Transformer Network and a feature fusion block. It can focus on significant regions and effectively maps the perceptual differences between the reference and distorted images to a latent distance for distortion evaluation. Another contribution is the dual-attention strategy that exploits channel attention and spatial attention to aggregate features for enhancing distortion sensitivity. In addition, a novel loss function is designed by jointly exploiting Mean Square Error (MSE), bidirectional Kullback–Leibler divergence, and rank order of quality scores. The designed loss function can offer stable training and thus enables the proposed UniDASTN to effectively learn visual perceptual image quality. Extensive experiments on standard IQA databases are conducted to validate the effectiveness of the proposed UniDASTN. The IQA results demonstrate that the proposed UniDASTN outperforms some state-of-the-art FR-IQA methods on the LIVE, CSIQ, TID2013, and PIPAL databases.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = jul,
articleno = {205},
numpages = {24},
keywords = {Transformer, siamese network, dual-attention, image quality assessment (IQA)}
}

@article{10.1109/TASLP.2024.3358719,
author = {Feng, Sheng and Zhu, Xiaoqian and Ma, Shuqing},
title = {Masking Hierarchical Tokens for Underwater Acoustic Target Recognition With Self-Supervised Learning},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3358719},
doi = {10.1109/TASLP.2024.3358719},
abstract = {Deep learning has made data-driven methods effective in underwater acoustic target recognition (UATR) using passive sonar signals. However, a major current challenge is the limited availability of underwater acoustic data, leading to suboptimal performance without sufficient data. Self-supervised learning (SSL) can help address this problem by learning intrinsic patterns within acoustic data. Nonetheless, applying SSL in UATR systems requires efficient learning of meaningful representations that can provide quick prediction speed for real-time recognition systems. To this end, we propose the masking hierarchical tokens (MHT) method to learn meaningful representations via efficient self-supervised learning for our previously proposed UATR-Transformer, giving rise to the MHT-UATR-Transformer. In particular, the MHT-UATR-Transformer first exploits a new designed token-convolution-based hierarchical tokenization to efficiently obtain rich time–frequency information from the input Mel-spectrogram. Then, most of these tokens are masked with a high masking ratio and subsequently reconstructed by an integrated Encoder–Decoder structure. In this way, the MHT-UATR-Transformer can learn intrinsic representations of underwater acoustic signals to achieve better recognition performance with fewer labeled data, which is expected to alleviate the dependency on expensive acoustic data. Experimental results on two widely studied underwater databases show that our proposed method achieves better performance than supervised learning and state-of-the-art SSL method in both accuracy and speed, especially in few-shot and noisy scenarios, thus enhancing its practicality in real marine applications.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jan,
pages = {1365–1379},
numpages = {15}
}

@inproceedings{10.1145/3624062.3624081,
author = {Vasan, Archit and Brettin, Thomas and Stevens, Rick and Ramanathan, Arvind and Vishwanath, Venkatram},
title = {Scalable Lead Prediction with Transformers using HPC resources},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3624081},
doi = {10.1145/3624062.3624081},
abstract = {A promising direction in cancer drug discovery is high-throughput screening of extensive compound datasets to identify advantageous properties, including their ability to interact with relevant biomolecules such as proteins. However, traditional structural approaches for assessing binding affinity, such as free energy methods or molecular docking, pose significant computational bottlenecks when dealing with such vast datasets. To address this, we have developed a docking surrogate called the SMILES transformer (ST), which learns molecular features from the SMILES representation of compounds and approximates their binding affinity. SMILES data is first tokenized using a well-established SMILES-pair tokenizer and fed into a BERT-like Transformer model to generate vector embeddings for each molecule, effectively capturing the essential information. These extracted embeddings are then fed into a regression model to predict the binding affinity. Leveraging the high-performance computing resources at Argonne National Lab, we devised a workflow to scale model training and inference across multiple supercomputing nodes. To evaluate the performance and accuracy of our workflow, we conducted experiments using molecular docking binding affinity data on multiple receptors, comparing ST with another state-of-the-art docking surrogate. Impressively, both surrogates yielded comparable val-r2 measurements of between 70 and 90%, affirming the capability of ST to learn molecular features directly from language-based data. Furthermore, one significant advantage of the ST approach is its notably faster tokenization preprocessing compared to the alternative method, which requires generating molecular descriptors using Mordred. Our workflow facilitated screening of ∼3 billion compounds on 48 nodes of the Polaris supercomputer in approximately an hour. In summary, our approach presents an efficient means to screen extensive compound databases for potential molecular properties that could serve as lead compounds targeting cancer. Looking ahead, an important future direction for our workflow involves integrating de-novo drug design, enabling us to scale our efforts to explore the limits of synthesizable compounds within chemical space.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {123},
numpages = {1},
keywords = {Deep Learning, Drug discovery, High performance computing, Language Models},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@inproceedings{10.1145/3649902.3653351,
author = {Chugh, Soumil and Ye, Juntao and Fu, Yuqi and Eizenman, Moshe},
title = {CSA-CNN: A Contrastive Self-Attention Neural Network for Pupil Segmentation in Eye Gaze Tracking},
year = {2024},
isbn = {9798400706073},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649902.3653351},
doi = {10.1145/3649902.3653351},
abstract = {This paper presents a novel Contrastive Self-Attention Convolutional Neural Network (CSA-CNN) model with enhanced Difficulty Aware (DA) loss function to improve the segmentation of pupils in eye images. The incorporation of transformer-style self-attention and Difficulty-Aware loss in a UNET-style architecture allows for robust feature representation and promotes shape alignment. The novel model was trained on two public databases (LPW and RIT-Eyes) and evaluated on two other public datasets (ExCuSe and ElSe). When compared with seven state-of-the-art pupil center detection methods, the CSA-CNN showed improvement of over 6% in pupil center detection accuracy (detection within 5 pixels of the labeled center) and more than 9% in Intersection Over Union (IOU) accuracy, compared to the best performer among the other seven methods. Furthermore, when the CSA-CNN model was integrated into a glint-based eye tracking system that uses learning based methods to detect pupil-center, we saw a 25% improvement in gaze accuracy.},
booktitle = {Proceedings of the 2024 Symposium on Eye Tracking Research and Applications},
articleno = {6},
numpages = {7},
keywords = {Attention, Convolutional Neural Networks, Eye Tracking, Gaze Estimation, Pupil Center, Transformers},
location = {Glasgow, United Kingdom},
series = {ETRA '24}
}

@inproceedings{10.1145/3584371.3613007,
author = {Hasani, Moein and N. Trost, Chantel and Timmerman, Nolen and Jin, Lingling},
title = {AcrTransAct: Pre-trained Protein Transformer Models for the Detection of Type I Anti-CRISPR Activities},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3613007},
doi = {10.1145/3584371.3613007},
abstract = {Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) and CRISPR-associated (Cas) proteins serve as a formidable defense mechanism for bacteria against foreign DNA; on the other hand, some bacteriophages (phages) and other mobile genetic elements have evolved anti-CRISPR (Acr) proteins to counteract CRISPR-Cas systems and ensure their own survival. Because Acr proteins provide phages with a fitness advantage relative to the bacteria that they infect, accurately identifying Acr proteins that inhibit CRISPR-Cas systems has the potential to significantly and positively impact our ability to harness phages to fight antimicrobial resistance. However, Acr identification is, at present, laborious and involves costly experimental procedures. Existing computational tools for protein-protein interaction (PPI) are not designed to predict complex inhibition, which could be the collective result of multiple PPIs. In this study, we developed a transformer-based deep neural network, AcrTransAct, to predict the probability of Acr-mediated CRISPR-Cas inhibition. Our model comprises two main components: 1. a feature extraction module that incorporates a pre-trained Evolutionary Scale Modeling (ESM) protein transformer and the NetSurfP-3.0 secondary structure prediction system; 2. a classification module that consists of either a convolutional or recurrent neural network. We created an inhibition dataset compiled from two Acr databases, AcrHub [30], Anti-CRISPRdb [5], and several published works [9, 12, 18, 20]. The AcrTransAct model is trained and tested on this dataset. We achieved an accuracy of 95% and an F1 score of 0.95 in predicting the inhibition of I-C, I-E, and I-F CRISPR-Cas systems by Acrs in our dataset. A web application of AcrTransAct (https://acrtransact.usask.ca) is implemented with the best-performing models from this study to predict the probability of multiple CRISPR-Cas systems inhibited by a putative Acr protein. Our code and data are available here: https://github.com/USask-BINFO/AcrTransAct.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {22},
numpages = {6},
keywords = {CRISPR-cas, anti-CRISPR, transformers, deep learning, large language models, protein inhibition},
location = {Houston, TX, USA},
series = {BCB '23}
}

@article{10.1109/TCBB.2024.3414497,
author = {Qin, Xinyi and Zhang, Lu and Liu, Min and Liu, Guangzhong},
title = {PRFold-TNN: Protein Fold Recognition With an Ensemble Feature Selection Method Using PageRank Algorithm Based on Transformer},
year = {2024},
issue_date = {Nov.-Dec. 2024},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {21},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2024.3414497},
doi = {10.1109/TCBB.2024.3414497},
abstract = {Understanding the tertiary structures of proteins is of great benefit to function in many aspects of human life. Protein fold recognition is a vital and salient means to know protein structure. Until now, researchers have successively proposed a variety of methods to realize protein fold recognition, but the novel and effective computational method is still needed to handle this problem with the continuous updating of protein structure databases. In this study, we develop a new protein structure dataset named AT and propose the PRFold-TNN model for protein fold recognition. First, different types of feature extraction methods including AAC, HMM, HMM-Bigram and ACC are selected to extract corresponding features for protein sequences. Then an ensemble feature selection method based on PageRank algorithm integrating various tree-based algorithms is used to screen the fusion features. Ultimately, the classifier based on the Transformer model achieves the final prediction. Experiments show that the prediction accuracy is 86.27% on the AT dataset and 88.91% on the independent test set, indicating that the model can demonstrate superior performance and generalization ability in the problem of protein fold recognition. Furthermore, we also carry out research on the DD, EDD and TG benchmark datasets, and make them achieve prediction accuracy of 88.41%, 97.91% and 95.16%, which are at least 3.0%, 0.8% and 2.5% higher than those of the state-of-the-art methods. It can be concluded that the PRFold-TNN model is more prominent.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = jun,
pages = {1740–1751},
numpages = {12}
}

