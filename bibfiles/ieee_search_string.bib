@INPROCEEDINGS{10893106,
  author={Reichert, Heidi and Tabarsi, Benyamin T. and Zang, Zifan and Fennell, Cheri and Bhandari, Indira and Robinson, David and Drayton, Madeline and Crofton, Catherine and Lococo, Matthew and Xu, Dongkuan and Barnes, Tiffany},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Empowering Secondary School Teachers: Creating, Executing, and Evaluating a Transformative Professional Development Course on ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={Background and Context. This innovative practice full paper describes the development and implementation of a professional development (PD) opportunity for secondary teachers to learn about ChatGPT. Incorporating generative AI techniques from Large Language Models (LLMs) such as ChatGPT into educational environments offers unprecedented opportunities and challenges. Prior research has highlighted their potential to personalize feedback, assist in lesson planning, generate educational content, and reduce teachers' workload, alongside concerns such as academic integrity and student privacy. However, the rapid adoption of LLMs since ChatGPT's public release in late 2022 has left educators, particularly at the secondary level, with a lack of clear guidance on how LLMs work and can be effectively adopted. Objective. This study aims to introduce a comprehensive, free, and vetted ChatGPT course tailored for secondary teachers, with the objective of enhancing their technological competencies in LLMs and fostering innovative teaching practices. Method. We developed a five-session interactive course on ChatGPT capabilities, limitations, prompt-engineering techniques, ethical considerations, and strategies for incorporating ChatGPT into teaching. We introduced the course to six middle and high school teachers. Our curriculum emphasized active learning through peer discussions, hands-on activities, and project-based learning. We conducted pre- and post-course focus groups to determine the effectiveness of the course and the extent to which teachers' attitudes toward the use of LLMs in schools had changed. To identify trends in knowledge and attitudes, we asked teachers to complete feedback forms at the end of each of the five sessions. We performed a thematic analysis to classify teacher quotes from focus groups' transcripts as positive, negative, and neutral and calculated the ratio of positive to negative comments in the pre- and post-focus groups. We also analyzed their feedback on each individual session. Finally, we interviewed all participants five months after course completion to understand the longer-term impacts of the course. Findings. Our participants unanimously shared that all five of the sessions provided a deeper understanding of ChatGPT, featured enough opportunities for hands-on practice, and achieved their learning objectives. Our thematic analysis underlined that teachers gained a more positive and nuanced understanding of ChatGPT after the course. This change is evidenced quantitatively by the fact that quotes with positive connotations rose from 45% to 68% of the total number of positive and negative quotes. Participants shared that in the longer term, the course improved their professional development, understanding of ChatGPT, and teaching practices. Implications. This research underscores the effectiveness of active learning in professional development settings, particularly for technological innovations in computing like LLMs. Our findings suggest that introducing teachers to LLM tools through active learning can improve their work processes and give them a thorough and accurate understanding of how these tools work. By detailing our process and providing a model for similar initiatives, our work contributes to the broader discourse on teaching professional educators about computing and integrating emerging technologies in educational and professional development settings.},
  keywords={Technological innovation;Privacy;Computational modeling;Large language models;Education;Active learning;Position measurement;Chatbots;Market research;Planning;K-12;large language models;chatgpt;professional development;secondary education},
  doi={10.1109/FIE61694.2024.10893106},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10893096,
  author={Lejmbach, Karol and Mackay, Sean},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Using Chat-GPT to Create Multiple Choice CS Exams}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work in progress Innovative Practice paper presents our work evaluating how Large Language Models (LLMs) can be utilized to aid in the development of scalable and authentic programming exam questions for students in upper-division courses. Traditionally, students' understanding of computing concepts are often verified using written exams. This is especially the case in larger universities due to their overall enrollment sizes, making more authentic, involved assignments particularly hard to facilitate. Since the rise of Chat-GPT and other LLMs, the use of such exams has seen a resurgence in popularity in classrooms globally. Fears have recently grown that programming assignments, particularly those that are take home assignments, are not adequate assessments of students' understanding given the ease at which students can use LLMs such as Chat-GPT to obtain answers. multiple-choice exams have been a traditionally popular programming exam format, where-in students are required to choose the correct answer to a prompt or the segment of code that best fits within a larger block of code. Another form of exam question that has been traditionally popular is providing students with blocks of code and ask students to either interpret the code's meaning or find the errors in the code. Both of these styles of assignments provide opportunities for students to demonstrate a deep understanding of code syntax and structure, while also tasking them to demonstrate their understanding of what the intended purpose of the code is. However, the development of these exam problems has traditionally required a substantial amount of work for instructors and teaching assistants to develop. Our goal with this work was to determine if LLMs represent effective tools for developing exam questions. Additionally, we wanted to see if LLMs could effectively design problems based on learning outcomes, allowing the instructor to become the evaluator of the exam questions rather than the original author. Our motivation for this was to develop a reproducible and easier to implement methodology for developing exams at scale for instructors while alleviating the workload imposed on instructors during the development of exams. Our initial research has indicated the use of these LLMs for exam problem generation greatly reduces the workload for instructors while allowing for the creation of far richer programming questions for students that require them to apply more of their knowledge to individual problems. We have had a good amount of success in developing these problems for upper-division courses, as well as introductory-level courses. This work represents initial steps towards the use of these LLMs for generating exams and more work is needed to determine the actual efficacy and long-term benefits and reliability of these tools. Regardless, we are confident that LLMs in their current form represent incredibly powerful tools for instructors to utilize in the development of their course exams.},
  keywords={Codes;Large language models;Education;Syntactics;Reliability;Programming profession;large language models;exam development;computing education;Chat-GPT},
  doi={10.1109/FIE61694.2024.10893096},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10578933,
  author={Frank, Lukas and Herth, Fabian and Stuwe, Paul and Klaiber, Marco and Gerschner, Felix and Theissler, Andreas},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Leveraging GenAI for an Intelligent Tutoring System for R: A Quantitative Evaluation of Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={The tremendous advances in Artificial Intelligence (AI) open new opportunities for education, with Intelligent Tutoring Systems (ITS) powered by Generative Artificial Intelligence (GenAI) proving to be a promising prospect. Because of this, our work explores state-of-the-art (SOTA) ITS approaches with the integration of Large Language Models (LLMs) to improve programming education. We investigate whether and how a GenAI-based ITS can effectively support students in learning R programming skills. We measured the performance of three current pairings of LLMs and user interfaces: GPT-3.5 via ChatGPT, PaLM 2 via Google Bard, and GPT-4 via Bing. Therefore, we evaluated the LLMs on four types of problem settings when learning/teaching programming. Our experimental results show that the use of generative AI, specifically LLMs for R programming, is promising, where GPT-3.5 yielded the most satisfactory results. Furthermore, the advantages and limitations of our approach are addressed and revealed. Finally, open research directions towards explainable AI (XAI) and integrated self-assessment are pointed out.},
  keywords={Generative AI;Explainable AI;Current measurement;Benchmark testing;Chatbots;Internet;Task analysis;Generative AI;AI in Education;Intelligent Tutoring Systems;R Programming;Student Support},
  doi={10.1109/EDUCON60312.2024.10578933},
  ISSN={2165-9567},
  month={May},}@ARTICLE{10518103,
  author={Neyem, Andrés and González, Luis A. and Mendoza, Marcelo and Alcocer, Juan Pablo Sandoval and Centellas, Leonardo and Paredes, Carlos},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Toward an AI Knowledge Assistant for Context-Aware Learning Experiences in Software Capstone Project Development}, 
  year={2024},
  volume={17},
  number={},
  pages={1599-1614},
  abstract={Software assistants have significantly impacted software development for both practitioners and students, particularly in capstone projects. The effectiveness of these tools varies based on their knowledge sources; assistants with localized domain-specific knowledge may have limitations, while tools, such as ChatGPT, using broad datasets, might offer recommendations that do not always match the specific objectives of a capstone course. Addressing a gap in current educational technology, this article introduces an AI Knowledge Assistant specifically designed to overcome the limitations of the existing tools by enhancing the quality and relevance of large language models (LLMs). It achieves this through the innovative integration of contextual knowledge from a local “lessons learned” database tailored to the capstone course. We conducted a study with 150 students using the assistant during their capstone course. Integrated into the Kanban project tracking system, the assistant offered recommendations using different strategies: direct searches in the lessons learned database, direct queries to a generative pretrained transformers (GPT) model, query enrichment with lessons learned before submission to GPT and large language model meta AI (LLaMa) models, and query enhancement with Stack Overflow data before GPT processing. Survey results underscored a strong preference among students for direct LLM queries and those enriched with local repository insights, highlighting the assistant's practical value. Furthermore, our linguistic analysis conclusively demonstrated that texts generated by the LLM closely mirrored the linguistic standards and topical relevance of university course requirements. This alignment not only fosters a deeper understanding of course content but also significantly enhances the material's applicability to real-world scenarios.},
  keywords={Software;Artificial intelligence;Task analysis;Software engineering;Codes;Chatbots;Knowledge engineering;Capstone courses;ChatGPT;context-aware learning;generative artificial intelligence (AI);large language models (LLMs);software engineering education},
  doi={10.1109/TLT.2024.3396735},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10554680,
  author={Cipriano, Bruno Pereira and Alves, Pedro},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard's Capacity to Handle Object-Oriented Programming Assignments}, 
  year={2024},
  volume={},
  number={},
  pages={162-169},
  abstract={Large Language Models (LLMs) have emerged as promising tools to assist students while solving programming assignments. However, object-oriented programming (OOP), with its inherent complexity involving the identification of entities, relationships, and responsibilities, is not yet mastered by these tools. Contrary to introductory programming exercises, there exists a research gap with regard to the behavior of LLMs in OOP contexts. In this study, we experimented with three prominent LLMs - GPT-3.5, GPT-4, and Bard - to solve real-world OOP exercises used in educational settings, subsequently validating their solutions using an Automatic Assessment Tool (AAT). The findings revealed that while the models frequently achieved mostly working solutions to the exercises, they often overlooked the best practices of OOP. GPT-4 stood out as the most proficient, followed by GPT-3.5, with Bard trailing last. We advocate for a renewed emphasis on code quality when employing these models and explore the potential of pairing LLMs with AATs in pedagogical settings. In conclusion, while GPT-4 show-cases promise, the deployment of these models in OOP education still mandates supervision.},
  keywords={Training;Codes;Object oriented modeling;Complexity theory;Object recognition;Object oriented programming;Programming profession;programming assignments;teaching;object-oriented programming;object-oriented design;OOP best practices;large language models;gpt-3;gpt-4;bard},
  doi={10.1145/3639474.3640052},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{10664775,
  author={Li, Max Z},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Using Prompt Engineering to Enhance STEM Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={With the advent of large language models (LLMs), such as ChatGPT, Gemini and LLaMA, there is no doubt that AI will forever change how education works. However, there is a gap between K-12 students and the LLM. The prompts given to LLM need to be well designed to be effectively utilized for K-12 education. To use LLMs more appropriately for K-12 STEM educational purposes, the author developed a prototype tool with prompt engineering to fully utilize the educational potential of LLMs and reduce usage for academic dishonesty. The tool would have a student register by giving the grade that they're in, and then ask as the topic the student would like to learn more about. Using prompt engineering techniques, the tool can prompt LLMs to produce educational content such as a descriptions, question and answer, AI-generated quizzes, and reviews, as well as asking the LLM to simplifying complex topics further to aid in understanding. The AI-enabled tool, effectively a virtual and personal mentor, could help propel STEM education further and make STEM more interesting to students as it could help explain complex topics in a way that students can understand easily. The tool and AI can help students understand a topic through interactive practice instead of just memorizing facts and putting them on a sheet of paper. The tool present in this paper will enhance the STEP education by AI.},
  keywords={Reviews;Large language models;Education;Prototypes;Propulsion;Chatbots;Registers},
  doi={10.1109/ISEC61299.2024.10664775},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{10834365,
  author={Alario-Hoyos, Carlos and Kemcha, Rebiha and Kloos, Carlos Delgado and Callejo, Patricia and Estévez-Ayres, Iria and Santín-Cristóbal, David and Cruz-Argudo, Francisco and López-Sánchez, José Luis},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Tailoring Your Code Companion: Leveraging LLMs and RAG to Develop a Chatbot to Support Students in a Programming Course}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Students frequently rely on chatbots powered by generative Artificial Intelligence (GenAI), such as ChatGPT, Copilot, Gemini, and Claude, to assist with a wide range of academic tasks. However, these chatbots are not specifically designed for the context of particular courses, which can lead to responses that are sometimes inaccurate or insufficiently relevant. This paper introduces a chatbot specifically designed to support first-year engineering students in a Java programming course. Developed using the Retrieval-Augmented Generation (RAG) technique, the chatbot draws on course-specific resources such as videos, quizzes, programming exercises, and other materials, while using OpenAI’s Large Language Models (LLMs) GPT-4 and GPT-3.5 for information analysis and response generation. The data collected, consisting of logs from 1,059 messages sent by students to the chatbot and 30 responses to a survey, indicate that students primarily used the chatbot to clarify concepts and explain code snippets. Moreover, most of the students reported that the responses provided by the chatbot were well suited to the Java programming course.},
  keywords={Surveys;Java;Codes;Large language models;Retrieval augmented generation;Learning (artificial intelligence);Programming;Chatbots;Videos;Information analysis;Large Language Models (LLMs);Retrieval-Augmented Generation (RAG);Generative Artificial Intelligence (GenAI);Chatbots;and Programming Course},
  doi={10.1109/TALE62452.2024.10834365},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10893528,
  author={Nath, Sagnik and Yoon, So Yoon},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: Beyond Code: Evaluating ChatGPT, Gemini, Claude, and Meta AI as AI Tutors in Computer Science and Engineering Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This Work-in-Progress research paper evaluates the validity of Large Language Models (LLMs) as conversational AI tutors for computer science learning. While current engineering education literature has predominantly emphasized the rapid evolution of LLMs as conversational AI tutors for programming languages, the exploration into their effectiveness within general STEM topics remains comparatively scarce. This WIP study thus centers on evaluating the potential of LLMs to facilitate understanding of core hardware design concepts critical to computer science and engineering (CSE) education. By cross-checking the responses from generative AI chatbots to an openended CSE-based question, we aimed to uncover how LLMs, such as ChatGPT-3.5, Claude, Gemini, and Meta AI, can contribute to teaching and learning of general CSE courses instead of a specifically coding-based one. Our method involved simulating a student query on the popular debate between CISC vs. RISC related to computer architecture and analyzing the chatbots' responses. This initial collection of data served as the foundation for a continual comparative analysis aimed at determining the inherent instructional value of each LLM and its validity and reliability. To systematically assess the responses, we introduced an evaluation framework focusing on metrics, such as response accuracy, persuasiveness, and depth of explanation. The current work anticipates not only enriching our understanding of how these advanced LLMs can support general CSE education but also identifying areas where further development is needed for a more holistic integration of LLM-based chatbots in assisting student comprehension in the overarching engineering education.},
  keywords={Computer science;Measurement;Reduced instruction set computing;Large language models;Computer architecture;Chatbots;Hardware;Reliability;Engineering education;STEM;Large Language Models (LLMs);computer engineering education;AI tutors;CISC;RISC;computer architecture;Instruction set architecture},
  doi={10.1109/FIE61694.2024.10893528},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10911947,
  author={Zaripova, Rinata R. and Danilov, Andrew V. and Salekhova, Leila L. and Fazliakhmetov, Timur R.},
  booktitle={2024 17th International Conference on Development in eSystem Engineering (DeSE)}, 
  title={The Development of Individualized Assignment Generator}, 
  year={2024},
  volume={},
  number={},
  pages={521-525},
  abstract={The article discusses the development of a system that uses artificial intelligence (AI) to generate individualized mathematics assignments for bilingual students in Tatarstan, Russia. The goal is to enhance learning by tailoring assignments to students’ linguistic preferences, cognitive styles, and knowledge levels. The system employs machine learning techniques and GPT-based models to create personalized tasks that align with curriculum goals while addressing linguistic diversity, particularly for Tatar-Russian bilinguals. The study evaluates several large language models (LLMs), including GPT-4, GPT-3.5 Turbo, YandexGPT, and GigaChat, based on their ability to generate math problems and content in the Tatar language. While GPT-4 and GPT-3.5 Turbo show superior performance in producing accurate and semantically correct problems, their proficiency in Tatar remains inconsistent. The research underscores the need for further development of LLMs to enhance content generation for bilingual educational contexts and highlights the potential of AI in advancing adaptive learning for mathematics education. Future directions include expanding the system’s functionality and testing its effectiveness across diverse educational settings.},
  keywords={Adaptive learning;Adaptation models;Large language models;Semantics;Machine learning;Linguistics;Mathematical models;Natural language processing;Optimization;Testing;Natural Language Processing;Bilingual Education;Adaptive Learning;Large Language Models;Tatar-Russian Bilingualism},
  doi={10.1109/DeSE63988.2024.10911947},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10852497,
  author={Brach, William and Košt’ál, Kristián and Ries, Michal},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={Can Large Language Model Detect Plagiarism in Source Code?}, 
  year={2024},
  volume={},
  number={},
  pages={370-377},
  abstract={The issue of code plagiarism represents a significant challenge in the academic environment. This study examines the potential of large language models (LLMs) in improving the detection of code plagiarism. The performance of several LLMs, including GPT-4o, GPT-3.5 Turbo, LLaMA 3, and CodeLlama, is evaluated in comparison to conventional tools, such as JPlag, across a range of levels of code plagiarism. The findings of our study illustrate that state-of-the-art LLMs are able to outperform traditional methods, particularly in the detection of sophisticated forms of plagiarism. GPT-4o exhibited the highest overall accuracy (78.70%) and an F1 score of 86.97%. It is important to note that open-source models, such as LLaMA 3 (accuracy 71.53%, F1 score 82.75%), demonstrated the ability to detect the most complex forms of plagiarism with the same accuracy as GPT-4o. While these results demonstrate the promising potential of LLMs in code similarity analysis, it is also evident that higher false positive rates may be an inherent limitation, emphasizing the need for human oversight. This study contributes valuable insights into the application of AI in maintaining code integrity and academic honesty, paving the way for more effective, interpretable, and fair plagiarism detection systems in software development education and practice. For further information, source code, and updates on this project, please visit our GitHub at https://github.com/fiit-ba/llm-plagiarism-check.},
  keywords={Measurement;Computer languages;Codes;Accuracy;Reviews;Plagiarism;Large language models;Source coding;Education;Software development management;large language models;natural language processing;code similarity;code plagiarism},
  doi={10.1109/FLLM63129.2024.10852497},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10479881,
  author={Popov, Vladislav S.},
  booktitle={2024 6th International Youth Conference on Radio Electronics, Electrical and Power Engineering (REEPE)}, 
  title={ChatGPT and Unified State Exam in Computer Science}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, it is presented the obtained and studied statistics of solving tasks of demo versions of the Unified State Exam (USE) in Computer Science 2011-2023 using the GPT-3.5 language model and ChatGPT. The obtained results of the Unified State Examination in Computer Science are presented, their analysis and the results of solving individual tasks are shown, examples of successful solutions of the Unified State Exam tasks in Computer Science, limitations when working with ChatGPT are described. Based on the results of solving exam tasks, ChatGPT scored 47-57 test scores in 2011-2014 before the cancellation of the test part, and also slightly overcame the threshold score in 2015-2017, 2019, 2020, did not score the points necessary for passing the USE in Computer Science in 2018, 2021-2023. Based on the obtained research data, a gradual complication of the USE exam model in Computer Science is shown, in which the test part of the exam in 2015 is abandoned and the computer format of the exam is introduced in 2021. Using the example of the USE in Computer Science, it is shown that ChatGPT, GPT-3.5 and similar language models can serve tool for expert assessment of the complexity of examination tasks and examination model.},
  keywords={Computer science;Power engineering;Computational modeling;Unified modeling language;Chatbots;Data models;Complexity theory;ChatGPT;GPT-3.5;language model;ChatGPT exam;USE in Computer Science;artificial intelligence testing},
  doi={10.1109/REEPE60449.2024.10479881},
  ISSN={2831-7262},
  month={Feb},}@INPROCEEDINGS{10892934,
  author={Andersen-Kiel, Noah and Linos, Panagiotis Panos},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Using ChatGPT in Undergraduate Computer Science and Software Engineering Courses: A Students' Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice full paper presents an empirical study aimed at evaluating the potential of ChatGPT, an advanced AI-driven chatbot, as a supplementary educational tool in undergraduate Computer Science and Software Engineering (CSSE) courses. The study, initiated in the summer of 2023, focused on assessing ChatGPT's capabilities in generating accurate and complete computer code, identifying and rectifying code defects (bugs), and its scalability in handling larger programs. To achieve this, we conducted a series of experiments with ChatGPT. In one experiment, we introduced bugs into small programs from introductory CSSE courses. ChatGPT was tasked with detecting these defects and providing recommendations for fixing them. We evaluated ChatGPT's effectiveness in bug detection, the quality of its recommendations, and the completeness of the proposed solutions. We sought answers to questions such as whether ChatGPT found all injected defects, provided appropriate recommendations, and delivered high-quality solutions based on criteria like code completeness, size, complexity, and readability. In another experiment, ChatGPT was asked to generate code for assignments from previous CSSE courses, including Intro to Computer Science and Programming in C++, Intro to Python Programming, and Object-Oriented Programming and Data Structures using Java. We assessed the generated code's correctness and quality in comparison to student-written code. Similarly, in a third experiment, we evaluated ChatGPT's ability to generate larger programs using requirement specifications from an upper-division CSSE course on Agile Software Engineering. Analyzing both qualitative and quantitative data from these experiments during the summer, we determined that ChatGPT showed promise as an educational tool. Consequently, we developed a plan to integrate ChatGPT into select CSSE courses for the fall semester of 2023. Specifically, ChatGPT was integrated into two of our introductory CSSE courses enabling students to utilize it for debugging assignments and generating practice questions for exam preparation. In addition, we encouraged student teams in our EPICS (Engineering Projects In Community Service) course to utilize ChatGPT as a supplementary aid to help them find and learn any new programming languages or technologies needed for their projects. Anonymous surveys were conducted at the beginning and at the end of these courses to collect feedback from students regarding their experiences with ChatGPT. Initial responses indicated that students were generally familiar with ChatGPT and expressed curiosity about its potential utility, although some skepticism was present. However, by the semester's end, students demonstrated a positive shift in perceptions. They appreciated ChatGPT's assistance in rectifying code bugs, especially after-hours. Additionally, students valued ChatGPT for generating practice questions for exams, despite some inconsistencies in its responses. In our EPICS course, students felt ChatGPT was useful for learning new technologies, though opinions varied on its project management benefits. Lastly, the majority of students felt that ChatGPT helped them adjust to their work progress, showing its potential utility in keeping pace with ongoing projects. Based on student feedback, we propose integrating ChatGPT into future CSSE courses. Finally, as AI -based tools become more integral to academic settings, we believe that disseminating our experiences could potentially enhance engineering and computing education.},
  keywords={Surveys;Codes;Scalability;Computer bugs;Project management;Chatbots;Object oriented programming;Programming profession;Software engineering;Python;AI;GenAl;Chatbot;ChatGPT;Software Engineering;Computer Science Education;EPICS},
  doi={10.1109/FIE61694.2024.10892934},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10673924,
  author={Lee, Jung X. and Song, Yeong-Tae},
  booktitle={2024 IEEE/ACIS 27th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)}, 
  title={College Exam Grader using LLM AI models}, 
  year={2024},
  volume={},
  number={},
  pages={282-289},
  abstract={By far, the most effective knowledge assessment in college education is to give students exam and grade their answers then assess their level of understanding. However, exam grading can be time-consuming, tedious, cumbersome, and sometimes the grading results are not consistent with the rubric. Here, we propose an AI based exam grader that can not only ease educators’ burden but also produce accurate, consistent, and precise grading results. We have used GPT-3.5, GPT-4.0, and Gemini-pro, respectively, as our grading engine. To verify the correctness, precision, and accuracy of our proposed grader, the results were compared with the instructor’s grading result and also with human grader such as teaching assistants. In our experiment, GPT-4.0 showed the most reliable and consistent results.},
  keywords={Accuracy;Education;Reliability engineering;Software reliability;Artificial intelligence;Engines;Software engineering;ChatGPT;Gemini;grading;college education;artificial intelligence;prompt engineering},
  doi={10.1109/SNPD61259.2024.10673924},
  ISSN={2693-8421},
  month={July},}@INPROCEEDINGS{10754661,
  author={Zabala, Eric and Narman, Husnu S.},
  booktitle={2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)}, 
  title={Development and Evaluation of an AI-Enhanced Python Programming Education System}, 
  year={2024},
  volume={},
  number={},
  pages={787-792},
  abstract={The integration of Artificial Intelligence (AI) in education has shown promising potential to enhance learning experiences and provide personalized assistance to students. However, existing AI-based educational tools often exhibit limitations, including inconsistent feedback, limited adaptability to diverse learning needs, and difficulties in delivering real-time and accurate assessments. These limitations restrict the full effectiveness of AI in supporting students’ educational journeys. In this paper, we present the development of an AI-based Python programming education system that integrates a Chatbot for student assistance, an automated grading system for feedback, and an entrance exam feature that suggests chapters and sections for review. The Chatbot and grading system employs GPT-3.5 Turbo, leveraging its extensive knowledge base, cost-effectiveness, time efficiency, and adaptability to various programming queries, which enhances student engagement. Although the system underwent interactive testing and continuous improvements, the development process encountered difficulties in maintaining consistent AI feedback and enhancing real-time performance. Users can take quizzes, receive grades, obtain personalized feedback, and get course recommendations. The grading system achieved 28/30 consistency with its output while the course recommendation system achieved $26 / 30$ consistency with its outputs. The results indicate that while the AI-based system aids in learning programming by providing instant feedback and recommendations for improvement, its effectiveness is limited. This project underscores the potential of AI to enhance educational tools and sets the stage for further advancements in AI-driven education systems.},
  keywords={Reviews;Education;Learning (artificial intelligence);Chatbots;Mobile communication;Real-time systems;Programming profession;Recommender systems;Python;Testing;Artificial Intelligence;Python;Education;Advanced Learning Technologies},
  doi={10.1109/UEMCON62879.2024.10754661},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10981398,
  author={Montoya Montoya, José Fabián and Lopez-Vargas, Jorge},
  booktitle={2025 IEEE Engineering Education World Conference (EDUNINE)}, 
  title={DS Generative AI for Supporting Teaching Activities}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={Generative Artificial Intelligence (GAI) has become significant in education, particularly for creating content, resources, and automating repetitive and timeconsuming tasks. This project explores GAI’s potential to support teachers in analyzing low-to-medium complexity programs of student’s tasks, supporting the activities of teachers. The proposed solution includes an API and web application built based on the GPT-4o Large Language Model (LLM), specifically designed for teachers. The methodology begins with a review of relevant literature review to identify scenarios where GAI have shown their potential in the educational field. Subsequently, the performance of the GPT-4o model is evaluated in the context of review and analysis of student’s source code, using the Teaching Plans which the task proposals are extracted along with their respective evaluation rubrics, determining the quality and effectiveness of generative AI within this real application.},
  keywords={Generative AI;Source coding;Large language models;Refining;Prototypes;Reliability engineering;Proposals;Iterative methods;Programming profession;Systematic literature review;generative artificial intelligence;education;programming;source code analysis;gpt-4o;api;web application},
  doi={10.1109/EDUNINE62377.2025.10981398},
  ISSN={},
  month={March},}@INPROCEEDINGS{10946635,
  author={Wang, Yizhuo and Cui, Shiqi and Wan, Rongxin and Wang, Jingyi and Wang, Fanggang},
  booktitle={2024 IEEE 24th International Conference on Communication Technology (ICCT)}, 
  title={Large Language Models Based Communication Simulation Platform}, 
  year={2024},
  volume={},
  number={},
  pages={1891-1895},
  abstract={In recent years, Large Language Models (LLMs) have been widely used in various fields, including personalized education, data analysis, disease diagnosis, and engineering design. These advancements have opened new possibilities for wireless communication engineering. In this paper, we propose an LLM-based human-machine collaborative framework to generate a simulation platform for the communication system. The proposed framework effectively combines human experience with the powerful generative capabilities of LLMs through well-designed prompt engineering techniques, enhancing the design of wireless communication systems. Specifically, the proposed prompt engineering framework directs the LLM in tasks such as requirement elicitation, system modeling, and code generation for different modules of wireless communication systems. Parallel tests on the commercially mature LLMs like GPT-3.5 and Claude 3 further demonstrate that our approach can improve the efficiency, quality, and reliability of the design process.},
  keywords={Wireless communication;Codes;Large language models;Human-machine systems;Collaboration;Systems modeling;Reliability engineering;Prompt engineering;Medical diagnosis;Signal to noise ratio;Code generation;human-machine collaboration;large language models;prompt engineering;wireless communication},
  doi={10.1109/ICCT62411.2024.10946635},
  ISSN={2576-7828},
  month={Oct},}@INPROCEEDINGS{10892822,
  author={Pu, Cong},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Integrating Generative AI with Data Structures and Algorithm Analysis Course Homework}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice full paper describes how to integrate generative Artificial Intelligence (AI) with Data Structures and Algorithm Analysis (CS2) homework at Oklahoma State University. Data Structures and Algorithm Analysis (CS2) course covers extremely important knowledge and skills of becoming a computer scientist. However, students might fail to meet the learning outcomes of CS2 course, somewhat due to the abstract nature of concepts but also because of a misunderstanding of concepts, the selection of inappropriate data structure and algorithm, a lack of effective debugging skills, and writing inefficient code. Currently we are in an Artificial Intelligence (AI) revolution, and generative AI (also widely known as AI chatbots) are already popular across college and university campuses. Generative AI that are designed to learn and mimic human conversation is capable of generating, translating, or paraphrasing text and answering questions in a way that is often indistinguishable from human-generated content. We investigate the above-mentioned potential challenges faced by students while learning CS2 course at Oklahoma State University (OSU) and redesign the course homework in Fall 2023 semester. The objectives of the redesigned course homework are to provide students with opportunities to use generative AI to support their learning in the CS2 course as well as measure the effectiveness of utilizing generative AI to improve student learning outcomes in the CS2 course. At the end of Fall 2023 semester, we conducted a student perception survey in the CS2 course and collected valuable feedback from 47 out of 61 students (77% response rate). In summary, 85.1%, 76.6%, 74.5%, 63.8%, and 70.2% respondents indicated that generative AI help to understand testing and debugging better, improve coding skills and code quality, design and implement efficient data structures and algorithms, select appropriate algorithms and data structures with the assistance of generative AI, and under-stand the importance of designing and implementing efficient data structures and algorithms, respectively. In this paper, we summarize the experience of redesigning CS2 course homework at OSU, share lessons learned, and provide candid suggestions for utilizing course homework in CS2 courses at other institutions.},
  keywords={Surveys;Codes;Translation;Generative AI;Debugging;Writing;Data structures;Chatbots;Encoding;Testing;Computer Science;Data Structures;Algorithm Analysis;CS2;Artificial intelligence (AI);Generative AI;AI Chatbots},
  doi={10.1109/FIE61694.2024.10892822},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11016406,
  author={Wang, Karen D. and Wu, Zhangyang and Tufts, L'Nard and Wieman, Carl and Salehi, Shima and Haber, Nick},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Scaffold or Crutch? Examining College Students' Use and Views of Generative AI Tools for STEM Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Developing problem-solving competency is central to Science, Technology, Engineering, and Mathematics (STEM) education, yet translating this priority into effective approaches to problem-solving instruction and assessment has been a significant challenge. The recent proliferation of generative artificial intelligence (genAI) tools like ChatGPT in higher education introduces new considerations: how to define problem-solving competency in a genAI era, and how these tools can help or hinder students' development of STEM problem-solving competency. Our research takes steps in examining these considerations by studying how and why college students are currently using genAI tools in their STEM coursework, with a specific focus on how they employ these tools to support their problem-solving. We conducted an online survey of 40 STEM college students from diverse institutions across the US. In addition, we surveyed 28 STEM faculty to understand instructor views on effective and ineffective genAI tool use in STEM courses and their guidance for students. Our findings reveal high adoption rates and diverse applications of genAI tools among STEM students. The most common use cases of genAI tools in STEM coursework include finding explanations, exploring related topics, summarizing readings, and helping with problem-set questions. The primary motivation for using genAI tools in STEM coursework was to save time. Moreover, we found that over half of the student participants reported simply inputting a problem for AI to generate solutions, potentially bypassing their own problem-solving processes. These findings indicate that despite high adoption rates, students' current approaches to utilizing genAI tools often fall short in enhancing their own STEM problem-solving competencies. The study also explored students' and STEM instructors' perceptions of the benefits and risks associated with using genAI tools in STEM education. Our findings provide insights into how to guide students on appropriate genAI use in STEM courses and how to design genAI-based tools to foster students' problem-solving competency.},
  keywords={Surveys;Generative AI;Educational technology;Chatbots;Problem-solving;Engineering education;STEM;Generative AI;Educational Technology;STEM},
  doi={10.1109/EDUCON62633.2025.11016406},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10662984,
  author={Meißner, Niklas and Speth, Sandro and Becker, Steffen},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Automated Programming Exercise Generation in the Era of Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Lecturers are increasingly attempting to use large language models (LLMs) to simplify and make the creation of exercises for students more efficient. Efforts are also being made to automate the exercise creation process in software engineering (SE) education. This study explores the use of advanced LLMs, including GPT-4 and LaMDA, for automated programming exercise creation in higher education and compares the results with related work using GPT-3.5-turbo. Utilizing applications such as ChatGPT, Bing AI Chat, and Google Bard, we identify LLMs capable of initiating different exercise designs. However, manual refinement is crucial for accuracy. Common error patterns across LLMs highlight challenges in complex programming concepts, while specific strengths in various topics showcase model distinctions. This research underscores LLMs' value in exercise generation, emphasizing the critical role of human supervision in refining these processes. Our concise insights cater to educators, practitioners, and other researchers seeking to enhance SE education through LLM applications.},
  keywords={Large language models;Refining;Manuals;Chatbots;Internet;Usability;Engineering education;Programming profession;Software engineering;Graphical user interfaces;AI-Generated Exercises;Large Language Models;Programming Exercises;Software Engineering Education},
  doi={10.1109/CSEET62301.2024.10662984},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10578839,
  author={Duong, Ta Nguyen Binh and Meng, Chai Yi},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Automatic Grading of Short Answers Using Large Language Models in Software Engineering Courses}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Short-answer based questions have been used widely due to their effectiveness in assessing whether the desired learning outcomes have been attained by students. However, due to their open-ended nature, many different answers could be considered entirely or partially correct for the same question. In the context of computer science and software engineering courses where the enrolment has been increasing recently, manual grading of short-answer questions is a time-consuming and tedious process for instructors. In software engineering courses, assessments concern not just coding but many other aspects of software development such as system analysis, architecture design, software processes and operation methodologies such as Agile and DevOps. However, existing work in automatic grading/scoring of text-based answers in computing courses have been focusing more on coding-oriented questions. In this work, we consider the problem of autograding a broader range of short answers in software engineering courses. We propose an automated grading system incorporating both text embedding and completion approaches based on recently introduced pre-trained large language models (LLMs) such as GPT-3.5/4. We design and implement a web-based system so that students and instructors can easily leverage autograding for learning and teaching. Finally, we conduct an extensive evaluation of our automated grading approaches. We use a popular public dataset in the computing education domain and a new software engineering dataset of our own. The results demonstrate the effectiveness of our approach, and provide useful insights for further research in this area of AI-enabled education.},
  keywords={Computer science;Training;Costs;Large language models;Focusing;Software;Encoding;automatic grading;large language models;embedding;software engineering courses;short answers},
  doi={10.1109/EDUCON60312.2024.10578839},
  ISSN={2165-9567},
  month={May},}@ARTICLE{10904141,
  author={Haldar, Susmita and Pierce, Mary and Fernando Capretz, Luiz},
  journal={IEEE Access}, 
  title={Exploring the Integration of Generative AI Tools in Software Testing Education: A Case Study on ChatGPT and Copilot for Preparatory Testing Artifacts in Postgraduate Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={46070-46090},
  abstract={Software testing education is important for building qualified testing professionals. To ensure that software testing graduates are ready for real-world challenges, it is necessary to integrate modern tools and technologies into the curriculum. With the emergence of Large Language Models (LLMs), their potential use in software engineering has become a focus, but their application in software testing education remains largely unexplored. This study, conducted in the Capstone Project course of a postgraduate software testing program, was carried out over two semesters with two distinct groups of students. A custom-built Travel Application limited to a web platform was used in the first semester. In the second semester, a new set of students worked with an open-source application, offering a larger-scale, multi-platform experience across web, desktop, and mobile platforms. Students initially created preparatory testing artifacts manually as a group deliverable. Following this, they were assigned an individual assignment to generate the same artifacts using LLM tools such as ChatGPT 3.5 in the first semester and Microsoft Copilot in the second. This process directly compared manually created artifacts and those generated using LLMs, leveraging AI for faster outputs. After completion, they responded to a set of assigned questions. The students’ responses were assessed using an integrated methodology, including quantitative and qualitative assessments, sentiment analysis to understand emotions, and a thematic approach to extract deeper insights. The findings revealed that while LLMs can assist and augment manual testing efforts, they cannot entirely replace the need for manual testing. By incorporating innovative technology into the curriculum, this study highlights how Generative AI can support active learning, connect theoretical concepts with practical applications, and align educational practices with industry needs.},
  keywords={Software testing;Education;Generative AI;Industries;Chatbots;Software engineering;Sentiment analysis;Large language models;Accuracy;Systematic literature review;Capstone project;ChatGPT;generative AI;software testing education;Microsoft Copilot;sentiment analysis},
  doi={10.1109/ACCESS.2025.3545882},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10229357,
  author={Berrezueta-Guzman, Jonnathan and Krusche, Stephan},
  booktitle={2023 IEEE 35th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Recommendations to Create Programming Exercises to Overcome ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={147-151},
  abstract={Large language models, such as ChatGPT, possess the potential to revolutionize educational practices across various domains. Nonetheless, the deployment of these models can inadvertently foster academic dishonesty due to their facile accessibility. In practical courses like programming, where hands-on experience is crucial for learning, relying solely on ChatGPT can hinder students’ ability to engage with the exercises, consequently impeding the attainment of learning outcomes.This paper conducts an experimental analysis of GPT 3.5 and GPT 4, gauging their proficiencies and constraints in resolving a compendium of 22 programming exercises. We discern and categorize exercises based on ChatGPT’s ability to furnish viable solutions, alongside those that remain unaddressed. Moreover, an evaluation of the malleability of the solutions proposed by ChatGPT is undertaken. Subsequently, we propound a series of recommendations aimed at curtailing undue dependence on ChatGPT, thereby fostering authentic competency development in programming. The efficaciousness of these recommendations is underpinned by their integration into the design and delivery of an examination as part of the corresponding course.},
  keywords={Chatbots;Programming profession;interactive learning;online training;education;assessment;plagiarism;autograder;large language models},
  doi={10.1109/CSEET58097.2023.00031},
  ISSN={2377-570X},
  month={Aug},}@INPROCEEDINGS{10190438,
  author={Neumann, Michael and Rauschenberger, Maria and Schön, Eva-Maria},
  booktitle={2023 IEEE/ACM 5th International Workshop on Software Engineering Education for the Next Generation (SEENG)}, 
  title={“We Need To Talk About ChatGPT”: The Future of AI and Higher Education}, 
  year={2023},
  volume={},
  number={},
  pages={29-32},
  abstract={On November 30th, 2022, OpenAI released the large language model ChatGPT, an extension of GPT-3. The AI chatbot provides real-time communication in response to users’ requests. The quality of ChatGPT’s natural speaking answers marks a major shift in how we will use AI-generated information in our day-to-day lives. For a software engineering student, the use cases for ChatGPT are manifold: assessment preparation, translation, and creation of specified source code, to name a few. It can even handle more complex aspects of scientific writing, such as summarizing literature and paraphrasing text. Hence, this position paper addresses the need for discussion of potential approaches for integrating ChatGPT into higher education. Therefore, we focus on articles that address the effects of ChatGPT on higher education in the areas of software engineering and scientific writing. As ChatGPT was only recently released, there have been no peer-reviewed articles on the subject. Thus, we performed a structured grey literature review using Google Scholar to identify preprints of primary studies. In total, five out of 55 preprints are used for our analysis. Furthermore, we held informal discussions and talks with other lecturers and researchers and took into account the authors’ test results from using ChatGPT. We present five challenges and three opportunities for the higher education context that emerge from the release of ChatGPT. The main contribution of this paper is a proposal for how to integrate ChatGPT into higher education in four main areas.},
  keywords={Manifolds;Source coding;Education;Chatbots;Real-time systems;Internet;Proposals;ChatGPT;GPT-3;large language model;higher education;AI influences;position paper},
  doi={10.1109/SEENG59157.2023.00010},
  ISSN={},
  month={May},}@INPROCEEDINGS{10892956,
  author={Hammond, Emily and Faber, Courtney},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Work in Progress: Integration of AI Tools on an Open-Ended Computer Programming Project}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress, innovative practice paper describes the design and implementation of a computer programming project that encouraged students to use artificial intelligence (AI) tools (e.g., ChatGPT). This innovative practice was implemented at a state university in an introduction to programming course. Course assessments included weekly homework assignments, an open-ended project, one quiz, and three midterm exams. Students were explicitly told in class and in the syllabus that no AI was allowed for weekly homework assignments; however, students were encouraged to use AI for the open-ended project. This decision was made because the problems on weekly assignments were more structured and could be easily solved by AI tools. In comparison, the learning objective of the project was focused on code design with open-ended requirements making it harder for AI to provide workable code. Students who reported using AI indicated that they used it to help start the project and/or a piece of the project and to aid in debugging or finding errors. Project grades were similar to grades seen in previous years for similar projects; however, grades on midterm two, which occurred after the project, were surprisingly higher than the grades for midterm one and higher than exam grades from previous years on similar topics. At this point, we do not know if/how the project contributed to these improved exam scores. Given the success of the project in its first implementation, Dr. E plans to use the assignment in future semesters. Additionally, Dr. C plans to collect data to begin exploring how the use of AI tools in this open-ended project supported students' learning and understanding of principles in the course.},
  keywords={Codes;Debugging;Chatbots;Artificial intelligence;Programming profession;undergraduate;learning technology;computational thinking},
  doi={10.1109/FIE61694.2024.10892956},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10734661,
  author={Dingle, Adam and Kruliš, Martin},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={Tackling Students’ Coding Assignments with LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={94-101},
  abstract={State-of-the-art large language models (LLMs) have demonstrated an extraordinary ability to write computer code. This ability can be quite beneficial when integrated into an IDE to assist a programmer with basic coding. On the other hand, it may be misused by computer science students for cheating on coding tests or homework assignments. At present, knowledge about the exact capabilities and limitations of state-of-the-art LLMs is still inadequate. Furthermore, their capabilities have been changing quickly with each new release. In this paper, we present a dataset of 559 programming exercises in 10 programming languages collected from a system for evaluating coding assignments at our university. We have experimented with four well-known LLMs (GPT-3.5, GPT-4, Codey, Code Llama) and asked them to solve these assignments. The evaluation results are intriguing and provide insights into the strengths and weaknesses of the models. In particular, GPT-4 (which performed the best) is currently capable of solving 55% of all our exercises and achieved an average score of 86% on exercises from the introductory programming course (using the best of five generated solutions).CCS CONCEPTS• Computing methodologies → Natural language processing; • General and reference → Evaluation; • Applied computing→ Education.},
  keywords={Computer languages;Codes;Large language models;Computational modeling;Conferences;Education;Encoding;Natural language processing;Programming profession;LLM;large language model;coding;programming;student assignment;teaching},
  doi={},
  ISSN={},
  month={April},}@ARTICLE{11015259,
  author={Liu, Shiqi and Liu, Sannyuya and Sha, Lele and Zeng, Zijie and Gašević, Dragan and Liu, Zhi},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Annotation Guideline-Based Knowledge Augmentation: Towards Enhancing Large Language Models for Educational Text Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Automated classification of learner-generated text to identify behavior, emotion, and cognition indicators, collectively known as learning engagement classification (LEC), has received considerable attention in fields such as NLP, learning analytics, and educational data mining. Recently, large language models (LLMs), such as ChatGPT, which are considered promising technologies for artificial general intelligence, have demonstrated remarkable performance in various NLP tasks. However, their capabilities in LEC tasks still lack comprehensive evaluation and improvement approaches. This study introduces a novel benchmark for LEC, encompassing six datasets that cover behavior classification (question and urgency level), emotion classification (binary and epistemic emotion), and cognition classification (opinion and cognitive presence). In addition, we propose the annotation guideline-based knowledge augmentation (AGKA) approach, which leverages GPT-4.0 to recognize and extract label definitions from annotation guidelines and applies random undersampling to select a representative set of examples. Experimental results demonstrate the following: AGKA enhances LLM performance compared to vanilla prompts, particularly for GPT-4.0 and Llama-3 70B; GPT-4.0 and Llama-3 70B with AGKA are comparable to fully fine-tuned models such as BERT and RoBERTa on simple binary classification tasks; for multiclass tasks requiring complex semantic understanding, GPT-4.0 and Llama-3 70B outperform the fine-tuned models in the few-shot setting but fall short of the fully fine-tuned models; Llama-3 70B with AGKA shows comparable performance to GPT-4.0, demonstrating the viability of these open-source alternatives; and the ablation study highlights the importance of customizing and evaluating knowledge augmentation strategies for each specific LLM architecture and task.},
  keywords={Annotations;Guidelines;Cognition;Text categorization;Chatbots;Benchmark testing;Prompt engineering;Tuning;Large language models;Training;Large language models (LLMs);text classification;learning engagement;prompt learning;knowledge augmentation},
  doi={10.1109/TLT.2025.3570775},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10457630,
  author={Hu, Yunwei and Goktas, Yavuz and Yellamati, David Deepak and De Tassigny, Catherine},
  booktitle={2024 Annual Reliability and Maintainability Symposium (RAMS)}, 
  title={The Use and Misuse of Pre-Trained Generative Large Language Models in Reliability Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Generative Large Language Models (LLMs) have garnered significant attention since the release of ChatGPT in November 2022. Researchers are actively exploring diverse applications to leverage the capabilities of these LLM systems. Within the field of reliability engineering there exists a potential for fruitful utilization of such models. In this paper, we delve into the applications of Large Language Models in reliability engineering, specifically focusing on their impressive language processing capabilities beyond traditional Natural Language Processing (NLP) tasks. Our study aims to evaluate the LLMs' potential in answering complex engineering questions and offering solutions to intricate problems. Additionally, we investigate the limitations of LLMs to understand their boundaries in providing accurate and reliable outputs. The paper emphasizes the significance of prompt engineering to enhance the accuracy and reliability of LLMs for improved performance in quantitative tasks. By incorporating minor prompt engineering techniques, the Large Language Models (LLMs), especially GPT-4, exhibited promising performance in answering Certified Reliability Engineer (CRE) exam questions. Our study involves an analysis of the errors made by the LLMs, allowing for a understanding of their limitations. Drawing from our findings, we provide recommendations on the appropriate application and areas to exercise caution when employing LLMs in the field of reliability engineering. These insights aim to guide practitioners in maximizing the benefits of LLMs while being mindful of their limitations and potential pitfalls. It is important to note that Generative AI and LLMs are rapidly evolving, and the evaluation conducted in this study reflects the test results at the time of writing. We anticipate that LLM responses may vary in the future. We are currently conducting research on developing applications based on LLMs to support the daily tasks of reliability engineers. We are excited about the possibilities and look forward to sharing our outcomes and contributing to the community.},
  keywords={Generative AI;Random access memory;Focusing;Writing;Reliability engineering;Chatbots;Task analysis;Large Language Model;Machine Learning;Reliability;FMEA},
  doi={10.1109/RAMS51492.2024.10457630},
  ISSN={2577-0993},
  month={Jan},}@INPROCEEDINGS{10578934,
  author={Murali, Ritwik and Dhanalakshmy, Dhanya M. and Avudaiappan, Veeramanohar and Sivakumar, Gayathri},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Towards Assessing the Credibility of Chatbot Responses for Technical Assessments in Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={The recent challenge in higher education is to convey the importance of understanding concepts over rote learning. This challenge has increased in complexity with the arrival of large language model (LLM) based chatbots. Students are increasingly looking to such AI based chatbots as “sources of wisdom” instead of utilizing the same as learning aids. Despite disclaimers by the LLM creators, many students turn to the chatbot for answers to almost all learning assignments. This research work explores the level to which the LLM responses can be utilized for student learning in technical education. By understanding the contradictions between student answers and the responses generated by the LLMs, this work explores the limitations of the LLM based environments towards providing acceptable answers for assessments - specifically within the computer science engineering domain. While numerous studies have concentrated on ChatGPT, it is essential to consider the diverse range of alternative chat-bots accessible online that students may also utilize. Therefore, this work considers 5 popular AI-based chatbots for the study. With the “prompt” being the prime factor that impacts the response from chat-bots, the responses of the chatbots were collected using 2 different prompting techniques. The chatbot responses were evaluated against actual student responses by multiple reviewers to gauge its effectiveness as appropriate student answers. Both students and all chatbots were given questions aligned with the Blooms taxonomy levels (BTL) 1 to 4 in three different subjects. Each of the courses included a diverse range of questions including text-based questions, mathematical problems, and programming questions. The results show that the chatbot responses were acceptable for low BT level questions but failed to answer convincingly when asked for an algorithm. Overall, the chatbot performance (across the tested LLMs) was below average when the question set covered the BTL range 1–4. However, since the answers up to BTL2 were acceptable, LLM based chatbot answers were able to barely pass 1–2 of the 3 subjects (with the best performers scoring near the pass mark). Based on these results, it is possible to conclude that LLM based chatbots cannot be depended on for higher order learning but can be used to aid students who are struggling to pass basic courses.},
  keywords={Technical management;Taxonomy;Grasping;Chatbots;Reliability;Problem-solving;Task analysis;AI Chat-bots;Large Language Models (LLMs);Education;Generative AI},
  doi={10.1109/EDUCON60312.2024.10578934},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10343171,
  author={Reynolds, Sarah and Pate, William C. and Ochoa, Omar},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={An Ontology and Management System for Learning Outcomes and Student Mastery}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Universities, faculty, and students use Learning Outcomes (LO) to create a shared understanding of the content provided in an individual course, known as Outcome-Based Education (OBE). One area of interest in OBE is evaluating whether the instructor and individual student performance have met the LO, which is integral to ensuring all invested parties are on the same page about class content and student performance. This work proposes a system for the management and evaluation of LO. Primarily, this work defines an ontology to support the management and evaluation of LO via Knowledge Graphs (KG). The KG links individual LO with individual assessment items. Two state-of-the-art Natural Language Processing models, BERT and ChatGPT, are evaluated in respect to their effectiveness in automating this linking. This data allows the educational professional to reflect on how well their assessments match the course's LO. The second part of this system harnesses student data to measure performance in relation to LO. In this Work-in-Progress paper, the system is prototyped and tested on the midterm results of a course in the Software Engineering curriculum. Student performance is documented in relation to each assessment question on the exams to measure student mastery of course material. Through this approach, courses can be evaluated and improved to deliver better quality education to all students. This includes improvements at the course level and possibilities for early intervention to ensure student success. This paper details the development of this system and through its implementation shows how it benefits engineering educators and their students.},
  keywords={Knowledge engineering;Taxonomy;Knowledge graphs;Ontologies;Market research;Chatbots;Software measurement;Learning outcomes;BERT;ontology;knowledge graph;assessment;Bloom's taxonomy},
  doi={10.1109/FIE58773.2023.10343171},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10967440,
  author={Tavasoli, Reza and VarastehNezhad, Arya and Masumi, Mostafa and Taghiyareh, Fattaneh},
  booktitle={2025 29th International Computer Conference, Computer Society of Iran (CSICC)}, 
  title={Analyzing the Mathematical Proficiency of Large Language Models in Computer Science Graduate Admission Tests}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This study evaluates the performance of six prominent Large Language Models (LLMs) on graduate entrance exam multiple-choice mathematics questions in computer science, computer engineering, and information technology programs, with a focus on their cross-lingual capabilities. The selected models, GPT-4o, Claude 3.5 Sonnet, Gemini 1.5 Pro, Llama 3.1 405B, Mistral Large 2, and Qwen 2.5 72B, were tested on 146 questions presented in both Persian and English, spanning four key mathematical domains. Results reveal significant variations in accuracy, with Gemini 1.5 Pro achieving the highest overall performance in English (63.70%) and Claude 3.5 leading in Persian (52.0%). However, some models struggled with maintaining consistent accuracy across languages, showing a cross-lingual performance gap. The findings underscore the potential of LLMs in addressing complex mathematical tasks but also highlight their current limitations, particularly in multilingual contexts. Notable disparities in model performance point to the importance of architectural innovations and multilingual training.},
  keywords={Training;Computer science;Adaptation models;Technological innovation;Accuracy;Large language models;Computational modeling;Mathematical models;Cognition;Multilingual;Large Language Models;Computer Science Education;Mathematical Reasoning;Graduate Entrance Exams;Generative AI;Large Language Models in Education},
  doi={10.1109/CSICC65765.2025.10967440},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10893343,
  author={Ramasamy, Vijayalakshmi and Ramamoorthy, Suganya and Walia, Gursimran Singh and Kulpinski, Eli and Antreassian, Aaron},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Enhancing User Story Generation in Agile Software Development Through Open AI and Prompt Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This innovative practice full paper explores the use of AI technologies in user story generation. With the emergence of agile software development, generating comprehensive user stories that capture all necessary functionalities and perspectives has become crucial for software development. Every computing program in the United States requires a semester-or year-long senior capstone project, which requires student teams to gather and document technical requirements. Effective user story generation is crucial for successfully implementing software projects. However, user stories written in natural language can be prone to inherent defects such as incompleteness and incorrectness, which may creep in during the downstream development activities like software designs, construction, and testing. One of the challenges faced by software engineering educators is to teach students how to elicit and document requirements, which serve as a blueprint for software development. Advanced AI technologies have increased the popularity of large language models (LLMs) trained on large multimodal datasets. Therefore, utilizing LLM-based techniques can assist educators in helping students discover aspects of user stories that may have been overlooked or missed during the manual analysis of requirements from various stakeholders. The main goal of this research study is to investigate the potential application of OpenAI techniques in software development courses at two academic institutions to enhance software design and development processes, aiming to improve innovation and efficiency in team project-based educational settings. The data used for the study constitute student teams generating user stories by traditional methods (control) vs. student teams using OpenAI agents (treatment) such as gpt-4-turbo for generating user stories. The overarching research questions include: RQ-l) What aspects of user stories generated using OpenAI prompt engineering differ significantly from those generated using the traditional method? RQ-2) Can the prompt engineering data provide insights into the efficacy of the questions/prompts that affect the quality and comprehensiveness of user stories created by software development teams? Industry experts evaluated the user stories created and analyzed how prompt engineering affects the overall effectiveness and innovation of user story creation, which provided guidelines for incorporating AI-driven approaches into software development practices. Overall, this research seeks to contribute to the growing body of knowledge on the application of AI in software engineering education, specifically in user story generation. Investigating the use of AI technologies in user story generation could further enhance the usability of prompt engineering in agile software development environments. We plan to expand the study to investigate the long-term effects of prompt engineering on all phases of software development.},
  keywords={Technical requirements;Technological innovation;Agile software development;Collaboration;Software;Prompt engineering;Stakeholders;Usability;Software engineering;Testing;Collaboration network;complex network analysis;structured collaboration network},
  doi={10.1109/FIE61694.2024.10893343},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10748200,
  author={Popescu, Diana M. and Joyner, David A.},
  booktitle={2024 IEEE Digital Education and MOOCS Conference (DEMOcon)}, 
  title={Novelty, Rigidity, and Complexity: Toward Developing AI-Resistant Assessments in an Introductory Computer Science Class}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Since the public launch of ChatGPT on November 20, 2022, there has been significant interest in its role in education. While some analyses focus on its potential to support student learning, a parallel line of investigation examines its potential to facilitate the false demonstration of competency on assessments. A broader underlying question is whether certain skills remain valuable to teach in the age of artificial intelligence, particularly in developing a new generation of computer programmers who continue to employ critical problem-solving skills in their work. The work presented in this paper examines the impact of large language models (LLMs), such as ChatGPT-4, on a college-level introductory computing course offered simultaneously as a massive open online course (MOOC) on the edX platform. The study focuses on the strengths and limitations of LLMs in solving coding assignments while also aiming to identify problems that are resistant to LLM solutions, so these types of specific categories could be employed by other instructors in their MOOC courses to provide a better experience for students. The paper explores GPT’s proficiency in various areas, including pseudo-code interpretation, handling multiple correct answers, and addressing complex problem statements. The goal is to create a robust framework that discourages over-reliance on AI assistance from some students while preserving the scalability of the course. This research provides insights into the dynamics of AI in education and emphasizes the need for a balanced approach between technological assistance and genuine student participation.},
  keywords={Resistance;Computer aided instruction;Electronic learning;Scalability;Large language models;Education;Chatbots;Rigidity;Problem-solving;Programming profession;E-learning;Artificial Intelligence;Applied Computing},
  doi={10.1109/DEMOcon63027.2024.10748200},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10260931,
  author={Laato, Samuli and Morschheuser, Benedikt and Hamari, Juho and Björne, Jari},
  booktitle={2023 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={AI-Assisted Learning with ChatGPT and Large Language Models: Implications for Higher Education}, 
  year={2023},
  volume={},
  number={},
  pages={226-230},
  abstract={The recent progress in generative AI models, particularly large language models (LLMs), has brought about a transformation in the field of education. Conversational LLM services, such as Google's Bard and OpenAI's ChatGPT, offer students access to many abilities such as summarization and generation of text and code, and on-demand replies to questions on expert topics. In this paper, we observe ChatGPT to explore how LLM services impact learning and instruction in higher education. First, we mapped the capabilities of the system by reviewing the grey literature on ChatGPT and using the system ourselves for two months. Second, we selected a Bachelor level computer science curriculum from a Finnish university, and examined the impact of ChatGPT on the offered courses. As an outcome of this study, we highlight 13 implications for students' learning in higher education, and discuss the contemporary future of AI-assisted learning in universities and beyond.},
  keywords={Computer science;Codes;Education;Chatbots;Internet;Artificial intelligence;ChatGPT;Bard;GPT-4;generative language models;large language models;higher education;learning},
  doi={10.1109/ICALT58122.2023.00072},
  ISSN={2161-377X},
  month={July},}@ARTICLE{10628100,
  author={Allen, Mia and Naeem, Usman and Gill, Sukhpal Singh},
  journal={IEEE Transactions on Education}, 
  title={Q-Module-Bot: A Generative AI-Based Question and Answer Bot for Module Teaching Support}, 
  year={2024},
  volume={67},
  number={5},
  pages={793-802},
  abstract={Contributions: In this article, a generative artificial intelligence (AI)-based Q&A system has been developed by integrating information retrieval and natural language processing techniques, using course materials as a knowledge base and facilitating real-time student interaction through a chat interface. Background: The rise of advanced AI exemplified by ChatGPT developed by OpenAI, has sparked interest in its application within higher education. AI has the potential to reshape education delivery through chatbots and related tools, improving remote learning and mitigating challenges, such as student isolation and educator administrative burdens. Yet, ChatGPT’s practical applications in education remain uncertain, potentially due to its novel and enigmatic nature. Additionally, current e-learning chatbot systems often suffer from development complexity and a lack of input from key stakeholders, leading to developer-focused solutions rather than user-centered ones. Intended Outcomes: In this manuscript, we introduce a practical implementation of AI in education by creating a system called Q-Module-Bot that is accessible for both technical and nontechnical educators to harness e-learning benefits and demystify generative pretraining transformer (GPT). Application Design: The proposed Q-Module-Bot system has utilized pretrained large language models (LLMs) to build a Q&A system that helps students with their queries and supports education delivery using content extracted from a virtual learning environment (VLE). Findings: The prototype and system evaluation confirm the effectiveness of a scalable cross-departmental tool featuring source attribution and real-time responses. While successful in encouraging wider acceptance of GPT use cases in higher education, refinements are needed for full integration into the VLE and expansion to other modules/courses.},
  keywords={Chatbots;Education;Artificial intelligence;Stakeholders;Electronic learning;Real-time systems;Plagiarism;Artificial intelligence (AI);chatbots;ChatGPT;e-learning;generative AI;information retrieval (IR);virtual learning environment (VLE)},
  doi={10.1109/TE.2024.3435427},
  ISSN={1557-9638},
  month={Oct},}@INPROCEEDINGS{10893452,
  author={Browning, Jonathan W. and Bustard, John and Anderson, Neil and Galway, Leo},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={A Data Science Course Utilizing GenAI}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This innovative practice full paper describes an indepth analysis of the pedagogical implications of incorporating generative artificial intelligence (genAI) tools, specifically Chat-GPT, into a data science course for postgraduate masters computing students. This research is grounded in the implementation of ChatGPT in a data analysis course, aiming to evaluate its effectiveness in fostering students' analytical and decision-making capabilities. The study employs a qualitative methodology to assess the educational outcomes of integrating ChatGPT, focusing on its impact on student engagement, learning efficiency, and the development of critical thinking skills in the context of data science. Through a combination of interviews, and analysis of students' project outcomes, we gather insights into the challenges and opportunities presented using genAI in the data science course. A notable innovation of our approach is the introduction of a dual-report assessment method, which not only evaluates the students' project results but also their proficiency in prompt engineering - a crucial skill for effective interaction with genAI tools. Our findings suggest that while students demonstrate enhanced data analysis skills, they also face difficulties in accurately framing queries to yield useful results from genAI, highlighting an essential area for further curriculum development. Further-more, the work delves into the pedagogical strategies that can optimize the benefits of genAI tools in education. It emphasizes the importance of a structured framework that guides students in the ethical use of genAI, encourages critical reflection on AI-generated content, and fosters a deeper understanding of the underlying algorithms and their implications for data science. The implications of this research extend beyond the classroom, offering valuable insights for instructors, curriculum developers, and policymakers on integrating AI technologies into educational practices. By providing a comprehensive overview of the benefits and challenges associated with the use of ChatGPT in data science education, this paper contributes to the ongoing dialogue on preparing students for a future where genAI might a significant role. In conclusion, this work highlights the potential of genAI to revolutionize data science education by enhancing analytical skills and decision-making capabilities. Continued exploration of effective strategies for integrating AI tools into learning environments, such as data science, is required to ensure that students are equipped with the knowledge and skills necessary to navigate the complexities of genAI for future employment.},
  keywords={Knowledge engineering;Technological innovation;Navigation;Education;Decision making;Data science;Chatbots;Reflection;Prompt engineering;Interviews;computer engineering;data science;education;generative artificial intelligence;student experience},
  doi={10.1109/FIE61694.2024.10893452},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11016399,
  author={Romão, Artur C. and Ribeiro, Fabianne and Sousa, Lúcia M. and Neves, António J. R.},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Mapping of Educational Course Descriptions to ESCO Competences Using Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The business sector currently faces a challenge in linking the descriptions of training offers with the actual skills acquired by participants at the time of its completion, posing a barrier for both workers when choosing job offers and companies when selecting candidates based on their skills. To address this issue, the European Union recently made available a database containing the multilingual taxonomy of European Qualifications, Competences, and Occupations (ESCO), which aims to be the fundamental reference for professional integration and mobility within Europe. This taxonomy works as a dictionary that categorizes and describes more than 3000 occupations and 13,900 competences. Consequently, the objective of this research was to develop a computational system capable of processing educational information from course descriptions and mapping it to ESCO competencies. Large Language Models (LLMs), specifically GPT-4, were used to assist in this task. In terms of implementation, the user can interact with the system based on an interface with a chat-like appearance and an API that integrates and communicates with the ESCO API and GPT-4 through Flowise, a workflow framework for LLMs. To validate the system's effectiveness, an experiment was conducted with professors coordinating various courses. They tested the platform and provided feedback on its performance in mapping course descriptions to the appropriate ESCO competences. The ultimate goal of this system is to benefit universities, students, and companies. For universities, it assists in mapping course descriptions to ESCO competencies. For students, it provides a clearer understanding of the skills they will gain from a specific course, assisting in career planning and personal development. For companies, it offers a reliable way to assess the skills of graduates, which improves hiring decisions.},
  keywords={Visualization;Accuracy;Large language models;Taxonomy;Europe;Companies;Reliability;Usability;Software engineering;Qualifications;taxonomies;training and educational offers;skills;information systems;large language models;artificial intelligence},
  doi={10.1109/EDUCON62633.2025.11016399},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10892816,
  author={Mazzone, Samuel B and Forden, Jack and Brylow, Dennis},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Exploring the Potential of Locally Run Large Language (AI) Models for Automated Grading in Introductory Computer Science Courses}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice full paper describes the effectiveness of self-hosted large language models (LLMs) in assisting with the automatic grading of CSI assignments. Educators often rely on automated review of student code submissions in larger courses. Despite recent advancements, current systems primarily focus on assessing functionality, with important aspects such as code structure, efficiency, and style often relegated to secondary foci. LLMs provide an increasingly attractive addition to these systems to enhance those overlooked areas. Prior research has shown LLM's capable of assisting students in understanding and resolving programmer error messages, correcting syntax errors, providing enhanced explanations of code segments, or even generating code. The absence of freely available, purpose-designed LLMs for grading and providing feedback on code submissions prevents widespread adoption by educators. Remotely-hosted systems, such as fine-tuned GPT models, have shown promise, yet the associated risks of privacy breaches, ethical considerations, and recurring costs make this approach unfeasible as a universal solution. To mitigate these concerns, self-hosted open-source models are an alternative that can operate on consumer-grade hardware and prevent some privacy and security concerns. While no purpose-built solution yet exists, it is unclear if any existing models are powerful enough to facilitate automated grading. To explore these questions, we present a two-phase analysis, leveraging real grading data from a semester length, introductory CSI course with 124 students and nine programming projects. Nine stable LLM models were selected and repeatedly prompted to grade student submissions using the same context that a human teaching assistant (TA) was given. This paper analyzes 1,172,383 API requests, totaling 33.4 days of active runtime, evaluating model consistency, ability to adhere to specified constraints, and comparison to human-generated grades. The results show various models' inability to consistently grade assignments, albeit with some exceptions. The importance of providing comprehensive context to models was highlighted, as incomplete contexts resulted in worse performance. Other models struggled with longer prompts, delivering less consistent results. Despite disparities between AI-generated and human-assigned grades, the potential for refinement is clear; improved rubrics or selective fine-tuning could enhance model output. Future work will focus on analyzing models' qualitative justifications for grades, refining rubrics, training on domain-specific datasets, and fine-tuning the highest performing models to potentially improve grading accuracy.},
  keywords={Training;Analytical models;Codes;Runtime;Computational modeling;Large language models;Syntactics;Complexity theory;Security;Context modeling;Large language model (LLMs);automated assessment tools (AATs);CSI},
  doi={10.1109/FIE61694.2024.10892816},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10837624,
  author={Timcenko, Olga},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Case Study: Using Artificial Intelligence as a Tutor for a Programming Course}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Artificial Intelligence (AI) has emerged as a key tool in reshaping education, particularly in programming courses. This paper presents a case study where second-semester Media Technology students used GitHub Copilot as a coding tutor throughout their coursework and for a three-day Game-jam, during which they developed 2D mobile games as part of their final exam. Students were encouraged to use Copilot to assist with homework assignments and game development, leading to significantly higher-quality projects compared to previous years. The study explores the impact of AI on student performance, the resulting shift in learning dynamics, and potential recommendations for enhancing curriculum and assessment methods in light of AI integration. This paper discusses the benefits, challenges, and recommendations for integrating AI in non-computer science education, emphasizing its role as a tutor for programming courses.},
  keywords={Training;Games;Media;Encoding;Artificial intelligence;Information technology;Programming profession;Software development management;Land mobile radio;Artificial Intelligence in Education;GitHub Copilot;Programming Education;Game Development;Unity;C#;AI Tutoring},
  doi={10.1109/ITHET61869.2024.10837624},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{11016293,
  author={Galatro, Daniela and Chakraborty, Sourojeet},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Strategies to Map Education 5.0 and Industry 5.0 in the Context of a Modernized Undergraduate Program in Chemical Engineering}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Education 5.0 is the direct application of novel technologies to consciously create a humanized, holistic teaching experience, to directly target the requirements of Industry 5.0. This work describes the design and implementation of a set of pedagogical strategies systematically employed to comprehensively map Education 5.0 and Industry 5.0, within the context of modernization of the undergraduate Chemical Engineering & Applied Chemistry program, clustered by (i) core courses such as Heat & Mass Transfer, (ii) electives such as Petroleum Processing, and (iii) 500level (undergraduate/graduate) advanced courses, such as Data Based Modelling for Prediction and Control. Implementation strategies include consciously integrating sustainability and engineering safety practices for chemical process design, using Generative Artificial Intelligence (Generative AI) in class to augment student self-learning, data-driven causation and machine learning versus first-principle-based phenomena analysis by employing dynamic process simulation and computational fluid dynamics tools, industry standards, codes and recommended practices, to instill active learning among students, and circularity indicators for process design and description. Examples of active learning initiatives embedded within our strategies include (i) the Petroleum Processing Lab, where students combine chatbots use and Machine Learning (ML) and/or simulation tools to analyze oil price market trends, mass balances crude distillation units, and risk assessments in oil refineries; and (ii) the Heat and Mass Transfer Lab, where students combine data analysis, machine learning and first-principles to describe and analyze heat convection relationships during the lectures. Chatbots assisted activities are qualitatively assessed for accuracy via a novel APC-EPE approach (Assumptions, Process description, and Calculations, with Effective Prompt Engineering); and we have successfully employed the APC-EPE framework to enhance the chances of chatbots providing accurate and reliable results aligned with students' expectations. Vertical integration of such strategies, right from sophomore to final years of our undergraduate program is implemented in tandem with standalone 'practices' in courses; and dedicated process design / capstone courses which combine several of these practices are offered. Our strategies are currently being assessed via anonymized student surveys, thereby attesting towards their effectiveness and high receptivity, as the department gradually transitions to a more modernized curriculum in upcoming years. Student and faculty feedback is identified as critical towards iteratively improving the course/curriculum design process in future, to ensure that the department's teaching approach towards realizing Education 5.0 is perceived as valuable to Industry 5.0 requirements and demands that employers seek from undergraduates. Our efforts are thus impactful towards creating future generations of the industry workforce trained in Education 5.0 to match Industry 5.0's requirements.},
  keywords={Process design;Industries;Accuracy;Computational fluid dynamics;Chemical engineering;Active learning;Machine learning;Chatbots;Fifth Industrial Revolution;Petroleum;Mapping Education 5.0 and Industry 5.0;curriculum modernization;Generative AI;simulation},
  doi={10.1109/EDUCON62633.2025.11016293},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10554757,
  author={Lehtinen, Teemu and Koutcheme, Charles and Hellas, Arto},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={Let's ask AI About Their Programs: Exploring ChatGPT's Answers to Program Comprehension Questions}, 
  year={2024},
  volume={},
  number={},
  pages={221-232},
  abstract={Recent research has explored the creation of questions from code submitted by students. These Questions about Learners' Code (QLCs) are created through program analysis, exploring execution paths, and then creating code comprehension questions from these paths and the broader code structure. Responding to the questions requires reading and tracing the code, which is known to support students' learning. At the same time, computing education researchers have witnessed the emergence of Large Language Models (LLMs) that have taken the community by storm. Researchers have demonstrated the applicability of these models especially in the introductory programming context, outlining their performance in solving introductory programming problems and their utility in creating new learning resources. In this work, we explore the capability of the state-of-the-art LLMs (GPT-3.5 and GPT-4) in answering QLCs that are generated from code that the LLMs have created. Our results show that although the state-of-the-art LLMs can create programs and trace program execution when prompted, they easily succumb to similar errors that have previously been recorded for novice programmers. These results demonstrate the fallibility of these models and perhaps dampen the expectations fueled by the recent LLM hype. At the same time, we also highlight future research possibilities such as using LLMs to mimic students as their behavior can indeed be similar for some specific tasks.},
  keywords={Training;Codes;Storms;Source coding;Writing;Data models;Task analysis;QLCs;large language models;artificial intelligence;introductory programming;program comprehension},
  doi={},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{10342898,
  author={Tran, Andrew and Angelikas, Kenneth and Rama, Egi and Okechukwu, Chiku and Smith, David H. and MacNeil, Stephen},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Generating Multiple Choice Questions for Computing Courses Using Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Generating high-quality multiple-choice questions (MCQs) is a time-consuming activity that has led practitioners and researchers to develop community question banks and reuse the same questions from semester to semester. This results in generic MCQs which are not relevant to every course. Template-based methods for generating MCQs require less effort but are similarly limited. At the same time, advances in natural language processing have resulted in large language models (LLMs) that are capable of doing tasks previously reserved for people, such as generating code, code explanations, and programming assignments. In this paper, we investigate whether these generative capabilities of LLMs can be used to craft high-quality M CQs more efficiently, thereby enabling instructors to focus on personalizing MCQs to each course and the associated learning goals. We used two LLMs, GPT-3 and GPT-4, to generate isomorphic MCQs based on MCQs from the Canterbury Question Bank and an Introductory to Low-level C Programming Course. We evaluated the resulting MCQs to assess their ability to generate correct answers based on the question stem, a task that was previously not possible. Finally, we investigate whether there is a correlation between model performance and the discrimination score of the associated MCQ to understand whether low discrimination questions required the model to do more inference and therefore perform poorly. GPT-4 correctly generated the answer for 78.5% of MCQs based only on the question stem. This suggests that instructors could use these models to quickly draft quizzes, such as during a live class, to identify misconceptions in real-time. We also replicate previous findings that GPT-3 performs poorly on answering, or in our case generating, correct answers to MCQs. We also present cases we observed where LLMs struggled to produce correct answers. Finally, we discuss implications for computing education.},
  keywords={Codes;Correlation;Computational modeling;Education;Real-time systems;Natural language processing;Recycling;large language models;generative AI;multiple-choice questions;computing education},
  doi={10.1109/FIE58773.2023.10342898},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10343296,
  author={Chan, Miguel Morales and Amado-Salvatierra, Hector R. and Hernandez-Rizzardini, Rocael and De La Roca, Mónica},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={The potential role of AI-based Chatbots in Engineering Education. Experiences from a teaching perspective}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The irruption of Artificial Intelligence (AI) based chatbot tools is undoubtedly at the frontiers of education. AI chatbots in education has emerged as a promising solution to enhance the quality of education and to improve learning outcomes. As all new technology does, it has begun to generate news about prohibition, ethical aspects, anti-plagiarism detection tools, and a series of policies from different educational systems. However, we should not deny the positive aspects of these tools if they are well used. AI-based chatbots have interesting potential to help both teachers and students, who must learn to use them well for their own benefit. This article provides an overview of AI-based chatbots, particularly ChatGPT, an artificial intelligence language model developed by OpenAI. GPT, or “Generative Pre-Training Transformer” is a neural network trained to generate “human-like text” by predicting the next word in a sequence given a large dataset of examples. ChatGPT uses the neural network model and is used to generate responses to students' questions in real time, in the sense of a personal teacher assistant. Chatbots are designed to be able to carryon a natural conversation by understanding the context of the conversation, generating appropriate responses, and engaging in active interaction. Nowadays, this type of tool can generate more than just text; for example, the use of LaTeX code (using TeXGPT) or tools for coding and debugging programming exercises. This work explores the potential role that AI-based chatbots can have in engineering education, by examining the answers of a group of teachers' about how the use of AI-based chatbots can improve the learning process of the students in engineering education. The questions that teachers had to answer, from a pedagogical and technological perspective, are related to how chatbots can be integrated into the curriculum to enhance the efficiency of engineering education, their potential impact on the learning process, and actual examples of possible learning activities using AI-based chatbots in their courses.},
  keywords={Training;Education;Neural networks;Oral communication;Chatbots;Transformers;Real-time systems;AI-based education;Engineering education;Natural Language Processing},
  doi={10.1109/FIE58773.2023.10343296},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10976353,
  author={Gong, Liuying and Chen, Jingyuan and Wu, Fei},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Is ChatGPT a Competent Teacher? Systematic Evaluation of Large Language Models on the Competency Model}, 
  year={2025},
  volume={18},
  number={},
  pages={530-541},
  abstract={The capabilities of large language models (LLMs) in language comprehension, conversational interaction, and content generation have led to their widespread adoption across various educational stages and contexts. Given the fundamental role of education, concerns are rising about whether LLMs can serve as competent teachers. To address the challenge of comprehensively evaluating the competencies of LLMs as teachers, a systematic quantitative evaluation based on the competency model has emerged as a valuable approach. Our study, grounded in the teacher competency model and drawing from 14 existing scales, constructed an evaluation framework called TeacherComp. Based on TeacherComp, we evaluated six LLMs from OpenAI across four dimensions: knowledge, skills, values, and traits. Through comparisons between LLMs’ responses and human norms, we found that: 1) with each successive update, LLMs have shown overall improvements in knowledge, while their skills dimension scores have increasingly aligned with human norms; 2) there are both commonalities and differences in the performance of various LLMs regarding values and traits. For instance, while they all tend to exhibit more negative traits than humans, their morals can vary; and 3) LLMs with reduced security, constructed using jailbreak techniques, exhibit values and traits more closely aligned with human norms. Building on these findings, we provided interpretations and suggestions for the application of LLMs in various educational contexts. Overall, this study helps teachers and students use LLMs in appropriate contexts and provides developers with guidance for future iterations, thereby advancing the role of LLMs in empowering education.},
  keywords={Education;Ethics;Chatbots;Systematics;Standards;Security;Psychology;Large language models;Generative AI;Ciphers;Evaluation;large language models (LLMs);teacher competency},
  doi={10.1109/TLT.2025.3564177},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10663001,
  author={Jacobs, Sven and Jaschke, Steffen},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Leveraging Lecture Content for Improved Feedback: Explorations with GPT-4 and Retrieval Augmented Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper presents the use of Retrieval Augmented Generation (RAG) to improve the feedback generated by Large Language Models for programming tasks. For this purpose, corresponding lecture recordings were transcribed and made available to the Large Language Model GPT-4 as external knowledge source together with timestamps as metainformation by using RAG. The purpose of this is to prevent hallucinations and to enforce the use of the technical terms and phrases from the lecture. In an exercise platform developed to solve programming problems for an introductory programming lecture, students can request feedback on their solutions generated by GPT-4. For this task GPT-4 receives the students' code solution, the compiler output, the result of unit tests and the relevant passages from the lecture notes available through the use of RAG as additional context. The feedback generated by GPT-4 should guide students to solve problems independently and link to the lecture content, using the time stamps of the transcript as meta-information. In this way, the corresponding lecture videos can be viewed immediately at the corresponding positions. For the evaluation, students worked with the tool in a workshop and decided for each feedback whether it should be extended by RAG or not. First results based on a questionnaire and the collected usage data show that the use of RAG can improve feedback generation and is preferred by students in some situations. Due to the slower speed of feedback generation, the benefits are situation dependent.},
  keywords={Codes;Large language models;Conferences;Recording;Programming profession;Videos;Programming Education;Feedback;Large language Models;GPT-4;Retrieval Augmented Generation},
  doi={10.1109/CSEET62301.2024.10663001},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{11016495,
  author={Brieven, Géraldine and Malcev, Lev and Donnet, Benoit},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={How to Automate Feedback on Diagrammatic Reasoning with a Relevant Degree of Freedom?}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This paper considers Café 2.0, an Automated Feedback system designed to support students' diagrammatic reasoning in STEM disciplines. Café 2.0 relies on a predefined error library, metamodels, and rules to correct students' solutions and deliver formative feedback. Implementing such a system requires a balance between constraining the solution syntax to enable AF and leaving freedom to students to reflect on their solution. This paper aims to evaluate whether the level of freedom provided by our AF system sufficiently prepares students for exams. In the exam, they must reason and construct solutions starting with a blank page. This study is conducted in an introductory programming course (CS1), based on two semesters (in 2022 and 2023), where Café 2.0 supports online homework. Findings reveal a discrepancy between students' performance in online homework and their success on exams. While many students feel comfortable with fill-in-the-blank diagrams in their homework, they struggle with the open-ended nature of exam tasks. Our results show that, among the students who succeeded in their online homework in 2023, $20\%$ were still unable to produce any diagram in the exam. Additionally, $70\%$ of them could not correctly provide a text description of their solution. To overcome this limitation, this paper proposes an enhanced system that integrates predefined rules with Large Language Models (LLMs). In this framework, LLMs serve as translators. Students can freely create their diagrams and annotate them with their own textual descriptions using a drawing editor. The LLM then maps these representations into a more structured format that aligns with predefined rules. In this way, Café 2.0 can generate accurate feedback. This transformed representation retains the same informational content as the original, differing only in format. This feature will offer students greater flexibility in constructing their solutions while ensuring that feedback remains precise and consistent by limiting the role of LLMs to translation rather than feedback generation.},
  keywords={Hands;Translation;Limiting;Large language models;Symbols;Metamodeling;Syntactics;Programming;Cognition;Libraries;automated feedback;diagrammatic reasoning;metamodeling;error detection;large language model},
  doi={10.1109/EDUCON62633.2025.11016495},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10663045,
  author={Vierhauser, Michael and Groher, Iris and Antensteiner, Tobias and Sauerwein, Clemens},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Towards Integrating Emerging AI Applications in SE Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Artificial Intelligence (AI) approaches have been incorporated into modern learning environments and software engineering (SE) courses and curricula for several years. However, with the significant rise in popularity of large language models (LLMs) in general, and OpenAI's LLM-powered chatbot ChatGPT in particular in the last year, educators are faced with rapidly changing classroom environments and disrupted teaching principles. Examples range from programming assignment solutions that are fully generated via ChatGPT, to various forms of cheating during exams. However, despite these negative aspects and emerging challenges, AI tools in general, and LLM applications in particular, can also provide significant opportunities in a wide variety of SE courses, supporting both students and educators in meaningful ways. In this early research paper, we present preliminary results of a systematic analysis of current trends in the area of AI, and how they can be integrated into university-level SE curricula, guidelines, and approaches to support both instructors and learners. We collected both teaching and research papers and analyzed their potential usage in SE education, using the ACM Computer Science Curriculum Guidelines CS2023. As an initial outcome, we discuss a series of opportunities for AI applications and further research areas.},
  keywords={Systematics;Large language models;Learning (artificial intelligence);Chatbots;Market research;Artificial intelligence;Engineering education;AI;Roadmap;Software Engineering Education},
  doi={10.1109/CSEET62301.2024.10663045},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10465292,
  author={Butgereit, Laurie and Abugosseisa, Muna Mahmoud},
  booktitle={2023 First International Conference on the Advancements of Artificial Intelligence in African Context (AAIAC)}, 
  title={Final Results: Prof Pi and GPT-4 Tutoring Mathematics in Arabic through Whatsapp}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Mathematics is an ancillary subject in many fields of study. At a university level, mathematics courses are often required of students whose primary course of study might be medicine or computer science. This paper presents the final results of a project which used OpenAI’s GPT-4 API to tutor mathematics to university level students studying at a university in Khartoum, Sudan. The tutoring was done in Arabic. The authors were curious not only of the quality of the mathematics tutoring provided by GPT-4 but also by the quality of the Arabic language input to GPT-4 and output from GPT-4. The GPT-4 API was accessible to students as a Whatsapp bot and students could use the bot 24 hours per day. The Whatsapp bot was named Prof Pi. Although Prof Pi as an artifact has been previously reported by the authors, a brief description of how Prof Pi works is provided in this paper for the convenience of the reader. The primary goal of this paper, however, is to present the final results from questionnaires filled by the students who took part in the research.},
  keywords={Computer science;Freeware;Urban areas;Chatbots;Mathematics;Internet telephony;Interviews;GPT-4;chatGPT;Whatsapp;Mathematics;Tutoring},
  doi={10.1109/AAIAC60008.2023.10465292},
  ISSN={},
  month={Nov},}@BOOK{10522552,
  author={Bodungen, Clint and Crow, Aaron},
  booktitle={ChatGPT for Cybersecurity Cookbook: Learn practical generative AI recipes to supercharge your cybersecurity skills},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Master ChatGPT and the OpenAI API and harness the power of cutting-edge generative AI and large language models to revolutionize the way you perform penetration testing, threat detection, and risk assessment.Key FeaturesEnhance your skills by leveraging ChatGPT to generate complex commands, write code, and create toolsAutomate penetration testing, risk assessment, and threat detection tasks using the OpenAI API and Python programmingRevolutionize your approach to cybersecurity with an AI-powered toolkitPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionAre you ready to unleash the potential of AI-driven cybersecurity? This cookbook takes you on a journey toward enhancing your cybersecurity skills, whether you’re a novice or a seasoned professional. By leveraging cutting-edge generative AI and large language models such as ChatGPT, you'll gain a competitive advantage in the ever-evolving cybersecurity landscape. ChatGPT for Cybersecurity Cookbook shows you how to automate and optimize various cybersecurity tasks, including penetration testing, vulnerability assessments, risk assessment, and threat detection. Each recipe demonstrates step by step how to utilize ChatGPT and the OpenAI API to generate complex commands, write code, and even create complete tools. You’ll discover how AI-powered cybersecurity can revolutionize your approach to security, providing you with new strategies and techniques for tackling challenges. As you progress, you’ll dive into detailed recipes covering attack vector automation, vulnerability scanning, GPT-assisted code analysis, and more. By learning to harness the power of generative AI, you'll not only expand your skillset but also increase your efficiency. By the end of this cybersecurity book, you’ll have the confidence and knowledge you need to stay ahead of the curve, mastering the latest generative AI tools and techniques in cybersecurity.What you will learnMaster ChatGPT prompt engineering for complex cybersecurity tasksUse the OpenAI API to enhance and automate penetration testingImplement artificial intelligence-driven vulnerability assessments and risk analysesAutomate threat detection with the OpenAI APIDevelop custom AI-enhanced cybersecurity tools and scriptsPerform AI-powered cybersecurity training and exercisesOptimize cybersecurity workflows using generative AI-powered techniquesWho this book is forThis book is for cybersecurity professionals, IT experts, and enthusiasts looking to harness the power of ChatGPT and the OpenAI API in their cybersecurity operations. Whether you're a red teamer, blue teamer, or security researcher, this book will help you revolutionize your approach to cybersecurity with generative AI-powered techniques. A basic understanding of cybersecurity concepts along with familiarity in Python programming is expected. Experience with command-line tools and basic knowledge of networking concepts and web technologies is also required.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781805125112},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10522552},}@INPROCEEDINGS{10722841,
  author={Akbar Khan, Muhammad Fawad and Ramsdell, Max and Nguyen, Ha and Karimi, Hamid},
  booktitle={2024 IEEE 11th International Conference on Data Science and Advanced Analytics (DSAA)}, 
  title={Human Evaluation of GPT for Scalable Python Programming Exercise Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Online coding platforms (OCPs) often offer a limited selection of exercises, which can restrict the scope of Computer Science (CS) education. This study investigates the capabilities of Large Language Models (LLMs), particularly GPT-4 Turbo, in broadening this scope by autonomously generating Python programming exercises. These exercises are tailored to the CS1 curriculum-an introductory course in computer science. Utilizing curriculum-driven prompt engineering, we developed a dataset of 11,700 exercises, characterized by a variety of cate-gories, types, and difficulty levels. These exercises are distributed across 78 unique topics, which were derived from the CS1 course catalogs of leading universities and supplemented with online educational resources. To evaluate the effectiveness of GPT-4 Turbo in generating CSI Python programming exercises, we conducted a user study involving both students and instruc-tors. The study focused on several metrics: exercise quality, curriculum relevance, understandability, appropriate difficulty level, and the generation of useful hints. Our findings indicate that GPT-4 Turbo can produce high-quality, educationally effective programming exercises at scale, provided that the prompts are systematically crafted. Based on insights from the user study, adjustments to prompt design are recommended to optimize exercise generation. Our research concludes that GPT-4 Turbo can be seamlessly integrated into AI-driven OCPs, offering a scalable, cost and time-effective method to enhance CS edu-cation. This is achieved through targeted prompt engineering and thorough data preprocessing to mitigate inconsistencies. The code is available online: https://github.com/DSAatUSU/GPT_CS1400_Exercise_Generation},
  keywords={Measurement;Large language models;Education;Data science;Encoding;Computer science education;Prompt engineering;Programming profession;Standards;Python;Large Language Models;GPT;Python Exercises Generation;Human Evaluation Computer Science Education},
  doi={10.1109/DSAA61799.2024.10722841},
  ISSN={2766-4112},
  month={Oct},}@ARTICLE{10553643,
  author={Karnouskos, Stamatis},
  journal={IEEE Open Journal of the Industrial Electronics Society}, 
  title={The Relevance of Large Language Models for Project Management}, 
  year={2024},
  volume={5},
  number={},
  pages={758-768},
  abstract={The rise of artificial intelligence, particularly the emergence of large language models (LLMs) like ChatGPT, continuously reveals numerous advantages across various domains. However, the area of project management has not yet been sufficiently explored. This study fills the research gap by conducting an empirical evaluation of three well-known LLMs: OpenAI's ChatGPT-3.5 and ChatGPT-4, as well as Google's Bard. The evaluation involves subjecting these LLMs to tests designed to prepare professionals for project management certification by the Project Management Institute. The findings cast a positive light on all three LLMs, with each model achieving scores exceeding 82%. Key insights acquired include: LLMs demonstrate the ability to effectively answer project management certification exam questions; LLMs and project managers should be viewed as a dynamic and complementary partnership; and project management certification should evolve to include an assessment of how project managers collaborate with LLMs to enhance project management.},
  keywords={Project management;Certification;Chatbots;Best practices;Generative AI;Artificial intelligence;Large language models;Bard;ChatGPT;Generative artificial intelligence (AI);large language models (LLMs);project management},
  doi={10.1109/OJIES.2024.3412222},
  ISSN={2644-1284},
  month={},}@INPROCEEDINGS{10343037,
  author={Maher, Mary Lou and Tadimalla, Sri Yash and Dhamani, Dhruv},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={An Exploratory Study on the Impact of AI tools on the Student Experience in Programming Courses: an Intersectional Analysis Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress paper presents a study that sheds light on the concerns that students may not develop sufficient programming skills and as a result, be less competent with the use of ChatGPT. The potential benefits for students are significant: Access to ChatGPT increases the ability for students to work constructively on their own schedule. The ease of use of ChatGPT may engage students who might otherwise hesitate in asking for support. Before these tools can be meaningfully introduced into a course, work must be done to study the impact of these AI tools on a student's ability to learn. In this study, participants are recruited from introductory Java programming courses at a large public university in the United States. This paper presents preliminary findings from a mixed method study design that consists of a pre-task assessment quiz; and a programming task in one of three conditions: (1) with no external help, (2) with the help of an AI chatbot, or (3) with the help of a generative AI tool like GitHub Copilot; followed by a post-task assessment and an interview on their experience and perceptions of the tools. Our preliminary findings describe our data collection, thematic analysis of the students' prompts and chatGPT responses, and a summary of the experience for 3 students. Our findings demonstrate a range of students' attitudes and behaviors towards chatGPT that provides insight for future research and plans for incorporating such AI tools in a course.},
  keywords={Java;Schedules;Data collection;Chatbots;Behavioral sciences;Artificial intelligence;Task analysis;ChatGPT;CS education;Student Experience;Intersectionality},
  doi={10.1109/FIE58773.2023.10343037},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10467740,
  author={Butgereit, Laurie and Abugosseisa, Muna Mahmoud and Elbashir, Mohammed},
  booktitle={2024 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)}, 
  title={Dynamic Reconfiguring of GPT-4 Based Tutors to Become GPT-4 Based Teachers in Underserved Areas in Africa and the Environs}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The popular GPT-4 API boasts excellent academic records of passing a number of standardized tests. As such it is used in a number of tutoring systems providing students and pupils with access to artificially intelligent tutors when help is not easily available. Tutoring and teaching, however, are different. In many underserved areas in Africa and the environs, students and pupils may attend formal school but then after hours no tutors are nearby to assist them with their studies and homework. Previous research by the authors has described mobile tutoring artifacts linking the popular Whatsapp mobile chat app with GPT-4 to provide that tutoring. In other underserved areas (especially in war torn areas), however, there may not be even teachers to provide the initial classroom instruction or Zoom based instruction. In such case these mobile tutoring artifacts need to be dynamically reconfigured to act as full teachers to these students. This paper describes the research to dynamically reconfigure GPT-4 based mobile tutors to become GPT-4 based mobile teachers wheGPT-4, chatGPT, Whatsapp, Tutoring, Java Programmingn necessary.},
  keywords={Freeware;Java;Education;Africa;Chatbots;Pupils;Internet telephony;component;formatting;style;styling;insert},
  doi={10.1109/ACDSA59508.2024.10467740},
  ISSN={},
  month={Feb},}@BOOK{10769215,
  author={Meyer, Lucas A.},
  booktitle={Building AI Applications with Microsoft Semantic Kernel: Easily integrate generative AI capabilities and copilot experiences into your applications},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Unlock the power of GenAI by effortlessly linking your C# and Python apps with cutting-edge models, orchestrating diverse AI services with finesse, and crafting bespoke applications through immersive, real-world examplesKey FeaturesLink your C# and Python applications with the latest AI models from OpenAICombine and orchestrate different AI services such as text and image generatorsCreate your own AI apps with real-world use case examples that show you how to use basic generative AI, create images, process documents, use a vector databasePurchase of the print or Kindle book includes a free PDF eBookBook DescriptionIn the fast-paced world of AI, developers are constantly seeking efficient ways to integrate AI capabilities into their apps. Microsoft Semantic Kernel simplifies this process by using the GenAI features from Microsoft and OpenAI. Written by Lucas A. Meyer, a Principal Research Scientist in Microsoft’s AI for Good Lab, this book helps you get hands on with Semantic Kernel. It begins by introducing you to different generative AI services such as GPT-3.5 and GPT-4, demonstrating their integration with Semantic Kernel. You’ll then learn to craft prompt templates for reuse across various AI services and variables. Next, you’ll learn how to add functionality to Semantic Kernel by creating your own plugins. The second part of the book shows you how to combine multiple plugins to execute complex actions, and how to let Semantic Kernel use its own AI to solve complex problems by calling plugins, including the ones made by you. The book concludes by teaching you how to use vector databases to expand the memory of your AI services and how to help AI remember the context of earlier requests. You’ll also be guided through several real-world examples of applications, such as RAG and custom GPT agents. By the end of this book, you'll have gained the knowledge you need to start using Semantic Kernel to add AI capabilities to your applications.What you will learnWrite reusable AI prompts and connect to different AI providersCreate new plugins that extend the capabilities of AI servicesUnderstand how to combine multiple plugins to execute complex actionsOrchestrate multiple AI services to accomplish a taskLeverage the powerful planner to automatically create appropriate AI callsUse vector databases as additional memory for your AI tasksDeploy your application to ChatGPT, making it available to hundreds of millions of usersWho this book is forThis book is for beginner-level to experienced .NET or Python software developers who want to quickly incorporate the latest AI technologies into their applications, without having to learn the details of every new AI service. Product managers with some development experience will find this book helpful while creating proof-of-concept applications. This book requires working knowledge of programming basics.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835469590},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10769215},}@INPROCEEDINGS{10602701,
  author={Luen William, Cheong Weng and Lim, Tong Ming},
  booktitle={2024 IEEE 4th International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB)}, 
  title={Comparative Studies: Leveraging Large Language Model In Theoritical and Practical Assessment Sample Question-Answer Bank on Programming Related Subjects}, 
  year={2024},
  volume={},
  number={},
  pages={331-335},
  abstract={Practical Code Assessment has been important in assessing students' level of understanding, coding, and assessing/evaluating. One of the challenges faced by lecturers is the difficulty in producing questions and answers creatively. To address this issue, an experimental proof-of-concept (POC) prototype was developed using Natural Language Processing (NLP) and Prompt Engineering techniques in the Large Language Model (LLM) to generate practical and high-quality questions and answers. Two Large Language Models, namely LLaMa2-7b and Mixtral-7b were compared to provide a scalable POC solution. Through evaluation and benchmarking, the prototype was tested based on Human-level Performance (HLP) standards. This prototype enhanced the work efficiency of the lecturers as it shortened the time to create questions and answers for assessments, which eventually enhanced learning outcomes and the educational, learning, and teaching experience.},
  keywords={Training;Codes;Large language models;Prototypes;Natural language processing;Encoding;Prompt engineering;large language model (LLM);natural language processing (NLP);prompt engineering;practical code assessment},
  doi={10.1109/ICEIB61477.2024.10602701},
  ISSN={},
  month={April},}@INPROCEEDINGS{10825505,
  author={Le, Linh and Tran, Dung},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={On Text Granularity and Metric Frameworks for Large Language Model Content Detection}, 
  year={2024},
  volume={},
  number={},
  pages={8301-8308},
  abstract={Breakthroughs in Large Language Models (LLMs) have allowed Artificial Intelligence (AI) assistant systems to provide quality information with conveniences. An issue is paralleling the advantages, however. One among the problems of LLM generated content is that they seem indistinguishable from that of human which leads to numerous issues in areas like science, education, information security, etc. Furthermore, approaches in LLM content detection are either computationally expensive or need the LLMs’ internal computations which make them more difficult to be used by the public. Addressing the research gap, we present a metric learning framework for LLM text detection that is balanced for resources, accessibility, and performance. Specifically, the detection framework relies on metric learning to evaluate the similarity between a given text to an equivalent example from LLMs and verify whether the former is from human or AI. The framework can be trained in triplets or pairs of text instances from the same contexts at either the full-text or the sentence granularity levels. For benchmarking, five corpora totalling over 95,000 contexts and responses from human and GPT-3.5 TURBO or GPT-4 TURBO are developed. In term of performance, our architectures maintain 0.87 to 0.95 F1 scores throughout multiple experiment settings. Our framework also requires much less time in training and inference compared to RoBERTa, LLaMA 3, and Ghostbuster, while having 90% to 150% performances of the best benchmark.},
  keywords={Measurement;Training;Computational modeling;Large language models;Training data;Text detection;Computer architecture;Benchmark testing;Transformers;Vectors;LLM text detection;metric learning;text granularity;triplet learning;contrastive learning},
  doi={10.1109/BigData62323.2024.10825505},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10893501,
  author={Chan, Rosanna Yuen-Yan and Chan, Cecilia Ka Yuk and Jong, Morris Siu-Yung and Hu, Zihao and Zhang, Yuming},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: Engineering Class Students' Epistemic Cognition when Interacting with Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work in progress belongs to the innovative practice category. Nowadays, generative AI (also known as GenAI) can produce novel data samples that closely resemble authentic datasets. The advent of large language models (LLMs), in particular, has caused a huge interest in utilizing GenAI within and beyond the realm of higher education. However, little about engineering students' views and behaviours related to knowing and knowledge when using GenAI, such as ChatGPT, is known. In this WIP, we have engaged a class of N = 37 engineering students taking a postgraduate course titled “Social Media Analytics”. They were required to write essays related to their course learning in the form of blog posts. They were required to use LLM tools, such as ChatGPT, to assist their writing processes. Their GenAI usage was guided by the cognitive-agent approach, Search Tree, Analyze and Repair, and Selection (STARS), while STARS was proposed by Kirk et al. in AAAI 2024 to extend and complement prompt engineering. In addition, the participants were invited to fill in the Epistemic Cognition Inventory (ECI) questionnaire to associate five aspects of epistemic cognition (EC) with their writing experience. It is confirmed in our results that students' EC, i.e., their beliefs related to knowledge and knowing, significantly predict their prompting engagement and academic performance. However, students' academic performance is found to be significantly and negatively associated with their preference for GenAI usage. Here, we have uncovered engineering students' EC when interacting with generative AI, an area where little has been known so far. Our findings also suggest that proper use of GenAI prompting might promote engineering students' EC and, therefore, engineering learning.},
  keywords={Social networking (online);Education;Stars;Writing;Maintenance engineering;Chatbots;Cognition;Reliability;Prompt engineering;Engineering students},
  doi={10.1109/FIE61694.2024.10893501},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10343457,
  author={Kiesler, Natalie and Lohr, Dominic and Keuning, Hieke},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Exploring the Potential of Large Language Models to Generate Formative Programming Feedback}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Ever since the emergence of large language models (LLMs) and related applications, such as ChatGPT, its performance and error analysis for programming tasks have been subject to research. In this work-in-progress paper, we explore the potential of such LLMs for computing educators and learners, as we analyze the feedback it generates to a given input containing program code. In particular, we aim at (1) exploring how an LLM like ChatGPT responds to students seeking help with their introductory programming tasks, and (2) identifying feedback types in its responses. To achieve these goals, we used students' programming sequences from a dataset gathered within a CS1 course as input for ChatGPT along with questions required to elicit feedback and correct solutions. The results show that ChatGPT performs reasonably well for some of the introductory programming tasks and student errors, which means that students can potentially benefit. However, educators should provide guidance on how to use the provided feedback, as it can contain misleading information for novices.},
  keywords={Analytical models;Codes;Error analysis;Computational modeling;Chatbots;Task analysis;Programming profession;ChatGPT;large language models;feedback;feedback types;introductory programming},
  doi={10.1109/FIE58773.2023.10343457},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10578596,
  author={Weber, Jason L and Neda, Barbara Martinez and Juarez, Kitana Carbajal and Wong–Ma, Jennifer and Gago–Masague, Sergio and Ziv, Hadar},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Beyond the Hype: Perceptions and Realities of Using Large Language Models in Computer Science Education at an R1 University}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={With the mainstream adoption of Large Language Models (LLMs) over the last year, members of both academia and the media have raised concerns around the potential impact on student learning and pedagogy. Many students and educators wonder about the pedagogical fit of this emerging technology. We aim to measure the adoption and perception of LLMs among the CS education community in an R1 University to distinguish reality from hype. To this end, we conduct a large survey study targeting three populations participating in computing courses at the university: intro-sequence students (ISS), experienced students (ES), and faculty. Our survey seeks to gather insight around the different populations' perceptions of LLMs in education, as well as how these perceptions may be changing as LLMs improve. Our results show several significant differences across the views of 760 respondents. Most students report LLMs' un-paralleled potential for quick information access, yet many harbor concerns about their reliability and impact on academic integrity. Additionally, while ES rapidly integrate LLMs into their learning, ISS and faculty remain cautious, highlighting a stark contrast in adoption rates. Faculty are unconvinced of LLMs' educational benefits and are concerned about potential challenges in evaluating students' learning outcomes. LLMs are reshaping pedagogical approaches and student engagement. However, with the notable reservations expressed by certain segments, particularly by faculty and ISS, there is an imperative for careful, informed, and ethical integration to ensure that these tools enhance rather than compromise the educational experience.},
  keywords={Surveys;Ethics;Accuracy;Atmospheric measurements;Sociology;Media;Particle measurements;Large Language Models (LLMs);Generative AI;Academic Integrity;Student Perception;Faculty Perception;ChatGPT;AI Tools},
  doi={10.1109/EDUCON60312.2024.10578596},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10843532,
  author={Alidadi, Marzieh and Taghiyareh, Fattaneh and Shahhoseini, Narges},
  booktitle={2024 11th International Symposium on Telecommunications (IST)}, 
  title={Evaluating LLM-Generated Persian Questions for Teaching Conditional Programming Using Bloom’s Taxonomy}, 
  year={2024},
  volume={},
  number={},
  pages={726-730},
  abstract={The use of Large Language Models (LLMs) to generate educational content is increasingly becoming popular, but we still need to learn more about their effectiveness in non-English languages, especially for professional areas such as teaching computational concepts. Using Bloom’s taxonomy as a framework of assessment, this study evaluates the ability of LLMs to author Persian (Farsi) Learning Objects (LOs) for teaching conditional programming. We provided four LLMs (BloomGPT, Code Tutor, Copilot, and LLaMa) with a prompt in Persian to create educational questions and exercises to teach conditional programming structures to novice learners. A group of experts was asked to evaluate questions generated by LLMs based on their alignment with the specified level of Bloom’s cognitive domain, suitability for teaching conditional programming structures, and clarity in using Persian language. Results show almost no agreement among experts in language clarity and fair agreement on other aspects of the study. BloomGPT proves itself to be dominant overall in Bloom’s Taxonomy, especially at the “Analyze” level. Meanwhile, Copilot closely followed Code Tutor in most aspects of the study. Our findings provide insights into the ability of LLMs to design high-quality Persian learning resources in computer programming.},
  keywords={Codes;Large language models;Taxonomy;Education;Telecommunications;Programming profession;Large Language Models (LLMs);Artificial Intelligence (AI);Learning Objects (LOs);Educational Contents;Persian;Question Generation;Bloom’s Taxonomy},
  doi={10.1109/IST64061.2024.10843532},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10664825,
  author={Simaremare, Mario E. S. and Pardede, Chandro and Tampubolon, Irma N. I. and Simangunsong, Daniel A. and Manurung, Putri E.},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={The Penetration of Generative AI in Higher Education: A Survey}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Context: The global teacher shortage crisis is a severe challenge. The crisis also rises in Indonesia, where the problem extends to unequal teaching quality and learning facilities. This situation seriously threatens the Indonesian 2045 vision of being a developed country with knowledgeable human resources. The advancement of AI brings opportunities to address the challenges. In recent years, there has been a wave of generative AI (GenAI) technologies and their adoption in education. However, there is no research on the penetration of such technology in our learning environment. Objective: In this study, we investigate the penetration of GenAI by students in a higher education setting. Method: We surveyed 1,157 students of Institut Teknologi Del, a private university in western Indonesia, and developed local knowledge based on the responses. Results: Our results show that most students are well aware of GenAI technologies (70.96%) and have used them to support their learning (98.96%). The top five most used GenAI tools are GitHub Copilot, OpenAI ChatGPT, Codex, Grammarly, and ChatPDF. Conclusion: GenAI is already part of the daily learning process. We believe that, sooner or later, GenAI will be one of many deciding factors in our future education systems, and we must be ready to adapt to it.},
  keywords={Surveys;Ethics;Generative AI;Source coding;Education;Knowledge based systems;Chatbots;education;generative AI;student;survey},
  doi={10.1109/ISEC61299.2024.10664825},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{10343215,
  author={Hallan Graven, Olaf and MacKinnon, Lachlan},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Developing Higher Education – Post-Pandemic – Influenced by AI}, 
  year={2023},
  volume={},
  number={},
  pages={01-08},
  abstract={The impact of the recent pandemic on Higher Education has been widely discussed in terms of the effects on students and the loss of the normal educational experience, accompanied by discussions of how to return to normality. However, in this paper the authors challenge the reality of that previous so-called normality and propose a number of changes to academic practices to take advantage of the opportunities offered by this break in existing practice. Additionally, new developments in AI technology, particularly in chatbots, present significant challenges to existing assessment practices, which were already under challenge from existing research. This also presents significant opportunities to introduce new, academically focused and effective assessment practices and instruments, taken from existing research, to improve the quality of evaluation of student learning in higher education. So, this paper has two main considerations: the development of better student engagement models to enhance cohort effects in the student experience; and the introduction of improved assessment practices and instruments from existing research, in particular focusing on student ownership of evaluation models. It discusses a number of existing research outputs, several of them produced by the authors, and some current initiatives, and looks at the pros and cons of each, in terms of effectiveness and staff and student responses. It has been widely reported that the student experience across a wide range of subjects, and in the whole range of higher education institutions, has been very badly affected by lockdowns and other changes brought about by the pandemic. In the engineering/computing community the authors have experienced first-hand the changes occasioned during this period, and have seen students become isolated, disaffected, anti-social and, in many cases, disengaged from their studies. It can be argued that one key criterion of the student experience that online delivery of learning does not support well is cohort-formation, and that developing entry-level cohort-based learning experiences, both online and face-to-face, offers a route more effective student engagement and retention. The authors discuss a number of such initiatives reported in existing research, and also describe a new initiative being developed at their own institution, based on early immersion in advanced technologies to spark interest and creativity, and thence engagement, in entry-level technology students. With regard to assessment and evaluation practices, there is a huge body of existing research questioning the widely used examination and coursework processes, arguing that these are only retained for administrative and cost efficiencies, not for any academic benefit. The recent release of ChatGPT by OpenAI has added considerable flame to the fire of essay-mills, code-farms, and bespoke thesis-writing, which has supported students cheating in assessment processes for many years. The authors take this opportunity to reconsider assessment practices, in the light of many successful models reported in the existing research, and to develop a new model of assessment, where students take responsibility for the ownership and evaluation of their own learning, mediated by academic processes.},
  keywords={Pandemics;Publishing;Instruments;Education;Force;Focusing;Fires;Assessment;AI;Cohort building;student engagement},
  doi={10.1109/FIE58773.2023.10343215},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10196869,
  author={Feng, Yunhe and Vanam, Sreecharan and Cherukupally, Manasa and Zheng, Weijian and Qiu, Meikang and Chen, Haihua},
  booktitle={2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Investigating Code Generation Performance of ChatGPT with Crowdsourcing Social Data}, 
  year={2023},
  volume={},
  number={},
  pages={876-885},
  abstract={The recent advancements in Artificial Intelligence, particularly in large language models and generative models, are reshaping the field of software engineering by enabling innovative ways of performing various tasks, such as programming, debugging, and testing. However, few existing works have thoroughly explored the potential of AI in code generation and users’ attitudes toward AI-assisted coding tools. This knowledge gap leaves it unclear how AI is transforming software engineering and programming education. This paper presents a scalable crowdsourcing data-driven framework to investigate the code generation performance of generative large language models from diverse perspectives across multiple social media platforms. Specifically, we utilize ChatGPT, a popular generative large language model, as a representative example to reveal its insights and patterns in code generation. First, we propose a hybrid keyword word expansion method that integrates words suggested by topic modeling and expert knowledge to filter relevant social posts of interest on Twitter and Reddit. Then we collect 316K tweets and 3.2K Reddit posts about ChatGPT’s code generation, spanning from Dec. 1, 2022 to January 31, 2023. Our data analytics show that ChatGPT has been used in more than 10 programming languages, with Python and JavaScript being the two most popular, for a diverse range of tasks such as code debugging, interview preparation, and academic assignment solving. Surprisingly, our analysis shows that fear is the dominant emotion associated with ChatGPT’s code generation, overshadowing emotions of happiness, anger, surprise, and sadness. Furthermore, we construct a ChatGPT prompt and corresponding code dataset by analyzing the screen-shots of ChatGPT code generation shared on social media. This dataset enables us to evaluate the quality of the generated code, and we have released this dataset to the public. We believe the insights gained from our work will provide valuable guidance for future research on AI-powered code generation.},
  keywords={Codes;Social networking (online);Debugging;Chatbots;Software;Task analysis;Interviews;ChatGPT;Coding Generation;Software Engineering;Large Language Models (LLMs);Generative Models;Social Media},
  doi={10.1109/COMPSAC57700.2023.00117},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{10893102,
  author={Oh, Sunggyeol and Cao, Yi and Katz, Andrew and Zhao, Jialu},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Explore Public's Perspectives on Generative AI in Computer Science (CS) Education: A Social Media Data Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research-to-practice full paper aims to analyze the public's comments on generative artificial intelligence (GAI) in computer science (CS) education, by the BERT-based model and Large Language Model (LLM) approaches to sentiment analysis and contextualize the results within broader educational and technological landscapes. Artificial intelligence (AI) has played a crucial role in advancing technical development throughout many areas. Evidence points toward the likelihood of major developmental breakthroughs unfolding soon in those sectors. Education is one such area. While there is certainly a possibility for hype and unfulfilled promises, the advent of available GAI platforms, such as ChatGPT, has caused a surge of scholarly interest in the impact of these technologies on CS education. Amid the growing debate, both the potential benefits and concerns of GAI in this sector are increasingly coming to the fore as people grapple with the tradeoffs associated with these technologies when applied in education settings. One can imagine the range of conversations around the topic, but that is difficult to use as input for policymakers and administrators without a more concrete understanding. To wit, there remain open questions about which benefits and concerns people tend to focus on when discussing GAI in education. This large-scale qualitative study addresses that gap by exploring the public's perspectives on GAI in CS education. We engage in this work by collecting and analyzing data from social media platforms, specifically Reddit comments. The social media dataset was analyzed using machine learning (ML) techniques to identify topics based on sentiment analysis. The study's objective was to document and characterize the public's perspectives concerning the general characteristics of GAI, its features related to learning, and its usability in educational settings. Through sentiment analysis using Large Language Models (LLM), the study revealed an overall positive public perception toward using generative AI in CS education, with over 57% of comments being favorable, while also identifying prominent topics of interest and concerns, such as the potential benefits of personalized learning support and automated grading, as well as issues like academic dishonesty, perpetuation of biases, over-reliance on AI hindering critical thinking, displacement of human instructors, and the need for updated curricula. The insights gleaned from the analysis will be instrumental in computing educators gaining a more profound comprehension of GAI 'srole in education and the subsequent development of GAI -enriched curricula.},
  keywords={Computer science;Bridges;Sentiment analysis;Ethics;Social networking (online);Generative AI;Large language models;Education;Problem-solving;Artificial intelligence;Generative AI;computer science education;social media dataset;sentiment analysis},
  doi={10.1109/FIE61694.2024.10893102},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10893046,
  author={Liu, Yi},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Integrating Conversational Large Language Models into Student Learning: A Case Study of ChatGPT in Software Engineering Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This innovative practice full paper describes a pilot study exploring the integration of ChatGPT, a Conversational Large Language Model (LLM), into the student learning process in software engineering education, which emphasizes principles and methodologies in software development. Focused on a software engineering class, the study examines ChatGPT as a tool for problem clarification, modeling assistance, system design feedback, and implementation support in a project on modeling, designing, and implementing a solution using finite state processes and concurrent programming in Java. A survey designed for the case study collects insights into students' experiences with ChatGPT at different stages of the project. Student feedback on using ChatGPT and their performance on the project are analyzed to understand the impact of conversational LLMs on learning outcomes and to address whether there is room for improvement in enhancing the use of conversational LLMs in software engineering education.},
  keywords={Surveys;Java;Software design;Large language models;Education;Programming;Chatbots;System analysis and design;Software engineering;Software development management;Conversational LLMs;ChatGPT;Software en-gineering education},
  doi={10.1109/FIE61694.2024.10893046},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10977933,
  author={Luo, Xiao and O'Connell, Sean and Mithun, Shamima},
  booktitle={2025 IEEE Symposium on Computational Intelligence in Natural Language Processing and Social Media (CI-NLPSoMe Companion)}, 
  title={Assessing Personalized AI Mentoring with Large Language Models in the Computing Field}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper provides an in-depth evaluation of three state-of-the-art Large Language Models (LLMs) for personalized career mentoring in the computing field, using three distinct student profiles that consider gender, race, and professional levels. We evaluated the performance of GPT-4, LLaMA 3, and Palm 2 using a zero-shot learning approach without human intervention. A quantitative evaluation was conducted through a custom natural language processing analytics pipeline to highlight the uniqueness of the responses and to identify words reflecting each student's profile, including race, gender, or professional level. The analysis of frequently used words in the responses indicates that GPT-4 offers more personalized mentoring compared to the other two LLMs. Additionally, a qualitative evaluation was performed to see if human experts reached similar conclusions. The analysis of survey responses shows that GPT-4 outperformed the other two LLMs in delivering more accurate and useful mentoring while addressing specific challenges with encouragement languages. Our work establishes a foundation for developing personalized mentoring tools based on LLMs, incorporating human mentors in the process to deliver a more impactful and tailored mentoring experience.},
  keywords={Surveys;Accuracy;Social networking (online);Engineering profession;Large language models;Zero shot learning;Pipelines;Natural language processing;Mentoring;Computational intelligence;AI mentoring;Natural Language Processing;Large Language Models;Computing Education},
  doi={10.1109/CI-NLPSoMeCompanion65206.2025.10977933},
  ISSN={},
  month={March},}@INPROCEEDINGS{10391549,
  author={Hajj, Jana Al and Sah, Melike},
  booktitle={2023 7th International Symposium on Innovative Approaches in Smart Technologies (ISAS)}, 
  title={Assessing the Impact of ChatGPT in a PHP Programming Course}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={ChatGPT changed the way of learning for both instructors and students. Since its introduction, it has attracted a lot of attention from learners as well as instructors. In this paper, the impact of ChatGPT in a PHP programming course using user studies was investigated. User studies were conducted in two different universities in North Cyprus with a total of 50 students. Students were divided into two groups and asked to perform two quizzes; (a) manually alone and (b) with the assistance of ChatGPT. To remove the learning effect, quizzes were swapped; the first student performed the quiz manually first, then perform the second quiz with the help of ChatGPT with similar questions. Subsequently, the second student performed the quiz using ChatGPT first, then perform the second quiz manually next. Swapping continued for all students. Furthermore, to understand the impact of ChatGPT on different question types in a programming course, the quizzes were designed with different question categories: Classical, True/False, multiple choices, and coding. After completing each quiz (manual or assistance of ChatGPT), post-questionnaires were also given to assess the attitudes of learners to the exams. Results of the user study were analyzed in terms of scores (correct answers), post-questionnaires as user attitudes and statistical paired t-tests. Results indicated that ChatGPT had statistically significant positive effect on coding questions, as well as, statistically moderate positive effect on classical and True/False questions. However, for multiple choice questions, there is no significant difference between the results of manual exam and exam with the assistance of ChatGPT for the programming course. User ratings for post-questionnaires also confirm these results.},
  keywords={Manuals;Programming;Chatbots;Encoding;Artificial intelligence;AI chatbot;ChatGPT;technology for teaching;user study;questionnaire;artificial intelligence},
  doi={10.1109/ISAS60782.2023.10391549},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10911129,
  author={Gomes, Roseline Florence and Thomas, Lijo},
  booktitle={2024 IEEE 4th International Conference on ICT in Business Industry & Government (ICTBIG)}, 
  title={DIP AI-Driven Architecture for Enhanced Project Management Using Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The integration of Large Language Models (LLMs), such as GPT-4, Claude, and Gemini AI, into project management systems has revolutionized how tasks are automated, tracked, and optimized. This paper presents a comparative analysis of LLMs in the context of project management, evaluating their performance in scheduling, resource allocation, and decision support. By leveraging both primary data from real-world simulations and secondary data from literature, the study highlights GPT-4’s superior accuracy, task completion speed, and scalability over other models. The findings suggest that AI-based systems can enhance efficiency and reduce human error in complex project management workflows.},
  keywords={Automation;Accuracy;Generative AI;Large language models;Scalability;Government;Project management;Data models;Resource management;Electronics packaging;Large Language Models;Project Management;GPT-4;Claude;Gemini AI;Automation;AI-based Scheduling;Resource Allocation;Generative AI},
  doi={10.1109/ICTBIG64922.2024.10911129},
  ISSN={},
  month={Dec},}@ARTICLE{10636140,
  author={Pirzado, Farman Ali and Ahmed, Awais and Mendoza-Urdiales, Román Alejandro and Terashima-Marin, Hugo},
  journal={IEEE Access}, 
  title={Navigating the Pitfalls: Analyzing the Behavior of LLMs as a Coding Assistant for Computer Science Students—A Systematic Review of the Literature}, 
  year={2024},
  volume={12},
  number={},
  pages={112605-112625},
  abstract={In recent years, large language models (LLMs) have been employed significantly in different domains of computing education. Nevertheless, these models have been focused on essential adherence to their integration as coding assistants in computing education. However, attention has been switched to thoroughly examining and analyzing LLM behavior, particularly in computing education for programming tasks such as code generation, code explanation, and programming error message explanation. Therefore, it becomes imperative to understand their behavior to examine potential pitfalls. This article addresses this gap systematically and details how different LLM-based coding chatbots, such as ChatGPT, Codex, Copilot, and others, react to various coding inputs within computing education. To achieve this objective, we collected and analyzed articles from 2021 to 2024, and 72 studies were thoroughly examined. These objectives include investigating the existing limitations and challenges associated with utilizing these systems for coding tasks, assessing their responses to prompts containing coding syntax, examining the impact of their output on student learning, and evaluating their performance as debugging tools. The findings of this review highlight that it is premature to incorporate these systems into computing education due to their limitations that may limit their effectiveness as comprehensive coding assistants for computer science students. These limitations include issues with handling prompts containing code snippets, potential negative impacts on student learning, limited debugging capabilities, and other ineffectiveness. The finding also reports multiple research directions that can be considered in future research related to LLMs in computing education.},
  keywords={Codes;Encoding;Chatbots;Programming profession;Task analysis;Surveys;Large language models;Computer science education;Error analysis;Large language models;computing education;code generation;code explanation;programming error messages explanation},
  doi={10.1109/ACCESS.2024.3443621},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10976127,
  author={Chen, Enfan},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Enhancing Teaching Quality Through LLM: An Experimental Study on Prompt Engineering}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={This study explores the application of Large Language Models Artificial Intelligence (LLM AI) in the assessment of course teaching quality, aiming to overcome the limitations of traditional teaching evaluation. Taking the experimental courses in School G as an example, we propose CORE, a framework to support generating feedback from student assessment during the course. Through the Solomon four-group design experiment, it validates the significant effectiveness of the teaching quality evaluation feedback generated by LLM in enhancing teachers' teaching quality. This feedback can help teachers improve teaching strategies, boost teaching effects, effectively make up for the limitations of traditional teaching assessment methods, and offer a new perspective and tool for teaching quality evaluation.},
  keywords={Large language models;Education;Prompt engineering;Information technology;Prompt engineering;Large Language Models (LLM);Teaching evaluation;Prompt framework;Large Language Models},
  doi={10.1109/ICEIT64364.2025.10976127},
  ISSN={},
  month={March},}@INPROCEEDINGS{10892858,
  author={Couder, Juan Ortiz and Pate, William C. and Machado, Daniel A. and Ochoa, Omar},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Incorporating AI in the Teaching of Requirements Tracing Within Software Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={During the Software Development Lifecycle (SDLC), the first stage entails the Requirement Engineering phase. In this phase, engineers gather, analyze, and specify the requirements for a software system. Requirements playa crucial role in the SDLC as they establish the foundation for the entire system by defining the expected behaviors of the software system to be built. The resulting specifications are captured in a Software Requirement Specification (SRS) document. As part of the validation process, requirement specifications are traced. Requirement tracing involves linking the requirement to the artifacts where the customer requested the high-level requirement. Teaching proper requirements tracing can be challenging in a traditional classroom setting. It is essential to educate future software engineers on the proper process of developing an SRS document and of tracing requirements back to the originating artifact, which is also challenging due to the complexity and large scope of applying the complete requirements engineering process. Understanding how changes in customer needs can impact requirements is an imperative learning opportunity. In this work, we aim to incorporate the use of AI in the teaching of requirements tracing using Large Language Models. In this experiment, both GPT -3.5 and GPT -4 are provided the transcript of an interview between the customer and the engineering team, as well as the subsequent requirements elicited from that meeting and other customer provided artifacts. The GPTs are then instructed to determine which requirements can be traced back to the interview transcript. At the same time, the students (the requirements engineering team) conduct their own effort to trace requirements back to the original interview. The experiment was taken one step further to assess students' and the GPTs abilities to address requirements modifications. After another interview with the customer, where some needs were changed, some requirements were modified, and students, and GPTs were asked to trace the modified requirements to the new interview. The results proved that students are better than both GPT versions at tracing modified requirements, yet GPTs again identified requirements that students didn't trace back. The findings, illustrate that AI can help in the teaching of requirement tracing; these results suggest that while no AI model is currently capable of replacing real requirement engineers as they don't outperform students, it can be used as a tool to test the completeness of the requirement tracing process. We posit that GPT can be a tool for students to self-assess the degree to which their own requirements tracing is exhaustive.},
  keywords={Training;Visualization;Atmospheric modeling;Prototypes;Software systems;Requirements engineering;Interviews;Artificial intelligence;Software engineering;Software development management;AI;Requirement Tracing;Education;Software Requirement Specification;Large Language Models},
  doi={10.1109/FIE61694.2024.10892858},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10554703,
  author={Xue, Yuankai and Chen, Hanlin and Bai, Gina R. and Tairas, Robert and Huang, Yu},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={Does ChatGPT Help With Introductory Programming? An Experiment of Students Using ChatGPT in CS1}, 
  year={2024},
  volume={},
  number={},
  pages={331-341},
  abstract={Generative AI, notably ChatGPT, has garnered attention in computer science education. This paper presents a controlled experiment that explores ChatGPT's role in CS1 in a classroom setting. Specifically, we aim to investigate the impact of ChatGPT on student learning outcomes and their behaviors when working on programming assignments. Participants were tasked with creating a UML diagram and subsequently implementing its design through programming, followed by a closed-book post-evaluation and a post-survey. All the participants were required to screen-record the whole process. In total, 56 participants were recruited, with 48 successful screen recordings. Participants in the Experimental Group can access ChatGPT 3.5 and other online resources, such as Google and Stack Overflow when creating the UML diagram and programming; however, participants in the Control Group can access all online resources except for ChatGPT (i.e., the only design variable is the access to ChatGPT). Finally, we measured and analyzed participants' learning outcomes through their UML diagram, programming, and post-evaluation scores. We also analyzed the time participants took to complete the tasks and their interactions with ChatGPT and other resources from the screen recordings. After finishing the tasks, student participants also provided their perceptions of using ChatGPT in CS1 through a post-survey. With rigorous quantitative and qualitative analysis, we found that (1) using ChatGPT does not present a significant impact on students' learning performance in the CS1 assignment-style tasks; (2) once using ChatGPT, students' tendency to explore other traditional educational resources is largely reduced (though available) and they tend to rely solely on ChatGPT, and this reliance on ChatGPT did not guarantee enhanced learning performance; (3) the majority of students hold neutral views on ChatGPT's role in CS1 programming but most of them raised concerns about its potential ethical issues and inconsistent performance across different tasks. We hope this study can help educators and students better understand the impact of ChatGPT in CS1 and inspire future work to provide proper guidelines for using ChatGPT in introductory programming classes.},
  keywords={Training;Ethics;Generative AI;Unified modeling language;Chatbots;Recording;Computer science education;CS education;CS1;Generative AI;ChatGPT;OOP},
  doi={10.1145/3639474.3640076},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{10710677,
  author={Örpek, Zeynep and Tural, Büşra and Destan, Zeynep},
  booktitle={2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP)}, 
  title={The Language Model Revolution: LLM and SLM Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={As technology develops day by day, significant developments have been made in the field of artificial intelligence (AI). In particular, machine learning (ML) and deep learning (DL), as the main technologies that form the basis of artificial intelligence, have offered revolutionary innovations and laid the foundation for future technologies. Traditional artificial intelligence models are based on algorithms that show high performance in certain tasks such as classification, scoring, prediction, and pattern recognition. These algorithms are developed to best perform a specific task, making it difficult for artificial intelligence to be sufficiently effective in areas that require flexibility. Generative artificial intelligence, which has become widespread in recent years, has the ability to produce certain types of content in addition to the competencies of traditional artificial intelligence models. This has revolutionized the field of productivity in artificial intelligence. Generative artificial intelligence language models have gone beyond the limitations and started a new era in artificial intelligence applications. Where traditional artificial intelligence models are limited, language models have come into play, especially with their natural language processing (NLP) capabilities. Rather than just analyzing data, language models can learn the rules of the language and provide human-like responses, produce text, and offer a wider range of applications. In this way, artificial intelligence systems have become more flexible, extensible, and dynamic. With the rise of language models in this field, concepts such as large language models (LLM) and small language models (SLM) have emerged. Large language models have come to the fore as systems that can provide deep knowledge and language production on a wide variety of topics by being trained on huge data sets. Large language models such as ChatGPT are one of the most common and impressive examples in this field. However, small language models, which are smaller and specialized language models, have begun to be used as an alternative to large language models in certain areas because they require less data and processing power. Small language models stand out with their lighter but targeted performance, offering effective solutions, especially in situations where there are resource limitations. At this point, using both large and small versions of language models in the right scenarios provides great advantages in terms of sustainability and efficiency. This study aims to reveal the transformative effect of technology on artificial intelligence and the critical role of language models in this process by evaluating language models and the issues to be considered in the selection of these models.},
  keywords={Productivity;Analytical models;Technological innovation;Generative AI;Large language models;Prediction algorithms;Data models;Classification algorithms;Artificial intelligence;Sustainable development;artificial intelligence;large language models;small language models},
  doi={10.1109/IDAP64064.2024.10710677},
  ISSN={},
  month={Sep.},}@ARTICLE{11008781,
  author={Ge, Chuyan and Wang, TianTian and Yang, XiaoTian and Treude, Christoph},
  journal={IEEE Transactions on Software Engineering}, 
  title={Cross-Level Requirements Tracing Based on Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-23},
  abstract={Cross-level requirements traceability, linking high-level requirements (HLRs) and low-level requirements (LLRs), is essential for maintaining relationships and consistency in software development. However, the manual creation of requirements links necessitates a profound understanding of the project and entails a complex and laborious process. Existing machine learning and deep learning methods often fail to fully understand semantic information, leading to low accuracy and unstable performance. This paper presents the first approach for cross-level requirements tracing based on large language models (LLMs) and introduces a data augmentation strategy (such as synonym replacement, machine translation, and noise introduction) to enhance model robustness. We compare three fine-tuning strategies—LoRA, P-Tuning, and Prompt-Tuning—on different scales of LLaMA models (1.1B, 7B, and 13B). The fine-tuned LLMs exhibit superior performance across various datasets, including six single-project datasets, three cross-project datasets within the same domain, and one cross-domain dataset. Experimental results show that fine-tuned LLMs outperform traditional information retrieval, machine learning, and deep learning methods on various datasets. Furthermore, we compare the performance of GPT and DeepSeek LLMs under different prompt templates, revealing their high sensitivity to prompt design and relatively poor result stability. Our approach achieves superior performance, outperforming GPT-4o and DeepSeek-r1 by 16.27% and 16.8% in F1 score on cross-domain datasets. Compared to the baseline method that relies on prompt engineering, it achieves a maximum improvement of 13.8%.},
  keywords={Feature extraction;Semantics;Deep learning;Information retrieval;Data augmentation;Software;Vectors;Training;Large language models;Accuracy;Requirements Tracing;Large Language Models;Fine-tuning;Data Augmentation;Software Requirements},
  doi={10.1109/TSE.2025.3572094},
  ISSN={1939-3520},
  month={},}@INPROCEEDINGS{10229416,
  author={Speth, Sandro and Meißner, Niklas and Becker, Steffen},
  booktitle={2023 IEEE 35th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Investigating the Use of AI-Generated Exercises for Beginner and Intermediate Programming Courses: A ChatGPT Case Study}, 
  year={2023},
  volume={},
  number={},
  pages={142-146},
  abstract={In recent years, artificial intelligence (AI) has been increasingly used in education and supports teachers in creating educational material and students in their learning progress. AI-driven learning support has recently been further strengthened by the release of ChatGPT, in which users can retrieve explanations for various concepts in a few minutes through chat. However, to what extent the use of AI models, such as ChatGPT, is suitable for the creation of didactically and content-wise good exercises for programming courses is not yet known. Therefore, in this paper, we investigate the use of AI-generated exercises for beginner and intermediate programming courses in higher education using ChatGPT. We created 12 exercise sheets with ChatGPT for a beginner to intermediate programming course focusing on the objects-first approach. We report our process, prompts, and experience using ChatGPT for this task and outline good practices we identified. The generated exercises are assessed and revised, primarily using ChatGPT, until they met the requirements of the programming course. We assessed the quality of these exercises by using them in our external teaching assignment course at the University of Education Ludwigsburg and let the students evaluate them. Results indicate the quality of the generated exercises and the time-saving for creating them using ChatGPT. However, our experience showed that while it is fast to generate a good version of an exercise, almost every exercise requires minor manual changes to improve its quality.},
  keywords={Java;Software architecture;Education;Focusing;Manuals;Learning (artificial intelligence);Chatbots;AI-Generated Exercises;SE Education;Automatic Question Generation;Programming Course;ChatGPT},
  doi={10.1109/CSEET58097.2023.00030},
  ISSN={2377-570X},
  month={Aug},}@INPROCEEDINGS{10893585,
  author={Jemetz, Michael and Motschnig, Renate},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Teachers' Development of Competence in Managing Generative AI Technology: Findings from a Qualitative Interview Series}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research full paper strives to shed light on educators' ways of dealing with the rapid advances in generative AI tools, which have opened up new challenges and opportunities for learners and educators alike. Both are confronted with the opportunity of supporting themselves in the completion of a wide range of tasks in this new reality. The study presented here aims to identify different strategies teachers use to develop their competences in responding to students' AI usage and in utilizing this new technology for their own professional tasks. Strategies are identified through a series of semi-structured qualitative interviews with a diverse group of nineteen teachers from two vocational and three general education secondary schools in urban and rural areas of Austria. The participants are mainly teaching technical and language subjects and range from technical experts teaching IT to general education teachers who are faced with the need to quickly adapt to learners with different levels of digital and AI competences. The findings of a qualitative content analysis of the gathered data are contextualized with previous work on educators' digital competence development and comparisons are drawn. It was found that a major contribution to the educators' skills in handling generative AI technology was made through self-regulated learning facilitated by various resources ranging from academic literature to social media and experimentation, as was the case with general digital skills. Nevertheless, the desire to be formally supported in further developing AI competence through training was voiced with requirements for this training being that the content is up-to-date, contains practical examples, and is delivered by experts. In addition, open, inclusive forms of seminars were suggested. These findings aim to inform curriculum designers, teacher educators, professional development trainers and administrators. Furthermore, struggling educators will find a starting point for self-organized work on their AI competences and pointers to potentially useful resources both for their teaching and their own learning in the field.},
  keywords={Training;Seminars;Content management;Generative AI;Social networking (online);Distance measurement;Interviews;AI competence;GenAI;teacher's competence;competence development;self-regulated learning;LLMs},
  doi={10.1109/FIE61694.2024.10893585},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10487568,
  author={Kupershtein, Ethan and Kumar, Yulia and Manikandan, Anjana and Morreale, Patricia and Li, J. Jenny},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={ChatGPT as a Game-Changer for Embedding Emojis in Faculty Feedback}, 
  year={2023},
  volume={},
  number={},
  pages={1039-1046},
  abstract={This study explores the potential of integrating emojis, and digital pictographs, into faculty feedback to augment student learning outcomes. This additional layer of expressiveness, encouragement, and involvement adds a personal touch to the often distant and virtual student-educator communications, fostering motivation. The study focuses on the impact of emojis on the learning process within the scrutinized Computer Science (CS) Department. Capitalizing on the capabilities of OpenAI's Large Language Model (LLM) ChatGPT-4, its Application Programming Interface (API), and associated tools and third-party plugins, a system that translates text into corresponding emojis and vice versa has been developed. The proposed application offers direct benefits to educators by simplifying the provision of detailed and extensive feedback to students. The primary research question is: Can the appropriate use of emojis, matched with the sentiment of the feedback text, contribute to enhanced student learning outcomes, higher retention rates, and boost the reputation of the educators providing it? Two surveys on the impact of emojis across selected course sections were conducted to answer the question: a pre-survey and a post-survey involving 175 active participants. The results were analyzed, and it was concluded that integrating emojis in faculty feedback, particularly when grading student work, could potentially enhance student learning outcomes and their overall course experience.},
  keywords={Surveys;Computer science;Chatbots;Emojis;Application programming interfaces;emojis;Feedback Emojifier;ChatGPT;computer science education;text-to-emoji translation},
  doi={10.1109/CSCE60160.2023.00173},
  ISSN={},
  month={July},}@INPROCEEDINGS{10665141,
  author={Kumar, Yulia and Manikandan, Anjana and Li, J. Jenny and Morreale, Patricia},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Optimizing Large Language Models for Auto-Generation of Programming Quizzes}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This study analyzes the use of Large Language Models (LLMs) like ChatGPT in creating quizzes for Java programming courses, specifically Object-Oriented Programming (CS1) and Data Structures (CS2). It aims to evaluate the accuracy of LLM-generated assessments, understand the benefits and drawbacks of using LLMs in CS education from educators' viewpoints, and identify effective prompt engineering strategies to enhance the quality of educational materials. The research compares quizzes made by LLMs against human-created content to assess their consistency with Java programming principles, alignment with CS1 and CS2 learning goals, and their impact on student engagement and comprehension, providing insights into LLMs' effectiveness in academic assessment creation for computer science education.},
  keywords={Java;Accuracy;Large language models;Education;Data structures;Chatbots;Computer science education;Java programming instruction;AI-Supplemental Instructor (AI-SI);use of LLMs in CS education},
  doi={10.1109/ISEC61299.2024.10665141},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{10398297,
  author={Hu, Minjie and Assadi, Tony and Mahroeian, Hamid},
  booktitle={2023 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Explicitly Introducing ChatGPT into First-year Programming Practice: Challenges and Impact}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={ChatGPT has recently emerged to aid in computer programming education due to its cutting-edge functionality of generating program code, debugging, etc. This research firstly focused on what the ethical considerations and solutions are for the first-year IT students who use ChatGPT to write computer programs in an integrated assignment. And then it turned to investigate what impact ChatGPT has on the programming competencies and learning outcomes of students compared to those who do not use ChatGPT. To ensure students use ChatGPT ethically, guidance was provided together with a declaration form of ethically using ChatGPT in each phase of the assignment. Next, we collected and analyzed a survey and their declaration from students and compared student effort, time spent, and performance outcomes from those who were using and without using ChatGPT. Based on the findings, we concluded that although ChatGPT provides an opportunity to the first-year students to learn programming in the way of analysis, synthesis, and evaluation, many students still prefer the conventional way of learning programming in terms of comprehension and application. We argued that since our students in the programming course are always from different academic background levels, we would continue to use both ChatGPT and conventional eLearning resources to meet different learning requirements.},
  keywords={Surveys;Ethics;Electronic learning;Education;Taxonomy;Chatbots;Programming profession;ChatGPT;divide-and-conquer;Bloom’s taxonomy},
  doi={10.1109/TALE56641.2023.10398297},
  ISSN={},
  month={Nov},}@ARTICLE{11024014,
  author={Dahal, Rajashree and Murray, Greg and Chataut, Robin and Hefeida, Mohamed and Srivastava, Anurag and Gyawali, Prashnna},
  journal={IEEE Access}, 
  title={AutoTA: A Dynamic Intent-Based Virtual Teaching Assistant for Students Using Open Source LLMs}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Large Language Models (LLMs) are explored for their potential to transform education by serving as virtual teaching assistants, offering personalized support through human-like responses to tasks such as content-related questions and coursework guidance. In this study, we present a novel framework that leverages intent classification to enhance the effectiveness of LLMs in this role. Our framework, AutoTA, categorizes student queries into distinct topics— lecture discussions, homework assistance, and syllabus questions—triggering specific conversation chains tailored to each intent. Additionally, we incorporate a custom vector-space filter that refines responses based on filename tracking after intent identification. To evaluate the framework, we used course materials from the undergraduate-level CS course, Computer Incident Response, and compared the performance of several open-source LLMs, including Llama 3.1. Our results show that the framework accurately classifies intent and provides appropriate guidance, measured through quantitative and qualitative metrics. These findings highlight the potential of the proposed framework to enhance personalized learning and improve student engagement. While tested in a computer science course, the framework incorporates diverse assessment types that suggest potential for broader application.},
  keywords={Education;Intent recognition;Oral communication;Large language models;Programming profession;Measurement;Information retrieval;Virtual assistants;Real-time systems;History;Education;Large language models (LLMs);prompting;teaching assistant},
  doi={10.1109/ACCESS.2025.3576329},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10837667,
  author={Speiser, Sebastian and Weng, Annegret},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Enhancing Short Answer Grading with OpenAI APIs}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Automated short-answer grading can accelerate and standardize the assessment of tests in higher education. The topic has received a significant boost due to the rapid development of powerful LLM models in recent years. We examine the performance of the OpenAI models GPT-3.5 and GPT-4o on the CSSAG dataset and demonstrate that GPT-4o, in particular, achieves an accuracy that falls within the range observed in assessments by different human evaluators. We pay special attention to cases where there are significant deviations from the reference assessment. Additionally, we discuss the practical implications.},
  keywords={Training;Accuracy;Life estimation;Information technology;Few shot learning;Overfitting;LLMs;Automated Grading;Short Answer Grading},
  doi={10.1109/ITHET61869.2024.10837667},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{11012850,
  author={Lin, Yadanar and Ferdous Khan, M. Fahim and Sakamura, Ken},
  booktitle={2025 1st International Conference on Consumer Technology (ICCT-Pacific)}, 
  title={Athena: A GenAI-Powered Programming Tutor Based on Open-Source LLM}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={With the rapid growth of generative artificial intelligence (GenAI), it is important to find ways to utilize them for academic advantage. GenAI tools embody immense potential in providing personalized feedback to students any time anywhere, and hence can provide a reliable helping hand to teachers who often experience burnout in large classes and are burdened with administrative tasks. While current GenAI tools like ChatGPT are helpful, they occasionally offer misinformation - a phenomenon known as hallucination, undermine critical thinking by providing direct answers to questions, and, as paid services, can further widen the digital divide. Against the backdrop of these problems, this research introduces Athena, a GenAI programming mentor based on an open-source large language model (LLM), constructed to guide programming learners to think critically and provide reliable information leveraging retrieval augmented generation. Its impact on learning outcomes was measured by feedback from programming students. Most students have given a positive response, saying that their motivation to keep learning and their confidence in their abilities have increased. These results imply that having a reliable AI mentor that can guide students at all times can have a positive impact in self-directed learning process.},
  keywords={Hands;Generative AI;Large language models;Retrieval augmented generation;Education;Chatbots;Reliability;Digital divide;Fake news;Programming profession;Generative artificial intelligence (GenAI);programming education;large language model (LLM);retrieval augmented generation (RAG);educational chatbot},
  doi={10.1109/ICCT-Pacific63901.2025.11012850},
  ISSN={},
  month={March},}@INPROCEEDINGS{10837650,
  author={Dobre, Stefania-Carmen and Popescu, Elvira},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Exploring Students' Perception and Experience with ChatGPT and Critical Thinking in a Higher Education Context}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={ChatGPT (Chat Generative Pre-trained Transformer) is a chatbot based on a large language model that enables users to engage in conversations with it in a human-like way. The adoption of ChatGPT in education has generated significant interest because of its potential to enhance students' learning experience. By delivering personalised and prompt responses, ChatGPT can meet individual student needs, provide immediate feedback, and aid comprehension of difficult concepts. In this paper, we investigate students' experience with ChatGPT, focusing on the topic of critical thinking skills in a higher education context. Data was collected by means of an opinion survey applied to 122 students from the University of Craiova, Romania. The paper reports and discusses the survey findings, with respect to the following issues: students' perceptions of ChatGPT's role in the learning process; the potential benefits and challenges that learners may encounter when using ChatGPT for educational purposes; students' trust in ChatGPT's responses; and students' critical evaluation of the content generated by ChatGPT.},
  keywords={Surveys;Training;Navigation;Large language models;Focusing;Oral communication;Chatbots;Transformers;Information technology;Interviews;ChatGPT;large language model;AI in education;student survey;learning experience;critical thinking},
  doi={10.1109/ITHET61869.2024.10837650},
  ISSN={2473-2060},
  month={Nov},}@ARTICLE{10753620,
  author={Song, Tian and Zhang, Hang and Xiao, Yijia},
  journal={IEEE Transactions on Learning Technologies}, 
  title={A High-Quality Generation Approach for Educational Programming Projects Using LLM}, 
  year={2024},
  volume={17},
  number={},
  pages={2242-2255},
  abstract={High-quality programming projects for education are critically required in teaching. However, it is hard to develop those projects efficiently and artificially constrained by the lecturers' experience and background. The recent popularity of large language models (LLMs) has led to a great number of applications in the field of education, but concerns persist that the output might be unreliable when dealing with intricate requirements. In this study, we design a customized role-based agent (CRBA), which can be configured for different roles specializing in specific areas of expertise, making the LLM yield content of higher specialization. An iterative architecture of multi-CRBAs is proposed to generate multistep projects, where CRBAs automatically criticize and optimize the LLM's intermediate outputs to enhance quality. We propose ten evaluation metrics across three aspects to assess project quality through expert grading. Further, we conduct an A/B test among 60 undergraduate students in a programming course and collect their feedback through a questionnaire. According to the students' rating results, the LLM-generated projects have comparable performance to man-made ones in terms of project description, learning step setting, assistance to students, and overall project quality. This study effectively integrates LLM into educational scenarios and enhances the efficiency of creating high-quality and practical programming exercises for lecturers.},
  keywords={Programming profession;Codes;Education;Iterative methods;Computer architecture;Prompt engineering;Measurement;Chatbots;Python;Logic;Automatic generation;generative pretrained transformer (GPT);large language models (LLMs);programming education;programming projects},
  doi={10.1109/TLT.2024.3499751},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10893211,
  author={Rachha, Ashwin and Seyam, Mohammed},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={LLM-Enhanced Learning Environments for CS: Exploring Data Structures and Algorithms with Gurukul}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={In this Innovative Practice full paper, we introduce Gurukul, an innovative coding platform designed to support teaching Data Structures and Algorithm (DSA) course by integrating advanced Large Language Models (LLMs). LLMs have emerged as powerful tools in Computer Science Education (CSEd), offering unparalleled opportunities for enhancing student comprehension and engagement. However, their use in educational settings presents challenges, including tendencies toward hallucination, contextual inaccuracies, and the risk of undermining critical thinking by providing explicit solutions. To address these challenges, and to explore how specialized LLMs can bolster learner engagement, we present Gurukul, a platform featuring dual innovations: Retrieval-Augmented Generation (RAG) and Guardrails. Gurukul offers a hands-on practice feature where students can solve DSA problems within a code editor, supported by a dynamically Guardrailed LLM that prevents the delivery of explicit solutions. Additionally, the platform's study feature utilizes RAG, drawing from OpenDSA as a trusted source, to ensure accurate and contextually relevant information is provided. To assess the platform's effectiveness, we conducted a User Study with students, and a User Expert Review with faculty from a U.S. public state university specializing in DSA courses. Our analysis of student usage patterns and perceptions, along with insights from instructors, reveal that Gurukul positively impacted student engagement and learning in DSA, demonstrating the potential of specialized LLMs to enhance educational outcomes in this field.},
  keywords={Technological innovation;Codes;Reviews;Large language models;Retrieval augmented generation;Education;Data structures;Encoding;Data models;Computer science education;Large Language Models;Retrieval Augmented Generation;Guardrails;Computer Science Education;ChatGPT;AI in Education},
  doi={10.1109/FIE61694.2024.10893211},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10837649,
  author={Ilić, Jelena and Ivanović, Mirjana and Klašnja-Milićević, Aleksanda},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={The Impact of ChatGPT on Student Learning Experience in Higher STEM Education: A Systematic Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research paper aims to analyse the significance and utilisation of artificial intelligence, with a particular focus on ChatGPT, in learning systems. Integrating AI tools like ChatGPT has become a prominent trend in education. This study examines the impact of ChatGPT in higher STEM education, drawing on scientific articles published between 2020 and 2024. It explores whether ChatGPT produces positive learning outcomes, the potential approaches for its application now and in the future, and its effectiveness as a teaching tool. Findings from this literature review highlight the numerous benefits of using ChatGPT in higher STEM education. These benefits include improved opportunities for students to engage with AI technology, the provision of personalised support that meets individual learning needs, and an overall increase in the quality of the learning experience. Furthermore, ChatGPT enables greater accessibility of information, which encourages deeper learning and better knowledge retention. Despite these advantages, it is crucial to acknowledge the ethical considerations and biases inherent in AI models that must be addressed. Empirical evidence suggests that ChatGPT significantly improves student engagement by delivering personalised responses tailored to individual learning needs, offering timely and constructive feedback and making information more easily accessible. Together, these factors contribute to improved educational outcomes and encourage the development of students' critical thinking skills. The inclusion of ChatGPT in educational contexts marks a transformative shift in teacher roles, moving away from traditional content delivery methods. This evolution fosters a personalised and differentiated learning environment, allowing teachers to respond more effectively to the diverse needs of their students. There are obvious limitations that require further study. The reason for the insufficient number of empirical research is that ChatGPT in education is a relatively new AI tool.},
  keywords={Training;Accuracy;Navigation;Education;Transforms;Chatbots;Market research;Artificial intelligence;Systematic literature review;STEM;ChatGPT;artificial intelligence;higher education;STEM education;systematic literature review},
  doi={10.1109/ITHET61869.2024.10837649},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10734434,
  author={Rasnayaka, Sanka and Wang, Guanlin and Shariffdeen, Ridwan and Iyer, Ganesh Neelakanta},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project}, 
  year={2024},
  volume={},
  number={},
  pages={111-118},
  abstract={Large Language Models (LLMs) represent a leap in artificial intelligence, excelling in tasks using human language(s). Although the main focus of general-purpose LLMs is not code generation, they have shown promising results in the domain. However, the usefulness of LLMs in an academic software engineering project has not been fully explored yet. In this study, we explore the usefulness of LLMs for 214 students working in teams consisting of up to six members. Notably, in the academic course through which this study is conducted, students were encouraged to integrate LLMs into their development tool-chain, in contrast to most other academic courses that explicitly prohibit the use of LLMs.In this paper, we analyze the AI-generated code, prompts used for code generation, and the human intervention levels to integrate the code into the code base. We also conduct a perception study to gain insights into the perceived usefulness, influencing factors, and future outlook of LLM from a computer science student’s perspective. Our findings suggest that LLMs can play a crucial role in the early stages of software development, especially in generating foundational code structures, and helping with syntax and error debugging. These insights provide us with a framework on how to effectively utilize LLMs as a tool to enhance the productivity of software engineering students, and highlight the necessity of shifting the educational focus toward preparing students for successful human-AI collaboration.CCS CONCEPTS• Software and its engineering → Software development techniques; • Applied computing → Education.},
  keywords={Productivity;Codes;Large language models;Conferences;Education;Debugging;Syntactics;Software;Software engineering;Software development management;LLM for Code Generation;Software Engineering},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10893442,
  author={Scholl, Andreas and Kiesler, Natalie},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={How Novice Programmers Use and Experience ChatGPT when Solving Programming Exercises in an Introductory Course}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research paper contributes to the computing education research community's understanding of Generative AI (GenAI) in the context of introductory programming, and specifically, how students utilize related tools, such as ChatGPT. An increased understanding of students' use is mandatory for educators and higher education institutions, as GenAI is here to stay, and its performance is likely to improve rapidly in the near future. Learning about students' use patterns is not only crucial to support their learning, but to develop adequate forms of instruction and assessment. With the rapid advancement of AI, its broad availability, and ubiquitous presence in educational environments, elaborating how AI can enhance learning experiences, especially in courses such as introductory programming is important. To date, most studies have focused on the educator's perspective on GenAI, its performance, characteristics, and limitations. However, the student perspective, and how they actually use GenAI tools in course contexts, has not been subject to a great number of studies. Therefore, this study is guided by the following research questions: (1) What do students report on their use pattern of ChatGPT in the context of introductory programming exercises? and (2) How do students perceive ChatGPT in the context of introductory programming exercises? To address these questions, computing students at a large German university were asked to solve programming tasks with the assistance of ChatGPT as part of their introductory programming course. Students (n=298) provided information regarding the use of ChatGPT, and their evaluation of the tool via an online survey. This research provides a comprehensive evaluation of ChatGPT-3.5's application by novice programmers in a higher education context. The findings reveal that while students widely adopt GenAI, their use varies significantly, ranging from acceptance of generated solutions to dynamic, and critical engagement. Therefore, this work has implications for educators designing guardrails or forms of instructions on the use of GenAI tools in the classroom.},
  keywords={Surveys;Generative AI;Education;Chatbots;Distance measurement;Programming profession;ChatGPT;generative AI;large language models;students;application;introductory programming},
  doi={10.1109/FIE61694.2024.10893442},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11016577,
  author={Liu, ShuChang and Pan, MingHui and Yang, YeHan},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={I-LEAD: A Digital-Intelligence-Powered Ecosystem for Innovation and Entrepreneurship Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Generative artificial intelligence and large model agents are revolutionizing the higher education, influencing everything from talent development frameworks and teaching methodologies to knowledge acquisition processes and research paradigms. Meanwhile, in the context of digital transformation and technological innovation, data as a production factor and emerging productive forces are reshaping the requirements and demands for cultivating high-level interdisciplinary engineering talents. This paper draws on the joint educational achievements between Beijing University of Posts and Telecommunications and Queen Mary University of London, focusing on the coconstruction and sharing of experimental resources, as well as innovation-driven entrepreneurship education. It introduces a digital-intelligence-powered educational platform aimed at fostering internationally-minded, innovative, and outstanding talents. The platform's core philosophy, development strategy, functional modules, and technical framework are detailed. The wide recognition and interest among stakeholders further validate its potential to support the development of a cross-disciplinary, cross-professional, and cross-national ecosystem for innovation and entrepreneurship education. As a key outcome of the 20th Anniversary Development Conference of Joint Education of our two universities, I-LEAD is a platform designed to cultivate students' comprehensive innovative capabilities. Leveraging large language models (LLMs) and multi-agent technology, we have developed BUPT iMentor, an intelligent agent for innovation and entrepreneurship guidance; and BUPT EnPower, a cultivation assistant for personalized longlife learning. By LLMs with a robust knowledge based augmented generation and fine tuning, this tool effectively addresses common student challenges during innovation & entrepreneurship projects, such as idea generation and validation, access to relevant learning resources. I-LEAD provides comprehensive support, including customized course creation, problem-solving guidance, real-time interactive Q&A, and learning progress monitoring. This empowers students to independently plan their learning journeys and holistically enhance their academic and innovative skills. The effectiveness and practicality of the platform have been validated through a questionnaire survey. Therefore, we are extensively gathering feedback and continuously optimizing the platform's services. The teacher-student collaborative learning represents the future of higher education. This student-centered education system provides a platform for that.},
  keywords={Technological innovation;Large language models;Knowledge acquisition;Education;Ecosystems;Entrepreneurship;Production;Real-time systems;Telecommunications;Monitoring;innovation and entrepreneurship education;large language model agents;interdisciplinary talent cultivation;digital and intelligent empowerment},
  doi={10.1109/EDUCON62633.2025.11016577},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10663055,
  author={Pereira, Juanan and López, Juan-Miguel and Garmendia, Xabier and Azanza, Maider},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Leveraging Open Source LLMs for Software Engineering Education and Training}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Generative AI, particularly Large Language Models (LLMs), presents innovative opportunities to enhance software engineering education. Open source LLMs such as LLaMA and Mistral leverage the potential of generative AI offering distinct advantages over proprietary options including transparency, customizability, collaboration, and cost savings. This paper de-velops a catalog of LLM prompt examples tailored for software engineering training, mapped to knowledge areas from the Soft-ware Engineering Body of Knowledge (SWEBoK) framework. Example prompts demonstrate LLMs' capabilities in eliciting requirements, diagram generation, API simulation, effort esti-mation through role-playing, and other areas. The methodology involves evaluating prompt responses from ChatGPT, Mistral, and LLaMA on representative tasks. Quantitative and qualitative analysis assesses quality, usefulness, and correctness. Findings show ChatGPT and Mistral outperforming LLaMA overall, but no model perfectly executes complex interactions. We examine implications and challenges of integrating open source LLMs into classrooms, emphasizing the need for oversight, verification, and prompt design aligned with pedagogical objectives.},
  keywords={Training;Knowledge engineering;Costs;Generative AI;Large language models;Collaboration;Chatbots;Software Engineering Education;Open Source AI Models;Large Language Models;Prompt Engineering},
  doi={10.1109/CSEET62301.2024.10663055},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10893118,
  author={Kusam, Venkata Alekhya and Shrestha, Summit and Kattan, Khalid and Maxim, Bruce and Song, Zheng},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={A PBL-Based Mini Course Module for Teaching Computer Science Students to Utilize Generative AI for Enhanced Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research-to-practice paper introduces a mini-course module designed to teach computer science students how to interact more efficiently with Generative AI(GAI). The rapid rise of GAI is transforming education by providing students with easy access to knowledge and answers to their questions, acting as a personal tutor. Particularly in the field of computer science, where GAI can easily generate code based on specific requirements, many instructors struggle to prevent students from using tools like ChatGPT for completing assigned programming assignments and homeworks. However, we argue that 1) the use of GAI is inevitable, necessitating a redesign of courses so that students cannot merely rely on GAI without actual learning; and 2) students' learning can be enhanced if they learn to use GAI more effectively. In this paper, we demonstrate how we integrate Project-Based Learning to design the course module in a concise yet effective manner, which not only facilitates students' learning of GAI but also enriches their learning in relation to the host course where this mini-course module is embedded. In particular, the goal of this module is to teach CS students: 1) the basic principles and workflow of GAI; 2) Prompt Engineering: how to craft questions to interact more effectively with GAI; and 3) Extending GAI: how to create interactive tools by training customized GAI models. Designed to be completed within two weeks, the mini-course module can easily be incorporated into host courses. This mini-course module was integrated into a graduate-level Artificial Intelligence course with 42 students in Winter 2024. To assess the module's impact on student learning and engagement, we conducted pre- and post-course surveys as well as student interviews. The results from the surveys and interviews highlighted key areas for improving the design of educational modules to better teach essential GAI skills. These insights focused on enhancing student engagement and learning efficiency within a concise time frame.},
  keywords={Surveys;Training;Codes;Navigation;Chatbots;Prompt engineering;Interviews;Programming profession;Generative AI;Course Module Design;Project Based Learning(PBL)},
  doi={10.1109/FIE61694.2024.10893118},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10936806,
  author={Mi, Chunqiao and Xiao, Hongbo and Deng, Qingyou and Zhao, Changhua and Tang, Bo},
  booktitle={2024 International Conference on Information Technology, Comunication Ecosystem and Management (ITCEM)}, 
  title={Research on the Effectiveness of Human-Machine Collaborative Teaching Based on Data Analysis in the Era of Digital Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={233-237},
  abstract={In the era of digital intelligence, the integration of artificial intelligence (AI) into educational practices has the potential to transform traditional teaching methods. Human-machine collaborative teaching (HMCT) is a new paradigm that leverages the strengths of both human educators and AI tools to enhance learning outcomes. This study investigates the effectiveness of three human-machine collaborative teaching strategies—directive, guided, and collaborative-implemented in a university—level software engineering course. The experiment involved 99 third-year students and aimed to evaluate the impact of these teaching strategies on creativity and academic performance. The results show that the collaborative teaching method, enhanced by generative AI tools, led to the highest performance in final exams and overall academic achievement, as well as increased participation in extracurricular innovation activities in homework. While directive teaching produced consistent results, it did not foster the same level of engagement or creativity. Guided teaching demonstrated moderate success, but the greatest benefits were observed in the collaborative approach, where students took an active role in their learning. This study suggests that integrating AI into collaborative learning environments can enhance both academic outcomes and student creativity, and recommends expanding the use of AI-supported strategies in higher education. Future research should explore the scalability of these findings across disciplines and investigate long-term impacts on student development and career readiness.},
  keywords={Technological innovation;Data analysis;Generative AI;Federated learning;Education;Collaboration;Transforms;Digital intelligence;Creativity;Software engineering;human-machine collaborative teaching;collaborative learning;generative AI;data analysis;effectiveness evaluation},
  doi={10.1109/ITCEM65710.2024.00050},
  ISSN={},
  month={Dec},}@ARTICLE{10004013,
  author={Wu, Zhengyang and Deng, Ke and Qiu, Judy and Tang, Yong},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={ExamGAN and Twin-ExamGAN for Exam Script Generation}, 
  year={2023},
  volume={35},
  number={11},
  pages={11354-11367},
  abstract={Nowadays, the learning management system (LMS) has been widely used in different educational stages from primary to tertiary education for student administration, documentation, tracking, reporting, and delivery of educational courses, training programs, or learning and development programs. Towards effective learning outcome assessment, the exam script generation problem has attracted many attentions recently. But the research in this field is still in its early stage. Two essential issues have been ignored largely by existing solutions. First, given a course, it is unknown yet how to generate an quality exam script which concurrently has (i) the proper difficulty level, (ii) the coverage of essential knowledge points, (iii) the capability to distinguish academic performances between students, and (iv) the student scores in normal distribution. Second, while frequently encountered in practice, it is unknown so far how to generate a pair of high quality exam scripts which are equivalent in assessment (i.e., the student scores are comparable by taking either of them) but have significantly different sets of questions. To fill the gap, this paper proposes ExamGAN (Exam Script Generative Adversarial Network) to generate high quality exam scripts, and then extends ExamGAN to T-ExamGAN (Twin-ExamGAN) to generate a pair of high quality exam scripts. Based on extensive experiments on three benchmark datasets, it has verified the superiority of proposed solutions in various aspects against the state-of-the-art. Moreover, we have conducted a case study which demonstrated the effectiveness of proposed solution in the real teaching scenarios.},
  keywords={Hidden Markov models;Generative adversarial networks;Knowledge engineering;Training;Gaussian distribution;Task analysis;Databases;Deep knowledge tracing;educational data mining;exam script generation;generative adversarial network},
  doi={10.1109/TKDE.2022.3233046},
  ISSN={1558-2191},
  month={Nov},}@INPROCEEDINGS{10962520,
  author={Chandrasekaran, Jaganmohan and Patel, Ankita Ramjibhai and Lanus, Erin and Freeman, Laura J.},
  booktitle={2025 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={Evaluating Large Language Model Robustness using Combinatorial Testing}, 
  year={2025},
  volume={},
  number={},
  pages={300-309},
  abstract={Recent advancements in large language models (LLMs) have demonstrated remarkable proficiency in understanding and generating human-like text, leading to widespread adoption across domains. Given LLM’s versatile capabilities, current evaluation practices assess LLMs across a wide variety of tasks, including answer generation, sentiment analysis, text completion, and question and answers, to name a few. Multiple choice questions (MCQ) have emerged as a widely used evaluation task to assess LLM’s understanding and reasoning across various subject areas. However, studies from the literature have revealed that LLMs exhibit sensitivity to the ordering of options in MCQ tasks, with performance variations based on option sequence, thus underscoring the robustness concerns in LLM performance.This work presents a combinatorial testing-based framework for systematic and comprehensive robustness assessment of pre-trained LLMs. By leveraging the sequence covering array, the framework constructs test sets by systematically swapping the order of options, which are then used in ascertaining the robustness of LLMs. We performed an experimental evaluation using the Measuring Massive Multitask Language Understanding (MMLU) dataset, a widely used MCQ dataset and evaluated the robustness of GPT 3.5 Turbo, a pre-trained LLM. Results suggest the framework can effectively identify numerous robustness issues with a relatively minimal number of tests.},
  keywords={Sentiment analysis;Systematics;Sensitivity;Large language models;Combinatorial testing;Conferences;Robustness;Cognition;Testing AI;Combinatorial Testing;Testing LLM;LLM Robustness;LLM Evaluation;Option Order Swapping},
  doi={10.1109/ICSTW64639.2025.10962520},
  ISSN={2159-4848},
  month={March},}@ARTICLE{10689494,
  author={Chen, Zixin and Wang, Jiachen and Xia, Meng and Shigyo, Kento and Liu, Dingdong and Zhang, Rong and Qu, Huamin},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={StuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT Interactions}, 
  year={2025},
  volume={31},
  number={1},
  pages={908-918},
  abstract={The integration of Large Language Models (LLMs), especially ChatGPT, into education is poised to revolutionize students' learning experiences by introducing innovative conversational learning methodologies. To empower students to fully leverage the capabilities of ChatGPT in educational scenarios, understanding students' interaction patterns with ChatGPT is crucial for instructors. However, this endeavor is challenging due to the absence of datasets focused on student-ChatGPT conversations and the complexities in identifying and analyzing the evolutional interaction patterns within conversations. To address these challenges, we collected conversational data from 48 students interacting with ChatGPT in a master's level data visualization course over one semester. We then developed a coding scheme, grounded in the literature on cognitive levels and thematic analysis, to categorize students' interaction patterns with ChatGPT. Furthermore, we present a visual analytics system, StuGPTViz, that tracks and compares temporal patterns in student prompts and the quality of ChatGPT's responses at multiple scales, revealing significant pedagogical insights for instructors. We validated the system's effectiveness through expert interviews with six data visualization instructors and three case studies. The results confirmed StuGPTViz's capacity to enhance educators' insights into the pedagogical value of ChatGPT. We also discussed the potential research opportunities of applying visual analytics in education and developing AI-driven personalized learning solutions.},
  keywords={Data visualization;Chatbots;Oral communication;Education;Visual analytics;Artificial intelligence;Data collection;Visual analytics for education;ChatGPT for education;student-ChatGPT interaction},
  doi={10.1109/TVCG.2024.3456363},
  ISSN={1941-0506},
  month={Jan},}@ARTICLE{10938596,
  author={Pwanedo Amos, Joanah and Ahmed Amodu, Oluwatosin and Azlina Raja Mahmood, Raja and Bolakale Abdulqudus, Akanbi and Zakaria, Anies Faziehan and Rhoda Iyanda, Abimbola and Ali Bukar, Umar and Mohd Hanapi, Zurina},
  journal={IEEE Access}, 
  title={A Bibliometric Exposition and Review on Leveraging LLMs for Programming Education}, 
  year={2025},
  volume={13},
  number={},
  pages={58364-58393},
  abstract={The world is experiencing an AI revolution, with large language models (LLMs) transforming various industries, including education. Academics are striving to harness the potential of LLMs while also contending with their risks. This paper presents the first bibliometric analysis focused on LLM research in programming education, identifying leading countries, authors, and institutions while analyzing key terms and popular keywords in this field. Additionally, it highlights influential studies on topics such as introductory programming, computer science, computing, programming education, and prompt engineering, discussing key insights from these works. Findings indicate that LLMs could play a significant role in programming education and may be integrated into computer science curricula. However, careful consideration is needed to ensure their benefits outweigh their risks across various use cases. This study specifically examines ChatGPT as a representative LLM, exploring its benefits and limitations as both a learning aid for students and a support tool for professionals. It also evaluates the quality of ChatGPT-generated code and its effectiveness in simplifying programming concepts for beginners. Furthermore, the ethical implications of increasing reliance on LLMs for programming tasks, including concerns about dependency, plagiarism, and potential effects on critical thinking, are addressed. By contributing to the ongoing discourse on integrating AI tools like ChatGPT in programming education, this research emphasizes the importance of responsible and ethical usage to maximize benefits for students, educators, and the broader educational community.},
  keywords={Chatbots;Programming profession;Education;Bibliometrics;Market research;Large language models;Codes;Ethics;Requirements engineering;Mathematics;ChatGPT;code generation;ethical concerns;large language models (LLMs);introductory programming;programming education;prompt engineering},
  doi={10.1109/ACCESS.2025.3554627},
  ISSN={2169-3536},
  month={},}@ARTICLE{10706931,
  author={Neumann, Alexander Tobias and Yin, Yue and Sowe, Sulayman and Decker, Stefan and Jarke, Matthias},
  journal={IEEE Transactions on Education}, 
  title={An LLM-Driven Chatbot in Higher Education for Databases and Information Systems}, 
  year={2025},
  volume={68},
  number={1},
  pages={103-116},
  abstract={Contribution: This research explores the benefits and challenges of developing, deploying, and evaluating a large language model (LLM) chatbot, MoodleBot, in computer science classroom settings. It highlights the potential of integrating LLMs into LMSs like Moodle to support self-regulated learning (SRL) and help-seeking behavior. Background: Computer science educators face immense challenges incorporating novel tools into LMSs to create a supportive and engaging learning environment. MoodleBot addresses this challenge by offering an interactive platform for both students and teachers. Research Questions: Despite issues like bias, hallucinations, and teachers’ and educators’ resistance to embracing new (AI) technologies, this research investigates two questions: (RQ1) To what extent do students accept MoodleBot as a valuable tool for learning support? (RQ2) How accurately does MoodleBot churn out responses, and how congruent are these with the established course content? Methodology: This study reviews pedagogical literature on AI-driven chatbots and adopts the retrieval-augmented generation (RAG) approach for MoodleBot’s design and data processing. The technology acceptance model (TAM) evaluates user acceptance through constructs like perceived usefulness (PU) and Ease of Use. Forty-six students participated, with 30 completing the TAM questionnaire. Findings: LLM-based chatbots like MoodleBot can significantly improve the teaching and learning process. This study revealed a high accuracy rate (88%) in providing course-related assistance. Positive responses from students attest to the efficacy and applicability of AI-driven educational tools. These findings indicate that educational chatbots are suitable for integration into courses to improve personalized learning and reduce teacher administrative burden, although improvements in automated fact-checking are needed.},
  keywords={Chatbots;Education;Computer science;Databases;Accuracy;Mentoring;Information technology;Information systems;Adaptation models;Vectors;Chatbots;higher education;large language model (LLM);moodle;moodlebot},
  doi={10.1109/TE.2024.3467912},
  ISSN={1557-9638},
  month={Feb},}@INPROCEEDINGS{10893499,
  author={Nguyen, Thomas and Sayadi, Hossein},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={ChatGPT vs. Gemini: Comparative Evaluation in Cybersecurity Education with Prompt Engineering Impact}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={The advent of Large Language Models (LLMs) has revolutionized numerous domains, notably education, by offering powerful tools for personalized learning and automated assistance. These models have the potential to significantly enhance the educational experience, particularly in the field of Computer Science (CS), where the complexity and rapidly evolving nature of topics present unique challenges and opportunities. In this study, we present a comparative evaluation into the transformative potential of LLMs in CS education, with a specific focus on cybersecurity. Our study centers on two leading LLMs: Ope-nAI's ChatGPT and Google's Gemini Pro, employing a three-fold assessment methodology. Firstly, we analyze the subject matter within cybersecurity education to identify key topics and challenges for examination. Secondly, we meticulously assess and compare the efficacy of ChatGPT and Gemini across various factors in producing satisfactory responses. Lastly, we explore the impact of leveraging prompt engineering on enhancing the quality of responses generated by these AI tools. Through this holistic approach, our research aims to provide insights into the strengths, limitations, and potential avenues for enhancement of these models, thereby enriching the ongoing discourse on LLMs integration in higher education.},
  keywords={Computer science;Large language models;Computational modeling;Education;Chatbots;Internet;Complexity theory;Prompt engineering;Computer security;Artificial Intelligence;ChatGPT;Education;Gemini;Large Language Models;Prompt Engineering},
  doi={10.1109/FIE61694.2024.10893499},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10366692,
  author={Hanifi, Khadija and Cetin, Orcun and Yilmaz, Cemal},
  booktitle={2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security (QRS)}, 
  title={On ChatGPT: Perspectives from Software Engineering Students}, 
  year={2023},
  volume={},
  number={},
  pages={196-205},
  abstract={ChatGPT, an increasingly popular Large Language Model (LLM), has found widespread acceptance, especially among the younger generation, who rely on it for various tasks, such as comprehending complex course materials and tackling homework assignments. This surge in interest has drawn the attention of researchers, leading to numerous studies that delve into the advantages and disadvantages of the upcoming LLM dominant era. In our research, we explore the influence of ChatGPT and similar models on the field of software engineering, specifically from the perspective of software engineering students. Our main objective is to gain valuable insights into their usage habits and opinions through a comprehensive survey. The survey encompassed diverse questions, addressing the specific areas where ChatGPT was utilized for assistance and gathering students’ reflections on each aspect. We found that ChatGPT has garnered widespread acceptance among software engineering students, with 93% of them utilizing it for their projects. These students expressed satisfaction with the level of assistance provided, and most intend to continue using it as a valuable tool in their work. During our investigation, we also assessed the students’ awareness of the underlying technologies behind ChatGPT. Approximately half of the students demonstrated awareness of these technologies, while 38.7% had made extra efforts to explore prompt engineering to enhance ChatGPT’s productivity. However, an important finding was that 90.6% of the students reported experiencing hallucinations during their interactions with ChatGPT. These hallucinations were shared as examples, raising significant concerns that warrant further exploration and mitigation. Moreover, we delved into potential improvements and gathered valuable recommendations, which could help ChatGPT to become even more effective and dependable in its applications.},
  keywords={Surveys;Software quality;Chatbots;Reliability engineering;Reflection;Software reliability;Security;ChatGPT;software engineering;academic education;generative AI;Large Language Models},
  doi={10.1109/QRS60937.2023.00028},
  ISSN={2693-9177},
  month={Oct},}@INPROCEEDINGS{10663054,
  author={Sah, Chandan Kumar and Xiaoli, Lian and Islam, Muhammad Mirajul and Islam, Md Kamrul},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Navigating the AI Frontier: A Critical Literature Review on Integrating Artificial Intelligence into Software Engineering Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The swift development of Artificial Intelligence (AI), namely the introduction of Large Language Models (LLMs), is drastically altering various industries and necessitating a major change in the way software engineering is taught. To equip upcoming software engineers with the knowledge and abilities to function in this AI-powered environment, curriculum and pedagogical techniques must be critically reevaluated. To better understand the integration of AI and LLMs into software engineering education, this study gives a thorough and critical analysis of the literature, looking at existing models, pedagogical frameworks, and enduring issues. We explore various approaches utilized by educational establishments, including as specialized AI and LLM courses, incorporating modules into pre-existing curricula, and utilizing open-source LLM materials. Our analysis, which is based on case studies and research data, thoroughly assesses how well these strategies enable software engineers to comprehend, make use of, and ethically create AI and LLMs. Key obstacles to the successful integration of AI and LLM are also identified by our analysis, including the inexperienced status of LLM educators, resource limitations, potential biases in AI and LLM algorithms, and insufficient instructor knowledge. Building on these discoveries, we provide solid answers to these problems and suggest interesting avenues for further study to improve the integration of AI and LLM. In the end, this study advocates for a multimodal strategy to get future software engineers ready for the impending AI and LLM future and secure their place in this quickly changing field.},
  keywords={Ethics;Reviews;Navigation;Large language models;Education;Software algorithms;Solids;large language models (LLMs);software engineering education;artificial intelligence (AI);Pedagogical frame-works;curriculum integration;successful strategies;problems and solutions;Instructor Skill;Resource Limitations;LLM Bias;AI Bias;Open-Source LLM Resources},
  doi={10.1109/CSEET62301.2024.10663054},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10592785,
  author={Dhar, Rudra and Vaidhyanathan, Karthik and Varma, Vasudeva},
  booktitle={2024 IEEE 21st International Conference on Software Architecture (ICSA)}, 
  title={Can LLMs Generate Architectural Design Decisions? - An Exploratory Empirical Study}, 
  year={2024},
  volume={},
  number={},
  pages={79-89},
  abstract={Architectural Knowledge Management (AKM) involves the organized handling of information related to architectural decisions and design within a project or organization. An essential artefact of AKM is the Architecture Decision Records (ADR), which documents key design decisions. ADRs are documents that capture decision context, decision made and various aspects related to a design decision, thereby promoting transparency, collaboration, and understanding. Despite their benefits, ADR adoption in software development has been slow due to challenges like time constraints and inconsistent uptake. Recent advancements in Large Language Models (LLMs) may help bridge this adoption gap by facilitating ADR generation. However, the effectiveness of LLM for ADR generation or understanding is something that has not been explored. To this end, in this work, we perform an exploratory study which aims to investigate the feasibility of using LLM for the generation of ADRs given the decision context. In our exploratory study, we utilize GPT and T5-based models with 0-shot, few-shot, and fine-tuning approaches to generate the Decision of an ADR given its Context. Our results indicate that in a 0-shot setting, state-of-the-art models such as GPT-4 generate relevant and accurate Design Decisions, although they fall short of human-level performance. Additionally, we observe that more cost-effective models like GPT-3.5 can achieve similar outcomes in a few-shot setting, and smaller models such as Flan-T5 can yield comparable results after fine-tuning. To conclude, this exploratory study suggests that LLM can generate Design Decisions, but further research is required to attain human-level generation and establish standardized widespread adoption.},
  keywords={Software architecture;Large language models;Standards organizations;Collaboration;Organizations;Computer architecture;Knowledge management;ADR;LLM},
  doi={10.1109/ICSA59870.2024.00016},
  ISSN={2835-7043},
  month={June},}
@INPROCEEDINGS{10500042,
  author={Woerner, Jan H.R. and Turtova, Aleksandra P. and Lang, Andrew S.I.D.},
  booktitle={SoutheastCon 2024}, 
  title={Transformative Potentials and Ethical Considerations of AI Tools in Higher Education: Case Studies and Reflections}, 
  year={2024},
  volume={},
  number={},
  pages={510-515},
  abstract={This paper examines the transformative impact of Artificial Intelligence (AI) tools, especially Large Language Models like ChatGPT, on higher education. Focusing on how AI can enhance and challenge the learning environment, it navigates through the benefits and ethical concerns, such as privacy issues, overreliance on the technology itself, and potential biases. The article's core comprises two practical case studies-one in computer science, where ChatGPT aids in teaching programming, and another in English composition, exploring its role in developing writing skills. In the computer science context, ChatGPT shows how AI can introduce diverse problem-solving approaches and elevate student engagement, with notable improvements in students' comprehension and application of programming techniques. In English composition, the integration of ChatGPT assists in crafting texts, highlighting the balance needed between AI assistance and human critical thinking. Concluding with a call for a balanced approach, the study emphasizes that AI should complement, not substitute, traditional teaching methods. It advocates for a responsible and ethical application of AI in education, underlining the need to integrate technological advancements with fundamental core literacies to elevate the academic experience of all students.},
  keywords={Ethics;Privacy;Navigation;Education;Writing;Chatbots;Reflection;AI;Artificial Intelligence;classroom;teacher;exploration;concerns;strategies;computer-mediated;learning},
  doi={10.1109/SoutheastCon52093.2024.10500042},
  ISSN={1558-058X},
  month={March},}@ARTICLE{10105236,
  author={Shoufan, Abdulhadi},
  journal={IEEE Access}, 
  title={Exploring Students’ Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey}, 
  year={2023},
  volume={11},
  number={},
  pages={38805-38818},
  abstract={ChatGPT has sparked both excitement and skepticism in education. To analyze its impact on teaching and learning it is crucial to understand how students perceive ChatGPT and assess its potential and challenges. Toward this, we conducted a two-stage study with senior students in a computer engineering program ( $n=56$ ). In the first stage, we asked the students to evaluate ChatGPT using their own words after they used it to complete one learning activity. The returned responses (3136 words) were analyzed by coding and theme building (36 codes and 15 themes). In the second stage, we used the derived codes and themes to create a 27-item questionnaire. The students responded to this questionnaire three weeks later after completing other activities with the help of ChatGPT. The results show that the students admire the capabilities of ChatGPT and find it interesting, motivating, and helpful for study and work. They find it easy to use and appreciate its human-like interface that provides well-structured responses and good explanations. However, many students feel that ChatGPT’s answers are not always accurate and most of them believe that it requires good background knowledge to work with since it does not replace human intelligence. So, most students think that ChatGPT needs to be improved but are optimistic that this will happen soon. When it comes to the negative impact of ChatGPT on learning, academic integrity, jobs, and life, the students are divided. We conclude that ChatGPT can and should be used for learning. However, students should be aware of its limitations. Educators should try using ChatGPT and guide students on effective prompting techniques and how to assess generated responses. The developers should improve their models to enhance the accuracy of given answers. The study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development.},
  keywords={Chatbots;Education;Codes;Encoding;Performance evaluation;Oral communication;ChatGPT;students’ perceptions;education},
  doi={10.1109/ACCESS.2023.3268224},
  ISSN={2169-3536},
  month={},}@ARTICLE{10418595,
  author={Safari, Pegah and Shamsfard, Mehrnoush},
  journal={IEEE Access}, 
  title={Data Augmentation and Preparation Process of PerInfEx: A Persian Chatbot With the Ability of Information Extraction}, 
  year={2024},
  volume={12},
  number={},
  pages={19158-19180},
  abstract={In this paper, we describe data preparation for our proposed chatbot PerInfEx (Persian Information Extraction chatbot). It aims to interactively chit-chat with users in Persian and by asking the least number of direct questions, extract as much personal information as possible such as user’s age or occupation. Collecting data in considerable size and aligned with our system’s specifics is a crucial step to train data-hungry modules of Natural Language Understating (NLU) and Natural Language Generating (NLG). Initially, for NLU module, we collect 99 free-discussion dialogues and crawl 74 English training conversations as more-general datasets while also manually translate 72 dialogues of ConvAI2 corpus. Moreover, we gamify collection by implementing a chatting website results in 94 dialogues. It detects direct questions and assigns random profiles to participants. They should guess the opponents profile. Also, we propose two augmentation methods: a semi-automatic and a novel fully automatic method, comprehensively evaluated on NLU benchmarks and applied on our datasets. Also, by prompting OpenAI’s GPT-3.5 model, we automatically generate 304 dialogues. The first part of these datasets is manually annotated while we use an active learning method for annotating rest of them. Next, to evaluate data quality, we assess them extrinsically using NLU baseline which results in intent-accuracy = 88.64, slot-F1 = 83.68 and exact-match = 78.22. Also, for NLG module, we automatically translate almost the rest of ConvAI2 corpus (16,217 dialogues) and paraphrase previously sets for its fine-tuning using GPT-3.5 model. Their assessment using our NLG baseline results in perplexity of 15.74 on train and 52.17 on test set.},
  keywords={Chatbots;Oral communication;Training;Data augmentation;Semantics;Data mining;Natural languages;Data collection;Data augmentation;data collection;dialogue generation;direct question;Persian open-domain chatbot;paraphrasing;personal information extraction},
  doi={10.1109/ACCESS.2024.3360863},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10967301,
  author={Simaremare, Mario and Pardede, Chandro and Tampubolon, Irma and Manurung, Putri and Simangunsong, Daniel},
  booktitle={2024 31st Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={Pair Programming in Programming Courses in the Era of Generative AI: Students' Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={507-511},
  abstract={Context: The emergence of Generative AI (GenAI) technology presents an opportunity to enhance students' learning experience in programming courses using pair programming. GenAI can take the navigator role in student-GenAI pairing as an alternative to traditional student-student pairing. Objective: This study explored various use cases, challenges, and learning experiences IT students faced when using the student-GenAI pairing approach. Method: We integrated GenAI into CS1 and CS2 courses in one semester split into two halves: in the first half, students worked in student-GenAI pairs, while in the second half students worked in traditional student-student pairing with GenAI as an additional reinforcement. At the end of the semester, we interviewed 12 students purposefully selected out of 103 enrollments and employed a thematic analysis approach to synthesize the qualitative data. Results: We identified five distinct GenAI use cases confirming the existing studies and matching how software practitioners utilize GenAI in the industry, indicating an alignment between education and industry practice. Furthermore, we identified six challenges. One novel challenge related to the consequence of the technology is narrowing the students' learning horizons. The students also expressed a lack of engagement and empathy in student-GenAI pairing. They preferred the traditional pairing with GenAI as additional support, providing a better learning experience. Conclusion: Integrating GenAI into programming courses can enhance the learning experience, but new challenges emerge, provoking further studies to address them.},
  keywords={Industries;Generative AI;Navigation;Education;Chatbots;Software;Programming profession;Software engineering;Software development management;Generative AI;pair programming;programming course;ChatGPT;GitHub Copilot},
  doi={10.1109/APSEC65559.2024.00069},
  ISSN={2640-0715},
  month={Dec},}@ARTICLE{10530940,
  author={Kalluri, Balaji and Prasad, Prajish and Sharma, Prakrati and Chippa, Divyaansh},
  journal={IEEE Transactions on Education}, 
  title={Developing Future Computational Thinking in Foundational CS Education: A Case Study From a Liberal Education University in India}, 
  year={2024},
  volume={67},
  number={6},
  pages={944-953},
  abstract={Contribution: This article proposes a new theoretical model with a goal to develop future human computational thinking (CT) in foundational computer science (CS) education. The model blends six critical types of thinking, i.e., logical thinking, systems thinking, sustainable thinking, strategic thinking, creative thinking, and responsible thinking into the design of a first-year undergraduate programming course. The study describes a creative blended pedagogy that embeds the proposed model into the course plan.Background: The emergence of artificial intelligent systems such as large language models from a knowledge provider perspective, coupled with a gradual change in post-pandemic outlook of education challenge the relevance and raises concerns about the future of education. The 21st-century human CT requirements, viz., learning to code (skill) and thinking computationally (competency), will be inadequate in the future. Moreover, there is substantial evidence which shows that most introductory programming courses fail to integrate critical elements like ethics and responsibility as part of the course.Intended Outcomes: The authors anticipate experiential learning models such as this has immense potential to future-proof CS education, as well as make future software engineers responsible citizens.Application Design: The proposed model blends six types of thinking into the design and activities of the course. The underlying theoretical basis of these activities revolve around three key principles: 1) experiential learning; 2) self-reflection; and 3) peer learning.Findings: This case study from a liberal educational institution in India qualitatively shows evidence of students developing six critical elements of thinking that shapes their future CT ability.},
  keywords={Education;Sustainable development;Computational modeling;Systems thinking;Programming profession;Software systems;Green products;21st-century skills;computer science (CS);creative pedagogy;foundational education;future thinking},
  doi={10.1109/TE.2024.3394060},
  ISSN={1557-9638},
  month={Dec},}@INPROCEEDINGS{10893333,
  author={Tuzmen, Ayca},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Use of Generative Artificial Intelligence in the Education of Software Verification and Validation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Since the introduction of generative artificial intelligence (GenAI), education in computer science has prompted efforts to incorporate it into the educational curriculum. This innovative practice full paper presents a study into using GenAI to enhance student learning of software engineering. It outlines the initiatives to introduce GenAI into a graduate-level software engineering course in Software Verification and Validation (SV&V). The paper presents the educational goals, methodologies and findings of these endeavors in this course. The primary education goal of this course is that students have a solid understanding of principles and practices of software quality assurance and seek to introduce students to diverse techniques employed for SV&V. The study presented in this paper centers on the practical application of GenAI within the domain of testing strategies. The paper introduces the findings of an exercise where GenAI was used to apply testing strategies for unit testing. The exercise consisted of the use of GenAI in the development of unit tests for an algorithm. Rigorous assessments were conducted to gauge the effectiveness of the unit tests developed for validating the accurate implementation of the algorithm. This exploration shed light on the tangible impact of GenAI on the precision and efficiency of unit testing procedures. The findings underscore the significance of encouraging students to actively explore emerging trends and methodologies in the realm of software verification and validation. By incorporating GenAI into the educational framework, students not only gain insights into the capabilities and limitations of this technology but also foster a mindset of continuous learning in software quality assurance. The paper demonstrates that it is not sufficient to use the test cases developed by GenAI for software validation since test cases recommended by GenAI do not cover corner cases which causes gaps in coverage in unit testing. The majority of the students were able to understand the limitation of GenAI in SV&V but appreciated its support in suggesting test cases for the most common cases. This exercise allowed students to enhance their creative problem-solving through human-guided AI partnership which is pivotal in cultivating a new generation of professionals capable of contributing to the ongoing evolution of software quality.},
  keywords={Technological innovation;Codes;Generative AI;Education;Software algorithms;Software quality;Solids;Problem-solving;Testing;Software engineering;generative artificial intelligence;software verification and validation;unit testing},
  doi={10.1109/FIE61694.2024.10893333},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10502959,
  author={Vijaya, J. and Swati, Ch and Satya, Swastika},
  booktitle={2024 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI)}, 
  title={Ikigai: Artificial Intelligence-Based Virtual Desktop Assistant}, 
  year={2024},
  volume={2},
  number={},
  pages={1-6},
  abstract={The AI Desktop Assistant project aims to create an advanced virtual assistant inspired by cinematic intelligent systems to enhance user interactions with computers by integrating natural language voice commands into daily tasks. The project harnesses existing techniques, offering users the ability to interact with the assistant through voice commands for tasks like sending emails and scheduling while also automating routine activities such as file organization. However, despite its promising features, the existing project may have some drawbacks. One Potential limitation could be its reliance on pre-defined voice commands, which may limit the flexibility and naturalness of interactions. Additionally, the system’s ability to understand and respond accurately to various user accents and speech patterns may need further refinement to ensure inclusivity. Furthermore, as the project aims to automate routine tasks, user privacy and data security concerns might require careful consideration and mitigation. Addressing These challenges and continuously improving the project will be essential to deliver a robust and user-friendly desktop assistant. To overcome project drawbacks, we’ll enhance NLP for natural interactions, improve adaptive voice recognition, prioritize user-centric design, deploy machine learning for command understanding, enable personalization and accessibility, and provide user education. We Would Utilize advanced NLP models like BERT or GPT-3.5 for language understanding. Fine-tune these models on diverse text data to enhance natural language interactions. We will collect speech and text data from reputable sources such as Kaggle and other open-source datasets. We are additionally integrating the NASA navigator (which gives news related to space) so that users can stay informed about space-related events and missions, fostering their curiosity and interest in space exploration. Success metrics include user satisfaction and the assistant’s efficiency in executing tasks. Continuous user feedback fuels improvements, promising a seamless and intelligent desktop assistant experience.},
  keywords={Adaptation models;Technological innovation;Navigation;Virtual assistants;NASA;Speech recognition;Organizations;Virtual Assistant;UI;Artificial Intelligence;Python Library;Natural Language Process},
  doi={10.1109/IATMSI60426.2024.10502959},
  ISSN={},
  month={March},}@ARTICLE{10521640,
  author={Bengesi, Staphord and El-Sayed, Hoda and Sarker, MD Kamruzzaman and Houkpati, Yao and Irungu, John and Oladunni, Timothy},
  journal={IEEE Access}, 
  title={Advancements in Generative AI: A Comprehensive Review of GANs, GPT, Autoencoders, Diffusion Model, and Transformers}, 
  year={2024},
  volume={12},
  number={},
  pages={69812-69837},
  abstract={The launch of ChatGPT in 2022 garnered global attention, marking a significant milestone in the Generative Artificial Intelligence (GAI) field. While GAI has been in effect for the past decade, the introduction of ChatGPT sparked a new wave of research and innovation in the Artificial Intelligence (AI) domain. This surge has led to the development and release of numerous cutting-edge tools, such as Bard, Stable Diffusion, DALL-E, Make-A-Video, Runway ML, and Jukebox, among others. These tools exhibit remarkable capabilities, encompassing tasks ranging from text generation and music composition, image creation, video production, code generation, and even scientific work. They are built upon various state-of-the-art models, including Stable Diffusion, transformer models like GPT-3 (recent GPT-4), variational autoencoders, and generative adversarial networks. This advancement in GAI presents a wealth of exciting opportunities across various sectors, such as business, healthcare, education, entertainment, and media. However, concurrently, it poses unprecedented challenges such as impersonation, job displacement, privacy breaches, security vulnerabilities, and misinformation. To addressing these challenges requires a new direction for research to develop solutions and refine existing products. In our endeavor to contribute profound insights to society and advance research on GAI, we present a comprehensive journal which explores the theoretical and mathematical foundations of GAI state-of-the-art models, exploring the diverse spectrum of tasks they can perform, examining the challenges they entail, and discussing the promising prospects for the future of GAI.},
  keywords={Decoding;Mathematical models;Task analysis;Vectors;Codes;Transformers;Neural networks;Generative AI;Generative adversarial networks;Artificial intelligence;Chatbots;Encoding;Generative AI;GPT;bard;ChatGPT;diffusion model;transformer;GAN;autoencoder;artificial intelligence},
  doi={10.1109/ACCESS.2024.3397775},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10578917,
  author={Duvignau, Romaric},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={ChatGPT Has Eaten My Assignment: A Student-Centric Experiment on Supervising Writing Processes in the AI Era}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={AI-powered text generation tools have brought about a profound shift in students' approaches to writing assignments, prompting the need for writing supervisors to gain a deeper understanding of how these tools can effectively tackle conventional university assignments. This ongoing work presents a documented and student-centered experiment where such tools are used for crafting the final assignment in a higher education course. Through the lens of a reflective essay, the study provides insights into the experiment's nuances and offers practical considerations that can prove invaluable to writing supervisors. Despite being introduced in late 2022, ChatGPT, a prominent AI language model, has quickly become a focal point in higher education research. This work distinguishes itself from existing literature by presenting a practical guide tailored for writing supervisors involved in overseeing diverse writing processes. By documenting a student's firsthand experience using ChatGPT to generate a self-assessment plan within the context of a university writing supervision course, the study not only explores the benefits and challenges of integrating AI tools but also underscores the importance of responsible usage. In particular, this work furnishes valuable insights for writing supervisors navigating the evolving landscape of AI-driven writing tools, offering a nuanced understanding of their practical implications.},
  keywords={Navigation;Writing;Chatbots;Educational courses;Artificial intelligence;Engineering education;Lenses;ChatGPT;AI;assignment;writing supervision},
  doi={10.1109/EDUCON60312.2024.10578917},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10893139,
  author={Lauren, Paula},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Work-in-Progress: Course-based Undergraduate Research Experience (CURE) with Generative AI in a Computer Science Course}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress innovative practice paper describes a novel integration of Generative AI with Course-based Undergraduate Research Experiences (CUREs). CUREs integrate research activities into the curriculum, allowing all students in a course to participate in inquiry-based research projects. Generative Artificial Intelligence (AI) applications are advanced AI designed to generate human-like responses by processing natural language inputs. These applications leverage machine learning models to produce outputs that can assist users in a variety of tasks from writing to coding. The integration of Generative AI with CURE had been adopted in a text-based machine learning course during the Fall 2023 semester. A comparative analysis had been conducted on student survey responses from Fall 2022 and Fall 2023 to evaluate the effectiveness of Generative AI in a CURE integrated course. Descriptive statistics and statistical tests were conducted to assess differences in student perceptions between the two semesters. Although the differences were not statistically significant, the results indicate a promising trend towards improved student perceptions of both the overall course effectiveness and the benefits of Generative AI in enhancing various aspects of the research process, especially the literature review.},
  keywords={Surveys;Computer science;Generative AI;Natural languages;Machine learning;Writing;Market research;Encoding;Systematic literature review;Course-based Undergraduate Research Experiences (CUREs);Generative AI;Artificial Intelligence in Education (AIEd)},
  doi={10.1109/FIE61694.2024.10893139},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10343474,
  author={Liu, Yunkai},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Leveraging the Power of AI in Undergraduate Computer Science Education: Opportunities and Challenges}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The paper analyzes the potential opportunities and challenges of incorporating advanced AI tools, such as ChatGPT, into undergraduate computer science education. Through a literature review, the current research on the use of AI in computer science education is summarized and gaps in the current literature are identified. The paper argues that with proper planning and support, the integration of AI tools in computer science education can enhance the curriculum and prepare students for both programming education and literature education. The limitations of ChatGPT and related AI tools are also discussed, including ethical implications and potential effects on teaching style and undergraduate research. The results of a simple survey show the current level of knowledge and usage of ChatGPT among faculty and undergraduate students in computer science majors. The paper concludes that while there are challenges to overcome, such as ethical concerns, an optimistic attitude towards the integration of AI into undergraduate computer science education can lead to positive outcomes and prepare students for the workforce.},
  keywords={Surveys;Ethics;Bibliographies;Education;Chatbots;Computer science education;Planning;ChatGPT;Artificial Intelligence;Computer Science Education;Nature Language Processing},
  doi={10.1109/FIE58773.2023.10343474},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10923833,
  author={Lee, John S. Y. and Liu, Fengkai and Cai, Tianyuan},
  booktitle={2024 IEEE 13th International Conference on Engineering Education (ICEED)}, 
  title={Code Debugging with LLM-Generated Explanations of Programming Error Messages}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Programming is an essential part of the curriculum for electrical, computer and software engineering students. Since one inevitably makes coding mistakes, it is important for programmers to develop debugging skills. However, it could be challenging for beginners to repair a non-compiling program, since programming error messages tend to be opaque, and might not directly address the error. This paper investigates the use of Large Language Models to generate plain, novice-friendly explanations of programming error messages. In an introductory course on Natural Language Processing, We evaluate the extent to which these explanations help students debug Python code with six common programming error categories. Experimental results suggest that explanations generated with zero-shot GPT-4 are effective in raising the code revision success rate.},
  keywords={Codes;Large language models;Debugging;Maintenance engineering;Encoding;Logic;Engineering education;Programming profession;Software engineering;Python;computer science;computer engineering;software engineering;Python;debugging;Large Language Model;Programming Error Message},
  doi={10.1109/ICEED62316.2024.10923833},
  ISSN={},
  month={Nov},}@ARTICLE{10546497,
  author={Shaer, Orit and Cooper, Angelora},
  journal={IEEE Pervasive Computing}, 
  title={Integrating Generative Artificial Intelligence to a Project-Based Tangible Interaction Course}, 
  year={2024},
  volume={23},
  number={1},
  pages={63-69},
  abstract={Generative Artificial Intelligence (AI), including large language and image models, have created new opportunities for pervasive computing education. How do we integrate emerging AI models and tools into our courses in a way that fosters critical engagement? How do we teach students to use AI models and tools responsibly, thoughtfully, and ethically, while being aware of their capabilities and limitations? In this article, we share insights from integrating generative AI tools and machine learning (ML) models into a project-based undergraduate tangible and embodied interaction (TEI) course by employing co-creation processes. TEI is an evolving area within human–computer interaction, which focuses on integrating computation into our daily physical environments and objects, thus fostering an embodied, multisensory, and often collaborative interaction experience. We use the term co-creation to describe a process, where humans and AI work together to create new artifacts or solve a problem. We integrated structured co-creation activities into various phases of the project including ideation, conceptual design, and prototyping. We describe practical ways and learning goals for integrating emerging generative AI tools and ML models into the project design process, provide insight on how novice interaction designers iterate and collaborate with generative AI and ML models, and reflect on the merits and limitations of using generative AI tools and ML models for project-based interaction design courses for pervasive computing.},
  keywords={Pervasive computing;Ethics;Generative AI;Computational modeling;Education;Collaboration;Machine learning;Large language models;Artificial intelligence;Machine learning;Educational courses},
  doi={10.1109/MPRV.2023.3346548},
  ISSN={1558-2590},
  month={Jan},}@INPROCEEDINGS{10838104,
  author={Sedilla, Raymond B. and Beley, Rafael Joseph T. and Gamboa, John Jeremie D. and Liu, Bon Pin M. and Mariano, Jules and Samonte, Mary Jane C.},
  booktitle={2024 IEEE 7th International Conference on Computer and Communication Engineering Technology (CCET)}, 
  title={Assessment of Machine Translation in Addressing Communication Barriers on the Perception of College Students}, 
  year={2024},
  volume={},
  number={},
  pages={262-266},
  abstract={As tools powered by Artificial Intelligence (AI) continue to advance, more specifically large language models, as they continue to develop improvements in machine translation. 59.9% of the student respondents say they use AI for machine translation daily. Google Translate is still the majority of the AI tools used in machine translation by students with 22% followed by Chat-GPT with 21%. Amongst the three criteria asked in the survey, there is an ongoing pattern that a huge majority of the students are satisfied with the accuracy, adequacy, and fluency of the translated text. The findings illuminate a widespread reliance on AI tools, with Google Translate and ChatGPT leading the preferences. The study underscores the importance of these tools across diverse academic disciplines, from engineering to language training, revealing a nuanced landscape of AI integration in education. The satisfaction levels reported by the students regarding accuracy, adequacy, and fluency highlight the positive impact of AI in facilitating language-related tasks.},
  keywords={Training;Surveys;Translation;Accuracy;Navigation;Collaboration;Chatbots;Internet;Machine translation;Artificial intelligence;machine translation;language barrier;communication},
  doi={10.1109/CCET62233.2024.10838104},
  ISSN={2836-5992},
  month={Aug},}@INPROCEEDINGS{10959426,
  author={Alashwal, May},
  booktitle={2025 2nd International Conference on Advanced Innovations in Smart Cities (ICAISC)}, 
  title={Generative AI in Computer Science Education: Insights from Topic Modeling and Text Network Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The rapid evolution of generative artificial intelligence (AI) is reshaping educational landscapes., particularly in computer science education. This study investigates research trends in generative AI applications through text network and topic modeling analyses. A comprehensive literature review across IEEE Xplore., Scopus., and Web of Science identified 151 studies published between 2023 and 2024. Text network analysis revealed that “AI.,” “student.,” “education.,” “learning.,” and “performance” were the most frequently occurring terms., highlighting key research themes. Ego-network analysis demonstrated strong interconnectivity between educational AI tools and student learning outcomes. Using Latent Dirichlet Allocation (LDA)., four major research topics emerged: educational chatbots (35.1 %)., AI literacy (25.8%)., exam performance (21.8%)., and technology integration (17.2%). Findings indicate a dominant focus on chatbots for student engagement., while ethical concerns and multimodal AI applications remain underexplored. The study underscores the necessity of addressing AI literacy gaps and enhancing interdisciplinary AI integration in educational settings. Despite its potential., generative AI adoption is hindered by privacy risks., uneven technological access., and the lack of standardized policies. Future research should focus on ethical AI frameworks., multimodal AI tools., and long-term learning outcomes. This study provides a data-driven foundation for understanding the evolving role of generative AI in education and its implications for educators., policymakers., and researchers.},
  keywords={Ethics;Analytical models;Privacy;Generative AI;Computational modeling;Education;Network analyzers;Chatbots;Market research;Computer science education;Generative AI;Computer Science Education;AI Literacy;Educational Chatbots;Topic Modeling Analysis},
  doi={10.1109/ICAISC64594.2025.10959426},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10342963,
  author={Dehbozorgi, Nasrin and Kunuku, Mourya Teja},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Affective Computing: A Topic-Based SER Approach on Collaborative Discussions in Academic Setting}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={One of the biggest concerns in the modern day especially in the educational domain centers on the student's mental health. High rates of anxiety and depression have especially brought the attention of researchers in engineering education to apply affective computing to help with students' academic performance. It is known that a person's emotional states cause physiological and physical changes in the body. Emotions may impact facial expression, tone of speech, blood pressure, pulse, etc. Since visual and auditory signals are two variables that can be measured without the need to attach any physical device to the individuals, they are most studied in this field. Speech in particular has been known as a means that transfers much information about the mental and emotional states of the person. Speech Emotion Recognition (SER) is a growing field that has been applied in several domains including engineering education. Recent advancements in AI, Natural Language Understanding (NLU), and Large Language Models (LLM) have significantly streamlined this line of research. In this work which is a continuation of our prior work, we propose a speech analysis model that extracts both the emotions and topics from verbal discussions in a computer science classroom to understand if the expressed emotions were mostly about the course related topics or not. The goal of this research is to develop a tool that helps educators gain insights into the students' emotional states in teamwork and also understand the context of their conversations. We further analyze if the expressed emotions in the verbal class discussions are mostly about the course content or other subjects outside class setting. To expand the emotion analysis module we added a new layer to our developed pipeline by passing the speech data into the ChatGPT API to generate summarized scripts and extract additional classes of emotion. The preliminary results from this study are promising, indicating the potential value of this research direction and its prospects for further development. Application of this model in the educational domain can greatly benefit both educators and students and allows the instructors to make necessary interventions needed to maximize students' positive experiences in team settings while considering their emotional states.},
  keywords={Computer science;Analytical models;Emotion recognition;Affective computing;Computational modeling;Pipelines;Chatbots;Speech Emotion Recognition (SER);Large Language Models (LLM);NLP;Topic modeling;Affective computing;ChatGPT API;Teamwork;Engineering education},
  doi={10.1109/FIE58773.2023.10342963},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10870136,
  author={Lang, Qi and Wang, Minjuan and Yin, Minghao and Liang, Shuang and Song, Wenzhuo},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Transforming Education With Generative AI (GAI): Key Insights and Future Prospects}, 
  year={2025},
  volume={18},
  number={},
  pages={230-242},
  abstract={Generative artificial intelligence (GAI) has demonstrated remarkable potential in both educational practice and research, particularly in areas, such as personalized learning, adaptive assessment, innovative teaching methods, and cross-cultural communication. However, it faces several significant challenges, including the comprehension of complex domain knowledge, technological accessibility, and the delineation of AI's role in education. Addressing these challenges necessitates collaborative efforts from educators and researchers. This article summarizes the state-of-the-art large language models (LLMs) developed by various technology companies, exploring their diverse applications and unique contributions to primary, higher, and vocational education. Furthermore, it reviews recent research from the past three years, focusing on the challenges and solutions associated with GAI in educational practice and research. The aim of the review is to provide novel insights for enhancing human–computer interaction in educational settings through the utilization of GAI. Statistical analysis reveals that the current application of LLMs in the education sector is predominantly centered on the ChatGPT series. A key focus for future research lies in effectively integrating a broader range of LLMs into educational tasks, with particular emphasis on the interaction between multimodal LLMs and educational scenarios.},
  keywords={Education;Artificial intelligence;Large language models;Transformers;Chatbots;Technological innovation;Enthalpy;Collaboration;Visualization;Videos;Artificial intelligence (AI)-assisted learning;educational technologies;generative artificial intelligence (GAI);large language models (LLMs);survey research},
  doi={10.1109/TLT.2025.3537618},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10811132,
  author={Thaqi, Alba and Musa, Arbena and Rexha, Blerim},
  booktitle={2024 5th International Conference on Communications, Information, Electronic and Energy Systems (CIEES)}, 
  title={Leveraging AI for CTF Challenge Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Capture the Flag (CTF) competitions have become integral to developing cybersecurity skills, providing participants with real-world scenarios that challenge their problem-solving abilities. However, the complexity of these challenges often creates barriers for participants, especially those with less experience. This paper explores the potential of leveraging Artificial Intelligence (AI), specifically OpenAI’s Large Language Models (LLMs), to optimize the CTF challenge-solving process. By conducting a comparative study, we analyze how AI can assist participants by offering intelligent hints and personalized suggestions without compromising the integrity of the challenge. Our approach focuses on using pre-trained models to enhance learning outcomes, improve engagement, and streamline problem-solving across different difficulty levels. The results show that AI-driven solutions significantly improve the accessibility and effectiveness of CTF challenges, particularly for novice participants, by creating a more collaborative learning environment. The paper concludes that the integration of AI in CTF competitions can revolutionize cybersecurity education by making it more inclusive and adaptable to a wide range of learners.},
  keywords={Surveys;Statistical analysis;Federated learning;Large language models;Complexity theory;Problem-solving;Artificial intelligence;Intelligent systems;Optimization;Testing;capture the flag;OpenAI;cyber security},
  doi={10.1109/CIEES62939.2024.10811132},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10590238,
  author={Wang, Kevin and Akins, Seth and Mohammed, Abdallah and Lawrence, Ramon},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Student Mastery or AI Deception? Analyzing ChatGPT's Assessment Proficiency and Evaluating Detection Strategies}, 
  year={2023},
  volume={},
  number={},
  pages={1615-1621},
  abstract={Generative AI systems such as ChatGPT have a disruptive effect on learning and assessment. Computer science requires practice to develop skills in problem solving and programming that are traditionally developed using assignments. Generative AI has the capability of completing these assignments for students with high accuracy, which dramatically increases the potential for academic integrity issues and students not achieving desired learning outcomes. This work investigates the performance of ChatGPT by evaluating it across three courses (CS1,CS2,databases). ChatGPT completes almost all introductory assessments perfectly. Existing detection methods, such as MOSS and JPlag (based on similarity metrics) and GPTzero (AI detection), have mixed success in identifying AI solutions. Evaluating instructors and teaching assistants using heuristics to distinguish between student and AI code shows that their detection is not sufficiently accurate. These observations emphasize the need for adapting assessments and improved detection methods.},
  keywords={Measurement;Accuracy;Codes;Generative AI;Scientific computing;Education;Programming;ChatGPT;generative AI;performance;detection;plagarism;CS1;CS2;database},
  doi={10.1109/CSCI62032.2023.00268},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{11016417,
  author={Rachmat, Agatha and Watterson, Craig and Lundqvist, Karsten},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={The Impact of Chatbots on Students' Reflective Thinking in Introductory Programming Course}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This study investigated New Zealand students' views on utilising chatbots and the impact of using ChatGPT or similar chatbots with suggested prompts on the reflective thinking skills of university students. The research was conducted in an introductory computer programming course (COMP102) in the School of Engineering and Computer Science. This introductory course uses a flipped classroom approach. The students were introduced to an approach to use a generative AI-based chatbot as an intervention. The intervention consisted of a brief explanation of chatbot training and utilisation, along with a specifically designed prompt intended to support learning. An example of prompt usage was demonstrated. Students' feedback was collected through two instruments: a Reflective Thinking Scale questionnaire, which measured students' reflective thinking abilities, and an open-ended student guide questionnaire designed to gather qualitative insights into their views and experiences using chatbots. Employing a mixed-methods research approach, we incorporated quantitative (Reflective Thinking Scale questionnaire) and qualitative (open-ended student guide questionnaire) data collection instruments within an experimental pre-test and post-test control group design. The pretest yielded 86 completed responses, while the post-test had 49 participants out of over 400 students enrolled in the course. The pre-test and posttest results did not yield quantitatively significant results in students' reflective thinking after the intervention. However, 21 out of 29 qualitative post-test respondents who utilise chatbots indicated that their interactions with the chatbot showed evidence of reflective thinking that improved their learning processes. The results revealed that students initially had doubts about using a chatbot for their learning, as they felt it might hinder their learning process or be unnecessary. Students perceived chatbots to be unreliable due to providing wrong answers, inaccurate code snippets, hallucinations, and plagiarised content. Therefore, students preferred to be self-reliant and not dependent on chatbots. Following the intervention, students demonstrated an increase of confidence in utilising chatbots as a learning tool, especially those who also used the suggested prompt. Students found that chatbots and the suggested prompt could be used to support learning and not only to provide answers. The chatbot was beneficial as a learning tool, providing additional information to clarify their understanding and reasoning behind providing simple explanations of programming concepts. Future work will focus on an intervention study in a more controlled environment to isolate the features of generative AI tools' impact and minimise external factors.},
  keywords={Training;Knowledge engineering;Electronic learning;Generative AI;Instruments;Data collection;Chatbots;Online services;Engineering education;Programming profession;Reflective Thinking;Chatbots;Introductory programming;ChatGPT;Generative AI;Higher Education},
  doi={10.1109/EDUCON62633.2025.11016417},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10691721,
  author={Qiu, Siyu and Tan, Benjamin and Pearce, Hammond},
  booktitle={2024 IEEE LLM Aided Design Workshop (LAD)}, 
  title={LLM-aided explanations of EDA synthesis errors}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Training new engineers in digital design is a challenge, particularly when it comes to teaching the complex electronic design automation (EDA) tooling used in this domain. Learners will typically deploy designs in the Verilog and VHDL hardware description languages to Field Programmable Gate Arrays (FPGAs) from Altera (Intel) and Xilinx (AMD) via proprietary closed-source toolchains (Quartus Prime and Vivado, respectively). These tools are complex and difficult to use—yet, as they are the tools used in industry, they are an essential first step in this space. In this work, we examine how recent advances in artificial intelligence may be leveraged to address aspects of this challenge. Specifically, we investigate if Large Language Models (LLMs), which have demonstrated text comprehension and question-answering capabilities, can be used to generate novice-friendly explanations of compile-time synthesis error messages from Quartus Prime and Vivado. To perform this study we generate 936 error message explanations using three OpenAI LLMs over 21 different buggy code samples. These are then graded for relevance and correctness, and we find that in approximately 71% of cases the LLMs give correct & complete explanations suitable for novice learners.},
  keywords={Training;Industries;VHDL;Design automation;Large language models;Conferences;Computer bugs;Logic gates;Hardware;Field programmable gate arrays;EDA;CAD;AI;LLM;Bug Explanation},
  doi={10.1109/LAD62341.2024.10691721},
  ISSN={},
  month={June},}@INPROCEEDINGS{10892995,
  author={Barlowe, Scott and Aoulou, Daniel and Ponce-Castillo, Alex},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: Generative AI as an Instructional Resource in a Computer Science Ethics Course}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress research paper reports our initial attempt at integrating generative artificial intelligence (Gen AI) into our two credit hour ethics course required for computer science majors. Course content includes ethical frameworks, presentations, current event and stakeholder analysis, formal debates, job seeking, and codes of conduct. Given the wide applicability of computer ethics and the crowded schedule in the course, our inquiry seeks to find ways of utilizing Gen AI to streamline content delivery, to provide opportunities for independent student exploration, and to aid students during preparation for class activities. In this paper, we first describe a novel assignment integrating Gen AI given to students enrolled in the Spring 2024 offering of our computer science ethics course. The findings from a survey addressing student use of Gen AI before and during the assignment and the analysis of assignment artifacts submitted by students are then reported. Finally, we present additional student data and results from our separate experimentation, both of which focus on the use of Gen AI for debate preparation. Our efforts reveal that Gen AI can be a useful instructional tool for a computer science ethics course but should be integrated carefully.},
  keywords={Computer science;Surveys;Ethics;Schedules;Codes;Generative AI;Stakeholders;Springs;ethics;professional skills;computer science},
  doi={10.1109/FIE61694.2024.10892995},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10577164,
  author={Hang, Ching Nam and Wei Tan, Chee and Yu, Pei-Duo},
  journal={IEEE Access}, 
  title={MCQGen: A Large Language Model-Driven MCQ Generator for Personalized Learning}, 
  year={2024},
  volume={12},
  number={},
  pages={102261-102273},
  abstract={In the dynamic landscape of contemporary education, the evolution of teaching strategies such as blended learning and flipped classrooms has highlighted the need for efficient and effective generation of multiple-choice questions (MCQs). To address this, we introduce MCQGen, a novel generative artificial intelligence framework designed for the automated creation of MCQs. MCQGen uniquely integrates a large language model (LLM) with retrieval-augmented generation and advanced prompt engineering techniques, drawing from an extensive external knowledge base. This integration significantly enhances the ability of the LLM to produce educationally relevant questions that align with both the goals of educators and the diverse learning needs of students. The framework employs innovative prompt engineering, combining chain-of-thought and self-refine prompting techniques, to enhance the performance of the LLM. This process leads to the generation of questions that are not only contextually relevant and challenging but also reflective of common student misconceptions, contributing effectively to personalized learning experiences and enhancing student engagement and understanding. Our extensive evaluations showcase the effectiveness of MCQGen in producing high-quality MCQs for various educational needs and learning styles. The framework demonstrates its potential to significantly reduce the time and expertise required for MCQ creation, marking its practical utility in modern education. In essence, MCQGen offers an innovative and robust solution for the automated generation of MCQs, enhancing personalized learning in the digital era.},
  keywords={Education;Knowledge engineering;Testing;Knowledge based systems;Task analysis;Semantics;Problem-solving;Large language models;Information retrieval;Data augmentation;Large language models;multiple-choice questions;personalized learning;prompt engineering;retrieval-augmented generation},
  doi={10.1109/ACCESS.2024.3420709},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10892891,
  author={Ghimire, Aashish and Pather, James and Edwards, John},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Generative AI in Education: A Study of Educators' Awareness, Sentiments, and Influencing Factors}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research full paper delves into university in-structors' experiences and attitudes toward AI language models, filling a gap in the literature by analyzing educators' perspectives on AI's role in the classroom and its potential impacts on teaching and learning. The rapid advancement of artificial intelligence (AI) and the expanding integration of large language models (LLMs) have ignited a debate about their application in education. The objective of this research is to investigate the level of awareness, overall sentiment towards adoption, and the factors influencing these attitudes for LLMs and generative AI-based tools in higher education. Data was collected through a survey using a Likert scale, which was complemented by follow-up interviews to gain a more nuanced understanding of the instructors' viewpoints. The collected data was processed using statistical and thematic analysis techniques. Our findings reveal that educators are increasingly aware of and generally positive towards these tools. We find no correlation between teaching style and attitude toward generative AI. Finally, while CS educators show far more confidence in their technical understanding of generative AI tools and more positivity towards them than educators in other fields, they show no more confidence in their ability to detect AI-generated work.},
  keywords={Surveys;Training;Uncertainty;Generative AI;Shape;Navigation;Large language models;Education;Artificial intelligence;Interviews;LLM;Chatbot;ChatGPT;AI in Education;Teachers' attitude},
  doi={10.1109/FIE61694.2024.10892891},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10765070,
  author={Liu, Fang and Liu, Zhenwei and Zhao, Qianhui and Jiang, Jing and Zhang, Li and Li, Ge and Sun, Zian and Li, Zhongqi and Ma, Yuchi},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={FastFixer: An Efficient and Effective Approach for Repairing Programming Assignments}, 
  year={2024},
  volume={},
  number={},
  pages={669-680},
  abstract={Providing personalized and timely feedback for student’s programming assignments is useful for programming education. Automated program repair (APR) techniques have been used to fix the bugs in programming assignments, where the Large Language Models (LLMs) based approaches have shown promising results. Given the growing complexity of identifying and fixing bugs in advanced programming assignments, current fine-tuning strategies for APR are inadequate in guiding the LLM to identify bugs and make accurate edits during the generative repair process. Furthermore, the autoregressive decoding approach employed by the LLM could potentially impede the efficiency of the repair, thereby hindering the ability to provide timely feedback. To tackle these challenges, we propose FastFixer, an efficient and effective approach for programming assignment repair. To assist the LLM in accurately identifying and repairing bugs, we first propose a novel repair-oriented fine-tuning strategy, aiming to enhance the LLM’s attention towards learning how to generate the necessary patch and its associated context. Furthermore, to speed up the patch generation, we propose an inference acceleration approach that is specifically tailored for the program repair task. The evaluation results demonstrate that FastFixer obtains an overall improvement of 20.46% in assignment fixing when compared to the state-of-the-art baseline. Considering the repair efficiency, FastFixer achieves a remarkable inference speedup of 16.67× compared to the autoregressive decoding algorithm.CCS CONCEPTS• Software and its engineering; • Computing methodologies → Artificial intelligence;},
  keywords={Large language models;Computer bugs;Software algorithms;Education;Maintenance engineering;Inference algorithms;Software;Decoding;Programming profession;Software engineering;Automated Program Repair;Large Language Models;Programming Education;Inference Acceleration},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{11016317,
  author={Matobobo, Courage and Ncube, Prince Daughin Ngqabutho and Ngesimani, Nomputumo Linah and Dzvapatsva, Godwin Pedzisai and Chinhamo, Edmore},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Enhancing Computational Thinking and Problemsolving in Programming Education Through Generative AI: A Scoped Review}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={This study assesses how generative artificial intelligence tools enhance computational thinking and problemsolving skills in the context of programming education. Generative AI (GenAI) has ushered in a new era in programming education, offering immediate, personalised support through tools like ChatGPT and GitHub Copilot. Although generative AI tools have shown promise in enhancing immediate problem-solving abilities, there is a lack of research on their long-term effects on students' computational thinking and professional programming skills development. This study conducted a scoped evaluation of previously published papers using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) standard, and the data was analysed using a thematic approach. The findings from the study indicate that integrating GenAI can potentially enhance computational thinking and problem-solving for programming students. On the flipside, our study highlighted some significant ethical challenges associated with using GenAI in academia, particularly regarding issues of originality in student work. Contrary to expectations on how GenAI tools enhance learners' decomposition, abstraction, and algorithm design skills, most of the findings concentrated on students' completion of tasks. From a practical perspective, it is evident that GenAI has changed the learning landscape therefore, there is a need from a policy perspective to start thinking about the transformational roles of educators. Future studies should be carried out over a long period and should start by assessing students' levels of problem-solving at a particular age before the immersive use of GenAI and then check the results after the use of these tools.},
  keywords={Measurement;Ethics;Generative AI;Inhibitors;Chatbots;Problem-solving;Programming profession;Standards;Systematic literature review;Software development management;Computational Thinking;Generative Artificial Intelligence;Programming Education;Problem Solving Skills;ChatGPT},
  doi={10.1109/EDUCON62633.2025.11016317},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10349057,
  author={Arista, Artika and Shuib, Liyana and Ismail, Maizatul Akmar},
  booktitle={2023 International Conference on Informatics, Multimedia, Cyber and Informations System (ICIMCIS)}, 
  title={A Glimpse of chatGPT: An Introduction of Features, Challenges, and Threads in Higher Education}, 
  year={2023},
  volume={},
  number={},
  pages={694-698},
  abstract={When used in conjunction with education, ChatGPT is a helpful tool for teaching and understanding fundamental concepts. Students who struggle to find study partners or lack the time to attend tutoring sessions may discover that reviewing and studying with the chatGPT are helpful. Students' access to material and completion of assignments can be accelerated using this technology in research and education. More than one-third of university students who participated in a poll said that they used the ChatGPT for writing assessments. Professors have referred to these technologies as a "threat" and a "plague on education," and ChatGPT has been prohibited from several educational institutions. Thus, this research focuses on the introduction of Features, Challenges, and Threads chatGPT in Higher Education. This study is conducted using the literature review method. According to this research result, this tool can boost student engagement by providing immersive, dynamic, and customized learning environments. However, there are some related issues that need to be considered such as integrity, accuracy and reliability, information bias, and privacy issues. We can therefore infer that there may be benefits as well as drawbacks to employing AI in education that need to be taken into account.},
  keywords={Context;Privacy;Multimedia systems;Instruction sets;Education;Chatbots;Data structures;chatGPT;Features;Challenges;Threads;Higher Education},
  doi={10.1109/ICIMCIS60089.2023.10349057},
  ISSN={2837-5203},
  month={Nov},}@ARTICLE{10993361,
  author={Kuo, Ming-Mu and Li, Xiangfang and Obiomon, Pamela and Qian, Lijun and Dong, Xishuang},
  journal={IEEE Access}, 
  title={Improving Student Learning Outcome Tracing at HBCUs Using Tabular Generative AI and Deep Knowledge Tracing}, 
  year={2025},
  volume={13},
  number={},
  pages={82407-82420},
  abstract={Historically Black Colleges and Universities in the United States serve a vital role in providing educational opportunities and training, particularly for underrepresented students, facing a challenge of lower retention and graduation rates compared to other institutions. To overcome this challenge, this study explores the application of generative artificial intelligence models to generate synthetic data, augmenting real datasets to improve student learning outcome tracing at these colleges and universities using Deep Knowledge Tracing techniques, which potentially offers actionable insights to identify at-risk students and enables proactive interventions to enhance retention and graduation rates in Science, Technology, Engineering and Math education. Utilizing two years of educational data from Prairie View A&M University, it applied data augmentation with tabular generative artificial intelligence models. The experimental results indicate that augmenting training data with synthetic samples generated by these models improved tracing performance measured by AUC and accuracy by approximately 5% and 3%, respectively, underscoring the potential of synthetic data to enhance the monitoring of student learning outcomes in diverse educational contexts. These findings highlight the critical role of data augmentation through generative artificial intelligence in improving the student learning outcome tracing, offering valuable insights for strategies to enhance retention and graduation rates.},
  keywords={Data models;Synthetic data;Predictive models;Accuracy;Generative AI;Numerical models;Education;Training;Knowledge engineering;Adaptation models;Generative AI;student learning outcome tracing;historically black colleges and universities;STEM education},
  doi={10.1109/ACCESS.2025.3568171},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10663028,
  author={AlOmar, Eman Abdullah and Mkaouer, Mohamed Wiem},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Cultivating Software Quality Improvement in the Classroom: An Experience with ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Large Language Models (LLMs), like ChatGPT, have gained widespread popularity and usage in various software engineering tasks, including programming, testing, code review, and program comprehension. However, their effectiveness in improving software quality in the classroom remains uncertain. In this paper, our aim is to shed light on our experience in teaching the use of Programming Mistake Detector (PMD) to cultivate a bugfix culture and leverage LLMs to improve software quality in educational settings. This paper discusses the results of an experiment involving 102 submissions that carried out a code review activity of 1,230 rules. Our quantitative and qualitative analysis reveals that a set of PMD quality issues influences the acceptance or rejection of the issues, and design-related categories that take longer to resolve. Although students acknowledge the potential of using ChatGPT during code review, some skepticism persists. We envision our findings to enable educators to support students with code review strategies to raise students' awareness about LLMs and promote software quality in education.},
  keywords={Codes;Reviews;Large language models;Education;Software quality;Detectors;Chatbots;large language models;education;bugfix;code quality},
  doi={10.1109/CSEET62301.2024.10663028},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10722016,
  author={Mehnen, Lars and Pohn, Birgit},
  booktitle={2024 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)}, 
  title={Supporting Academic Teaching with Integrating AI in Learning Management Systems: Introducing a Toolchain for Students and Lecturers}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Artificial Intelligence (AI) is transforming educational technology by enhancing both teaching and learning processes. This paper examines the “LearnStreamAI” project at Technikum Wien, which integrates an AI-driven chatbot within the Moodle LMS to support real-time student interactions. Utilizing advanced AI technologies like OpenAI’s ChatGPT-4, Google Gemini, and Anthropic Claude3, the chatbot adapts to individual students’ knowledge levels, provides tailored feedback, and enhances engagement through interactive elements in quizzes. Multilingual subtitles using OpenAI’s Whisper technology further improve accessibility for diverse student bodies. In parallel, a toolchain has been developed that automates the creation of academic materials using a PowerShell script and the OpenAI API, based on an easily maintainable Excel input file. This includes generating PowerPoint slides, Moodlecompatible questions, and detailed topic descriptions, all exported into Moodle XML format. The approach ensures accessibility and ease of use for lecturers across various disciplines. The results indicate significant time savings and improved consistency in material preparation. Feedback from pilot studies shows that the AI-generated content is clear, relevant, and well-aligned with academic goals. The system also aids lecturers in quickly acquiring new knowledge by explaining, translating, and summarizing literature. This paper discusses the design, implementation, benefits, and potential improvements of this AI-driven tool, highlighting its role in modern academic teaching and the associated challenges and ethical considerations.},
  keywords={Learning management systems;Ethics;XML;Learning (artificial intelligence);Chatbots;Software;Real-time systems;Telecommunications;Internet;Materials preparation;Artificial Intelligence;Teaching;Learning;ChatGPT},
  doi={10.23919/SoftCOM62040.2024.10722016},
  ISSN={1847-358X},
  month={Sep.},}@INPROCEEDINGS{10527886,
  author={Li, Haoyuan},
  booktitle={2023 3rd International Conference on Computer Science, Electronic Information Engineering and Intelligent Control Technology (CEI)}, 
  title={The Potential of Large Language Models as Tools for Analyzing Student Textual Evaluation: A Differential Analysis Between CS and Non-CS Students}, 
  year={2023},
  volume={},
  number={},
  pages={225-230},
  abstract={Research on the analysis of Student Textual Evaluation encounters ongoing challenges. Large language models, as emerging tools in natural language processing, have garnered extensive attention. This study explores the potential of large-scale language models as tools for analyzing student course evaluations on the Coursera platform and compares Computer Science (CS) and non-Computer Science (non-CS) course reviews to investigate variations in student sentiment and thematic content between these two domains. The study adopts a systematic approach to review and analyze student reviews, identifying common sentiments and patterns, and categorizing reviews into relevant evaluation themes. Additionally, the study assesses inter-annotator agreement to validate the accuracy of manual analyses. Experimental findings reveal a strong correlation between large language models and actual course ratings as well as human-analyzed results, suggesting their potential as tools for assessing student course evaluations. Results from the analysis of CS and non-CS course reviews indicate significant disparities in the distribution of thematic content between these two academic domains.},
  keywords={Computer science;Analytical models;Systematics;Correlation;Reviews;Computational modeling;Natural language processing;Sentiment;Large Language Model;Student Textual Evaluation;Computer Science;Course Reviews},
  doi={10.1109/CEI60616.2023.10527886},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11016446,
  author={Martinez-Romo, Juan and Araujo, Lourdes and Plaza, Laura and López-Ostenero, Fernando},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Generative AI for Education: A Retrieval-Augmented System for Effective Feedback in Self-Assessment}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={The application of generative AI in education has shown significant potential to enhance learning outcomes by providing personalized, adaptive feedback to students. In this work, we present a novel Retrieval-Augmented Generation (RAG) system designed to improve the explanations and feedback provided to students during self-assessment activities. The system we developed is grounded in the course's reference material, ensuring that the feedback remains accurate, consistent, and contextually relevant to the student's curriculum. The system retrieves information directly from the textbook, reducing ambiguity and interpretation errors, and generates responses tailored to the specific needs of each student. The feedback is not only designed to correct misconceptions but also to reinforce key concepts, making the system a valuable tool for self-guided learning. In this study, we also explore the importance of prompt engineering in creating effective AI-generated feedback. We detail the iterative process used to optimize the prompts and the strategies employed to ensure high-quality, interpretable responses. The findings from this work suggest that generative AI, when integrated with subject-specific textbooks and careful prompt engineering, can significantly enhance the educational experience by providing dynamic, and contextually accurate feedback. This approach opens new possibilities for AI-driven education tools, contributing to more personalized and effective learning experiences.},
  keywords={Computer science;Accuracy;Retrieval augmented generation;Prompt engineering;Iterative methods;Engineering education;Self-assessment tools;formative feedback;computer science;generative IA;Retrieval augmented generation},
  doi={10.1109/EDUCON62633.2025.11016446},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11016298,
  author={Naeem, Usman and Styve, Arne and Virkki, Outi T.},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Stimulating Critical Thinking in a Web Programming Module with Generative AI Tools}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Web frameworks have significantly changed how developers create web applications for the Internet. Thanks to pre-defined libraries, these frameworks not only accelerate development time but also reduce the amount of code developers need to write. However, to get the most out of the frameworks and libraries, developers need to have a deep understanding of core web programming languages. This allows them to write efficient code, troubleshoot effectively, and push the boundaries of what the frameworks can achieve. The same principle applies to Generative Artificial Intelligence (AI) tools, as they have the potential to enhance a developer's toolkit. However, they will only be useful if the developer has sound fundamental knowledge to verify the output from these tools. Educators in higher education face a similar predicament with the widespread use of Generative AI tools by learners. Many learners rely on these tools as a go-to solution without being able to verify or fully comprehend the output, leading to shallow understanding. The work in this paper outlines an approach used in a first-year web programming module within the School of Electronic Engineering and Computer Science at Queen Mary University of London, where learners were encouraged to use Generative AI tools to stimulate critical thinking when conducting assessments. Specifically, GitHub CoPilot was used as a pair programmer, and ChatGPT served as a peer reviewer. In this context, the peer reviewer's role was to help the learner reflect on the tool's output. The aim of this study was to explore the design of active learning activities that incorporate Generative AI tools for web programming to foster critical thinking practices among learners. To evaluate our approach, we employed a critical thinking self-evaluation questionnaire instrument, where learners' opinions and customs were surveyed before and after both of the assignments.},
  keywords={Codes;Generative AI;Instruments;Active learning;Chatbots;Libraries;Internet;Programming profession;Faces;Software development management;Generative AI;critical thinking;ChatGPT;GitHub CoPilot;web programming},
  doi={10.1109/EDUCON62633.2025.11016298},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11016571,
  author={Zönnchen, Benedikt and Hobelsberger, Martin and Socher, Gudrun and Thurner, Veronika and Ottinger, Sarah},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Exploring the Role of Large Language Models as Artificial Tutors}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={As large language models (LLMs) become increasingly integrated into learning environments, their potential to enhance or hinder the acquisition of computational skills remains debated. This study investigates the role of generative AI (GenAI) tools, particularly Harvard's CS50 Duck, in supporting programming education. Through a mixed-methods approach, we examine students' perceptions, engagement, and practical application of the CS50 Duck within our Computational Thinking course. Our results indicate that while proficient students use GenAI tools to reinforce problem-solving skills, struggeling students may over-rely on them, potentially bypassing critical learning processes. Survey and assignment data suggest that students value the non-judgmental feedback provided by the CS50 Duck, yet express nuanced views on GenAI's role in formal assessments and programming education. We show that analysing chat histories can serve as a qualitative framework for examining the interactions between students and artificial tutors, while simultaneously offering critical insights into students' learning processes and the challenges they encounter. This study also underscores the need for instructional strategies that guide responsible GenAI use and highlights the importance of educator involvement in integrating these tools effectively.},
  keywords={Surveys;Hands;Generative AI;Large language models;Learning (artificial intelligence);Solids;Problem-solving;History;Engineering education;Programming profession;artificial intelligence;generative artificial intelligence;large language models;computing education;programming courses;artificial tutor},
  doi={10.1109/EDUCON62633.2025.11016571},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10734610,
  author={Chusap, Krerkkiat and Liu, Chang},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={Gauging Tech Community Acceptance of Rapid Prototyping in Unfamiliar Programming Languages using LLM Chatbots}, 
  year={2024},
  volume={},
  number={},
  pages={8-13},
  abstract={Large Language Model (LLM) chatbots such as ChatGPT possess information not only about human languages but also computer languages. It is now possible to perform programming and software design tasks with assistance from ChatGPT. We are particularly interested in how the software development community views the use of LLM chatbots in rapid prototyping using unfamiliar programming languages. In four different tech events, several example scenarios of how a tech-savvy engineer could use ChatGPT to prototype apps in unfamiliar programming languages were demonstrated, including a health education app. The four events include an IEEE chapter workshop, an IEEE WIE (Woman In Engineering) meeting, an IEEE joint chapter talk, and a university-level Computer Science class. The responses from the tech audience showed that the majority perceived value in the use of LLM chatbots in these contexts, even though there were subtle differences among different groups. This shows the need for further research on how to effectively incorporate LLM chatbots into traditional software design workflow to better serve the software development community.CCS CONCEPTS• Software and its engineering → Software design engineering.},
  keywords={Computer languages;Software design;IEEE Chapters;Conferences;Large language models;Chatbots;Rapid prototyping;Software;Programming profession;Software development management;Software Engineering;Software Design;Rapid Prototyping;LLMs;ChatGPT},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10305701,
  author={Wang, Tianjia and Díaz, Daniel Vargas and Brown, Chris and Chen, Yan},
  booktitle={2023 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Exploring the Role of AI Assistants in Computer Science Education: Methods, Implications, and Instructor Perspectives}, 
  year={2023},
  volume={},
  number={},
  pages={92-102},
  abstract={The use of AI assistants, along with the challenges they present, has sparked significant debate within the community of computer science education. While these tools demonstrate the potential to support students' learning and instructors' teaching, they also raise concerns about enabling unethical uses by students. Previous research has suggested various strategies aimed at addressing these issues. However, they concentrate on introductory programming courses and focus on one specific type of problem. The present research evaluated the performance of ChatGPT, a state-of-the-art AI assistant, at solving 187 problems spanning three distinct types that were collected from six undergraduate computer science. The selected courses covered different topics and targeted different program levels. We then explored methods to modify these problems to adapt them to ChatGPT's capabilities to reduce potential misuse by students. Finally, we conducted semi-structured interviews with 11 computer science instructors. The aim was to gather their opinions on our problem modification methods, understand their perspectives on the impact of AI assistants on computer science education, and learn their strategies for adapting their courses to leverage these AI capabilities for educational improvement. The results revealed issues ranging from academic fairness to long-term impact on students' mental models. From our results, we derived design implications and recommended tools to help instructors design and create future course material that could more effectively adapt to AI assistants' capabilities.},
  keywords={Visualization;Shape;Computational modeling;Education;Chatbots;Distance measurement;Computer science education;Computer science education;Large language model;ChatGPT;Interview},
  doi={10.1109/VL-HCC57772.2023.00018},
  ISSN={1943-6106},
  month={Oct},}@INPROCEEDINGS{10448947,
  author={Suryavanshi, Deepali Prakash and Kaveri, Parag Ravikant and Kadlag, Poonam Sachin},
  booktitle={2023 Intelligent Computing and Control for Engineering and Business Systems (ICCEBS)}, 
  title={Advancing Digital Transformation in Indian Higher Education Institutions}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The paper focuses on advancing the use of Digital Transformation in Indian Higher Education Institutions, although India being a developing country it is important for the educational institution to practice transformation in various forms. The paper covers the detail literature study and conclude with various opinions that have been generated through primary data collection. The objective of the study is to identify the need of digital transformation for education environment by two major methods literature study and stakeholder data analysis. Technological expectation was also studied using questionnaires. The study also analyzed related studies that had been done in the past using the Vosviewer programme for the years 1980 to 2004 for Scopus dataset in order to understand the year-by-year publications, research articles, and book chapters in the subject of Digital Transformation in Higher Education. The majority of stakeholders concur that using digital transformation technologies like IoT, AI & ChatGpt, Generative AI, Augmented reality in higher education is essential for implementing NEP 2020 and successfully integrating digital technologies. The paper covers a detail discussion including literature review on various aspects of digital transformation in education institutes. It also covers opinion from various stakeholders to understand actual outcomes expected from the study which was conducted. The current study uses a mixed research methodology because the questionnaire includes both quantitative and qualitative questions. A sample of 40 respondents was collected, representing the four main stakeholders in education: students, faculty, businesspeople, and educationalists. The responses were analysed using the SPSS Percentage and mean. The newly adopted educational policy NEP 2020 encourages the use of technology and skill-based learning. The importance of technology in teaching and learning processes has been emphasized in numerous research papers in order to improve the teaching-learning process and its outcomes. The thorough assessment of the literature was carried out utilizing the VOS viewer to evaluate the pertinent studies and pinpoint any gaps.},
  keywords={Industries;Reviews;Digital transformation;Education;Stakeholders;Object recognition;Standards;Digital Transformation;Data Analysis;Digital revolution;Educational Institution;Technology Adoption;Stakeholders},
  doi={10.1109/ICCEBS58601.2023.10448947},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10260964,
  author={Fantechi, Alessandro and Gnesi, Stefania and Passaro, Lucia and Semini, Laura},
  booktitle={2023 IEEE 31st International Requirements Engineering Conference (RE)}, 
  title={Inconsistency Detection in Natural Language Requirements using ChatGPT: a Preliminary Evaluation}, 
  year={2023},
  volume={},
  number={},
  pages={335-340},
  abstract={With the rapid advancement of tools based on Artificial Intelligence, it is interesting to assess their usefulness in requirements engineering. In early experiments, we have seen that ChatGPT can detect inconsistency defects in natural language (NL) requirements, that traditional NLP tools cannot identify or can identify with difficulties even after domain-focused training. This study is devoted to specifically measuring the performance of ChatGPT in finding inconsistency in requirements. Positive results in this respect could lead to the use of ChatGPT to complement existing requirements analysis tools to automatically detect this important quality criterion. For this purpose, we consider GPT-3.5, the Generative Pretrained Transformer language model developed by OpenAI. We evaluate its ability to detect inconsistency by comparing its predictions with those obtained from expert judgments by students with a proven knowledge of RE issues on a few example requirements documents.},
  keywords={Training;Codes;Natural languages;Refining;Manuals;Chatbots;Transformers;ChatGPT;Natural Language Requirements;Inconsistency Detection},
  doi={10.1109/RE57278.2023.00045},
  ISSN={2332-6441},
  month={Sep.},}@INPROCEEDINGS{10772819,
  author={Farkas, Imre and Kovari, Attila and Rajcsanyi-Molnar, Mónika},
  booktitle={2024 IEEE 7th International Conference and Workshop Óbuda on Electrical and Power Engineering (CANDO-EPE)}, 
  title={The Emergence of Artificial Intelligence in Education and its Impact on Individual Literacy in Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={83-88},
  abstract={In the last three years, a new partner has emerged for teachers and educators in the field of education. The mushrooming of applications based on large language models has greatly shaped the educational development fields of the present era. The use of various AI applications has become commonplace among students and teachers alike. Many questions are being raised by researchers in this field. What does the rapid development of AI applications bring to the field of pedagogy? Should the products of such applications be compared with human performance? The form presented in this thesis seeks to answer similar questions. What is the impact of frequent use of these applications on the literacy level of individuals? In which areas do students tend to use these applications? The results indicate that half of the students believe their literacy levels will decrease with the mass emergence of AI applications, while 36% feel it will not change. However, 88 % of students have already dealt with AI-based applications, with 64 % using them several times or more, suggesting a high level of integration into their educational processes.},
  keywords={Ethics;Power engineering;Large language models;Education;Collaboration;Learning (artificial intelligence);Reliability;Artificial intelligence;Monitoring;Guidelines;artificial intelligence;literacy;LLM;artificial intelligence hallucination},
  doi={10.1109/CANDO-EPE65072.2024.10772819},
  ISSN={2831-4506},
  month={Oct},}@INPROCEEDINGS{10743009,
  author={Astudillo, Gabriel and Ponce, Victor},
  booktitle={2024 11th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={Hybrid Platforms for IoT in the Classroom – A Competency Analysis and Performance Evaluation}, 
  year={2024},
  volume={},
  number={},
  pages={104-108},
  abstract={The Internet of Things (IoT) has been increasingly deployed in the last decade. It can now integrate faster new technologies such as Large Language Models (LLMs) into the IoT layers. IoT applications, frameworks, and tools are becoming accessible through on-premises implementations or using cloud providers such as Amazon Web Services (AWS). As a result, IoT is a mature approach to support computer science (CS) education. This paper presents how IoT is applied to College education to achieve CS competencies in Quebec, Canada. We present our experience in IoT teaching with on-premises and cloud deployments and describe a performance assessment framework for IoT platforms to simplify their selection process. Specifically, it examines the scalability (measured by throughput and average response time) of the ThingsBoard and AWS IoT Core platforms. Our findings show that a hybrid infrastructure that combines the best features of both platforms is the best suited solution for the proposed learning scenario.},
  keywords={Cloud computing;Protocols;Web services;Scalability;Education;Throughput;Time measurement;Internet of Things;Time factors;Programming profession;CS education;Internet of Things;learning;performance;evaluation},
  doi={10.1109/FiCloud62933.2024.00024},
  ISSN={2996-1017},
  month={Aug},}@INPROCEEDINGS{10773849,
  author={Wray, Tom and Wang, Ying},
  booktitle={MILCOM 2024 - 2024 IEEE Military Communications Conference (MILCOM)}, 
  title={5G Specifications Formal Verification with Over-the-Air Validation: Prompting is All You Need}, 
  year={2024},
  volume={},
  number={},
  pages={412-418},
  abstract={The critical role of 5G and other complex systems in infrastructure necessitates rigorous protocol verification and system validation to ensure security and reliability. This paper explores the application of applying Large Language Model enabled auto Formal Verification with Real-world Prompting on Large Language Models (LLMs) for 5G and NextG protocols, addressing ambiguities and security concerns in network infrastructure protocol and specification design. By leveraging generative transformer-based LLMs, we present a formal approach to prompt engineering that validates complex specifications and implements formal verification techniques to detect and eliminate hallucinations. Our approach is agnostic to specific LLMs, with performance comparisons across currently popular models. We thoroughly examine the human processes involved to identify entry points where Prompt Engineering can reduce process overhead. We have developed a novel framework for iterative prompting and self-monitoring to aid in formal verification using 5G reasoner, enabling closed-loop automatic 5G protocol verification. Focusing on the RRC layer of 5G release 17, specifically sections 5.3.3.3, 5.3.3.4, and 5.3.5.3, we examined the liveness properties and detected a total of seven vulnerabilities, including variations of Null Cipher, Denial of Service (DoS), Lullaby, and Incarceration attacks. Further, we established a general testing framework that spans conception, virtualization, and over-the-air testing, providing a holistic approach to security assessment. This comprehensive framework underscores the importance of robust protocol verification and system validation in the deployment of critical infrastructure technologies.},
  keywords={Protocols;5G mobile communication;Wireless networks;Security;Reliability;Prompt engineering;System validation;Virtualization;Formal verification;Testing;5G;Artificial Intelligence;Prompt Engineering;Large Language Models;Security},
  doi={10.1109/MILCOM61039.2024.10773849},
  ISSN={2155-7586},
  month={Oct},}@INPROCEEDINGS{10764812,
  author={Yu, Xiao and Zhang, Zexian and Niu, Feifei and Hu, Xing and Xia, Xin and Grundy, John},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={What Makes a High-Quality Training Dataset for Large Language Models: A Practitioners’ Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={656-668},
  abstract={Large Language Models (LLMs) have demonstrated remarkable performance in various application domains, largely due to their self-supervised pre-training on extensive high-quality text datasets. However, despite the importance of constructing such datasets, many leading LLMs lack documentation of their dataset construction and training procedures, leaving LLM practitioners with a limited understanding of what makes a high-quality training dataset for LLMs. To fill this gap, we initially identified 18 characteristics of high-quality LLM training datasets, as well as 10 potential data pre-processing methods and 6 data quality assessment methods, through detailed interviews with 13 experienced LLM professionals. We then surveyed 219 LLM practitioners from 23 countries across 5 continents. We asked our survey respondents to rate the importance of these characteristics, provide a rationale for their ratings, specify the key data pre-processing and data quality assessment methods they used, and highlight the challenges encountered during these processes. From our analysis, we identified 13 crucial characteristics of high-quality LLM datasets that receive a high rating, accompanied by key rationale provided by respondents. We also identified some widely-used data pre-processing and data quality assessment methods, along with 7 challenges encountered during these processes. Based on our findings, we discuss the implications for researchers and practitioners aiming to construct high-quality training datasets for optimizing LLMs.CCS CONCEPTS• Software and its engineering → Software implementation planning.},
  keywords={Training;Surveys;Data integrity;Large language models;Documentation;Software;Planning;Continents;Interviews;Software engineering;Large Language Models;High-Quality Data;Practitioners’ Perspective;Empirical Study},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{10578646,
  author={Vishnumolakala, Sai Krishna and C, Sobin C and Subheesh, N P and Kumar, Prabhat and Kumar, Randhir},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={AI-Based Research Companion (ARC): An Innovative Tool for Fostering Research Activities in Undergraduate Engineering Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The engineering education today emphasizes the need to combine book learning with real-world application. However, much of the research done by undergraduates, which could be very valuable, is scattered and not fully used. To address this, a new tool called “AI-based Research Companion (ARC)” has been developed. ARC leverages advanced Generative AI technology, including GPT-4, to systematically organize, enhance, and offer personalized recommendations for undergraduate research projects. This platform is more than a simple tool; it aims to inspire undergraduates to dive into research by making the process approachable and engaging, thus increasing participation in research activities. Initial assessments of ARC have revealed an encouraging rise in student engagement with research, indicating a shift towards more research-oriented projects. The integration of GPT-4 within ARC stands out significantly; it precisely addresses the detailed demands of undergraduate research by providing a tailored, intelligent exploration pathway. By incorporating GPT-4's advanced features with a user-centric design, ARC emerges as an innovative platform, emphasizing the pivotal role of Generative AI in enhancing and expanding undergraduate research initiatives.},
  keywords={Technological innovation;Generative AI;Information age;Research initiatives;Engineering education;Testing;AI-based Research Companion (ARC);Dynamic recommendations;Engineering education;Generative AI;GPT-4;Undergraduate research},
  doi={10.1109/EDUCON60312.2024.10578646},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10317226,
  author={Tan, Chi Wee and Lim, Khai Yin},
  booktitle={2023 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
  title={Revolutionizing Formative Assessment in STEM Fields: Leveraging AI and NLP Techniques}, 
  year={2023},
  volume={},
  number={},
  pages={1357-1364},
  abstract={Artificial intelligence (AI) has been extensively studied in science, technology, engineering, and mathematics (STEM), but there is a disparity between AI-generated and human-written scientific content. To bridge this gap, a prototype utilizing Natural Language Processing (NLP) techniques and a large language model (LLM) generates assessment questions and evaluates student answers. This formative assessment system offers a user-friendly and scalable solution for higher education educators. It tailors’ assessments to individual students, accommodates varying capabilities, and facilitates performance analysis. Through rigorous evaluation and benchmarking, the prototype ensures alignment with High-Level Performance (HLP) standards. This AI-assisted formative assessment system enhances efficiency and efficacy by providing accurate and timely feedback. It has the potential to significantly improve STEM education through scalable and personalized formative assessment experiences. AI and NLP enable educators to access tailored assessment options, enhancing learning outcomes and the overall educational experience.},
  keywords={Training;Scalability;Education;Prototypes;Optimized production technology;Natural language processing;Time factors},
  doi={10.1109/APSIPAASC58517.2023.10317226},
  ISSN={2640-0103},
  month={Oct},}@INPROCEEDINGS{10487465,
  author={Taylor, Zachary and Blair, Cy and Glenn, Ethan and Devine, Thomas Ryan},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={Plagiarism in Entry-Level Computer Science Courses Using ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={1135-1139},
  abstract={Recent advances in AI-generated code could potentially be plagiarized by students in entry-level programming courses. This paper examines the use of ChatGPT for generating code to solve a programming project for an entry-level computer science course. We analyzed 59 anonymized student samples along with 75 regular generations of ChatGPT code and 75 samples of ChatGPT code prompted directly for obfuscation. Results showed that 44% of ChatGPT-generated code did not compile in three or fewer manual fixes. Additionally, plagiarism detection software was not easily able to flag AI-generated code. However, the results showed that AI -generated code was more dissimilar in comparison to student-generated code, which could potentially aid in automated detection.},
  keywords={Codes;Plagiarism;Manuals;Programming;Syntactics;Chatbots;Software;ChatGPT;AI;Plagiarism Detection},
  doi={10.1109/CSCE60160.2023.00189},
  ISSN={},
  month={July},}@INPROCEEDINGS{10125121,
  author={Qadir, Junaid},
  booktitle={2023 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Engineering Education in the Era of ChatGPT: Promise and Pitfalls of Generative AI for Education}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={Engineering education is constantly evolving to keep up with the latest technological developments and meet the changing needs of the engineering industry. One promising development in this field is the use of generative artificial intelligence technology, such as the ChatGPT conversational agent. ChatGPT has the potential to offer personalized and effective learning experiences by providing students with customized feedback and explanations, as well as creating realistic virtual simulations for hands-on learning. However, it is important to also consider the limitations of this technology. ChatGPT and other generative AI systems are only as good as their training data and may perpetuate biases or even generate and spread misinformation. Additionally, the use of generative AI in education raises ethical concerns such as the potential for unethical or dishonest use by students and the potential unemployment of humans who are made redundant by technology. While the current state of generative AI technology represented by ChatGPT is impressive but flawed, it is only a preview of what is to come. It is important for engineering educators to understand the implications of this technology and study how to adapt the engineering education ecosystem to ensure that the next generation of engineers can take advantage of the benefits offered by generative AI while minimizing any negative consequences.},
  keywords={Training;Productivity;Biological system modeling;Training data;Chatbots;Artificial intelligence;Engineering education;Generative AI;ChatGPT;Engineering Education},
  doi={10.1109/EDUCON54358.2023.10125121},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{11016616,
  author={Elhayany, Mohamed and Meinel, Christoph},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Empowering Educators: Towards a GPT-Based Approach to Automate Unit Test Generation}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Assessing code automatically is a significant challenge in distance learning, especially in large online courses with limited teaching resources. Although auto-gradable programming exercises address scalability, creating enough high-quality exer-cises-particularly designing comprehensive unit tests-remains time-consuming and labor-intensive. To address this, we introduce a GPT-based feature that automates unit test generation for customized exercises. With a single button press, instructors can adapt existing exercises to meet specific teaching objectives while preserving auto-gradability. The AI-generated tests comprehensively cover potential edge cases that might otherwise be overlooked, thus reducing the need for manual oversight. An empirical evaluation with eight experienced educators showed these tests to be both thorough and time-efficient, achieving an average System Usability Scale (SUS) score of 81.79. Participants, who reported intermediate to advanced proficiency in designing manual unit tests and intermediate familiarity with AI tools like ChatGPT, praised the feature's ease of use and seamless workflow integration. Their combined expertise in teaching, coding, and AI-informed course development allowed them to provide insightful feedback on the practicality and reliability of our GPT-based solution. Our study includes a small participant pool ($\mathrm{n}=8$) and primarily focuses on Python, a language wellsupported by GPT. Future research will involve expanding the participant group, exploring additional programming languages, and assessing long-term tool performance and adaptability in diverse educational contexts. By harnessing GPT's language modeling capabilities, our approach addresses the gap between generic, limited-coverage test generation and the need for robust, domain-specific tests. Early reports from participants suggest that specialized exercises-such as those involving advanced data structures-can also benefit from automated unit test generation, though further evaluation is necessary. By leveraging artificial intelligence, this method streamlines exercise customization and enhances the overall usability and effectiveness of programming education tools. It has the potential to revolutionize auto-gradable exercise creation at scale, empowering educators to deliver high-quality instruction while tackling both the technical and pedagogical challenges in programming education.},
  keywords={Technological innovation;Codes;Education;User centered design;Manuals;Test pattern generators;Artificial intelligence;Usability;Programming profession;Testing;Unit testing;Programming Education;GPT-4omini;System Usability},
  doi={10.1109/EDUCON62633.2025.11016616},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10810629,
  author={Niranon, Panuwat and Triyason, Tuul},
  booktitle={2024 8th International Conference on Information Technology (InCIT)}, 
  title={The Efficiency of ChatGPT Vs Google Against Self-Learning of Undergraduate Students}, 
  year={2024},
  volume={},
  number={},
  pages={382-386},
  abstract={ChatGPT has sparked excitement across various domains, especially in education. It has been applied in various contexts such as homework assignments and essay writing, igniting both excitement and curiosity, particularly regarding ChatGPT's effectiveness in self-learning methods. This study aims to compare the effectiveness of ChatGPT and Google Search in self-learning among undergraduate students. The sample groups consisted of 20 English language students and 20 physical education students, totaling 40 participants selected through Purposive Sampling and Randomized Controlled Trial (RCT). They were divided into two groups: Group A using ChatGPT and Group B using Google Search for self-learning on predetermined topics. The research instrument is a skill training sets for using ChatGPT and Google Search for self-learning on ethics and laws related to information use. The study found that overall, ChatGPT had an average score higher than the sample group using Google Search.},
  keywords={Training;Ethics;Electronic learning;Reviews;Instruments;Games;Chatbots;Internet;Grammar;Information technology;ChatGPT;Self-learning;Undergraduate students},
  doi={10.1109/InCIT63192.2024.10810629},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10811263,
  author={Andročec, Darko},
  booktitle={2024 5th International Conference on Communications, Information, Electronic and Energy Systems (CIEES)}, 
  title={Using Large Language Models for Students’ Essays Plagiarism Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Large language models are used and fine-tuned today for different tasks. In educational environment, one problematic usage of this technology is for creation of plagiarism work. The focus of this work is to use large language models to detect plagiarised student essays. The recent relevant Kaggle competition "Detect AI Generated Text" is analysed. The top most accurate solutions in this competition used the ensembles of various large language models. In the efficiency track of the competition, winning solutions used more classical machine learning methods. We also analyse the main datasets used to finetune the LLM and machine learning models for students’ essays plagiarism detection. The most accurate models use comprehensive set of essay data and ensemble of different large language models.},
  keywords={Accuracy;Codes;Plagiarism;Large language models;Computational modeling;Machine learning;Data models;Hardware;Servers;Interoperability;plagiarism detection;large language models;machine learning;AI-generated text},
  doi={10.1109/CIEES62939.2024.10811263},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10672225,
  author={Yuan, Yuan and Xu, Haoyang and Si, Liming},
  booktitle={2024 International Conference on Microwave and Millimeter Wave Technology (ICMMT)}, 
  title={ChatGPT as an Artificial Intelligence (AI) Tool for Assisting Undergraduate Talent Cultivation Program in Major of Microelectronic Science and Engineering}, 
  year={2024},
  volume={1},
  number={},
  pages={1-3},
  abstract={As one of the important higher education universities in China, Beijing Institute of Technology (BIT) takes a significant responsibility in cultivating students in the field of integrated circuits. This paper takes the School of Integrated Circuits and Electronics at BIT as an example to delve into the application of the artificial intelligence (AI) tool ChatGPT in undergraduate talent cultivation programs in Microelectronic Science and Engineering. ChatGPT should provide many advantages, including personalized learning assistance, problem-solving guidance, and extensive knowledge resources. By using the capabilities of ChatGPT, teachers and educators can improve student engagement, promote understanding of complex concepts, and help students for career planning in the major of microelectronics. The results indicate that integrating ChatGPT into undergraduate cultivation programs offers valuable insights into the future of engineering education.},
  keywords={Pediatrics;Microwave integrated circuits;Plagiarism;Millimeter wave technology;Chatbots;Microelectronics;Planning},
  doi={10.1109/ICMMT61774.2024.10672225},
  ISSN={2994-3124},
  month={May},}@INPROCEEDINGS{10852455,
  author={Michelutti, Chiara and Eckert, Jens and Monecke, Milko and Klein, Julian and Glesner, Sabine},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={A Systematic Study on the Potentials and Limitations of LLM-assisted Software Development}, 
  year={2024},
  volume={},
  number={},
  pages={330-338},
  abstract={In the field of software engineering, Large Language Models like GPT have gained enormous interest in recent times. With its expanding area of application, ChatGPT has become an essential tool for code generation. Several studies have shown that the quality of generated code depends on the underlying dataset and the quality of the provided prompts. However, its precise capabilities and limitations remain uncertain, as does the extent of assistance required for effective code generation. We present the results of our systematic study in which we investigate the potential of ChatGPT, based on GPT-4, in solving assignments of an introductory-level programming class. We examine the impact of programming language choice, different prompting strategies, and the results of the model compared to those of real students. Our results show that ChatGPT cannot solve the assignments independently, but outperforms the average student with human assistance.},
  keywords={Computer languages;Java;Sequential analysis;Codes;Systematics;Large language models;Chatbots;Testing;Software engineering;Software development management;Large Language Models;Software Development;ChatGPT;Code Generation;Haskell;Java;Functional Programming;Object Oriented Programming;Prompt Engineering},
  doi={10.1109/FLLM63129.2024.10852455},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10469472,
  author={R, Prasanna Kumar and M, Rithani and G, Bharathi Mohan and R, Venkatakrishnan},
  booktitle={2024 Fourth International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT)}, 
  title={Empirical Evaluation of Large Language Models in Resume Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={The study’s primary objective is to investigate the effectiveness of Large Language Models (LLMs) in the specialized field of resume classification, a critical aspect of talent acquisition and human resource management. The research aims to overcome the limitations of conventional approaches that often rely on basic Natural Language Processing (NLP) techniques by introducing a more efficient alternative through the utilization of LLMs. In pursuit of this goal, a comprehensive empirical assessment was undertaken, encompassing multiple LLMs, including various iterations of Text Davinci and GPT models. The research methodology employed was rigorous, incorporating data preprocessing and text normalization techniques to ensure the robustness and credibility of the results. The study’s outcomes include a comparative analysis of the chosen LLMs, with a focus on essential performance metrics such as accuracy, precision, recall, and the F1-Score. The results obtained from this analysis demonstrate a significant enhancement in the performance of LLMs compared to traditional methods in the context of resume classification. In conclusion, this research provides invaluable insights into the applicability and effectiveness of LLMs within the realm of resume classification. It not only addresses existing limitations but also serves as a foundational work that paves the way for future research in this domain. Moreover, it underscores the transformative potential of LLMs in reshaping the landscape of talent acquisition and human resource management processes.},
  keywords={Measurement;Knowledge engineering;Electric potential;Computational modeling;Data preprocessing;Natural language processing;Robustness;Large Language Models;Resume Classification;Talent Acquisition;Text Davinci;GPT Models},
  doi={10.1109/ICAECT60202.2024.10469472},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10814750,
  author={Wightman, Pedro},
  booktitle={2024 IEEE Latin American Conference on Computational Intelligence (LA-CCI)}, 
  title={Twisted Games: A First Experience of Inclusion of AI tools in First Year Programming Classes}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The recent rapid advancements in Large Language Models (LLMs) and the increasing availability of AI-powered tools have underscored the need for the current generation of programmers to learn how to effectively collaborate with AI from the early stages of their university education. This paper explores the integration of AI tools into a first-year programming course through the implementation of modified classic games (4 in a row with L-shapes, 3-player Battleship, etc.). The primary objective of this study was to assess the impact of AI assistance on students’ ability to define and adapt requirements for novel software applications, while also fostering an understanding of the power and limitations of AI in the classroom. The results reveal a positive student experience, with participants reporting increased confidence in utilizing AI tools for requirements elicitation and recognizing the potential benefits for their future careers. In addition, it highlighted the need to train students in developing skills for requirement identification, prompt creation, and testing and debugging the code.},
  keywords={Codes;Education;Layout;Debugging;Games;Encoding;Software;Artificial intelligence;Programming profession;Testing;Artificial intelligence;Large Language Models;Software development;Game development},
  doi={10.1109/LA-CCI62337.2024.10814750},
  ISSN={2769-7622},
  month={Nov},}@INPROCEEDINGS{11016469,
  author={Haider, Sami Ahmed and Ahmad, Khwaja Mutahir and Akbar, Jehan and Soni, Mukesh and Keshta, Ismail and AlGhamdi, Azzah and Shahzadi, Hafiza Mahrukh},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Generative AI as a Catalyst for Transforming Transnational Engineering Education: Opportunities, Challenges, and Future Directions}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Generative Artificial Intelligence (GAI) is emerging as a transformative force that empowers transnational education (TNE) in engineering. Recent trends indicate a significant shift in the application of generative AI in engineering policies, academic research, business practices, and educational settings throughout TNE. Governments and organizations are transitioning from restrictive stances to developing guiding frameworks for its application, enabling cross-border collaboration in TNE. Numerous universities have permitted and even promoted the utilization of GAI. Furthermore, academic research around the world is looking into the pros and cons of GAI in engineering education, focusing on how it can help teachers and keep students interested. Industrial applications are diversifying, extending across disciplines, and TNE is occurring in engineering contexts, including cross-border programs. GAI possesses the capacity to transform TNE by revolutionizing talent development, reformulating engineering models, and facilitating scientific assessment across multinational frameworks. However, problems like the generative illusion, ethical and ideological risks, lack of trust between teachers and students, and new threats to TNE in engineering equity in global settings require substantial focus. This study examines these concerns and outlines potential strategies to leverage GAI for transnational education in engineering, offering stakeholders the opportunity to prioritize AI literacy among educators and learners. This work emphasizes that cross-disciplinary and collaborative R&D, following national and international standards, should tackle application hurdles while guaranteeing safety and inclusion. This study also addresses several future directions that can contribute to creating a unified framework and cost-effective solutions. These solutions, integrated with platforms like the National Smart Education Platform, can bridge digital divides, ensuring equitable access and enabling global TNE stakeholders to capitalize on the GAI revolution. We also provide several statistics and case studies to show the effectiveness of GAI over TNE in engineering and provide practical solutions for the incorporation of GAI into TNE within engineering frameworks, guaranteeing inclusivity and equity.},
  keywords={Ethics;Generative AI;Catalysts;Collaboration;Transforms;Market research;Safety;Stakeholders;Engineering education;Research and development;Transnational Education;Generative AI;ChatGPT;Technological Factors;Intelligent Computing;Artificial Intelligence},
  doi={10.1109/EDUCON62633.2025.11016469},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10765410,
  author={Gao, Hong and Huai, Haochuan and Yildiz-Degirmenci, Sena and Bannert, Maria and Kasneci, Enkelejda},
  booktitle={2024 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, 
  title={DataliVR: Transformation of Data Literacy Education through Virtual Reality with ChatGPT-Powered Enhancements}, 
  year={2024},
  volume={},
  number={},
  pages={120-129},
  abstract={Data literacy is essential in today’s data-driven world, emphasizing individuals’ abilities to effectively manage data and extract meaningful insights. However, traditional classroom-based educational approaches often struggle to fully address the multifaceted nature of data literacy. As education undergoes digital transformation, innovative technologies such as Virtual Reality (VR) offer promising avenues for immersive and engaging learning experiences. This paper introduces DataliVR, a pioneering VR application aimed at enhancing the data literacy skills of university students within a contextual and gamified virtual learning environment. By integrating Large Language Models (LLMs) like ChatGPT as a conversational artificial intelligence (AI) chatbot embodied within a virtual avatar, DataliVR provides personalized learning assistance, enriching user learning experiences. Our study employed an experimental approach, with chatbot availability as the independent variable, analyzing learning experiences and outcomes as dependent variables with a sample of thirty participants. Our approach underscores the effectiveness and user-friendliness of ChatGPT-powered DataliVR in fostering data literacy skills. Moreover, our study examines the impact of the ChatGPT-based AI chatbot on users’ learning, revealing significant effects on both learning experiences and outcomes. Our study presents a robust tool for fostering data literacy skills, contributing significantly to the digital advancement of data literacy education through cutting-edge VR and AI technologies. Moreover, our research provides valuable insights and implications for future research endeavors aiming to integrate LLMs (e.g., ChatGPT) into educational VR platforms.},
  keywords={Electronic learning;Digital transformation;Large language models;Education;Data visualization;Learning (artificial intelligence);Data collection;Chatbots;User experience;Data mining;Virtual reality;data literacy;LLMs;ChatGPT;digital transformation;immersive learning},
  doi={10.1109/ISMAR62088.2024.00026},
  ISSN={2473-0726},
  month={Oct},}@INPROCEEDINGS{10578883,
  author={Pérez-Colado, Iván J. and Freire-Morán, Manuel and Calvo-Morata, Antonio and Pérez-Colado, Víctor M. and Fernández-Manjón, Baltasar},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={AI Asyet Another Tool in Undergraduate Student Projects: Preliminary Results}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={How do students use artificial intelligence tools in coursework projects when given the liberty to do so, with the only requirement of documenting how, where and why? We describe experiences with two groups of undergraduates in courses related to serious game authoring and human-computer interaction, both carried out in the second semester of 2023. In the serious games course, students were given the option of following a teacher-developed methodology for generating graphical assets for their serious games using a set of generative AI tools. This methodology was explained in the class but not hands on lab was carried out. In the interaction course, students were free to choose which AI tools to use when designing their system or in the development of their project documentation. Despite the limited number of participants (41 in total) we can see very different views and degrees of involvement: while some tried to use AI for as many tasks as possible, others considered that the learning curve for those tools was too steep to be worthwhile. Both experiences included a free-text survey at the end, and taken together, provide insights into how both supervised and unsupervised generative AI use could impact undergraduate projects in similar subjects. In addition to describing how students chose to use the tools, and the main takeaways from their survey response, we also discuss some of the ethical aspects about the access to the tools and what should be the minimal conditions to be met to allow the equitable use of AI in the classroom.},
  keywords={Surveys;Human computer interaction;Generative AI;Games;Documentation;Task analysis;Engineering education;AI in education;generative artificial intelligence;game development;serious games authoring;goal-driven design},
  doi={10.1109/EDUCON60312.2024.10578883},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{11016382,
  author={Chen, Yue and Chai, Kok Keong and Loo, Jonathan and Moosaei, Reza and Obstfeld, Joel},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={GenAI-Empowered Group-Based Authentic Assessment for Network Engineering Courses}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The emergence of generative artificial intelligence (GenAI) has brought both challenges and opportunities for education. In this paper, we propose a GenAI-empowered, group-based authentic assessment for a Network Engineering course. This group assignment promotes challenge-based learning (CBL) and leverages GenAI to enhance students' creativity, critical thinking, collaboration, and technical problem-solving skills, while also improving students' GenAI literacy through fostering their ability to effectively engage with GenAI tools. The authenticity of this assignment is reflected in two folds: 1) students engage in a real-world engineering challenge, roleplaying as network engineers, and 2) they develop essential skills for co-creating solutions using GenAI tools, a key competency for future engineers. The group assignment is structured into five stages, each aligned with Bloom's Taxonomy to progressively develop cognitive skills from understanding foundational knowledge to synthesis, evaluation, and creation. To mitigate challenges such as overreliance on GenAI tools and varying levels of digital literacy, we provide guidance on the responsible and ethical use of GenAI, design reflective assessment tasks with constructive feedback, and establish clear marking criteria that emphasise both the learning process and the final outputs of the assignment. Initial evaluation and feedback from trials have highlighted the effectiveness of using GenAI tools in addressing complex engineering challenges and the value of collaborating in a real-world engineering context. This innovative approach demonstrates the potential of GenAIempowered authentic assessments to enhance learning experiences in technical fields like Network Engineering.},
  keywords={Ethics;Generative AI;Taxonomy;Documentation;Data collection;Teamwork;Problem-solving;Digital intelligence;Engineering education;Creativity;GenAI;Authentic Assessment;ChallengedBased Learning;Group-Based Learning;Network Engineering},
  doi={10.1109/EDUCON62633.2025.11016382},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11016572,
  author={Lindsay, Euan D and Zhang, Mike and Johri, Aditya and Bjerva, Johannes},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={The Responsible Development of Automated Student Feedback with Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Providing rich, constructive feedback to students is essential for supporting and enhancing their learning. Recent advancements in Generative Artificial Intelligence (AI), particularly with large language models (LLMs), present new opportunities to deliver scalable, repeatable, and instant feedback, effectively making abundant a resource that has historically been scarce and costly. From a technical perspective, this approach is now feasible due to breakthroughs in AI and Natural Language Processing (NLP). While the potential educational benefits are compelling, implementing these technologies also introduces a host of ethical considerations that must be thoughtfully addressed. One of the core advantages of AI systems is their ability to automate routine and mundane tasks, potentially freeing up human educators for more nuanced work. However, the ease of automation risks a “tyranny of the majority”, where the diverse needs of minority or unique learners are overlooked, as they may be harder to systematize and less straightforward to accommodate. Ensuring inclusivity and equity in AI-generated feedback, therefore, becomes a critical aspect of responsible AI implementation in education. The process of developing machine learning models that produce valuable, personalized, and authentic feedback also requires significant input from human domain experts. Decisions around whose expertise is incorporated, how it is captured, and when it is applied have profound implications for the relevance and quality of the resulting feedback. Additionally, the maintenance and continuous refinement of these models are necessary to adapt feedback to evolving contextual, theoretical, and student-related factors. Without ongoing adaptation, feedback risks becoming obsolete or mismatched with the current needs of diverse student populations. Addressing these challenges is essential not only for ethical integrity but also for building the operational trust needed to integrate AI-driven systems as valuable tools in contemporary education. Thoughtful planning and deliberate choices are needed to ensure that these solutions truly benefit all students, allowing AI to support an inclusive and dynamic learning environment.},
  keywords={Ethics;Automation;Generative AI;Navigation;Machine learning;Turning;Planning;Maintenance;Artificial intelligence;Lenses;Educational Technology;Artificial Intelligence;Ethics;Natural Language Processing;Human-Computer Interaction;Generative AI},
  doi={10.1109/EDUCON62633.2025.11016572},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10665196,
  author={Kumar, Yulia and Manikandan, Anjana and Kupershtein, Ethan and Li, J. Jenny and Morreale, Patricia},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Assessing the Impact of Professional Development on K-12 CS Education: A One-Year Follow-Up Survey Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The paper presents the findings from a one-year follow-up survey analyzing the impact of a targeted professional development (PD) program conducted by a state Computer Science (CS) hub on K-12 CS education. It scrutinizes the long-term effects of the PD initiative on educators' pedagogical strategies and students' readiness for college-level CS coursework. The study focuses on integrating the introductory course CS0, which shapes educational strategies and outcomes. Through the lens of three research questions, the analysis delves into the enhancements in educators' instructional approaches following PD, the ongoing influence of PD on the integration of interdisciplinary methods within CS curricula, and the correlation between PD and student engagement and achievement in CS disciplines. The survey of thirty educators reveals a sustained implementation of acquired pedagogical practices and a positive influence on student college readiness in CS. Moreover, the study underscores the pivotal role of PD in elevating educators’ proficiency in delivering advanced CS concepts, ultimately benefiting student learning trajectories. The concluding remarks advocate including Large Language Models (LLMs) as a supplementary tool to enrich the CS educational paradigm. The recommendations provided serve as a strategic roadmap for stakeholders aiming to elevate the standard of CS education through PD and curricular development.},
  keywords={Surveys;Computer science;Shape;Large language models;Education;Trajectory;Stakeholders;computer science education;curriculum development;educator professional development;pedagogical strategies},
  doi={10.1109/ISEC61299.2024.10665196},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{10834357,
  author={Tang, Shan and Lei, Chi-Un and Wang, Hongren},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Revealing Vocational Training on Achieving UN’s Sustainable Development Goals: Analysis Through Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Vocational training plays a crucial role in supporting the achievement of the United Nations Sustainable Development Goals (SDGs), outlined explicitly in SDG Targets 4.3, 4.4, and 4.5. However, there is a lack of comprehensive studies examining the teaching of knowledge in state-level vocational training programs to support the attainment of SDGs. The primary objective of this study is to investigate the connection between SDG education and vocational training. To achieve this, we analyzed the curricula of i) four vocational training courses and ii) three applied technological and applied studies courses adopted by the government of New South Wales in Australia. The classification was based on a public training dataset from OSDG and subject descriptions via logistic regression (LR) and a generative pre-trained transformer (GPT) model. The findings from the subject-level analysis demonstrate the effectiveness of the adopted approach. Across all curricula, SDG 9 is the most prominently incorporated SDG. However, policymakers should be aware of the limited SDG representation related to social equality in vocational training. To evaluate the classification's performance, the authors have also manually classified each module of a course. While there is substantial agreement between human reviewers, the agreement between human reviewers, LR and GPT approach is only fair, indicating less consistency in the SDG classifications between human, LR, and GPT assessments.},
  keywords={Surveys;Logistic regression;Generative Pre-trainer transformer;Writing;Vocational training;Transformers;Solids;Australia;Reliability;Sustainable development;sustainable development goals;classification;curriculum analysis;vocational training;machine learning;GPT},
  doi={10.1109/TALE62452.2024.10834357},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10487436,
  author={Deshpande, Sanjay and Szefer, Jakub},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={Analyzing ChatGPT's Aptitude in an Introductory Computer Engineering Course}, 
  year={2023},
  volume={},
  number={},
  pages={1034-1038},
  abstract={ChatGPT has recently gathered attention from the general public and academia as a tool that is able to generate plausible and human-sounding text answers to various questions. While recent works have explored the use of ChatGPT in the context of humanities, business school, or medical school, this work explores how ChatGPT performs in the context of an introductory computer engineering course. This work assesses ChatGPT's aptitude in answering quizzes, homework, and laboratory questions in an introductory-level computer engineering course. This work finds that ChatGPT can do well on questions asking about generic concepts. However, predictably, as a text- only tool, it cannot handle questions with diagrams or figures, nor can it generate diagrams and figures. Further, also clearly, the tool cannot do hands-on lab experiments, breadboard assembly, etc., but can generate plausible answers to some laboratory manual questions. One of the key observations presented in this work is that the ChatGPT tool could not be used to pass all components of the course. Nevertheless, it does well on quizzes and short-answer questions. On the other hand, plausible, human-sounding answers could confuse students when generating incorrect but still plausible answers.},
  keywords={Humanities;Codes;Manuals;Breadboard;Chatbots;Assembly;Business;Computer Engineering;Education;ChatGPT;GPT-3;OpenAI},
  doi={10.1109/CSCE60160.2023.00172},
  ISSN={},
  month={July},}@INPROCEEDINGS{10779794,
  author={Butgereit, Laurie and Zhou, Helper},
  booktitle={2024 International Conference on Next Generation Computing Applications (NextComp)}, 
  title={Using GPT-4 to Tutor Python Programming in Shona and Ndebele in Zimbabwe}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In many post-Colonial African countries, English is the medium of instruction at schools and universities. Many, if not most of the students, however, are not home language English speakers. In the specific situation of Zimbabwe, approximately eighty percent of the population is Shona speaking and approximately ten percent of the population is Ndebele speaking. Existing research shows that when learners or students are forced to learn technical subjects (such as mathematics and computer programming) in their non-home language, they are doing double work. Not only do they need to learn the new subject domain, they also need to translate these new terms to and from their home language. This paper investigates the use of an GPT-4 based artificially intelligent tutoring bot configured to tutor the subject of Python Programming in both Shona and Ndebele. This paper is the first step of a multi-step research project which has the final goal of helping Zimbabwean learners and students learn Python Programming in their home language. This first step, however, reports on language evaluations of the GPT-4 based tutoring bot operating in Shona and Ndebele.},
  keywords={Oral communication;Africa;Programming;Chatbots;Mathematics;Next generation networking;Python;GPT-4;chatGPT;Shona;Ndebele;Python;Tutoring},
  doi={10.1109/NextComp63004.2024.10779794},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10132255,
  author={Jalil, Sajed and Rafi, Suzzana and LaToza, Thomas D. and Moran, Kevin and Lam, Wing},
  booktitle={2023 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={ChatGPT and Software Testing Education: Promises & Perils}, 
  year={2023},
  volume={},
  number={},
  pages={4130-4137},
  abstract={Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers. More recently, we have seen the ad-vent of general purpose "large language models", based on neural transformer architectures, that have been trained on massive datasets of human written text, which includes code and natural language. However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability. Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end users.The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock. However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction. As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum. We found that given its current capabilities, ChatGPT is able to respond to 77.5% of the questions we examined and that, of these questions, it is able to provide correct or partially correct answers in 55.6% of cases, provide correct or partially correct explanations of answers in 53.0% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct answers and explanations. Based on these findings, we discuss the potential promises and perils related to the use of ChatGPT by students and instructors.},
  keywords={Software testing;Codes;Limiting;Conferences;Natural languages;Predictive models;Chatbots;ChatGPT;testing;education;case study},
  doi={10.1109/ICSTW58534.2023.00078},
  ISSN={2159-4848},
  month={April},}@INPROCEEDINGS{10892932,
  author={Bego, Campbell R. and Crockett, Cenetria L. and Danovitch, Judith H. and Martinez, Liliana G. and Rajkumar, Alwin K. and Thomas, Elisabeth L. and Thompson, Angela K. and Tran, Alvin and Valavala, Benarji},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={First-Year Engineering Students' Expertise and Trust in GenAl}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This full-length research study investigated first-year engineering students “trust in generative artificial intelligence (GenAl) before and after course instruction. Pre-and post-surveys were conducted with questions on students” experience with GenAl tools as well as trust in GenAl. The trust questions had students evaluate the likelihood of GenAl generating a correct response to various prompts such as “explain the unit circle” (correct response likely) to “solving this system of equations …” (correct response unlikely for tools available in Fall 2023). Within-subjects analyses indicated that lessons in the course significantly increased trust in ChatGPT for correct-response-likely items. In addition, the lessons significantly decreased students “trust in ChatGPT for correct-response-unlikely items. There were no significant interactions between prior experience level and change in trust. These results show that guided exposure to GenAl helped first-year engineering students begin to understand capabilities and limitations of GenAl. These results are promising because student trust in GenAl output will directly impact decisions to engage with it for different tasks. More work is needed to optimize instruction and understand students” use of the tool beyond the classroom integration, including their full ethical decision-making process, but the malleability of trust at this level is an indication that engineering educators can impact student perspectives of GenAl.},
  keywords={Ethics;Accuracy;Generative AI;Decision making;Chatbots;Reliability engineering;Engineering students;Generative AI;engineering education;trust},
  doi={10.1109/FIE61694.2024.10892932},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10873911,
  author={Pratama, Bacharuddin Adieb and Wiharja, Kemas Rahmat Saleh and Wulandari, Gia Septiana},
  booktitle={2023 International Conference on Artificial Intelligence Robotics, Signal and Image Processing (AIRoSIP)}, 
  title={Knowledge Acquisition from Student Lecture Reflection Data: Leveraging Large Language Models and Tacit Knowledge}, 
  year={2023},
  volume={},
  number={},
  pages={388-392},
  abstract={This research paper addresses a pertinent challenge encountered by lecturers in higher education institutions efficiently managing and analyzing the substantial volume of student lecture reflection data. To overcome this issue, we propose a novel knowledge acquisition system that amalgamates the capabilities of Large Language Models (LLM) with the invaluable tacit knowledge possessed by lecturers, enabling the inference of solutions. The process involves meticulously extracting textual information from student reflections and applying a multilingual BERT model for precise categorization. The acquired knowledge is subsequently stored within a sophisticated web-based platform, yielding an impressive acquisition rate of 73.85%, with 13.07% attributed to LLM and 60.78% emanating from lecturers' tacit knowledge. This study effectively showcases the potential of synergizing cutting-edge language models with human expertise, augmenting knowledge acquisition in educational environments. Furthermore, the proposed system furnishes a comprehensive and easily accessible resource, presenting insights into frequently encountered challenges and corresponding resolutions, benefiting students and lecturers.},
  keywords={Image resolution;Knowledge acquisition;Large language models;Education;Reflection;Data models;Multilingual;Data mining;Signal resolution;Robots;knowledge acquisition;student lecture reflections;text extraction;BERT;Large Language Model},
  doi={10.1109/AIRoSIP58759.2023.10873911},
  ISSN={},
  month={Aug},}@ARTICLE{10478015,
  author={Haindl, Philipp and Weinberger, Gerald},
  journal={IEEE Access}, 
  title={Students’ Experiences of Using ChatGPT in an Undergraduate Programming Course}, 
  year={2024},
  volume={12},
  number={},
  pages={43519-43529},
  abstract={Increasing use of artificial intelligence tools in programming education calls for a deeper understanding of their effect on students’ learning. This paper presents a study that investigates the experiences of part-time undergraduate students using ChatGPT in a five-week Java programming course. After each exercise, students provided feedback via anonymous surveys in which they rated different suitability aspects of ChatGPT. The majority viewed ChatGPT positively and suitable for learning programming concepts. However, its suitability for specific implementation tasks received mixed reviews. Students found it easy to adapt ChatGPT’s generated code to the exercises’ implementation tasks. The students primarily used it for acquiring background knowledge, learning syntax and programming concepts and suggesting suitable algorithms. Yet, some abstained from using it due to concerns to not garner sufficient programming proficiency, retrieving partially incorrect or misleading generated code, preferring an independent working style, or general skepticism about its benefits. Finally, in response to our findings, we also discuss three perspective directions for improving the suitability of LLM chatbots for students in programming education.},
  keywords={Chatbots;Codes;Programming profession;Task analysis;Education;Artificial intelligence;Surveys;Programming education;ChatGPT;generative AI;large language models},
  doi={10.1109/ACCESS.2024.3380909},
  ISSN={2169-3536},
  month={},}@ARTICLE{11028593,
  author={Tatar, Moosa and Farokhi, Soheila and Foumani, Arash Azizian and Uzunlar, Emirhan and Araz, Ozgur M.},
  journal={IEEE Engineering Management Review}, 
  title={Application of Gemini in Public Health Amid the Artificial Intelligence Era}, 
  year={2025},
  volume={},
  number={},
  pages={1-13},
  abstract={In December 2023, Google DeepMind unveiled its large language model, Gemini, which is shown to be capable of understanding and processing multimodal information. This article explores the applications of Gemini in public health. Unlike traditional models, Gemini integrates and analyzes information through diverse modalities (text, image, video, etc.) fostering new applications. Notably, Google Gemini is presented as the first model to surpass human experts on the Massive Multitask Language Understanding (MMLU) benchmark, which combines multiple subjects including science, technology, engineering, and mathematics (STEM), humanities, and others to test the knowledge and problem-solving abilities of artificial intelligence (AI) models. While Gemini's capabilities are claimed to surpass established models such as ChatGPT, offering improved accuracy, efficiency, and interdisciplinary research integration, its utilization in research is still limited. A wide range of applications, including healthcare communication and delivery, medical diagnosis and decision-making, early disease diagnosis, public health surveillance, interventions, and education, drug research, and adverse effects prevention can benefit from Gemini's features. By extracting insights from sizable datasets and comprehending complex medical information, Gemini enables researchers and practitioners. However, responsible use with expert oversight is crucial. Overall, Gemini's capabilities offer new opportunities for improving public health research, practice, and ultimately, population health outcomes.},
  keywords={Public healthcare;Artificial intelligence;Medical diagnostic imaging;Chatbots;Accuracy;Internet;Data mining;Training;Medical services;Medical diagnosis;Artificial Intelligence for Technology Management;Human Information and Knowledge Processing;Public Health;Gemini;Multimodal AI},
  doi={10.1109/EMR.2025.3577913},
  ISSN={1937-4178},
  month={},}@INPROCEEDINGS{10343337,
  author={Ilic, Peter and Carr, Nicholas},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Work in Progress: Safeguarding Authenticity: Strategies for Combating AI-Generated Plagiarism in Academia}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress (WiP) research explores the role of rubrics in mitigating the negative impact of generative AI, such as ChatGPT, on writing assessment practices in STEM. This approach addresses the growing need for innovative methods of ensuring student academic integrity and authenticity in the rapidly expanding ecosystem of AI tools. A rubric consisting of five criteria is employed to rate the students' deconstruction of written text into language frames for the purpose of differentiating between human-written and AI-generated content. The language frames are common English language sentence patterns used for expressing five academic written functions: compare/contrast, cause/effect, classification, chronological order, and spatial order. By evaluating the performance of student deconstruction of one paragraph written by the student and a second paragraph produced by ChatGPT, it is anticipated that the rubric will enable the instructor to differentiate between the two by capturing any gaps in knowledge required to identify, deconstruct, and reproduce previously learned sentence frames. This assumes that the student will be more familiar with a self-written text than an unfamiliar AI produced one. This difference may then be employed by educators to aid in the identification of AI-generated plagiarism submitted by students. The key insights from this pilot study include: The need for a rubric threshold level of between 70% and 80% to differentiate between human and AI texts. Students appear to score higher at the identification of language frames than the production of the same frames. They were equal or better at identifying sentence frames from the AI generated text. Also, students scored very low on critical thinking questions that required the selection of alternative sentence frames. This WiP paper details the rubric design, research methodology, and preliminary insights from a small pilot study, which informs the evolution towards a larger future implementation.},
  keywords={Plagiarism;Design methodology;Ecosystems;Production;Writing;Chatbots;Artificial intelligence;AI;Assessment;Rubric;Writing;Cheating;Plagiarism;ChatGPT;EFL;STEM},
  doi={10.1109/FIE58773.2023.10343337},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10628428,
  author={Jahić, Jasmin and Sami, Ashkan},
  booktitle={2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C)}, 
  title={State of Practice: LLMs in Software Engineering and Software Architecture}, 
  year={2024},
  volume={},
  number={},
  pages={311-318},
  abstract={Large Language Models (LLMs) are finding their way into Software Engineering by assisting with tasks such as code generation. Furthermore, LLMs might have a potential to perform even more complex tasks, such as suggesting architectural design. However, there is a lack of empirical surveys on how software engineering companies use (and plan to use) LLMs and if LLMs truly can provide benefits to software architects. To understand the state of practice considering adoption of LLMs in software engineering, existing challenges, and future trends, we have surveyed 15 different software engineering companies. To understand the ability of LLMs to perform more complex tasks, we report on our experiments with LLM-assisted architectural design. We applied ChatGPT on 5 software projects and in total performed 50 different experiments. Our results capture the state of the practice of LLMs in software engineering and demonstrate how LLMs perform when assisting with (more complex task such as) architectural design. Engineers, architects, and project managers should profit from these results to guide their decision towards targeted adoption of LLMs in their business and engineering domains.},
  keywords={Surveys;Codes;Software architecture;Large language models;Companies;Market research;Chatbots;Architecture;AI;Design Space Exploration;ChatGPT},
  doi={10.1109/ICSA-C63560.2024.00059},
  ISSN={2768-4288},
  month={June},}@INPROCEEDINGS{10825051,
  author={Tihanyi, Norbert and Bisztray, Tamas and Dubniczky, Richard A. and Toth, Rebeka and Borsos, Bertalan and Cherif, Bilel and Jain, Ridhi and Muzsai, Lajos and Ferrag, Mohamed Amine and Marinelli, Ryan and Cordeiro, Lucas C. and Debbah, Merouane and Mavroeidis, Vasileios and Jøsang, Audun},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Dynamic Intelligence Assessment: Benchmarking LLMs on the Road to AGI with a Focus on Model Confidence}, 
  year={2024},
  volume={},
  number={},
  pages={3313-3321},
  abstract={As machine intelligence evolves, the need to test and compare the problem-solving abilities of different AI models grows. However, current benchmarks are often simplistic, allowing models to perform uniformly well and making it difficult to distinguish their capabilities. Additionally, benchmarks typically rely on static question-answer pairs that the models might memorize or guess. To address these limitations, we introduce Dynamic Intelligence Assessment (DIA), a novel methodology for testing AI models using dynamic question templates and improved metrics across multiple disciplines such as mathematics, cryptography, cybersecurity, and computer science. The accompanying dataset, DIA-Bench, contains a diverse collection of challenge templates with mutable parameters presented in various formats, including text, PDFs, compiled binaries, visual puzzles, and CTF-style cybersecurity challenges. Our framework introduces four new metrics to assess a model’s reliability and confidence across multiple attempts. These metrics revealed that even simple questions are frequently answered incorrectly when posed in varying forms, highlighting significant gaps in models’ reliability. Notably, API models like GPT-4o often overestimated their mathematical capabilities, while ChatGPT-4o demonstrated better performance due to effective tool usage. In self-assessment OpenAI’s o1-mini proved to have the best judgement on what tasks it should attempt to solve. We evaluated 25 state-of-the-art LLMs using DIA-Bench, showing that current models struggle with complex tasks and often display unexpectedly low confidence, even with simpler questions. The DIA framework sets a new standard for assessing not only problem-solving, but also a model’s adaptive intelligence and ability to assess its limitations. The dataset is publicly available on the project’s page: https://github.com/DIA-Bench.},
  keywords={Measurement;Adaptation models;Computational modeling;Benchmark testing;Reliability engineering;Mathematical models;Data models;Reliability;Problem-solving;Computer security;Artificial Intelligence;Large Language Models;Dynamic Benchmarking;Performance Metrics;Reliability},
  doi={10.1109/BigData62323.2024.10825051},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10662994,
  author={Brockenbrough, Allan and Salinas, Dominic},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Using Generative AI to Create User Stories in the Software Engineering Classroom}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={A user story is used in agile methodology to describe functionality that is valuable to the user and may include criteria to determine if the developer has completed the story. This study investigates undergraduate computer science students using ChatGPT to create user stories from user feedback. The study compares aspects of the user stories created by students using ChatGPT with those not using ChatGPT. Are user stories written by students with AI assistance of higher or lower quality? How does the time spent writing the user story change with the use of ChatGPT? We evaluate student user stories using a modified INVEST story rating system. Evaluated user story properties include structure, independence, value, testability, and grammar. The results show that ChatGPT-assisted students produce higher-quality user stories than unassisted students. However, using ChatGPT to write user stories does not guarantee high quality. ChatGPT can fail to recognize dependencies between user feedback and create structurally incorrect user stories. We see a need for students to be trained in effectively using this tool by carefully examining AI-assisted output and making revisions.},
  keywords={Computer science;Generative AI;Chatbots;Grammar;Software engineering;user stories;ChatGPT;GPT-Generative AI;INVEST;software engineering education;LLM},
  doi={10.1109/CSEET62301.2024.10662994},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10465435,
  author={Butgereit, Laurie and Egu, Asaminew Gizaw},
  booktitle={2023 First International Conference on the Advancements of Artificial Intelligence in African Context (AAIAC)}, 
  title={Using GPT-4 to Tutor Java Programming in Amharic}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Education is associated with economic development. Higher levels of education creates better likelihoods of employment. Technical education is growing even more important in the modern world. In Africa and other developing areas, there are many barriers to education. One such barrier is non-home language education. When students are forced to learn technical subjects in a second language, then they are doing double work. Not only are they learning a new technical subject; they are also translating all the new terms and concepts in and out of their home language. This paper specifically looks at using an artificial intelligence to help tutor the technical subject of Java Programming in the Amharic language. A Java tutoring system was developed which used GPT-4 as its artificial intelligence. The system was configured (or prompted) to act as a tutor in the Java programming language and to assist students using the Amharic language. The results of this research showed that although GPT-4 did make some language errors in Amharic, the language evaluation showed that at university level, students could easily recognize the language errors and still benefit from the Amharic Java Programming tutor.},
  keywords={Economics;Java;Computer languages;Education;Employment;Africa;Chatbots;Java;GPT-4;Tutoring;Amharic},
  doi={10.1109/AAIAC60008.2023.10465435},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10494274,
  author={Wu, Wennan and Liu, Ruisi and Chu, Junjie},
  booktitle={2023 16th International Symposium on Computational Intelligence and Design (ISCID)}, 
  title={How important is Trust: Exploring the Factors Influencing College Students' Use of Chat GPT as a Learning Aid}, 
  year={2023},
  volume={},
  number={},
  pages={67-70},
  abstract={With the rapid development of artificial intelligence technology, its functions have become increasingly powerful. Large Language Models such as ChatGPT have solved various tasks such as text creation and code debugging, and the impact in the field of education has caused close attention from many scholars. Therefore, by establishing an extended TAM, we conducted a questionnaire survey on 470 college students to explore their acceptance of using ChatGPT as an auxiliary learning tool. Structural equation modeling (SEM) was used to analyze the data. The results showed that trust, facilitating conditions, perceived usefulness, and perceived ease of use have a positive impact on college students' use intention of ChatGPT. Hence, by improving the credibility of generated content and providing appropriate auxiliary resources will help promote students' acceptance of ChatGPT. The research results provide suggestions and directions for future design.},
  keywords={Surveys;Technology acceptance model;Numerical analysis;Computational modeling;Education;Debugging;Chatbots;technology acceptance model (TAM);structural equation modeling (SEM);ChatGPT},
  doi={10.1109/ISCID59865.2023.00024},
  ISSN={2473-3547},
  month={Dec},}@ARTICLE{10478897,
  author={Rodriguez-Echeverría, Roberto and Gutiérrez, Juan D. and Conejero, José M. and Prieto, Álvaro E.},
  journal={IEEE Revista Iberoamericana de Tecnologias del Aprendizaje}, 
  title={Analysis of ChatGPT Performance in Computer Engineering Exams}, 
  year={2024},
  volume={19},
  number={},
  pages={71-80},
  abstract={The appearance of ChatGPT at the end of 2022 was a milestone in the field of Generative Artificial Intelligence. However, it also caused a shock in the academic world. For the first time, a simple interface allowed anyone to access a large language model and use it to generate text. These capabilities have a relevant impact on teaching-learning methodologies and assessment methods. This work aims to obtain an objective measure of ChatGPT’s possible performance in solving exams related to computer engineering. For this purpose, it has been tested with actual exams of 15 subjects of the Software Engineering branch of a Spanish university. All the questions of these exams have been extracted and adapted to a text format to obtain an answer. Furthermore, the exams have been rewritten to be corrected by the teaching staff. In light of the results, ChatGPT can achieve relevant performance in these exams; it can pass many questions and problems of different natures in multiple subjects. A detailed study of the results by typology of questions and problems is provided as a fundamental contribution, allowing recommendations to be considered in the design of assessment methods. In addition, an analysis of the impact of the non-deterministic aspect of ChatGPT on the answers to test questions is presented, and the need to use a strategy to reduce this effect for performance analysis is concluded.},
  keywords={Chatbots;Education;Artificial intelligence;Guidelines;Oral communication;Computational modeling;Generative AI;Computer science education;Testing;Performance evaluation;Learning systems;Artificial intelligence;ChatGPT;education;experiment},
  doi={10.1109/RITA.2024.3381842},
  ISSN={1932-8540},
  month={},}@INPROCEEDINGS{10569779,
  author={Santos, Patricia and Urgel, Keysha and Moreno, Verónica},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Generative Artificial Intelligence in Teaching and Learning of ICT Engineering Education: A Literature Review and Illustrative Scenarios}, 
  year={2024},
  volume={},
  number={},
  pages={1338-1343},
  abstract={This paper presents a comprehensive literature review on the integration of Generative Artificial Intelligence (Gen AI) in the teaching and learning processes within Information and Communication Technologies (ICT) engineering education. The study delves into the potential of Gen AI technologies to enhance educational practices in engineering contexts. Through synthesizing existing literature, this review analyzes the impact of Gen AI on pedagogical strategies, curriculum development, and student engagement in the realm of ICT engineering education. The paper presents authentic teaching cases, including applications and experiments with students, from various studies conducted at higher education institutions worldwide. The illustrative scenarios primarily focus on showcasing the practical applications of Gen AI in two key areas: programming skills and ethics within ICT engineering education. The exploration of these cases provides valuable insights and discussion into the effective implementation of Gen AI in higher education, recognizing the importance of integrating the learning of these technologies into the curriculum. This research provides a valuable resource for ICT engineering educators, researchers, and policymakers aiming to harness AI technologies for transformative progress in engineering education.},
  keywords={Generative AI;Reviews;Bibliographies;Soft sensors;Training data;Learning (artificial intelligence);Information and communication technology;Generative Artificial Intelligence;Engineering education;programming;tools;ethics},
  doi={10.1109/MIPRO60963.2024.10569779},
  ISSN={2623-8764},
  month={May},}@ARTICLE{11006075,
  author={Oprea, Simona-Vasilica and Bâra, Adela},
  journal={IEEE Access}, 
  title={Transforming Education With Large Language Models: Trends, Themes, and Untapped Potential}, 
  year={2025},
  volume={13},
  number={},
  pages={87292-87312},
  abstract={Our research focuses on the transformative intersection of Large Language Models (LLMs) and education in the last six years (2019–2024), examining their potential to modernize educational systems and enhance learning outcomes. Leveraging a comprehensive methodological framework, we analyzed 9,598 publications from Web of Science (WoS), extracting 25,381 education-related terms and mapping academic trends across diverse research areas. Educational research involving LLMs focuses heavily on learning, research and training, with terms such as “education” (1546), “learning” (4828), “research” (4438) and “training” (327) frequently appearing in the analyzed dataset. Specific applications such as grading (121) and tutoring (82) are less emphasized, presenting potential areas for further exploration. Key elements include annual publication patterns, institutional collaborations, citation dynamics and keyword co-occurrence maps. Advanced topic modeling techniques, such as LDA, LDA-BERT and BERT-Clustering, reveal a spectrum of themes, from foundational AI concepts in education to domain-specific applications in fields like legal and financial contexts. The findings highlight major educational themes such as “AI in education”, “medical education” and “programming education”, alongside subfields like “computer science education” and “software engineering education” underscoring a strong focus on technology-driven learning.},
  keywords={Education;Chatbots;Artificial intelligence;Bibliometrics;Market research;Ethics;Collaboration;Focusing;Large language models;Systematic literature review;Large language models;artificial intelligence;education;topic modeling},
  doi={10.1109/ACCESS.2025.3570649},
  ISSN={2169-3536},
  month={},}@ARTICLE{10777837,
  author={Cui, Xiao and Qin, Yulei and Gao, Yuting and Zhang, Enwei and Xu, Zihan and Wu, Tong and Li, Ke and Sun, Xing and Zhou, Wengang and Li, Houqiang},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={SinKD: Sinkhorn Distance Minimization for Knowledge Distillation}, 
  year={2024},
  volume={},
  number={},
  pages={1-15},
  abstract={Knowledge distillation (KD) has been widely adopted to compress large language models (LLMs). Existing KD methods investigate various divergence measures including the Kullback–Leibler (KL), reverse KL (RKL), and Jensen–Shannon (JS) divergences. However, due to limitations inherent in their assumptions and definitions, these measures fail to deliver effective supervision when a distribution overlap exists between the teacher and the student. In this article, we show that the aforementioned KL, RKL, and JS divergences, respectively, suffer from issues of mode-averaging, mode-collapsing, and mode-underestimation, which deteriorates logits-based KD for diverse natural language processing (NLP) tasks. We propose the Sinkhorn KD (SinKD) that exploits the Sinkhorn distance to ensure a nuanced and precise assessment of the disparity between distributions of teacher and student models. Besides, thanks to the properties of the Sinkhorn metric, we get rid of sample-wise KD that restricts the perception of divergences inside each teacher–student sample pair. Instead, we propose a batch-wise reformulation to capture the geometric intricacies of distributions across samples in the high-dimensional space. A comprehensive evaluation of GLUE and SuperGLUE, in terms of comparability, validity, and generalizability, highlights our superiority over state-of-the-art (SOTA) methods on all kinds of LLMs with encoder-only, encoder–decoder, and decoder-only architectures. Codes and models are available at https://github.com/2018cx/SinKD.},
  keywords={Minimization;Encoding;Bidirectional control;Temperature measurement;Costs;Adaptation models;Transformers;Training;Sun;Robustness;Knowledge distillation (KD);Sinkhorn distance;Wasserstein distance},
  doi={10.1109/TNNLS.2024.3501335},
  ISSN={2162-2388},
  month={},}@INPROCEEDINGS{10662990,
  author={Frankford, Eduard and Höhn, Ingo and Sauerwein, Clemens and Breu, Ruth},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={A Survey Study on the State of the Art of Programming Exercise Generation Using Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper analyzes Large Language Models (LLMs) with regard to their programming exercise generation capabilities. Through a survey study, we defined the state of the art, extracted their strengths and weaknesses and finally proposed an evaluation matrix, helping researchers and educators to decide which LLM is the best fitting for the programming exercise generation use case. We also found that multiple LLMs are capable of producing useful program-ming exercises. Nevertheless, there exist challenges like the ease with which LLMs might solve exercises generated by LLMs. This paper contributes to the ongoing discourse on the integration of LLMs in education.},
  keywords={Surveys;Data privacy;Navigation;Large language models;Education;Fitting;Transforms;Programming Education;Programming Exercise Generation;Large Language Models;Artificial Intelligence;ChatGPT;Programming Exercise Generation Benchmark},
  doi={10.1109/CSEET62301.2024.10662990},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10837662,
  author={Jang, Wunmin and Hou, Ruikun and Gao, Hong and Kasneci, Enkelejda},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Analyzing Communication Logs in Pair Programming: A Comparison of Human- and LLM-Based Approaches}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Communication challenges have often been a significant b arrier t o e ffective P air Programming (PP), especially for novices in higher education. A deep understanding of communication patterns can enhance learning outcomes during PP. To explore this, we conducted an experiment involving 19 participants engaged in debugging tasks at a university, grouped into three pairing configurations: e xpert p airs, student pairs, and mixed pairs. We manually transcribed and coded the participants' verbal interactions based on nine predefined communication patterns. Considering that manual coding is cost-intensive, we also explored an automated annotation approach by leveraging recent Large Language Models (LLMs) with zero-shot capabilities for multi-label classification. Our findings revealed distinct differences in communication patterns. Integration, extension, feedback request, and critique were the most common patterns, while completion, justification request, clarification,j uxtaposition, a nd p araphrase w ere r are a cross all groups. These insights highlight the importance of fostering a comfortable and supportive environment that encourages agreement and idea expansion during PP, particularly those that require collaborative programming practices. Furthermore, our model evaluation indicates that the advanced GPT-4o model performs best, achieving a F1-score of 0.59. This study suggests that encouraging diverse transactive interactions can enhance the effectiveness of PP. Additionally, the LLM-based automated annotation approach shows promise as a substitute for human observers, prompting large-scale communication research.},
  keywords={Training;Annotations;Large language models;Collaboration;Multi label classification;Manuals;Observers;Encoding;Problem-solving;Programming profession;communication analysis;higher education;pair programming;LLMs zero-shot annotation},
  doi={10.1109/ITHET61869.2024.10837662},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10837661,
  author={Abid, Abir and Somai, Meriem and Kammoun, Habib M. and Kallel, Ilhem},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={The NAJEH Effect: How ChatGPT is Shaping the Future of Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In the digital era, Artificial Intelligence is increasingly developing. In recent years, one of the promising development in this field is ChatGPT which has sparked considerable interest. ChatGPT is a language model developed by OpenAI that allows people to interact with a computer in a more natural and conversational way. It offers students and educators personalized learning experiences Linked to ChatGPt open AI API. Therefore, we present in this paper a virtual tutor, named NAJEH, integrated into the student engagement portal and mobile application (MYU) and have access to the Student Information System (SIS) and Learning Management System (LMS) of the Honoris United Universities11https://honoris.net/, which includes 6 institutions in Tunisia. Around five thousand students from the Université Centrale had the learning experience with NAJEH. A survey was carried out in order to explore students satisfaction and acceptance of NAJEH. Thus, with a 76% response rate, results show that more than 80 % of students find this chatbot tutor very useful, easy and use it at least once a day. As perspective, we propose to investigate on the impact of these interactions on the students' academic performance and teaching efficiency. In fact, an in-depth study requires more data available over a longer period, even several years.},
  keywords={Training;Surveys;Learning management systems;Computational modeling;Chatbots;Mobile applications;Artificial intelligence;Information technology;Portals;Information systems;NAJEH;ChatGPT API;OpenAI;E-learning;Higher Education;Students' Feedback},
  doi={10.1109/ITHET61869.2024.10837661},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10295122,
  author={Hernandez, Alexander A. and Padilla, Jay Rhald C. and Montefalcon, Myron Darrel L.},
  booktitle={2023 IEEE 13th International Conference on System Engineering and Technology (ICSET)}, 
  title={Information Seeking Behavior in ChatGPT: The Case of Programming Students from a Developing Economy}, 
  year={2023},
  volume={},
  number={},
  pages={72-77},
  abstract={ChatGPT is a promising emerging technology that could revolutionize the programming-related activities of students in universities throughout their academic programs. However, to date, academics need understanding on information-seeking behavior of students in programming courses, its potential role, and benefits to learning and assessment. To answer this gap, this study develops a conceptual framework with hypotheses tested through a survey of higher education students to examine the use of ChatGPT for searching programming-related information. Results show that perceived ease of use, usefulness, social influence, herding, trustworthiness, convenience, and ethical considerations positively influenced the use of ChatGPT to search for programming-related information. Likewise, using ChatGPT is positively correlated with information-seeking behavior. Thus, ChatGPT is a promising tool that may bring forward programming activities to students and instructors. Practical and research implications are provided to broaden the conversation on ChatGPT further.},
  keywords={Surveys;Ethics;Education;Oral communication;Chatbots;Systems engineering and theory;Behavioral sciences;artificial intelligence;ChatGPT;developing country;use behavior;information-seeking behavior;technology acceptance model;technology adoption},
  doi={10.1109/ICSET59111.2023.10295122},
  ISSN={2470-640X},
  month={Oct},}@INPROCEEDINGS{10481602,
  author={Prajapati, Manish and Baliarsingh, Santos Kumar and Dora, Chinmayee and Bhoi, Ashutosh and Hota, Jhalak and Mohanty, Jasaswi Prasad},
  booktitle={2024 International Conference on Emerging Systems and Intelligent Computing (ESIC)}, 
  title={Detection of AI-Generated Text Using Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={735-740},
  abstract={A large language model (LLM) is a trained deep-learning model that understands and generates text in a human-like fashion. Due to the significant advancements of LLM, it becomes a challenging task to distinguish human-written content from artificial intelligence (AI) generated content. In this work, we leverage the machine learning (ML) models to reliably identify whether an essay is authored by a human being or by an LLM. Concerns about LLMs replacing human tasks, especially in education persist. However, optimism remains for their potential as tools to enhance writing skills. An academic worry is LLMs facilitating plagiarism due to their extensive training in text and code datasets. Using diverse texts and unknown generative models, we replicate typical scenarios to encourage feature learning across models. In a study involving human subjects, we demonstrate that the annotation scheme offered by generative textual likelihood ratio (GLTR) enhances the human detection rate of fake text from 74% to 99% without requiring any previous training. GLTR is open source and publicly deployed, already finding widespread use in detecting generated outputs.},
  keywords={Training;Representation learning;Generative AI;Current measurement;Plagiarism;Text detection;Writing;LLM;AI;Machine Learning;ChatGPT;text detection},
  doi={10.1109/ESIC60604.2024.10481602},
  ISSN={},
  month={Feb},}@ARTICLE{10820047,
  author={Huang, Yuheng and Song, Jiayang and Wang, Zhijie and Zhao, Shengming and Chen, Huaming and Juefei-Xu, Felix and Ma, Lei},
  journal={IEEE Transactions on Software Engineering}, 
  title={Look Before You Leap: An Exploratory Study of Uncertainty Analysis for Large Language Models}, 
  year={2025},
  volume={51},
  number={2},
  pages={413-429},
  abstract={The recent performance leap of Large Language Models (LLMs) opens up new opportunities across numerous industrial applications and domains. However, the potential erroneous behavior (e.g., the generation of misinformation and hallucination) has also raised severe concerns for the trustworthiness of LLMs, especially in safety-, security- and reliability-sensitive industrial scenarios, potentially hindering real-world adoptions. While uncertainty estimation has shown its potential for interpreting the prediction risks made by classic machine learning (ML) models, the unique characteristics of recent LLMs (e.g., adopting self-attention mechanism as its core, very large-scale model size, often used in generative contexts) pose new challenges for the behavior analysis of LLMs. Up to the present, little progress has been made to better understand whether and to what extent uncertainty estimation can help characterize the capability boundary of an LLM, to counteract its undesired behavior, which is considered to be of great importance with the potential wide-range applications of LLMs across industry domains. To bridge the gap, in this paper, we initiate an early exploratory study of the risk assessment of LLMs from the lens of uncertainty. In particular, we conduct a large-scale study with as many as twelve uncertainty estimation methods and eight general LLMs on four NLP tasks and seven programming-capable LLMs on two code generation tasks to investigate to what extent uncertainty estimation techniques could help characterize the prediction risks of LLMs. Our findings confirm the potential of uncertainty estimation for revealing LLMs’ uncertain/non-factual predictions. The insights derived from our study can pave the way for more advanced analysis and research on LLMs, ultimately aiming at enhancing their trustworthiness.},
  keywords={Uncertainty;Estimation;Codes;Hidden Markov models;Adaptation models;Artificial intelligence;Training;Risk management;Electronic mail;Transformers;Large language models;deep neural networks;uncertainty estimation;software reliability},
  doi={10.1109/TSE.2024.3519464},
  ISSN={1939-3520},
  month={Feb},}@ARTICLE{10485416,
  author={Jeong, Yongwoo and Song, Jae-Jun and Yang, Jiseon and Kang, Sungmin},
  journal={IEEE Access}, 
  title={Advancing Tinnitus Therapeutics: GPT-2 Driven Clustering Analysis of Cognitive Behavioral Therapy Sessions and Google T5-Based Predictive Modeling for THI Score Assessment}, 
  year={2024},
  volume={12},
  number={},
  pages={52414-52427},
  abstract={Cognitive Behavioral Therapy (CBT) for tinnitus alleviates psychological discomfort caused by severe tinnitus symptoms. During CBT, the patients will have various homework assignments, including writing daily diaries and self-monitoring. Most of these homework assignments are hand-written, textual data. This paper proposes that tinnitus therapeutics can utilize Large Language Models (LLMs) to analyze CBT and predict the outcomes of CBT treatments to manage high caseloads. We anonymized patient data and examined it with GPT-2-based-embedding, dimensionality reduction, and clustering process to observe how patients themselves changed their misconceptions and developed less unnecessary excessive emotional discomfort and how their Tinnitus Handicap Inventory (THI) scores were improved after the CBT treatment. We also discussed clustering results as a part of the demonstrations that LLMs can give us insights into the CBT. Then, we augmented textual patient data in three ways to minimize augmentation bias with a corresponding penalty to overcome the constraints of limitation of the number of datasets. We trained the Google T5 Transformer with the augmented data to predict the THI score outcomes at the end of the CBT sessions. We measured the performance using the ROUGE-L metric during the training and validation. The generated THI scores by Google T5 were converted from strings to floats to measure RMSE performance, which proved that the LLM could predict the outcome of CBT treatment with CBT data. Even though there is a risk of overfitting issues, this work demonstrated that tinnitus therapeutics experts can employ LLMs to manage caseloads.},
  keywords={Medical treatment;Internet;Depression;Clustering algorithms;Transformers;Support vector machines;Principal component analysis;Social networking (online);Cognition;Behavioral sciences;Ear;Patient monitoring;Writing;Large language models;Augmentation;cognitive;CBT;GPT-2;Google;tinnitus;T5;RMSE;ROUGE-L},
  doi={10.1109/ACCESS.2024.3383020},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11016290,
  author={Horne, Christopher},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Leveraging AI Chatbots to Enhance Student Understanding of Electric Circuits}, 
  year={2025},
  volume={},
  number={},
  pages={1-3},
  abstract={This work-in-progress (WIP) examines the potential of AI-powered chatbots, especially ChatGPT, as instructional tools to support student learning in an introductory electric circuits course. AI chatbots are becoming increasingly prominent in educational settings due to their capabilities in providing immediate, natural language-based explanations that support both procedural and conceptual understanding. In this WIP, electrical engineering students engaged with ChatGPT to solve problems related to fundamental topics such as Voltage and Current Division, as well as Nodal Analysis. Through structured assignments, students compared traditional problem-solving methods with chatbot-assisted approaches. Key findings indicate mixed outcomes, with students demonstrating improved comprehension of conceptual topics but facing challenges in accuracy due to prompting errors and limitations in ChatGPT's analytical processing. On average, 82 % of students expressed positive feedback on ChatGPT, with 48 % reporting improved confidence and understanding in electric circuits. However, for Nodal Analysis, only 22 % of students who provided accurate prompts received correct solutions from ChatGPT that closely matched their hand calculations.},
  keywords={Hands;Electric potential;Accuracy;Generative AI;Circuits;Voltage;Chatbots;Problem-solving;Engineering education;Equivalent circuits;Electric Circuits;Circuit Analysis;ChatGPT;Engineering education;Generative AI;GPT-4},
  doi={10.1109/EDUCON62633.2025.11016290},
  ISSN={2165-9567},
  month={April},}@ARTICLE{10638538,
  author={Haindl, Philipp and Weinberger, Gerald},
  journal={IEEE Access}, 
  title={Does ChatGPT Help Novice Programmers Write Better Code? Results From Static Code Analysis}, 
  year={2024},
  volume={12},
  number={},
  pages={114146-114156},
  abstract={In the realm of AI-enhanced programming education, there is growing interest in using such tools to help students understand good coding principles. This study investigates the impact of ChatGPT on code quality among part-time undergraduate students in introductory Java programming courses, who lack prior Java experience. The source code of 16 students from the control group (without ChatGPT) and 22 students from the treatment group (with ChatGPT) who completed identical programming exercises focused on coding conventions was analyzed. Static code analysis tools assessed adherence to a common coding convention ruleset and calculated cyclomatic and cognitive complexity metrics. The comparative analysis shows that the ChatGPT-assisted group significantly improved code quality, with fewer rule violations and reduced cyclomatic and cognitive complexities. The treatment group adhered more closely to coding standards and produced less complex code. Violations primarily occurred in line length, final parameters, and the extensibility of object-oriented programming (OOP). These findings suggest that ChatGPT can be beneficial in programming education by helping students write cleaner, less complex code and adhere to coding conventions. However, the study’s limitations, such as the small sample size and novice status of participants, call for further research with larger, more diverse populations and different educational contexts.},
  keywords={Codes;Chatbots;Programming;Programming profession;Education;Complexity theory;Java;Programming education;ChatGPT large language models;static code analysis},
  doi={10.1109/ACCESS.2024.3445432},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10913535,
  author={Watanabe, Rei and Okada, Satoshi and Watarai, Koki and Mitsunaga, Takuho},
  booktitle={2024 International Conference on Engineering and Emerging Technologies (ICEET)}, 
  title={Cloud SecNavigator: RAG Approach to Bridge Gaps and Strengthen Cloud Security Practices with RAGAS Assessment}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, many cyber incidents have resulted from misconfigurations of AWS. Although AWS provides exten-sive security guidelines, the sheer volume of documentation makes it difficult for developers to read and apply them completely. To address this, we propose a development support tool, Cloud SecNavigator. This tool uses Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) to extract relevant content and accurately respond to user queries based on AWS documentation. Our evaluation measures Cloud SecNavigator's output accuracy using two approaches: (1) Retrieval-Augmented Generation Assessment (RAGAS) and (2) a comparative accuracy assessment between Cloud SecNavigator-generated responses and a non-RAG LLM (GPT-40). The results indicate that Cloud Sec-Navigator achieves superior accuracy, highlighting its potential as an effective development support tool.},
  keywords={Accuracy;Large language models;Cloud computing security;Retrieval augmented generation;Documentation;Medical services;User interfaces;Internet;Security;Usability;Cloud Security;Retrieval-Augmented Generation (RAG);LLM (Large Language Models);RAGAS},
  doi={10.1109/ICEET65156.2024.10913535},
  ISSN={2831-3682},
  month={Dec},}@ARTICLE{10840322,
  author={Zhou, Bohao and Zhan, Yibing and Wang, Zhonghai and Li, Yanhong and Zhang, Chong and Yu, Baosheng and Ding, Liang and Jin, Hua and Liu, Weifeng and Wang, Xiongbin and Tao, Dapeng},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Benchmarking Medical LLMs on Anesthesiology: A Comprehensive Dataset in Chinese}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={With the recent success of large language models (LLMs), interest in developing them for medical domains has increased. However, due to the lack of benchmark datasets, evaluating the capabilities of medical LLMs remains challenging, particularly in highly specialized fields such as anesthesiology. To address this gap, we introduce a comprehensive anesthesiology benchmark dataset in Chinese, known as the Chinese Anesthesiology Benchmark (CAB). This benchmark facilitates the evaluation of medical LLMs for anesthesiology across three crucial dimensions: knowledge, application, and safety. Specifically, the CAB provides more than 8 k questions collected from examinations and books for knowledge-level evaluation; more than 2 k questions collected from online anesthesia consultations and hospitals for application-level evaluation; and 136 tests from seven anesthesia medical care scenarios for safety-level evaluation. With the proposed CAB dataset, we conducted a thorough evaluation of six medical LLMs, such as Bianque-2 and HuatuoGPT-13B, and eleven general LLMs, such as Qwen-7B-Chat and GPT-4. The evaluation results revealed that there are still clear gaps in the capacities of medical LLMs for anesthesiology compared with those of medical students in the field of anesthesia. We hope that the proposed CAB dataset can facilitate the development of medical LLMs for anesthesiology.},
  keywords={Anesthesiology;Anesthesia;Accuracy;Safety;Benchmark testing;Question answering (information retrieval);Data collection;Tag clouds;Physiology;Hospitals;Anesthesiology;benchmark;dataset;evaluation;large language model;medicine},
  doi={10.1109/TETCI.2024.3502465},
  ISSN={2471-285X},
  month={},}@INPROCEEDINGS{10578820,
  author={He, Zhangying and Nguyen, Thomas and Miari, Tahereh and Aliasgari, Mehrdad and Rafatirad, Setareh and Sayadi, Hossein},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={The AI Companion in Education: Analyzing the Pedagogical Potential of ChatGPT in Computer Science and Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Artificial Intelligence (AI), with ChatGPT as a prominent example, has recently taken center stage in various domains including higher education, particularly in Computer Science and Engineering (CSE). The AI revolution brings both convenience and controversy, offering substantial benefits while lacking formal guidance on their application. The primary objective of this work is to comprehensively analyze the pedagogical potential of ChatGPT in CSE education, understanding its strengths and limitations from the perspectives of educators and learners. We employ a systematic approach, creating a diverse range of educational practice problems within CSE field, focusing on various subjects such as data science, programming, AI, machine learning, networks, and more. According to our examinations, certain question types, like conceptual knowledge queries, typically do not pose significant challenges to ChatGPT, and thus, are excluded from our analysis. Alternatively, we focus our efforts on developing more in-depth and personalized questions and project-based tasks. These questions are presented to ChatGPT, followed by interactions to assess its effectiveness in delivering complete and meaningful responses. To this end, we propose a comprehensive five-factor reliability analysis framework to evaluate the responses. This assessment aims to identify when ChatGPT excels and when it faces challenges. Our study concludes with a correlation analysis, delving into the relationships among subjects, task types, and limiting factors. This analysis offers valuable insights to enhance ChatGPT's utility in CSE education, providing guidance to educators and students regarding its reliability and efficacy.},
  keywords={Systematics;Limiting;Focusing;Machine learning;Chatbots;Reliability;Task analysis;ChatGPT;Computer Science and Engineering;Education;Generative Artificial Intelligence;Reliability Analysis},
  doi={10.1109/EDUCON60312.2024.10578820},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10672220,
  author={Helal, Manal and Holthaus, Patrick and Wood, Luke and Velmurugan, Vignesh and Lakatos, Gabriella and Moros, Silvia and Amirabdollahian, Farshid},
  booktitle={2024 5th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={When the Robotic Maths Tutor is Wrong - Can Children Identify Mistakes Generated by ChatGPT?}, 
  year={2024},
  volume={},
  number={},
  pages={83-90},
  abstract={This study delves into integrating Large Language Models (LLMs), particularly ChatGPT-powered robots, as educational tools in primary school mathematics. Against the backdrop of Artificial Intelligence (AI) increasingly permeating educational settings, our investigation focuses on the response of young learners to errors made by these LLM-powered robots. Employing a user study approach, we conducted an experiment using the Pepper robot in a primary school classroom environment, where 77 primary school students from multiple grades (Year 3 to 5) took part in interacting with the robot. Our statistically significant findings highlight that most students, regardless of the year group, could discern between correct and incorrect responses generated by the robots, demonstrating a promising level of understanding and engagement with the AI-driven educational tool. Additionally, we observed that students' correctness in answering the Maths questions significantly influenced their ability to identify errors, underscoring the importance of prior knowledge in verifying LLM responses and detecting errors. Additionally, we examined potential confounding factors such as age and gender. Our findings underscore the importance of gradually integrating AI-powered educational tools under the guidance of domain experts following thorough verification processes. Moreover, our study calls for further research to establish best practices for implementing AI-driven pedagogical approaches in educational settings,},
  keywords={Brain;Large language models;Atmospheric modeling;Education;Learning (artificial intelligence);Chatbots;Mathematical models;Large Language Models;LLM Mathematical Correctness;Educational Robots;Cognition;Social Robotics},
  doi={10.1109/AIRC61399.2024.10672220},
  ISSN={},
  month={April},}@INPROCEEDINGS{11016463,
  author={Bhatt, Vishwa and Yu, Zhixin and Hou, Yunfei and Jin, Jennifer},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={ChatGPT as a Programming Tutor: Student Perceptions, Effectiveness, and Challenges}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This research examines the impact of ChatGPT on computer science education, focusing on its application in learning programming languages like SQL, C++, Python, and C#. Through a survey of 149 university students, the study identifies both the advantages and challenges of using ChatGPT as a virtual lab assistant. The results show that ChatGPT offers considerable assistance to students, especially in providing prompt feedback, facilitating debugging, and clarifying complex programming concepts. However, the research also points out significant challenges, including the potential for over-reliance on AI tools and worries about the accuracy of the responses generated by AI. Several students reported experiencing misleading or incomplete information from ChatGPT, indicating a need for enhancements in its accuracy and dependability. To address these challenges, the study proposes a transition from assignments focused on theory to personalized, project-based activities that foster independent problem-solving. In summary, this research sheds light on the advantages and obstacles of incorporating ChatGPT into computer science courses. Although ChatGPT provides beneficial support for learning, its function should be supplementary rather than central to programming education. The results highlight the necessity of thoughtful integration, promoting self-directed learning while utilizing AI's capabilities to foster engagement and offer immediate assistance.},
  keywords={Training;Surveys;Accuracy;Systematics;Debugging;Chatbots;Prompt engineering;Problem-solving;Artificial intelligence;Programming profession;ChatGPT;Generative AI;Programming education;AI dependency;AI accuracy;Programming Tutor},
  doi={10.1109/EDUCON62633.2025.11016463},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10663035,
  author={Yabaku, Mounika and Ouhbi, Sofia},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={University Students' Perception and Expectations of Generative AI Tools for Software Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Adopting Generative Artificial Intelligence (AI) tools in software engineering represents a shift in how tasks like coding and idea generation are approached. This paper investigates uni-versity students' perceptions and expectations regarding the use of Generative AI tools such as ChatGPT and Copilot in software engineering. To achieve this, we conducted a questionnaire study with volunteer participants studying at Uppsala University in Sweden, resulting in a total of 127 responses. These responses were about the usage preferences, motivations for adoption, per-ceived benefits, encountered challenges, and suggested improve-ment of these tools. The findings reveal that 16 % of participants have never used a Generative AI tool, while of those who have used such tools predominantly use ChatGPT3.5. Among users of Generative AI, respondents reported benefits such as code optimization and idea generation, alongside challenges such as inaccuracies in generated content and understanding user intent. Despite these challenges, participants perceive the integration of Generative AI tools as transformative for traditional software engineering practices. The results of this paper offer insights into the practical use of AI tools and suggestions for improving their functionality, thereby influencing the future direction of software engineering education.},
  keywords={Industries;Training;Productivity;Ethics;Technological innovation;Generative AI;Refining;Generative AI;software engineering;university students;perception;expectation;questionnaire},
  doi={10.1109/CSEET62301.2024.10663035},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10734623,
  author={Troussas, Christos and Krouska, Akrivi and Papakostas, Christos and Mylonas, Phivos and Sgouropoulou, Cleo},
  booktitle={2024 9th South-East Europe Design Automation, Computer Engineering, Computer Networks and Social Media Conference (SEEDA-CECNSM)}, 
  title={Assessing the Impact of Integrating ChatGPT as an Advice Generator in Educational Software}, 
  year={2024},
  volume={},
  number={},
  pages={127-133},
  abstract={This paper reports on the study of the integration of ChatGPT as an advice generator in custom educational software developed for Java programming. The software, in cooperation with ChatGPT API, pursues providing real-time, context-specific advice to students for better learning. This work adopted a two-fold evaluation approach to evaluating this integration. First, this study examines the effectiveness of this integration with the help of the Interrupted Time Series Analysis methodology to measure possible improvement in the performance metrics of the students in terms of error rates and task completion times. Second, this work presents a custom-designed questionnaire used to get student perceptions regarding the clarity, usefulness, and impact of ChatGPT’s advice, and the level of student satisfaction with the user interface. The key takeaways from this research study are the substantial improvements in performance metrics that were noted quantitatively, with students achieving lower error rates and faster completion times after the intervention of ChatGPT. Qualitatively, learners express their satisfaction with the clarity of advice, which gives them an understanding that works on their learning and confidence in Java programming. These findings point toward the promise of integrating such advanced AI solutions in educational software toward a significant improvement in learning outcomes and the necessity of human-aided continuous user feedback for system refinement.},
  keywords={Java;Error analysis;Time series analysis;User interfaces;Chatbots;Software;Generators;Time measurement;Artificial intelligence;Programming profession;ChatGPT in Education;Advice generator;Educational Software;Java Programming Learning;Artificial Intelligence in Education;Interrupted Time Series Analysis;User Experience Evaluation;AI-Powered Tutoring Systems;Programming Education;Technology-Enhanced Learning;Custom Questionnaire Assessment},
  doi={10.1109/SEEDA-CECNSM63478.2024.00031},
  ISSN={},
  month={Sep.},}@ARTICLE{10833612,
  author={Banerjee, P. and Srivastava, Anurag K. and Adjeroh, Donald A. and Reddy, Ramana and Karimian, Nima},
  journal={IEEE Access}, 
  title={Understanding ChatGPT: Impact Analysis and Path Forward for Teaching Computer Science and Engineering}, 
  year={2025},
  volume={13},
  number={},
  pages={11049-11069},
  abstract={Large Language Models (LLMs) like ChatGPT have become the most popular regenerative AI applications, used for obtaining responses for queries in different domains. The responses of ChatGPT are already becoming mainstream and are challenging conventional methods of learning. This article focuses on the application of ChatGPT for academic instructional purposes in the field of computer engineering and related majors. The capability of ChatGPT for instructional purposes is evaluated based on the responses to different questions about these engineering streams. This article explores different opportunities (with use cases), that ChatGPT can provide in augmenting the learning experience. It also provides scenarios of limitations and modifying the evaluation process to prevent the use of ChatGPT, which may lead to an inaccurate dissemination of accepted facts. In this paper, common classroom problems and their respective responses from ChatGPT in the domains of Computer Science, Cyber Security, Data Science, and Electrical Engineering are analyzed to determine the categories of queries for which ChatGPT offers reliable responses and those for which it may be factually incorrect. A student survey is performed to demonstrate that students must be made aware that ChatGPT may not be suitable for certain types of queries and means of upgrading the evaluation process.},
  keywords={Chatbots;Artificial intelligence;Measurement;Education;Computer science;Writing;Object recognition;Electrical engineering;Translation;Robot sensing systems;ChatGPT;education;LLM;computer science and engineering;electrical engineering},
  doi={10.1109/ACCESS.2024.3524102},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10893514,
  author={De La Hoz, Jose L. and Restrepo, David and Vieira, Camilo},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: Supporting Student Understanding of Finite Element Analysis and Computational Science: Classroom Scaffolding and ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress research paper presents the preliminary results of a study exploring the effectiveness of using computational notebooks to enhance student learning in a Finite Element Analysis (FEA) course for undergraduate Mechanical Engineering students. Our previous work has shown that students often face difficulties in grasping abstract concepts from mechanics of materials while simultaneously learning computational modeling. However, students recognized several advantages of using MATLAB for FEA compared to manual calculations, including significant time savings, increased efficiency, and reduced errors. Nevertheless, they also faced challenges, including a steep learning curve for MATLAB and concerns about how this limitation hinders their conceptual understanding. Despite these drawbacks, they recognized the importance and value of developing computational skills for their future careers. In this study, we extended the scaffolds and changed the sequence of activities to address the challenges the students faced in the previous iteration of our work. Specifically, we provided worked examples that students needed to use, self-explain, and modify before they engaged in programming from scratch. Also, after developing a basic understanding of how to implement FEA in MATLAB, the students used ChatGPT to generate a code that would do the same task. This activity required them to evaluate and refine automatically generated MATLAB code, as ChatGPT may provide alternative solutions that might not always work correctly. We explore three main topics to understand student experiences with and perceptions of this approach: (1) the value of using computational methods compared to manual completion for FEA; (2) the challenges and support of using MATLAB for FEA; and (3) the effectiveness of simulation tools to learn FEA. The goal of this project is two-fold: (1) supporting student learning of intricate phenomena explored in mechanics of materials, like distribution of stress, and stiffness, and (2) fostering essential computational thinking skills through practical disciplinary coding experience. By implementing these elements, the study anticipates a substantial improvement in students' understanding of FEA principles and their ability to translate them into solutions for real-world engineering challenges.},
  keywords={Codes;Scientific computing;Manuals;Transforms;Chatbots;Encoding;Finite element analysis;MATLAB;Programming profession;Stress;Mechanics of materials;computational thinking;threshold concepts;Finite Element Analysis;ChatGPT;Scaffolding},
  doi={10.1109/FIE61694.2024.10893514},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10398408,
  author={Chan, Henry C. B.},
  booktitle={2023 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Grading Generative AI-based Assignments Using a 3R Framework}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={With the advent of generative artificial intelligence (GenAI), there is a strong need to revisit the grading or assessment mechanism. In this paper, we present a 3R framework to facilitate the grading of GenAI-based assignments. Basically, there are three essential components: Report, Revise and Reflect. Students should report on how they use GenAI tool(s). They should also revise its output by providing their own input or contributions. Last but not least, they should provide a learning reflection. We also present a 3R rubric for evaluation purposes and propose a GPT formula for determining an effective grade. For illustration purposes, we discuss two cases, covering essay assignments and programming assignments. Furthermore, to evaluate the 3R framework from the student perspective, we present and discuss student survey results. The 3R framework can provide the basis for further research study as well.},
  keywords={Surveys;Systematics;Generative AI;Education;Programming;Reflection;generative AI;ChatGPT;assessment},
  doi={10.1109/TALE56641.2023.10398408},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10578680,
  author={Zönnchen, Benedikt and Thurner, Veronika and Böttcher, Axel},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={On the Impact of ChatGPT on Teaching and Studying Software Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={AI -systems that are based on large language models, such as ChatGPT, have quickly increased their prowess over the last year, and at the same time became readily available. As of now, many disciplines gain experience in using tools such as ChatGPT in a professional setting - and software engineering is no exception. Just as with any new kind of tooling, it is to be expected that in the era of ChatGPT, some traditional skills of the discipline will become rather obsolete, while at the same time new skill sets emerge that will be required from future professionals. Therefore, as educators we must reconsider the skill set we aim at fostering in our software engineering students, and adapt our intended learning outcomes accordingly. Furthermore, we need to adapt both assessment strategies and the teaching and learning methods we employ, in order to provide our students with a study experience that adheres to the principle of constructive alignment.},
  keywords={Learning systems;Taxonomy;Chatbots;Engineering education;Programming profession;Software engineering;software engineering education;learning objectives;teaching methods;assessment;large language models},
  doi={10.1109/EDUCON60312.2024.10578680},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10989326,
  author={Alshammari, Mohammad T.},
  booktitle={2025 4th International Conference on Computing and Information Technology (ICCIT)}, 
  title={An Investigation into ChatGPT-Based Instructional Feedback on Programming Projects}, 
  year={2025},
  volume={},
  number={},
  pages={624-628},
  abstract={Providing high-quality instructional feedback is essential for enhancing learning and motivation. However, the large number of learners and time constraints of instructors can hinder this process. Automating instructional feedback through online learning environments presents a potential solution, but current systems may not adequately address complex learning assignments. Artificial intelligence technologies like ChatGPT can offer an opportunity to deliver feedback efficiently, especially for complex learning tasks. Despite its potential, relatively few studies have examined the distinctions between ChatGPT-generated and expert-based feedback and learners' perceptions of these feedback sources. This study stands among the limited research efforts that seek to compare instructional feedback produced by ChatGPT and that provided by experts, shedding light on learners' subjective assessment of such feedback in the context of programming projects. The findings showed that experts consistently rated programming projects higher than ChatGPT. However, ChatGPT demonstrated strengths in providing more comprehensive textual feedback on the learners' work. Notably, the learners rated ChatGPT feedback more favorably than feedback from domain experts. The study's findings are thoroughly discussed, and future research avenues are outlined.},
  keywords={Codes;Accuracy;Education;Focusing;Learning (artificial intelligence);Writing;Chatbots;Time factors;Information technology;Programming profession;ChatGPT;programming;education;feedback},
  doi={10.1109/ICCIT63348.2025.10989326},
  ISSN={},
  month={April},}@INPROCEEDINGS{10898626,
  author={Lui, Richard Wing Cheung and Bai, Haoran and Zhang, Aiden Wen Yi and Chu, Elvin Tsun Him},
  booktitle={2024 International Conference on Advances in Electrical Engineering and Computer Applications (AEECA)}, 
  title={GPTutor: A Generative AI-powered Intelligent Tutoring System to Support Interactive Learning with Knowledge-Grounded Question Answering}, 
  year={2024},
  volume={},
  number={},
  pages={702-707},
  abstract={With increasing popularity of artificial intelligence (AI) in the education industry, intelligent tutoring system (ITS) powered by AI have been widely adopted to optimize the learning experience. However, the relationship between students’ engagement level of Generative AI (GenAI) and their academic performance is still under exploration. Also current popular GenAI products like ChatGPT suffer from the hallucination problem, which includes factuality, faithfulness, and maliciousness issues in the generated answer. This paper presents GPTutor, an ITS leveraging GenAI to support students' learning processes. GPTutor integrates a Retrieval-Augmented Generation (RAG) pipeline to deliver actual and contextually rich answers aligned to student questions and intended learning outcomes (ILO). A pilot evaluation involving undergraduate and postgraduate students assessed the system’s association with user experience, engagement, and academic performance. Results demonstrated that students generally recognize the effectiveness of GPTutor. Some students also provided insightful feedback on the benefits of GPTutor in improving learning efficiency and some limitations to be addressed. Notably, students with higher engagement levels showed significantly better academic performance on the final exam. This study proposed GPTutor to provide an interactive and knowledge-grounded learning experience and showed the strong association between students’ engagement in GPTutor and academic performance.},
  keywords={Industries;Electrical engineering;Generative AI;Retrieval augmented generation;Pipelines;Education;Learning (artificial intelligence);Computer applications;User experience;Question answering (information retrieval);intelligent tutoring system;generative AI;interactive learning;knowledge-grounded question-answering;retrieval-augmented generation},
  doi={10.1109/AEECA62331.2024.00124},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10499744,
  author={Perera, K. G. D. K. and Wijayanayake, J. and Prasadika, J.},
  booktitle={2024 4th International Conference on Advanced Research in Computing (ICARC)}, 
  title={Factors Affecting the Effectiveness of Generative Artificial Intelligence Apps on University Students' Programming Language Learning in Sri Lanka: A Systematic Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={276-281},
  abstract={In today's era, technology has become pervasive worldwide, significantly facilitating access to learning resources. Notably, the emergence of Generative Artificial Intelligence (AI) has garnered rapid attention and interest in a short period with the introduction of ChatGPT. Many individuals have extensively discussed and evaluated this AI-powered language model, from researchers to casual internet users. Importantly, Generative AI applications are increasingly recognized for their potential in educational contexts. In the realm of education, AI has the potential to significantly broaden and improve teaching and learning in higher education. However, while numerous studies have explored the effectiveness of Generative AI applications in programming language learning, an absence of research examining their impact comprehensively exists. Hence, this study aims to identify the factors that affect the successful utilization of Generative AI applications in the context of undergraduate programming language learning, with a particular emphasis on the viewpoints of university students. A systematic literature review was undertaken to obtain the research objectives, adhering to the Prisma 2020 guidelines, which involved selecting and analyzing 47 prior studies. Mainly this study utilized a systematic literature review to comprehend the factors influencing the effective utilization of Generative AI apps by undergraduate students in their programming learning experiences. Furthermore, the study discusses the advantages and challenges university students face when learning programming using generative AI applications.},
  keywords={Computer languages;Systematics;Generative AI;Bibliographies;Face recognition;Education;Learning (artificial intelligence);Generative AI Apps;Learning;Programming Language Learning;Technologies},
  doi={10.1109/ICARC61713.2024.10499744},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{10975909,
  author={Huang, Min and Ma, Jiarui and Bo, Sun},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Design and Implementation of a Multi-Level Personalized Teaching Framework Based on LLM}, 
  year={2025},
  volume={},
  number={},
  pages={8-14},
  abstract={Personalized teaching is a key focus in modern education, aiming to meet individual student needs and improve learning efficiency. Traditional teaching methods struggle to address student differences in large-scale settings, leading to suboptimal personalized instruction. Recent advancements in generative artificial intelligence (GAI) and large language models (LLMs) offer significant support for the design and implementation of personalized teaching. This paper proposes a multilevel personalized teaching framework that integrates the core elements of the educational system, supporting personalized learning for students, optimizing teaching tasks for teachers, and enhancing resource management for higher education institutions. The framework operates from three perspectives: student, teacher, and institution, offering personalized services throughout the teaching process, including lesson planning, real-time adjustments, and post-class evaluations. The paper discusses the implementation approach based on technologies such as Mixture of Experts (MoE), Chain-of-Thought (CoT) reasoning, and dynamic prompting techniques, along with scenario examples and a validation scheme. The proposed framework provides theoretical support and practical guidance for universities to implement more effective personalized teaching based on AI technologies.},
  keywords={Emotion recognition;Adaptation models;Large language models;Scalability;Education;Transforms;Cognition;Resource management;Testing;Software engineering;Personalized Teaching;Artificial Intelligence;Large Language Models (LLMs);Multi-level;Teaching Framework},
  doi={10.1109/ICEIT64364.2025.10975909},
  ISSN={},
  month={March},}@INPROCEEDINGS{10536194,
  author={Fiore, Marco and Gattullo, Michele and Mongiello, Marina},
  booktitle={2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={First Steps in Constructing an AI-Powered Digital Twin Teacher: Harnessing Large Language Models in a Metaverse Classroom}, 
  year={2024},
  volume={},
  number={},
  pages={939-940},
  abstract={This study proposes a ground-breaking idea at the intersection of Artificial Intelligence and virtual education: the creation of an AI-powered Digital Twin instructor in a Metaverse-based classroom using Large Language Models. We aim to build a teacher avatar capable of dynamic interactions with students, tailored teaching approaches, and contextual response inside a virtual world. The research aims to address two major issues for both students and teachers: the Digital Twin can provide feedbacks to resolve doubts about course content and material; also, it can improve student management and allow teachers to answer the trickiest questions raised by students.},
  keywords={Three-dimensional displays;Metaverse;Conferences;Avatars;Education;User interfaces;Digital twins;Social and professional topics—Professional topics—Computer education programs—Software engineering education;Computing methodologies—Artificial intelligence—Natural language processing—Discourse, dialogue and pragmatics Applied computing—Education—Computer-assisted instruction},
  doi={10.1109/VRW62533.2024.00266},
  ISSN={},
  month={March},}@INPROCEEDINGS{10401713,
  author={Ayman, Shehab Eldeen and El-Seoud, Samir A. and Nagaty, Khaled and Karam, Omar H.},
  booktitle={2023 International Conference on Computer and Applications (ICCA)}, 
  title={The Influence of ChatGPT on Student Learning and Academic Performance}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This study delves into the integration of ChatGPT, an artificial intelligence-driven language model, within undergraduate education. The research scrutinizes the potential advantages, obstacles, and ethical dimensions linked to including ChatGPT in educational practices. It assesses how ChatGPT may impact student engagement, critical thinking, problem-solving abilities, writing proficiency, and the delivery of personalized learning experiences. A survey administered to university faculty members captures their perspectives on ChatGPT usage, encompassing its influence on learning outcomes and academic performance. An internal inquiry at the British University in Egypt found high plagiarism rates in various faculties, with mass media having the highest at 66%, while political science had the lowest at 28%. A survey has been conducted on teaching staff at the university. 75% of teaching staff believes that ChatGPT should be integrated into teaching. However, they are still undecided about whether ChatGPT has affected the teaching and learning process. The study underscores the significance of responsible implementation, faculty training, and continuous assessment to optimize ChatGPT’s benefits while adhering to ethical standards in education. In conclusion, this paper illuminates ChatGPT’s potential as a valuable tool in undergraduate education, underscoring the imperative of preserving critical thinking skills and human interaction in the learning journey.},
  keywords={Surveys;Ethics;Plagiarism;Education;Media;Chatbots;Artificial intelligence;ChatGPT;AI;Education;Plagiarism;Assessment},
  doi={10.1109/ICCA59364.2023.10401713},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10925748,
  author={Sarkar, Sneha and Kushwaha, Suresh Prasad and Sharma, Vandana and Mishra, Nilamadhab and Alkhayyat, Ahmed},
  booktitle={2024 International Conference on Intelligent & Innovative Practices in Engineering & Management (IIPEM)}, 
  title={A Novel LLM enabled Code Snippet Generation Framework}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Large Language Models (LLMs) represent a breakthrough in natural language processing (NLP), leveraging deep learning techniques to achieve exceptional proficiency in code generation, analysis and modification of human languages. These models, characterized by their vast scale and parameter count, like Bidirectional Encoder Representations from Transformers (BERT by Google) and the Generative Pre-trained Transformer series (by OpenAI’s GPT), have revolutionized various applications including text generation, translation, summarization, and question answering. In our paper we investigate the practicality,complications, and significance of using LLMs for code generation. We provide a review analysis of existing LLM models in use and compare their proficiency for code generation. This paper examines the underlying mechanisms of LLMs, specially their ability to grasp the code syntax, semantics, and programming logic from large-scale repositories and their documentations. The models’ training techniques include fine-tuning programming-specific datasets and enhancing the models' competency to generate code snippets that are syntactically correct and contextually relevant.},
  keywords={Training;Codes;Translation;Reviews;Semantics;Syntactics;Transformers;Throughput;Software development management;Context modeling;Large Language Models (LLMs);Code Generation;Natural Language Processing (NLP);Code Quality;Software Development},
  doi={10.1109/IIPEM62726.2024.10925748},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10578564,
  author={Israilidis, John and Chen, Wen-Yuan and Tsakalerou, Mariza},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Software Development and Education: Transitioning Towards AI Enhanced Teaching}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper investigates the impact of large language model (LLM) AI tools, such as ChatGPT and Copilot, on software development education, focusing on usability, efficiency, and effectiveness in real-world scenarios. The research employs a quantitative approach, utilizing a survey of 50 software developers with varying levels of experience. Preliminary findings suggest that AI tools have a positive influence on expediting coding tasks and automating text generation, particularly in the early stages of product development. Challenges related to customization, accuracy, and transparency, as well as concerns about their potential impacts on employment, personal privacy, and ethical boundaries, have been identified. Pointers and initial recommendations for transitioning to AI-enhanced teaching and optimizing interactions between learners and generative AI practices are provided.},
  keywords={Surveys;Privacy;Ethics;Generative AI;Focusing;Software;Product development;AI tools;software development;education},
  doi={10.1109/EDUCON60312.2024.10578564},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10893407,
  author={Crandall, Aaron S. and Fischer, Bryan J. and Crandall, Johannah L.},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: ARTful Insights from a Pilot Study on GPT-Based Automatic Code Reviews in Undergraduate Computer Science Programs}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work in progress research paper describes a pilot study using a Large Language Model (LLM) Generative Pre-Trained Transformer-based (GPT) system that generates industry-style code reviews for student feedback on software development projects in Computer Science 2nd, 3rd, and 4th+ semester classes (CS2, CS3, CS4+) at an ABET accredited baccalaureate institution. Code reviews are a valuable, but work-intensive, component of the software engineering process and provide important training to undergraduate students in the form of mentor-peer knowledge transfer. Participants in this study engaged in iterative experiential learning using the Automatic Review Tool (ART), an artificial intelligence tool to support software engineering as an Automatic Static Analysis Tool in the Continuous Integration pipeline alongside software testing harnesses and code style checkers. This pilot study was based on earlier results from a full computer science second semester (CS2) class $(\mathrm{n}=74)$ to develop an ART-generated code review intervention pilot study with a small group of students in CS2 / 3 and CS4. The project underway uses an experiential learning and iterative feedback process to answer research questions including “Does ART provide accurate and actionable code reviews for students” and “Which levels of students are best prepared to receive and use ART-based code reviews?” During this pilot study, the project used a mixed methods research approach with a series of surveys, code review interventions, and numerical analysis of the code reviews' accuracy. Results showed a reasonable degree of code review accuracy by ART and the students learned code review skills from interaction with the ART-based reviews they received. Ongoing work includes increasing the scale of data collection, using this work to refine and focus the ART-based reviews onto the categories of feedback that students find the most valuable, and building out a more modular tool for wider release in the academic community.},
  keywords={Computer science;Training;Surveys;Codes;Accuracy;Reviews;Subspace constraints;Transformers;Iterative methods;Software engineering;Adaptive computer learning;Computer science;Qualitative;Mixed methods research;Code Reviews;Software Engineering Education},
  doi={10.1109/FIE61694.2024.10893407},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10304857,
  author={Li, Jingyue and Meland, Per Håkon and Notland, Jakob Svennevik and Storhaug, André and Tysse, Jostein Hjortland},
  booktitle={2023 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)}, 
  title={Evaluating the Impact of ChatGPT on Exercises of a Software Security Course}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Along with the development of large language models (LLMs), e.g., ChatGPT, many existing approaches and tools for software security are changing. It is, therefore, essential to understand how security-aware these models are and how these models impact software security practices and education. In exercises of a software security course at our university, we ask students to identify and fix vulnerabilities we insert in a web application using state-of-the-art tools. After ChatGPT, especially the GPT-4 version of the model, we want to know how the students can possibly use ChatGPT to complete the exercise tasks. We input the vulnerable code to ChatGPT and measure its accuracy in vulnerability identification and fixing. In addition, we investigated whether ChatGPT can provide a proper source of information to support its outputs. Results show that ChatGPT can identify 20 of the 28 vulnerabilities we inserted in the web application in a white-box setting, reported three false positives, and found four extra vulnerabilities beyond the ones we inserted. ChatGPT makes nine satisfactory penetration testing and fixing recommendations for the ten vulnerabilities we want students to fix and can often point to related sources of information.},
  keywords={Codes;Education;Chatbots;Software;Security;Software measurement;Task analysis;Software security;artificial intelligence;large language models;ChatGPT;IT education},
  doi={10.1109/ESEM56168.2023.10304857},
  ISSN={},
  month={Oct},}@ARTICLE{10507034,
  author={Kong, Siu-Cheung and Yang, Yin},
  journal={IEEE Transactions on Learning Technologies}, 
  title={A Human-Centered Learning and Teaching Framework Using Generative Artificial Intelligence for Self-Regulated Learning Development Through Domain Knowledge Learning in K–12 Settings}, 
  year={2024},
  volume={17},
  number={},
  pages={1562-1573},
  abstract={The advent of generative artificial intelligence (AI) has ignited an increase in discussions about generative AI tools in education. In this study, a human-centered learning and teaching framework that uses generative AI tools for self-regulated learning development through domain knowledge learning was proposed to catalyze changes in educational practices. The framework illustrates how generative AI tools can revolutionize educational practices and transform the processes of teaching and learning to become human-centered. It emphasizes the evolving roles of teachers, who increasingly become skillful facilitators and humanistic storytellers who craft differentiated instructions and attempt to develop students’ individualized learning. Drawing upon insights from neuroscience, the framework guides students to employ generative AI tools to augment their attentiveness, stimulate active engagement in learning, receive immediate feedback, and encourage self-reflection. The pedagogical approach is also reimagined; teachers equipped with generative AI tools and AI literacy can refine their teaching strategies to better equip students to meet future challenges. The practical application of the framework is demonstrated in a case study involving the development of Chinese language writing ability among primary students within a K–12 educational context. This article also reports the results of a 60-h development programme for teachers. Specifically, providing in-service teachers with cases involving uses of the proposed framework helped them to better understand the generative AI concepts and integrate them into their teaching and learning and increased their perceived ability to design AI-integrated courses that would enhance students’ attention, engagement, confidence, and satisfaction.},
  keywords={Generative AI;Education;Artificial intelligence;Learning (artificial intelligence);Guidelines;Task analysis;Transformers;Generative artificial intelligence;human-centered;learning and teaching framework;pedagogical design;self-regulated learning (SRL)},
  doi={10.1109/TLT.2024.3392830},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10578884,
  author={Ambikairajah, Eliathamby and Sirojan, Tharmakulasingam and Thiruvaran, Tharmarajah and Sethu, Vidhyasaharan},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={ChatGPT in the Classroom: A Shift in Engineering Design Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Artificial intelligence tools like ChatGPT are increasingly being incorporated into our education paradigm. This paper explores how ChatGPT was used in an Electrical Engineering Design Proficiency course at the University of New South Wales in Sydney. The course is a term-long laboratory-based class that centres on independent student work in system design, implementation, and validation. Students were encouraged to consult ChatGPT for design solutions, explanations, and suggestions, with the requirement that they declare any use of AI tools. The assessment process was carefully designed to determine whether responses originated from AI tools or the students' own understanding. Notably, 70% of the fifty students in the class utilised ChatGPT to enhance their understanding of the subject. The paper will also discuss the specific design tasks given to students, the assessment process, and explore ChatGPT's potential as a supportive educational tool in other courses.},
  keywords={Industries;Electrical engineering;Codes;Debugging;Chatbots;Artificial intelligence;Task analysis;Generative AI;ChatGPT;Engineering Education;Engineering Design;Learning and Teaching},
  doi={10.1109/EDUCON60312.2024.10578884},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10923772,
  author={Browning, Jonathan W. and Bustard, John and Anderson, Neil and Galway, Leo},
  booktitle={2024 IEEE 13th International Conference on Engineering Education (ICEED)}, 
  title={Evaluating the Impact of Unrestricted GenAI Usage on Experiential-Based Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This work examines the usage and experience of students using generative AI (genAl) in a engineering entrepreneurship experiential-based learning course. It utilizes a project-based learning approach, where students are in teams of five. The course takes place over a full academic year, i.e., the fall and spring semesters. One of the aims of the course is to be as realistic as possible within an academic setting, with the students trying to create a new technology-based business, in the hopes that they will continue their ventures after the course concludes. Therefore, the teams were allowed to and encouraged to use any genAI they wish throughout the course to assist them. Outside of academia, it would be expected that a start-up founder would use genAl to speed up many aspects of starting their business. Therefore, we want to examine how the students use genAI without there being any constraints. As part of the summative assessment for the course each student peer assesses the members of their team. Included within that they also “peer assess” genAI as though it were another team member, which is a critical reflection of their genAI usage. This work addresses how students use genAI, in experiential-based learning courses when they are allowed to use it any way possible to assist them. The study uses a quantitative and qualitative approach with student data from their “peer assessment” (i.e., critical reflection) of their genAI usage from the academic year 2023/24. Within the peer assessment of the genAI team member the students answer Likert-scale statements to be rated on a five-point semantic differential scale. The results indicate a varied adoption and value of genAI across different project phases. While some students appreciated genAI for speeding up specific tasks, its contribution to creative processes like ideation was less impactful.},
  keywords={Training;Electrical engineering;Generative AI;Soft sensors;Semantics;Project management;Entrepreneurship;Reflection;Springs;Engineering education;computer engineering;critical reflection;electrical engineering;experiential learning;student experience},
  doi={10.1109/ICEED62316.2024.10923772},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10893294,
  author={Ramasamy, Vijayalakshmi and Kulpinski, Eli and Beaupre, Thomas and Antreassian, Aaron and Jeong, Yunhwan and Clarke, Peter J. and Aiello, Anthony and Ray, Charles},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Enhancing CS Education with LAs Using AI-Empowered AIELA Program}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice full paper delves into the transformative role of Learning Assistants (LAs) in Computer Science education, focusing on enhancing student engagement and improving learning outcomes. The LA model, which aligns with Vygotsky's Social Constructivist Learning Theory, fosters an environment of student-centered learning and social interaction. In a pilot study conducted in Spring 2024 at a public university, the LA program is implemented in two computer science courses. A quasi-experimental design has been used to evaluate the impact of LA-facilitated team activities on student learning outcomes. The study compares a control group receiving traditional instruction with an experimental group participating in LA-facilitated team activities. The experimental group engaged in weekly team-based activities, guided by LAs and faculty, to reinforce class concepts and promote collaboration among team members. Student engagement and learning have been evaluated using feedback from students and LAs collected through Discussion Boards (DBs). Preliminary findings suggest that LA-facilitated in-class activities promote active learning and enhance problem-solving skills. LAs provide valuable support and guidance to students, particularly those struggling to understand complex concepts. The study tested a working model of AIELA, an innovative AI-powered chatbot that assists human LAs in supporting students through knowledge-reinforcing questions and multimodal data analysis, powered by OpenAI API's gpt-4-turbo model. This research is a step towards embracing the challenges of modern CS education, inspiring further innovation in this critical field. The findings will benefit educators seeking innovative strategies to enrich student engagement and learning in engineering and computing disciplines.},
  keywords={Technological innovation;Analytical models;Computational modeling;Education;Active learning;Collaboration;Prototypes;Data models;Problem-solving;Springs;Learning Assistant model;active learning strategies;Artificial Intelligence-enabled chatbot;student engagement},
  doi={10.1109/FIE61694.2024.10893294},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10684453,
  author={Bai, Yu and Li, Jun and Shen, Jun and Zhao, Liang},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Investigating the Efficacy of ChatGPT-3.5 for Tutoring in Chinese Elementary Education Settings}, 
  year={2024},
  volume={17},
  number={},
  pages={2102-2117},
  abstract={The potential of artificial intelligence (AI) in transforming education has received considerable attention. This study aims to explore the potential of large language models (LLMs) in assisting students with studying and passing standardized exams, while many people think it is a hype situation. Using primary education as an example, this research investigates whether ChatGPT-3.5 can achieve satisfactory performance on the Chinese Primary School Exams and whether it can be used as a teaching aid or tutor. We designed an experimental framework and constructed a benchmark that comprises 4800 questions collected from 48 tasks in Chinese elementary education settings. Through automatic and manual evaluations, we observed that ChatGPT-3.5’s pass rate was below the required level of accuracy for most tasks, and the correctness of ChatGPT-3.5’s answer interpretation was unsatisfactory. These results revealed a discrepancy between the findings and our initial expectations. However, the comparative experiments between ChatGPT-3.5 and ChatGPT-4 indicated significant improvements in model performance, demonstrating the potential of using LLMs as a teaching aid. This article also investigates the use of the trans-prompting strategy to reduce the impact of language bias and enhance question understanding. We present a comparison of the models' performance and the improvement under the trans-lingual problem decomposition prompting mechanism. Finally, we discuss the challenges associated with the appropriate application of AI-driven language models, along with future directions and limitations in the field of AI for education.},
  keywords={Education;Artificial intelligence;Benchmark testing;Standards;Training;Question answering (information retrieval);Proposals;ChatGPT-3.5;educational intelligence (EI);large language models (LLMs);primary education},
  doi={10.1109/TLT.2024.3464560},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10714575,
  author={Kim, Nam Wook and Ko, Hyung-Kwon and Myers, Grace and Bach, Benjamin},
  booktitle={2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={ChatGPT in Data Visualization Education: A Student Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={109-120},
  abstract={Unlike traditional educational chatbots that rely on pre-programmed responses, large-language model-driven chatbots, such as ChatGPT, demonstrate remarkable versatility to serve as a dynamic resource for addressing student needs from understanding advanced concepts to solving complex problems. This work explores the impact of such technology on student learning in an interdisciplinary, project-oriented data visualization course. Throughout the semester, students engaged with ChatGPT across four distinct projects, designing and implementing data visualizations using a variety of tools such as Tableau, D3, and Vega-lite. We collected conversation logs and reflection surveys after each assignment and conducted interviews with selected students to gain deeper insights into their experiences with ChatGPT. Our analysis examined the advantages and barriers of using ChatGPT, students’ querying behavior, the types of assistance sought, and its impact on assignment outcomes and engagement. We discuss design considerations for an educational solution tailored for data visualization education, extending beyond ChatGPT’s basic interface.},
  keywords={Surveys;Visualization;Knowledge based systems;Education;Data visualization;Oral communication;Chatbots;Dynamic scheduling;Reflection;Interviews;ChatGPT;large language model;data visualization;education;project-based learning},
  doi={10.1109/VL/HCC60511.2024.00022},
  ISSN={1943-6106},
  month={Sep.},}@INPROCEEDINGS{10893214,
  author={Haldar, Susmita and Pierce, Mary and Capretz, Luiz Fernando},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: Assessing the Effectiveness of ChatGPT in Preparatory Testing Activities}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This innovative practice WIP paper describes a research study that explores the integration of ChatGPT into the software testing curriculum and evaluates its effectiveness compared to human-generated testing artifacts. In a Capstone Project course, students were tasked with generating preparatory testing artifacts using ChatGPT prompts, which they had previously created manually. Their understanding and the effectiveness of the Artificial Intelligence generated artifacts were assessed through targeted questions. The results, drawn from this in-class assignment at a North American community college indicate that while ChatGPT can automate many testing preparation tasks, it cannot fully replace human expertise. However, students already familiar with Information Technology at the postgraduate level, found the integration of ChatGPT into their workflow to be straightforward. The study suggests that AI can be gradually introduced into software testing education to keep pace with technological advancements.},
  keywords={Software testing;Chatbots;Artificial intelligence;North America;Information technology;Software Testing Education;ChatGPT;Black-box Testing;Product Testing;Higher Education},
  doi={10.1109/FIE61694.2024.10893214},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10427187,
  author={Ma'ruf, Harry and Aditya, Bayu Rima and Hernawati, Elis and Gunawan, Tedi and Wijayanto, Pikir Wisnu},
  booktitle={2023 8th International Conference on Information Technology and Digital Applications (ICITDA)}, 
  title={Usability Testing of ChatGPT Website as a Medium for Task Collaboration Using the System Usability Scale Method (SUS)}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This study aims to determine the level of usability of the ChatGPT website for students at Telkom University Bandung as a means of collaborating on student assignments. ChatGPT is an Artificial Intelligence application that uses a chatbot to have human-like conversations. ChatGPT is widely used by students to help with their academic assignments, such as scientific papers, explaining the answer to a question, and even the programming language of an application. With the various uses of ChatGPT, many students at Telkom University Bandung use ChatGPT to help do their assignments. To conduct this research, the method used is System Usability Scale. This method is done by distributing questionnaires to Telkom University Bandung students totaling 102 respondents who have used ChatGPT. Consists of 15 questions for analysis. The SUS score results got 71.17, these results got the predicate “GOOD” in the Adjective Ratings assessment and “Acceptable” in the Acceptable Range. The SUS score results indicate that the ChatGPT usability level is good and can be well received by students. The analyzed questionnaire received an average answer of 3.65 which indicates that ChatGPT functions well and provides appropriate answers to student tasks. This explains that the ChatGPT website can be used well by Telkom University students in its use to assist with student assignments. This research data can be used as empirical data to develop student assignment collaboration.},
  keywords={Collaboration;Oral communication;Chatbots;Usability;Task analysis;Information technology;Testing;system usability scale;ChatGPT;student assignment},
  doi={10.1109/ICITDA60835.2023.10427187},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10893132,
  author={Dickey, Ethan and Bejarano, Andres},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={GAIDE: A Framework for Using Generative AI to Assist in Course Content Development}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={Contribution: This research-to-practice full paper presents “GAIDE: Generative AI for Instructional Development and Education,” introducing a pragmatic and systematic framework for employing Generative AI (GenAI) in the development of educational content. Unlike existing frameworks, GAIDE emphasizes practical applicability for educators, facilitating the creation of diverse, engaging, and academically sound materials. The novel aspect of our approach lies in its detailed methodology for integrating GenAI into curriculum design processes, thereby reducing instructors' workload and improving the quality of educational materials. Through GAIDE, we contribute a distinct, adaptable model for leveraging technological advancements in education, providing a foundational step towards more efficient and effective instructional material development. Background: The motivation for our study emerges from the increasing demand for innovative and engaging educational content, coupled with the notable rise in Generative AI (GenAI) utilization among students for academic tasks. Our investigations reveal that nearly half of students engage with GenAI tools for completing homework assignments, highlighting a significant shift in study behaviors and the potential for technology to shape educational practices. This scenario presents a dual challenge for educators: to adapt to and incorporate these emerging technologies into their teaching methodologies, not merely to keep pace with technological advancements but to leverage them in fostering a more dynamic and inclusive learning environment. This research addresses these challenges by offering a concrete, adaptable solution, aiming to reshape the landscape of educational content creation and its application across diverse learning settings. Intended Outcomes: The primary objectives of introducing GAIDE are to: 1) Streamline the course content development process for educators, 2) Foster the creation of dynamic, engaging, and varied educational materials, and 3) Demonstrate the practical utility of GenAI in enhancing instructional design, potentially setting a precedent for its adoption in diverse educational contexts. Application Design: GAIDE was conceived out of a necessity to efficiently harness GenAI's potential in education. The application design is rooted in constructivist learning theory and TPCK, emphasizing the importance of integrating technology in a manner that complements pedagogical goals and content knowledge. Our Outcomes-Based Course Design approach aids educators in crafting effective GenAI prompts and guides them through interactions with GenAI tools, both of which are critical for generating high-quality, contextually appropriate content. Findings: Preliminary evaluation of GAIDE indicates its effectiveness in mitigating the instructional challenges associated with content creation. Educators reported a significant reduction in the time and effort required to develop course materials, without compromising on the breadth or depth of the content. Moreover, the use of GenAI has shown promise in deterring conventional cheating methods, suggesting a positive impact on academic integrity and student engagement.},
  keywords={Adaptation models;Systematics;Generative AI;Shape;Education;Aerodynamics;Pragmatics;─Generative AI (GenAI);course content development;content generation framework;instructional workload reduction;instructional design;course design;faculty development},
  doi={10.1109/FIE61694.2024.10893132},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10590395,
  author={Ogunleye, Olalekan Samuel},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={ChatGPT Implications on Higher Education: Educational Apocalypse or Educational Reboot? A Developing Countries Perspective}, 
  year={2023},
  volume={},
  number={},
  pages={1685-1690},
  abstract={Artificial intelligence has disrupted many industries, and education is no exception. ChatGPT, a Large Language Model (LLM), has emerged as a promising tool for boosting learning experiences and altering traditional teaching methods in higher education. ChatGPT can be considered a combination of chat and a language model. This article investigates ChatGPT's effects on higher education, focusing on the opportunities and obstacles that may arise. This paper tries to answer whether ChatGPT will lead to an educational apocalypse or a much-needed reboot in higher education by assessing the influence of ChatGPT on educators' usage, student involvement, individualised learning, and administrative operations. In its conclusion, the article explores the prospects of incorporating ChatGPT into higher education and offers some ideas on how to do so successfully.},
  keywords={Industries;Scientific computing;Large language models;Education;Focusing;Developing countries;Chatbots;ChatGPT;Artificial Intelligence;Higher Education},
  doi={10.1109/CSCI62032.2023.00278},
  ISSN={2769-5654},
  month={Dec},}@ARTICLE{10813359,
  author={Abdelgadir Mohamed, Yasir and Mohamed, Abdul Hakim H. M. and Khanan, Akbar and Bashir, Mohamed and Adiel, Mousab A. E. and Elsadig, Muawia A.},
  journal={IEEE Access}, 
  title={Navigating the Ethical Terrain of AI-Generated Text Tools: A Review}, 
  year={2024},
  volume={12},
  number={},
  pages={197061-197120},
  abstract={This review examines the ethical, social, and technical challenges posed by AI-generated text tools, focusing on their rapid advancement and widespread adoption. An exhaustive literature search across many databases, strict inclusion/exclusion criteria, and a rigorous analysis procedure are all parts of our systematic review technique. This guarantees an impartial and complete study of the current status of AI-generated text tools. The study analyzes prominent language models, including GPT-3, GPT-4, LaMDA, PaLM, Claude, Jasper, and Llama 2, evaluating their capabilities in natural language processing and generation. The analysis reveals significant advancements, with GPT-3 demonstrating a 92% accuracy rate on standard natural language understanding benchmarks, outperforming LaMDA (88%) and PaLM (85%). To illustrate real-world implications, the review presents a case study of ChatGPT’s application in healthcare, where it achieved 80% consistency with expert opinions in assessing acute ulcerative colitis. This case highlights both the potential benefits and ethical concerns of AI in critical domains. Quantitative bias analysis shows that GPT-3 generated biased content in 15% of test cases involving sensitive topics, a higher rate than LaMDA (12%) and PaLM (10%). We provide an in-depth analysis of fairness and bias issues, particularly in image generation tasks depicting professional roles. Our research synthesizes insights from technical advancements, ethical considerations, and real-world applications across healthcare, education, and creative sectors. We address critical privacy concerns and data protection challenges, noting struggles in AI-generated text detection and investigating AI’s potential in enabling cyberattacks. We underscore the need for comprehensive governance systems and multidisciplinary cooperation. To provide a cohesive analysis of the ethical considerations surrounding AI-generated text tools, we employ a multifaceted ethical framework drawing on established theories. Utilitarianism, which seeks to maximize happiness for everyone; deontology, which places an emphasis on right and wrong; and Virtue Ethics, which analyzes the moral nature of deeds and actors, are all included in this framework. In this article, we use this approach to investigate AI ethics from a variety of angles, including privacy, prejudice, and social implications, as well as concerns of justice and fairness. Moreover, the study critically examines existing and proposed legal frameworks addressing AI ethics, identifying regulatory gaps and proposing adaptive policy recommendations to address the unique challenges posed by AI-generated text tools. Our review contributes a critical analysis of AI-generated text tools, their impacts, and the need for responsible innovation. The study provides precise guidelines for the ethical development and implementation of AI, highlighting the need to strike a balance between technical progress and ethical concerns to guarantee that AI technologies have a beneficial effect on society while protecting human values. The emergence of generative artificial intelligence (AI) signifies a substantial revolution in our methods of interacting with language and information.},
  keywords={Ethics;Artificial intelligence;Reviews;Generative AI;Analytical models;Privacy;Object recognition;Technological innovation;Search problems;Industries;Generative AI;text generation;ethics},
  doi={10.1109/ACCESS.2024.3521945},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10555768,
  author={Idialu, Oseremen Joy and Mathews, Noble Saji and Maipradit, Rungroj and Atlee, Joanne M. and Nagappan, Meiyappan},
  booktitle={2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR)}, 
  title={Whodunit: Classifying Code as Human Authored or GPT-4 generated- A case study on CodeChef problems}, 
  year={2024},
  volume={},
  number={},
  pages={394-406},
  abstract={Artificial intelligence (AI) assistants such as GitHub Copilot and ChatGPT, built on large language models like GPT-4, are revolutionizing how programming tasks are performed, raising questions about whether code is authored by generative AI models. Such questions are of particular interest to educators, who worry that these tools enable a new form of academic dishonesty, in which students submit AI-generated code as their work. Our research explores the viability of using code stylometry and machine learning to distinguish between GPT-4 generated and human-authored code. Our dataset comprises human-authored solutions from CodeChef and AI-authored solutions generated by GPT-4. Our classifier outperforms baselines, with an F1-score and AUC-ROC score of 0.91. A variant of our classifier that excludes gameable features (e.g., empty lines, whitespace) still performs well with an F1-score and AUC-ROC score of 0.89. We also evaluated our classifier on the difficulty of the programming problem and found that there was almost no difference between easier and intermediate problems, and the classifier performed only slightly worse on harder problems. Our study shows that code stylometry is a promising approach for distinguishing between GPT-4 generated code and human-authored code.},
  keywords={Codes;Focusing;Machine learning;Software;Robustness;Regulation;Task analysis;code stylometry;chatgpt;AI code;GPT-4 generated code;authorship profiling;software engineering},
  doi={},
  ISSN={2574-3864},
  month={April},}@INPROCEEDINGS{10795589,
  author={Tona, Claudia and Juárez-Ramírez, Reyes and Jiménez, Samantha and Durán, Mayra},
  booktitle={2024 12th International Conference in Software Engineering Research and Innovation (CONISOFT)}, 
  title={Exploring LLM Tools Through the Eyes of Industry Experts and Novice Programmers}, 
  year={2024},
  volume={},
  number={},
  pages={313-321},
  abstract={At present, Large Language Models (LLM) and Generative AI models have emerged and impacted industry and society. LLMs are Artificial intelligence (AI) systems designed to understand and generate human language. The rise in popu-1arity of LLM-based systems has motivated research into their use in education, including code generation tools, automated feedback systems, and support for student software projects. The release of ChatGPT™ marked a significant milestone, providing an accessible tool for IA interaction. ChatGPT™ has gained popularity among students, not only in software areas. This study analyzes the perspectives of software engineering students and software engineers on using LLM tools such as ChatGPT™ for software development projects. In this study, we use a questionnaire to analyze different viewpoints and graphics to show the experiment results between these groups. The findings of this study are expected to provide valuable contributions to the understanding of how LLM tools are perceived in the context of software development and their potential implications for educational practices and industry standards.},
  keywords={Industries;Graphics;Technological innovation;Generative AI;Large language models;Software;Standards;Programming profession;Software engineering;Software development management;Programming Education;Generative AI;Large Language Models;Software Engineering},
  doi={10.1109/CONISOFT63288.2024.00048},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10578855,
  author={Zdravkova, Katerina and Dalipi, Fisnik and Ahlgren, Fredrik and Ilijoski, Bojan and Olsson, Tobias},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Unveiling the Impact of Large Language Models on Student Learning: A Comprehensive Case Study}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Large language models (LLMs) have achieved planetary popularity and have become accepted in higher education. On the basis of face-to-face interviews, a survey examining students' attitudes about the integration of LLM into education, and our own academic experience, we defined a realistic solution for creating assignments. It embraces essay writing as well as various aspects of computer programming. The experiments were carried out during the winter semester of academic 2023/24 at two universities from two different countries. This paper presents the experience gained in the creation of two different computer science assignments with and without the use of LLM. Comparative analysis refers on three approaches: traditional or manual assignment preparation without using any LLM; full reliance on LLMs; and a hybrid mode, depending on the amount of application of the LLM in the preparation of the assignment. The proposed solution was evaluated quantitatively, with the aim of becoming a benchmark for examining the integration of LLM studies into higher education. Findings reveal the importance of hybrid mode, as the most preferred approach among students.},
  keywords={Surveys;Large language models;Manuals;Writing;Benchmark testing;Interviews;Engineering education;Programming profession;AI learning tool;ChatGPT;large language models;higher education;practical implementation},
  doi={10.1109/EDUCON60312.2024.10578855},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10342970,
  author={Lauren, Paula and Watta, Paul},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Work-in-Progress: Integrating Generative AI with Evidence-based Learning Strategies in Computer Science and Engineering Education}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Generative AI assistants are AI-powered applications that can provide personalized responses to user queries or prompts. A variety of AI assistants have recently been released, and among the most popular is OpenAI's ChatGPT. In this work-in-progress in innovative practice, we explore evidence-based learning strategies and the integration of Generative AI for computer science and engineering education. We expect this research will lead to innovative pedagogical approaches to enhance undergraduate computer science and engineering education. In particular, we describe how ChatGPT was used in two computing-based courses: a Junior-level course in database systems and a Senior-level class in mobile application development. We identify four evidence-based learning strategies: well-defined learning goals, authentic learning experiences, structured learning progression, and strategic assessment. We align these strategies with the two aforementioned courses and evaluate the usefulness of ChatGPT specifically in achieving the learning goals. Combining Generative AI with evidence-based learning has the potential to transform modern education into a more personalized learning experience.},
  keywords={Computer science;Transforms;Chatbots;Mobile communication;Database systems;Artificial intelligence;Engineering education;Generative AI;Artificial Intelligence in Education (AIEd);pedagogy},
  doi={10.1109/FIE58773.2023.10342970},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10747947,
  author={Rush, Libby and Fogle, Eli and Eden, Sarah and Urban, Alexandra D. and Tijare, Harshal and Mooney, Shannon},
  booktitle={2024 IEEE Digital Education and MOOCS Conference (DEMOcon)}, 
  title={Generative Artificial Intelligence Driving More Efficient and Effective Course Optimizations}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The purpose of this study was to explore the efficacy of Generative Artificial Intelligence (GenAI) in optimizing online degree courses to enhance student retention and performance. Within the context of online learning platforms, there is a challenge in efficiently and effectively updating course content, which can impact the quality and relevance of the experience. The aim of this pilot was to utilize GenAI to create and augment educational resources, thus improving the clarity, scaffolding, and engagement of the online degree coursework. The methods employed in this pilot study included a quasi-experimental design where a Performance-Based Admissions (PBA) degree course was selected, its content was optimized using GenAI, and the impact was measured using a Difference-in-Differences (DID) analysis comparing optimized and non-optimized courses. The results indicate a 6% increase in course pass rates and significant improvements in midterm pass rates, average final grades, and the percentage of assignments submitted on time within the optimized course. Given these results, we estimate a 3% to 13% positive impact on second term persistence if all first-term courses received a similar GenAI optimization. The impact of this study is significant, demonstrating the potential of GenAI to revolutionize educational practices by providing quickly-produced, high-quality, low-cost content that enhances student learning outcomes. It supports the shift towards student-centered learning approaches and can be particularly beneficial in resource-constrained environments. In conclusion, the study underscores the transformative role of GenAI in education and emphasizes the need for ethical and responsible use to empower students and improve learning outcomes.},
  keywords={Measurement;Ethics;Computer aided instruction;Electronic learning;Generative AI;Navigation;Engineering profession;Education;Problem-solving;Optimization;GenAI;online teaching;degrees;performance-based admissions;content optimization},
  doi={10.1109/DEMOcon63027.2024.10747947},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11016479,
  author={Qadir, Junaid},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Generative AI in Undergraduate Classrooms: Lessons from Implementing a Customized GPT Chatbot for Learning Enhancement}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The advent of Generative Artificial Intelligence (GenAI) has sparked significant interest in education, offering ways to support learning, personalize student experiences, and boost engagement. Generative AI holds the promise of transforming education with personalized learning, instant feedback, and assistance with complex problem-solving. However, its integration into classrooms requires careful management due to ethical concerns, misinformation risks, and potential misuse. While many articles explore the potential of generative AI in education, empirical studies on its real-world classroom use are limited. This paper presents an experience report on deploying a customized GPT-powered chatbot at Qatar University to support learning in two undergraduate courses: Data and Computer Communications Networks (technical) and Computer Ethics. Working across these diverse courses allows a thorough analysis of generative AI's strengths and weaknesses in different academic contexts, offering a comprehensive evaluation of its applicability and effectiveness. We used a mixed-methods approach with over 100 students, collecting quantitative and qualitative data via questionnaires to assess the chatbot's impact. Findings are analyzed with established theoretical frameworks to contextualize the pedagogical impact of generative AI, aligned with UNESCO guidelines for ethical integration. This paper details the chatbot's technical customization to meet course-specific needs, provides evidence-based insights into practical challenges and opportunities, and offers strategic recommendations for effective AI-assisted pedagogy. Directions for further research are also outlined to explore and refine the role of generative AI in classroom settings. By examining two distinct courses, this study demonstrates how generative AI can be adapted across academic disciplines for more nuanced applications in education.},
  keywords={Ethics;Generative AI;Terminology;Learning (artificial intelligence);Chatbots;Reflection;Real-time systems;Problem-solving;Fake news;Guidelines;ChatGPT;generative AI;pedagogy;education},
  doi={10.1109/EDUCON62633.2025.11016479},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10410383,
  author={Shaikh, Sarang and Daudpota, Sher Muhammad and Yayilgan, Sule Yildirim and Sindhu, Sindhu},
  booktitle={2023 International Conference on Frontiers of Information Technology (FIT)}, 
  title={Exploring the potential of large-language models (LLMs) for student feedback sentiment analysis}, 
  year={2023},
  volume={},
  number={},
  pages={214-219},
  abstract={Large-language models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing (NLP) tasks, including synthetic text generation, classification, question answering, and language translation. In this paper, we explore the potential of leveraging these LLMs for sentiment analysis or opinion mining of students’ feedback about their teachers, typically collected at the end of a course. Analyzing students’ sentiments is crucial for academic decision-making. We conducted our study by employing ChatGPT, a popular LLM, to perform sentiment classification on a diverse dataset of student feedback. This dataset was collected and scientifically labeled with sentiment annotations by our experienced annotators team. Our findings demonstrate the immense promise of using LLMs in accurately classifying students’ feedback into positive, negative, or neutral sentiments. The ChatGPT model achieved an impressive overall F1-score of 88%, outperforming state-of-the-art deep learning and transformer-based models. These results show the significance of LLMs in advancing sentiment analysis in educational contexts and provide valuable insights for educators and administrators to enhance the learning experience.},
  keywords={Deep learning;Sentiment analysis;Analytical models;Chatbots;Transformers;Data models;Task analysis;chatgpt;large language models;transformers;sentiment analysis;student feedback;deep learning},
  doi={10.1109/FIT60620.2023.00047},
  ISSN={2473-7569},
  month={Dec},}@INPROCEEDINGS{10605325,
  author={Liu, Zhengyuan and Yin, Stella Xin and Lee, Carolyn and Chen, Nancy F.},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Scaffolding Language Learning via Multi-modal Tutoring Systems with Pedagogical Instructions}, 
  year={2024},
  volume={},
  number={},
  pages={1258-1265},
  abstract={Intelligent tutoring systems (ITSs) that imitate human tutors and aim to provide immediate and customized instructions or feedback to learners have shown their effectiveness in education. With the emergence of generative artificial intelligence, large language models (LLMs) further entitle the systems to complex and coherent conversational interactions. These systems would be of great help in language education as it involves developing skills in communication, which, however, drew relatively less attention. Additionally, due to the complicated cognitive development at younger ages, more endeavors are needed for practical uses. Scaffolding refers to a teaching technique where teachers provide support and guidance to students for learning and developing new concepts or skills. It is an effective way to support diverse learning needs, goals, processes, and outcomes. In this work, we investigate how pedagogical instructions facilitate the scaffolding in ITSs, by conducting a case study on guiding children to describe images for language learning. We construct different types of scaffolding tutoring systems grounded in four fundamental learning theories: knowledge construction, inquiry-based learning, dialogic teaching, and zone of proximal development. For qualitative and quantitative analyses, we build and refine a seven-dimension rubric to evaluate the scaffolding process. In our experiment on GPT-4V, we observe that LLMs demonstrate strong potential to follow pedagogical instructions and achieve self-paced learning in different student groups. Moreover, we extend our evaluation framework from a manual to an automated approach, paving the way to benchmark various conversational tutoring systems.},
  keywords={Statistical analysis;Generative AI;Large language models;Education;Manuals;Benchmark testing;Intelligent Tutoring Systems;Scaffolding;Multimodal Language Models},
  doi={10.1109/CAI59869.2024.00223},
  ISSN={},
  month={June},}@INPROCEEDINGS{10386291,
  author={Gan, Wensheng and Qi, Zhenlian and Wu, Jiayang and Lin, Jerry Chun-Wei},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Large Language Models in Education: Vision and Opportunities}, 
  year={2023},
  volume={},
  number={},
  pages={4776-4785},
  abstract={With the rapid development of artificial intelligence technology, large language models (LLMs) have become a hot research topic. Education plays an important role in human social development and progress. Traditional education faces challenges such as individual student differences, insufficient allocation of teaching resources, and assessment of teaching effectiveness. Therefore, the applications of LLMs in the field of digital/smart education have broad prospects. The research on educational large models (EduLLMs) is constantly evolving, providing new methods and approaches to achieve personalized learning, intelligent tutoring, and educational assessment goals, thereby improving the quality of education and the learning experience. This article aims to investigate and summarize the application of LLMs in smart education. It first introduces the research background and motivation of LLMs and explains the essence of LLMs. It then discusses the relationship between digital education and EduLLMs and summarizes the current research status of educational large models. The main contributions are the systematic summary and vision of the research background, motivation, and application of large models for education (LLM4Edu). By reviewing existing research, this article provides guidance and insights for educators, researchers, and policy-makers to gain a deep understanding of the potential and challenges of LLM4Edu. It further provides guidance for further advancing the development and application of LLM4Edu, while still facing technical, ethical, and practical challenges requiring further research and exploration.},
  keywords={Ethics;Analytical models;Systematics;Machine vision;Education;Educational technology;Big Data;artificial intelligence;LLMs;smart education;vision;opportunities},
  doi={10.1109/BigData59044.2023.10386291},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11023957,
  author={Kumar, Abhishek and Sankar, Sandhya and Haiduc, Sonia and Das, Partha Pratim and Chakrabarti, Partha Pratim},
  booktitle={2025 IEEE/ACM 47th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)}, 
  title={LLMs as Evaluators: A Novel Approach to Commit Message Quality Assessment}, 
  year={2025},
  volume={},
  number={},
  pages={111-115},
  abstract={Evaluating the quality of commit messages is a challenging task in software engineering. Existing evaluation approaches, such as automatic metrics like BLEU, ROUGE and METEOR, as well as manual human assessments have notable limitations. Automatic metrics often overlook semantic relevance and context, while human evaluations are time consuming and costly. To address these challenges, we explore the potential of using Large Language Models (LLMs) as an alternative method for commit message evaluation. We conducted two tasks using state-of-the-art LLMs, GPT-4o, LLaMA 3.1 (70B and 8B), and Mistral Large, to assess their capability in evaluating commit messages. Our findings show that LLMs can effectively identify relevant commit messages and align well with human judgment, demonstrating their potential to serve as reliable automated evaluators. This study provides a new perspective on utilizing LLMs for commit message assessment, paving the way for scalable and consistent evaluation methodologies in software engineering.},
  keywords={Measurement;Large language models;Semantics;Manuals;Software reliability;Quality assessment;Meteors;Software engineering;Large Language Models;Commit Messages;Evaluation;Human Judgement},
  doi={10.1109/ICSE-NIER66352.2025.00028},
  ISSN={2832-7632},
  month={April},}@INPROCEEDINGS{10663042,
  author={Datta, Soma},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Using Generative Artificial Intelligence Tools in Software Engineering Courses}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={This pilot study focuses on allowing students to use generative Artificial intelligence (AI) tools for their learning and assignments. Therefore, the study looks to improve the assignments to assess their learning. Students in their course have both formative and summative assessments. Both these assessments consist of writing, quizzes, and presentations. These students are both from the undergraduate and graduate levels. The study seeks to make the assessments sustainable for all teaching levels. The change in writing assessment would help to assess students better. The assignments are tested on ChatGPT and Bard to check if a student gets a passing grade using an AI tool.},
  keywords={Generative AI;Education;Learning (artificial intelligence);Writing;Chatbots;Software engineering;Generative Artificial Intelligence;Software Engineering;Assessment;AI tools},
  doi={10.1109/CSEET62301.2024.10663042},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10935410,
  author={Zhao, Lili and Yuan, Feng and Miao, Long},
  booktitle={2024 14th International Conference on Information Technology in Medicine and Education (ITME)}, 
  title={Exploration of the Reform of Programming Courses Based on Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={869-873},
  abstract={With the rapid development of artificial intelligence technology, the application of Generative AI in the field of education is becoming increasingly widespread. This article uses CiteSpace to visually analyze the development trajectory, hot trends, and cutting-edge research of artificial intelligence applications in the field of education in China. It clarifies the necessity and feasibility of integrating generative AI with education and proposes a programming course teaching reform model based on generative AI. The aim is to explore how to use generative AI technology to reform programming courses, solve many problems in traditional teaching models through student portraits, intelligent generation of teaching content, automatic evaluation of student assignments, and providing personalized learning suggestions, in order to improve education quality and students' learning efficiency.},
  keywords={Adaptive learning;Data analysis;Accuracy;Generative AI;Education;Learning (artificial intelligence);Market research;Trajectory;Information technology;Programming profession;generative AI;programming courses;curriculum reform},
  doi={10.1109/ITME63426.2024.00174},
  ISSN={2474-3828},
  month={Sep.},}@INPROCEEDINGS{10651492,
  author={Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Teaching UML using a RAG-based LLM}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Teaching the Unified Modelling Language (UML) is a critical task in the frame of Software Engineering courses. Teachers need to understand the students’ behavior along with their modeling activities to provide suggestions and feedback to avoid more frequent mistakes and improve their capabilities. This paper presents a novel approach for teaching the UML in Software Engineering courses, focusing on understanding and improving student behavior and capabilities during modeling activities. It introduces a cloud-based tool that captures and analyzes UML diagrams created by students during their interactions with a UML modeling tool. The key aspect of the proposal is the integration of a Retrieval Augmented Generation Large Language Model (RAG-based LLM), which generates insightful feedback for students by leveraging knowledge acquired during the modeling process.The effectiveness of this method is demonstrated through an experiment involving a substantial dataset comprising 5,120 labeled UML models. The validation process confirms the performance of the UML RAG-based LLM in providing relevant feedback related to entities and relationships in the students’ models. Additionally, a qualitative analysis highlights the user satisfaction, underscoring its potential as a valuable tool in enhancing the learning experience in software modeling education.},
  keywords={Analytical models;Accuracy;Statistical analysis;Unified modeling language;Education;Software;Robustness;Deep Learning;Generative AI;LLMs;Computing Education;UML;Software Modelling},
  doi={10.1109/IJCNN60899.2024.10651492},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10548827,
  author={Nam, Daye and Macvean, Andrew and Hellendoorn, Vincent and Vasilescu, Bogdan and Myers, Brad},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE)}, 
  title={Using an LLM to Help with Code Understanding}, 
  year={2024},
  volume={},
  number={},
  pages={1184-1196},
  abstract={Understanding code is challenging, especially when working in new and complex development environments. Code comments and documentation can help, but are typically scarce or hard to navigate. Large language models (LLMs) are revolutionizing the process of writing code. Can they do the same for helping understand it? In this study, we provide a first investigation of an LLM-based conversational UI built directly in the IDE that is geared towards code understanding. Our IDE plugin queries OpenAI's GPT-3.5-turbo model with four high-level requests without the user having to write explicit prompts: to explain a highlighted section of code, provide details of API calls used in the code, explain key domainspecific terms, and provide usage examples for an API. The plugin also allows for open-ended prompts, which are automatically contextualized to the LLM with the program being edited. We evaluate this system in a user study with 32 participants, which confirms that using our plugin can aid task completion more than web search. We additionally provide a thorough analysis of the ways developers use, and perceive the usefulness of, our system, among others finding that the usage and benefits differ between students and professionals. We conclude that in-IDE prompt-less interaction with LLMs is a promising future direction for tool builders.},
  keywords={Codes;Navigation;Prototypes;Documentation;Task analysis;Web search;Software engineering;User study;LLM;Program comprehension;Information support;Developer tool},
  doi={10.1145/3597503.3639187},
  ISSN={1558-1225},
  month={April},}@INPROCEEDINGS{10683837,
  author={Dumitran, Adrian Marius and Badea, Adrian Cǎtǎlin and Muscalu, Stefan-Gabriel},
  booktitle={2024 International Conference on INnovations in Intelligent SysTems and Applications (INISTA)}, 
  title={Evaluating the Performance of Large Language Models in Competitive Programming: A Multi-Year, Multi-Grade Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This study explores the performance of large language models (LLMs) in solving competitive programming problems from the Romanian Informatics Olympiad at the county level. Romania, a leading nation in computer science competitions, provides an ideal environment for evaluating LLM capabilities due to its rich history and stringent competition standards. We collected and analyzed a dataset comprising 304 challenges from 2002 to 2023, focusing on solutions written by LLMs in C++ and Python for these problems. Our primary goal is to understand why LLMs perform well or poorly on different tasks. We evaluated various models, including closed-source models like GPT-4 and open-weight models such as CodeLlama and RoMistral, using a standardized process involving multiple attempts and feedback rounds. The analysis revealed significant variations in LLM performance across different grades and problem types. Notably, GPT-4 showed strong performance, indicating its potential use as an educational tool for middle school students. We also observed differences in code quality and style across various LLMs.},
  keywords={Technological innovation;Codes;Large language models;Focusing;History;Intelligent systems;Informatics;Large Language Models (LLMs);Benchmark;IOI;Code Generation;AI in Education;C++;Python},
  doi={10.1109/INISTA62901.2024.10683837},
  ISSN={2768-7295},
  month={Sep.},}@INPROCEEDINGS{10684637,
  author={Liu, Yangtao and Liu, Hengyuan and Yang, Zezhong and Li, Zheng and Liu, Yong},
  booktitle={2024 IEEE 24th International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={Empirical Evaluation of Large Language Models for Novice Program Fault Localization}, 
  year={2024},
  volume={},
  number={},
  pages={180-191},
  abstract={Integrating Large Language Models (LLMs) into software fault localization represents a significant advancement in improving debugging efficiency for programmers. However, novice program fault localization, which is essential for computer science education, has not been thoroughly investigated in previous studies. In contrast to industrial programs target practical functionality, novice programs primarily deal with individual algorithmic issues. The distinct logic structures between novice and industrial programs can impact how effectively LLM understand and process them. Moreover, this difference reveals the inapplicability of the Competent Programmer Hypothesis, a fundamental assumption in industrial fault localization, to novice program fault localization. Therefore, industrial methodologies are unsuitable for novice programming, emphasizing the need for our empirical studies. To fill this gap, we evaluate LLMs’ effectiveness in localizing faults for novice programs in statement level. Using the widely used novice programs dataset Codeflaws and Condefects, we compare the performance of two commercial LLMs (i.e., ChatGPT-3.5 and ChatGPT-4) and three open-source LLMs (i.e., ChatGLM3, Llama2, and Code Llama) against traditional fault localization methods, examining their accuracy and overlap. Additionally, we investigate how prompt engineering improves localization precision. Our findings show ChatGPT-4’s overall superior performance, with ChatGPT-3.5 exhibiting minor advantages in certain cases. ChatGPT-4 outperforms the traditional methods with best performance by 592% and 137% on Codeflaws and Condefects. Specifically, each method exhibits unique strengths in localizing novice programming faults. Moreover, carefully crafted prompts can improve LLMs’ precision. These insights underscore the promising potential of utilizing LLMs for fault localization in novice programming.},
  keywords={Location awareness;Codes;Accuracy;Large language models;Software algorithms;Software quality;Reliability engineering;Large Language Model;Fault Localization;Empirical Study;Novice Programming;Prompt Engineering},
  doi={10.1109/QRS62785.2024.00027},
  ISSN={2693-9177},
  month={July},}@INPROCEEDINGS{10734431,
  author={Grandel, Skyler and Schmidt, Douglas C. and Leach, Kevin},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={Applying Large Language Models to Enhance the Assessment of Parallel Functional Programming Assignments}, 
  year={2024},
  volume={},
  number={},
  pages={102-110},
  abstract={Courses in computer science (CS) often assess student programming assignments manually, with the intent of providing in-depth feedback to each student regarding correctness, style, efficiency, and other quality attributes. As class sizes increase, however, it is hard to provide detailed feedback consistently, especially when multiple assessors are required to handle a larger number of assignment submissions. Large language models (LLMs), such as ChatGPT, offer a promising alternative to help automate this process in a consistent, scalable, and minimally-biased manner.This paper explores ChatGPT-4’s scalablility and accuracy in assessing programming assignments based on predefined rubrics in the context of a case study we conducted in an upper-level undergraduate and graduate CS course at Vanderbilt University. In this case study, we employed a method that compared assessments generated by ChatGPT-4 against human graders to measure the accuracy, precision, and recall associated with identifying programming mistakes. Our results show that when ChatGPT-4 is used properly (e.g., with appropriate prompt engineering and feature selection) it can improve objectivity and grading efficiency, thereby acting as a complementary tool to human graders for advanced computer science graduate and undergraduate students.CCS CONCEPTS• Software and its engineering → Software maintenance tools; • Applied computing → Computer-assisted instruction.},
  keywords={Software maintenance;Accuracy;Codes;Large language models;Conferences;Computational modeling;Feature extraction;Chatbots;Prompt engineering;Functional programming;ChatGPT;Education;Generative AI;Large Language Models;Prompt Engineering;Automated Grading},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10914617,
  author={Zhang, Jingying and Liu, Kang},
  booktitle={2024 8th International Symposium on Computer Science and Intelligent Control (ISCSIC)}, 
  title={JavaLLM: A Fine-Tuned LLM for Java Programming Education}, 
  year={2024},
  volume={},
  number={},
  pages={276-280},
  abstract={The integration of Large Language Models (LLMs) into education marks a significant advancement toward personalized and adaptive learning environments, particularly in programming education. Addressing the limitations of existing LLMs in specialized domains like Java programming, this paper introduces JavaLLM — a model specifically tailored for Java programming education. Built upon a robust codeLLM and fine-tuned using extensive, high-quality Java-focused datasets, JavaLLM demonstrates superior performance in code generation and Java-specific question answering. Through rigorous evaluation and iterative refinement, JavaLLM facilitates a transformative classroom experience, enhancing the quality of teaching and enabling a personalized learning journey for students in Java programming courses. This innovation paves the way for smarter, more tailored educational approaches, leveraging AI’s generative capabilities to meet the evolving demands of modern education.},
  keywords={Java;Adaptation models;Technological innovation;Codes;Large language models;Education;Question answering (information retrieval);Iterative methods;Programming profession;Intelligent control;Large Language Model;Java Education;Fine-tuning},
  doi={10.1109/ISCSIC64297.2024.00064},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10893137,
  author={Sinha, Anvit and Goyal, Shruti and Sy, Zachary and Kuperus, Rhianna and Dickey, Ethan and Bejarano, Andres},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={BoilerTAI: A Platform for Enhancing Instruction Using Generative AI in Educational Forums}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Contribution: This Full paper in the Research Category track describes a practical, scalable platform that seamlessly integrates Generative AI (GenAI) with online educational forums, offering a novel approach to augment the instructional capabilities of staff. The platform empowers instructional staff to efficiently manage, refine, and approve responses by facilitating interaction between student posts and a Large Language Model (LLM). Background: This study is anchored in Vygotsky's socio- cultural theory, with a particular focus on the concept of the More Knowledgeable Other (MKO). It examines how GenAI can augment the instructional capabilities of course staff in educational environments, acting as an auxiliary MKO to facilitate an enriched educational dialogue between students and instructors. This theoretical backdrop is important for understanding the integration of AI within educational contexts, suggesting a balanced collaboration between human expertise and artificial intelligence to enhance the learning and teaching experience. Research Question: How effective is GenAI in reducing the workload of instructional staff when used to pre-answer student questions posted on educational discussion forums? Methodology: Employing a mixed-methods approach, our study concentrated on select first and second-year computer programming courses with significant enrollments. The investigation involved the use of an AI -assisted platform by designated (human) Teaching Assistants (AI- TAs) to pre-answer student queries on educational forums. Our analysis includes a qualitative examination of feedback and interactions, focusing on the AI-TAs' experiences and perceptions. While we primarily analyzed efficiency indicators such as the frequency of modifications required to AI generated responses, we also explored broader qualitative aspects to understand the impact and reception of AI -generated responses within the educational context. This approach allowed us to gather insights into both the quantitative engagement with AI -assisted posts and the qualitative sentiments expressed by the instructional staff, laying the groundwork for further in-depth analysis. Findings: The findings indicate no significant difference in student reception to responses generated by AI - TAs compared to those provided by human instructors. This suggests that GenAl can effectively meet educational needs when adequately managed. Moreover, AI - TAs experienced a reduction in the cognitive load required for responding to queries, pointing to GenAI's potential to enhance instructional efficiency without compromising the quality of education.},
  keywords={Generative AI;Large language models;Education;Focusing;Collaboration;Learning (artificial intelligence);Programming;Cognitive load;Cultural differences;Artificial intelligence;─Educational technology [syn;E-learning];Computer science;Social cognitive theories [syn: Social learning the- ory];Instructional change;Online discussions;GenAI;Generative AI;AI-Lab;ChatGPT;More Knowledgeable Other;AI- TA},
  doi={10.1109/FIE61694.2024.10893137},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10923798,
  author={Rafiee, Gholamreza and Ahmadli, Firuza and Collins, Matthew},
  booktitle={2024 IEEE 13th International Conference on Engineering Education (ICEED)}, 
  title={Fostering Personalized Learning in Data Science: Integrating Innovative Tools and Strategies for Diverse Pathways}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper introduces an innovative teaching approach in data science tailored for students in non-computer science pathways, specifically Business Information Technology (BIT) and Computing and Information Technology (CIT). Over a five-year period, a unique teaching approach has been developed incorporating a virtual reality (VR) game event and ChatGPT-4 as a generative artificial intelligence (AI) tool. To address the inherent complexities of learning data science, particularly the diverse prerequisite skills, this study introduces a framework including a diagnostic assessment centered around a specific education research question: “How can the learning experiences of individual students be customized to address the multifaceted challenges of data science education?” Through a diagnostic assessment process, conducted via a survey completed by students, this framework identifies students' unique requirements and skill areas facilitating the delivery of personalized content recommendations within the initial week of teaching. By fostering a culture of self-directed learning, the approach aims to enable students to concentrate on essential customized learning materials. This paper also highlights the overall student satisfaction with the module averaged 4.5 out of 5 with a standard deviation of 0.9 indicating a high level of contentment with the teaching approach. The discussion encompasses the framework's implications for teaching and its alignment with educational theories. This paper contributes to the computing education field by addressing the research question and offering insights for future research and teaching practices.},
  keywords={Surveys;Generative AI;Education;Virtual reality;Games;Data science;Complexity theory;Information technology;Engineering education;Standards;Content recommendation;data science education;individualized learning experience framework;prerequisite skill identification;self-directed learning;ChatGPT-4;Virtual Reality},
  doi={10.1109/ICEED62316.2024.10923798},
  ISSN={},
  month={Nov},}@ARTICLE{10883995,
  author={Álvarez Ariza, Jonathan and Benitez Restrepo, Milena and Hernández Hernández, Carola},
  journal={IEEE Access}, 
  title={Generative AI in Engineering and Computing Education: A Scoping Review of Empirical Studies and Educational Practices}, 
  year={2025},
  volume={13},
  number={},
  pages={30789-30810},
  abstract={Since the release of diverse generative AI (GenAI) tools such as ChatGPT, Google Gemini, DALL $\cdot $ E, and GitHub Copilot, there has been much debate around the impacts and implications of these tools on education. Currently, extant literature remarks on the affordances, challenges, and opportunities of GenAI, but few studies report and analyze empirical studies and educational practices coming up by GenAI usage in learning settings. Then, in this Scoping Review (ScR) based on 146 studies retrieved from the databases SCOPUS, Web of Science (WoS), and ERIC, we analyzed the implications of integrating GenAI in engineering and computing education from K-12 to tertiary levels. We adopted an approach starting from the bibliometric features of the studies in terms of authors, cites, years, or cluster topics, and navigating to the identification of methodologies, strategies, AI literacy instruments and guidelines, learning outcomes, and students’ and teachers’ perceptions, among other features. We advocate that current educational practices in engineering and computing with GenAI can indicate to us a roadmap of its potentialities, uses, and risks from the standpoint of both teachers and students, and this could help us to create more reflexive methodologies that enhance the teaching-learning process based on the evidence. Our purpose with the outcomes and conclusions of this scoping review is to support educators, faculty members, and other stakeholders in engineering and computing education to co-create educational methodologies that articulate GenAI with curricula, AI literacy, and prompt engineering encompassing students’ learning domains such as cognitive, affective, or behavioral.},
  keywords={Artificial intelligence;Education;Ethics;Chatbots;Systematic literature review;Computational modeling;Affordances;Privacy;Plagiarism;Training;Generative AI;GenAI;GAI;artificial intelligence;AI;computer science education;engineering education;computing education;prompt engineering;AI literacy},
  doi={10.1109/ACCESS.2025.3541424},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10764896,
  author={Zhao, Jiuang and Yang, Donghao and Zhang, Li and Lian, Xiaoli and Yang, Zitian and Liu, Fang},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Enhancing Automated Program Repair with Solution Design}, 
  year={2024},
  volume={},
  number={},
  pages={1706-1718},
  abstract={Automatic Program Repair (APR) endeavors to autonomously rectify issues within specific projects, which generally encompasses three categories of tasks: bug resolution, new feature development, and feature enhancement. Despite extensive research proposing various methodologies, their efficacy in addressing real issues remains unsatisfactory. It’s worth noting that, typically, engineers have design rationales (DR) on solution— planed solutions and a set of underlying reasons—before they start patching code. In open-source projects, these DRs are frequently captured in issue logs through project management tools like Jira. This raises a compelling question: How can we leverage DR scattered across the issue logs to efficiently enhance APR?To investigate this premise, we introduce DRCodePilot, an approach designed to augment GPT-4-Turbo’s APR capabilities by incorporating DR into the prompt instruction. Furthermore, given GPT-4’s constraints in fully grasping the broader project context and occasional shortcomings in generating precise identifiers, we have devised a feedback-based self-reflective framework, in which we prompt GPT-4 to reconsider and refine its outputs by referencing a provided patch and suggested identifiers. We have established a benchmark comprising 938 issue-patch pairs sourced from two open-source repositories hosted on GitHub and Jira. Our experimental results are impressive: DRCodePilot achieves a full-match ratio that is a remarkable 4.7x higher than when GPT-4 is utilized directly. Additionally, the CodeBLEU scores also exhibit promising enhancements. Moreover, our findings reveal that the standalone application of DR can yield promising increase in the full-match ratio across CodeLlama, GPT-3.5, and GPT-4 within our benchmark suite. We believe that our DRCodePilot initiative heralds a novel human-in-the-loop avenue for advancing the field of APR.CCS CONCEPTS• Software and its engineering → Maintaining software.},
  keywords={Solution design;Computer bugs;Project management;Grasping;Maintenance engineering;Benchmark testing;Software;Human in the loop;Software engineering;Software development management;Design rationale;Issue logs;Developer discussion;Automated program repair},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{10578838,
  author={Jacobs, Sven and Jaschke, Steffen},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Evaluating the Application of Large Language Models to Generate Feedback in Programming Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This study investigates the application of large language models, specifically GPT-4, to enhance programming education. The research outlines the design of a web application that uses GPT-4 to provide feedback on programming tasks, without giving away the solution. A web application for working on programming tasks was developed for the study and evaluated with 51 students over the course of one semester. The results show that most of the feedback generated by GPT-4 effectively addressed code errors. However, challenges with incorrect suggestions and hallucinated issues indicate the need for further improvements.},
  keywords={Fault diagnosis;Codes;Large language models;Task analysis;Engineering education;Programming profession},
  doi={10.1109/EDUCON60312.2024.10578838},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10937513,
  author={Moazzez, Ava and Barman, Aditya and Liang, Sarah and Katikaneni, Vibhav and Nuli, Achyut and Kandala, Vineel and Kamat, Kashi and Boicu, Mihai},
  booktitle={2024 IEEE MIT Undergraduate Research Technology Conference (URTC)}, 
  title={Assessing the Consistency of Open-Source Large Language Models for Algorithm Evaluation}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The grading of open-ended questions in education is labor-intensive and subject to human error, making it an attractive target for automation through artificial intelligence. This work explores the grading consistency of four open-source large language models (LLMs) in rubric grading algorithms on design, completeness, clarity & readability, and logic. Statistical methods revealed that Anthropic Claude was the most consistent scorer, with an average normalized standard deviation (SD) of 0.17 points and an intraclass correlation coefficient of 0.828, while Microsoft Copilot was the least consistent. The “completeness” rubric category had the lowest average SD, indicating it was graded the most consistently.},
  keywords={Hands;Codes;Statistical analysis;Large language models;Education;Internet;Logic;Time factors;Standards;Testing;large language model;consistency;rubric},
  doi={10.1109/URTC65039.2024.10937513},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10486710,
  author={Haensch, Anna-Carolina and Ball, Sarah and Herklotz, Markus and Kreuter, Frauke},
  booktitle={2023 Big Data Meets Survey Science (BigSurv)}, 
  title={Seeing ChatGPT Through Students’ Eyes: An Analysis of TikTok Data}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Advanced large language models like ChatGPT have gained considerable attention recently, including among students. However, while the debate on ChatGPT in academia is making waves, more understanding is needed among lecturers and teachers on how students use and perceive ChatGPT. To address this gap, we analyzed the content on ChatGPT available on TikTok in February 2023. TikTok is a rapidly growing social media platform popular among individuals under 30. Specifically, we analyzed the content of the 100 most popular videos in English tagged with #chatgpt, which collectively garnered over 250 million views. Most of the videos we studied promoted the use of ChatGPT for tasks like writing essays or code. In addition, many videos discussed AI detectors, with a focus on how other tools can help to transform ChatGPT output to fool these detectors. This also mirrors the discussion among educators on how to treat ChatGPT as lecturers and teachers in teaching and grading. What is, however, missing from the analyzed clips on TikTok are videos that discuss ChatGPT producing content that is nonsensical or unfaithful to the training data.},
  keywords={Surveys;Video on demand;Training data;Detectors;Transforms;Writing;Chatbots},
  doi={10.1109/BigSurv59479.2023.10486710},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10893099,
  author={Reeping, David and Shah, Aarohi},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Work-in-Progress: Students' Prompting Strategies When Solving an Engineering Design Task}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress research paper investigates how students prompt generative AI while tackling an engineering design challenge. As tools like ChatGPT become common in education, we must understand how to incorporate them into our teaching and guide students on their proper use. Although the existing literature focuses on understanding what students use generative AI tools for, less work has been done to examine students' prompting strategies when engaging with these systems. We leveraged a new brainstorming assignment in a first-year engineering course at a large Midwest public university, where students ideated collaboratively using ChatGPT for the design of their term project - a semiautonomous robot (n = 97 teams, 589 prompts). Most prompts (~50%) ranged between 55 and 95 characters, or approximately 8 to 19 words. Our initial qualitative findings suggest that their approaches center on seeking information, much like how they would use a search engine. Others directly ask the chatbot to provide alternatives for their design without providing the appropriate criteria or constraints. A subset of prompts had an evaluative component, asking ChatGPT to weigh ideas against one another. We found that 11 % of prompts included instructing ChatGPT to produce the “best” solution instead of generating multiple ideas, suggesting students focus on using the chatbot in a more convergent design process - unlike divergent thinking in brainstorming.},
  keywords={Generative AI;Heuristic algorithms;Education;Curriculum development;Search engines;Chatbots;Data mining;Particle swarm optimization;Robots;first year experience;ideation;prompting;generative AI;ChatGPT},
  doi={10.1109/FIE61694.2024.10893099},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10893324,
  author={Wiktor, Sandra and Dorodchi, Mohsen and Wiktor, Nicole},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={AI Can Help Instructors Help Students: An LLM-Supported Approach to Generating Customized Student Reflection Responses}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice paper presents an LLM-supported technique to help instructors respond effectively to periodic students' reflections. Efficient communication between instructors and students is integral to supporting a productive learning environment. Recognizing the significance of understanding students' perceptions and challenges, we present the initial implementation of a system to help instructors analyze and respond to students' feedback promptly and effectively. This research is inspired by and extends prior works where instructors sent progress check emails to students, with some works finding that such communication increased students' motivation. To collect feedback, we administer regular student reflections throughout the semester that capture how students feel about the course and uncover the challenges they face. This regular feedback-gathering approach allows instructors to better track their students' progress and respond to comments throughout the semester to provide guidance. However, reading and responding to each reflection manually in the context of their overall learning experience can be time consuming. To address this challenge, we introduce an LLM-based automated approach that generates tailored, performance-contextualized responses to student reflections that can be used to guide first-contact interventions. The generated reflection responses (GRRs) address issues discussed in student reflections and provide advice, support, course information, and follow-up questions to the students. Additionally, they provide feedback to students based on their accomplishments and behavioral data within the learning management system (LMS), such as submission patterns. In this work, we discuss our method of generating responses based on students' reflections and their LMS behavior. We also present example scenarios of the proposed approach. Preliminary results indicate that this approach can help instructors facilitate positive educational interactions with students and that the participating students view the interventions favorably, fostering a constructive learning environment. This work provides an initial presentation of our large language model-based response generation method to motivate further investigation into AI-assisted student support mechanisms},
  keywords={Learning management systems;Face recognition;Reflection;Artificial intelligence;student experience;reflection},
  doi={10.1109/FIE61694.2024.10893324},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10345949,
  author={Virvou, Maria and Tsihrintzis, George A.},
  booktitle={2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)}, 
  title={Is ChatGPT Beneficial to Education? A Holistic Evaluation Framework Based on Intelligent Tutoring Systems}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={The recent launch of ChatGPT by OpenAI has created a profound global impact, initiating deep questions among educators about how it might affect education, syllabi and teaching methods. Currently, the full scope of potential benefits and risks associated with ChatGPT in education remains unclear, given that its impact surpasses the level of preparation educators and institutions may have had for such a pre-trained generative AI tool. While Artificial Intelligence in Education has long been a subject of research, with a particular focus on developing Intelligent Tutoring Systems, the emergence of ChatGPT marks a distinctive advancement in this field. Unlike dedicated Intelligent Tutoring Systems, ChatGPT is readily available to a diverse spectrum of educational stakeholders, including teachers, students, schools, universities, and educational institutions. Scholars have initiated assessments of ChatGPT's effectiveness across various educational disciplines, even though ChatGPT was not explicitly designed for educational purposes. However, the widespread accessibility of ChatGPT, coupled with its extensive knowledge base, necessitates the development of comprehensive evaluation frameworks. In this paper, we introduce a holistic evaluation framework tailored for ChatGPT. This framework takes into account both soft and hard skills, and it is designed to seamlessly incorporate ChatGPT into Intelligent Tutoring Systems, making it suitable for a wide range of educational fields. By establishing a connection between ITS and ChatGPT, as they are both AI tools, we can benefit from the substantial background work achieved by previous research in ITSs to evaluate the educational influence of ChatGPT.},
  keywords={Ethics;Education;Knowledge based systems;Chatbots;Cognition;Stakeholders;ChatGPT;AI in Education;Intelligent Tutoring Systems;e-learning;Educational Evaluation Frameworks;educational software;large language models;generative AI},
  doi={10.1109/IISA59645.2023.10345949},
  ISSN={},
  month={July},}@INPROCEEDINGS{10893284,
  author={Song, Isabel Hyo Jung and Wang, Jingyi and Sunico, Rafael and Dahlstrom, Andrew},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: Enhancing Career Preparedness Through a Software Engineering Capstone Course Design}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This research to practice WIP paper describes capstone projects in software engineering which effectively combine theoretical education with practical skills, fostering career development in alignment with Career Construction Theory (CCT). This paper introduces a course designed to enhance students' career readiness by incorporating Agile methodologies for soft skills development, proficiency in modern technologies like Large Language Models (LLMs), and targeted career preparation such as resume building. The course's effectiveness, evaluated through CCT adaptability for 42 students, shows a positive impact on career preparedness in three of the four dimensions. This is the first attempt to measure the impact of a capstone course on career development using CCT adaptability. While the initial results are promising, further research is crucial to fully enhance all dimensions of CCT adaptability and to explore the scalability of this study across other engineering fields, potentially transforming engineering education and career preparation on a broader scale.},
  keywords={Training;Career development;Engineering profession;Scalability;Large language models;Buildings;Project management;Engineering education;Software engineering;career development;software engineering education;capstone course;Career Construction Theory;Agile methodology;Large Language Model (LLM)},
  doi={10.1109/FIE61694.2024.10893284},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10851491,
  author={Kerimbayev, Nurassyl and Menlibay, Zhanbota and Garvanova, Magdalena and Djaparova, Saltanat and Jotsov, Vladimir},
  booktitle={2024 International Conference Automatics and Informatics (ICAI)}, 
  title={A Comparative Analysis of Generative AI Models for Improving Learning Process in Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={271-276},
  abstract={This study comprehensively analyses ten advanced generative AI models including GPT-4, Microsoft Copilot, Claude, DeepSeek, Pi and others to assess their applicability in higher education for computer science students. The study uses a mixed-method approach involving qualitative and quantitative analyses to evaluate these models across four key groups: architecture, content quality, adaptability, and performance. The results show that while each model has certain strengths - such as GPT-4’s content creation capabilities and Pi’s adaptability - none is the optimal choice across all clusters. The study emphasizes the importance of aligning the choice of AI tool with specific educational goals and needs. It also emphasizes the need for continuous evaluation of AI technologies to ensure their effectiveness in dynamic educational environments. The study contributes to the growing discourse on AI in education by offering a sound framework for evaluating AI models and guiding their implementation in educational environments.},
  keywords={Computer science;Training;Adaptation models;Analytical models;Accuracy;Generative AI;Computational modeling;Education;Data models;Context modeling;generative AI;higher education;computer science;educational technologies;Evaluation of AI models},
  doi={10.1109/ICAI63388.2024.10851491},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11016505,
  author={Böttcher, Axel and Thurner, Veronika and Zönnchen, Benedikt},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Concepts for Teaching Software Development in the Age of AI-Tools}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={LLM-based tools such as ChatGPT, GitHub Copilot, and the like have already arrived in software development practice, and continue to change the way of how software is created. Students use Generative AI tools for any purpose, whether we agree with the use or not. In this paper, we argue that in order to appropriately prepare our students for professional life, we educators need to incorporate the use of these tools explicitly into the teaching and learning process, so that students will learn a systematic and professional usage of these tools. Teaching basic software development concepts to students with only little or no prior knowledge has always been a challenge. Incorporating GenAI-based tools into software development education requires some careful rethinking of teaching concepts, especially with respect to constructive alignment, i. e. aligning learning objectives, teaching and learning methods, and exams to address GenAI-based support. Based upon first observations on the usage of GenAI tools in class, in this paper we suggest and compare concepts for teaching and learning basic software development that integrate GenAI tools at different levels of intensity and at different points during a semester. From these observations, we derive recommendations both for teaching and learning settings and for corresponding assessments, for teaching software development in a constructively aligned way in the age of GenAI tools.},
  keywords={Learning systems;Systematics;Generative AI;Education;Chatbots;Software;Engineering education;Programming profession;Software development management;Generative AI;programming education;student struggle;constructive alignment},
  doi={10.1109/EDUCON62633.2025.11016505},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10893117,
  author={Simmons, Archer and Holanda, Maristela and Chamon, Christiana and Da Silva, Dilma},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={AI Generated Code Plagiarism Detection in Computer Science Courses: A Literature Mapping}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This is a full research paper. Integrity in the detection of plagiarism in students' source codes in university programming courses is a research topic for instructors and institutions seeking to improve the quality of their teaching. In particular, introductory courses such as CS1, are of paramount importance, as this is when students gain fundamental knowledge to build their future on. With the latest developments in Large Language Models (LLM) such as ChatGPT, GitHub Copilot, etc., methods of plagiarism have evolved, however methods of detection may not be capable of accurately differentiating between code generated by human and artificial intelligence (AI). In this context, this paper seeks to answer the research question: What does the current literature report on AI generated code plagiarism detection in higher education? To expand on and formulate a comprehensive answer to our research question (RQ), we have formulated six sub-questions: RQ1) How many papers were published per year by country?; RQ2) Which conferences and journals have published most papers on this subject?; RQ3) Which plagiarism detection tools were most often used prior to common AI use?; RQ4) How are educators adapting assignments to minimize the use of AI?; RQ5) Which modern methods are being deployed to specifically detect AI?; RQ6) Which data sources and languages are most prevalent in the literature? The methodology was based on a systematic literature review. Initially, we confined our search for literature to Scopus and Web of Science, however additional literature was included from Google Scholar. Inclusion criteria were applied to include documents from the years 2023 and 2024 (after the launch of ChatGPT), and only published by conferences and journals. Exclusion criteria: papers that do not focus on plagiarism and programming courses; papers that are not about the undergraduate-level; papers not written in English. We found 165 papers via Scopus and WebScience, from which the metadata were collected, resulting in 17 relevant papers selected for this work. The second step was a search in Google Scholar, where we analyzed 200 documents from 2023 (100 relevant documents) and 2024 (100 relevant documents). We used the same inclusion and exclusion criteria, however, we included the ArXiv papers, and found 9 more papers. Following this process, we have identified 26 papers to include in this literary mapping. In this paper we present the answers to these research questions and discussions about this research topic.},
  keywords={Technological innovation;Codes;Plagiarism;Source coding;Education;Chatbots;Internet;Artificial intelligence;Programming profession;Systematic literature review;programming;plagiarism detection;code;AI;academia;education;similarity;mapping},
  doi={10.1109/FIE61694.2024.10893117},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11016587,
  author={Yee-King, Matthew and Fiorucci, Andrea},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Deploying Language Model-Based Assessment Support Technology in a Computer Science Degree: How Do the Academics Feel About It?}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={We present two contrasting case studies wherein we used large language model (LLM) technology to support critical elements of our work in the context of a large scale online undergraduate computer science degree. Firstly we used semantic embeddings to identify student-student collusion in exam answers. Secondly we used LLMs to generate starter drafts for exam question papers. We gathered academic staff responses to the two systems through structured interviews. We describe and use a novel, LLM-powered inductive thematic analysis methodology to tag and identify themes in the interviews. All analysis was carried out on locally hosted language models. We identified 26 themes, some shared across the two systems, others unique. The academics were largely comfortable with the use of LLM technology in assessment, the exam generator system helped to kick-start exam writing and the collusion detection tool found otherwise invisible cases. Academics emphasised the need for human oversight of such systems, but were prepared to use them as they perceived that they improved the efficiency of exam processes.},
  keywords={Computer science;Analytical models;Large language models;Computational modeling;Semantics;Writing;Question generation;Generators;Interviews;Engineering education;Large Language Models (LLMs);Student Collusion Detection;Exam Question Generation;Inductive Thematic Analysis;Assessment Efficiency;Human Oversight in AI Systems;Locally Hosted AI Models},
  doi={10.1109/EDUCON62633.2025.11016587},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10555866,
  author={Deo, Soham and Hinge, Divya and Chavan, Omkar Sandip and Olivia Wang, Yaxuan and Mkaouer, Mohamed Wiem},
  booktitle={2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR)}, 
  title={Analyzing Developer-ChatGPT Conversations for Software Refactoring: An Exploratory Study}, 
  year={2024},
  volume={},
  number={},
  pages={207-211},
  abstract={In recent years, Large Language Models (LLMs) have witnessed a remarkable ascent, with OpenAI’s ChatGPT, introduced in 2022, garnering substantial attention. ChatGPT’s rapid adoption in the software development community has opened up new avenues for exploring its qualitative and quantitative impact on Developer-ChatGPT conversations. In this paper, we delve into a rich dataset from GitHub and Hacker News to perform a thorough analysis. Our objectives include characterizing the nature of these interactions and evaluating the use of ChatGPT in refactoring. To achieve these goals, we employ a combination of exploratory data analysis and data annotation, utilizing relevant keyword filters to extract pertinent information. Our examination encompasses the identification and analysis of code refactorings facilitated by ChatGPT. Through a meticulous exploration of these conversations, our goal is to illuminate the potential of ChatGPT to enhance software development practices. This research promises to provide valuable insights into the evolving role of ChatGPT in the world of software development.CCS CONCEPTS• Software Engineering → Software Quality; Refactoring.},
  keywords={Codes;Filters;Focusing;Oral communication;Software quality;Chatbots;Data mining;Refactoring documentation;ChatGPT;mining software repositories},
  doi={},
  ISSN={2574-3864},
  month={April},}@INPROCEEDINGS{11016372,
  author={Bourguet, Marie-Luce},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Decoding Student Approaches: Navigating Complex Open-Ended Engineering Problems with Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The resolution of complex open-ended problems is a core aspect of engineering practice. This study aims to explore students' approaches to using large-language models (LLM) to tackle such problems in engineering. LLMs are highly versatile tools with immense potential in education; however, their effective use to solve open-ended problems requires students to evaluate and analyse information, consider diverse perspectives, and make informed decisions. This raises important questions about students' readiness to critically and responsibly use LLMs for these tasks, as well as the role of educators in fostering critical thinking skills while integrating LLMs into engineering courses. Using a mixed inductive and deductive coding approach to analyse dialogue records with LLMs from nine students and their responses in semi-structured interviews, this study uncovers several misconceptions about LLMs that hinder their effective use. Furthermore, we propose practical strategies for designing problem-solving tasks that enhance students' understanding of LLM capabilities and guide them toward responsible, critical engagement with these tools.},
  keywords={Ethics;Accuracy;Navigation;Large language models;Cultural differences;Problem-solving;Reliability;Mirrors;Interviews;Engineering education;Large language models;Engineering education;Complex open-ended problems;Critical thinking},
  doi={10.1109/EDUCON62633.2025.11016372},
  ISSN={2165-9567},
  month={April},}@ARTICLE{10287345,
  author={Niu, Yanmin and Xue, Han},
  journal={IEEE Access}, 
  title={Exercise Generation and Student Cognitive Ability Research Based on ChatGPT and Rasch Model}, 
  year={2023},
  volume={11},
  number={},
  pages={116695-116705},
  abstract={In the context of generative artificial intelligence (AI), AIGCP (content generation-based AI products), represented by ChatGPT, have attracted extensive attention in the field of education. This study focuses on the discipline of university operating systems and adopts the Rasch model as the theoretical foundation. By combining ChatGPT with existing question banks and using the bidirectional fine-grained table method, it compiles questions that match the corresponding abilities for three different levels of student groups. This aims to explore personalized question matching and student cognitive ability analysis methods to support personalized teaching. The research findings indicate that ChatGPT is capable of matching exercises of similar difficulty under the Rasch model, but its accuracy in generating exercise content is relatively low, and the variety of exercise content is limited. Students’ performance in overall competency requires improvement. This study aims to leverage the combined strengths of ChatGPT and traditional educational assessment methods to introduce an innovative approach to support personalized instruction. It aims to establish the routine utilization of exercise creation by ChatGPT and personalized analysis of student cognitive abilities, thereby better fulfilling the demands of education within the classroom setting.},
  keywords={Computational modeling;Chatbots;Mathematical models;Education;Analytical models;Testing;Operating systems;Generative adversarial networks;Artificial intelligence;Question answering (information retrieval);Generative artificial intelligence;Rasch model;personalized question matching;cognitive ability;operating system exercises},
  doi={10.1109/ACCESS.2023.3325741},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10734619,
  author={Kumar, Smitha S and Lones, Michael Adam and Maarek, Manuel and Zantout, Hind},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={Investigating the Proficiency of Large Language Models in Formative Feedback Generation for Student Programmers}, 
  year={2024},
  volume={},
  number={},
  pages={88-93},
  abstract={Generative AI has considerably altered traditional workplace practice across numerous industries. Ever since the emergence of large language models (LLMs), their potential to generate formative feed-back for introductory programming courses has been extensively researched. However, most of these studies have focused on Python. In this work, we examine the bug-fixing and feedback-generation abilities of Code Llama and ChatGPT for Java programming assignments using our new Java benchmark called CodeWBugs. The results indicate that ChatGPT performs reasonably well, and was able to fix 94.33% programs. By comparison, we observed high variability in the results from Code Llama. We further analyzed the impact of different types of prompts and observed that prompts that included task descriptions and test inputs yielded better results. In most cases, the LLMs precisely localized the bugs and also offered guidance on how to proceed. Nevertheless, we also noticed incorrect responses generated by the LLMs, emphasizing the need to validate responses before disseminating feedback to learners.CCS CONCEPTS• Applied computing → Computer-assisted instruction; • Computing methodologies → Machine translation; Natural language generation.},
  keywords={Java;Codes;Large language models;Natural language generation;Benchmark testing;Maintenance engineering;Chatbots;Machine translation;Programming profession;Python;Large language models (LLM);GPT-4;Feedback;Java Programming;Program Repair},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10837605,
  author={Boubakri, Meryem and Nafil, Khalid},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Enhancing Student Learning in Scrum Projects with Generative AI Assistance}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This article focuses on integrating generative AI tools, particularly ChatGPT and Bard, into Scrum framework education to enhance student learning and collaboration. Drawing from feedback obtained from students, the study compares the effectiveness of these tools, highlighting ChatGPT's detailed responses and Bard's conciseness. Despite students' overall satisfaction with GAI integration, they highlighted the irreplaceable role of human educators. Areas for improvement include addressing technical issues and enhancing GAI adaptability. The students' recommendations include utilizing GAI for various tasks and providing clearer prompts and training. Moving forward, the focus should be on improving GAI tools to better comprehend context and adaptability, and exploring collaborative learning approaches. To evaluate the impact of GAI integration on student outcomes, long-term studies must be conducted. In summary, while generative AI has potential to enhance Scrum education, its incorporation should be balanced with human guidance to create dynamic and effective learning environments.},
  keywords={Training;Surveys;Technological innovation;Generative AI;Federated learning;Reviews;Instruments;Collaboration;Project management;Chatbots;Education;Scrum;ChatGPT;Bard;Generative AI;Prompting},
  doi={10.1109/ITHET61869.2024.10837605},
  ISSN={2473-2060},
  month={Nov},}@ARTICLE{10111520,
  author={Ibrahim, Hazem and Asim, Rohail and Zaffar, Fareed and Rahwan, Talal and Zaki, Yasir},
  journal={IEEE Intelligent Systems}, 
  title={Rethinking Homework in the Age of Artificial Intelligence}, 
  year={2023},
  volume={38},
  number={2},
  pages={24-27},
  abstract={The evolution of natural language processing techniques has led to the development of advanced conversational tools such as ChatGPT, capable of assisting users with a variety of activities. Media attention has centered on ChatGPT’s potential impact, policy implications, and ethical ramifications, particularly in the context of education. As such tools become more accessible, students across the globe may use them to assist with their homework. However, it is still unclear whether ChatGPT’s performance is advanced enough to pose a serious risk of plagiarism. We fill this gap by evaluating ChatGPT on two introductory and two advanced university-level courses. We find that ChatGPT receives near-perfect grades on the majority of questions in the introductory courses but has not yet reached the level of sophistication required to pass in advanced courses. Moreover, adding a few full stops or typos may fool a machine learning algorithm designed to detect ChatGPT-generated text. These findings suggest that, at least for some courses, current artificial intelligence tools pose a real threat that can no longer be overlooked by educational institutions.},
  keywords={Ethics;Machine learning algorithms;Plagiarism;Education;Media;Chatbots;Intelligent systems;Artificial intelligence},
  doi={10.1109/MIS.2023.3255599},
  ISSN={1941-1294},
  month={March},}@INPROCEEDINGS{10645934,
  author={Bakharia, Aneesha and Abdi, Solmaz},
  booktitle={2024 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Shaping Programming and Data Science Education: Insights from GenAI Technical Book Trends}, 
  year={2024},
  volume={},
  number={},
  pages={116-120},
  abstract={As GenAI technologies, particularly Large Language Models (LLMs), continue to revolutionize programming and data science, it is increasingly vital for educators to adapt computer science curricula. This paper presents a review of recent technical books on AI-Assisted programming and utilizes the findings to guide curriculum changes in higher education. Our analysis underscores the necessity for novel teaching strategies, emphasizing skills like problem decomposition, top-down design, and advanced debugging. Furthermore, it emphasizes the crucial expansion of curricula to encompass courses on developing applications based on LLMs, utilizing libraries such as LangChain and incorporating Retrieval Augmented Generation functionality. Our analysis reveals a significant gap in technical literature regarding the ethical and societal impacts of GenAI, highlighting the urgent need for programming curricula to evolve and equip students with the skills required to ethically develop AI-enhanced software products. This paper advocates for curriculum development that not only aligns with the latest industry trends but also contributes to research on AI-assisted coding and its future impact.},
  keywords={Ethics;Reviews;Education;Debugging;Data science;Market research;Encoding;AI-assisted programming;Programming curriculum development;Programming education;Data science education},
  doi={10.1109/ICALT61570.2024.00040},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{11016653,
  author={Mushtaq, Abdullah and Naeem, Rafay and Ghaznavi, Ibrahim and Taj, Imran and Hashmi, Imran and Qadir, Junaid},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Multi-Agent Large Language Models (LLMs) are gaining attention for their ability to harness collective intelligence in complex problem-solving, decision-making, and planning tasks. This aligns with the wisdom of crowds concept, where diverse agents collectively generate effective solutions, making them well-suited for educational settings. Senior design projects, pivotal in engineering education, integrate theoretical knowledge with practical application, fostering critical thinking, teamwork, and real-world problem-solving skills. These projects often involve multidisciplinary considerations and conflicting objectives, such as optimizing technical performance while addressing ethical, social, and environmental concerns. In this paper, we explore a framework where distinct LLM agents embody expert perspectives, including problem formulation, system complexity, societal and ethical considerations, and project management. These agents engage in rich, collaborative dialogues, leveraging multi-agent system principles like coordination, cooperation, and negotiation. Prompt engineering is employed to create diverse personas, simulating human engineering teams and incorporating swarm AI principles to balance contributions efficiently. To evaluate the framework, we analyzed six senior capstone project proposals from engineering and computer science, comparing Multi-Agent and single-agent LLMs using metrics developed with engineering faculty and widely used NLP-based measures. These metrics assess technical quality, ethical considerations, social impact, and feasibility, aligning with the educational objectives of engineering design. Our findings suggest that Multi-Agent LLMs can provide a richer, more inclusive problem-solving environment compared to single-agent systems with 89% alignment with engineering-faculty scores, offering a promising tool for enhancing the educational experience of engineering and computer science students by simulating the complexity and collaboration of real-world engineering and computer science practice. By supporting senior design projects, this tool not only aids in achieving academic excellence but also prepares students for the multifaceted challenges they will face in their professional engineering careers. We have open-sourced our framework for further development and adaptation on GitHub11Copilot is available at GitHub Repository: https://github.com/AbdullahMushtaq78/Multi-Agent-SDP-Copliot.},
  keywords={Measurement;Computer science;Ethics;Large language models;Complexity theory;Teamwork;Problem-solving;Stakeholders;Engineering education;Multi-agent systems;Large Language Models;Gen AI;LLM Agents;LLM-Based Multi-Agent Systems;Multi-Agent Collaboration;Agentic AI},
  doi={10.1109/EDUCON62633.2025.11016653},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10893159,
  author={Tadimalla, Sri Yash and Maher, Mary Lou},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={AI Literacy for All: Adjustable Interdisciplinary Socio-technical Curriculum}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research-to-practice paper presents a curriculum, “AI Literacy for All,” to promote an interdisciplinary under-standing of AI, its socio-technical implications, and its practical applications for all levels of education. With the rapid evolution of artificial intelligence (AI), there is a need for AI literacy that goes beyond the traditional AI education curriculum. AI literacy has been conceptualized in various ways, including public literacy, competency building for designers, conceptual understanding of AI concepts, and domain-specific upskilling. Most of these conceptualizations were established before the public release of Generative AI (Gen-AI) tools such as ChatGPT. AI education has focused on the principles and applications of AI through a technical lens that emphasizes the mastery of AI principles, the mathematical foundations underlying these technologies, and the programming and mathematical skills necessary to implement AI solutions. The non-technical component of AI literacy has often been limited to social and ethical implications, privacy and security issues, or the experience of interacting with AI. In AI Literacy for all, we emphasize a balanced curriculum that includes technical as well as non-technical learning outcomes to enable a conceptual understanding and critical evaluation of AI technologies in an interdisciplinary socio-technical context. The paper presents four pillars of AI literacy: understanding the scope and technical dimensions of AI, learning how to interact with Gen-AI in an informed and responsible way, the socio-technical issues of ethical and responsible AI, and the social and future implications of AI. While it is important to include all learning outcomes for AI education in a Computer Science major, the learning outcomes can be adjusted for other learning contexts, including, non-CS majors, high school summer camps, the adult workforce, and the public. This paper advocates for a shift in AI literacy education to offer a more interdisciplinary socio-technical approach as a pathway to broaden participation in AI. This approach not only broadens students' perspectives but also prepares them to think critically about integrating AI into their future professional and personal lives.},
  keywords={Ethics;Privacy;Navigation;Generative AI;Education;Chatbots;Security;Artificial intelligence;Programming profession;Lenses;AI literacy;AI education;Active learning;Responsible AI;Democratizing AI},
  doi={10.1109/FIE61694.2024.10893159},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10917294,
  author={Kim, Mark and Puder, Arno and Hayward, Craig and Yang, Hui},
  booktitle={2024 IEEE International Conference on Data Mining Workshops (ICDMW)}, 
  title={Foundation Models for Course Equivalency Evaluation}, 
  year={2024},
  volume={},
  number={},
  pages={300-306},
  abstract={This study investigates the potential of Large Language Models (LLMs) for evaluating course equivalency in higher education. We introduce an innovative approach that utilizes publicly available course descriptions and unmodified LLMs for pairwise course comparison. We selected Google PaLM2 and its successor, Gemini Pro v1.0, due to their accessible free-tier API and their ability to reliably generate structured data.The most challenging aspect of our methodology was extracting data from course descriptions. Nonetheless, Gemini Pro v1.0 demonstrated a serviceable ability to comprehend the context of unprocessed descriptions and effectively categorize their components. Notably, classification t asks u sing r aw text yielded better results compared to those based on extracted topics, indicating potential improvements in topic extraction.Our findings reveal that the model tends to exhibit a conservative bias, often leaning towards non-equivalence judgments. We introduced additional categories such as "unsure" and "inadequate data," which enhanced the statistical performance of the model in the equivalent/nonequivalent classes and simulated the possible decision-making processes of human advisors in ambiguous cases.This study underscores both the challenges and opportunities presented by LLMs in course equivalency evaluation. Key considerations include prompt sensitivity, computational costs, and API limitations. Future research will focus on comparing results across different models and prompt designs, exploring alternative techniques such as embeddings and instruction fine-tuning, and striving to develop a more precise and reliable course equivalency assessment system.},
  keywords={Sensitivity;Foundation models;Large language models;Computational modeling;Education;Decision making;Reliability engineering;Information retrieval;Internet;Data mining;Higher Education;Educational Data Mining;Information Extraction;Large Language Models;Course Equivalency Evaluation},
  doi={10.1109/ICDMW65004.2024.00045},
  ISSN={2375-9259},
  month={Dec},}@INPROCEEDINGS{10343247,
  author={Dos Santos, Otávio Lube and Cury, Davidson},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Challenging the Confirmation Bias: Using ChatGPT as a Virtual Peer for Peer Instruction in Computer Programming Education}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper proposes the implementation of Chat-GPT, a large language model, as a virtual peer for peer instruction in computer programming courses. The authors argue that AI tools, including ChatGPT, can bring benefits such as personalized learning, instant feedback, and active engagement to the classroom. An experiment was conducted with two groups of programming students: one receiving traditional instruction and the other utilizing the ChatGPT-based peer instruction model. Both groups were given the same programming assignments and assessments. The results indicated that the ChatGPT group outperformed the traditionally instructed group, demonstrating better programming skills and a deeper understanding of concepts. The ChatGPT group also reported higher engagement and satisfaction. However, some difficulties were observed when using ChatGPT for more abstract problems. Overall, the study highlights the effectiveness of using ChatGPT as a virtual peer to enhance active learning and student outcomes in computer programming courses, challenging biases regarding AI's potential benefits in education. The authors hope this study encourages educators to embrace AI tools in the classroom and overcome confirmation biases about their impact.},
  keywords={Codes;Computational modeling;Education;Learning (artificial intelligence);Chatbots;Encoding;Data models;peer instruction;pair programming;artificial intelligence;chatgpt},
  doi={10.1109/FIE58773.2023.10343247},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10830556,
  author={Zhang, Liang and Lin, Jionghao and Sabatini, John and Borchers, Conrad and Weitekamp, Daniel and Cao, Meng and Hollander, John and Hu, Xiangen and Graesser, Arthur C.},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Data Augmentation for Sparse Multidimensional Learning Performance Data Using Generative AI}, 
  year={2025},
  volume={18},
  number={},
  pages={145-164},
  abstract={Learning performance data, such as correct or incorrect answers and problem-solving attempts in intelligent tutoring systems (ITSs), facilitate the assessment of knowledge mastery and the delivery of effective instructions. However, these data tend to be highly sparse (80%$\sim$90% missing observations) in most real-world applications. This data sparsity presents challenges to using learner models to effectively predict learners' future performance and explore new hypotheses about learning. This article proposes a systematic framework for augmenting learning performance data to address data sparsity. First, learning performance data can be represented as a 3-D tensor with dimensions corresponding to learners, questions, and attempts, effectively capturing longitudinal knowledge states during learning. Second, a tensor factorization method is used to impute missing values in sparse tensors of collected learner data, thereby grounding the imputation on knowledge tracing (KT) tasks that predict missing performance values based on real observations. Third, data augmentation using generative artificial intelligence models, including generative adversarial network (GAN), specifically vanilla GANs and generative pretrained transformers (GPTs, specifically GPT-4o), generate data tailored to individual clusters of learning performance. We tested this systemic framework on adult literacy datasets from AutoTutor lessons developed for adult reading comprehension. We found that tensor factorization outperformed baseline KT techniques in tracing and predicting learning performance, demonstrating higher fidelity in data imputation, and the vanilla GAN-based augmentation demonstrated greater overall stability across varying sample sizes, whereas GPT-4o-based augmentation exhibited higher variability, with occasional cases showing closer fidelity to the original data distribution. This framework facilitates the effective augmentation of learning performance data, enabling controlled, cost-effective approach for the evaluation and optimization of ITS instructional designs in both online and offline environments prior to deployment, and supporting advanced educational data mining and learning analytics.},
  keywords={Data models;Imputation;Data augmentation;Generative adversarial networks;Predictive models;Tensors;Analytical models;Generative Pre-trainer transformer;Computational modeling;Adaptation models;Data augmentation;data sparsity;generative artificial intelligence (GenAI);intelligent tutoring system (ITS);learning performance data},
  doi={10.1109/TLT.2025.3526582},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10343052,
  author={Jamieson, Peter and Bhunia, Suman and Rao, Dhananjai M.},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={With ChatGPT, Do We have to Rewrite Our Learning Objectives - CASE Study in Cybersecurity}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={With the emergence of Artificial Intelligent chatbot tools such as ChatGPT and code writing AI tools such as GitHub Copilot, educators need to question what and how we should teach our courses and curricula in the future. In reality, automated tools may result in certain academic fields being deeply reduced in the number of employable people. In this work, we make a case study of cybersecurity undergrad education by using the lens of “Understanding by Design” (UbD). First, we provide a broad understanding of learning objectives (LOs) in cybersecurity from a computer science perspective. Next, we dig a little deeper into a curriculum with an undergraduate emphasis on cybersecurity and examine the major courses and their LOs for our cybersecurity program at Miami University. With these details, we perform a thought experiment on how attainable the LOs are with the above-described tools, asking the key question “what needs to be enduring concepts?” learned in this process. If an LO becomes something that the existence of automation tools might be able to do, we then ask “what level is attainable for the LO that is not a simple query to the tools?”. With this exercise, we hope to establish an example of how to prompt ChatGPT to accelerate students in their achievements of LOs given the existence of these new AI tools, and our goal is to push all of us to leverage and teach these tools as powerful allies in our quest to improve human existence and knowledge.},
  keywords={Computer science;Vocabulary;Taxonomy;Education;Writing;Chatbots;Computer security},
  doi={10.1109/FIE58773.2023.10343052},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10578821,
  author={Strachan, Rebecca and Oguna, Cynthia and Oruche, Ugochukwu},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={The Postgraduate Student Perspective on Academic Misconduct in the Era of Essay Mills and Generative AI: A Case Study from Northeast England}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Globally the number of students at university has been growing with UNESCO reporting in 2023, that there are now 235 million university students across the world, double the number from 20 years ago. Higher education is now a key area of economic growth for many countries and thus has also become a target for exploitation, evidenced by the growing numbers of essay mills and similar services, and even more recently by some of the generative Artificial Intelligence (AI) tools. The UK has also seen a growth in student numbers, particularly at postgraduate and for international students. In computing for example, UK PGT student numbers have increased rapidly with the UK Higher Education Statistics Agency reporting 25,225 computing PGT students in 2019/2020 rising to 47,410 in 2021/22, with 69% of these students being classed as international. These students can find it challenging to adapt to education in the UK and can have differing levels of abilities including digital literacy. Alongside this growth, the variety/incidence of student academic misconduct (AM) has also been rising. Previous research has tended to focus on plagiarism but there is an increasing need to explore the implications arising from the widespread availability of essay mills and generative AI tools. This study aims to provide a greater understanding of AM from the perspective of the computing PGT student. Adopting a case study approach, computing PGT students (n=358) were surveyed at one UK university in Spring 2023 with a follow up focus group. The study employed two PG students as researchers and this enabled a more trusted and student-centered approach to the survey, focus group and analysis. Thematic analysis of the data from the survey (responses n=26) and focus group (n=7) show students believe AM affects academic standards and understand the reasons behind this. They believe the university is providing clear AM guidance, but have more mixed opinions on whether they think the AM process is appropriate/fair. The analysis demonstrates the need for a holistic and concerted effort between staff and students based around six main areas: assessment; educational provision; staff attitudes/support; student opportunity/motivation; student belonging/engagement; and student-friendly AM guidance/resources. Future work is building on these recommendations to create a framework and set of practical interventions to promote academic integrity, and address the current AM challenges.},
  keywords={Surveys;Economics;Generative AI;Target recognition;Engineering profession;Plagiarism;Buildings;Academic integrity;academic misconduct;student perspective;essay mills;generative AI},
  doi={10.1109/EDUCON60312.2024.10578821},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10628487,
  author={Wei, Bingyang},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference (RE)}, 
  title={Requirements are All You Need: From Requirements to Code with LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={416-422},
  abstract={The pervasive use of textual formats in the documentation of software requirements presents a great opportunity for applying large language models (LLMs) to software engineering tasks. High-quality software requirements not only enhance the manual software development process but also position organizations to fully harness the potential of the emerging LLMs technology. This paper introduces a tailored LLM for automating the generation of code snippets from well-structured requirements documents. This LLM is augmented with knowledge, heuristics, and instructions that are pertinent to the software development process, requirements analysis, object-oriented design, and test-driven development, effectively emulating the expertise of a seasoned software engineer. We introduce a “Progressive Prompting” method that allows software engineers to engage with this LLM in a stepwise manner. Through this approach, the LLM incrementally tackles software development tasks by interpreting the provided requirements to extract functional requirements, using these to create object-oriented models, and subsequently generating unit tests and code based on the object-oriented designs. We demonstrate the LLM's proficiency in comprehending intricate user requirements and producing robust design and code solutions through a case study focused on the development of a web project. This study underscores the potential of integrating LLMs into the software development workflow to significantly enhance both efficiency and quality. The tailored LLM is available at https://chat.openai.com/g/g-bahoiKzkB-software-engineer-gpt.},
  keywords={Knowledge engineering;Codes;Software design;Object oriented modeling;Refining;Software;Requirements engineering;Requirements Engineering;Large Language Models (LLMs);ChatGPT;Code Generation;Use Cases;Software Specification;Automated Software Engineering},
  doi={10.1109/RE59067.2024.00049},
  ISSN={2332-6441},
  month={June},}@BOOK{10162340,
  author={Rothman, Denis and Gulli, Antonio},
  booktitle={Transformers for Natural Language Processing: Build, train, and fine-tune deep neural network architectures for NLP with Python, Hugging Face, and OpenAI's GPT-3, ChatGPT, and GPT-4},
  year={2022},
  volume={},
  number={},
  pages={},
  abstract={OpenAI’s GPT-3, ChatGPT, GPT-4 and Hugging Face transformers for language tasks in one book. Get a taste of the future of transformers, including computer vision tasks and code writing and assistance. Purchase of the print or Kindle book includes a free eBook in PDF formatKey FeaturesImprove your productivity with OpenAI’s ChatGPT and GPT-4 from prompt engineering to creating and analyzing machine learning modelsPretrain a BERT-based model from scratch using Hugging FaceFine-tune powerful transformer models, including OpenAI's GPT-3, to learn the logic of your dataBook DescriptionTransformers are...well...transforming the world of AI. There are many platforms and models out there, but which ones best suit your needs? Transformers for Natural Language Processing, 2nd Edition, guides you through the world of transformers, highlighting the strengths of different models and platforms, while teaching you the problem-solving skills you need to tackle model weaknesses. You'll use Hugging Face to pretrain a RoBERTa model from scratch, from building the dataset to defining the data collator to training the model. If you're looking to fine-tune a pretrained model, including GPT-3, then Transformers for Natural Language Processing, 2nd Edition, shows you how with step-by-step guides. The book investigates machine translations, speech-to-text, text-to-speech, question-answering, and many more NLP tasks. It provides techniques to solve hard language problems and may even help with fake news anxiety (read chapter 13 for more details). You'll see how cutting-edge platforms, such as OpenAI, have taken transformers beyond language into computer vision tasks and code creation using DALL-E 2, ChatGPT, and GPT-4. By the end of this book, you'll know how transformers work and how to implement them and resolve issues like an AI detective.What you will learnDiscover new techniques to investigate complex language problemsCompare and contrast the results of GPT-3 against T5, GPT-2, and BERT-based transformersCarry out sentiment analysis, text summarization, casual speech analysis, machine translations, and more using TensorFlow, PyTorch, and GPT-3Find out how ViT and CLIP label images (including blurry ones!) and create images from a sentence using DALL-ELearn the mechanics of advanced prompt engineering for ChatGPT and GPT-4Who this book is forIf you want to learn about and apply transformers to your natural language (and image) data, this book is for you. You'll need a good understanding of Python and deep learning and a basic understanding of NLP to benefit most from this book. Many platforms covered in this book provide interactive user interfaces, which allow readers with a general interest in NLP and AI to follow several chapters. And don't worry if you get stuck or have questions; this book gives you direct access to our AI/ML community to help guide you on your transformers journey!},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781803243481},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10162340},}@INPROCEEDINGS{10933867,
  author={Meza, Federico and Acevedo, Oscar and González, Matías},
  booktitle={2024 IEEE 42nd Central America and Panama Convention (CONCAPAN XLII)}, 
  title={Improving the Efficacy of an Automated Judging System in an Introductory Programming Class using a Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={There is evidence supporting that extensive practice in programming learning improves learning outcomes. Automated judging systems are commonly used as a tool to allow programming students to have access to a vast pool of exercises to improve their skills. These systems help students by assessing the correctness of their solutions. However, the feedback received is binary and limited to indicating whether the solution is correct, depending on whether the program passes all the provided test cases. Also, creating new exercises and test cases remains a demanding task for instructors.Large Language Models have recently gained popularity due to their remarkable ability to learn and generate highly proficient human language. These systems are being used in various contexts, including education.This paper presents our efforts to extend the automated judging system used in the Introduction to Programming class at the Universidad Técnica Federico Santa María in Chile. We used a commercial system supported by a Large Language Model to incorporate new functionalities into our platform. The extended system can create new programming exercises for each unit in the course and guide students’ learning by recommending exercises based on their demonstrated performance. It also provides enhanced feedback on students’ solutions to help them identify and correct their errors. In the early stages of problem-solving, the system asks students questions to ensure they fully understand the problem statement and the desired behavior of the solution. Additionally, the platform collects information that allows for a deeper analysis of students’ common mistakes and learning patterns.A preliminary evaluation of the extended system’s features shows promising results regarding the effectiveness of the mechanisms for exercise generation, guided learning, automatic verification of problem understanding, and enhanced feedback. An improvement in students’ self-efficacy was also observed.},
  keywords={Adaptive learning;Large language models;Learning automata;Problem-solving;Programming profession;automated judging system;large language model;feedback;formative evaluation;adaptive learning},
  doi={10.1109/CONCAPAN63470.2024.10933867},
  ISSN={2687-7244},
  month={Nov},}@INPROCEEDINGS{10893028,
  author={Mohammed, Crista and Sarjusingh, Wayne},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP Productive Uses of Generative AI: Preliminary Findings from an Electrical and Computer Engineering Capstone Course}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress, research-to-practice paper examines how students have used generative AI (GAI) productively and with permission to complete their senior capstone course in an undergraduate electrical and computer engineering program. Data were extracted from two sources: faculty lists of permissible use and student feedback. Data show that GAI was used to clarify concepts; generate bibliographies; summarize literature; write code; classify phenomena; edit written work; and produce models. Similar student use has been reported in other engineering education contexts. One striking finding is that some students elected not to use GAI. They reasoned that the capstone project was too high stakes a task to risk submitting incorrect work as they were uncertain about their command of the subject matter to confidently vet the AI's outputs. This study is part of a larger discussion on how to productively deploy GAI in classrooms. It proposes a preliminary cache of uses specific to electrical and computer engineering and it may prove useful to engineering instructors who wish to create assessment tasks that leverage GAI.},
  keywords={Codes;Generative AI;Scholarships;Computational modeling;Bibliographies;Distance measurement;Data models;Data mining;Probes;Engineering education;assessment;capstone course;electrical engineering education;generative AI},
  doi={10.1109/FIE61694.2024.10893028},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10903317,
  author={WeiminZhao and Mahmoud, Qusay H.},
  booktitle={2024 International Conference on Machine Learning and Applications (ICMLA)}, 
  title={Evaluating the Efficacy of Large Language Models in Automating Academic Peer Reviews}, 
  year={2024},
  volume={},
  number={},
  pages={1208-1213},
  abstract={This paper explores the application of large language models (LLMs) in automating the peer review process for academic papers, a critical area for enhancing the efficiency and consistency of scholarly publication. We utilized GPT-4-0125 to automatically generate reviews for 20 papers sourced from openreview.net and analyzed the AI-generated peer reviews for quality and effectiveness. The analysis includes a detailed assessment of the text properties of the reviews, such as sentiment, revealing that LLM-generated reviews tend to be more uniformly positive than their human-written counterparts. In addition, we conducted a user survey in which participants attempted to distinguish between AI-generated and human-written reviews. The survey results indicated a low correct identification rate, suggesting that participants often could not discern the origin of the review, thereby highlighting the potential of LLMs to mimic human-like review qualities. However, the study also identifies limitations in LLM's performance, particularly concerning the variability in review quality, which appears to correlate with the model's vocabulary usage of the generated content.},
  keywords={Surveys;Vocabulary;Reviews;Large language models;Machine learning;Transformers;Large language model;machine learning;peer review;generative pre-trained transformer},
  doi={10.1109/ICMLA61862.2024.00187},
  ISSN={1946-0759},
  month={Dec},}@INPROCEEDINGS{11006172,
  author={Shahriary, Amirali and Sedighi, Mohammadsaeid and Tajik, Nima and Shahinfar, Mohammadali and Asiyabar, Amirhossein Rahati},
  booktitle={2025 11th International Conference on Web Research (ICWR)}, 
  title={Assessing Large Language Models as Agile Scrum Masters: A Comparative Study of Project Planning Efficiency}, 
  year={2025},
  volume={},
  number={},
  pages={150-156},
  abstract={Agile project management has become a cornerstone of modern software development, with Scrum Masters playing a critical role in ensuring project success. The advent of large language models (LLMs) has introduced new possibilities for automating project planning tasks, raising questions about their effectiveness compared to human expertise. This study aims to evaluate the feasibility of LLMs in Agile project planning by comparing their performance against human Scrum Masters. A standardized project planning template was used to ensure uniformity across all generated plans, focusing on key Scrum principles such as task breakdown, sprint organization, and risk management. The project plans produced by both LLMs and human Scrum Masters were assessed by software engineering faculty members from the University of Tehran based on predefined evaluation criteria. The results revealed that certain LLMs, including ChatGPT and Gemini Flash 1.5, outperformed human Scrum Masters in terms of operational feasibility, task clarity, and sprint organization. However, the findings also highlighted significant variability in the effectiveness of different models, emphasizing the critical role of prompt engineering in optimizing output quality. While LLMs demonstrated their potential to enhance efficiency and scalability in structured environments, they lacked the human-centric qualities necessary for dynamic project adaptation, risk identification, and team management. This study concludes that LLMs can serve as valuable augmentation tools for Agile project management, complementing human expertise rather than replacing it. Future works should focus on integrating LLMs into dynamic, real-world Agile environments and exploring hybrid approaches that leverage both AI capabilities and human intuition.},
  keywords={Electric breakdown;Large language models;Scalability;Standards organizations;Agile project management;Organizations;Planning;Complexity theory;Prompt engineering;Scrum (Software development);Agile Project Management;Scrum;Large Language Model;Software Development;Project Planning},
  doi={10.1109/ICWR65219.2025.11006172},
  ISSN={2837-8296},
  month={April},}@INPROCEEDINGS{10343189,
  author={Morsy, Mohamed and Farraj, Abdallah and Reavis, David},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={On the Challenges and Opportunities of Using ChatGPT in Academia}, 
  year={2023},
  volume={},
  number={},
  pages={01-06},
  abstract={When it comes to advanced language models, ChatGPT, created by OpenAI, is a standout chatbot that proves to be highly effective in various academic settings. Its ability to generate responses that resemble human ones and offer detailed answers makes it a valuable resource for educational purposes. While its use has potential drawbacks, such as the risk of academic dishonesty, this paper investigates the pros and cons of implementing ChatGPT in educational settings, particularly in engineering and computer science. Through an in-depth evaluation of its effectiveness, the article suggests measures to minimize the likelihood of cheating. ChatGPT presents a promising tool for enhancing students' learning experiences in these fields. ChatGPT's implementation in academia faces many challenges as it becomes essential to consider its pros, cons, and limitations. On the positive side, students can significantly benefit from its ability to help them understand complex concepts, generate questions, and find detailed solutions for their assignments. Educators can also use ChatGPT to provide personalized learning experiences, including immediate feedback and context-based questions. However, a significant concern is the potential for academic dishonesty. Since ChatGPT can produce responses that resemble human-generated ones, students may be tempted to misuse it to cheat on their work, such as writing essays or exam answers. This poses a challenge for educators in identifying plagiarism. Additionally, there is a risk that ChatGPT could be used to create false references or provide inaccurate information. To mitigate the risk of cheating, professors can take several approaches. A possible solution is to educate students about the appropriate use of ChatGPT and incorporate it into the classroom to emphasize its educational value. Another method is to use anti-plagiarism software that can detect if ChatGPT generates the student's work. However, anti-plagiarism software may have varying degrees of success in detecting ChatGPT-generated text. Since ChatGPT creates text that can be very similar to human-generated text, it may be challenging for the software to differentiate between the two. However, some anti-plagiarism software may be designed to recognize patterns in the text that are indicative of machine-generated content, and they may flag such content as potentially plagiarized. Nevertheless, the effectiveness of anti-plagiarism software depends on the type of software being used, its capabilities, and the sophistication of the methods used to generate the text. Additionally, since ChatGPT can generate context-based and original text, it may be more challenging for anti-plagiarism software to detect plagiarism. A new transformation is required for anti-plagiarism software to detect AI-generated texts effectively. Therefore, while anti-plagiarism software may be helpful in detecting some instances of plagiarism, it may not be a foolproof method of detecting ChatGPT-generated text. In Conclusion, while ChatGPT has the potential to be a valuable tool in academia, there are potential negative implications, such as the risk of cheating. Educators must be aware of these risks and take measures to mitigate them.},
  keywords={Text recognition;Plagiarism;Grasping;Writing;Chatbots;Software;Mathematical models;ChatGPT;AI;AI detectors;Engineering Education},
  doi={10.1109/FIE58773.2023.10343189},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10838799,
  author={Shin, Jinnie and Cruz-Castro, Laura and Yang, Zhenlin and Castelblanco, Gabriel and Aggarwal, Ashish and Leite, Walter L. and Carroll, Bruce F.},
  booktitle={2024 Winter Simulation Conference (WSC)}, 
  title={Understanding Optimal Interactions Between Students and A Chatbot During A Programming Task}, 
  year={2024},
  volume={},
  number={},
  pages={3106-3117},
  abstract={This study explores integrating Large Language Models (LLMs) into computer science education by examining undergraduate interactions with a GPT-4-based chatbot during a formative assignment in an introductory course. We aim to delineate optimal help-seeking behaviors and ascertain if effective problem-navigating strategies correlate with improved learning outcomes. Using descriptive statistics and Structural Topic Modeling (STM), we analyze the types of questions posed and their connection to task completion success. Findings reveal a positive association between the number of attempts and help requests, indicating more engaged students seek assistance. STM analysis shows high-ability students address abstract concepts early, while lower-ability students focus on syntax-related issues. These insights underscore the need to evaluate interaction behaviors to optimize chatbot use in education, leading to proposed guidelines to enhance chatbot utilization, promoting responsible use and maximizing educational advantages.},
  keywords={Analytical models;Large language models;Computational modeling;Education;Chatbots;Computer science education;Programming profession;Guidelines},
  doi={10.1109/WSC63780.2024.10838799},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{10470521,
  author={Dean, Max and Bond, Raymond R. and McTear, Michael F. and Mulvenna, Maurice D.},
  booktitle={2023 31st Irish Conference on Artificial Intelligence and Cognitive Science (AICS)}, 
  title={ChatPapers: An AI Chatbot for Interacting with Academic Research}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={A growing and significant number of computer science related papers are being published; hence it is challenging to keep up with the latest research. This paper describes the development of a large language model (LLM) augmentation chatbot and user interface that provides responses to research queries in the domain of computer science. Around 200,000 computer science research papers from arXiv were embedded, resulting in ~11 million vectors (based on ‘chunks’ from the papers). Each vector is comprised of 384 numbers/dimensions. Technologies used include Langchain, a Vector Database, and Semantic Searching with document / query embeddings. The chatbot was tested using 30 sample questions that could be asked by computer science students across several topics and from different education levels (i.e., BSc, MSc and PhD level). The responses from this chatbot were compared with those from GPT-4. The responses with and without prompting were also compared. Readability metrics (Flesch-Kincaid and Coleman-Liau) were used to compare the responses from this LLM with GPT-4. Retrieval Augmented Generation Assessment (RAGAS), a novel LLM self-evaluation method was used to evaluate the system. We observed that the developed system provides more suitable responses to the user based on the readability level at which the questions were asked.},
  keywords={Computer science;Databases;Semantics;Knowledge based systems;Education;User interfaces;Chatbots;large language model;chatbot;retrieval augmented generation;Langchain;vector database;semantic search;GPT-4;Retrieval Augmented Generation Assessment;Readability metrics;Flesch-Kincaid;Coleman-Liau},
  doi={10.1109/AICS60730.2023.10470521},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10423681,
  author={Zdravkova, Katerina and Dalipi, Fisnik and Ahlgren, Fredrik},
  booktitle={2023 International Symposium on Computers in Education (SIIE)}, 
  title={Integration of Large Language Models into Higher Education: A Perspective from Learners}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Large language models (LLMs) are being criticized for copyright infringement, inadvertent bias in training data, a danger to human innovation, the possibility of distributing incorrect or misleading information, and prejudice. Due to their popularity among students, the introduction of many comparable apps, and the inability to resist unfair and fraudulent student usage, their educational use needs to be adapted and harmonized. The incorporation of LLMs should be defined not only by pedagogues and educational institutions, but also by students who will actively utilize them to learn and prepare assignments. In order to find out what students from two universities think and suggest about LLMs use in education, they were asked to give their contribution by answering the survey that was conducted at the beginning of the spring semester of academic 2022/23. Their feedback was quantitatively and qualitatively analyzed, showing in a better light what students think about LLMs and how and why they would use them. Based on the analysis, the authors propose an original strategy for integrating LLMs into education. The proposed approach is also adapted for those students who are not interested in using LLMs and for those who prefer the hybrid mode by combining their own research with LLMs generated recommendations. The authors expect that by implementing the proposed strategy, schools will benefit from a better education in which research, creativity, academic honesty, recognition of false information, and the ability to improve knowledge will prevail.},
  keywords={Surveys;Technological innovation;Computational modeling;Education;Training data;Resists;Springs;AI learning tool;ChatGPT;large language models;academic integrity;students’ feedback;higher education},
  doi={10.1109/SIIE59826.2023.10423681},
  ISSN={2476-2172},
  month={Nov},}@INPROCEEDINGS{10915427,
  author={Meeradevi and PJ, Sriraksha and Vishal, Rahul K and Kulkarni, Pooja S},
  booktitle={2025 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)}, 
  title={Quantales: Bridging Realms with Quantum Generative Adversarial Networks and Transformers in Educational Content Creation}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Traditional teaching methods in Indian schools often lack engaging elements, hindering students’ full comprehension of concepts and fostering a tendency to memorize rather than understand. Existing solutions fail to provide effective visualization-based interactive learning. To address these issues, we propose an interactive application-based solution utilizing generative AI image generation models that can be used by students and teachers. Our application employs interactive story generation, allowing students to prompt creative texts and gain a deeper understanding of concepts. Trained on the school curriculum, this tool facilitates self-study, empowering students to understand complex topics independently. The application extends to classroom use, enabling teachers to incorporate interactive and application-based learning alongside traditional methods. Leveraging Quantum Generative Adversarial Networks (QGANs) and transformer-based models, the system analyses user input, extracts key elements, and creates dynamic story graphs for engaging narrative experiences. The integration of quantum computing enhances the application's capabilities, providing a novel approach to education through dynamic storytelling.In conclusion, the proposed solution seeks to bridge the gap in traditional teaching methods by introducing an innovative and interactive approach to education using Quantum Generative Adversarial Networks. This holistic solution addresses the limitations of current educational practices, offering a transformative learning experience for students and teachers alike.},
  keywords={Solid modeling;Visualization;Quantum computing;Image synthesis;Computational modeling;Education;Generative adversarial networks;Transformers;Solids;System analysis and design;Quantum Generative Adversarial Network(QGAN);Quantum Generative Learning Models(QGLMs)},
  doi={10.1109/IITCEE64140.2025.10915427},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10605388,
  author={Zhu, Gaoxia and Sudarshan, Vidya and Kow, Jason Fok and Soon Ong, Yew},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Human-Generative AI Collaborative Problem Solving Who Leads and How Students Perceive the Interactions}, 
  year={2024},
  volume={},
  number={},
  pages={680-686},
  abstract={This research investigates distinct human-generative AI collaboration types and students’ interaction experiences when collaborating with generative AI (i.e., ChatGPT) for problem-solving tasks and how these factors relate to students’ sense of agency and perceived collaborative problem solving. By analyzing the surveys and reflections of 79 undergraduate students, we identified three human-generative AI collaboration types: even contribution, human leads, and AI leads. Notably, our study shows that 77.21% of students perceived they led or had even contributed to collaborative problem-solving when collaborating with ChatGPT. On the other hand, 15.19% of the human participants indicated that the collaborations were led by ChatGPT, indicating a potential tendency for students to rely on ChatGPT. Furthermore, 67.09% of students perceived their interaction experiences with ChatGPT to be positive or mixed. We also found a positive correlation between positive interaction experience and a sense of positive agency. The results of this study contribute to our understanding of the collaboration between students and generative AI and highlight the need to study further why some students let ChatGPT lead collaborative problem-solving and how to enhance their interaction experience through curriculum and technology design.},
  keywords={Surveys;Ethics;Generative AI;Federated learning;Collaboration;Lead;Chatbots;Human-generative AI collaboration;ChatGPT;problem-solving;agency;overreliance;higher education},
  doi={10.1109/CAI59869.2024.00133},
  ISSN={},
  month={June},}@INPROCEEDINGS{10664407,
  author={Wang, Beian and Wang, Chong and Liang, Peng and Li, Bing and Zeng, Cheng},
  booktitle={2024 IEEE International Conference on Software Services Engineering (SSE)}, 
  title={How LLMs Aid in UML Modeling: An Exploratory Study with Novice Analysts}, 
  year={2024},
  volume={},
  number={},
  pages={249-257},
  abstract={Since the emergence of GPT-3, Large Language Models (LLMs) have caught the eyes of researchers, practitioners, and educators in the field of software engineering. However, there has been relatively little investigation regarding the performance of LLMs in assisting with requirements analysis and UML modeling. This paper explores how LLMs can assist novice analysts in creating three types of typical UML models: use case models, class diagrams, and sequence diagrams. For this purpose, we designed the modeling tasks of these three UML models for 45 undergraduate students who participated in a requirements modeling course, with the help of LLMs. By analyzing their project reports, we found that LLMs can assist undergraduate students as novice analysts in UML modeling tasks, but LLMs also have shortcomings and limitations that should be considered when using them.},
  keywords={Analytical models;Atmospheric modeling;Large language models;Unified modeling language;Software;Software engineering;Large Language Model;Generative AI;Require-ments Analysis;UML Modeling;ChatGPT},
  doi={10.1109/SSE62657.2024.00046},
  ISSN={},
  month={July},}@ARTICLE{11018865,
  author={Pei, Dashuai and Wu, Yiwen and He, Jianhua and Liu, Kezhong and Chen, Mozi and Xiao, Xuedou and Zhang, Shengkai and Zheng, Jiawei},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Methodology and Benchmark for Automated Driving Theory Test of Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={Large Language Models (LLMs), with their strong generalization and inference capabilities, have been increasingly leveraged to address the challenges of handling corner cases in autonomous driving (AD). However, a critical unresolved issue remains: the lack of a comprehensive understanding and formal assessment of LLMs’ driving theory knowledge and practical skills. To address this issue, we propose the first dedicated driving theory test framework and benchmark for LLMs. That is a crucial yet unexplored area in the literature, particularly for safety-critical applications in autonomous driving and driver assistance. Our framework systematically evaluates LLMs’ competence in driving theory and hazard perception, akin to the official UK driving theory test, ensuring their qualification for critical driving-related tasks. To facilitate rigorous benchmarking, we construct a comprehensive dataset comprising over 700 multiple-choice questions (MCQs) and 54 hazard perception video tests sourced from the official UK driving theory examination. Additionally, we incorporate two standardized MCQ sets from the UK’s Driver and Vehicle Standards Agency (DVSA). For these two types of theoretical test items, we design tailored assessment methodologies and evaluation metrics, including accuracy, recall, precision, F1-score, real-time performance, and computational efficiency. The experimental results reveal that among all LLMs tested, only GPT-4o achieved an accuracy of 88. 21% in the MCQs test, successfully passing this component. However, in hazard perception testing, none of the evaluated models met the passing criteria under the given settings, highlighting the substantial improvements required before these models can be practically deployed for real-world driving applications. Our key insight is that the specific test questions LLMs fail to answer correctly directly reflect their deficiencies in understanding and flexibly applying traffic regulations, as well as in analyzing and responding to complex driving scenarios. This provides clear directions for future improvements.},
  keywords={Autonomous vehicles;Decision making;Hazards;Vehicles;Pipelines;Benchmark testing;Computational modeling;Navigation;Large language models;Heavily-tailed distribution;Autonomous driving;large language model;driving theory test;hazard perception test;remote driving;mobile computing},
  doi={10.1109/TITS.2025.3571213},
  ISSN={1558-0016},
  month={},}@INPROCEEDINGS{10235793,
  author={Ashraf, A. and Imam, A.},
  booktitle={8th International Conference on Computing in Engineering and Technology (ICCET 2023)}, 
  title={ChatGPT's use case for software engineers}, 
  year={2023},
  volume={2023},
  number={},
  pages={487-492},
  abstract={The chat-bot GPT-3 has been a boom in the field of tech education for the recent times. Seeing it's growth in a large scale we have tried to direct it towards seeking the ethical help of ChatGPT in our work with respect to a software student's career. In this article we have focused our study on the use of ChatGPT for software engineering students casting light upon how they can use this chat-bot to advance their careers. To do so we analyze three studies that focuses on ChatGPT's functioning in solving coding questions, potential of bug fixing and accessing logic for various mathematical problems. While many articles have already researched ChatGPT and its connection to the field of education, we have differentiated us by analyzing different studies and giving a simple yet effective conclusion to its performance in a single study which makes it easy for software engineers to understand how to best use ChatGPT to boost their careers.},
  keywords={},
  doi={10.1049/icp.2023.1537},
  ISSN={},
  month={July},}@INPROCEEDINGS{10685663,
  author={Li, Yishu and Keung, Jacky and Ma, Xiaoxue},
  booktitle={2024 International Symposium on Educational Technology (ISET)}, 
  title={Integrating Generative AI in Software Engineering Education: Practical Strategies}, 
  year={2024},
  volume={},
  number={},
  pages={49-53},
  abstract={The transformative influence of generative artificial intelligence (AI), notably large language models (LLMs), has significantly reshaped the software engineering (SE) landscape, impacting various aspects of software development within industry and academia. The imperative to integrate generative AI into educational programs arises from the necessity to furnish graduates with contemporary methodologies that enhance software quality and streamline development processes. Nevertheless, a research gap exists concerning the systematic integration of established SE education guidelines with specific course contexts to strengthen SE education through incorporating generative AI. In response to this gap, our study presents a vision for integrating generative AI into SE education, with a particular emphasis on practical integration strategies aimed at endowing students with essential competencies tailored for contemporary software development. Aligning our vision with the knowledge domains within SE education, we delineate its application across specific areas such as code generation, auto test case completion, and others. The overall objective of these proposed initiatives is to furnish students in SE with an updated and immersive learning experience, thereby addressing the evolving demands of the field.},
  keywords={Industries;Systematics;Generative AI;Large language models;Software quality;Educational technology;Software engineering;software engineering;education;generative AI;large language models;code generation;auto test case completion},
  doi={10.1109/ISET61814.2024.00019},
  ISSN={2766-2144},
  month={July},}@INPROCEEDINGS{10628461,
  author={Krishna, Madhava and Gaur, Bhagesh and Verma, Arsh and Jalote, Pankaj},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference (RE)}, 
  title={Using LLMs in Software Requirements Specifications: An Empirical Evaluation}, 
  year={2024},
  volume={},
  number={},
  pages={475-483},
  abstract={The creation of a Software Requirements Specification (SRS) document is important for any software development project. Given the recent prowess of Large Language Models (LLMs) in answering natural language queries and generating sophisticated textual outputs, our study explores their capability to produce accurate, coherent, and structured drafts of these documents to accelerate the software development lifecycle. We assess the performance of GPT-4 and CodeLlama in drafting an SRS for a university club management system and compare it against human benchmarks using eight distinct criteria. Our results suggest that LLMs can match the output quality of an entry-level software engineer to generate an SRS, delivering complete and consistent drafts. We also evaluate the capabilities of LLMs to identify and rectify problems in a given requirements document. Our experiments indicate that GPT-4 is capable of identifying issues and giving constructive feedback for rectifying them, while CodeLlama's results for validation were not as encouraging. We repeated the generation exercise for four distinct use cases to study the time saved by employing LLMs for SRS generation. The experiment demonstrates that LLMs may facilitate a significant reduction in development time for entry-level software engineers. Hence, we conclude that the LLMs can be gainfully used by software engineers to increase productivity by saving time and effort in generating, validating and rectifying software requirements.},
  keywords={Productivity;Accuracy;Large language models;Impedance matching;Natural languages;Benchmark testing;Software;Requirements engineering;software requirements specifications;empirical research;large language models},
  doi={10.1109/RE59067.2024.00056},
  ISSN={2332-6441},
  month={June},}@INPROCEEDINGS{10664905,
  author={Wang, Yang and McCoey, Margaret and Hu, Qian and Jalalitabar, Maryam},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Teaching Security in the Era of Generative AI: A Course Design of Security + ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={01-06},
  abstract={The 2023 CS curriculum by ACM, IEEE, and AAAI identifies security as an independent knowledge area that develops the “security mindset” so that students are ready for the “continual changes” in computing. Likewise, the curriculum emphasises the coverage of “uses”, and “shortcomings/pitfalls” of practical AI-tools like ChatGPT. This paper presents our endeavors to approach those goals with the design of an Information Security course. Our course design bears the following distinct features: Certificate-readiness, where we align the knowledge areas with major security/ethical hacking certificates; Coverage of ChatGPT, where the uses of ChatGPT for assisting security tasks and security issues caused by ChatGPT usage are both addressed for the first time in the teaching; “Learn defending from attackers' perspective”, where labs of both offensive and defensive natures are developed to equally sharpen ethical hacking and hardening skills, and to facilitate the discussion on legal/ethical implications; Current and Representative, where ajust-enough set of representative and/or current security topics are selected in order and covered in respective modules in the most current form. In addition, we generalize our design principles and strategies, with the hope to shed lights on similar efforts in other institutions.},
  keywords={Ethics;Generative AI;Education;Information security;Chatbots;Security;Computer crime;Security;Generative AI;ChatGPT},
  doi={10.1109/ISEC61299.2024.10664905},
  ISSN={2473-7623},
  month={March},}@BOOK{10769246,
  author={Guilmette, Aaron and Miles, Steve and Tender, Peter De},
  booktitle={Microsoft Azure AI Fundamentals AI-900 Exam Guide: Gain proficiency in Azure AI and machine learning concepts and services to excel in the AI-900 exam},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Get ready to pass the certification exam on your first attempt by gaining actionable insights into AI concepts, ML techniques, and Azure AI services covered in the latest AI-900 exam syllabus from two industry experts Key FeaturesDiscover Azure AI services, including computer vision, Auto ML, NLP, and OpenAIExplore AI use cases, such as image identification, chatbots, and moreWork through 145 practice questions under chapter-end self-assessments and mock examsPurchase of this book unlocks access to web-based exam prep resources, including mock exams, flashcards, and exam tipsBook DescriptionThe AI-900 exam helps you take your first step into an AI-shaped future. Regardless of your technical background, this book will help you test your understanding of the key AI-related topics and tools used to develop AI solutions in Azure cloud. This exam guide focuses on AI workloads, including natural language processing (NLP) and large language models (LLMs). You’ll explore Microsoft’s responsible AI principles like safety and accountability. Then, you’ll cover the basics of machine learning (ML), including classification and deep learning, and learn how to use training and validation datasets with Azure ML. Using Azure AI Vision, face detection, and Video Indexer services, you’ll get up to speed with computer vision-related topics like image classification, object detection, and facial detection. Later chapters cover NLP features such as key phrase extraction, sentiment analysis, and speech processing using Azure AI Language, speech, and translator services. The book also guides you through identifying GenAI models and leveraging Azure OpenAI Service for content generation. At the end of each chapter, you’ll find chapter review questions with answers, provided as an online resource. By the end of this exam guide, you’ll be able to work with AI solutions in Azure and pass the AI-900 exam using the online exam prep resources.What you will learnDiscover various types of artificial intelligence (AI)workloads and services in AzureCover Microsoft's guiding principles for responsible AI development and useUnderstand the fundamental principles of how AI and machine learning workExplore how AI models can recognize content in images and documentsGain insights into the features and use cases for natural language processingExplore the capabilities of generative AI servicesWho this book is forWhether you're a cloud engineer, software developer, an aspiring data scientist, or simply interested in learning AI/ML concepts and capabilities on Azure, this book is for you. The book also serves as a foundation for those looking to attempt more advanced AI and data science-related certification exams (e.g. Microsoft Certified: Azure AI Engineer Associate). Although no experience in data science and software engineering is required, basic knowledge of cloud concepts and client-server applications is assumed. },
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835885673},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10769246},}@INPROCEEDINGS{10981409,
  author={Verdicchio, Michael},
  booktitle={2025 IEEE Engineering Education World Conference (EDUNINE)}, 
  title={Adapting Program Assessment for the Age of Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Program assessment practices not designed to account for student use of generative AI have the potential to mislead as to the perceived degree of student outcome attainment in all STEM fields. Understanding how AI tools like Chat-GPT and GitHub Copilot have impacted student approaches to problem-solving will allow us to design and deploy more effective assessment instruments and collect more meaningful data. An assessment plan structured according to ABET accreditation criteria has opportunities at several levels to make meaningful adjustments. This work summarizes recent literature and best practices in program assessment. Next, it offers suggestions for adaptations from the assessment perspective, along with the course-level perspective. Finally, a brief experience report is provided that describes efforts to account for student use of generative AI, along with example assignments, which are described from the perspective of the instructor and student. The experience is then generalized for ETC education with recommendations for other programs to follow.},
  keywords={Generative AI;Instruments;Accreditation;Problem-solving;Engineering education;Best practices;Software development management;assessment;accreditation;ABET;generative AI;performance indicators},
  doi={10.1109/EDUNINE62377.2025.10981409},
  ISSN={},
  month={March},}@INPROCEEDINGS{10554752,
  author={Frankford, Eduard and Sauerwein, Clemens and Bassner, Patrick and Krusche, Stephan and Breu, Ruth},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={AI-Tutoring in Software Engineering Education: Experiences with Large Language Models in Programming Assessments}, 
  year={2024},
  volume={},
  number={},
  pages={309-319},
  abstract={With the rapid advancement of artificial intelligence (AI) in various domains, the education sector is set for transformation. The potential of AI-driven tools in enhancing the learning experience, especially in programming, is immense. However, the scientific evaluation of Large Language Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an AI-Tutor remains largely unexplored. Therefore, there is a need to understand how students interact with such AI-Tutors and to analyze their experiences. In this paper, we conducted an exploratory case study by integrating the GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis. Through a combination of empirical data collection and an exploratory survey, we identified different user types based on their interaction patterns with the AI-Tutor. Additionally, the findings highlight advantages, such as timely feedback and scalability. However, challenges like generic responses and students' concerns about a learning progress inhibition when using the AI-Tutor were also evident. This research adds to the discourse on AI's role in education.},
  keywords={Training;Surveys;Analytical models;Scalability;Education;User interfaces;Data collection;Programming Education;Automated Programming Assessment Systems;Artificial Intelligence;ChatGPT;OpenAI;ChatBots},
  doi={10.1145/3639474.3640061},
  ISSN={2832-7578},
  month={April},}@ARTICLE{10329992,
  author={Schäfer, Max and Nadi, Sarah and Eghbali, Aryaz and Tip, Frank},
  journal={IEEE Transactions on Software Engineering}, 
  title={An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation}, 
  year={2024},
  volume={50},
  number={1},
  pages={85-105},
  abstract={Unit tests play a key role in ensuring the correctness of software. However, manually creating unit tests is a laborious task, motivating the need for automation. Large Language Models (LLMs) have recently been applied to various aspects of software development, including their suggested use for automated generation of unit tests, but while requiring additional training or few-shot learning on examples of existing tests. This paper presents a large-scale empirical evaluation on the effectiveness of LLMs for automated unit test generation without requiring additional training or manual effort. Concretely, we consider an approach where the LLM is provided with prompts that include the signature and implementation of a function under test, along with usage examples extracted from documentation. Furthermore, if a generated test fails, our approach attempts to generate a new test that fixes the problem by re-prompting the model with the failing test and error message. We implement our approach in TestPilot, an adaptive LLM-based test generation tool for JavaScript that automatically generates unit tests for the methods in a given project's API. We evaluate TestPilot using OpenAI's gpt3.5-turbo LLM on 25 npm packages with a total of 1,684 API functions. The generated tests achieve a median statement coverage of 70.2% and branch coverage of 52.8%. In contrast, the state-of-the feedback-directed JavaScript test generation technique, Nessie, achieves only 51.3% statement coverage and 25.6% branch coverage. Furthermore, experiments with excluding parts of the information included in the prompts show that all components contribute towards the generation of effective test suites. We also find that 92.8% of TestPilot's generated tests have $\leq$≤ 50% similarity with existing tests (as measured by normalized edit distance), with none of them being exact copies. Finally, we run TestPilot with two additional LLMs, OpenAI's older code-cushman-002 LLM and StarCoder, an LLM for which the training process is publicly documented. Overall, we observed similar results with the former (68.2% median statement coverage), and somewhat worse results with the latter (54.0% median statement coverage), suggesting that the effectiveness of the approach is influenced by the size and training set of the LLM, but does not fundamentally depend on the specific model.},
  keywords={Training;Test pattern generators;Documentation;Codes;Source coding;Software;Electronic mail;Test generation;JavaScript;language models},
  doi={10.1109/TSE.2023.3334955},
  ISSN={1939-3520},
  month={Jan},}@INPROCEEDINGS{10942198,
  author={Chau, Michelle and Veny and Kurniawan, Priscilla Anthonio and Gui, Anderes},
  booktitle={2024 Beyond Technology Summit on Informatics International Conference (BTS-I2C)}, 
  title={Analyzing Student Ethical Perception on ChatGPT Usage in Indonesian Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={566-571},
  abstract={This study explores the ethical implications and factors influencing ChatGPT adoption in Indonesian higher education. Indonesia presently leads Southeast Asia in ChatGPT usage due to younger generations who are quick to adopt new technology into their daily life. ChatGPT's growing role in education has resulted in numerous benefits, such as intelligent tutoring systems, personalized help, and adaptable learning experiences that have reshaped the learning process. However, students may become overly dependent on this tool, which could undermine the goal of education by weakening higher-level cognitive abilities like creativity, problem-solving, and critical thinking. This research, therefore, set out to evaluate students' knowledge, attitudes, perspectives, concerns, and ethical considerations around ChatGPT usage. Using a quantitative approach, data were collected via an online questionnaire from 512 student respondents and analysed with Partial Least Squares Structural Equation Modeling (PLS-SEM). Results showed that four of the five proposed hypotheses were supported and revealed that knowledge of ChatGPT has no significant impact on its usage, whereas students' attitudes did play a critical role. Moreover, ChatGPT usage significantly influenced students' views, concerns, and their perceptions of ethical considerations. This study provides a novel, student-centered perspective on the ethical considerations of AI in education and sparks discussion on establishing appropriate, accountable use of ChatGPT in Indonesia's higher education system.},
  keywords={Training;Ethics;Education;Chatbots;Mathematical models;Sparks;Problem-solving;Artificial intelligence;Informatics;Guidelines;AI Usage;Artificial Intelligence;ChatGPT;Indonesia Higher Education;Perceived Ethics},
  doi={10.1109/BTS-I2C63534.2024.10942198},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10398310,
  author={Chen, Li and Shimada, Atsushi},
  booktitle={2023 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Designing Worksheet for Using ChatGPT: Towards Enhancing Information Retrieval and Judgment Skills}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={This study introduces a worksheet to support students using ChatGPT for information retrieval and understanding. ChatGPT is a powerful tool; however, its value in education largely depends on how it is used. Therefore, this study aims to provide a design of a worksheet to help students assess the credibility of information through source checks, expertise, and consensus assessment alongside ChatGPT. Scoring criteria are established to determine how students use information judgment strategies through the worksheet. The worksheet and the use of ChatGPT have been introduced in computer science courses at the authors' university. Future work involves refining worksheet scoring and exploring students' use of ChatGPT and its impact on comprehension. This study proposes a potential positive use of ChatGPT in education.},
  keywords={Statistical analysis;Education;Refining;Oral communication;Chatbots;Information retrieval;Reliability;AI in education;ChatGPT;information retrieval;information judgment},
  doi={10.1109/TALE56641.2023.10398310},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10500634,
  author={do Amaral, Inês},
  booktitle={2024 IEEE World Engineering Education Conference (EDUNINE)}, 
  title={Reflection on the use of Generative Language Models as a Tool for Teaching Design}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Design education is undergoing a technological revolution with the integration of Chat GPT into the learning process being one of the most promising innovations. This article explores how this revolutionary technology can have an impact on the teaching of design, providing students and professors with a tool to improve creativity, efficiency and the quality. The aim of this article is to reflect on the importance of using chat GPT in the teaching of design methodology so that in the future we can outline some strategies for effectively incorporating it into the curriculum for teaching design, giving some examples of how teachers can guide students to use the technology ethically and efficiently in their processes. This represents an exciting opportunity to transform the way students learn design. With due caution, it can become a valuable tool for inspiring the next generation of designers and driving innovation in the field of design.},
  keywords={Technological innovation;Ethics;Design methodology;Education;Learning (artificial intelligence);Transforms;Reflection;Chat GPT;Design;Methodologies;Generative Artificial Intelligence Models},
  doi={10.1109/EDUNINE60625.2024.10500634},
  ISSN={},
  month={March},}@INPROCEEDINGS{10923780,
  author={Ismail, Shereen and Lynch, Jenice and Alghazo, Runna},
  booktitle={2024 IEEE 13th International Conference on Engineering Education (ICEED)}, 
  title={Enhancing STEM Education with ChatGPT: A Case Study on Developing Practice Assessments for C Programming}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={ChatGPT has proven its effectiveness as an assistance tool in the learning process for students. In this paper, an experiment was designed using ChatGPT to generate practice problems aligned with specific course objectives for a Computer Science (CS) introductory programming course, focusing on assessment questions in the form of short answer questions (SAQ) and multiple choice questions (MCQ). The paper aims to investigate how ChatGPT can assist educators in generating high quality assessment questions that align with course objectives. The evaluation is done by specialized educators. The findings demonstrate that ChatGPT offers valuable support for teachers in establishing coherent practice exam items that align with course objectives; however, caution must be used when utilizing ChatGPT to create assessment questions to ensure they are error-free and match the evaluation rubric.},
  keywords={Measurement;Electronic learning;Codes;Focusing;Chatbots;Encoding;Quality assessment;Reliability;Engineering education;Programming profession;ChatGPT;Education;C Programming Course;Computer Science;Student Assessment;E-learning},
  doi={10.1109/ICEED62316.2024.10923780},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10893530,
  author={Farhana, Effat and Wu, Fan and Shahriar, Hossain and Karmaker Santu, Shubhra Kanti and Rahman, Akond},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Challenges and Preferences of Learning Machine Learning: A Student Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research paper systematically identifies the perceptions of learning machine learning (ML) topics. To keep up with the ever-increasing need for professionals with ML expertise, for-profit and non-profit organizations conduct a wide range of ML-related courses at undergraduate and graduate levels. Despite the availability of ML-related education materials, there is lack of understanding how students perceive ML-related topics and the dissemination of ML-related topics. A systematic categorization of students' perceptions of these courses can aid educators in understanding the challenges that students face, and use that understanding for better dissemination of ML-related topics in courses. The goal of this paper is to help educators teach machine learning (ML) topics by providing an experience report of students' perceptions related to learning ML. We accomplish our research goal by conducting an empirical study where we deploy a survey with 83 students across five academic institutions. These students are recruited from a mixture of undergraduate and graduate courses. We apply a qualitative analysis technique called open coding to identify challenges that students encounter while studying ML-related topics. Using the same qualitative analysis technique we identify quality aspects do students prioritize ML-related topics. From our survey, we identify 11 challenges that students face when learning about ML topics, amongst which data quality is the most frequent, followed by hardware-related challenges. We observe the majority of the students prefer hands-on projects over theoretical lectures. Furthermore, we find the surveyed students to consider ethics, security, privacy, correctness, and performance as essential considerations while developing ML-based systems. Based on our findings, we recommend educators who teach ML-related courses to (i) incorporate hands-on projects to teach ML-related topics, (ii) dedicate course materials related to data quality, (iii) use lightweight virtualization tools to showcase computationally intensive topics, such as deep neural networks, and (iv) empirical evaluation of how large language models can be used in ML-related education.},
  keywords={Surveys;Privacy;Ethics;Systematics;Data integrity;Education;Machine learning;Security;Virtualization;Faces;artifical intelligence;empirical study;machine learning;perception},
  doi={10.1109/FIE61694.2024.10893530},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10578869,
  author={Palacios-Alonso, Daniel and Urquiza-Fuentes, Jaime and Velázquez-Iturbide, J. Ángel and Guillén-García, Julio},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Experiences and Proposals of Use of Generative AI in Advanced Software Courses}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={The last year, we have witnessed the popularization of generative artificial intelligence. Its output includes text, code, image, audio, speech, voice, music, and video. Therefore, it impacts education courses where students are required to elaborate on any of these artifacts. In particular, the generation of code affects informatics courses, where assignments usually ask students to develop and deliver programming code. The impact of generative artificial intelligence on informatics courses has been mainly studied for introductory programming courses. These studies have shown that generative artificial intelligence is able to produce highly sophisticated programs, but also that its results and rationale can be inaccurate. Moreover, the impact of generative artificial intelligence has not been studied for other informatics subjects. In this paper, we present our preliminary experience and proposals on three advanced software courses, namely video games, advanced algorithms and language processors. For the video games course, we present the opportunities of use of generative artificial intelligence and the results of a survey conducted with students on their use to obtain different media products. For the algorithms course, we present the result of a session driven by the instructor on different design techniques, showing the merits and demerits of the answers generated. For the language processors course, a proposal of use of generative artificial intelligence is presented, broken down into the parts of a typical language processor. The paper concludes with some suggestions for instructors.},
  keywords={Surveys;Video games;Program processors;Codes;Generative AI;Software algorithms;Software;informatics education;generative artificial intelligence;video games;advanced algorithms;language processors},
  doi={10.1109/EDUCON60312.2024.10578869},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10578746,
  author={Styve, Arne and Virkki, Outi T. and Naeem, Usman},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Developing Critical Thinking Practices Interwoven with Generative AI Usage in an Introductory Programming Course}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={Software development has evolved significantly. In the past, developers were required to have comprehensive understanding of programming languages, algorithms, and computer architecture. However, with the emergence of the Internet, software libraries, frameworks, and forums became widely available, which utilize reusable software components that can reduce development time and costs. The advent of Generative Artificial Intelligence (AI) tools, such as ChatGPT, GitHub Copilot, and Amazon CodeWhisperer, has further enhanced the developer's toolkit, as these tools can be used for a wide variety of tasks such as code generation, documentation, commenting and reviewing. As programming is often slow and requires trial and error, novice programmers can be tempted to apply the first solution found on the Internet or proposed by an AI tool without much critical reflection or notion of responsibility. Hence, the advances of AI have raised both excitement and concerns among Information Technology (IT)/Computer Science (CS) students and educators. Yet, AI tools are here to stay, and students must learn to use them responsibly. The aim of this paper is to investigate how to design learning activities that introduce Generative AI tools (GitHub Copilot and ChatGPT) for programming while promoting critical thinking practices among students in an introductory programming course in the first semester. Students' opinions and customs were surveyed before and after the AI-based programming assignment. The results indicate that students' awareness of the possibilities and limitations of AI, as well as practices of critical thinking in programming increased. This is encouraging as critical thinking is an integral part of best programming practices.},
  keywords={Software libraries;Generative AI;Software algorithms;Chatbots;Software;Reflection;Internet;Generative AI;Critical Thinking;Higher Education;CS1},
  doi={10.1109/EDUCON60312.2024.10578746},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10094133,
  author={Kovačević, Darko},
  booktitle={2023 22nd International Symposium INFOTEH-JAHORINA (INFOTEH)}, 
  title={Use of ChatGPT in ESP Teaching Process}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The emergence of ChatGPT, a chatbot launched by OpenAI in November 2022, opened a large amount of opportunities for using the artificial intelligence (AI) for dealing with creation and processing of textual materials, including the use in teaching and learning of foreign languages at all educational and age levels. In terms of the teaching process regarding English for Specific Purposes (ESP), Chat GPT can be used as an effective and time-saving tool for various aspects of preparation and implementation of teaching units and evaluation of students’ written assignments, and that is the topic that will be presented end elaborated in the central part of the paper. Before that, an introduction regarding AI, its use in education and language teaching and learning, ESP and ChatGPT will be made. The final part of the paper will contain the conclusions relating the overall use of this AI tool in teaching ESP.},
  keywords={Vocabulary;Navigation;Education;Machine learning;Learning (artificial intelligence);Chatbots;Software;English for Specific Purposes (ESP);ChatGPT;artificial intelligence (AI);teaching process;text},
  doi={10.1109/INFOTEH57020.2023.10094133},
  ISSN={2767-9470},
  month={March},}@INPROCEEDINGS{10578748,
  author={Martins Ferreira, José Manuel},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={A Strategy for AI-Supplemented Teaching and Learning}, 
  year={2024},
  volume={},
  number={},
  pages={01-10},
  abstract={This paper presents a strategy designed to evaluate AI-supplemented teaching and learning in a course belonging to a master program in Computer Science at the University of South-Eastern Norway. The strategy was closely related to the delivery format adopted in this program, where students take only one course at a time. Each course lasts for 6 weeks, comprising an initial “reading week”, an “intensive lectures” week, a 3-week “project assignment”, and one “assessment week”. The university supported the cost of OpenAI Plus account subscriptions offered to each student while the course was running, and specific activities were proposed to the class exploring the different ways in which AI tutoring could be used during each one of the 4 phases included in the course work plan. The strategy can be adapted to other program delivery formats by redistributing the proposed activities in accordance with the planned sequence of learning activities. It is also independent of which generative AI tool is selected, although OpenAI Plus accounts allow access to specific features that offer relevant pedagogical benefits, e.g., a simple process to create private language models that are easily customizable to each course subject.},
  keywords={Costs;Generative AI;Operating systems;Education;Intellectual property;Writing;Chatbots;generative AI;teaching and learning model},
  doi={10.1109/EDUCON60312.2024.10578748},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10578789,
  author={Balart, Trini and Shryock, Kristi J.},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Work in Progress: Empowering Engineering Education With ChatGPT: A Dive into the Potential and Challenges of Using AI for Tutoring}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={This research explores the integration of ChatGPT, an advanced AI language model, in engineering and computer science education. It investigates ChatGPT's effectiveness in enhancing learning outcomes, engagement, and skill development among first-year engineering students. Utilizing a mixed-method approach in an introductory programming course, the study compares the impact of ChatGPT, traditional teaching assistant support, and a combined method on student performance and perceptions. Anticipated findings aim to illuminate the benefits and challenges of AI tutoring, focusing on personalized learning experiences and ethical considerations in AI integration. This research contributes to the discourse on AI in education, highlighting its potential to transform educational practices and outcomes in engineering and computer science fields.},
  keywords={Ethics;Generative AI;Computational modeling;Scalability;Focusing;Transforms;Chatbots;Engineering education;Artificial intelligence;Computer science education;Educational technology;Intelligent tutoring system;Educational programs;Curriculum development},
  doi={10.1109/EDUCON60312.2024.10578789},
  ISSN={2165-9567},
  month={May},}@ARTICLE{10681094,
  author={Ahmed, Zishan and Shanto, Shakib Sadat and Rime, Most. Humayra Khanom and Morol, Md. Kishor and Fahad, Nafiz and Hossen, Md. Jakir and Abdullah-Al-Jubair, Md.},
  journal={IEEE Access}, 
  title={The Generative AI Landscape in Education: Mapping the Terrain of Opportunities, Challenges, and Student Perception}, 
  year={2024},
  volume={12},
  number={},
  pages={147023-147050},
  abstract={Generative AI (GAI) technologies like ChatGPT are permanently changing academic education. Their integration opens up vast opportunities for bespoke learning and better student interaction but also brings about academic honesty issues and the application of real-life educators. This study aims to fill the literature gap regarding the use of multiple GAI tools and their effect on academic outcomes via a comprehensive review. A systematic literature review was performed following PRISMA guidelines to synthesize results on the potential and drawbacks of GAI in educational domains. We included theoretical and empirical papers that used qualitative, quantitative, or mixed-methods study designs. We have also explored conceptual frameworks and the most creative AI applications with a special emphasis on uniqueness and practicability. Experiences, and Perceptions Concerning To compile the information needed we gathered insights into what students were going through by conducting the survey which contains 200 respondents of undergraduate university students gathering insights into the college students’ experiences and perceptions related to GAI used for educational purposes. At the basic level, GAI comprises areas like personalization, task automation, teacher assistance, and efficiency among others, and respective solutions for the immersion of a learner in learning processes to reform directions. However, it generates plenty of challenges such as the question of assessment integrity, the risk that too much automated grading could overwhelm educational value, and relevantly the veracity of AI-generated content as well as the potential disruption to skills like critical thinking, in addition to data privacy and ethical issues. Student Perception Survey the text also indicates that most students, as per the student perception survey found AI systems useful in academic support. However, they also know the other side of the coin and are very familiar with the technology constraints and challenges.},
  keywords={Education;Generative AI;Artificial intelligence;Surveys;Chatbots;Ethics;Market research;Chatbots;education;generative AI;opportunities and challenges;student perception},
  doi={10.1109/ACCESS.2024.3461874},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10633247,
  author={Orenstrakh, Michael Sheinman and Karnalim, Oscar and Suárez, Carlos Aníbal and Liut, Michael},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Detecting LLM-Generated Text in Computing Education: Comparative Study for ChatGPT Cases}, 
  year={2024},
  volume={},
  number={},
  pages={121-126},
  abstract={Due to the recent improvements and wide availability of Large Language Models (LLMs), they have posed a serious threat to academic integrity in education. Modern LLM-generated text detectors attempt to combat the problem by offering educators with services to assess whether some text is LLM-generated. In this work, we have collected 124 submissions from computer science students before the creation of ChatGPT. We then generated 40 ChatGPT submissions. We used this data to evaluate eight publicly-available LLM-generated text detectors through the measures of accuracy, false positives, and resilience. Our results find that Copy Leaks is the most accurate LLM-generated text detector, G PTKit is the best LLM-generated text detector to reduce false positives, and GLTR is the most resilient LLM-generated text detector. We note that all LLM-generated text detectors are less accurate with code, other languages (aside from English), and after the use of paraphrasing tools.},
  keywords={Measurement;Accuracy;Plagiarism;Large language models;Education;Detectors;Chatbots;Large Language Models;ChatGPT;GPT;AI Detectors;Plagiarism;Academic Integrity},
  doi={10.1109/COMPSAC61105.2024.00027},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{9998298,
  author={Aydın, Nazif and Erdem, O. Ayhan},
  booktitle={2022 3rd International Informatics and Software Engineering Conference (IISEC)}, 
  title={A Research On The New Generation Artificial Intelligence Technology Generative Pretraining Transformer 3}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In the digitalizing world, Artificial Intelligence (AI) paves the way for the automation of routine work done by humans and makes life easier. Recently, there is no area where AI and its applications are not used in daily life, from health to education, from transportation to energy, and from agriculture to tourism. AI applications are making rapid progress in the direction of important and current developments, especially in Natural Language Processing (NLP) and Deep Learning (DL). A concrete example of progress in these areas is the GPT-3 (Generative Pre-trained Transformer 3) language model. AI-assisted GPT-3 technology is the DL model that is effectively used in many NLP fields, which can produce long and consistent content similar to the texts written by people using pre-trained algorithms. The GPT-3 architecture has reached a level that can compete with people in many areas by producing optimum solutions for all kinds of inputs by using the Transformer-based language model, which is an attention-based deep learning technique. This article aims to convey the efficiency, structure and potential of the Transformer-assisted GPT-3 model, which is one of the most up-to-date NLP technologies, to the reader. Since the number of Turkish studies in the field of GPT-3 AI is quite limited, it is considered that this study will contribute to the literature in terms of both quantity and quality. In addition, the performance parameters of the model were examined by making a customized fine-tuned sample application in the beta version of the GPT-3 model.},
  keywords={Deep learning;Automation;Education;Transportation;Computer architecture;Transformers;Natural language processing;Artificial Intelligence;Natural Language Processing;Deep Learning;Transformer;GPT-3},
  doi={10.1109/IISEC56263.2022.9998298},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{10850830,
  author={Kormaník, Tomáš and Gabonai, Michal Gabonai and Porubän, Jaroslav},
  booktitle={2024 International Conference on Emerging eLearning Technologies and Applications (ICETA)}, 
  title={Using Machine Learning Concepts with ControlNet for Educational Advancements}, 
  year={2024},
  volume={},
  number={},
  pages={350-355},
  abstract={Machine learning has become recognized as an important field that is rapidly changing the entire world. Machine learning education primarily targets older students, with little consideration paid to their motivation or participation. This research project considers the integration of ControlNet, a neural network framework for picture production, into Python machine learning applications to enhance student learning via immediately apparent visual feedback. By leveraging ControlNet together with the generative model Stable Diffusion, students can observe the immediate effects of changes in source code on generated images, thereby reducing the gap between theoretical understanding and practical application. This approach promotes student engagement and offers a dynamic platform for studying fundamental machine learning principles, including classification, regression, and model training. The research presented here explains the implementation process, technical obstacles, and advantages of integrating ControlNet into learning environments, giving insights into its potential as an innovative pedagogical instrument. Student feedback and testing reveal that visualbased learning can enhance comprehension and retention of machine learning concepts, rendering this method of teaching an interesting direction for a further look in informatics education.},
  keywords={Training;Visualization;Instruments;Source coding;Scalability;Education;Machine learning;Rendering (computer graphics);Problem-solving;Testing;Education;ControlNet;Stable Diffusion;Machine Learning},
  doi={10.1109/ICETA63795.2024.10850830},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11016556,
  author={Theissler, Andreas and Klaiber, Marco and Gerschner, Felix and Ritzer, Philip and Wang, Jie},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Engaging Students in Scientific Writing: The STRaWBERRY Checklist Framework with LLM-based Paper Draft Assessment}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Writing scientific papers is essential for advancing any given research field, yet undergraduate and graduate students often struggle with this task, facing challenges in clearly presenting their ideas and results. Valuable scientific contributions described in papers that are not well-structured and not easy to follow may not get published. This paper addresses these challenges by proposing a framework called STRaWBERRY, which provides a checklist-based guide to help evaluate individual components of paper drafts against essential quality criteria. Additionally, we propose the use of Large Language Models (LLMs) to automate the assessment based on these criteria. The LLM evaluation process encourages active learning (in the educational sense) and allows the drafts to be iteratively refined through feedback from the LLM. We evaluate the STRaWBERRY framework by its use in lectures and the corresponding outcome: STRaWBERRY has been successfully used in 10 university courses, leading to multiple student pub-lications. Furthermore, we evaluate the LLM-based approach by assessing its accuracy in evaluating a selection of sample papers, demonstrating its potential to supplement and enhance traditional proofreading cycles.},
  keywords={Visualization;Accuracy;Large language models;Conferences;Active learning;Buildings;Writing;Engineering education;Guidelines;scientific writing;guidelines;student engagement;educational active learning;large language models},
  doi={10.1109/EDUCON62633.2025.11016556},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11013578,
  author={Abu-Arqoub, Mohammad and Alkarim Banna, Abed and El-Khalili, Nuha and Al-Shaikh Hasan, Mohammad},
  booktitle={2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA)}, 
  title={Design and Implementation of a Comprehensive RAG-Driven Dashboard Within the ILO System for Data Visualization and Query Support: A Case Study of the University of Petra}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This article presents a comprehensive study on designing and implementing a dashboard for enhanced data visualization and query support at the University of Petra. The system leverages retrieval-augmented generation (RAG) and large language models (LLMs) to support diverse document types, including curricula, course descriptions, and program outcomes, alongside intended learning outcome (ILO)-related files. Our implementation demonstrates significant improvements in data accessibility and query response times while maintaining high accuracy in information retrieval and visualization. Through extensive evaluation, we show that this innovative approach transforms data management processes in higher education by enabling natural language interactions with educational data systems, building upon established business intelligence frameworks while introducing advanced AI capabilities.},
  keywords={Large language models;Retrieval augmented generation;Natural languages;Data visualization;Transforms;Educational technology;Information retrieval;Data systems;Business intelligence;Time factors;RAG;Learning Analytics;Data Visualization;Educational Technology;ILO System;Business Intelligence},
  doi={10.1109/ICCIAA65327.2025.11013578},
  ISSN={},
  month={April},}@INPROCEEDINGS{10869067,
  author={Liu, Longfei and Zhang, Dengbo and Yan, Binger and Wu, Dan},
  booktitle={2024 4th International Conference on Educational Technology (ICET)}, 
  title={EduGuard-LLM: An AI-Generated Content Detector Using Large Language Models for Safeguarding Educational Integrity}, 
  year={2024},
  volume={},
  number={},
  pages={102-105},
  abstract={In response to the widespread use of AI-generated tools by students to complete assignments, which poses significant challenges to educational integrity and fairness, this study proposes a novel detection model called EduGuard-LLM. EduGuard-LLM leverages the powerful text recognition capabilities of large language models to accurately distinguish between student-authored content and AI-generated content across different educational stages. By deeply analyzing text content and identifying AI-generated features, this model can effectively detect the authenticity of student submissions in primary, middle, high school, and university levels. In our experiments, we utilized 21 publicly available datasets, comprising a total of 164,543 text samples, covering various types of texts from elementary to university levels. The model achieved an accuracy of 93.96% on the pre-training dataset, and accuracies of 95.01%, 94.64%, 93.97%, and 94.94% on four external validation sets, respectively. The experimental results demonstrate that EduGuard-LLM has high detection accuracy across different educational stages, effectively ensuring the authenticity of student submissions. This provides strong technical support for educational institutions, maintaining educational integrity.},
  keywords={Adaptation models;Accuracy;Large language models;Soft sensors;Training data;Educational technology;Feature extraction;Data models;Standards;Faces;Educational Integrity;AI-Generated Content Detection;Large Language Model;Text Authenticity Verification},
  doi={10.1109/ICET62460.2024.10869067},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11024507,
  author={Paloniemi, Teemu and Setälä, Manu and Mikkonen, Tommi},
  booktitle={2025 IEEE/ACM 22nd International Conference on Software and Systems Reuse (ICSR)}, 
  title={Porting an LLM based Application from ChatGPT to an On-Premise Environment}, 
  year={2025},
  volume={},
  number={},
  pages={78-83},
  abstract={Given the data-intensive nature of Machine Learning (ML) systems in general, and Large Language Models (LLM) in particular, using them in cloud based environments can become a challenge due to legislation related to privacy and security of data. Taking such aspects into consideration implies porting the LLMs to an on-premise environment, where privacy and security can be controlled. In this paper, we study this porting process of a real-life application using ChatGPT, which runs in a public cloud, to an on-premise environment. The application being ported is AIPA, a system that leverages Large Language Models (LLMs) and sophisticated data analytics to enhance the assessment of procurement call bids. The main considerations in the porting process include transparency of open source models and cost of hardware, which are central design choices of the on-premise environment. In addition to presenting the porting process, we evaluate downsides and benefits associated with porting.},
  keywords={Procurement;Cloud computing;Privacy;Costs;Large language models;Legislation;Machine learning;Chatbots;Software;Hardware;Porting;Large Language Models;LLMs},
  doi={10.1109/ICSR66718.2025.00014},
  ISSN={},
  month={April},}@INPROCEEDINGS{10837643,
  author={Mondego, Domingos and Aziz, Omar},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Mapping the Educational Revolution: A Bibliometric Analysis of ChatGPT's Impact on Teaching and Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study provides a succinct overview of the research conducted on the impact of ChatGPT in education. A bibliometric analysis reveals a significant increase in research activity between November 2022 and April 2024. The study identified and analysed the most relevant papers from this period, focusing on 745 relevant studies sourced from the Scopus database. Key findings include the model's contribution to enhancing learner engagement and optimising knowledge acquisition through personalised learning. The study also examines the influence of ChatGPT on curriculum design, assessment strategies, and the emergence of AI-powered educational tools, such as intelligent tutoring systems and chatbots. While highlighting the transformative potential of ChatGPT in education, ethical considerations are acknowledged, including concerns about assessment value reduction, data privacy, and algorithmic bias. Responsible AI integration is emphasised for a balanced and ethical use in learning environments. The bibliometric analysis identifies prominent authors, countries, and subject areas contributing to the field. Kleebayoon, emerges as a prolific contributor, and the United States leads in citations. Co-word and co-citation analyses reveal clusters of keywords and authors, illustrating interconnected themes and relationships in the literature. The study underscores ChatGPT's transformative potential in education, quantifies research trends through bibliometric analysis, and emphasises the importance of responsible AI integration and addressing ethical considerations in the evolving educational landscape.},
  keywords={Training;Ethics;Data privacy;Pandemics;Knowledge acquisition;Education;Bibliometrics;Chatbots;Market research;Artificial intelligence;Education;ChatGPT;Artificial Intelligence;AI-powered Educational tools;Teaching and Learning;Bibliometric Analysis;Scopus},
  doi={10.1109/ITHET61869.2024.10837643},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10892969,
  author={Mason, Sharon and Borasi, Raffaella and Miller, David and Vaughan-Brogan, Patricia and Han, Yu Jung and DeAngelis, Karen},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Avoiding ‘Sinking the Boat’ While not ‘Missing the Boat’: K-12 Leaders' Early-on Perspectives of AI Risks and Benefits and Their Implications for Developers}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This full research to practice paper reports on early perspectives from K-12 leaders regarding AI use in schools. With the advent of generative AI applications, K-12 leaders have a key role in providing (or precluding) access to students and teachers' uses of AI tools - as superintendents, principals and other district and school-level administrators will continue to be making (or at the very least informing) decisions about what AI tools will be made available as well as policies governing their use. These decisions will be informed by what K-12 leaders perceive are the potential risks and benefits of AI - as a key charge for K-12 leaders considering any innovation is to evaluate its potential to support student learning while reducing potentially harmful consequences. It is important to understand these current perceptions, especially for anyone designing applications of AI for K-12 education. While previous work has reported on teachers' views of AI, the perspectives of K-12 leaders, who serve as thought-leaders and decision makers, remain largely unexplored. U sing a semi-structured interview protocol, in late 2023, researchers interviewed 36 K-12 leaders across 23 districts in western New York state in order to gather their early perspectives regarding AI and to answer the research question: How do K-12 leaders perceive the risks and opportunities associated with using artificial intelligence in their school environments? Participants included superintendents, principals and various district and school-level administrators as well as some teacher leaders. These K-12 leaders articulated risks that can be categorized by four themes: (a) concerns regarding the ethical use of AI by both students and teachers (including cheating), (b) concerns around privacy and cybersecurity, (c) concerns around the accuracy or legitimacy of the output from AI systems and (d) concerns about replacing people/jobs. At the same time, these K-12 leaders recognized several important opportunities presented by AI, which should also be taken into consideration when making decisions, including (a) preparing students for the future, (b) improving potential for learning and instructional development and (c) supporting K-12 educators. Collectively, these risks and opportunities can be characterized with the idea that K-12 leaders were aware of the need to balance the risks in order to not “sink the boat” while also using care to not delay actions and potentially “miss the boat,” and which represents a more nuanced view of risk, consistent with what has been identified in the entrepreneurship literature. This work has implications for deliberate and informed decision-making regarding policies for and use of AI in the K-12 domain, and the supports needed for their adoption and effective use. The findings also provide valuable insights for developers of domain specific AI systems for K-12 schools. As computer scientists and engineers continue to train models, develop and select algorithms to serve schools, learners and educators, considering the risks and opportunities articulated by K-12 thought leaders and decision makers can support their work in advancing the technologies and potentially improving adoption.},
  keywords={Technological innovation;Privacy;Ethics;Protocols;Generative AI;Boats;Entrepreneurship;Delays;Artificial intelligence;Interviews;artificial intelligence;K-12 leaders;K-12 schools},
  doi={10.1109/FIE61694.2024.10892969},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10578655,
  author={Socher, Gudrun and Weisser, Tina},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Shaping the Future: A Cross-Disciplinary Journey in Design and Technology Integration}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In today's world, where digital technologies and artificial intelligence (AI) are everywhere, the education sector is challenged with updating its course formats to stay relevant and future-focused. This paper discusses an innovative educational approach in the Informatics and Design program, combining computer science elements with design education. The program differs from traditional computer science curriculums. It caters to students with heterogeneous levels of tech skills and emphasizes a balanced approach to teach both, design and software development. Central to this program is a unique project co-taught by a computer scientist and a service designer. The project centers on creating a chatbot, incorporating the latest in Natural Language Processing and Large Language Models. This initiative not only keeps pace with the latest tech developments but also stresses the importance of a human-centered design approach in merging design with technology. The outcomes of this educational approach demonstrate that when design and technology are taught in tandem, it leads to a more comprehensive understanding and skill set among students. This approach not only prepares them for the current landscape of digital technology but also instills a mindset of continuous adaptation and learning, which is crucial in the ever-evolving field of informatics and design.},
  keywords={Computer science;Merging;Prototypes;Chatbots;Informatics;Engineering education;Stress;transdisciplinarity;curriculum design;AI education;chatbots;human-centered design},
  doi={10.1109/EDUCON60312.2024.10578655},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10893165,
  author={Torek, Adam and Sorensen, Elijah and Hahle, Natalie and Kennington, Casey},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={A Systematic Evaluation of Code-generating Chatbots for Use in Undergraduate Computer Science Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research paper focuses on evaluating code-generating chatbots. Chatbots like ChatGPT released in the past three years have proven capable of a wide variety of tasks within a conversational interaction, including writing code and answering code-related questions. With these recent advances, chatbots have many potential uses in education, including computer science education. However, before these chatbots are used in CS curricula, their capabilities and limitations must be systematically tested and understood. In this work, we evaluate the capabilities and limitations of four known, open-source, code-based chatbots in programming tasks by performing a standardized study in which different chatbots are tasked with providing answers for a variety of assignments from Boise State University's computer science program. We found that while all of the chatbots can write code and provide explanations, some do better than others, and each of them work differently in conversations. Moreover, all of them suffered similar and important limitations, which has implications for adoption in curriculum. As a second experiment, we used the Llama chatbot to perform a human evaluation by enabling student novice and experienced programmers to use it as a coding assistant to complete specific tasks in a common software development environment. We found that the coding assistant can help novice programmers accomplish simple tasks in comparable time and code efficacy as more experienced programmers. Given these experiments, and given feedback from participants in our studies, we see a clear picture emerge: new programmers should learn important concepts about programming without the help of code assistants so students can (1) demonstrate their understanding of important concepts and (2) have enough experience to assess code assistant output as useful or erroneous. Then, once intermediate skills are mastered (e.g., object oriented programming and data structures), it seems appropriate to introduce students systematically to coding assistants to help with specific assignments throughout the undergraduate computer science curriculum. We conclude by addressing ethical considerations for the use of code-based chatbots in computer science education and future directions of research.},
  keywords={Codes;Systematics;Object oriented modeling;Computational modeling;Writing;Chatbots;Encoding;Computer science education;Programming profession;Software development management;chatbot;large language models;code copilot},
  doi={10.1109/FIE61694.2024.10893165},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10828756,
  author={Durrani, Usman and Akpinar, Mustafa and Togher, Madeleine and Malik, Asif and Dordevic, Milan and Aoudi, Samer},
  booktitle={2024 International Conference on Artificial Intelligence, Metaverse and Cybersecurity (ICAMAC)}, 
  title={Harnessing AI for Personalized Academic Major Recommendations An Application of Large Language Models in Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the domain of educational counseling, the utilization of Large Language Models (LLMs) in conjunction with sophisticated AI technologies, such as embeddings and vector databases, introduces a groundbreaking methodology for advising students on their academic specializations. This study explores the complexities associated with conventional recommendation systems, which include issues like data imbalance and insufficient contextual awareness etc. By adopting a FewShot Learning framework, we harness the flexibility of LLMs to identify critical factors related to students’ interests and competencies. Our approach enables the dynamic extraction of important contextual information, thereby enhancing the predictive efficacy of the models. Through comprehensive experimentation with varied student datasets, we will experiment on if our AI system outperforms traditional recommendation techniques implemented by academic advisors and if it can yield detailed analyses customized to individual student profiles. This pioneering strategy holds considerable potential for advancing academic advising and assisting students in making well-informed choices regarding their educational trajectories.},
  keywords={Employee welfare;Metaverse;Databases;Large language models;Education;Predictive models;Vectors;Trajectory;Data mining;Recommender systems;Artificial Intelligence in Education;Large Language Models Personalized Academic Advising;Educational Recommender Systems;AI-Powered Recommendations},
  doi={10.1109/ICAMAC62387.2024.10828756},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10981346,
  author={Morales-Chan, Miguel and Amado-Salvatierra, Hector R. and Hernandez-Rizzardini, Rocael and Román, Byron Linares},
  booktitle={2025 IEEE Engineering Education World Conference (EDUNINE)}, 
  title={Workshop: Transforming Student Interaction through Building Educational Chatbots in Engineering and Computing}, 
  year={2025},
  volume={},
  number={},
  pages={1-2},
  abstract={Educational chatbots offer a potential way to enhance student engagement and provide ongoing support throughout a course. This workshop is designed to empower educators with the skills to create educational chatbots tailored to classroom needs using the no-code platform Chatbase, alongside an introduction to OpenAI's API capabilities for non-programmers. Participants will explore the evolving capabilities of AI in creating chatbots that deliver local, course-specific context, such as assignment details, deadlines, and customized responses. The session emphasizes designing chatbot flows that support realistic educational interactions and integrate content specific to their courses. By the end of the workshop, educators will have a working prototype of a chatbot tailored to their specific class requirements, enhancing engagement in personalized learning. This hands-on experience offers an accessible path for educators to embrace AI-driven tools in education.},
  keywords={Generative AI;Conferences;Buildings;Prototypes;Chatbots;Engineering education;artificial intelligence;Chatbot;generative AI tools;LLMs},
  doi={10.1109/EDUNINE62377.2025.10981346},
  ISSN={},
  month={March},}@ARTICLE{10285884,
  author={Wang, Mo and Wang, Minjuan and Xu, Xin and Yang, Lanqing and Cai, Dunbo and Yin, Minghao},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Unleashing ChatGPT's Power: A Case Study on Optimizing Information Retrieval in Flipped Classrooms via Prompt Engineering}, 
  year={2024},
  volume={17},
  number={},
  pages={629-641},
  abstract={This research project investigates the impact of prompt engineering, a key aspect of chat generative pretrained transformer (ChatGPT), on college students' information retrieval in flipped classrooms. In recent years, an increasing number of students have been using AI-based tools, such as ChatGPT rather than traditional research engines to learn and to complete course assignments. Despite this growing trend, previous research has largely overlooked the influence of prompt engineering on students' use of ChatGPT and effective strategies for improving the quality of information retrieval in learning settings. To address this research gap, this study examines the information quality obtained from ChatGPT in a flipped classroom by evaluating its effectiveness in task completion among 26 novice undergraduates from the same major and cohort. The experimental results provide evidence that proficient mastery of prompt engineering improves the quality of information obtained by students using ChatGPT. Consequently, by acquiring proficiency in prompt engineering, students can maximize the positive impact of ChatGPT, obtain high-quality information, and enhance their learning efficiency in flipped classrooms.},
  keywords={Chatbots;Artificial intelligence;Task analysis;Online services;Electronic learning;Transformers;Oral communication;Chat generative pretrained transformer (ChatGPT);flipped classrooms;information retrieval;prompt engineering},
  doi={10.1109/TLT.2023.3324714},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{11021219,
  author={Aspra, Nico O. and Chong, Chien Hwa},
  booktitle={2025 Systems and Information Engineering Design Symposium (SIEDS)}, 
  title={Developing an AI-Driven NC Programming Assistant: A Productive Failure Approach in CNC Education}, 
  year={2025},
  volume={},
  number={},
  pages={438-443},
  abstract={The integration of artificial intelligence (AI) into engineering and technology education offers new possibilities for enhancing student learning and feedback delivery. In machining, where accuracy and logic are essential, AI can serve as a powerful support tool. This paper presents the NC Programming Assistant, an application that combines rule-based logic and generative AI to help students write and debug numerical control (NC) programs. The assistant provides real-time, context-specific feedback on errors such as syntax issues and safety violations, enabling students to revise their work and strengthen their programming skills. Grounded in the Productive Failure Model, the assistant is designed not only to correct errors but also to encourage learners to engage in trial, failure, and reflection. The tool was deployed in a machining course, where its impact was evaluated through surveys, usage data, and statistical analysis. Results showed improvements in student confidence, debugging ability, and comprehension. By providing immediate and personalized feedback, the assistant addresses common instructional challenges in technical education and demonstrates how theory-informed AI tools can enhance learning outcomes in skill-based disciplines.},
  keywords={Generative AI;Education;Debugging;Machining;Learning (artificial intelligence);Syntactics;Reflection;Logic;Time factors;Programming profession;Artificial intelligence;Education;CNC Programming;Productive Failure},
  doi={10.1109/SIEDS65500.2025.11021219},
  ISSN={2994-3531},
  month={May},}@ARTICLE{10916617,
  author={Chen, Xin and Zhang, Jin and Zhou, Tong and Zhang, Feng},
  journal={IEEE Access}, 
  title={LLM-CDM: A Large Language Model Enhanced Cognitive Diagnosis for Intelligent Education}, 
  year={2025},
  volume={13},
  number={},
  pages={47165-47180},
  abstract={Cognitive diagnosis is a key component of intelligent education to assess students’ comprehension of specific knowledge concepts. Current methodologies predominantly rely on students’ historical performance records and manually annotated knowledge concepts for analysis. However, the extensive semantic information embedded in exercises, including latent knowledge concepts, has not been fully utilized. This paper presents a novel cognitive diagnosis model based on the LLAMA3-70B framework (referred to as LLM-CDM), which integrates prompt engineering with the rich semantic information inherent in exercise texts to uncover latent knowledge concepts and improve diagnostic accuracy. Specifically, this study first inputs exercise texts into a large language model and develops an innovative prompting method to facilitate deep mining of implicit knowledge concepts within these texts by the model. Following the integration of these newly extracted knowledge concepts into the existing Q matrix, this paper employs a neural network to diagnose students’ understanding of knowledge concepts while applying the monotonicity assumption to ensure the interpretability of model factors. Experimental results from an examination data set for course completion assessments demonstrate that LLM-CDM exhibits superior performance in both accuracy and explainability.},
  keywords={Education;Large language models;Annotations;Accuracy;Semantics;Prompt engineering;Printers;Optimization;Manuals;Long short term memory;Cognitive diagnosis;large language models;exercise texts;higher education and intelligent education},
  doi={10.1109/ACCESS.2025.3549309},
  ISSN={2169-3536},
  month={},}@ARTICLE{10508087,
  author={Liao, Jian and Zhong, Linrong and Zhe, Longting and Xu, Handan and Liu, Ming and Xie, Tao},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Scaffolding Computational Thinking With ChatGPT}, 
  year={2024},
  volume={17},
  number={},
  pages={1628-1642},
  abstract={ChatGPT has received considerable attention in education, particularly in programming education because of its capabilities in automated code generation and program repairing and scoring. However, few empirical studies have investigated the use of ChatGPT to customize a learning system for scaffolding students’ computational thinking. Therefore, this article proposes an intelligent programming scaffolding system using ChatGPT following the theoretical framework of computational thinking and scaffolding. A mixed-method study was conducted to investigate the affordance of the scaffolding system using ChatGPT, and the findings show that most students had positive attitudes about the proposed system, and it was effective in improving their computational thinking generally but not their problem-solving skills. Therefore, more scaffolding strategies are discussed with the aim of improving student computational thinking, especially regarding problem-solving skills. The findings of this study are expected to guide future designs of generative artificial intelligence tools embedded in intelligent learning systems to foster students’ computational thinking and programming learning.},
  keywords={Chatbots;Education;Programming profession;Codes;Task analysis;Problem-solving;Encoding;Artificial-intelligence-generated content (AIGC);ChatGPT;computational thinking (CT);scaffolding},
  doi={10.1109/TLT.2024.3392896},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{11016545,
  author={Mohammed, Crista and Rocke, Sean},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Electrical and Computer Engineering Freshmen and Generative AI: Awareness, Attitudes, and Ethics}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={We are responding to calls for students to be trained in using generative AI (GAI). But training must take account of what students know; their prevailing attitudes; and their ethics with respect to using GAI. And knowing what our students know about GAI gives instructors an opportunity to co-construct meaningful teaching and learning moments. A class of 103 students, enrolled in the course Communication in the Engineering Sciences, in our BSc program in Electrical and Computer Engineering, was probed on their use of generative AI. The study draws on two datasets—student responses to a case study on unethical use of GAI and a questionnaire gathering qualitative data. Questionnaire responses reveal that generally students understand the basics of how GAI works. But this understanding is flawed, for example some students erroneously believe that GAI draws in real time from the Internet. Most respondents have used GAI in their studies, particularly to clarify concepts and summarize. We did not find widespread use of GAI for higher cognitive tasks. But this we suspect is linked to program sequencing: as students advance in their program more sophisticated uses of GAI are likely. This supports the need for longitudinal studies which track use in relation to program advancement. Like peers elsewhere, this class expressed concern about GAI's ability to propagate misinformation and bias; GAI-facilitated plagiarism; data privacy; and overreliance leading to impairment of learning. As it relates to whether GAI qualifies as an author, students demonstrated a fairly nuanced understanding of this complex issue. One student felt that this was a gray area, citing that even outside of GAI generated content, scholars build on each other's work to such an extent that the originality of any work can be questioned. In case study responses, all 103 students agreed that using GAI without permission is dishonest. Respondents noted that students, instructors, and university administration each have a responsibility to ensure that GAI is not misused. And like peers elsewhere, they welcome institutional policy and guidance on using GAI.},
  keywords={Training;Ethics;Sequential analysis;Data privacy;Generative AI;Plagiarism;Real-time systems;Internet;Engineering education;Fake news;academic honesty;engineering education;ethics;freshmen;generative AI},
  doi={10.1109/EDUCON62633.2025.11016545},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11016518,
  author={Dewan, Umama and Hingle, Ashish and McDonald, Nora and Johri, Aditya},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Engineering Educators' Perspectives on the Impact of Generative AI in Higher Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The introduction of generative artificial intelligence (GenAI) has been met with a mix of reactions by higher education institutions, ranging from consternation and resistance to whole-hearted acceptance. Previous work has looked at the discourse and policies adopted by universities across the U.S. as well as educators, along with the inclusion of GenAI-related content and topics in higher education. Building on previous research, this study reports findings from a survey of engineering educators on their use of and perspectives toward generative AI. Specifically, we surveyed 98 educators from engineering, computer science, and education who participated in a workshop on GenAI in Engineering Education to learn about their perspectives on using these tools for teaching and research. We asked them about their use of and comfort with GenAI, their overall perspectives on GenAI, the challenges and potential harms of using it for teaching, learning, and research, and examined whether their approach to using and integrating GenAI in their classroom influenced their experiences with GenAI and perceptions of it. Consistent with other research in GenAI education, we found that while the majority of participants were somewhat familiar with GenAI, reported use varied considerably. We found that educators harbored mostly hopeful and positive views about the potential of GenAI. We also found that those who engaged more with their students on the topic of GenAI, both as communi-cators (those who spoke directly with their students) and as incorporators (those who included it in their syllabus), tend to be more positive about its contribution to learning, while also being more attuned to its potential abuses. These findings suggest that integrating and engaging with generative AI is essential to foster productive interactions between instructors and students around this technology. Our work ultimately contributes to the evolving discourse on GenAI use, integration, and avoidance within educational settings. Through exploratory quantitative research, we have identified specific areas for further investigation.},
  keywords={Surveys;Resistance;Computer science;Ethics;Generative AI;Shape;Conferences;Distance measurement;Engineering education;Lenses;Generative AI;teaching and research;higher education;engineering education},
  doi={10.1109/EDUCON62633.2025.11016518},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11023952,
  author={Sheng, Junjie and Lin, Yanqiu and Wu, Jiehao and Huang, Yanhong and Shi, Jianqi and Zhang, Min and Wang, Xiangfeng},
  booktitle={2025 IEEE/ACM 47th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)}, 
  title={SolSearch: An LLM-Driven Framework for Efficient SAT-Solving Code Generation}, 
  year={2025},
  volume={},
  number={},
  pages={6-10},
  abstract={The Satisfiability (SAT) problem is a core challenge with significant applications in software engineering, including automated testing, configuration management, and program verification. This paper presents SolSearch, a novel framework that harnesses large language models (LLMs) to discover and optimize SAT-solving strategies automatically. Leveraging a curriculum-based, trial-and-error process, SolSearch enables the LLM to iteratively modify and generate SAT solver code, thereby improving solving efficiency and performance. This automated SAT-solving paradigm has the advantage of being plug-and-play, allowing integration with any SAT solver and accelerating the development or design process of new SAT solvers (new methods). Our preliminary experimental results are encouraging by demonstrating that the LLM-powered paradigm improves state-of-the-art SAT solvers on general SAT benchmarks and significantly enhances the performance of the widely used Z3 solver (11% on PAR-2 score). These results highlight the potential for using LLM-driven methods to advance solver adaptability and effectiveness in real-world software engineering challenges. Future research directions are discussed to further refine and validate this approach, offering a promising avenue for integrating AI with traditional software engineering tasks.},
  keywords={Codes;Large language models;Configuration management;Benchmark testing;Software engineering;Large Language Models (LLM);SAT Solver;Code Generation;Heuristic Method},
  doi={10.1109/ICSE-NIER66352.2025.00007},
  ISSN={2832-7632},
  month={April},}@ARTICLE{10843681,
  author={Shoaib, Muhammad and Husnain, Ghassan and Sayed, Nasir and Yasin Ghadi, Yazeed and Alajmi, Masoud and Qahmash, Ayman},
  journal={IEEE Access}, 
  title={Automated Generation of Multiple-Choice Questions for Computer Science Education Using Conditional Generative Adversarial Networks}, 
  year={2025},
  volume={13},
  number={},
  pages={16697-16715},
  abstract={This work presents a novel perspective towards generating automated multiple-choice questions (MCQs)-a task fundamentally different due to the highly dynamic nature of computer science education, which spans several sub-domains. Taking advantage of Conditional Generative Adversarial Networks (cGANs), our model provides a versatile approach to addressing the need for diversity and context in relevant MCQ generation across proficiency levels, topic areas. Resulting MCQs inspire implementations within a variety of educational environments - from classrooms, to online courses, and finally exams - equipping teachers with an instrument that could be easily adapted based on the specific needs o students. The model is trained on a carefully constructed dataset that includes material from more than 20 subareas in computer science, consisting of materials such as textbooks, online encyclopedias and Q&A websites. Through rigorous evaluation using comprehensive performance metrics, including Question Relevance Score (QRS), Diversity Index (DI), and Difficulty Alignment Accuracy (DAA), we demonstrate the efficacy and robustness of our framework in generating high-quality MCQs. Moreover, we address ethical considerations inherent in AI-driven educational assessment, ensuring fairness, transparency, and accountability in the MCQ generation process. The cGAN architecture facilitates the generation of contextually relevant MCQs across various proficiency levels and subject domains, enhancing the educational assessment process. The comprehensive dataset developed for this study encompasses diverse computer science topics curated from authoritative textbooks, online resources, question banks, and instructor-generated content. Additionally, a user-friendly QT application has been developed, enabling seamless integration of the cGAN model into educational environments. Through rigorous evaluation and ethical considerations, this framework demonstrates its efficacy, ensuring fairness, transparency, and accountability in MCQ generation. This interdisciplinary work represents a significant advancement in computer science education, providing educators with a powerful tool to enhance student engagement and learning outcomes.},
  keywords={Education;Computer science;Computer science education;Generative adversarial networks;Computational modeling;Indexes;Ethics;Chatbots;Training;Testing;Automated MCQ generation;conditional generative adversarial networks (cGANs);computer science education;dataset curation;educational assessment},
  doi={10.1109/ACCESS.2025.3530474},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10983252,
  author={Bhatia, Gaurav and Alhajri, Raya},
  booktitle={2025 International Conference for Artificial Intelligence, Applications, Innovation and Ethics (AI2E)}, 
  title={Accelerate Learning with AI Powered Quiz Master Using Llama LLM}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Multiple-choice questions quizzes provide an interactive and engaging way to assess students' understanding and reinforce learning, but their manual creation can be time-consuming and labor-intensive for educators. The emergence of Large Language Models (LLMs) offers a transformative solution by enabling automated MCQ generation, correction, and personalized feedback. LLMs, with their advanced natural language understanding and generation capabilities, facilitate the creation of diverse and adaptive MCQ quizzes that cater to various learning objectives and difficulty levels. This paper introduces Quiz Master, an AI-powered platform for automated MCQ quiz generation, correction, and feedback, developed using open-source tools such as Meta Llama, Ollama, LangChain, and Streamlit. Quiz Master delivers an engaging and personalized learning experience, allowing students to actively participate in quizzes while receiving instant, adaptive feedback. By optimizing quiz creation and reducing educator workload, Quiz Master demonstrates the potential of LLMs to enhance educational practices, making learning more enjoyable, interactive, and effective.},
  keywords={Human computer interaction;Technological innovation;Ethics;Adaptation models;Adaptive systems;Large language models;Education;Manuals;Natural language processing;Data models;LLM;Llama3.2;Ollama;LangChain;Streamlit;AI},
  doi={10.1109/AI2E64943.2025.10983252},
  ISSN={},
  month={Feb},}@BOOK{10769323,
  author={Wen, Jun},
  booktitle={Accelerating IoT Development with ChatGPT: A practical guide to building your first IoT project using AI-assisted coding and cloud integration},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Build cutting-edge projects with ChatGPT, PlatformIO, ESP32, and Arduino-compatible sensors by integrating AWS Cloud and the ThingsBoard dashboardKey FeaturesLeverage ChatGPT to generate code on ESP32 for sending sensor data to AWS CloudCreate your own visualization dashboard on ThingsBoard CloudFollow step-by-step configuration guidance to ingest, process, store, and query data on AWS CloudPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionUnlike other IoT books that focus on theory and generic applications, this guide takes a practical approach, empowering you to leverage ChatGPT to build your very first IoT prototype. With over 20 years of experience in wireless and IoT technologies and a background as an instructor, Jun Wen expertly guides you from project kick-off to a fully functional prototype. The book emphasizes the transformative impact of ChatGPT for IoT, teaching you how to use ChatGPT to generate code for your applications, even with limited coding experience. You’ll be introduced to using PlatformIO IDE within Visual Studio Code and discover the cutting-edge RISC-V architecture, the ESP32 MCU, Arduino-compatible sensors, and integration methods for AWS and the ThingsBoard dashboard. Working through 10 different project examples, including flame detection, smoke detection, and air quality measurement, you’ll become proficient in the functions and specifications of each sensor and the use cases they solve. By the end of this book, you’ll be ready to undertake IoT development projects, bridging the gap between your ideas and functional creations.What you will learnMaster IoT essentials, such as networks, end devices, wireless connectivity, and the cloudExplore the ChatGPT prompting framework and build crucial skills for IoT projectsDiscover best practices for building robust IoT hardware prototypesFind out how to set up Visual Studio Code and PlatformIO IDEConnect ESP32 to AWS through TLS and MQTTExplore popular connectivity technologies widely adopted in IoTIntegrate IoT sensors with ESP32 to capture accurate data using ChatGPT's assistanceWho this book is forIf you’re a beginner interested in applying IoT technology to your projects but face challenges due to limited experience in embedded software coding, specifically in C and C++, this book is for you. Whether you’re a student, hardware hobbyist, DIY enthusiast, IoT developer, or professional from a non-technical background, if you feel that your ability to innovate is often stalled by the complexity of software coding, this easy-to-follow guide to using ChatGPT for generating example code will boost your IoT prototype development.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835467879},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10769323},}@ARTICLE{10979380,
  author={Maraza-Quispe, Benjamín and Hugo Rosas-Iman, Victor and Feliciano-Yucra, Giuliana and Cesar Martínez-Lopez, Atilio and Marianela Quispe-Flores, Lita and Reyes-Villalba, Edwin and Pablo Nina-Mita, Pedro},
  journal={IEEE Revista Iberoamericana de Tecnologias del Aprendizaje}, 
  title={Enhancing Research Capabilities in Teaching and Learning: The Transformative Impact of ChatGPT}, 
  year={2025},
  volume={20},
  number={},
  pages={115-124},
  abstract={The research analyzes the impact of ChatGPT on the development of investigative competencies in students of regular basic education, focusing on three main aspects: its role in information retrieval, its contribution to the generation of accurate and relevant content, and its usability in fostering investigative skills. An experimental design was applied to a sample of 100 students, with 50 students using ChatGPT during the development of learning sessions and a control group of 50 students conducting their sessions through traditional methods. The students developed research projects evaluated according to six key criteria: coherence, precision, originality, content depth, problem-solving ability, and source management. Descriptive and comparative statistical analyses indicated that the experimental group outperformed the control group in coherence, precision, and originality. However, the control group showed better performance in source management, suggesting that traditional methodologies remain more effective for handling bibliographic references and searching for reliable sources. Regarding content depth and problem-solving ability, both groups achieved similar results, with a slight advantage observed in the experimental group. In summary, ChatGPT improves students’ coherence, precision, and originality in research tasks. Nonetheless, it is recommended to integrate its use with traditional methods to strengthen source management and ensure the comprehensive development of investigative competencies, promoting the ethical and responsible use of technology.},
  keywords={Chatbots;Education;Artificial intelligence;Ethics;Usability;Training;Learning (artificial intelligence);Data privacy;Collaboration;Coherence;ChatGPT;investigative competencies;information retrieval;research skills development;educational technology},
  doi={10.1109/RITA.2025.3565180},
  ISSN={1932-8540},
  month={},}@INPROCEEDINGS{10980840,
  author={Mangarelli, Eduardo},
  booktitle={2025 IEEE Engineering Education World Conference (EDUNINE)}, 
  title={Plenary: Enhancing Engineering Education: Integrating Generative AI Tools}, 
  year={2025},
  volume={},
  number={},
  pages={1-2},
  abstract={Generative Artificial Intelligence and Large Language Models are reshaping the way we produce, refine, and engage with information. This plenary focuses on the implications of these technologies, specifically in engineering education, highlighting both the general educational benefits and the unique demands of adapting established engineering practices to leverage Artificial Intelligence (AI) effectively. We discuss practical strategies for classroom and laboratory integration, illustrate how software engineering workflows must accommodate AI-generated code, and underscore the importance of equipping future engineers with the essential technical and ethical competencies. Finally, we address the broad challenge of envisioning how industry and academic disciplines may evolve in response to AI, so that institutions can proactively provide learners with the skills and knowledge needed for the professions of tomorrow.},
  keywords={Industries;Ethics;Codes;Generative AI;Large language models;Engineering education;Software engineering;Generative AI;Engineering Education;AI Engineering Workflows},
  doi={10.1109/EDUNINE62377.2025.10980840},
  ISSN={},
  month={March},}@INPROCEEDINGS{10554692,
  author={Gallagher, Shannon K. and Ratchford, Jasmine and Brooks, Tyler and Brown, Bryan and Heim, Eric and McMillan, Scott and Nichols, William R. and Rallapalli, Swati and Smith, Carol and VanHoudnos, Nathan and Winski, Nick and Mellinger, Andrew O.},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)}, 
  title={Assessing LLMs for High Stakes Applications}, 
  year={2024},
  volume={},
  number={},
  pages={103-105},
  abstract={Large Language Models (LLMs) promise strategic benefit for numerous application domains. The current state-of-the-art in LLMs, however, lacks the trust, security, and reliability which prohibits their use in high stakes applications. To address this, our work investigated the challenges of developing, deploying, and assessing LLMs within a specific high stakes application, intelligence reporting workflows. We identified the following challenges that need to be addressed before LLMs can be used in high stakes applications: (1) challenges with unverified data and data leakage, (2) challenges with fine tuning and inference at scale, and (3) challenges in re-producibility and assessment of LLMs. We argue that researchers should prioritize test and assessment metrics, as better metrics will lead to insight to further improve these LLMs.},
  keywords={Measurement;Security;Reliability;Tuning;Software engineering;Large language models;TEVV;metrics;scaling;HCI;trust},
  doi={10.1145/3639477.3639720},
  ISSN={2832-7659},
  month={April},}@INPROCEEDINGS{10714569,
  author={Tang, Ningzhi},
  booktitle={2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Towards Effective Validation and Integration of LLM-Generated Code}, 
  year={2024},
  volume={},
  number={},
  pages={369-370},
  abstract={Recent advances in large language model (LLM)-based code generation tools have shown the potential to lower the barrier to programming and improve developer productivity. However, validating the generated codes and integrating them into projects present significant challenges, especially for developers with limited expertise or domain-specific knowledge. I present a novel approach to help developers understand and modify LLM-generated code to align with their intentions, informed by my empirical study of developer behaviors when working with LLM code generation models. In the future, I propose to extend the work to include support for project-level code validation, dynamic program behavior integration, developer behavioral and cognitive context modeling, and computer science education.},
  keywords={Productivity;Visualization;Codes;Computational modeling;Large language models;Computer science education;Programming profession;Context modeling;large language model;debugging;developer behavior;code generation},
  doi={10.1109/VL/HCC60511.2024.00051},
  ISSN={1943-6106},
  month={Sep.},}@ARTICLE{10706805,
  author={Yin, Xin and Ni, Chao and Wang, Shaohua},
  journal={IEEE Transactions on Software Engineering}, 
  title={Multitask-Based Evaluation of Open-Source LLM on Software Vulnerability}, 
  year={2024},
  volume={50},
  number={11},
  pages={3071-3087},
  abstract={This paper proposes a pipeline for quantitatively evaluating interactive Large Language Models (LLMs) using publicly available datasets. We carry out an extensive technical evaluation of LLMs using Big-Vul covering four different common software vulnerability tasks. This evaluation assesses the multi-tasking capabilities of LLMs based on this dataset. We find that the existing state-of-the-art approaches and pre-trained Language Models (LMs) are generally superior to LLMs in software vulnerability detection. However, in software vulnerability assessment and location, certain LLMs (e.g., CodeLlama and WizardCoder) have demonstrated superior performance compared to pre-trained LMs, and providing more contextual information can enhance the vulnerability assessment capabilities of LLMs. Moreover, LLMs exhibit strong vulnerability description capabilities, but their tendency to produce excessive output significantly weakens their performance compared to pre-trained LMs. Overall, though LLMs perform well in some aspects, they still need improvement in understanding the subtle differences in code vulnerabilities and the ability to describe vulnerabilities to fully realize their potential. Our evaluation pipeline provides valuable insights into the capabilities of LLMs in handling software vulnerabilities.},
  keywords={Software;Training;Biological system modeling;Codes;Software quality;Large language models;Source coding;Software systems;Software engineering;Nickel;Software vulnerability analysis;large language model},
  doi={10.1109/TSE.2024.3470333},
  ISSN={1939-3520},
  month={Nov},}@INPROCEEDINGS{10460039,
  author={Ram, Shanker and Qian, Chen},
  booktitle={2023 International Conference on Machine Learning and Applications (ICMLA)}, 
  title={A Study on the Vulnerability of Test Questions against ChatGPT-based Cheating}, 
  year={2023},
  volume={},
  number={},
  pages={1710-1715},
  abstract={ChatGPT is a chatbot that can answer text prompts fairly accurately, even performing very well on postgraduate-level questions. Many educators have found that their take-home or remote tests and exams are vulnerable to ChatGPT-based cheating because students may directly use answers provided by tools like ChatGPT. In this paper, we try to provide an answer to an important question: how well ChatGPT can answer test questions and how we can detect whether the questions of a test can be answered correctly by ChatGPT. We generated ChatGPT's responses to the MedMCQA dataset, which contains over 10,000 medical school entrance exam questions. We analyzed the responses and uncovered certain types of questions ChatGPT answers more inaccurately than others. In addition, we have created a basic natural language processing model to single out the most vulnerable questions to ChatGPT in a collection of questions or a sample exam. Our tool can be used by test-makers to avoid ChatGPT-vulnerable test questions.},
  keywords={Machine learning;Chatbots;machine learning;data analysis;ChatGPT;NLP},
  doi={10.1109/ICMLA58977.2023.00259},
  ISSN={1946-0759},
  month={Dec},}@INPROCEEDINGS{10624638,
  author={Ning, Jing and Gao, Yi and Luo, Mingxin},
  booktitle={2024 International Conference on Informatics Education and Computer Technology Applications (IECA)}, 
  title={Application Research of Generative Artificial Intelligence Technology in the Design and Art Course Teaching}, 
  year={2024},
  volume={},
  number={},
  pages={165-169},
  abstract={The education mode of art design education in colleges and universities is more flexible, and the practitioners and art design talents in this field have a high acceptance of new technologies and new scenes, providing a wide range of application scenarios and product forms for the integration of technology and art. However, there is little research on the application of AI technology in the field of design and design education, so this paper studies the application of generative AI in the teaching of art and design courses. To provide help for the promotion and characteristic development of artificial intelligence technology in art design education in universities. Study artificial intelligence to understand its intelligent dialogue mechanism. Artificial intelligence can support vector machine sorting learning algorithms, transform sorting questions into classification questions, and answer the questioner’s questions. The operation mode of generative artificial intelligence technology and its application in the analysis of design teaching needs can allocate the application of creative teaching concept of art design, try to build a high-quality design education system supported by digital technology, promote the implementation of digital strategy of design education, and help realize modern design education in colleges and universities.},
  keywords={Support vector machines;Art;Generative AI;Education;Transforms;Learning (artificial intelligence);Classification algorithms;Generative artificial intelligence;Design teaching;Digital education},
  doi={10.1109/IECA62822.2024.00038},
  ISSN={},
  month={Jan},}@ARTICLE{10529287,
  author={Diab Idris, Mohamed and Feng, Xiaohua and Dyo, Vladimir},
  journal={IEEE Access}, 
  title={Revolutionizing Higher Education: Unleashing the Potential of Large Language Models for Strategic Transformation}, 
  year={2024},
  volume={12},
  number={},
  pages={67738-67757},
  abstract={This paper investigates the transformative potential of Large Language Models (LLMs) within higher education, highlighting their capacity to reshape the academic landscape. By examining the complex impact of LLMs across critical areas of Higher Education Institutions (HEIs), including the role of HEIs as gatekeepers of knowledge, providers of credentials, research centres, incubators of innovation, drivers of social change and employers. In addition to academic integrity, the future of higher education, intellectual property, and public perception. The findings of this paper indicate that LLMs can empower transformation in HEIs by revolutionising various aspects of academia. The aim is to unveil the profound implications of integrating these cutting-edge technologies. The comprehensive study in this paper reveals the significant impacts and challenges associated with using LLMs in academic settings, which is achieved through a detailed analysis of current literature. The core findings suggest that LLMs hold the promise to trigger significant advancements in higher education. This paper also discusses the innovative potential of LLMs, and it outlines a path for their effective use in HEIs, emphasising the importance of a thoughtful approach to maximise their educational benefits. HEIs must address these challenges thoughtfully, ensuring that the integration of LLMs aligns with their fundamental objectives of promoting education, critical thinking, and personal growth.},
  keywords={Education;Training;Large language models;Ethics;Task analysis;Planning;Performance evaluation;Challenges of LLMs in higher education;impacts of LLMs in higher education;higher education institutions (HEIs);large language models (LLMs);LLMs in education},
  doi={10.1109/ACCESS.2024.3400164},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10569736,
  author={Šarčević, Antonia and Tomičić, Ivan and Merlin, Andrija and Horvat, Marko},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Enhancing Programming Education with Open-Source Generative AI Chatbots}, 
  year={2024},
  volume={},
  number={},
  pages={2051-2056},
  abstract={This paper describes the development of an Open-Source Generative AI Chatbot, utilizing free Large Language Models (LLM) to enrich the student learning experience for a university course in “Introduction to Programming”. The article aims to provide a step-by-step guide for selecting, fine-tuning, and evaluating available models. As a first step in choosing the appropriate LLM, which provides the most accurate responses while not requiring excessive computing power, the article will cover a discussion of the advantages and disadvantages of local vs. cloud-available models. After selecting a few promising models, the next stage includes fine-tuning LLMs to answer domain-specific questions using a dataset containing essential rules, guidelines, and explanatory content regarding the subject. The crucial aspect of selecting a model was evaluating answers, and in this context, both human and automatic evaluation techniques will be presented. Finally, it is possible to enhance the model performance and accuracy by incorporating Retrieval-Augmented Generation (RAG) techniques and exploring the influence of various factors, such as different vector databases, model temperatures, maximum token lengths, prompt templates, embeddings, repetition penalties, and chunking sizes. Our results show that chatbots have significant potential to improve academic support and learning efficiency, as well as personalized education in general.},
  keywords={Electric potential;Accuracy;Temperature;Generative AI;Computational modeling;Education;Chatbots;chatbots;generative models;large language models;natural language processing;education;digital learning},
  doi={10.1109/MIPRO60963.2024.10569736},
  ISSN={2623-8764},
  month={May},}@INPROCEEDINGS{11016490,
  author={Zhang, Yue and Reusch, Pascal},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Trust in and Adoption of Generative AI in University Education: Opportunities, Challenges, and Implications}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Generative AI has emerged as a transformative tool in the realm of higher education, offering a wealth of opportunities for personalized learning, automated feedback, and enhanced collaboration. However, its successful adoption within university environments is significantly dependent on the trust it earns from its users, particularly students. This study investigates the levels of trust and the adoption of Generative AI among students enrolled in both German and international study programs at Hochschule Bielefeld (HSBI) and its transnational partner, Hainan Bielefeld University of Applied Sciences (BiUH). Utilizing a comprehensive questionnaire, the research explores students' perceptions of the trustworthiness of Generative AI, their usage patterns, and their concerns regarding the ethical and academic implications of its use. Preliminary findings suggest that while students widely recognize the potential of Generative AI to improve learning outcomes and efficiency, the degree of trust in its reliability and fairness varies significantly. Key factors influencing this trust include the transparency of AI systems, the perceived accuracy of outputs, and concerns about bias and misuse. Students in international and cross-cultural programs face additional challenges, such as language barriers and cultural differences, which affect how AI is perceived and utilized. Ethical concerns, particularly regarding plagiarism and academic integrity, are prevalent across all groups, underscoring the need for clear institutional guidelines and policies. The findings highlight the importance of fostering AI literacy and providing support structures to build trust and encourage responsible use. Recommendations include the implementation of transparent AI tools, tailored training programs, and the development of ethical guidelines to ensure that Generative AI enhances education while upholding academic standards. This research provides actionable insights for universities aiming to integrate Generative AI into diverse educational contexts, ensuring that it serves as a beneficial tool that complements traditional educational methods while preparing students for a future where AI plays an increasingly central role.},
  keywords={Training;Ethics;Generative AI;Plagiarism;Learning automata;Reliability;Artificial intelligence;Engineering education;Standards;Guidelines;Generative AI;trust;university education;adoption;academic integrity;AI literacy},
  doi={10.1109/EDUCON62633.2025.11016490},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11016313,
  author={Drašković, Dražen},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Integration of Ai Tools into an Ai-Driven Software System to Make Learning Programming Easier}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Today, a person can be considered fully digitally literate if they know how to use and integrate ready-made artificial intelligence (AI) tools. The use of AI tools is becoming increasingly common in students' learning processes. However, learning programming can be challenging and exhausting, especially for younger learners. In this research, a software system was developed to integrate multiple AI tools to facilitate the learning process. The system includes tools for speech and text processing, program code generation, code testing, and result verification. Through a user-friendly software interface, users can define a problem or programming task using speech. The software then converts the speech into text using the Whisper AI API, which is subsequently processed by the GPT-3.5 Turbo and Claude AI APIs to generate program code. Once the program code is generated, it undergoes a series of tests, including parallel testing on the LeetCode platform. Users then compare the obtained results and manually complete a survey evaluating both external tools. One key research requirement was for the software system to accept input data in Serbian, a language with limited resources and complex grammatical rules. This made it difficult to find a suitable AI tool for accurate speech-to-text transformation. The system was tested with speech in both English and Serbian but supports many additional languages thanks to the powerful Whisper AI API. The implemented system is modular and easily extensible with new APIs, making it applicable to other areas of education beyond programming.},
  keywords={Codes;Accuracy;Speech coding;Writing;Software systems;Artificial intelligence;Speech processing;Programming profession;Testing;Text processing;Artificial intelligence;Large language models;Multilingual AI tools;GPT-3.5 Turbo;Claude;Whisper},
  doi={10.1109/EDUCON62633.2025.11016313},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10825124,
  author={Underwood, William and Gage, Joan},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Can GPT-4 Think Computationally about Digital Archival Tasks? – Part 2}, 
  year={2024},
  volume={},
  number={},
  pages={2533-2542},
  abstract={This study examines the computational problem-solving capabilities of GPT-4, focusing on its knowledge of machine learning, email categorization, and computational problem solving, alongside its proficiency in Python programming, computational abstraction, and program debugging. The aim of these investigations is to evaluate whether the capabilities of Large Language Models (LLMs), as demonstrated by GPT-4, can support Master of Library and Information Science (MLIS), graduate students in developing computational thinking skills relevant to digital archival tasks.},
  keywords={Computational modeling;Large language models;Text categorization;Machine learning;Debugging;Chatbots;Electronic mail;Problem-solving;Programming profession;Python;computational thinking;GPT-4;computational problem solving;large language models;MLIS education},
  doi={10.1109/BigData62323.2024.10825124},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10892918,
  author={Hussein, Rania and Zhang, Zhiyun and Amarante, Pedro and Hancock, Nate and Orduna, Pablo and Rodriguez-Gil, Luis},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Integrating Personalized AI-Assisted Instruction Into Remote Laboratories: Enhancing Engineering Education with OpenAI's GPT Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={In recent years, remote laboratories have become integral to modern education, offering flexibility and accessibility compared to traditional, in-person labs. Integrating AI-powered assistance into remote labs has the potential to give them an edge by providing personalized learning experiences. This paper explores an innovative approach to promoting independent learning and critical thinking by embedding AI-driven support, using OpenAI's GPT-4 model, into a remote Field Programmable Gate Array (FPGA) laboratory. Through a web-based code editor, students write SystemVerilog programs and receive tailored assistance from the AI, while their designs are deployed on a Terasic DEl-SoC FPGA development board with real-time feedback via a live camera feed. The study, which involved students from an advanced digital design course interacting with the AI assistant, revealed strong engagement and positive feedback. Preliminary results indicate that AI-powered guidance can meaningfully boost student involvement, providing a scalable and effective framework for fostering active learning in engineering education.},
  keywords={Remote laboratories;Navigation;Logic gates;Real-time systems;Encoding;Trajectory;Feeds;Artificial intelligence;Engineering education;Field programmable gate arrays;AI assistance;remote laboratories;engineering education;GPT models;personalized learning},
  doi={10.1109/FIE61694.2024.10892918},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11016449,
  author={Shu, Chao and Yao, Na and Chen, Yue and Wijeratne, Vindya and Ma, Ling and Loo, Jonathan and Chai, Kok Keong and Alam, Atm and Abuelmaatti, Aisha},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Ai-Assisted Multiple-Choice Questions Generation with Multimodal Large Language Models in Engineering Higher Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={This paper presents an AI-assisted approach that leverages Multimodal Large Language Models (MLLMs) to automate the generation of Multiple-Choice Questions (MCQs) for modules in engineering education. The system introduces a LOs extraction to MCQs generation pipeline, which extracts Learning Outcomes (LOs) from provided lecture notes and generates relevant MCQs with solutions and explanations based on the extracted LOs. By harnessing MLLMs' capabilities in vision and text comprehension, coupled with carefully crafted prompts from human educators, the tool efficiently produces context-relevant MCQs that can streamline teaching material development. The effectiveness of this AI-powered MCQ generation pipeline is investigated through experiments across a number of engineering modules with evaluations on the quality of the generated MCQs by human educators. The analysis of the evaluation results shows the AI tool's ability to generate MCQs that are well-aligned with LOs and exhibit strong contextual relevance, demonstrating the potential of AI-assisted approaches to enhance the efficiency of creating high-quality MCQs in engineering education. However, the variability in quality ratings across different aspects underscores the continued need for human expertise and oversight in the assessment design process. The findings provide useful insights into the capabilities and limitations of state-of-the-art multimodal language models in supporting assessment development in engineering education.},
  keywords={Generative AI;Large language models;Pipelines;Learning (artificial intelligence);Question generation;Engineering education;Multiple-choice Question design;Learning Outcome authoring;Generative Artificial Intelligence (GenAI);Multimodal Large Language Models;Contextual generation;Engineering Education},
  doi={10.1109/EDUCON62633.2025.11016449},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10834324,
  author={Chen, Xin and Yin, Chuantao and Chen, Hui and Rong, Wenge and Ouyang, Yuanxin and Chai, Yanmei},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Course Recommendation System Based on Course Knowledge Graph Generated by Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={With the advent of the big data era, knowledge graphs, as important tools for organizing, managing, and understanding massive amounts of information, are gradually becoming a research hotspot in the field of artificial intelligence. This article focuses on the research and practice of automated construction and application of knowledge graphs in the field of university courses, aiming to improve the efficiency and accuracy of knowledge graph construction and provide strong support for the application in related fields.This study integrated publicly available datasets, mainstream online education platforms, and course explanation texts. Using rule-based and deep learning information extraction methods, combined with a large language model, the automatic extraction of entities, attributes, and relationships was successfully achieved, and an initial course knowledge graph was constructed based on this. Furthermore, by calculating the similarity between course description texts and combining the extracted course prerequisite and peer relationships from the texts, the study not only enriches the structure and content of the course knowledge graph, but also enhances its accuracy and practicality. In order to provide more personalized course recommendation services, this article combines sequence based recommendation algorithms and graph embedding algorithms, fully utilizing the information of the course itself and the dependency information of the course sequence, designing a unique personalized recommendation algorithm, and verifying its effectiveness and accuracy through experiments. This study not only provides strong knowledge graph support for online education platforms, but also provides strong technical support for personalized learning recommendations.},
  keywords={Deep learning;Accuracy;Large language models;Soft sensors;Education;Knowledge graphs;Big Data;Information retrieval;Data mining;Recommender systems;component;formatting;style;styling;insert},
  doi={10.1109/TALE62452.2024.10834324},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10893017,
  author={Johri, Aditya and Hingle, Ashish and Schleiss, Johannes},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Misconceptions, Pragmatism, and Value Tensions: Evaluating Students' Understanding and Perception of Generative AI for Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={In this research paper we examine undergraduate students' use of and perceptions of generative AI (GenAI). Although the initial hype around ChatGPT has subsided, GenAI applications continue to make inroads across learning activities. Like any other emerging technology, there is a lack of consensus around using GenAI within higher education. Students are early adopters of the technology, utilizing it in atypical ways and forming a range of perceptions and aspirations about it. To understand where and how students are using these tools and how they view them, we present findings from an open-ended survey response study with undergraduate students pursuing information technology degrees. Students were asked to describe 1) their understanding of GenAI; 2) their use of GenAI; 3) their opinions on the benefits, downsides, and ethical issues pertaining to its use in education; and 4) how they envision GenAI could ideally help them with their education. Thirty-seven students provided responses ranging in length from 20 to 300 words for each question. Responses were iteratively coded by researchers to uncover patterns in the data and then categorized thematically. Findings reveal that students' definitions of GenAI differed substantially and included many misconceptions - some highlight it as a technique, an application, or a tool, while others described it as a type of AI. There was a wide variation in the use of GenAI by students, with two common uses being writing and coding. They identified the ability of GenAI to summarize information and its potential to personalize learning as an advantage. Students identified two primary ethical concerns with using GenAI: plagiarism and dependency, which means that students do not learn independently. They also cautioned that responses from GenAI applications are often untrustworthy and need verification. Overall, they appreciated that they could do things quickly with GenAI but were cautious as using the technology was not necessarily in their best long-term as it interfered with the learning process. In terms of aspirations for GenAI, students expressed both practical advantages and idealistic and improbable visions. They said it could serve as a tutor or coach and allow them to understand the material better. We discuss the implications of the findings for student learning and instruction.},
  keywords={Surveys;Ethics;Generative AI;Plagiarism;Education;Writing;Encoding;Distance measurement;Stakeholders;Information technology;generative artificial intelligence (GenAI);survey study;thematic analysis;undergraduate students},
  doi={10.1109/FIE61694.2024.10893017},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10774819,
  author={Vhatkar, Abhijit and Pawar, Vilis and Chavan, Pravin},
  booktitle={2024 8th International Conference on Computing, Communication, Control and Automation (ICCUBEA)}, 
  title={Generative AI in Education: A Bibliometric and Thematic Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This research paper uses the bibliometric analysis technique to find out the current stage and future scope of research in the field of Generative Artificial Intelligence (AI) in the education sector. Generative AI which is demonstrated by popular platforms like ChatGPT, has emerged as a transformative force. It has offered a personalized learning environment, adaptive instruction, and opportunities for creative exploration for the students. The analysis done in this research paper is based on the data collected from the Scopus database. It shows the publication trends, geographical distribution, citation patterns, and thematic clusters of published research articles and conference papers in the recent past. The findings of this study reveal that the countries like United States, the United Kingdom, and Australia have significant research contributions with research themes spanning student-centred learning, medical and science education, and computing and information systems education. This research paper has identified the direction for future research which focuses on ethical considerations, teacher training, interdisciplinary collaboration, and inclusiveness. This research provides valuable insights into the growing field of Generative AI in education and guides future endeavours aiming at optimizing the educational outcome with responsible AI integration into the educational sector.},
  keywords={Training;Ethics;Generative AI;Databases;Data security;Bibliometrics;Force;Market research;Monitoring;Information systems;generative AI;generative artificial intelligence;artificial intelligence;quality education;ChatGPT},
  doi={10.1109/ICCUBEA61740.2024.10774819},
  ISSN={2771-1358},
  month={Aug},}@INPROCEEDINGS{10190325,
  author={Treude, Christoph},
  booktitle={2023 IEEE/ACM 5th International Workshop on Bots in Software Engineering (BotSE)}, 
  title={Navigating Complexity in Software Engineering: A Prototype for Comparing GPT-n Solutions}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Navigating the diverse solution spaces of non-trivial software engineering tasks requires a combination of technical knowledge, problem-solving skills, and creativity. With multiple possible solutions available, each with its own set of trade-offs, it is essential for programmers to evaluate the various options and select the one that best suits the specific requirements and constraints of a project. Whether it is choosing from a range of libraries, weighing the pros and cons of different architecture and design solutions, or finding unique ways to fulfill user requirements, the ability to think creatively is crucial for making informed decisions that will result in efficient and effective software. However, the interfaces of current chatbot tools for programmers, such as OpenAI’s ChatGPT or GitHub Copilot, are optimized for presenting a single solution, even for complex queries. While other solutions can be requested, they are not displayed by default and are not intuitive to access. In this paper, we present our work-in-progress prototype “GPTCOMPARE”, which allows programmers to visually compare multiple source code solutions generated by GPT-n models for the same programming-related query by highlighting their similarities and differences.},
  keywords={Navigation;Source coding;Prototypes;Chatbots;Software;Libraries;Problem-solving;Chatbots;diversity;complexity;solution spaces},
  doi={10.1109/BotSE59190.2023.00008},
  ISSN={},
  month={May},}@INPROCEEDINGS{10343467,
  author={Zastudil, Cynthia and Rogalska, Magdalena and Kapp, Christine and Vaughn, Jennifer and MacNeil, Stephen},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Generative AI in Computing Education: Perspectives of Students and Instructors}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={Generative models are now capable of producing natural language text that is, in some cases, comparable in quality to the text produced by people. In the computing education context, these models are being used to generate code, code explanations, and programming exercises. The rapid adoption of these models has prompted multiple position papers and workshops which discuss the implications of these models for computing education, both positive and negative. This paper presents results from a series of semi-structured interviews with 12 students and 6 instructors about their awareness, experiences, and preferences regarding the use of tools powered by generative AI in computing classrooms. The results suggest that Generative AI (GAI) tools will play an increasingly significant role in computing education. However, students and instructors also raised numerous concerns about how these models should be integrated to best support the needs and learning goals of students. We also identified interesting tensions and alignments that emerged between how instructors and students prefer to engage with these models. We discuss these results and provide recommendations related to curriculum development, assessment methods, and pedagogical practice. As GAI tools become increasingly prevalent, it's important to understand educational stakeholders' preferences and values to ensure that these tools can be used for good and that potential harms can be mitigated.},
  keywords={Codes;Systematics;Computational modeling;Education;Natural languages;Curriculum development;Stakeholders;Generative models;large language models;computing education;student perceptions;instructor perceptions},
  doi={10.1109/FIE58773.2023.10343467},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10670435,
  author={Gao, Lin and Lu, Jing and Shao, Zekai and Lin, Ziyue and Yue, Shengbin and Leong, Chiokit and Sun, Yi and Zauner, Rory James and Wei, Zhongyu and Chen, Siming},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Fine-Tuned Large Language Model for Visualization System: A Study on Self-Regulated Learning in Education}, 
  year={2025},
  volume={31},
  number={1},
  pages={514-524},
  abstract={Large Language Models (LLMs) have shown great potential in intelligent visualization systems, especially for domain-specific applications. Integrating LLMs into visualization systems presents challenges, and we categorize these challenges into three alignments: domain problems with LLMs, visualization with LLMs, and interaction with LLMs. To achieve these alignments, we propose a framework and outline a workflow to guide the application of fine-tuned LLMs to enhance visual interactions for domain-specific tasks. These alignment challenges are critical in education because of the need for an intelligent visualization system to support beginners' self-regulated learning. Therefore, we apply the framework to education and introduce Tailor-Mind, an interactive visualization system designed to facilitate self-regulated learning for artificial intelligence beginners. Drawing on insights from a preliminary study, we identify self-regulated learning tasks and fine-tuning objectives to guide visualization design and tuning data construction. Our focus on aligning visualization with fine-tuned LLM makes Tailor-Mind more like a personalized tutor. Tailor-Mind also supports interactive recommendations to help beginners better achieve their learning goals. Model performance evaluations and user studies confirm that Tailor-Mind improves the self-regulated learning experience, effectively validating the proposed framework.},
  keywords={Data visualization;Data models;Education;Adaptation models;Tutorials;Large language models;Knowledge based systems;Fine-tuned large language model;visualization system;self-regulated learning;intelligent tutorial system},
  doi={10.1109/TVCG.2024.3456145},
  ISSN={1941-0506},
  month={Jan},}@BOOK{10970464,
  author={Siino, Marco and Tinnirello, Ilenia and Cascia, Marco},
  booktitle={From Foundations to GPT in Text Classification: A Comprehensive Survey on Current Approaches and Future Trends},
  year={2025},
  volume={},
  number={},
  pages={},
  abstract={In several Natural Language Processing (NLP) applications like news categorization, sentiment analysis, and subject labelling, text classification is a crucial and relevant task. The goal is to tag or label textual components like sentences, questions, paragraphs, and documents. In this era of massive information dissemination, manually processing and categorizing huge amounts of text data takes a relevant amount of time and effort. Text classification stands as a cornerstone within the realm of NLP, particularly when viewed through computer science and engineering. The past decade has seen deep learning revolutionize text classification, propelling advancements in text retrieval, categorization, information extraction, and summarization. The efficacy of text classification models relies heavily on their ability to capture intricate textual relationships and non-linear correlations, necessitating a comprehensive examination of the entire text classification pipeline. This work integrates traditional and contemporary text mining methodologies, fostering a holistic understanding of text classification. In the NLP domain, numerous text representation techniques and model architectures have emerged, with Large Language Models (LLMs) and Generative pre-trained Transformers (GPTs) at the forefront. These models are adept at transforming extensive textual data into meaningful vector representations encapsulating semantic information. Text classification is multidisciplinary in nature, encompassing data mining, linguistics, and information retrieval. This monograph provides an in-depth exploration of the text classification pipeline, with a particular emphasis on evaluating the impact of each component on the overall performance of text classification models. The pipeline includes state-of-the-art datasets, text preprocessing techniques, text representation methods, classification models, evaluation metrics, and future trends. Each section examines these stages, presenting technical innovations and recent findings. The work assesses various classification strategies, offering comparative analyses, examples and case studies. These contributions extend beyond a typical survey, providing a detailed and insightful exploration of the field.},
  keywords={},
  doi={},
  ISSN={},
  publisher={now},
  isbn={9781638285595},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10970464},}@INPROCEEDINGS{11016470,
  author={Benites, Fernando and Battegay, Caspar},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={AI Literacy: Evaluation of an AI Literacy Course for Engineers}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={In this paper, we discuss the implementation and evaluation of a project-based self-direct learning competency-based module on AI literacy. This module was developed for various Bachelor's degree programs from the school of Engineering at the University of Applied Sciences and Arts Northwestern Switzerland. The aim of this course is not only to show how AI can help with writing and programming (learning), but also to get students firstly to reflect on working with AI and introduce them to important current debates, and secondly to teach the basics of large language models and central methods of data science. Students should be made aware to academic work (including finding and evaluating sources) with and about AI. During the course, they have to combine analytical and technical skills like programming and web scraping when developing a selfchosen project. An important finding of our work is that, despite their daily engagement with computer science and digital tools, without such specific formats, students are unlikely to acquire the necessary knowledge and critical thinking to navigate the rapidly changing landscape of AI autonomously and confidently.},
  keywords={Industries;Ethics;Navigation;Engineering profession;Large language models;Writing;Artificial intelligence;Programming profession;Faces;Guidelines;project-based learning;intrinsic motivation;self-directed learning},
  doi={10.1109/EDUCON62633.2025.11016470},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11012071,
  author={Othman, Zhala Sarkawt and Karabatak, Sonsül and Karabatak, Murat},
  booktitle={2025 13th International Symposium on Digital Forensics and Security (ISDFS)}, 
  title={Bibliometric Analysis in AI Assistant for e-learning to Focus Students by Using Camera, Keyboard and Mouse}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, artificial intelligence has been a widely researched topic, particularly in education. This study evaluates the role of AI assistants in enhancing student motivation and focus in e-Iearning by conducting a bibliometric analysis of academic publications. In our study, we analyzed the use of AI assistants in e-Iearning to help students stay focused through the use of cameras, keyboards, and mice, addressing student distraction in e-Iearning. We propose that AI assistants can support teachers in motivating students and improving their engagement. To conduct our analysis, we examined data from the last ten years (2015–2025) using the Web of Science database and bibliometric analysis tools such as VOSviewer. We focused on publications categorized under Computer Science - Artificial Intelligence, Education - Educational Research, and Computer Science - Software Engineering. A total of 676 academic publications ten years were analyzed. The highest number of publications occurred in 2024, with “Artificial Intelligence,” “ChatGPT,” and “Machine Learning” being the most frequently used keywords. The primary objective of this study was to examine previous research that applied AI in e-education, exploring its impact on students through various approaches. Based on our findings, AI assistants in e-Iearning are expected to playa crucial role not only in the present but also in the coming years. Our results indicate that AI-assisted educational technologies have rapidly evolved and are significantly improving student engagement in e-Iearning environments.},
  keywords={Computer science;Electronic learning;Bibliometrics;Keyboards;Machine learning;Cameras;Mice;Security;Artificial intelligence;Software engineering;artificial intelligence;AI assistant;focus student;motivate student;distance education;distance learning;e-learning;bibliometric analysis},
  doi={10.1109/ISDFS65363.2025.11012071},
  ISSN={2768-1831},
  month={April},}@INPROCEEDINGS{10795004,
  author={Rahman, Tajmilur and Zhu, Yuecai and Maha, Lamyea and Roy, Chanchal and Roy, Banani and Schneider, Kevin},
  booktitle={2024 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Take Loads Off Your Developers: Automated User Story Generation using Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={791-801},
  abstract={Software Maintenance and Evolution (SME) is moving fast with the assistance of artificial intelligence (AI), especially Large Language Models (LLM). Researchers have already started automating various activities of the SME workflow. Un-derstanding the requirements for maintenance and development work i.e. Requirements Engineering (RE) is a crucial phase that kicks off the SME workflow through multiple discussions on a proposed scope of work documented in different forms. The RE phase ends with a list of user stories for each unit task and usually created and tracked on a project management tool such as GitHub, Jira, AzurDev, etc. In this research, we collaborated with Bell Mobility to develop a tool “Geneus” (Generate UserSory) using GPT-4-turbo to automatically create user stories from software requirements documents. Requirements documents are usually long and contain complex information. Since LLMs typically suffer from hallucination when the input is too complex, this paper proposes a new prompting strategy, “Refine and Thought” (RaT), to mitigate that issue and improve the performance of the LLM in prompts with large and noisy contexts. Along with manual evaluation using RUST (Readability, Understandability, Specificity, Technical-aspects) survey questionnaire, automatic evaluation with BERTScore, and AlignScore evaluation metrics are used to evaluate the results of the “Geneus” tool. Results show that our method with RaT performs consistently better in most of the cases of interactions compared to the single-shot baseline method. However, the BERTScore and AlignScore test results are not consistent. In the median case, Geneus performs significantly better in all three interactions (requirements specifi-cation, user story details, and test case specifications) according to AlignScorebut it shows slightly low performance in requirements specifications according to BERTScore. Distilling RE documents requires significant time & effort from the senior members of the team through multiple meetings with stakeholders. We believe automating this process will certainly reduce additional loads off the software engineers and increase the ultimate productivity allowing them to utilize their time on other prioritized tasks.},
  keywords={Surveys;Productivity;Software maintenance;Large language models;Project management;Maintenance;Planning;Requirements engineering;Stakeholders;Testing;LLM;Prompt Engineering;Refine and Thought;User Story;Auto Generate;Software Maintenance Tasks},
  doi={10.1109/ICSME58944.2024.00082},
  ISSN={2576-3148},
  month={Oct},}@INPROCEEDINGS{10590605,
  author={Li, Yi and Zhang, Riteng and Qu, Danni and Samary, Maíra Marques},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Leveraging LLMs and MLPs in Designing a Computer Science Placement Test System}, 
  year={2023},
  volume={},
  number={},
  pages={1670-1676},
  abstract={Introductory Computer Science (CS) programs at higher education institutions include a variety of introductory courses commonly known as CS1 and CS2; some institutions offer additional variations (e.g., CS0, CS1.5). Accurate placement of students in these courses is vital for students' success. This paper introduces a machine learning-based CS placement test system using LLMs and classifiers, incorporating a concept inventory (CI) assessment. Five LLMs were evaluated, and the best one was chosen to generate questions. The questions were stored in a database, allowing customized placement tests through an interactive assessment system. After the test, students' performance data were used to train three simple MLP classifiers, achieving over 83% accuracy in a case study with 46 participants.},
  keywords={Computer science;Accuracy;Scientific computing;Reviews;Navigation;Filtering;Databases;Computer science education;Introductory CS courses;Placement test;Concept inventory;Large language model},
  doi={10.1109/CSCI62032.2023.00276},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{10710971,
  author={Bircan, Abdullah and Mandal, Dilek and Kösesoy, İrfan},
  booktitle={2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP)}, 
  title={Academic Use of ChatGPT: Examining the Trends According to Disciplines}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={With the rapid advancement of large language models, particularly ChatGPT, have had a profound impact both in the academic world and in commercial applications. The innovative solutions offered by this technology in areas such as natural language processing, data analysis, and human-computer interaction have led to the emergence of new research domains across various disciplines. However, there has been no comprehensive examination in the literature of which academic disciplines focus on ChatGPT and which areas have attracted more interest.This study aims to systematically examine academic publications related to ChatGPT and to identify the disciplines in which this technology is more widely adopted, as well as the areas where intensive research is conducted. To this end, a specially developed tool was utilized to scan all academic publications pertaining to ChatGPT, allowing for a comprehensive interdisciplinary analysis. The results of the analysis reveal the academic fields in which ChatGPT is most intensively utilized, highlighting the differences among these fields. Notably, there is a concentration in categories such as “Medical Sciences,” “Computer Sciences,” and “Education Sciences,” which also stand out among the most cited publications. Our findings indicate that ChatGPT has gained broad acceptance within the academic community, with certain disciplines leading the way in this regard. Furthermore, the interactions among categories sharing common keywords demonstrate how ChatGPT facilitates interdisciplinary knowledge flow.},
  keywords={Data analysis;Large language models;Chatbots;Market research;Data models;ChatGPT;Human-Computer Interaction (HCI);Natural Language Processing (NLP);Large Language Models (LLMs);Transformers},
  doi={10.1109/IDAP64064.2024.10710971},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11016312,
  author={Chans, Guillermo M. and Merino-Soto, César and Chávez, Santiago Santillán and García Castro, Jaime A. and Zavala, Genaro and Rodriguez, Elvia Sánchez},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Integrating Generative AI Into Design Thinking: Assessing Impact on Creativity and Innovation in STEM Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Design thinking (DT), widely recognized as a structured method for fostering creativity and innovation, has gained significant traction in research and practice across various disciplines. However, with the rise of disruptive technologies like artificial intelligence (AI), DT practices are gradually evolving, reshaping the innovation process. This study investigates the effectiveness of integrating generative AI into a product design thinking activity, employing a single-group pretest-posttest design (i.e., without a control group). The time interval between pretest and posttest measurements was four hours, coinciding with the duration of the DT activity. Conducted in a chemical engineering course at a private university in central Mexico, the research tasked nine students of average academic performance with designing a new beverage. Over a four-hour session, students used AI tools-ChatGPT, Perplexity, and Gemini-at various stages of the design process, including empathy mapping, need statements, idea classification, hills writing, and storyboarding. Several multidimensional constructs were measured using self-report questionnaires to assess the key attributes that DT stimulates: perceptions of creative self-efficacy, design thinking mindset, and empathy. Additionally, the study explored students' views on the usefulness of generative AI and their intention to use such tools. It was hypothesized that post-test scores for each construct would increase. The analysis involved two phases: first, psychometric indicators (alpha reliability) were obtained; second, a statistical approach for assessing individual change was applied, precisely the standardized individual difference (SID). The SID was set at a nominal level of 0.80 (right tail of the normal distribution). Scores with unacceptable measurement error (alpha <. 60) were excluded from the primary analysis. The results revealed a significant increase in students' perceived usefulness of AI between pre- and post-experiment measurements, with a moderate improvement in affective empathy. Other constructs also showed consistent, though modest, post-test score increases. However, only a few participants exceeded the SID threshold, indicating individual variations in response to the intervention. These preliminary findings highlight AI's potential to enhance student creativity through idea generation and expand their consideration of the end user in product design. The results provide valuable insights and recommendations for integrating AI into innovation-driven projects using the design thinking approach and implementing a single-group pretest-posttest design with short time intervals.},
  keywords={Technological innovation;Generative AI;Chemical engineering;Writing;Product design;Time measurement;Reliability;Problem-solving;Creativity;STEM;Design thinking;artificial intelligence;higher education;educational innovation;STEM;creative self-efficacy;empathy},
  doi={10.1109/EDUCON62633.2025.11016312},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10174472,
  author={Sudirman, Ivan Diryana and Rahmatillah, Intan},
  booktitle={2023 IEEE World AI IoT Congress (AIIoT)}, 
  title={Artificial Intelligence-Assisted Discovery Learning: An Educational Experience for Entrepreneurship Students Using ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={0786-0791},
  abstract={Artificial intelligence-assisted discovery learning is a powerful tool that can help students engage in discovery-based learning. This paper aims to investigate how ChatGPT might enrich the educational experience of students enrolled in Technopreneurship course. This research will be conducted on students from the Entrepreneurship Program in a university in Bandung. A total of 213 students participated in this study and filled out forms that were distributed via Google form. The results show that students who participated in the discussion session using ChatGPT found it both informative and enjoyable. The vast majority of students who attended the chatgpt session found the conversation informative and entertaining. The research question and the findings suggest that the use of AI-powered tools such as chatGPT can improve students’ learning experiences and aid them in developing workable ideas for mobile apps. This study can pave the way for further research into how AI can be applied to the classroom and what kind of impact it can have on students’ educational outcomes.},
  keywords={Heuristic algorithms;Education;Entrepreneurship;Learning (artificial intelligence);Oral communication;Chatbots;Market research;Artificial intelligence;discovery learning;ChatGPT;educational experience;Technopreneurship;entrepreneurship},
  doi={10.1109/AIIoT58121.2023.10174472},
  ISSN={},
  month={June},}@INPROCEEDINGS{10589972,
  author={Chen, Xi and Liao, Yuebin and Yu, Wei},
  booktitle={2024 6th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={Generative AI in Higher Art Education}, 
  year={2024},
  volume={},
  number={},
  pages={135-140},
  abstract={This research delves into the perspectives of Chinese university art teachers on the integration of Artificial Intelligence in Generative Content. Collaboratively initiated by art teachers from Chinese universities through the AI Art Education Alliance in Wuhan, the study aims to comprehend their attitudes, concerns, and preparations regarding the infusion of generative AI tools into art and design curricula. The research employs a comprehensive approach, incorporating group interviews during the inaugural session of the AI Art Education Alliance. Additionally, questionnaire research is utilized as supplementary evidence. Participants include middle-level administrators and teachers from diverse colleges, offering a nuanced understanding of viewpoints across various educational institutions. Key findings reveal nuanced perspectives on AI in higher art education. Notably, there exists a spectrum of AI anxiety, with comprehensive universities showing readiness, while caution prevails in art colleges. The study underscores the potential benefits of AI in art education but highlights concerns about its impact on traditional pedagogy. The research emphasizes the urgency of addressing equity issues related to resource disparities, academic integrity, and cultural resistance within the education community. Recommendations include standardized AI tool usage, adaptations in professional structures, and fostering collaborative alliances to harness AI's potential effectively.},
  keywords={Training;Art;Generative AI;Surface resistance;Education;Anxiety disorders;Collaboration;generative AI tools;higher education;teachers' perspectives;AI in art education;AI anxiety},
  doi={10.1109/CSTE62025.2024.00032},
  ISSN={},
  month={April},}@INPROCEEDINGS{10556182,
  author={Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
  booktitle={2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN)}, 
  title={Seven Failure Points When Engineering a Retrieval Augmented Generation System}, 
  year={2024},
  volume={},
  number={},
  pages={194-199},
  abstract={Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.CCS CONCEPTS• Software and its engineering → Empirical software validation.},
  keywords={Semantic search;Education;Information retrieval;Chatbots;Software;Robustness;Task analysis;Retrieval Augmented Generation;RAG;SE4AI;Case Study},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10554965,
  author={Ibrahimzada, Ali Reza},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)}, 
  title={Program Decomposition and Translation with Static Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={453-455},
  abstract={The rising popularity of Large Language Models (LLMs) has motivated exploring their use in code-related tasks. Code LLMs with more than millions of parameters are trained on a massive amount of code in different Programming Languages (PLs). Such models are used for automating various Software Engineering (SE) tasks using prompt engineering. However, given the very large size of industry-scale project files, a major issue of these LLMs is their limited context window size, motivating the question of “Can these LLMs process very large files and can we effectively perform prompt engineering?”. Code translation aims to convert source code from one PL to another. In this work, we assess the effect of method-level program decomposition on context window of LLMs and investigate how this approach can enable translation of very large files which originally could not be done due to out-of-context issue. Our observations from 20 well-known java projects and approximately 60K methods suggest that method-level program decomposition significantly improves the limited context window problem of LLMs by 99.5%. Furthermore, our empirical analysis indicate that with method-level decomposition, each input fragment on average only consumes 5% of the context window, leaving more context space for prompt engineering and the output. Finally, we investigate the effectiveness of a Call Graph (CG) approach for translating very large files when doing method-level program decomposition.},
  keywords={Java;Computer languages;Codes;Source coding;Static analysis;Task analysis;Software engineering},
  doi={10.1145/3639478.3641226},
  ISSN={2574-1934},
  month={April},}@ARTICLE{10908666,
  author={Chen, Jintao and Wang, Fan and Pang, Shengye and Chen, Mingshuai and Xi, Meng and Zhao, Tiancheng and Yin, Jianwei},
  journal={Tsinghua Science and Technology}, 
  title={A Privacy Policy Text Compliance Reasoning Framework with Large Language Models for Healthcare Services}, 
  year={2025},
  volume={30},
  number={4},
  pages={1831-1845},
  abstract={The advancement of artificial intelligence-generated content drives the diversification of healthcare services, resulting in increased private information collection by healthcare service providers. Therefore, compliance with privacy regulations has increasingly become a paramount concern for both regulatory authorities and consumers. Privacy policies are crucial for consumers to understand how their personal information is collected, stored, and processed. In this work, we propose a privacy policy text compliance reasoning framework called FACTOR, which harnesses the power of large language models (LLMs). Since the General Data Protection Regulation (GDPR) has broad applicability, this work selects Article 13 of the GDPR as regulation requirements. FACTOR segments the privacy policy text using a sliding window strategy and employs LLM-based text entailment to assess compliance for each segment. The framework then applies a rule-based ensemble approach to aggregate the entailment results for all regulation requirements from the GDPR. Our experiments on a synthetic corpus of 388 privacy policies demonstrate the effectiveness of FACTOR. Additionally, we analyze 100 randomly selected websites offering healthcare services, revealing that nine of them lack a privacy policy altogether, while 29 have privacy policy texts that fail to meet the regulation requirements.},
  keywords={Privacy;Pediatrics;Technological innovation;Sensitivity;Large language models;Medical services;Regulation;Cognition;General Data Protection Regulation;Protection;service regulation;privacy policy;compliance reasoning;healthcare services},
  doi={10.26599/TST.2024.9010089},
  ISSN={1007-0214},
  month={August},}@INPROCEEDINGS{10435040,
  author={Bau, Rahmat Taufik R.L and Hermila, A and Farman, Indra and Muhammad Hidayat, L and Salim, Sardi},
  booktitle={2023 9th International Conference on Education and Technology (ICET)}, 
  title={AI Perspectives in Education: A BERT-based Exploration of Informatics Students’ Attitudes to ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={36-41},
  abstract={This study examined informatics students’ perspectives on ChatGPT through sentiment analysis, utilizing advanced BERT neural networks within Python to understand their sentiments comprehensively. By harnessing BERT’s intricate contextual embeddings and attention mechanisms, we effectively evaluated the subtleties of students’ attitudes. Our methodology encompassed categorizing student ChatGPT reviews using a 5-star rating scale, capturing diverse sentiments and enabling scrutiny of their distribution and trends. Positive sentiments were predominant, as students lauded ChatGPT’s potential as a valuable academic tool. Its capacity to assist in research, assignments, and information retrieval garnered significant praise. However, neutral and negative sentiments pinpointed areas for improvement. Neutral sentiments indicated potential optimization, while negative sentiments flagged inaccuracies and response time concerns. Ultimately, this amalgamation of sentiment analysis and BERT insights provided a lucid view of informatics students’ interactions with ChatGPT. In conclusion, the fusion of sentiment analysis and BERT insights has spotlighted ChatGPT’s immense potential as an academic companion. This study underscores its value as an effective support tool, emphasizing the commitment to continuous enhancement. By diligently refining ChatGPT, we can enhance its performance, tailor it more precisely to students’ diverse needs, and seamlessly empower them to integrate AI-driven language models into their educational journeys.},
  keywords={Sentiment analysis;Education;Chatbots;User experience;Time factors;Informatics;Task analysis;sentiment analysis;students;ChatGPT;BERT},
  doi={10.1109/ICET59790.2023.10435040},
  ISSN={2770-4807},
  month={Oct},}@INPROCEEDINGS{10541593,
  author={McDaniel, Steven and Zibran, Minhaz F.},
  booktitle={2024 7th International Conference on Information and Computer Technologies (ICICT)}, 
  title={Improving Source Code with Assistance from AI — A Pilot Case Study with ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={332-337},
  abstract={ChatGPT queries were used to provide feedback on five C++ programs selected from various programming assignments for two graduate-level computer science courses – a scientific programming course and an algorithms course. The evaluated software was written by the first author for those courses within the last two years. ChatGPT was asked to evaluate and provide feedback for each program. Specifically, ChatGPT was asked to evaluate the code for strengths and weaknesses and make recommendations for improving (1) execution speed as well as (2) readability and maintainability. A subjective agreement rating was generated by the authors for each strength, weakness, and recommended change provided by ChatGPT. While the overall agreement with the ChatGPT provided feedback was over 90 percent, at times, ChatGPT’s recommendations were found misleading.},
  keywords={Codes;Generative AI;Source coding;Software algorithms;C++ languages;Software quality;Programming;ChatGPT;Code;Readability;Program;Analysis;Execution Speed;Maintainability},
  doi={10.1109/ICICT62343.2024.00060},
  ISSN={2769-4542},
  month={March},}@ARTICLE{10856105,
  author={Setyawan Soekamto, Yosua and Christopher Limanjaya, Leonard and Kaleb Purwanto, Yoshua and Kang, Dae-Ki},
  journal={IEEE Access}, 
  title={From Queries to Courses: SKYRAG’s Revolution in Learning Path Generation via Keyword-Based Document Retrieval}, 
  year={2025},
  volume={13},
  number={},
  pages={21434-21455},
  abstract={Large Language Models (LLMs) hold immense potential for transforming education by automating the generation of personalized learning paths. However, traditional LLMs often suffer from hallucinations and content irrelevance. To address these challenges, we propose SKYRAG, a Separated Keyword Retrieval Augmentation Generation system that enhances the learning path generation process by integrating advanced retrieval mechanisms with LLMs. SKYRAG retrieves relevant course materials from Massive Open Online Course (MOOC) platforms, aligning them with individual learner profiles to provide personalized and coherent learning paths. Compared with Naïve RAG, SKYRAG demonstrates superior performance in terms of accuracy, relevance, and user satisfaction, as confirmed by human evaluations across four domains. By improving retrieval precision and addressing the limitations of traditional methods, SKYRAG represents a significant advancement in educational technology. This study contributes to the growing body of research on AI-driven learning systems and highlights SKYRAG’s potential for widespread adoption in dynamic educational environments.},
  keywords={Retrieval augmented generation;Accuracy;Semantics;Mathematical models;Large language models;Data models;Context modeling;Computational modeling;Transformers;Training data;Retrieval augmented generation;personalized learning path;large language models;educational technology;human-centric design},
  doi={10.1109/ACCESS.2025.3535618},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10342985,
  author={Hingle, Ashish and Katz, Andrew and Johri, Aditya},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Exploring NLP-Based Methods for Generating Engineering Ethics Assessment Qualitative Codebooks}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={This Full Research paper presents a comparison of two codebook generation methods using natural language processing (NLP): a human and NLP collaboration method and a fully automated NLP method (referred to as Human-NLP and Auto-NLP, respectively). Codebook generation serves as a preliminary step in most qualitative projects, and using NLP as a tool can help support the analysis and efficiency of the researcher. By utilizing NLP in the early stages of codebook generation, there are opportunities for detailed and productive gains when working with large corpora of textual data. Using NLP at this stage also allows the researcher to make sense of any outputs generated through automated means rather than simply accepting the output as it is. The outcome of both methods tested in this work will be used to evaluate and apply the codes across a large dataset. The Human-NLP method involves generating the initial themes using a large-language model (LLM), and the researcher revises the codebook further. The Auto-NLP method involves generating three rounds of codes, summarizing the codes in each until a saturation level has been reached through the overarching themes. The dataset used for this study comes from an analysis of students' perception and recognition of ethical concepts after participating in a semester-long course focused on ethics, society, and technology. The course introduced students to traditional ethics topics, such as those around engineering disasters, but also explored developing topics, such as facial recognition, dataset bias, and the impact of technology on the global food supply. We collected data between fall 2020 and 2022 from six (6) iterations of a semester-long course. A total of 210 student responses to the question - what did this course teach you about ethics - were analyzed. The results from both Human-NLP and Auto-NLP methods were promising in the level of detail summarized and the similarity of themes across the data. Eight (8) themes were finalized through the Human-NLP method, and twelve (12) were generated through the Auto-NLP method. We present a discussion exploring these themes and the limitations of using these methods.},
  keywords={Ethics;Codes;Face recognition;Collaboration;Natural language processing;Artificial intelligence;engineering ethics;natural language processing;codebook generation;generative AI},
  doi={10.1109/FIE58773.2023.10342985},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11007284,
  author={Liu, Sunan and Jiang, Jiantao and Wei, Kailin and Wu, Runtian and Xu, Yaxiong},
  booktitle={2024 International Conference on Digital Technology and Intelligent Education (ICDTIE)}, 
  title={Enhancing University Students' ESG Competencies Through “Artificial Intelligence + Education”-A Case Study of ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={27-30},
  abstract={Under the background of “artificial intelligence + education”, artificial intelligence is promoting the high-quality development of education, especially showing the potential in cultivating of environmental, social and governance (ESG) capabilities. This study takes ChatGPT as an example to explore how intelligent education can empower university students in enhancing their ESG capabilities. A comprehensive, multidimensional educational strategy is proposed, which includes the curriculum system centered around the integration of artificial intelligence and ESG, the reinforcement of practice-oriented teaching methods, the promotion of interdisciplinary and cross-sector research projects, and the establishment of internship mechanisms based on collaboration between academia and industry. These strategies aim to facilitate students' deep understanding of ESG principles and enhance their ability to apply these concepts in real-world scenarios.},
  keywords={Industries;Education;Knowledge based systems;Collaboration;Chatbots;Multilingual;Sustainable development;Augmented reality;Immersive learning;ESG ability of college students;Educational empowerment;Interdisciplinary education;Chat-GPT},
  doi={10.1109/ICDTIE65977.2024.00012},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10342976,
  author={Hickman, Henry and McKeown, Paul and Bell, Tim},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Beyond Question Shuffling: Randomization Techniques in Programming Assessment}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={Randomization is a technique that can be used with programming assessments to discourage academic misconduct by making it unlikely for two colluding students to get the exact same questions. Previous research about randomization has shown it to be an effective tool for addressing academic misconduct, but this work often focuses on randomization broadly, with few considering specific techniques. In contrast, we consider different randomization techniques and the contexts that they are best suited to. In addition, we investigate the effectiveness of randomization techniques against emerging AI technologies. This is done by exploring randomization in the context of an online quiz system that evaluates student responses to pro-gramming challenges, specifically the CodeRunner system for the Moodle learning management system. We provide a classification of techniques, and discuss the benefits of each. This classification starts with simpler techniques, such as shuffling question order, shuffling multi-choice question options, and question pooling. We then move on to more advanced techniques, including simple substitution, altering expected output, switching logic, and steganography. We also investigate two approaches to generating randomized questions, considering the benefits and drawbacks of each. These approaches are generating the questions beforehand (pre-generation) and generating the questions when the quiz is started (on-the-fly generation). We then identify four categories of assessment based on assessment that is formative/summative, and proctored/non-proctored, then identify which randomization techniques are suited for each category. Finally, we test randomized questions against OpenAI's Codex, to see if these techniques could prevent this new opportunity for academic dishonesty. We found that there are some types of questions that Codex currently performs poorly on, such as program reasoning, and creating complex classes, but overall randomization was not effective in defeating it, with Codex scoring 79.7% on questions that were created after it was trained, and 85.3 % on questions that could have been available to it when it was trained.},
  keywords={Steganography;Learning management systems;Taxonomy;Education;Switches;Cognition;Servers;academic integrity;randomization;automatic assessment tools;AI generated code},
  doi={10.1109/FIE58773.2023.10342976},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{9766649,
  author={Ramnarain-Seetohul, Vidasha and Bassoo, Vandana and Rosunally, Yasmine},
  booktitle={2022 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Work-in-Progress: Computing Sentence Similarity for Short Texts using Transformer models}, 
  year={2022},
  volume={},
  number={},
  pages={1765-1768},
  abstract={The field of natural language processing is being revolutionized with transformers. The latter is based on a novel type of neural network framework that is already pre-trained. Hence, large datasets to train models are no longer required. This framework is suitable for automated assessment systems (AAS), where a large number of labeled data is needed. The larger the dataset, the higher the accuracy of the AAS. In this work-in-progress paper, a prototype for an AAS has been built where two transformer models, namely the Sentence-Transformers from hugging face and the OpenAI GPT-3 models have been used. The transformer models generate the similarity index between students’ answers and reference answers from the Texas dataset. Then the similarity index is used to compute marks for students. The performance of the prototype is evaluated using the quadratic weighted kappa metric.},
  keywords={Measurement;Computational modeling;Conferences;Neural networks;Prototypes;Transformers;Natural language processing;Sentence Similarity;Automated Assessment System;Transformers},
  doi={10.1109/EDUCON52537.2022.9766649},
  ISSN={2165-9567},
  month={March},}@INPROCEEDINGS{10857758,
  author={Keerthichandra, Malshan and Vihidun, Tharoosha and Lakshan, Shanuka and Perera, Indika},
  booktitle={2024 9th International Conference on Information Technology Research (ICITR)}, 
  title={Large Language Model-Based Student Intent Classification for Intelligent Tutoring Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Intent classification is a foundational element in natural language processing, enabling conversational systems to accurately interpret user intent. In educational contexts, effective intent classification within Intelligent Tutoring Systems (ITS) can significantly enhance personalized student interactions. This paper presents the intent classification module for the Learner-Aware AI (LAAI) tutor, a dialogue-based ITS designed to recognize and respond to diverse student behaviors, such as valid answers, questions, expressions of boredom, and requests for clarification. We introduce LAAIIntentD, a custom data set specifically designed for this task, containing 1,244 labeled training records and 278 evaluation records. Leveraging this dataset, we fine-tuned a large language model (LLM) LAAI-intent-classifier using Low-Rank Adaptation (LoRA) techniques to create a lightweight yet powerful intent classifier. Our fine-tuned model achieves better overall Recall (0.86), Precision (0.85), and F1-Score (0.83) compared to GPT-based methods. GPT models with CoT and Few-Shot prompting improve Recall but sacrifice F1 scores. This highlights our model's efficiency in balancing accuracy and scalability for ITS applications.},
  keywords={Training;Adaptation models;Intent recognition;Scalability;Large language models;Focusing;Robustness;Natural language processing;Information technology;Context modeling;Intent classification;Intelligent Tutoring System (ITS);Large Language Model (LLM);LAAI tutor;Few-shot prompting},
  doi={10.1109/ICITR64794.2024.10857758},
  ISSN={2831-3399},
  month={Dec},}@INPROCEEDINGS{11015302,
  author={Miladinovic, Igor and Schefer-Wenzl, Sigrid},
  booktitle={2024 15th International Conference on Distance Learning and Education (ICDLE)}, 
  title={From Learners to Contributors: Redefining Bachelor's and Master's Theses in the Context of Generative AI Tools}, 
  year={2024},
  volume={},
  number={},
  pages={15-19},
  abstract={The integration of Generative AI (GenAI) tools, such as ChatGPT, into academic environments has raised significant questions about the traditional format and integrity of final theses, particularly in engineering studies. This paper investigates the goal of final theses and the appropriate actions to achieve them in the context of modern technological advancements. Utilizing Dettmer's methodology, we identify and analyze the underlying causes of challenges introduced by GenAI tools. Our findings highlight the need for curriculum adaptations to address these challenges effectively. These include shifting the emphasis from thesis components easily generated by AI to students' contributions from a research project. These adaptations aim to enhance the quality and originality of final theses, foster deeper student engagement in research projects, and introduce innovative, multimedia formats for thesis presentation. The proposed solutions not only uphold academic integrity but also leverage the potential of GenAI tools to enrich the educational experience.},
  keywords={Computer aided instruction;Generative AI;Education;Chatbots;Generative AI;higher education;theses},
  doi={10.1109/ICDLE63439.2024.00010},
  ISSN={2169-1444},
  month={Sep.},}@INPROCEEDINGS{10814636,
  author={Beining, Yang and Alassane, Samba and Guillaume, Fraysse and Sihem, Cherrared},
  booktitle={2024 20th International Conference on Network and Service Management (CNSM)}, 
  title={Generating Commit Messages for Configuration Files in 5G Network Deployment Using LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Network automation is crucial for improving network performance. Commit messages describes the different actions of the modification of network configuration files and deployments. This paper presents experiments and studies on automated commit message generation in the deployment of 5G networks. We extracted data from repositories of various projects engineered in Orange’s 5G network. We then developed five prompts for experiments to identify the most suitable methods for this task. To select large language models, we used an in-house GPT-4 interface provided by Orange, and locally deployed popular large models such as Llama3, Mistral. We used both automated and human evaluation methods, selecting BLEU, ROUGE, and METEOR as our metrics for automated assessment. Our experiments shows that commit messages for configuration files generated by Large Language Models (LLMs) have better scores when using one-shot and Retrieval-Augmented Generation (RAG) technologies, for messages generated both by humans and bots.},
  keywords={Measurement;Automation;5G mobile communication;Large language models;Retrieval augmented generation;Meteors;Data mining;Commit Message Generation;Large Language Model;network automation},
  doi={10.23919/CNSM62983.2024.10814636},
  ISSN={2165-963X},
  month={Oct},}@INPROCEEDINGS{10372877,
  author={Cobos, Miguel and Cherres, Henry},
  booktitle={2023 IEEE 3rd International Conference on Advanced Learning Technologies on Education & Research (ICALTER)}, 
  title={School evaluation and artificial intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Assessment in education has evolved over time and has established new ways of obtaining information about students’ academic progress. However, the advent of artificial intelligence, such as ChatGPT, has posed challenges in the assessment process, as students can use these technologies to solve questions and tasks without studying. This research focused on recommending alternative educational resources for assessment, considering the pros and cons of ChatGPT and other AI. A systematic literature review was conducted and resources such as written tests, Kahoot!, Quizlet, Mentimeter and Nearpod were identified and evaluated in the tool designed in Microsoft Excel to evaluate their effectiveness. The results showed that the written test and the Plickers tool were the most effective, followed by ClassTools, Flip, Kahoot!, Quizlet, Mentimeter and Nearpod, in addition a list of activities that can be used to assess knowledge through the rubric is shown, among the most important are: oral lessons, exhibitions, open houses, speeches, case studies, debates and observation of participation, because these types of work encourage the speaker to prepare and master the subject. Traditional assessment in the educational field has faced challenges with the advent of artificial intelligence because AI’s ability to generate tasks and answers without students having to read, write or study poses a challenge to ensure the actual acquisition of knowledge and skills. This research recommends educational resources to assess through digital tools or educational activities that allow for authentic assessment of learning and limit reliance on AI.},
  keywords={Systematics;Bibliographies;Education;Learning (artificial intelligence);Chatbots;Spreadsheet programs;Task analysis;evaluation;educational resources;artificial intelligence;ChatGPT},
  doi={10.1109/ICALTER61411.2023.10372877},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10569759,
  author={Drushlyak, M. and Lukashova, T. and Sabadosh, Yuliia and Melnikov, Ivan and Semenikhina, O.},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Using ChatGPT for the Development of Critical Thinking in Youth: Example of Inequality Proof}, 
  year={2024},
  volume={},
  number={},
  pages={334-339},
  abstract={The article explores the problem of using artificial intelligence in education. Practices of using ChatGPT in professional training are analyzed, highlighting both the positive aspects and risks of AI implementation in the educational process. The possibility of using AI to develop pre-service teachers’ critical thinking is justified. ChatGPT is used as a generator of possible pupils’ responses. The application of artificial intelligence, specifically ChatGPT, in proving inequalities is demonstrated. The generated responses are analyzed. Results of a pedagogical experiment on using ChatGPT for the development of pre-service mathematics teachers’ critical thinking are described. The evaluation criteria for individual tasks are based on key characteristics of critical thinking: 1) the ability to analyze information critically; 2) the ability to identify logical inconsistencies in statements; 3) the ability to eliminate logical inconsistencies; 4) a tendency to seek the most rational solution to a problem. The sign test is employed for statistical analysis of the results. The hypothesis regarding the positive impact of analyzing proofs of inequalities proposed by ChatGPT on the development of students’ critical thinking is confirmed. Problems in using ChatGPT in the Ukrainian language are identified.},
  keywords={Training;Statistical analysis;Chatbots;Market research;Mathematics;Generators;Information and communication technology;critical thinking;artificial intelligence;proof of inequalities;mathematics education;pre-service mathematics teachers;professional training},
  doi={10.1109/MIPRO60963.2024.10569759},
  ISSN={2623-8764},
  month={May},}@ARTICLE{10697478,
  author={Zhang, Yuzhe and Liu, Huan and Xiao, Yang and Amoon, Mohammed and Zhang, Dalin and Wang, Di and Yang, Shusen and Quek, Chai},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={LLM-Enhanced Multi-Teacher Knowledge Distillation for Modality-Incomplete Emotion Recognition in Daily Healthcare}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={The critical importance of monitoring and recognizing human emotional states in healthcare has led to a surge in proposals for EEG-based multimodal emotion recognition in recent years. However, practical challenges arise in acquiring EEG signals in daily healthcare settings due to stringent data acquisition conditions, resulting in the issue of incomplete modalities. Existing studies have turned to knowledge distillation as a means to mitigate this problem by transferring knowledge from multimodal networks to unimodal ones. However, these methods are constrained by the use of a single teacher model to transfer integrated feature extraction knowledge, particularly concerning spatial and temporal features in EEG data. To address this limitation, we propose a multi-teacher knowledge distillation framework enhanced with a Large Language Model (LLM), aimed at facilitating effective feature learning in the student network by transferring knowledge of extracting integrated features. Specifically, we employ an LLM as the teacher for extracting temporal features and a graph convolutional neural network for extracting spatial features. To further enhance knowledge distillation, we introduce causal masking and a confidence indicator into the LLM to facilitate the transfer of the most discriminative features. Extensive testing on the DEAP and MAHNOB-HCI datasets demonstrates that our model outperforms existing methods in the modality-incomplete scenario. This study underscores the potential application of large models in this field. The code is publicly available at https://github.com/yuzhezhangEEG/LM-KD.},
  keywords={Brain modeling;Electroencephalography;Emotion recognition;Physiology;Knowledge engineering;Feature extraction;Medical services;Bioinformatics;Biological system modeling;Training;Healthcare;Emotion Recognition;Large Language Model;Multi-teacher Knowledge Distillation},
  doi={10.1109/JBHI.2024.3470338},
  ISSN={2168-2208},
  month={},}@INPROCEEDINGS{10441780,
  author={Kumar, Tajinder and Kait, Ramesh and Ankita and Rani, Sunita},
  booktitle={2023 International Conference on Advanced Computing & Communication Technologies (ICACCTech)}, 
  title={Possibilities and Pitfalls of Generative Pre-Trained Transformers in Healthcare}, 
  year={2023},
  volume={},
  number={},
  pages={37-44},
  abstract={For its potential use in healthcare, Generative Pre-trained Transformers (GPT) and comparable models have attracted a lot of attention. These models present opportunities for therapeutic decision assistance, effective recordkeeping, natural language interactions, and patient education. Their application in healthcare, however, also has some drawbacks and difficulties that need to be properly handled.. The applications of GPT models in healthcare are incredibly broad. Through natural language interactions, they can produce patient education materials, offer decision help to healthcare professionals, and enhance user experience. GPT models offer the potential to improve tele-medicine projects, healthcare process optimization, and patient engagement. They can also help in literature reviews, information retrieval, and medical research, which enable researchers and healthcare practitioners to stay current with evidence-based practices. When applying GPT models in healthcare, a number of issues must be taken into account. These include the limitations of medical knowledge, ethical issues, potential biases and informational errors, legal and regulatory compliance, and the difficulty of having limited contextual awareness. GPT models should be used to support human decision-making rather than to replace medical experts. Critical issues that must be taken into account include patient confidentiality, data security, and the ethical usage of GPT models. To establish credibility and validate the GPT models' outputs in healthcare contexts, improvements to their interpretability and explain ability are required. To guarantee the application and efficacy of GPT models in healthcare, domain-specific adaption and clinical validation are crucial research fields. To properly handle the opportunities and drawbacks of GPT models, collaboration between researchers, healthcare professionals, and policymakers is crucial. The potential for revolutionizing healthcare delivery is enormous with pre-trained Transformers. But the difficulties and potential traps they pose must be carefully considered. GPT models can be ethically implemented and help to improve healthcare outcomes by resolving ethical issues, guaranteeing data privacy and security, and proving their efficacy in clinical situations. For GPT models to be used in healthcare to their fullest potential and to reduce the hazards involved, further research and collaboration are required.},
  keywords={Ethics;Adaptation models;Education;Decision making;Collaboration;Medical services;Transformers;Generative Pre-trained Transformers (GPT);Medical Chatbot;GPT-3 Health Bots;GPT-3 Clinical Documentation;GPT-3 Health Assistant},
  doi={10.1109/ICACCTech61146.2023.00016},
  ISSN={},
  month={Dec},}@ARTICLE{10494570,
  author={Barambones, Jose and Moral, Cristian and de Antonio, Angélica and Imbert, Ricardo and Martínez-Normand, Loïc and Villalba-Mora, Elena},
  journal={IEEE Transactions on Learning Technologies}, 
  title={ChatGPT for Learning HCI Techniques: A Case Study on Interviews for Personas}, 
  year={2024},
  volume={17},
  number={},
  pages={1460-1475},
  abstract={Before interacting with real users, developers must be proficient in human–computer interaction (HCI) so as not to exhaust user patience and availability. For that, substantial training and practice are required, but it is costly to create a variety of high-quality HCI training materials. In this context, chat generative pretrained transformer (ChatGPT) and other chatbots based on large language models (LLMs) offer an opportunity to generate training materials of acceptable quality without foregoing specific human characteristics present in real-world scenarios. Personas is a user-centered design method that encompasses fictitious but believable user archetypes to help designers understand and empathize with their target audience during product design. We conducted an exploratory study on the Personas technique, addressing the validity and believability of interviews designed by HCI trainers and answered by ChatGPT-simulated users, which can be used as training material for persona creation. Specifically, we employed ChatGPT to respond to interviews designed by user experience (UX) experts. Two groups, HCI professors and professionals, then evaluated the validity of the generated materials considering quality, usefulness, UX, and ethics. The results show that both groups rated the interviews as believable and helpful for Personas training. However, some concerns about response repetition and low response variability suggested the need for further research on improved prompt design in order to generate more diverse and well-developed responses. The findings of this study provide insight into how HCI trainers can use ChatGPT to help their students master persona creation skills before working with real users in real-world scenarios for the first time.},
  keywords={Interviews;Training;Chatbots;Surveys;Ethics;Task analysis;Recruitment;Chatbots;computer science education;human–computer interaction (HCI);large language model (LLM);training;user-centered design},
  doi={10.1109/TLT.2024.3386095},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10852445,
  author={Sadiq, Muhammad and Tariq, Ramsha and Ullah, Anayat and Panezai, Jeneen},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={From Pixels to Paragraphs: Extraction of Text from Medical Reports using LLMs, Systematic Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={216-228},
  abstract={Large language models are emerging very rapidly in applications covering nearly all fields including healthcare. In healthcare, these are commonly used for image to text, information extraction and generation and finding results from the medical notes and images. In spite of their extraordinary applications in healthcare, a standard and comprehensive systematic literature review (SLR) in this domain is lacking. However, there are quite a few systematic literature reviews in the field of large language models (LLMs) approaching the medical field. For that reason, this paper evaluates the literature to gather the relevant studies regarding LLMs in the medical field. The SLR process including a detail search was utilized to evaluate the research papers published between 2018 to date i.e. 2024, and a total of 82 studies, after rigorous screening, were included in this SLR. To wisely categorize these studies, consequently, we employed specific quality assessment criteria. Out of these 82 significant studies, only 4% were recognized to have utilized standard SLR guidelines. The results were presented in the form of charts and tables covering all the important aspects of meta data related to these selected studies. The quality assessment in screening these studies is also carried out in a very meticulous manner. Finally, an extensive discussion is carried out on formulated research questions in the methodology section and the suitable answers are discussed there. This paper therefore fulfills the gap for the scholars working on LLMs in the medical domain.},
  keywords={Large language models;Medical services;Metadata;Information retrieval;Quality assessment;Standards;Systematic literature review;Biomedical imaging;Guidelines;large language models;LLMs;text extraction;vision language models (VLMs);medical images into text and LLMs in medicine},
  doi={10.1109/FLLM63129.2024.10852445},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10487540,
  author={Jo, Jinyoung and Choi, Sean},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={Analysis of Plagiarism via ChatGPT on Domain-Specific Exams}, 
  year={2023},
  volume={},
  number={},
  pages={1026-1033},
  abstract={This work presents a case study, linguistic analysis and potential prevention methods on the use of large language models (LLM) for generating solutions for exams on cloud computing course that require domain-specific knowledge. The study involves analyzing the responses of three groups of students: a group who used ChatGPT to plagiarize solutions, another group who referred to external non-LLM resources (e.g., web search) to plagiarize solutions, a control group who generated solutions without any external assistance. Results show that solutions from groups that participated in plagiarism tend to be lengthy, use uncommon words, and are similar to each other compared to human-generated solutions. This study not only shows that it is possible to generate legitimate solutions for exams that require extensive domain-specific knowledge using ChatGPT, but also shows some potential signals one can use to detect plagiarism, thus providing potential of promoting academic integrity by curbing unethical use of AI in academic settings.},
  keywords={Cloud computing;Plagiarism;Computational modeling;Linguistics;Chatbots;Computer science education;Web search;Large Language Model;Academic Integrity;Computer Science Education;Plagiarism Detection},
  doi={10.1109/CSCE60160.2023.00171},
  ISSN={},
  month={July},}@INPROCEEDINGS{11016642,
  author={Pua, Li Xue and Ramesh, Rushil and Natarajan, Prabhu and Iyer, Ganesh Neelakanta},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={CustomAIzEd: Bridging Interdisciplinary Gaps in AI Education with Customized Content Using LLMs}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The relationship between Artificial Intelligence (AI) and Education has witnessed substantial development in recent years, driven by a rising demand for learning AI concepts and the integration of AI technologies to enhance educational experiences. The inherent complexity of AI concepts necessitates the development of personalized pedagogical approaches to convey these concepts to students. However, few existing solutions enable the creation of customized content tailored to the unique learning needs of students. To bridge this gap, we have developed CustomAIzEd, an adaptive learning platform that harnesses large language models (LLMs) to thoughtfully create and recommend personalized quizzes and programming assignments focused on AI concepts. To evaluate the efficacy of this feature, a user study was conducted on students and instructors of IT1244, an introductory AI course offered by the National University of Singapore (NUS), based on the Unified Theory of Acceptance and Use of Technology (UTAUT) framework. The study revealed strong user intent from both students and instructors, highlighting the application's potential to enhance the experiences both of learners and educators in the field of AI.},
  keywords={Productivity;Learning management systems;Large language models;Learning (artificial intelligence);Solids;Prompt engineering;Artificial intelligence;Engineering education;Programming profession;Software engineering;Artificial Intelligence;Educational Technology;Software Engineering;Personalized Learning},
  doi={10.1109/EDUCON62633.2025.11016642},
  ISSN={2165-9567},
  month={April},}@ARTICLE{11002710,
  author={McIntosh, Timothy R and Susnjak, Teo and Arachchilage, Nalin and Liu, Tong and Xu, Dan and Watters, Paul and Halgamuge, Malka N},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Inadequacies of Large Language Model Benchmarks in the Era of Generative Artificial Intelligence}, 
  year={2025},
  volume={},
  number={},
  pages={1-18},
  abstract={The rapid rise in popularity of Large Language Models (LLMs) with emerging capabilities has spurred public curiosity to evaluate and compare different LLMs, leading many researchers to propose their own LLM benchmarks. Noticing preliminary inadequacies in those benchmarks, we embarked on a study to critically assess 23 state-of-the-art LLM benchmarks, using our novel unified evaluation framework through the lenses of people, process, and technology, under the pillars of benchmark functionality and integrity. Our research uncovered significant limitations, including biases, difficulties in measuring genuine reasoning, adaptability, implementation inconsistencies, prompt engineering complexity, evaluator diversity, and the overlooking of cultural and ideological norms in one comprehensive assessment. Our discussions emphasized the urgent need for standardized methodologies, regulatory certainties, and ethical guidelines in light of Artificial Intelligence (AI) advancements, including advocating for an evolution from static benchmarks to dynamic behavioral profiling to accurately capture LLMs’ complex behaviors and potential risks. Our study highlighted the necessity for a paradigm shift in LLM evaluation methodologies, underlining the importance of collaborative efforts for the development of universally accepted benchmarks and the enhancement of AI systems’ integration into society.},
  keywords={Benchmark testing;Cultural differences;Generative AI;Computer science;Large language models;Ethics;Cognition;Hardware;Adaptation models;Training;Artificial Intelligence (AI);AI Evaluation;Benchmark;Evaluation Frameworks;Large Language Model (LLM)},
  doi={10.1109/TAI.2025.3569516},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{10184267,
  author={Allam, Hesham and Dempere, Juan and Akre, Vishwesh and Parakash, Divya and Mazher, Noman and Ahamed, Jinesh},
  booktitle={2023 9th International Conference on Information Technology Trends (ITT)}, 
  title={Artificial Intelligence in Education: An Argument of Chat-GPT Use in Education}, 
  year={2023},
  volume={},
  number={},
  pages={151-156},
  abstract={Artificial intelligence (AI) is a popular concept for modernizing and automating traditional, time-consuming tasks with smart technology. AI can be applied to a wide range of areas, such as healthcare, finance, law, and education. AI has the potential to revolutionize the way we learn by making education more interactive and engaging. One possible step The way forward in this field is through the use of generative artificial intelligence.technologies like the ChatGPT conversational agent. Although enthusiastic techno-utopian cheerleaders are praising the tool.for answering questions, writing essays, summarizing documents,and generating sophisticated codes, it has some pitfalls that were acknowledged by the creators of OpenAI themselves. In this article, we discuss the application of artificial intelligence in education and put the trendy ChatGPT to the test in an educator-Learner context to see how it performs. We also discuss some of the benefits and drawbacks of ChatGPT and demonstrate how it might be utilized in the classroom. It is essential for educators to understand the implications of this technology and to investigate Strategies to modify the educational environment},
  keywords={Law;Education;Virtual reality;Medical services;Writing;Licenses;Chatbots;Artificial Intelligence;ChatGPT;AIED;intelligent agents;assessment;intelligent tutoring systems;personalized learning},
  doi={10.1109/ITT59889.2023.10184267},
  ISSN={},
  month={May},}@INPROCEEDINGS{10834346,
  author={Hayashi, Victor Takashi and Mohallem Paiva, Henrique},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={ChatGPT Calls for Self Reflection: Student Perceptions of Evaluation Activities in Video}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={ChatGPT has shown significant adoption for students when answering evaluation activities in undergraduate courses such as Information Systems, Computer Engineering, Software Engineering and Computer Science. When facing this challenge, one possibility for educators is to enable the students to learn while using the tool instead of restricting its usage. In this paper, we describe a case study of evaluation activities in video format as a way to motivate self-reflection in students. This alternative method prevents students from simply copying and pasting textual answers without any reflection. Furthermore, it encourages active participation and improves communication skills and the ability to articulate arguments, which may be lacking when students rely solely on written responses. We present 53 student perceptions regarding these video-based evaluation activities collected during two years, the benefits and drawbacks of the proposed approach, and suggestions for future implementations. According to students perceptions, most of them prefer text and coding evaluation approaches, however these are the ones more prone for ChtGPT ’copy and paste’. The qualitative responses indicate that the main positive aspects are the time flexibility and the additional reflection. The main negative aspects are related to lack of flexibility in communication form, extra work in video editing and additional student anxiety.},
  keywords={Technological innovation;Reviews;Generative AI;Scalability;Anxiety disorders;Chatbots;Reflection;Encoding;Software engineering;Information systems;evaluation;chatgpt;reflection;assessment;artificial intelligence;education},
  doi={10.1109/TALE62452.2024.10834346},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10578712,
  author={Ciolacu, Monica Ionita and Marghescu, Cristina and Mihailescu, Bogdan and Svasta, Paul},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Does Industry 5.0 Need an Engineering Education 5.0? Exploring Potentials and Challenges in the Age of Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Increasing disruption from Industry 4.0/5.0, climate change, digital transformation, wars and high levels of volatility, uncertainty, complexity and ambiguity (VUCA) are leading to major changes in the labor market. In addition, improvements in chatbots and Generative AI are opening new opportunities for students and the future workforce. They seem to have become ‘creative’ in their field of study and are turning to AI applications for their learning, assignments or theses. However, there are concerns about academic integrity and cybersecurity. Students and researchers have already started using AI chatbots to learn, program, write academic essays or conduct research faster and more effectively. This paper explores whether AI can serve as a bicycle for human creativity and innovation. What are the first words that come to mind when you think of Engineering Education 5.0? Have you used Artificial Intelligence tools in your teaching, learning or research? This paper presents the results of a survey conducted at the Faculty of Electronics, Technology and Information Technology on the challenges and opportunities of using Generative AI(GenAI) in Engineering Education. This paper also outlines the Generative AI ecosystem for teaching, learning and research. Engineering Education 5.0 needs a future ready Curricula including AI Literacy, new teaching and learning methods, analytical and critical thinking, reflection, collaboration and complex problem-solving, and communities of practice with the industry to foster innovation and creativity.},
  keywords={Industries;Learning systems;Technological innovation;Generative AI;Education;Artificial intelligence;Engineering education;engineering education 5.0;technology-enhanced learning;innovation;creativity;generative AI},
  doi={10.1109/EDUCON60312.2024.10578712},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10967446,
  author={Mahmoudi, Mohsen and Taghiyareh, Fattaneh and Hessami, Farshad},
  booktitle={2025 29th International Computer Conference, Computer Society of Iran (CSICC)}, 
  title={Enhancing Learning Performance through LLM-Driven Adaptive Contents Based on Facial Engagement Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Recent advancements in AI have opened new avenues for personalized education, enabling learning environments to adapt to individual needs. This study explores the intersection of AI and Image Processing, mainly using facial emotion detection to monitor cognitive engagement and distraction during learning tasks. Previous research highlights the efficacy of emotion detection in identifying cognitive states and improving educational outcomes through personalized learning environments. Our primary goal is to evaluate how AI can adapt educational content in real time to enhance learning effectiveness based on emotional feedback. We utilized an LLM to develop educational content and identified moments of distraction or disengagement by monitoring learners' facial emotions while interacting with the system. Upon detecting distraction, the LLM dynamically restructures the content, subtly reintegrating it into subsequent materials without the learners' awareness. This method reinforces learning by presenting material in varied contexts, thereby improving learners' understanding. Our preliminary results indicate that this approach enhances comprehension levels in distracted learners. Furthermore, integrating emotion-based monitoring with LLMs may provide a responsive educational framework that adapts to learners' immediate needs, promoting deep cognitive engagement and a pleasant personalized learning experience. These findings suggest broader applications beyond academic learning, including professional training. It is the ambition of any learning system to be able to detect any attention fall and to have smart reactions without learners' awareness, which is the vision of our approach.},
  keywords={Training;Learning systems;Emotion recognition;Adaptive systems;Large language models;Predictive models;Chatbots;Generators;Real-time systems;Monitoring;Adaptive Learning;Emotional Feedback;Large Language Models (LLM);Personalized Education;User Modeling},
  doi={10.1109/CSICC65765.2025.10967446},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10893194,
  author={Romero-Vera, Alex and Guarochico-Moreira, Victor and Velasco-Galarza, Victor and Espinoza-Andaluz, Mayken and Guaman-Quintanilla, Sharon and Chiluiza, Katherine},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Enhancing Pre-Class Content Learning in a Flipped Classroom: An Experimental Study of the Benefits of Note-Taking}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This research-to-practice full paper describes an experimental study investigating the benefits of note-taking to enhance pre-class content learning in a flipped classroom (FC) environment applied to an Engineering Physics course. In an FC, fundamental content learning occurs before the class (targeting low cognitive levels on Bloom's taxonomy), allowing in-class time to reinforce and apply concepts (addressing high cognitive levels on Bloom's taxonomy). However, there is a lack of empirical and controlled research studies investigating optimal strategies for obtaining high-value pre-class content learning. This study aims to contribute to this matter. Four groups are considered, each comprising an average of 40 students, following the FC instructional methodology. Pre-class activities precede the class, including reading prepared documents and watching prepared videos. In-class assessments consist of a brief multiple-choice test (maximum of 5 questions) related to the pre-class activities, aiming to evaluate low cognitive levels on Bloom's taxonomy. To enhance note-taking practices, students are encouraged to take notes, and at the beginning of the course, a video showcasing five note-taking strategies is provided. The experiment carried out along one of the chapters revised in the Engineering Physics course includes one control group and one experimental group. In the control group, students are encouraged to take notes without additional guidance, whereas in the experimental group, students receive a fill-in-the-blank style note- taking guide. The results indicate that students who engage in note-taking, irrespective of the strategy used, outperform those who do not take notes. It is well-documented that note-taking produces an improvement in the in-class learning process. Here, we show how this benefit can be translated to activities before class, enhancing self-regulation learning and reducing the cognitive load during in-class note-taking. Regarding the note-taking guide, there is no significant evidence to support the improvement of student performance. This lack of progress may be attributed to the nature of the guide, using a linear note-taking strategy that ends with non-generative notes. This study shows the benefits of note-taking in enhancing pre-class content learning in an FC environment applied to an Engineering Physics course and invites us to rethink how the note-taking guide structure could encourage the production of generative notes.},
  keywords={Electronic learning;Statistical analysis;Taxonomy;Education;Production;Cognitive load;Online services;Physics;Videos;note- taking;flipped classroom;linear note- taking strategy;Bloom's taxonomy},
  doi={10.1109/FIE61694.2024.10893194},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10795042,
  author={Tayeb, Ahmad and Alahmadi, Mohammad and Tajik, Elham and Haiduc, Sonia},
  booktitle={2024 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Investigating Developers' Preferences for Learning and Issue Resolution Resources in the ChatGPT Era}, 
  year={2024},
  volume={},
  number={},
  pages={413-425},
  abstract={The landscape of software developer learning re-sources has continuously evolved, with recent trends favoring engaging formats like video tutorials. The emergence of Large Language Models (LLMs) like ChatG PT presents a new learning paradigm. While existing research explores the potential of LLMs in software development and education, their impact on developers' learning and solution-seeking behavior remains unexplored. To address this gap, we conducted a survey targeting software developers and computer science students, gathering 341 responses, of which 268 were completed and analyzed. This study investigates how AI chatbots like ChatGPT have influenced developers' learning preferences when acquiring new skills, ex-ploring technologies, and resolving programming issues. Through quantitative and qualitative analysis, we explore whether AI tools supplement or replace traditional learning resources such as video tutorials, written tutorials, and Q&A forums. Our findings reveal a nuanced view: while video tutorials continue to be highly preferred for their comprehensive coverage, a significant number of respondents view AI chatbots as potential replacements for written tutorials, underscoring a shift towards more interactive and personalized learning experiences. Additionally, AI chatbots are increasingly considered valuable supplements to video tutorials, indicating their growing role in the developers' learning resources. These insights offer valuable directions for educators and the software development community by shedding light on the evolving preferences toward learning resources in the era of ChatGPT.},
  keywords={Surveys;Software maintenance;Large language models;Education;Tutorials;Chatbots;Market research;Programming profession;Software development management;AI-driven learning tools;ChatGPT;programming learning preferences;programming issue resolution;video tutorials;written tutorials;Q&A forums;developer learning resources},
  doi={10.1109/ICSME58944.2024.00045},
  ISSN={2576-3148},
  month={Oct},}@ARTICLE{10504111,
  author={Zhang, Yanjun and Sun, Xiaoyu and Yu, Jiangde},
  journal={Journal of Web Engineering}, 
  title={Transformative Technologies in the Evaluation of a Vocational Education System}, 
  year={2024},
  volume={23},
  number={2},
  pages={275-298},
  abstract={The increasing demand for vocational education has necessitated the presence of highly skilled teachers. This study presents a novel framework for the effective management of vocational college instructors' professional development through the utilization of advanced technologies. The system utilizes deep learning technology to analyze many data points, including academic achievements, teaching experience, student comments, and professional activities, in order to assess the performance and potential of teachers. The system evaluates both the positive and negative aspects, offers customized training programs, and enhances the delivery of instruction through the utilization of a generative language model. The effectiveness of the system is supported by a case study, which demonstrates enhancements in talent management, professional development, teaching quality, and student happiness. This proposed solution aims to improve vocational education by empowering educators and transforming the processes of evaluation, support, and guidance throughout their professional trajectories.},
  keywords={Training;Deep learning;Trajectory;Intelligent management framework;vocational college teachers;deep learning;generative language model},
  doi={10.13052/jwe1540-9589.2324},
  ISSN={1544-5976},
  month={March},}@INPROCEEDINGS{10983088,
  author={Srivastava, Snehi and Nagpal, Namrata and Srivastava, Meenakshi},
  booktitle={2024 IEEE 11th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)}, 
  title={Analyzing Student Engagement With ChatGPT: A Data-Analysis Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The study examines the use of ChatGPT in education, highlighting its potential to enhance productivity and learning. It emphasizes the importance of pedagogical strategies, human oversight, and data security. Performance Expectancy is linked to ChatGPT's effectiveness, while Effort Expectancy is related to its ease of use. The study reveals a predominantly optimistic student reception (approximately 73% of the total respondents) to ChatGPT in education, it's ease of use and versatile functionalities while also highlighting the need for ethical guidelines, data transparency, and academic integrity in its deployment. It was found that in the semi-structured interview of 2000 students, out of 1314 students who deemed ChatGPT advantageous, 87.9% also think they can pose potential risk if not used responsibly.},
  keywords={Productivity;Ethics;Vocabulary;Accuracy;Limiting;Education;Chatbots;Particle measurements;Interviews;Guidelines;ChatGPT;Data Analysis;Student engagement;Education Technology;Ethical Consideration;AI chatbot},
  doi={10.1109/UPCON62832.2024.10983088},
  ISSN={2687-7767},
  month={Nov},}@INPROCEEDINGS{10969684,
  author={Ahmed, Naveed and Iqbal, Zahid and Khan, Rabia and Al-Aswadi, Fatima N. and AlDharhani, Ghassan Saleh and Chan, Huah Yong},
  booktitle={International Conference on Energy, Power, Environment, Control and Computing (ICEPECC 2025)}, 
  title={Automated question generation from job descriptions using large language models: an evaluation of role-fit and fairness}, 
  year={2025},
  volume={2025},
  number={},
  pages={628-635},
  abstract={This paper introduces an automated framework for generating high-quality, role-specific interview questions directly from complex job descriptions using an ensemble of Large Language Models (LLMs). We leverage seven advanced LLMs (gemma2-9b-it,gemma-7b-it,llama-3.3-70b-versatile,llama-3.1-8b-instant,llama3-70b-8192,mixtral-8x7b-32768, andOpenAI-3.5) to produce a diverse pool of questions. Our approach integrates prompt engineering and debiasing strategies to ensure that the generated questions are contextually relevant, role-aligned, and free from harmful biases. We compare the LLMs’ outputs against a strong baseline (ChatGPT o1 Pro) and human domain experts’ assessments, employing a multi-faceted evaluation framework including relevance, clarity, specificity, and fairness metrics. Our results, validated on a curated set of job descriptions across multiple industries, demonstrate that a multi-model generation strategy, combined with bias mitigation and expert-informed prompt design, yields superior interview question sets. This research offers insights into enhancing recruitment practices, improving efficiency, and fostering equitable candidate assessment.},
  keywords={},
  doi={10.1049/icp.2025.1174},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11016655,
  author={Soll, Marcus and Kobras, Louis},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Do Large Language Models Require Prior Knowledge for Learning? A Preliminary Study}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={LLMs find increasing use as an educational tool, both from the instructors' perspective as well as from the students'. This paper presents a preliminary study investigating the effects of prior knowledge concerning a given topic on the effectiveness of using an LLM (Microsoft Copilot) to study the topic. Choosing Büchi automata as an example, twelve computer science students were tasked with first giving a self-report on prior knowledge, then studying Büchi automata for 15 minutes using only an LLM as a study tool, and afterwards filling out a short topical questionnaire. Two trends could be observed: Prior knowledge of LLMs seems to increase the learning effect while prior knowledge of a topic that is related to the studied topic seems to diminish the learning effect.},
  keywords={Visualization;Learning automata;Large language models;Fitting;Automata;Formal languages;Rendering (computer graphics);Market research;Filling;STEM;Computer Science Education;Large Language Models;Pedagogy;STEM education},
  doi={10.1109/EDUCON62633.2025.11016655},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10981323,
  author={Soto, Wilson},
  booktitle={2025 IEEE Engineering Education World Conference (EDUNINE)}, 
  title={Tool-Based Retrieval-Augmented Generative as an Automated Assistant in Object-Oriented Programming Course}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The integration of artificial intelligence into educational tools is transforming learning environments. In computer science, students frequently encounter challenges with complex concepts and practical applications. While LLMs offer valuable support, their responses can sometimes lack precision or rely on outdated information. Addressing these limitations is essential to enhance the effectiveness of AI-based tools in educational support. The main objective of this paper is to propose a tool-based RAG as automated assistant in an OOP Course. The tool was tested using common student queries and its responses were compared with those generated by ChatGPT. Initial observations suggest that RAG consistently generated contextually relevant responses due to its ability to access pertinent information from a structured knowledge base, resulting in more precise and applicable answers for students. The introduction of a RAG-based tool in classrooms has the potential to enhance student learning by providing instant, tailored responses to specific queries.},
  keywords={Computer science;Large language models;Knowledge based systems;Learning (artificial intelligence);Chatbots;Object oriented programming;Engineering education;Artificial Intelligence;Automated Assistant;Large Language Models (LLMs);OOP (Object-Oriented Programming);RAG (Retrieval-Augmented Generative)},
  doi={10.1109/EDUNINE62377.2025.10981323},
  ISSN={},
  month={March},}@INPROCEEDINGS{10814858,
  author={Sun, Jiaqin and Kwong, Chiew-Foong and Buticchi, Giampaolo},
  booktitle={2024 IEEE 11th International Conference on E-Learning in Industrial Electronics (ICELIE)}, 
  title={The Potential of AI in Electrical and Electronic Engineering Education: A Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid advancement of Artificial Intelligence (AI) technologies is transforming education, particularly in Electrical and Electronic Engineering (EEE). This paper explores the potential applications, benefits, and challenges of Generative AI (GenAI) and Large Language Models (LLMs) in EEE education. Key areas include personalized learning, intelligent tutoring systems, automated grading, and predictive analytics. While these technologies offer significant enhancements in teaching and learning, they also present challenges such as data privacy, bias, and the need for human interaction. By examining current implementations and providing recommendations, this paper aims to guide educators and researchers in effectively integrating AI to improve EEE education.},
  keywords={Industrial electronics;Electric potential;Data privacy;Electronic learning;Reviews;Generative AI;Large language models;Education;Predictive analytics;Electronics engineering education},
  doi={10.1109/ICELIE62250.2024.10814858},
  ISSN={2997-7282},
  month={Nov},}@INPROCEEDINGS{10633447,
  author={Takerngsaksiri, Wannita and Warusavitarne, Cleshan and Yaacoub, Christian and Keng Hou, Matthew Hee and Tantithamthavorn, Chakkrit},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Students' Perspectives on AI Code Completion: Benefits and Challenges}, 
  year={2024},
  volume={},
  number={},
  pages={1606-1611},
  abstract={AI Code Completion (e.g., GitHub's Copilot) has revolutionized how computer science students interact with programming languages. However, AI code completion has been studied from the developers' perspectives, not the students' perspectives who represent the future generation of our digital world. In this paper, we investigated the benefits, challenges, and expectations of AI code completion from students' perspectives. To facilitate the study, we first developed an open-source Visual Studio Code Extension tool AutoAurora, powered by a state-of-the-art large language model StarCoder, as an AI code completion research instrument. Next, we conduct an interview study with ten student participants and apply grounded theory to help analyze insightful findings regarding the benefits, challenges, and expectations of students on AI code completion. Our findings show that AI code completion enhanced students' productivity and efficiency by providing correct syntax suggestions, offering alternative solutions, and functioning as a coding tutor. However, the over-reliance on AI code completion may lead to a surface-level understanding of programming concepts, diminishing problem-solving skills and restricting creativity. In the future, AI code completion should be explainable and provide best coding practices to enhance the education process.},
  keywords={Productivity;Visualization;Computer languages;Codes;Syntactics;Encoding;Artificial intelligence;AI Code Completion;Software Engineering;Programming Education},
  doi={10.1109/COMPSAC61105.2024.00252},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{10956533,
  author={Maulana, Fairuz Iqbal and Adi, Puput Dani Prasetyo and Widartha, Vandha Pradwiyasma},
  booktitle={2024 International Conference on Informatics, Multimedia, Cyber and Information System (ICIMCIS)}, 
  title={A Comprehensive Review and Research Trends of Large Language Models (LLMs) in Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={346-351},
  abstract={The emergence of Artificial Intelligence (AI) has significantly impacted the development of computational models for social systems, providing new opportunities for feedback-rich simulations. To achieve human-level language understanding, the incorporation of language models into comprehensive understanding systems is a crucial advancement. The use of Large Language Models (LLMs) in various fields, such as geomorphology and physics, highlights the necessity for robust policies and frameworks to regulate their use. Data selection from the Scopus database yielded a total of 2149 documents from 1173 sources. The most cited article from 2023 is 799 citations. Average citations per doc is 6.221. USA, China, and United Kingdom appear to dominate in terms of the number of published. By conducting a scientometric review and bibliometric analysis using R studio and VOSviewer software, this study aims to identify key focus areas, challenges, and opportunities in the implementation of IoT technologies in urban environments. As AI technologies, including LLMs, progress, their influence on diverse sectors like education, engineering, and healthcare is increasingly evident, emphasizing the importance of thorough assessments of their capabilities and constraints. By synthesizing insights from existing literature and exploring emerging trends, this study contributes to the advancement of Large Language Models (LLMs) in Artificial Intelligence and the development of a more connected and intelligent urban future.},
  keywords={Reviews;Databases;Large language models;Computational modeling;Bibliometrics;Urban areas;Transformer cores;Market research;Transformers;Surges;Large language model;LLMs;Artificial Intelligence;Bibliometric;Review},
  doi={10.1109/ICIMCIS63449.2024.10956533},
  ISSN={2837-5203},
  month={Nov},}@INPROCEEDINGS{10837597,
  author={Gusman, Elvina and Gide, Ergun and El Khodr, Mahmoud and Chaudhry, Ghulam},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={The Benefits and Challenges of Using Artificial Intelligence in Teaching English as a Foreign Language in Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This study explores the implementation of artificial intelligence (AI) in education, particularly in teaching English as a foreign language (TEFL) in higher education. AI has been applied in TEFL since the 1950s and developed significantly over the decades. However, it has received global attention in the last two years after introducing ChatGPT and other similar Generative AI (GenAl) applications. Implementing AI provides benefits and challenges to educators and students in English learning and teaching (ELT). This study examines systematic literature reviews regarding the benefits and challenges of employing AI toward ELT in higher education. This study synthesizes previous research to enhance insights into TEFL by applying AI effectively. Applying AI to teach English as a foreign language has several benefits and challenges. These can be summarized in the dimensions of using machine learning, chatbots, intelligent virtual environments, translation tools, multidimensional ethics, and social media. Each dimension provides valuable benefits and considers the challenges for educators in delivering English as a foreign language at the university level. The benefits of utilizing AI in TEFL are evolutionary and revolutionary changes in teaching methods, personalized learning environments, better management, and more accessible education. Despite these benefits, the challenges of utilizing AI can be identified as computational issues, limited language exposure, and lack of human interaction. Furthermore, this study can enhance the understanding and insight of implementing AI in teaching English as a foreign language by minimizing the challenges and optimizing the benefits of AI.},
  keywords={Training;Ethics;Translation;Social networking (online);Education;Virtual environments;Machine learning;Chatbots;Artificial intelligence;Systematic literature review;artificial intelligence;GenAl;benefits;challenges;teaching English;higher education},
  doi={10.1109/ITHET61869.2024.10837597},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10593283,
  author={Singh, Anuradha and Sharma, Himanshu and Jindal, Kanika and Chaudhary, Ankur},
  booktitle={2024 International Conference on Communication, Computer Sciences and Engineering (IC3SE)}, 
  title={Synergizing Futures: Precision Career Mapping with Llama 2 and AI Fine-Tuning for Personalized Path Prediction and Guided Navigation}, 
  year={2024},
  volume={},
  number={},
  pages={336-341},
  abstract={These days, a lot of students struggle in how to choose the career. As they progress through their studies, students must recognize their abilities and assess their areas of interest to determine the most appropriate job for them. With the aid of this approach, today's youngsters will be able to determine which career route will yield the best outcomes in the long run if they choose the suggested vocation. This will assist in raising the student's performance and spark their interest to keep them concentrated on their desired job. This system is based on an exam that students must complete; based on their responses, it will produce a summary of the test results. The primary goal of this system is to give a summary of the artificial intelligence methods that we employed to forecast the student's performance. This structure likewise be emphasizing how we are identifying characteristics in student data by employing prediction systems. For educators, educational institutions, and students alike, using this system has proven to be advantageous. In this paper we have used various technologies like Flutter, Llama-2 generative A.I. model, Firebase and UI/UX design tools. Our experimental results of proposed system reduce the career searching effort by 80% when tested for Lyman people.},
  keywords={Employee welfare;Engineering profession;Navigation;Scalability;Large language models;Design tools;Sparks;Student career guidance;Artificial Intelligence;Llama-2;Fine-Tuning;P3GS},
  doi={10.1109/IC3SE62002.2024.10593283},
  ISSN={},
  month={May},}@ARTICLE{11029015,
  author={Chibuike, Onuoha and Dang, Vu Hai and Nam, Nguyen Duc and Huong, Truong Thu and Nam, Pham Ngoc and Thang, Truong Cong},
  journal={IEEE Access}, 
  title={Subjective and Objective Quality Assessments of AI-generated Images for Language E-Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={AI-generated images (AIGIs) are becoming popular and can be employed in many applications, thanks to Generative AI (GAI). Researchers have developed models that can be used to generate images in different scenarios. Also, researchers have proposed datasets of natural scene images for language learning and different AIGI-quality datasets for general applications. For e-learning, particularly in the context of language learning, no AIGI dataset is currently available. To fill this gap, we first proposed an AIGI quality dataset for language learning. Both subjective and objective assessments have been conducted on the proposed dataset. The findings from subjective assessment show that higher perceptual quality also corresponds to a more substantial alignment. It also shows that the average MOS scores of images generated from Stability AI models are similar and lower than images generated by the Dall.E3 model. Results from the objective assessment indicate that the performance of off-the-shelf quality models is generally low. In addition, results from finetuning learning-based quality models show that significant gains and improvements can be achieved using the dataset. Results from the alignment evaluation show that the HPS model is the best, and realistic images in the dataset produced the best alignment correlation compared with the other styles in the dataset. The findings also show that multimodal large language models, such as vision-enabled GPT-4 (GPT-4V) still struggle to produce alignment scores that correlate with humans.},
  keywords={Electronic learning;Visualization;Text to image;Quality of experience;Quality assessment;Diffusion models;Training data;Training;Generators;Generative AI;AI-generated image;subjective study;AIGI;objective evaluation;QoE;e-learning;language learning},
  doi={10.1109/ACCESS.2025.3578047},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10718488,
  author={Nivithan, S. and Abhishek, A. and Thanapal, P. and Prakash Balaji, M. Sundar and Joseph Michael Jerard, V. and Ganesan, P. and Elamaran, V.},
  booktitle={2024 Third International Conference on Electrical, Electronics, Information and Communication Technologies (ICEEICT)}, 
  title={Exploring State-of-the-Art Methods in Mastering Digital Signal Processing through Blended Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This study highlights the necessity of employing extremely potent software tools for both teaching and mastering mathematically complex theory subjects. In the field of Electrical Engineering, there are courses like Engineering Electromagnetics, Signals & Systems, Control Systems, Digital Signal Processing, Digital Image Processing, Antennas & Wave Propagation, etc., where students learn very little because teachers must spend a lot of time in the classroom explaining mathematical principles. Since lecturing alone doesn't aid in the appropriate interpretation of the material, learners perceive it as being extremely difficult and unconnected. A robust graphical data flow programming environment with an extensive library of functions and tool sets in both simulation and real-time mode is one of the many such software tools that are currently accessible. With the use of these technologies, students from non-electronics streams can complete courses with a strong mathematical foundation more quickly and easily. This paper uses Orange Data Mining software tools, ChatGPT, Google Classroom, Matlab, and the Whatsapp platform to teach digital signal processing more effectively. Educators may focus more on practice because of this kind of research, which encourages students to learn for themselves.},
  keywords={Propagation;Process control;Digital signal processing;Speech recognition;Real-time systems;Libraries;Software tools;MATLAB;Streams;Programming environments;Digital signal processing;classroom learning;lecturing;machine learning;Orange software;speech processing},
  doi={10.1109/ICEEICT61591.2024.10718488},
  ISSN={},
  month={July},}@INPROCEEDINGS{10336315,
  author={Sami, Mansour and Sami, Ashkan and Barclay, Pete},
  booktitle={2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={A case study of fairness in generated images of Large Language Models for Software Engineering tasks}, 
  year={2023},
  volume={},
  number={},
  pages={391-396},
  abstract={Bias in Large Language Models (LLMs) has significant implications. Since they have revolutionized content creation on the web, they can lead to more unfair outcomes, lack of inclusivity, reinforcement of stereotypes and ethical and legal concerns. Notably, OpenAI has recently made claims they have introduced a new technique to ensure that DALL-E-2 generates images of people accurately reflect the diversity of the world’s population. In order to investigate bias within the field of Software Engineering, the study utilized DALL-E-2 image generation to assess 56 tasks related to software engineering. Another objective was to determine the impact of OpenAI’s new measures on the generated images for these specific tasks. Two sets of experiments were conducted. In one set, the tasks were prefixed with the clause "As a Software Engineer," while in the other set, only the tasks themselves were used. The tasks were presented in a gender-neutral manner, and the AI was instructed to generate images for each task 20 times. For a female-dominant task of doing administrative tasks, 40 more images were generated. The study revealed a large gender bias in the 2,280 images generated. For instance, in the subset of experiments with prompts explicitly incorporating the phrase "As a software engineer," only 2% of the generated images portrayed female protagonists. In all the images in this setting, male protagonists were dominant and in 45 tasks 100% of the protagonists were male. Notably, images generated without the prefixed clause only had more female protagonists in ‘provide comments on project milestones’ and ‘provide enhancements’, while other tasks did not exhibit a similar pattern. The findings emphasize unsuitability of implemented guardrails and the importance of further research on LLMs assessments. Further research is needed in LLMs to find out where their guardrails fail so companies can address them properly.},
  keywords={Software maintenance;Ethics;Law;Image synthesis;Sociology;Companies;Task analysis;Large Language Models;bias;gender diversity;Generative images;DALL-E-2},
  doi={10.1109/ICSME58846.2023.00051},
  ISSN={2576-3148},
  month={Oct},}@INPROCEEDINGS{10815706,
  author={Tarek, Ahmed and Mahmoud, Marwa and Afifi, Basma and Mashaly, Maggie and Abu-Elkheir, Mervat},
  booktitle={2024 International Conference on Microelectronics (ICM)}, 
  title={Query-Based Topic Modeling and Trend Analysis in Scientific Literature}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The number of scientific publications grows every year. This growth has contributed to the continuous emergence of new trends across various scientific domains where researchers and investors are eager to predict these trends in advance. Using Natural Language Processing (NLP) techniques, this study aimed to develop a topic modeling approach to identify possible emerging trendy topics in a predetermined scientific field based on a given query and a set of thousands of abstracts. The proposed approach involves abstracts preprocessing, abstracts, and query encoding with the “allenai-specter” Sentence-BERT (SBERT) model, retrieving abstracts similar to the user query, and clustering them using the Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) algorithm. Subsequently, Latent Dirichlet Allocation (LDA) is applied to each cluster for topic modeling, and the resulting topics are labeled and analyzed over time to discover their trending status. Finally, abstracts discussing these emerging topics are summarized using the OpenAI “gpt-3.5-turbo-0125” model. Our approach, combining these technologies, achieved its objectives. Tested on data from 2016 to 2023 and focused on NLP as the domain of examination, our approach accurately identified five clusters, each representing specific NLP subfields, and highlighted approximately six trending topics spanning areas such as Performance Optimization in Pretrained Language Models, Multimodal Language Processing, Sentiment Analysis, and Text Generation methods in LLMs.},
  keywords={Analytical models;Sentiment analysis;Noise;Predictive models;Market research;Encoding;Data models;Microelectronics;Resource management;Optimization;NLP;LDA;trend prediction;HDBSCAN clustering;UMAP;SBERT;ML},
  doi={10.1109/ICM63406.2024.10815706},
  ISSN={2159-1679},
  month={Dec},}@INPROCEEDINGS{10662997,
  author={Böttcher, Axel and Thurner, Veronika},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Assessing Software Development Competences Constructively Aligned in an Open-Web Format}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={To assess in a constructively aligned way those programming competences that are relevant for the professional practice of future software developers, an assessment format would be suitable where students actively program, within the integrated development environment (IDE) that they are individually used to, and with unrestricted access for researching in the web. A format that accommodates these needs well is “Bring Your Own Device, Open Book, Open Web”, where students work on their own devices against given git repositories, with full access on knowledge bases and the internet. In this work, we share experiences and suggest well established practices for executing this exam type. As well, we discuss how the ready availability of large language models impacts this assessment type.},
  keywords={Large language models;Knowledge based systems;Software;Bring your own device;Programming profession;Software development management;assessment;electronic exams;computer science education;teaching methods},
  doi={10.1109/CSEET62301.2024.10662997},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10590517,
  author={Wang, Kevin and Lawrence, Ramon},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Using Assignment Incentives to Reduce Student Procrastination and Encourage Code Review Interactions}, 
  year={2023},
  volume={},
  number={},
  pages={1628-1633},
  abstract={Procrastination causes student stress, reduced learning and performance, and results in very busy help sessions immediately before deadlines. A key challenge is encouraging students to complete assignments earlier rather than waiting until right before the deadline, so the focus becomes on the learning objectives rather than just meeting deadlines. This work presents an incentive system encouraging students to complete assignments many days before deadlines. Completed assignments are code reviewed by staff for correctness and providing feedback, which results in more student-instructor interactions and may help reduce student use of generative AI. The incentives result in a change in student behavior with 45% of assignments completed early and 30% up to 4 days before the deadline. Students receive real-time feedback with no increase in marking time.},
  keywords={Codes;Scientific computing;Reviews;Generative AI;Real-time systems;Stress;Computational intelligence;incentives;procrastination;code review;generative AI;time management},
  doi={10.1109/CSCI62032.2023.00270},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{10868886,
  author={Remegio, Florlyn Mae C. and Asahid-Cheng, Remelyn},
  booktitle={2024 4th International Conference on Educational Technology (ICET)}, 
  title={Decoding Acceptance through Technology Acceptance Model: A Descriptive Study of ChatGPT Usage Across Academic Disciplines}, 
  year={2024},
  volume={},
  number={},
  pages={398-402},
  abstract={This study applies the Technology Acceptance Model (TAM) to explore students’ perceptions of ChatGPT’s usability across different academic disciplines. Using a stratified sample of university students, this research investigates variations in acceptance and identifies factors influencing usability perceptions. The findings reveal significant disciplinary differences, with students in computer-related fields showing the highest acceptance of ChatGPT. These insights underscore the importance of considering disciplinary contexts when integrating AI into educational frameworks. This paper demonstrates the utility of TAM in understanding AI adoption in higher education and provides actionable recommendations for leveraging AI tools like ChatGPT to enhance learning outcomes.},
  keywords={Technology acceptance model;Target tracking;Employment;Educational technology;Chatbots;Decoding;Artificial intelligence;Usability;Analysis of variance;Context modeling;Artificial Intelligence in Education;ChatGPT Usability;Technology Acceptance Model},
  doi={10.1109/ICET62460.2024.10868886},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10578718,
  author={de Kereki, Inés Friss and Garrido, Ismael},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Solving Computer Science 2 Tasks: Students’ Reflections on the Use of ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Computer Science II is a subject in the 2nd semester of the Bachelor's and Systems Engineering, Electrical, Electronics, and Telecommunications courses. As part of the evaluation, four tasks are included in the course to be performed individually by each student. From the beginning of the course, the use of Artificial Intelligence tools was introduced in different class activities, particularly ChatGPT. In this work, the activities are described and the solutions to the tasks presented by the students are evaluated. The surveys conducted with the students regarding their experience with these tools are examined.},
  keywords={Surveys;Chatbots;Reflection;Telecommunications;Problem-solving;Task analysis;Artificial intelligence;Computer Science 2;Programming;Artificial Intelligence;ChatGPT},
  doi={10.1109/EDUCON60312.2024.10578718},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{11023945,
  author={Doan, Long and Nguyen, ThanhVu},
  booktitle={2025 IEEE/ACM 47th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)}, 
  title={AI-Assisted Autoformalization of Combinatorics Problems in Proof Assistants}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Proof assistants such as Coq and LEAN have been increasingly used by renowned mathematicians to formalize and prove mathematical theorems. Despite their growing use, writing formal proofs is challenging, and even the first step of stating the problem formally is difficult as it requires a deep understanding of these systems’ languages. Recent advancements in AI, especially large language models (LLMs), have shown promise in automating this formalization task. However, domains such as combinatorics pose significant challenges for AI-assisted proof assistant systems due to their cryptic nature and the lack of existing data to train AI models. We introduce AutoForm4Lean, a system designed to leverage LLMs to aid in formalizing combinatorics problems for LEAN. By combining LLMs with techniques from software engineering and formal methods such as validation and synthesis, AutoForm4Lean generates formalizations of combinatorics problems more effectively than the current state-of-the-art LLMs. Moreover, this project seeks to provide a comprehensive collection of formalized combinatorics problems, theorems, and lemmas, which would enrich the LEAN library and provide valuable training data for LLMs. Preliminary results demonstrate the effectiveness of AutoForm4Lean in formalizing combinatorics problems in LEAN, making a step forward in AI-based theorem proving.},
  keywords={Large language models;Training data;Writing;Libraries;Data models;Software engineering;Proof assistants;Autoformalization;Combina-torics;AI;LLM;Lean},
  doi={10.1109/ICSE-NIER66352.2025.00006},
  ISSN={2832-7632},
  month={April},}@INPROCEEDINGS{10665172,
  author={Kaleemunnisa, FNU and Scharff, Christelle and Bathula, Krishna and Zhumakova, Begimai},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={ChatGPT in the Classroom: Experimentation in a Python Class for Non-Computing Majors}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={AI-based chatbots such as ChatGPT present themselves as technologies to assist students in their learning. This study explores the use of ChatGPT in solving Python programming assignments in an introduction to computing class taken by students who are new to programming and non-computing majors. It uses a mixed research approach and involves experimental and control groups. The experimental group used ChatGPT, while the control group did not. The learning satisfaction and overall attitude of students toward ChatGPT, as well as gained Python skills, were analyzed and evaluated through surveys, Google Colab notebook assignments, and ChatGPT transcripts, as data collection instruments. While the study is limited in scope, it shows promising results as students considered the tool as an enabler to solve different programming problems. The study could not conclude that ChatGPT motivates students in learning Python. The evaluation of transcripts show that students need to be trained on how to use ChatGPT, from using critical thinking to writing prompts. In parallel, instructors have to change the way they create, reuse and present assignments to challenge students.},
  keywords={Surveys;Instruments;Writing;Data collection;Chatbots;Internet;Programming profession;ChatGPT;Introduction to Computing;Non-computing Majors;Python},
  doi={10.1109/ISEC61299.2024.10665172},
  ISSN={2473-7623},
  month={March},}@ARTICLE{10646468,
  author={Yu, Le and Wang, Lina and Cai, Jijing and Yang, Zijia and Wen, Long and Bashir, Ali Kashif and Wang, Wei},
  journal={IEEE Consumer Electronics Magazine}, 
  title={Consumer Electronics and GenAI Providing User Experiences in Mental Health}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={As consumer electronics become more ubiquitous and Generative Artificial Intelligence (GenAI) technologies advance rapidly, processing and analyzing semantic information collected from users to enhance their experiences becomes especially important. Traditionally, monitoring students' educational and psychological health has relied primarily on teachers, a method that is both inefficient and inadequate for comprehensively grasping students' needs. Therefore, the application of artificial intelligence is particularly critical. GenAI has the capability to gather semantic information from consumer electronics commonly used by students, such as smartphones, wearable devices, and tablets, and perform in-depth analysis. By analyzing curriculum schedules, GenAI can personalize learning paths and predict students' psychological states through examining individual mental health and media usage data. This paper explores how GenAI processes this information to intervene in students' education and psychological health, and discusses the analysis of adolescent mental health test data collected in recent years as well. Evidence suggests that students enrolled in high schools suffer from the highest rates of depression and major depressive disorder compared to other stages, at 40% and 12.5% respectively, underscoring the importance of using GenAI for educational and psychological health monitoring. The article summarizes the relevant technologies and models, highlighting the potential of GenAI in enhancing student well-being and academic performance.},
  keywords={Consumer electronics;Mental health;Education;Semantics;Psychology;Monitoring;Smart phones},
  doi={10.1109/MCE.2024.3449558},
  ISSN={2162-2256},
  month={},}@ARTICLE{10912437,
  author={Yang, Meiqi and Diao, Mingguang and Luo, Jiahuan and Shen, Weiqi and Zhang, Chuyan},
  journal={IEEE Access}, 
  title={GLM-4 Based Method for Automatic Construction of Content Graph}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Content graphs are essential for representing domain knowledge and play a significant role in digital education. To overcome the challenges associated with manual knowledge extraction and content structuring, including low efficiency, high costs, and a high risk of errors, and to improve teaching and learning quality, this paper presents an automated approach for constructing course content graphs for digital teaching platforms by utilizing a large language model. Specifically, the pre-trained GLM-4 model is utilized for semantic parsing and entity extraction, while a group query attention mechanism is applied to infer relationships between knowledge points, automatically transforming raw course content into structured tabular datasets. The process involves two steps: entity extraction and relationship recognition, which convert the original dataset into discrete knowledge points and output them in a structured format. The structured data is then visualized using the Neo4j graph database, enabling automated content graph construction. Experimental results show that this method significantly enhances the accuracy and efficiency of content graph construction, achieving an F1 score above 0.85 for entity extraction and relationship recognition accuracies of 0.82 and 0.80 before and after processing, respectively. Leveraging the model’s strong performance, a content graph with 393,600 triples—consisting of 9 entity types and 2 relationship types—has been constructed, covering the domain of software engineering courses. These results offer an effective and scalable solution to advance the intelligent development of digital teaching platforms.},
  keywords={Semantics;Education;Accuracy;Feature extraction;Computational modeling;Analytical models;Vectors;Software;Tokenization;Context modeling;Course content graph;Large language models;Tabular datasets;Grouped query attention;Entity extraction;Digital teaching platforms},
  doi={10.1109/ACCESS.2025.3548590},
  ISSN={2169-3536},
  month={},}
@INPROCEEDINGS{10554730,
  author={Tao, Yida and Chen, Wenyan and Ye, Qingyang and Zhao, Yao},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={Beyond Functional Correctness: An Exploratory Study on the Time Efficiency of Programming Assignments}, 
  year={2024},
  volume={},
  number={},
  pages={320-330},
  abstract={Practical programming assignments are critical parts of programming courses in Computer Science education. Students are expected to translate programming concepts learned from lectures into executable implementations that solve the tasks outlined in the assignments. These implementations are primarily assessed based on their functional correctness, ensuring that students' code produces the expected output when provided with specific inputs. However, functional correctness is not the only metric that evaluates the quality of programs. Runtime efficiency is a metric that is less frequently evaluated in programming courses, yet it holds significant importance in the context of professional software development. To investigate this gap and its potential ramifications, we conducted a large-scale empirical study on the time efficiency of 250 programming assignments that are evaluated solely on functional correctness. The results demonstrate that students' programming assignments exhibit significant variance in terms of execution time. We further identified 27 recurring inefficient code patterns from these assignments, and observed that most of the inefficient patterns can be optimized by automated tools such as PMD, IntelliJ IDEA and ChatGPT. Our findings provide actionable guidelines for educators to enhance the organization and integration of code performance topics throughout the programming course curriculum.},
  keywords={Measurement;Training;Codes;Runtime;Organizations;Chatbots;Task analysis;Programming Assignment;Code Performance;Tool Support},
  doi={10.1145/3639474.3640065},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{10819129,
  author={Čikić, Đorđe and Đorđević, Nikola and Janković, Dragan},
  booktitle={2024 32nd Telecommunications Forum (TELFOR)}, 
  title={Comparison of Ensemble Methods for Sentiment Analysis in Serbian Language}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Sentiment analysis plays a significant role in natural language processing (NLP). This paper compares different ensemble methods for Sentiment analysis in Serbian language, as a low-resource language. No previous studies have experimented with ensemble methods in Serbian language and therefore this is a novel study. Dataset used in our experiment consists of movie reviews in Serbian language. Our experiment shows that ensemble of Large Language Models (LLMs) like BERT, RoBERTa, GPT-2, DistilBERT, that represent Transformers-based architecture and traditional models can boost the accuracy of the system in comparison with the base learners mentioned.},
  keywords={Training;Sentiment analysis;Analytical models;Accuracy;Reviews;Large language models;Transformers;Probability distribution;Telecommunications;Ensemble learning;sentiment analysis;ensemble methods;natural language processing;large language models},
  doi={10.1109/TELFOR63250.2024.10819129},
  ISSN={2994-5828},
  month={Nov},}@INPROCEEDINGS{10402376,
  author={Zagirniak, Denys and Shalimova, Nataliia and Akmaldinova, Oleksandra and Stezhko, Yuri and Perevozniuk, Viktoriia},
  booktitle={2023 IEEE 5th International Conference on Modern Electrical and Energy System (MEES)}, 
  title={Transformation of Education in the Context of Modern Informational and Cultural Realities of Artificial Intelligence ChatGPT Application}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The article is intended to provide an idea of the role of artificial intelligence in education in the postmodern situation. The emergence of ChatGPT with artificial intelligence has caused concern in society about possible threats and negative consequences, in particular, for education. Publications abound with warnings that artificial intelligence is capable of surpassing human intelligence. Therefore, the article substantiates the inability of ChatGPT to generate innovative ideas of the level of social intelligence. The generation of ideas by artificial intelligence burdened by formal logic does not accommodate innovation. The provision on the priority of authentic intelligence over its artificial prototype is substantiated. The role of integrity, responsibility and other personal qualities of the acquirer of knowledge in the application of the capabilities of artificial intelligence is revealed. The result of penetration of artificial intelligence into the area of postmodern cultural transformations is the humanitarianization of education in general and engineering in particular, overcoming its alienation from the value demands of society. The representation of reality in professional creativity is the parity of rational and irrational forms of knowledge. Professional competence involves systematic knowledge based on the integration of natural, mathematical, technical and social sciences, rethinking the very philosophy of education. The conducted experiment proved that in modern projecting as a mutual condition of divergent and convergent thinking, the advantage in the selection of ideas for innovation belongs to artificial intelligence. It is noted that with proper organization, the involvement of ChatGPT will lead to the intensification of the educational process, will become a personalized assistant for the student, a means of his release from routine work. It is mentioned that the expressed moderate optimism regarding the prospects of education in the realities of artificial intelligence conditions is based on the philosophical understanding of the priority of social creativity over its machine organization.},
  keywords={Training;Technological innovation;Education;Process control;Organizations;Chatbots;Artificial intelligence;education;artificial intelligence;creativity;innovativeness;postmodern culture;humanitarianization of education},
  doi={10.1109/MEES61502.2023.10402376},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10469498,
  author={Lee, Kuan-Yin and Hong, Cai-Lian},
  booktitle={2023 IEEE 3rd International Conference on Social Sciences and Intelligence Management (SSIM)}, 
  title={Usage Intentions of AIGC: From Social Media Conversation Volume and Consumer Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={328-333},
  abstract={In November 2022, OpenAI launched the ChatGPT chatbot, and within just two months, it had garnered one hundred million registrations. The introduction of ChatGPT has generated significant attention and discussions online. Its applications are incredibly diverse, impacting the development of numerous industries. It has improved work efficiency in the business sector, enhanced customer service, expanded market analysis, assisted in daily tasks, and provided personalized recommendations. In education, it has aided students in personalized learning, answering questions, and providing explanations. With the advancement of technology, Internet usage and social media have been used widely the current generation, particularly the Z generation. Social media has become a habitual practice, changing people's social habits. Social media provides a platform for communication, sharing images and videos, as well as interacting, commenting, and sharing other people's content. Utilizing the CHOOSE public option analysis platform developed by Blue Planet, we explores articles discussing ChatGPT on social media and analyzes the sources of conversation volume using the public option analysis to understand the level of interest and favorability of social media users regarding ChatGPT.},
  keywords={Social networking (online);Planets;Education;Social sciences;Oral communication;Media;Chatbots;AI technology;social media conversation volume;favorability},
  doi={10.1109/SSIM59263.2023.10469498},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10773596,
  author={Gerede, Çağdaş Evren},
  booktitle={2024 9th International Conference on Computer Science and Engineering (UBMK)}, 
  title={Are We Asking the Right Questions to ChatGPT for Learning Software Design Patterns?}, 
  year={2024},
  volume={},
  number={},
  pages={1092-1097},
  abstract={The emergence of AI-powered chatbots like ChatGPT has generated excitement in many fields, including education. Some see this technology as a tool with a transformative impact similar to that of the printing press or the Internet. In this paper, we evaluate how effectively undergraduate computer engineering students can use this technology and the challenges they encounter in their interactions with ChatGPT. To this end, we examined whether students could ask effective questions to ChatGPT while learning software design patterns with its assistance. Based on our findings, we provide curriculum recommendations to improve the integration of ChatGPT into undergraduate computer engineering education.},
  keywords={Computer science;Software design;Education;Chatbots;Internet;Computer science education;Engineering students;Printing machinery;ChatGPT;AI in higher education;computer engineering education;software design patterns;self-learning;effective questioning},
  doi={10.1109/UBMK63289.2024.10773596},
  ISSN={2521-1641},
  month={Oct},}@INPROCEEDINGS{10270477,
  author={Abdelfattah, Aly Maher and Ali, Nabila Ahmed and Elaziz, Mohamed Abd and Ammar, Hany H},
  booktitle={2023 International Conference on Artificial Intelligence Science and Applications in Industry and Society (CAISAIS)}, 
  title={Roadmap for Software Engineering Education using ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents a novel method for teaching software engineering using the AI tool, ChatGPT, to create an engaging and immersive learning platform. The technique emphasizes understanding requirements engineering principles via interactive exercises and hands-on examples. The approach involves ChatGPT assisting in collecting user stories, creating a use case and class diagrams, and formulating sequence diagrams. This method employs an agile strategy focusing on select user stories and encourages student interaction with ChatGPT for a deeper understanding of the subject. The goal is to demonstrate the potential of AI tools to transform software engineering education by providing practical applications and real-life scenarios. The research outlines a comprehensive plan for integrating ChatGPT into a software engineering syllabus, focusing on requirements engineering. The findings could significantly influence the teaching and understanding of software engineering principles, benefiting educators and students.},
  keywords={Learning systems;Industries;Education;Focusing;Virtual reality;Transforms;Learning (artificial intelligence);Software engineering education;Interactive learning environment;ChatGPT;Requirements engineering;Agile process;AI in education},
  doi={10.1109/CAISAIS59399.2023.10270477},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10420194,
  author={Padilla, Jay Rhald C. and Montefalcon, Myron Darrel L. and Hernandez, Alexander A.},
  booktitle={2023 IEEE 11th Conference on Systems, Process & Control (ICSPC)}, 
  title={Language AI in Programming: A Case Study of ChatGPT in Higher Eduation Using Natural Language Processing}, 
  year={2023},
  volume={},
  number={},
  pages={276-281},
  abstract={ChatGPT is an emerging technology used in education. It provides promising support to enhance teaching and learning activities. However, there is lacking understanding of its use to programming courses in computing programs. This study investigates the benefits, issues, and challenges of using ChatGPT, a language AI model, in programming tasks. Data was collected through surveys administered to undergraduate students in computing programs across various National Capital Region (NCR) universities. The collected data was analyzed using Natural Language Processing (NLP) and Latent Dirichlet Allocation (LDA) techniques to gain insights from the students responses. A word intrusion test assessed theme coherence, and evaluators demonstrated moderate agreement (Fleiss Kappa score: 0.62). The study reveals the benefits of employing ChatGPT for programming, including efficient coding, understanding complex codes, and its capability to be used as a problem-solving tool. However, it highlights critical issues and challenges, such as data privacy and ethical concerns, plagiarism tendencies, and contextual understanding limitations. The findings contribute valuable insights for developers, educators, and researchers interested in leveraging language AI models like ChatGPT to enhance programming workflows while effectively addressing associated challenges.},
  keywords={Education;Chatbots;Resource management;Problem-solving;Artificial intelligence;Task analysis;Programming profession;chatGPT;natural language processing;latent dirichlet allocation;artificial intelligence;programming;artificial intelligence in education},
  doi={10.1109/ICSPC59664.2023.10420194},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10297824,
  author={Butgereit, Laurie and Martinus, Herman and Abugosseisa, Muna Mahmoud},
  booktitle={2023 IEEE 27th International Conference on Intelligent Engineering Systems (INES)}, 
  title={Prof Pi: Tutoring Mathematics in Arabic Language using GPT-4 and Whatsapp}, 
  year={2023},
  volume={},
  number={},
  pages={000161-000164},
  abstract={Prof Pi is a mathematics tutoring system which is available using the Whatsapp chat facility, the Telegram chat facility, and the web. It is driven by GPT-4 (the underlying API behind chatGPT). Prof Pi allows participants to ask questions about specific mathematics problems. Prof Pi is specifically designed to NOT simply answer the mathematics questions but to, rather, guide the participants into solving their problems on their own. Although originally conceived to be an English language mathematics tutor, this paper describes a project of using the Prof Pi service in Khartoum, Sudan, to help university students with their mathematics problems using the Arabic language.},
  keywords={Freeware;Chatbots;Mathematics;Internet telephony;Prof Pi;math tutoring;GPT-4;Whatsapp},
  doi={10.1109/INES59282.2023.10297824},
  ISSN={1543-9259},
  month={July},}@INPROCEEDINGS{10795104,
  author={Kruse, Hans-Alexander and Puhlfürϐ, Tim and Maalej, Walid},
  booktitle={2024 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Can Developers Prompt? A Controlled Experiment for Code Documentation Generation}, 
  year={2024},
  volume={},
  number={},
  pages={574-586},
  abstract={Large language models (LLMs) bear great potential for automating tedious development tasks such as creating and maintaining code documentation. However, it is unclear to what extent developers can effectively prompt LLMs to create concise and useful documentation. We report on a controlled experiment with 20 professionals and 30 computer science students tasked with code documentation generation for two Python functions. The experimental group freely entered ad-hoc prompts in a Chat- GPT-like extension of Visual Studio Code, while the control group executed a predefined few-shot prompt. Our results reveal that professionals and students were unaware of or unable to apply prompt engineering techniques. Especially students perceived the documentation produced from ad-hoc prompts as significantly less readable, less concise, and less helpful than documentation from prepared prompts. Some professionals produced higher quality documentation by just including the keyword Docstring in their ad-hoc prompts. While students desired more support in formulating prompts, professionals appreciated the flexibility of ad-hoc prompting. Participants in both groups rarely assessed the output as perfect. Instead, they understood the tools as support to iteratively refine the documentation. Further research is needed to understand which prompting skills and preferences developers have and which support they need for certain tasks.},
  keywords={Computer science;Visualization;Software maintenance;Codes;Large language models;Documentation;Prompt engineering;Iterative methods;Python;Software Documentation;Large Language Model;Program Comprehension;Developer Study;AI4SE},
  doi={10.1109/ICSME58944.2024.00058},
  ISSN={2576-3148},
  month={Oct},}@INPROCEEDINGS{11016480,
  author={Strachan, Rebecca and Anderson, Emma and Oguna, Cynthia and Oruche, Ugochukwu},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={An Exploratory Study of Senior Computing UK Academic Faculty Perspectives on Academic Integrity and Student Cheating}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The expansion of essay mills and the recent emerging opportunities presented by generative Artificial Intelligence tools have led to fresh concerns about the authenticity of students' assessed work. These changes mean it is timely to revisit academic integrity within the UK Higher Education computing community. The aim of this research is to explore the current perspectives of senior computing academics on academic integrity and student cheating, particularly given the rapid development of generative AI tools and resources and the growth in essay mills. An exploratory research approach was adopted using a mixed methods approach. A critical literature review was undertaken and this together with the researcher team's expertise was used to underpin the design of the practical research activities. A survey was conducted of UK higher education senior academics (response rate, $\mathrm{n}=16$). The results from this informed a set of in-depth individual semistructured interviews with senior UK computing academics $(\mathrm{n}=5)$. Descriptive statistics were used to analyse the quantitative survey data and exploratory thematic analysis undertaken with the qualitative data from the survey and interviews. Methodological triangulation was used across these data sets to inform the key findings and their interpretation and discussion. The findings demonstrate that senior computing academics are concerned about the levels and types of student cheating on their assessed work. The reasons for this are complex and multifaceted, with no simple solution. Academic misconduct is perceived to adversely affect academic standards. Challenges with the detection and investigation of student cheating and the need to ensure consistency of approach by all staff are highlighted. Action is needed urgently and respondents emphasize that this should focus on prevention rather than detection of academic misconduct. These findings have informed a set of recommendations to promote good academic practice and integrity across the UK Higher Education computing community. The findings also highlight that in order to implement these recommendations, staff, students and their departments/institutions need to come together and draw on each others' expertise and experiences to enable a high-quality ethical learning experience.},
  keywords={Surveys;Ethics;Generative AI;Prevention and mitigation;Interviews;Engineering education;Standards;Systematic literature review;academic integrity;academic misconduct;student cheating;essay mills;generative AI;authenticity},
  doi={10.1109/EDUCON62633.2025.11016480},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10314331,
  author={Yu, Dan and Ai, Jun and Su, Haorao and Zhang, Hong},
  booktitle={2023 10th International Conference on Dependable Systems and Their Applications (DSA)}, 
  title={Assessing ChatGPT’s Comprehension of Perturbed Text through Text Linguistic Features}, 
  year={2023},
  volume={},
  number={},
  pages={839-850},
  abstract={This paper presents an evaluation method for assessing ChatGPT’s ability to understand perturbed text, offering a novel approach to evaluating the robustness of large language models from a text understanding perspective. The proposed method analyzes ChatGPT’s comprehension of perturbed text across three dimensions: static sensitivity, dynamic sensitivity, and comprehensive ability. This is achieved through the utilization of traditional metrics and a difference norm based on textual linguistic features. The integration of linguistic features into the assessment of text perturbation degree provides a fast, efficient, and accurate evaluation method that can be easily applied to other large language models. Analysing of results identifies perturbations with high static and dynamic sensitivity for ChatGPT, and assesses its comprehensive comprehension both qualitatively and quantitatively.},
  keywords={Deep learning;Sensitivity;Perturbation methods;Refining;Linguistics;Chatbots;Robustness;ChatGPT;Perturbation;Robustness;Linguistic feature;Large Language Model},
  doi={10.1109/DSA59317.2023.00119},
  ISSN={2767-6684},
  month={Aug},}@ARTICLE{10379820,
  author={Li, Bai and Xu, Tian'ao and Li, Xinyuan and Cui, Yaodong and Bian, Xuepeng and Teng, Siyu and Ma, Siji and Fan, Lili and Tian, Yonglin and Wang, Fei-Yue},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={Integrating Large Language Models and Metaverse in Autonomous Racing: An Education-Oriented Perspective}, 
  year={2024},
  volume={9},
  number={1},
  pages={59-64},
  abstract={This letter is the third report from a series of IEEE TIV's decentralized and hybrid workshops (DHWs) on intelligent vehicles for education (IV4E). Autonomous racing serves as a vital platform for nurturing engineering talents among university students, contributing to the development of skills essential for the intelligent vehicle industry. This letter investigates how recent emerging techniques, such as large language models (LLMs) and the Metaverse, can contribute to organizing IV4E-oriented autonomous racing events. Among these DHWs, scholars from diverse fields have collectively explored the integration of LLMs and the Metaverse into autonomous racing for educational purposes. The discussions emphasize the role of Metaverse in creating dynamic and immersive training virtual reality platforms and the role of LLMs in enhancing race commentary and the spectator experience. Within this context, the Metaverse introduces complex scenarios to the racetrack, maintaining suspense about the winning team until a race's final moment. This dynamic feature excites the race and motivates the participating teams to intensify their competition efforts. LLMs facilitate personalized commentary, inspiring spectators to become future participants in these races. Our DHWs highlighted a future in which technology, autonomy, and education intersect, fostering inclusive, educational, and engaging autonomous racing events.},
  keywords={},
  doi={10.1109/TIV.2024.3349466},
  ISSN={2379-8904},
  month={Jan},}@INPROCEEDINGS{11016517,
  author={Park, Seong Min and Ho, Marco and Lin, Michael Pin-Chuan and Ryoo, Jeeho},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Evaluating the Impact of Assistive AI Tools on Learning Outcomes and Ethical Considerations in Programming Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This study critically evaluates the efficacy of GitHub Copilot in low-level programming education, specifically within C programming tasks involving complex concepts like memory management and pointer manipulation. While AI tools have shown promise in supporting high-level programming, its impact on skill-intensive, low-level contexts remains underexplored. We conducted a within-subject experimental study with 34 graduate computer science students, assessing performance on AI -assisted and independent tasks. Statistical analyses revealed that Copilot, one of the AI programming tools, enhances productivity in routine coding activities; however, it is insufficient for tasks requiring deep problem-solving skills. Notably, a significant performance decline in AI-free tasks suggests a dependency on Copilot that may hinder the development of essential independent problem-solving abilities. Survey feedback underscores ethical concerns, with 40.6 % of students expressing uncertainty about responsible AI usage and potential over-reliance. These findings highlight the ne-cessity for structured instructional practices, including AI-free assessments and clear ethical guidelines, to promote balanced technology integration in programming education. This study contributes to educational theory by illuminating the limitations of generative AI within constructivist and self-regulated learning frameworks. Future research should explore the long-term effects of AI dependency on technical skill development and investigate AI advancements tailored for low-level programming to better support foundational skills.},
  keywords={Productivity;Ethics;Memory management;Debugging;Encoding;Problem-solving;Artificial intelligence;Programming profession;Software development management;Guidelines;GitHub Copilot;C Programming;Dependency in Learning;Constructivist Learning;Self-Regulated Learning;Educational Technology Ethics;AI-Assisted Learning;Program-ming Education;Academic Integrity in AI},
  doi={10.1109/EDUCON62633.2025.11016517},
  ISSN={2165-9567},
  month={April},}@ARTICLE{10819409,
  author={Liu, Qiming and Yang, Ruirong and Gao, Qin and Liang, Tengxiao and Wang, Xiuyuan and Li, Shiju and Lei, Bingyin and Gao, Kaiye},
  journal={IEEE Access}, 
  title={A Review of Applying Large Language Models in Healthcare}, 
  year={2025},
  volume={13},
  number={},
  pages={6878-6892},
  abstract={In response to the growing demand for healthcare and the increasing importance people place on medical services, efficiently meeting these needs within the constraints of limited healthcare resources is of great social and economic benefit. Therefore, research into applying Large Language Models (LLMs) in the healthcare sector holds significant importance. This paper provides a review of the research progress on the application of LLMs in the healthcare field. First, the basic framework of LLMs is summarized, and the training process of LLMs in healthcare is systematically reviewed. Next, six specific application areas of LLMs in healthcare are reviewed: disease diagnosis and decision support, dissemination of medical knowledge, medical assistance, medical image analysis, biomedicine, and medical education. Then, several representative healthcare-specific LLMs are discussed, along with their performance analysis. Following this, the challenges faced by LLMs in healthcare are summarized, and relevant suggestions are provided. The future development trends of LLMs in healthcare are also explored. Finally, a bibliometric analysis is performed. Through the literature review, we found: 1) After pretraining, LLMs are widely adaptable to downstream tasks, significantly enhancing processing performance and efficiency; 2) LLMs in healthcare possess multiple capabilities and can handle multimodal data; 3) Bibliometric analysis shows that researchers are paying increasing attention to the application of LLMs in healthcare; 4) Further research is needed in optimizing, improving reliability, and expanding practical applications of large healthcare models.},
  keywords={Medical services;Large language models;Training;Transformers;Medical diagnostic imaging;Biological system modeling;Bibliometrics;Analytical models;Mathematical models;Market research;Healthcare;large language models;literature bibliometric;medical},
  doi={10.1109/ACCESS.2024.3524588},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10172763,
  author={Kang, Sungmin and Yoon, Juyeon and Yoo, Shin},
  booktitle={2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)}, 
  title={Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction}, 
  year={2023},
  volume={},
  number={},
  pages={2312-2323},
  abstract={Many automated test generation techniques have been developed to aid developers with writing tests. To facilitate full automation, most existing techniques aim to either increase coverage, or generate exploratory inputs. However, existing test generation techniques largely fall short of achieving more semantic objectives, such as generating tests to reproduce a given bug report. Reproducing bugs is nonetheless important, as our empirical study shows that the number of tests added in open source repositories due to issues was about 28% of the corresponding project test suite size. Meanwhile, due to the difficulties of transforming the expected program semantics in bug reports into test oracles, existing failure reproduction techniques tend to deal exclusively with program crashes, a small subset of all bug reports. To automate test generation from general bug reports, we propose Libro, a framework that uses Large Language Models (LLMs), which have been shown to be capable of performing code-related tasks. Since LLMs themselves cannot execute the target buggy code, we focus on post-processing steps that help us discern when LLMs are effective, and rank the produced tests according to their validity. Our evaluation of Libro shows that, on the widely studied Defects4J benchmark, Libro can generate failure reproducing test cases for 33% of all studied cases (251 out of 750), while suggesting a bug reproducing test in first place for 149 bugs. To mitigate data contamination (i.e., the possibility of the LLM simply remembering the test code either partially or in whole), we also evaluate Libro against 31 bug reports submitted after the collection of the LLM training data terminated: Libro produces bug reproducing tests for 32% of the studied bug reports. Overall, our results show Libro has the potential to significantly enhance developer efficiency by automatically generating tests from bug reports.},
  keywords={Codes;Computer bugs;Semantics;Training data;Benchmark testing;Writing;Test pattern generators;test generation;natural language processing;software engineering},
  doi={10.1109/ICSE48619.2023.00194},
  ISSN={1558-1225},
  month={May},}@INPROCEEDINGS{10857545,
  author={Yadagiri, Annepaka and Pakray, Partha},
  booktitle={2025 19th International Conference on Ubiquitous Information Management and Communication (IMCOM)}, 
  title={Deep Learning Strategies for Identifying Machine-Generated Text}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Generative AIs like LLMs are now accessible to the general public. For example, students can utilize these tools to create essays or complete theses. However, how is a teacher supposed to determine if a text was composed by the student or an AI? Using deep learning techniques, we investigate novel and classic approaches for detecting text created by artificial intelligence. We also study the more complex instance when the AI is asked to write the text in a way that a human would not recognize as AI-generated, as we discovered that categorization is more challenging in this scenario. For our studies, we used llm-detect-ai-generated text from the Kaggle competition dataset, which included texts written by students and texts produced using different LLMs. Our top systems achieve an accuracy of 0.98% and F1 scores of more than 0.98% in classifying simple and complex texts produced by humans and AI-Genereted. The systems combine features such as TF-IDF vectorization, word2Vec, and word embedding properties. Our findings demonstrate that these additional characteristics significantly enhance the performance of several classifiers. Compared to deep learning models, our best-performing model for detecting AI-generated text outperforms even the fine-tuned ROBERTA-Open-AI classifier, achieving an accuracy of 0.98%. This underscores the efficacy of our proposed approach in distinguishing between human and AI-generated content.},
  keywords={Deep learning;Training;Adaptation models;Accuracy;Text recognition;Text categorization;Text detection;Detectors;Transformers;Information management;Large Language Models;Natural Language Processing;Neural Networks;Generative AI},
  doi={10.1109/IMCOM64595.2025.10857545},
  ISSN={},
  month={Jan},}@ARTICLE{10183726,
  author={Amaro, Ilaria and Barra, Paola and Greca, Attilio Della and Francese, Rita and Tucci, Cesare},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Believe in Artificial Intelligence? A User Study on the ChatGPT’s Fake Information Impact}, 
  year={2024},
  volume={11},
  number={4},
  pages={5168-5177},
  abstract={Technological evolution has enabled the development of new artificial intelligence (AI) models with generative capabilities. Among them, one of the most discussed is the virtual agent ChatGPT. This chatbot may occasionally produce fake information, as also declared by the producer OpenAI. Such a model may provide very useful support in several tasks, ranging from text summarization to programming. The research community has marginally investigated the impact that fake information created by AI models has on the users’ perceptions and on their belief in AI. We analyzed the impact of the fake information produced by AI on user perceptions, specifically trust and satisfaction, by performing a user study on ChatGPT. An additional issue is assessing whether the early or late knowledge of the possibility of the tool generating fake information has a different impact on the users’ perceptions. We conducted an experiment, involving 62 university students, a category of users who may employ tools such as ChatGPT extensively. The experiment consisted of a guided interaction with ChatGPT. Some of the participants experienced the failure of the chatbot, while a control group only received correct and reliable answers. We collected participants’ perceptions of trust, satisfaction, and usability, together with the net promoter score (NPS). The results demonstrated a statistically significant difference in trust and satisfaction between the users who early experienced fake information production compared to those who discovered ChatGPT’s faulty behaviors later during the interaction. Also, there is no statistically significant difference among the users who received the late fake information and the control group (no fake information). Usability and the NPS also resulted higher when the fake news was detected in the late interaction. When users are aware of the fake information generated by ChatGPT their trust and satisfaction decrease, especially when they impact on this at the early stage of use of the chatbot. Nevertheless, the perception of trust and satisfaction still remains high, as some of the users are still enthusiastic; others consider a more conscious use of the tool in terms of support to be verified. A useful strategy could be to favor a critical use of ChatGPT, letting young people to verify the provided information. This should be a new way to perform learning activities.},
  keywords={Chatbots;Artificial intelligence;Reliability;Usability;Ethics;Trajectory;Fake news;Trust management;Believe artificial intelligence (AI);ChatGPT;controlled experiment;fake information;trust in AI},
  doi={10.1109/TCSS.2023.3291539},
  ISSN={2329-924X},
  month={Aug},}@INPROCEEDINGS{10554713,
  author={Fwa, Hua Leong},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={Experience Report: Identifying Common Misconceptions and Errors of Novice Programmers with ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={233-241},
  abstract={Identifying the misconceptions of novice programmers is pertinent for informing instructors of the challenges faced by their students in learning computer programming. In the current literature, custom tools, test scripts were developed and, in most cases, manual effort to go through the individual codes were required to identify and categorize the errors latent within the students' code submissions. This entails investment of substantial effort and time from the instructors. In this study, we thus propose the use of ChatGPT in identifying and categorizing the errors. Using prompts that were seeded only with the student's code and the model code solution for questions from two lab tests, we were able to leverage on ChatGPT's natural language processing and knowledge representation capabilities to automatically collate frequencies of occurrence of the errors by error types. We then clustered the generated error descriptions for further insights into the misconceptions of the students. The results showed that although ChatGPT was not able to identify the errors perfectly, the achieved accuracy of 93.3% is sufficiently high for instructors to have an aggregated picture of the common errors of their students. To conclude, we have proposed a method for instructors to automatically collate the errors latent within the students' code submissions using ChatGPT. Notably, with the novel use of generated error descriptions, the instructors were able to have a more granular view of the misconceptions of their students, without the onerous effort of manually going through the students' codes.},
  keywords={Training;Adaptation models;Codes;Manuals;Knowledge representation;Syntactics;Chatbots;LLM;ChatGPT;misconception;programming;errors;cluster;prompts},
  doi={10.1145/3639474.3640059},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{10893083,
  author={Azemi, Asad},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Navigating the Dual Edges of AI in Engineering Education: Opportunities, Challenges, and Societal Readiness}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This research full paper describes how integrating Artificial Intelligence (AI) in engineering education represents a transformative shift with profound implications. In this work, we outline the multifaceted impact of AI, emphasizing its benefits and potential misuse within the classroom, and extend to consider its broader societal implications. AI's introduction in engineering education signals a new era of personalized learning environments. Its capacity for analyzing vast data sets enables tailored educational experiences, addressing individual student needs with unprecedented precision. AI-driven tools can identify learning gaps and provide customized resources, optimizing the learning process. These advancements are not without pitfalls. A notable concern is the misuse of AI by students, such as leveraging AI to complete assignments unethically, which undermines learning objectives and academic integrity. Beyond the classroom, AI's influence on society, particularly in the labor market, is a double-edged sword. AI poses a threat to traditional job markets. Automation risks displacing a significant portion of the workforce, particularly in sectors reliant on routine tasks. We have emphasized the importance of a balanced approach, advocating for the responsible integration of AI in educational settings with human oversight to prevent unethical use, potential job displacement, and other societal impacts. We have also advocated for studying and designing new pedagogical approaches and courses that would integrate AI-based applications such as ChatGPT to enhance problem-solving and critical thinking among students.},
  keywords={Automation;Navigation;Chatbots;Problem-solving;Artificial intelligence;Engineering education;Artificial Intelligence;Large Language Model;ChatGPT;Learning Methodologies},
  doi={10.1109/FIE61694.2024.10893083},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10510580,
  author={Maita, Idria and Saide, Saide and Putri, Afifah Mesha and Muwardi, Didi},
  journal={IEEE Engineering Management Review}, 
  title={Pros and Cons of Artificial Intelligence–ChatGPT Adoption in Education Settings: A Literature Review and Future Research Agendas}, 
  year={2024},
  volume={52},
  number={3},
  pages={27-42},
  abstract={The integration of artificial intelligence, particularly ChatGPT, in education presents both promising opportunities and notable challenges. Through a systematic review employing the PRISMA method, this article analyzed 45 references published of ChatGPTs impact on educational environments. While ChatGPT offers teachers a versatile learning tool, aiding in tasks, such as lesson planning and content generation, concerns regarding academic integrity and over-reliance on technology have emerged. Ethical considerations, including the potential for cheating in assignments and exams, highlight the need for clear guidelines and ethical frameworks to govern its use. Institutions or related organizations must address issues, such as plagiarism and data privacy, to ensure responsible integration of ChatGPT. Nurturing a growth mindset among educators and learners is crucial to effectively navigate ChatGPT integration. By aligning strategies to leverage ChatGPTs’ capabilities while mitigating risks, educators, institutions, and policymakers can enhance the quality of education in an evolving technological landscape. This article contributes to a deeper understanding of ChatGPTs’ implications in education, providing insights into its advantages and challenges. Informed decision making and proactive measures are essential to harness ChatGPTs potential for transformative impact while safeguarding educational integrity and ethics.},
  keywords={Chatbots;Artificial intelligence;Education;Information systems;Robots;Knowledge transfer;Ethics;Artificial intelligence (AI);chatGPT;digital pedagogy;educational technology;educators;information systems;knowledge management (KM);pros–cons circumstance;students},
  doi={10.1109/EMR.2024.3394540},
  ISSN={1937-4178},
  month={June},}@INPROCEEDINGS{10850835,
  author={Krupáš, Maroš and Antonets, Liudmyla and Vaščák, Ján and Zolotová, Iveta},
  booktitle={2024 International Conference on Emerging eLearning Technologies and Applications (ICETA)}, 
  title={AI-Based Assistant: LLMs for Effective Robotics Education and Research}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Large language models (LLMs) offer new educational and research opportunities by enabling personalized learning, providing tutoring and assistance and enhancing accessibility. This paper examines the current application solutions of LLMs in education and their usability, benefits, and challenges. Through our use case and experimental data on Turtlebot3 education robots, we discuss the potential of different transformer-based LLMs and their limitations to improve educational and research outcomes for students working with robotic systems in laboratory conditions. We also evaluated selected models based on quantitative and qualitative metrics to choose one which was best suited for our AI-based education and research assistant use case.},
  keywords={Measurement;Technological innovation;Systematics;Education;Transformers;Data models;Usability;Robots;Tuning;Testing;AI-based education and research assistant;Large Language Models (LLM);generative pre-trained transformers;robotics education;Turtlebot3},
  doi={10.1109/ICETA63795.2024.10850835},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10825748,
  author={Wu, Jinlin and Liang, Xusheng and Bai, Xuexue and Chen, Zhen},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot}, 
  year={2024},
  volume={},
  number={},
  pages={2041-2048},
  abstract={Surgical interventions, particularly in neurology, represent complex and high-stakes scenarios that impose substantial cognitive burdens on surgical teams. Although deliberate education and practice can enhance cognitive capabilities, surgical training opportunities remain limited due to patient safety concerns. To address these cognitive challenges in surgical training and operation, we propose SurgBox, an agent-driven sandbox framework to systematically enhance the cognitive capabilities of surgeons in immersive surgical simulations. Specifically, our SurgBox leverages large language models (LLMs) with tailored Retrieval-Augmented Generation (RAG) to authentically replicate various surgical roles, enabling realistic training environments for deliberate practice. In particular, we devise Surgery Copilot, an AI-driven assistant to actively coordinate the surgical information stream and support clinical decision-making, thereby diminishing the cognitive workload of surgical teams during surgery. By incorporating a novel Long-Short Memory mechanism, our Surgery Copilot can effectively balance immediate procedural assistance with comprehensive surgical knowledge. Extensive experiments using real neurosurgical procedure records validate our SurgBox framework in both enhancing surgical cognitive capabilities and supporting clinical decision-making. By providing an integrated solution for training and operational support to address cognitive challenges, our SurgBox framework advances surgical education and practice, potentially transforming surgical outcomes and healthcare quality. The code is available at https://github.com/franciszchen/SurgBox.},
  keywords={Training;Neurology;Decision making;Retrieval augmented generation;Surgery;Virtual environments;Medical services;Safety;Neurosurgery;Load modeling;Surgery Simulation;Surgery Copilot;Neurosurgery;Large Language Models},
  doi={10.1109/BigData62323.2024.10825748},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{11016497,
  author={i Vilar, Guiu Puigcercos and Rashid, Parvez and Tonekaboni, Navid Hashemi},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Accessible and Reliable AI Coding Tutors: Augmenting Large Language Models with Retrieval-Augmented Generation for Java Programming}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This paper addresses the challenge of improving the reliability and accuracy of Large Language Models (LLMs) for assisting students in learning Java programming, a critical component of object-oriented computer science courses. While LLMs have shown promise in generating code, they often produce incorrect or unreliable outputs, which can hinder the learning process. To mitigate these issues, we propose a novel augmentation framework that integrates Retrieval-Augmented Generation (RAG), enabling LLMs to retrieve best-practice Java code examples from external sources to enhance the accuracy of generated solutions. We evaluate this framework using 250 Java coding tasks, covering a range of difficulties. Our findings show that the RAG-augmented model, when applied to a lightweight LLM (Google DeepMind's Gemma), outperformed baseline model by 19 % for mid and high-difficulty problems. In particular, Augmented Gemma generated accepted code for 11 problems where no other model could provide a valid solution. This suggests that retrieving external best-practice examples is critical in addressing complex coding challenges. These results highlight the potential of lightweight, accessible models enhanced with RAG to provide reliable AI coding assistance in educational settings, facilitating both accurate problem-solving and reinforcement of best coding practices.},
  keywords={Java;Codes;Accuracy;Object oriented modeling;Large language models;Retrieval augmented generation;Reliability engineering;Encoding;Problem-solving;Programming profession;Large Language Models (LLMs);Retrieval Augmented Generation (RAG);Coding Assistant;Open-source models;Java programming language;Artificial Intelligence},
  doi={10.1109/EDUCON62633.2025.11016497},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10935983,
  author={Ruf, Boris and Detyniecki, Marcin},
  booktitle={2024 International Symposium on Multimedia (ISM)}, 
  title={The ≪Huh?≫ Button: Improving Understanding in Educational Videos with Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={285-289},
  abstract={We propose a simple way to use large language models (LLMs) in education. Specifically, our method aims to improve individual comprehension by adding a novel feature to online videos. We combine the low threshold for interactivity in digital experiences with the benefits of rephrased and elaborated explanations typical of face-to-face interactions, thereby supporting to close knowledge gaps at scale. To demonstrate the technical feasibility of our approach, we conducted a proof-of-concept experiment and implemented a prototype which is available for testing online. Through the use case, we also show how caching can be applied in LLM-powered applications to reduce their carbon footprint.},
  keywords={Human computer interaction;Generative AI;Large language models;Prototypes;Educational technology;Streaming media;Carbon footprint;Videos;Testing;Educational Technology;Human Computer Interaction;Generative AI;Large Language Models},
  doi={10.1109/ISM63611.2024.00064},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11015021,
  author={Pandini, Gabriele and Martini, Antonio and Videsjorden, Adela Nedisan and Fontana, Francesca Arcelli},
  booktitle={2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C)}, 
  title={An Exploratory Study on Architectural Smell Refactoring Using Large Languages Models}, 
  year={2025},
  volume={},
  number={},
  pages={462-471},
  abstract={Architectural smells are abundant in codebases and regularly hinder the development of stable and maintainable code. Understanding and removing these elements can consume a huge amount of developers' time, who often need to prioritize implementing new features. This causes a substantial increase in Technical Debt, compromising the scalability and maintainability of the codebases, at time bringing the development to a standstill. Meanwhile, the use of Large Language Models for small error correction is constantly growing, bringing the attention of an ever-wider audience to these technologies. This study explores a first approach to use Large Language Models to suggest refactoring for architectural smells, with a focus on Cyclic Dependencies smells. We study the use of detailed prompt and Retrieval-Augmented Generation (RAG) to enhance LLMs, and we study local vs cloud LLMs. The results are promising, also validated with a series of interviews with students and developers, and highlight how additional and precise context is key to enhance the use of LLMs to propose refactoring suggestions. A multi-agent approach seems to be more suited when increasing the complexity of the smells.},
  keywords={Codes;Software architecture;Large language models;Scalability;Retrieval augmented generation;Error correction;Complexity theory;Interviews;Architectural Smell;Refactoring;LLM;RAG},
  doi={10.1109/ICSA-C65153.2025.00070},
  ISSN={2768-4288},
  month={March},}@ARTICLE{10849533,
  author={Cubillos, Claudio and Mellado, Rafael and Cabrera-Paniagua, Daniel and Urra, Enrique},
  journal={IEEE Access}, 
  title={Generative Artificial Intelligence in Computer Programming: Does It Enhance Learning, Motivation, and the Learning Environment?}, 
  year={2025},
  volume={13},
  number={},
  pages={40438-40455},
  abstract={Generative artificial intelligence (GenAI) is emerging as a transformative technology in higher education, particularly in programming instruction. However, its impact on learning, motivation, and the educational environment must still be fully understood. This study aims to determine the capacity of GenAI to generate effective computer programming learning in STEM university students, comparing it with active learning methods based on video. An experiment was conducted with 40 computer engineering students divided into two groups: one using GenAI (Google Gemini 1.5) and another employing educational videos. Pre- and post-tests of knowledge and the Intrinsic Motivation Inventory (IMI) were applied to evaluate learning, intrinsic motivation, and the learning environment. No significant differences in learning were found between the groups. However, GenAI significantly increased perceived autonomy and reduced perceived effort and pressure, while video-based learning significantly improved perceived competence. These findings suggest that both methods seem to motivate in diverse ways and that they could complement each other in an integrated teaching approach, offering new perspectives for designing programming learning environments in higher education.},
  keywords={Programming profession;Education;Learning (artificial intelligence);Generative AI;Codes;Artificial intelligence;Focusing;Active learning;Ethics;Chatbots;Generative artificial intelligence;programming education;intrinsic motivation;active learning;engineering programming},
  doi={10.1109/ACCESS.2025.3532883},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10590353,
  author={Painter, Jeffery L. and Mahaux, Olivia and Vanini, Marco and Kara, Vijay and Roshan, Christie and Karwowski, Marcin and Chalamalasetti, Venkateswara Rao and Bate, Andrew},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Enhancing Drug Safety Documentation Search Capabilities with Large Language Models: A User-Centric Approach}, 
  year={2023},
  volume={},
  number={},
  pages={49-56},
  abstract={Integrating Large Language Models (LLMs) to enhance complex business document retrieval represents an emerging field known as retrieval-augmented generation (RAG). In highly regulated domains like drug safety (pharmacovigilance), its application has remained largely unexplored. This technology brings numerous advantages, including expedited staff on-boarding, enhanced comprehension of contextual queries, and swift information retrieval through natural language inquiries, surpassing conventional keyword searches. This study delves into various operational tasks, such as locating regulatory process guidance, navigating intricate scenarios for advice, and ensuring the LLM's competence in recognizing uncertainties to prevent misinformation. LLMs empower users to engage with documentation using natural language, markedly improving search efficiency. The case study underscores LLM's effectiveness in delivering prompt guidance within pharmacovigilance and adverse event processing and reporting, offering a user-centric solution that streamlines the search for intricate business documentation.},
  keywords={Drugs;Data privacy;Uncertainty;Large language models;Documentation;Information retrieval;User experience;large language models;LLM;retrieval-augmented generation;drug safety;pharmacovigilance},
  doi={10.1109/CSCI62032.2023.00015},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{10486526,
  author={Chopade, Abhay and Shingde, Vaibhav and Chavare, Aman and Bhagwat, Tejas},
  booktitle={2024 2nd International Conference on Computer, Communication and Control (IC4)}, 
  title={Code Insight - Flowchart Generator}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The goal of the project is to automate the conversion of pseudocode into visually appealing flowcharts, facilitating the transition from human-readable algorithm descriptions to machine-executable code in software. This study presents a new approach that uses the OpenAI GPT-3.5 Turbo model for automatic flowchart generation. Addressing the lack of tools that understand pseudocode, the method interprets pseudocode, generates executable code fragments, and creates aesthetically pleasing flowcharts. This article reviews the literature and highlights a gap in automated flow charts. The selected methodology uses state-of-theart language models, with a special focus on natural language processing (NLP). The study aims to improve the understanding of algorithms by visually representing complex algorithms through automatic flowchart generation.Examples 1. Sorting rhythm: Consider a scenario where a complex sorting algorithm is described in pseudocode. The flowchart generator interprets the pseudocode, generates the corresponding executable code, and converts it into a complete flowchart. This visual representation helps developers understand algorithm logic, encourages discussion, and improves collaboration.2. Recursive algorithms and tree structures: The project extends the application to handle recursive algorithms and tree structures. For example, when a flowchart generator is provided with recursive pseudocode to traverse a binary tree, it smoothly transforms the abstract description into a detailed flowchart. This feature increases the versatility of the toolbox and offers a wide range of algorithmic models.3. Optimization Algorithm Performance: The flowchart generator not only helps to understand but also to improve algorithms by identifying potential bottlenecks and optimizing the generated code. Critical decision points and loops in the flowchart visually highlight key areas and provide developers with valuable information to make informed optimization decisions.},
  keywords={Flowcharts;Visualization;Codes;Software algorithms;Transforms;Generators;Natural language processing;serialization;flowchart;algorithm design;tree structures;algorithm efficiency;pseudocode interpretation;natural language processing;GPT-3.5 turbo;collaborative development},
  doi={10.1109/IC457434.2024.10486526},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10554841,
  author={Sapozhnikov, Arkadii and Olsthoorn, Mitchell and Panichella, Annibale and Kovalenko, Vladimir and Derakhshanfar, Pouria},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)}, 
  title={TestSpark: IntelliJ IDEA's Ultimate Test Generation Companion}, 
  year={2024},
  volume={},
  number={},
  pages={30-34},
  abstract={Writing software tests is laborious and time-consuming. To address this, prior studies introduced various automated test-generation techniques. A well-explored research direction in this field is unit test generation, wherein artificial intelligence (AI) techniques create tests for a method/class under test. While many of these techniques have primarily found applications in a research context, existing tools (e.g., EvoSuite, Randoop, and AthenaTest) are not user-friendly and are tailored to a single technique. This paper introduces Test-Spark, a plugin for IntelliJ IDEA that enables users to generate unit tests with only a few clicks directly within their Integrated Development Environment (IDE). Furthermore, TestSpark also allows users to easily modify and run each generated test and integrate them into the project workflow. TestSpark leverages the advances of search-based test generation tools, and it introduces a technique to generate unit tests using Large Language Models (LLMs) by creating a feedback cycle between the IDE and the LLM. Since TestSpark is an open-source (https://github.com/JetBrains-Research/TestSpark), extendable, and well-documented tool, it is possible to add new test generation methods into the plugin with the minimum effort. This paper also explains our future studies related to TestSpark and our preliminary results. Demo video: https://youtu.be/0F4PrxWfiXo},
  keywords={Writing;Software;Test pattern generators;Software engineering;Unit Test Generation;IntelliJ IDEA Plugin;Large Language Models},
  doi={10.1145/3639478.3640024},
  ISSN={2574-1934},
  month={April},}@INPROCEEDINGS{10874112,
  author={Tian, John and Shao, Yourui},
  booktitle={2024 IEEE International Conference on Future Machine Learning and Data Science (FMLDS)}, 
  title={Predicting College Admission Results with Machine Learning on Unstructured Online Data}, 
  year={2024},
  volume={},
  number={},
  pages={289-300},
  abstract={College admissions in the U nited States is a complex and often opaque process, leading to uncertainty and potential unfair biases. This paper presents a novel approach to predicting college admission results using machine learning on unstructured online data. Specifically, we utilize GPT-4o to extract and structure student application details and admission outcomes from more than 4,000 posts on the r/collegeresults subreddit, demonstrating the capabilities of advanced language models in preprocessing unstructured data for machine learning tasks. We employ two distinct methods for predicting admissions results: the first combines descriptive scalars extracted by GPT-4o from unstructured text data with XGBoost and a neural network to predict the probability of acceptance into an institution selectivity tier. The second predicts admission outcomes for specific institutions and compares the effectiveness of tokenization versus descriptive scalars extracted by GPT-4o in representing text features. The models achieve promising results, with Method 1 attaining an accuracy of 91.66% and an AUC-ROC of 0.9298. The results from Method 2 also demonstrate the greater effectiveness of using tokenization (85.1±.2% accuracy) over the explicitly defined features we specified (84.3±.2% accuracy).},
  keywords={Accuracy;Uncertainty;Neural networks;Machine learning;Data science;Feature extraction;Tokenization;Data models;Data mining;college admissions;machine learning;natural language processing;GPT-4o;feature extraction},
  doi={10.1109/FMLDS63805.2024.00060},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10767612,
  author={Miranda, Diego and Palma, Dayana and Fernández, Adrian and Noel, René and Cechinel, Cristian and Munoz, Roberto},
  booktitle={2024 43rd International Conference of the Chilean Computer Science Society (SCCC)}, 
  title={Enhancing Agile Project Management Education with AI: ChatGPT-4's Role in Evaluating Student Contributions}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={The planning poker estimation technique encour-ages all team members to participate equally, which is essential in the training of future software engineers. By proposing a coordination scheme based on the experience and knowledge of the team members, it enforces the common ownership of effort estimation. Thus, it is crucial that all members contribute to the process [10]. However, given the personal factors that could affect team interaction dynamics, the contributions of team members could not be equally distributed, hindering the goal of the technique. Ensuring the equal participation of team members sets a challenge not only in the professional context but also for training future software developers and team managers [18] that must facilitate team collaboration. Hence, it is vital to detect team members' contributions in order to value collaboration in a development team. In this article, we present the analyses of the interventions of 13 groups of students from the Computer Engineering course at the University of Valparaiso during a user story estimation activity using planning poker. The experimental setup involved computer science undergraduate students, performing a learning activity regarding the Planning Poker estimation technique. The students' interventions were classified according to a human expert following a collaboration framework. Subsequently, they were classified using ChatGPT 4 using the Zero Shot technique in order to compare the automatically generated labels with those provided by human experts. The type of classification used was binary to determine whether or not the intervention analysed was a contribution. The analysis focused on evaluating the accuracy and consistency of ChatGPT in the contribution classification task, considering the model's ability to correctly identify the different types of interventions. The results of this comparison demonstrate the effectiveness of ChatGPT and its potential to assist in real-time evaluation and analysis tasks. This study enhances the understanding of how artificial intelligence tools can complement the work of human experts, improving efficiency and accuracy in educational and agile project management activities.},
  keywords={Training;Computer science;Accuracy;Collaboration;Estimation;Agile project management;Chatbots;Software;Planning;Artificial intelligence;planning poker;contributions;zero shot;collab-oration},
  doi={10.1109/SCCC63879.2024.10767612},
  ISSN={2691-0632},
  month={Oct},}@INPROCEEDINGS{10852461,
  author={Slama, Faten and Lemire, Daniel},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={Comparative Analysis of Loop-Free Function Evaluation Using ChatGPT and Copilot with C Bounded Model Checking}, 
  year={2024},
  volume={},
  number={},
  pages={58-65},
  abstract={Advanced machine learning models and automated coding helpers have significantly transformed software development and verification techniques in recent years. This paper performs a comparative investigation of two prominent AI-driven code generation tools, ChatGPT and Copilot, with a specific emphasis on their ability to evaluate loop-free functions. By employing C Bounded Model Checking (CBMC) as the verification framework, we use model checking (MC) to systematically compare the accuracy and effectiveness of code produced by both tools. Our approach entails creating function implementations that are free of loops by utilizing established requirements with the assistance of ChatGPT and Copilot. These implementations are then subjected to thorough examination using CBMC to evaluate aspects such as functional correctness, safety, and potential vulnerabilities. Performance measurements encompass coding accuracy, verification time, and error identification. Results reveal notable differences in the performance of ChatGPT and Copilot. While both tools show promise in code generation, distinct strengths and weaknesses emerge in handling complex specifications and ensuring code correctness. This work provides useful insights into coding assistants powered by artificial intelligence and emphasizes the significance of incorporating formal verification methods, such as CBMC, to ensure dependable software development. This comparative analysis adds to the expanding research on AI-assisted programming, offering practical guidance for developers and researchers seeking efficient and dependable code generation tools.},
  keywords={Codes;Accuracy;Model checking;Programming;Chatbots;Encoding;Software reliability;Software development management;Formal verification;Testing;AI-driven code generation tools;ChatGPT;Copilot;CBMC},
  doi={10.1109/FLLM63129.2024.10852461},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10554754,
  author={Pan, Wei Hung and Chok, Ming Jie and Wong, Jonathan Leong Shan and Shin, Yung Xin and Poon, Yeong Shian and Yang, Zhou and Chong, Chun Yong and Lo, David and Lim, Mei Kuan},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={Educators are increasingly concerned about the usage of Large Language Models (LLMs) such as ChatGPT in programming education, particularly regarding the potential exploitation of imperfections in Artificial Intelligence Generated Content (AIGC) Detectors for academic misconduct. In this paper, we present an empirical study where the LLM is examined for its attempts to bypass detection by AIGC Detectors. This is achieved by generating code in response to a given question using different variants. We collected a dataset comprising 5,069 samples, with each sample consisting of a textual description of a coding problem and its corresponding human-written Python solution codes. These samples were obtained from various sources, including 80 from Quescol, 3,264 from Kaggle, and 1,725 from Leet-Code. From the dataset, we created 13 sets of code problem variant prompts, which were used to instruct ChatGPT to generate the outputs. Subsequently, we assessed the performance of five AIGC detectors. Our results demonstrate that existing AIGC Detectors perform poorly in distinguishing between human-written code and AI-generated code.},
  keywords={Training;Codes;Detectors;Chatbots;Encoding;Programming profession;Software engineering;Software Engineering Education;AI-Generated Code;AI-Generated Code Detection},
  doi={10.1145/3639474.3640068},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{10663027,
  author={Speth, Sandro and Meißner, Niklas and Becker, Steffen},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={ChatGPT's Aptitude in Utilizing UML Diagrams for Software Engineering Exercise Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The integration of Artificial Intelligence (AI) tech-nologies into educational settings has paved the way for inno-vative teaching and learning approaches. In Software Engineering (SE) education, using Unified Modeling Language (UML) diagrams is a fundamental teaching element for understanding complex software systems. This research addresses ChatGPT's ability to utilize UML class and sequence diagrams to create SE modeling exercises. We use ChatGPT to generate exercises based on the information from uploaded UML diagrams by analyzing textual UML representations such as Mermaid and graphical diagrams. The research explores ChatGPT's ability to synthesize UML-specific information from class and sequence diagrams, enabling the generation of various exercises tailored to strengthen conceptual understanding and practical application. Furthermore, we investigate generating graphical UML class and sequence diagrams based on natural language as input. By bridging the gap between AI -driven natural language understanding and the comprehension of UML diagrams, this study highlights the potential of ChatGPT to improve SE education. Our concise findings address educators, practitioners, and other researchers engaged in the field of SE education with a special focus on UML.},
  keywords={Reviews;Unified modeling language;Education;Manuals;Learning (artificial intelligence);Chatbots;Software systems;Data mining;Engineering education;Software engineering;AI-Generated Exercises;UML Modeling;Model Comprehension;ChatGPT;Software Engineering Education},
  doi={10.1109/CSEET62301.2024.10663027},
  ISSN={2377-570X},
  month={July},}@ARTICLE{11015274,
  author={Zhu, Lanyun and Chen, Tianrun and Ji, Deyi and Xu, Peng and Ye, Jieping and Liu, Jun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={LLaFS++: Few-Shot Image Segmentation With Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-18},
  abstract={Despite the rapid advancements in few-shot segmentation (FSS), most of existing methods in this domain are hampered by their reliance on the limited and biased information from only a small number of labeled samples. This limitation inherently restricts their capability to achieve sufficiently high levels of performance. To address this issue, this paper proposes a pioneering framework named LLaFS++, which, for the first time, applies large language models (LLMs) into FSS and achieves notable success. LLaFS++ leverages the extensive prior knowledge embedded by LLMs to guide the segmentation process, effectively compensating for the limited information contained in the few-shot labeled samples and thereby achieving superior results. To enhance the effectiveness of the text-based LLMs in FSS scenarios, we present several innovative and task-specific designs within the LLaFS++ framework. Specifically, we introduce an input instruction that allows the LLM to directly produce segmentation results represented as polygons, and propose a region-attribute corresponding table to simulate the human visual system and provide multi-modal guidance. We also synthesize pseudo samples and use curriculum learning for pretraining to augment data and achieve better optimization, and propose a novel inference method to mitigate potential oversegmentation hallucinations caused by the regional guidance information. Incorporating these designs, LLaFS++ constitutes an effective framework that achieves state-of-the-art results on multiple datasets including PASCAL-$5^{i}$, COCO-$20^{i}$, and FSS-1000. Our superior performance showcases the remarkable potential of applying LLMs to process few-shot vision tasks.},
  keywords={Image segmentation;Feature extraction;Large language models;Data mining;Training;Prototypes;Few shot learning;Transformers;Semantics;Optimization;Few-shot segmentation;large language models},
  doi={10.1109/TPAMI.2025.3573609},
  ISSN={1939-3539},
  month={},}@INPROCEEDINGS{10765939,
  author={Castillo, Karina Culebro and Zárate Hernández, Ximena M. and Gazca Herrera, Luis A. and Garizurieta Bernabe, Jessica},
  booktitle={2024 IEEE International Conference on Engineering Veracruz (ICEV)}, 
  title={Study of perception on the use of generative artificial intelligence in higher-level students}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Generative Artificial Intelligence (GAI) tools are advanced systems capable of generating content in formats such as text, images, or videos, which has been transforming fields such as education. However, excessive use of these tools may result in students not fully utilizing their own skills, thereby diminishing their critical thinking, analytical abilities, and information search skills. This research aims to study the perceptions of higher education students regarding GAI tools to assess their experiences with the usefulness of these instruments and their impact on learning. To achieve this, a non-experimental, comparative, descriptive research approach with a quantitative focus was employed, involving theoretical and conceptual processing. An instrument was designed to measure dimensions such as ethics, experience, usefulness, and quality. Finally, the results revealed that students use and understand basic concepts of GAI tools, recognize their limitations, and are thus familiar with them. The study also identified certain risks related to students' perception of these tools as substitutes for their teachers rather than as supportive aids and noted that they are perceived as potentially diminishing students' learning capacity.},
  keywords={Ethics;Generative AI;Instruments;Education;Organizations;Information retrieval;Problem-solving;Videos;Higher education;learning process;generative artificial intelligence},
  doi={10.1109/ICEV63254.2024.10765939},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10569274,
  author={Milinković, Anja and Vuleta, Daniela and Babić, i Tihana},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Student Perception of Using Generative AI Tools in Relation to Academic Integrity and Their Advantages and Disadvantages}, 
  year={2024},
  volume={},
  number={},
  pages={601-606},
  abstract={The increasing use of generative artificial intelligence (AI) tools in learning contexts calls for a reassessment of the complex dynamics surrounding academic integrity. It is a “hot” topic in the academic community, given that these more generative AI tools have become available to students to complete student assignments, and universities have had to urgently adopt rules on their use for academic purposes. While some universities have completely banned the use of such programs for the purpose of writing assignments and essays because they believe that this violates academic integrity, some other universities believe that they have the potential to influence the way we learn and approach education and that generative AI tools they must use for the benefit of students and faculty staff. The aim of the study conducted at the universities of Vern and Algebra in Zagreb, in the winter semester academic year 2023/2024 was to investigate whether students use generative AI tools for writing assignments and academic papers, how they perceive academic integrity in relation to the use of generative AI tools, and the advantages and disadvantages of generative artificial intelligence tools.},
  keywords={Costs;Accuracy;Generative AI;Algebra;Education;Learning (artificial intelligence);Writing;artificial intelligence;academic integrity;generative AI tools;ChatGPT;students perception},
  doi={10.1109/MIPRO60963.2024.10569274},
  ISSN={2623-8764},
  month={May},}@INPROCEEDINGS{10797032,
  author={Bruscia, Mattia and Manduzio, Graziano A. and Galatolo, Federico A. and Cimino, Mario G.C.A. and Greco, Alberto and Cominelli, Lorenzo and Scilingo, Enzo Pasquale},
  booktitle={2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={An Overview On Large Language Models Across Key Domains: A Systematic Review}, 
  year={2024},
  volume={},
  number={},
  pages={125-130},
  abstract={This systematic review explores the applications of Large Language Models (LLMs) across a variety of academic disciplines and professional fields. The analysis is structured through a methodical examination of data derived from the Scopus database over the period from 2017 to 2024. We created both annual and comprehensive datasets of articles and related information based on a generic query, which allowed us to track the development and integration of LLMs into different application fields. To this end, we conceived a dedicated approach that includes an analysis of the trends of subject areas and a Pertinence Analysis (PA) to filter out articles that are not genuinely related to LLMs. Additionally, we performed an annual and overall Terminological Relevance Analysis (TRA) using Machine Learning (ML) techniques, and we examined the yearly trends in research areas containing LLM-related articles by observing the relevance indicators of emerging terms. This extensive investigation highlights how LLMs are increasingly being utilized to improve efficiency, accuracy and productivity, particularly in health and healthcare care, guiding the responsible advancement and application of these technologies in sensitive domains.},
  keywords={Productivity;Large language models;Neural engineering;Medical services;Machine learning;Learning (artificial intelligence);Metrology;Market research;Systematic literature review;Periodic structures;large language models;systematic review;Scopus database;trend analysis;metadata analysis;pertinence analysis;terminological relevance;health and healthcare;annual trend;professional fields;machine learning},
  doi={10.1109/MetroXRAINE62247.2024.10797032},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11008316,
  author={Lazrek, Ghita and Chetioui, Kaouthar and Balboul, Younes},
  booktitle={2025 5th International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET)}, 
  title={Unveiling Health’s Tomorrow: A Comprehensive Review of Anomaly Detection for IoMT Using Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This systematic literature review provides a thorough examination of the utilization of Large Language Models (LLMs) in predictive analysis and anomaly detection for IoMT networks, focusing on the latest developments in research landscape, and potential future prospects. LLMs have exhibited considerable promise in interpreting and analyzing vast datasets to recognize patterns, anticipate future occurrences, and identify abnormal behavior across diverse domains. Moreover, this review presents a detailed overview of LLM and outlines pivotal trends anticipated to influence the advancement of LLMs in these areas, encompassing the shift towards real-time processing, the significance of adopting sustainable modeling methodologies, and the benefits derived from collaboration across disciplines. In conclusion, this review emphasizes the revolutionary impact of LLMs in IoMT predictive and anomaly identification, highlighting the imperative for ongoing innovation, and practical solutions to fully harness their capabilities.},
  keywords={Technological innovation;Accuracy;Large language models;Market research;Real-time systems;Security;Reliability;Anomaly detection;Standards;Systematic literature review;Internet of Medical Things (IoMT);Security;Large Language Model (LLM);anomaly detection},
  doi={10.1109/IRASET64571.2025.11008316},
  ISSN={},
  month={May},}@INBOOK{10790761,
  author={Choi, Sean and Jo, Jinyoung},
  booktitle={Artificial Intelligence: Machine Learning, Convolutional Neural Networks and Large Language Models}, 
  title={Leveraging linguistic features to improve machine learning models for detecting ChatGPT usage on exams}, 
  year={2024},
  volume={},
  number={},
  pages={281-308},
  abstract={This work presents a case study, linguistic analyses, and the results of experiments on using linguistic features to improve the detection mechanism of the use of large language models (LLM) to generate solutions for exams that require domainspecific knowledge. The study involves analyzing the responses of three groups of students: a group who verbatim copied outputs of ChatGPT to plagiarize solutions, another group who referred to external non-LLM resources (e.g., web search) to plagiarize solutions, a control group who did not plagiarize. Linguistic analyses show that solutions from groups that participated in plagiarism tend to be longer, use uncommon words, and are similar to each other compared to solutions that were not plagiarized. In addition, utilizing these characteristics as features improves F1 score of machine learning models that detect plagiarism as much as 5.5%. This study shows that certain linguistic features can be utilized in machine learning models to detect use of LLMs, ultimately improving academic integrity by deterring the unethical use of AI in academic settings.},
  keywords={Chatbots;Feature extraction;Machine learning algorithms;Linguistics;Plagiarism;Machine learning;Text categorization;Computational modeling;Data models;Classification algorithms},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783111344171},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10790761},}@INPROCEEDINGS{10578705,
  author={Tripaldelli, Alessia and Pozek, George and Butka, Brian},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Leveraging Prompt Engineering on ChatGPT for Enhanced Learning in CEC330: Digital System Design in Aerospace}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research examines the transformative role of prompt engineering in optimizing ChatGPT's utility in a digital-system-design class at Embry-Riddle Aeronautical University. By exploring various prompt engineering strategies, the authors investigate how to tailor prompts to significantly enhance ChatGPT's ability to assist students in complex coding and debugging tasks. The study highlights the pivotal role of prompt engineering in elevating ChatGPT from a basic informational tool to an integral component of the educational process. The chosen course centers on using FPGAs to generate and apply state machines. One course activity involves generating musical tones and sequentially playing them to produce the specified songs. Another activity challenges students to construct the foundational elements of a simple reduced instruction set processor, which includes defining a custom instruction set and conforming to a 16-bit design specification. This process entails developing an arithmetic logic unit, creating a general register array, and formulating the processor's specific instruction set. Therefore, this research is a pilot study with a small sample of students using ChatGPT to examine what prompts work best when used in a technical programming class.},
  keywords={Adaptation models;Codes;Instruction sets;Refining;Chatbots;Encoding;Iterative methods;Artificial Intelligence;ChatGPT;Prompt Engineering},
  doi={10.1109/EDUCON60312.2024.10578705},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10766746,
  author={Mellado, Rafael and Cubillos, Claudio and Ahumada, Giovanni},
  booktitle={2024 IEEE International Conference on Automation/XXVI Congress of the Chilean Association of Automatic Control (ICA-ACCA)}, 
  title={Effectiveness of Generative Artificial Intelligence in learning programming to higher education students}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Learning programming in higher education faces significant challenges, including high dropout rates and difficulties in understanding abstract concepts. Previous studies have explored various teaching methods, but the effectiveness of Generative Artificial Intelligence (GenAI) in this context has not yet been widely investigated. This study compares the efficacy of GenAI with video-based active learning methods for teaching programming to university students. Through an experimental design with 40 computer engineering students, academic performance, perception of usefulness and ease of use, and satisfaction and motivation were evaluated. The results showed no statistically significant differences between the groups in academic performance, perception of usefulness and ease of use, or satisfaction and motivation. Both methods proved equally effective in improving learning and maintaining student motivation. These findings suggest that GenAI can be a viable alternative to traditional methods, offering opportunities to diversify pedagogical strategies in programming education. Educators are encouraged to consider integrating GenAI to complement existing methods, ensuring implementation that maintains high levels of perceived control, immersion, and curiosity among students.},
  keywords={Training;Technology acceptance model;Generative AI;Education;Learning (artificial intelligence);Educational technology;Engineering students;Programming profession;Faces;Videos;generative artificial intelligence;computer programming;active learning},
  doi={10.1109/ICA-ACCA62622.2024.10766746},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10549466,
  author={Imran, Mia Mohammad and Chatterjee, Preetha and Damevski, Kostadin},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE)}, 
  title={Uncovering the Causes of Emotions in Software Developer Communication Using Zero-shot LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={2244-2256},
  abstract={Understanding and identifying the causes behind developers' emotions (e.g., Frustration caused by ‘delays in merging pull requests’) can be crucial towards finding solutions to problems and fostering collaboration in open-source communities. Effectively identifying such information in the high volume of communications across the different project channels, such as chats, emails, and issue com-ments, requires automated recognition of emotions and their causes. To enable this automation, large-scale software engineering-specific datasets that can be used to train accurate machine learning models are required. However, such datasets are expensive to create with the variety and informal nature of software projects' communication channels. In this paper, we explore zero-shot LLMs that are pretrained on massive datasets but without being fine-tuned specifically for the task of detecting emotion causes in software engineering: ChatGPT, GPT-4, and flan-alpaca. Our evaluation indicates that these recently available models can identify emotion categories when given detailed emotions, although they perform worse than the top-rated models. For emotion cause identification, our results indicate that zero-shot LLMs are effective at recognizing the correct emotion cause with a BLEU-2 score of 0.598. To highlight the potential use of these techniques, we conduct a case study of the causes of Frus-tration in the last year of development of a popular open-source project, revealing several interesting insights.},
  keywords={Emotion recognition;Automation;Merging;Collaboration;Machine learning;Chatbots;Software;Emotion Cause Extraction;Emotion Classification;Zero-Shot Prompting;Large Language Model;GPT-4;ChatGPT},
  doi={10.1145/3597503.3639223},
  ISSN={1558-1225},
  month={April},}@INPROCEEDINGS{10893375,
  author={Qu, Yanzhen and Letort, Daniel and Evans, Howard and Abbas, Noura and Cai, Richard and Haj-Hussein, Mazen and Biggs, Anastasia and Durgin, Janet},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Unlocking Learning Potential: Generative AI Chatbots as Study Partners in Online BS in Computer Science Degree Program}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This research-to-practice full paper presents our innovative approach to integrating Generative Artificial Intelligence (GAI) chatbots into selected BSCS courses. These courses operate within an Online Learning Environment (OLE) based on asynchronous communication. We have detailed two distinct approaches to implement Retrieval-Augmented Generation (RAG) model-based GAI chatbots. The first approach utilizes Microsoft Copilot Studio, allowing us to create customized chatbots without the need for coding. The second approach involves Python coding to develop more advanced GAI chatbots. Both methods are straightforward and cost-effective, leveraging the latest advancements to enhance communication between students and faculty. By incorporating frequently asked questions and answers from various BSCS courses into these chatbots, we can enrich the learning experience and aid both students and faculty in achieving their goals. Our preliminary results suggest that with careful planning, design, and implementation, these chatbots can circumvent common issues such as misinformation, inaccuracy, ethical and safety concerns, and lack of contextual understanding, thereby enhancing the effectiveness of student learning in an asynchronous communication-based OLE.},
  keywords={Computer science;Ethics;Generative AI;Retrieval augmented generation;Chatbots;Encoding;Safety;Planning;Fake news;Python;GAI chatbot;RAG model;Online Learning Environment;Study Partner},
  doi={10.1109/FIE61694.2024.10893375},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10763263,
  author={Wijaya, Owen Christian and Purwarianti, Ayu},
  booktitle={2024 11th International Conference on Advanced Informatics: Concept, Theory and Application (ICAICTA)}, 
  title={An Interactive Question-Answering System Using Large Language Model and Retrieval-Augmented Generation in an Intelligent Tutoring System on the Programming Domain}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The insufficient communication between mentors and students has been one of the main disadvantages of modern programming learning platforms. In this paper, we propose the development of a web-based intelligent tutoring system with a question-answering (QA) system to provide live interaction between students and a mentor figure. We propose the implementation of an alternative QA system using a large language model (LLM) and a retrieval-augmented generation (RAG) mechanism. We utilized the LangChain library and integrated the RAG mechanism with the history-aware retriever and direct integration into the web application. We performed internal and external evaluations in the form of qualitative evaluation via subjective scoring towards answers from various quantized LLMs in both single-turn and multi-turn conversation scenarios. We conclude that the Llama 3 model displays consistent and promising results compared to other models and that documents with a higher character count may act as better knowledge bases for the RAG process.},
  keywords={Large language models;Knowledge based systems;Oral communication;Programming;Libraries;History;Informatics;Testing;LLM;question-answering;retrieval;chatbot},
  doi={10.1109/ICAICTA63815.2024.10763263},
  ISSN={2996-2552},
  month={Sep.},}@INPROCEEDINGS{10893904,
  author={Jothi, T. and Dominic, J. and Jaganbabu, J.},
  booktitle={2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI)}, 
  title={Enhancing Medical Libraries: AI-Driven Tools and Techniques for Digital Transformation and Sustainable Innovation}, 
  year={2025},
  volume={},
  number={},
  pages={1182-1186},
  abstract={Artificial intelligence (AI) is transforming numerous fields, particularly in research and education, and its integration into medical library operations has become essential to maintaining relevance and competitiveness in today's global landscape. This exploration examines how AI-driven tools and methods are reshaping various aspects of medical library services, offering a comprehensive look at the potential and practical applications of AI in the library setting. The core objective of AI is to develop systems capable of performing cognitive tasks that mimic human thought. By incorporating AI, medical libraries can transcend physical limitations, becoming more intelligent, accessible, and responsive. This article explores how advancements such as Natural Language Processing (NLP), Large Language Models (LLM), Expert Systems (ES), AI-powered indexing tools, and Chabot's can enhance medical library infrastructure and services. These AI applications hold promise for improving outcomes across user groups-benefiting students, faculty, healthcare researchers, and clinical practitioners a like. In providing an in-depth analysis of AI's advantages, limitations, and innovative uses, this article fosters a deeper understanding of AI's role in library science. Through a balanced perspective on AI's transformative potential, libraries are equipped to make informed decisions, leveraging technology to support an evolving and dynamic medical information environment.},
  keywords={Technological innovation;Large language models;Digital transformation;Education;Medical services;Libraries;Natural language processing;Artificial intelligence;Expert systems;Indexing;Artificial Intelligence (AI);Natural Language Processing (NLP);Large Language Model;Expert Systems;AI-driven Tools;Medical Institute library},
  doi={10.1109/ICMSCI62561.2025.10893904},
  ISSN={},
  month={Jan},}@ARTICLE{10649569,
  author={Dwivedi, Rahul and Elluri, Lavanya},
  journal={IEEE Access}, 
  title={Exploring Generative Artificial Intelligence Research: A Bibliometric Analysis Approach}, 
  year={2024},
  volume={12},
  number={},
  pages={119884-119902},
  abstract={Artificial Intelligence (AI) and its many applications are changing our lives in ways we could not have imagined a decade ago. Generative artificial intelligence is an artificial intelligence system capable of generating texts, images, and other media based on the input training data. Although still in their early stages, numerous examples of such systems in different domains have gained widespread attention from the public, media, policymakers, and researchers. This study aims to explore the generative AI academic research in the past decade using bibliometrics, text analysis, and social network analysis. Specifically, research themes and their relationships, the evolution of research themes over time, and prominent authors, articles, journals, institutions, and countries publishing in generative AI are identified. The data was further found to partially support the classical bibliometrics laws of Zipf, and Bradford’s. The two overarching research themes identified using knowledge synthesis from most cited articles and journals are technical advancements and developments in generative AI systems; and their applications to image processing, pattern recognition, and computer vision. ChatGPT, large language models, and the application of generative AI to healthcare and education are emerging research topics. Additionally, generative AI’s usefulness to geoscience, remote sensing, Internet of Things (IoT), and cybersecurity are discussed.},
  keywords={Bibliometrics;Generative AI;Artificial intelligence;Databases;Market research;Indexes;Internet;Generative artificial intelligence;bibliometric analysis},
  doi={10.1109/ACCESS.2024.3450629},
  ISSN={2169-3536},
  month={},}@ARTICLE{10507163,
  author={Liu, Zhijie and Tang, Yutian and Luo, Xiapu and Zhou, Yuming and Zhang, Liang Feng},
  journal={IEEE Transactions on Software Engineering}, 
  title={No Need to Lift a Finger Anymore? Assessing the Quality of Code Generation by ChatGPT}, 
  year={2024},
  volume={50},
  number={6},
  pages={1548-1584},
  abstract={Large language models (LLMs) have demonstrated impressive capabilities across various natural language processing (NLP) tasks, such as machine translation, question answering, summarization, and so on. Additionally, LLMs are also highly valuable in supporting software engineering tasks, particularly in the field of code generation. Automatic code generation is a process of automatically generating source code or executable code based on given specifications or requirements, improving developer productivity. In this study, we perform a systematic empirical assessment to the quality of code generation using ChatGPT, a recent state-of-the-art product LLM. We leverage 728 algorithm problems in five languages (i.e., C, C++, Java, Python, and JavaScript) and 18 CWEs with 54 code scenarios for the code generation task. Our evaluation encompasses a comprehensive analysis of code snippets generated by ChatGPT, focusing on three critical aspects: correctness, complexity, and security. We also specifically investigate ChatGPT's ability to engage in multi-round fixing process (i.e., ChatGPT's dialog ability, chatting between users and ChatGPT for fixing generated buggy code) of facilitating code generation. By delving into the generated code and examining the experimental results, this work provides valuable insights into the performance of ChatGPT in tackling code generation tasks over the three critical aspects. The experimental results demonstrate that (1) ChatGPT is better at generating functionally correct code for problems before 2021 in different languages than problems after 2021 with $48.14\%$48.14% advantage in Accepted rate on judgment platform, but ChatGPT's ability to directly fix erroneous code with multi-round fixing process to achieve correct functionality is relatively weak; (2) the distribution of cyclomatic and cognitive complexity levels for code snippets in different languages varies. Furthermore, the multi-round fixing process with ChatGPT  generally preserves or increases the complexity levels of code snippets; (3) in algorithm scenarios with languages of C, C++, and Java, and CWE scenarios with languages of C and Python3, the code generated by ChatGPT  has relevant vulnerabilities. However, the multi-round fixing process for vulnerable code snippets demonstrates promising results, with more than $89\%$89% of vulnerabilities successfully addressed; and (4) code generation may be affected by ChatGPT's non-determinism factor, resulting in variations of code snippets in functional correctness, complexity, and security. Overall, our findings uncover potential issues and limitations that arise in the ChatGPT-based code generation and lay the groundwork for improving AI and LLM-based code generation techniques.},
  keywords={Codes;Chatbots;Task analysis;Complexity theory;Security;Transformers;Electronic mail;Large language model;ChatGPT;code generation},
  doi={10.1109/TSE.2024.3392499},
  ISSN={1939-3520},
  month={June},}@ARTICLE{10720422,
  author={Wu, Dongyuan and Nie, Liming and Mumtaz, Rao Asad and Agarwal, Kadambri},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={A LLM-Based Hybrid-Transformer Diagnosis System in Healthcare}, 
  year={2024},
  volume={},
  number={},
  pages={1-12},
  abstract={The application of computer vision-powered large language models (LLMs) for medical image diagnosis has significantly advanced healthcare systems. Recent progress in developing symmetrical architectures has greatly impacted various medical imaging tasks. While CNNs or RNNs have demonstrated excellent performance, these architectures often face notable limitations of substantial losses in detailed information, such as requiring to capture global semantic information effectively and relying heavily on deep encoders and aggressive downsampling. This paper introduces a novel LLM-based Hybrid-Transformer Network (HybridTransNet) designed to encode tokenized Big Data patches with the transformer mechanism, which elegantly embeds multimodal data of varying sizes as token sequence inputs of LLMS. Subsequently, the network performs both inter-scale and intra-scale self-attention, processing data features through a transformer-based symmetric architecture with a refining module, which facilitates accurately recovering both local and global context information. Additionally, the output is refined using a novel fuzzy selector. Compared to other existing methods on two distinct datasets, the experimental findings and formal assessment demonstrate that our LLM-based HybridTransNet provides superior performance for brain tumor diagnosis in healthcare informatics.},
  keywords={Transformers;Image segmentation;Medical diagnostic imaging;Computer architecture;Medical services;Computational modeling;Accuracy;Training;Convolution;Context modeling;Diagnosis;Medical imaging;Transformer;Fuzzy selector;LLM},
  doi={10.1109/JBHI.2024.3481412},
  ISSN={2168-2208},
  month={},}@INPROCEEDINGS{10774681,
  author={Rachh, Rashmi and Kavatagi, Sanjana},
  booktitle={2024 3rd International Conference for Advancement in Technology (ICONAT)}, 
  title={Study on Students' Perceptions of Generative AI in Learning Programming Courses}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The proliferation of generative AI has taken the world by storm, and the education sector is no exception. It is imperative to leverage this emerging technology to bring about positive transformation in teaching and learning. However, the adoption of generative AI in education must be approached with caution, necessitating several pedagogical interventions. This paper discusses the various challenges and issues involved in adopting generative AI for teaching programming language courses and proposes plausible solutions.},
  keywords={Computer languages;Generative AI;Storms;Education;Programming profession;Generative AI;Education;Pedagogy;Programming},
  doi={10.1109/ICONAT61936.2024.10774681},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10986583,
  author={Deshpande, Deepali and Deshpande, Renuka and Gadekar, Akash and Gaikwad, Rutvik and Gejage, Vipul and Ghavate, Sarthak},
  booktitle={2025 3rd International Conference on Disruptive Technologies (ICDT)}, 
  title={Skilldev: Genai-Powered Skill Upgrading Platform}, 
  year={2025},
  volume={},
  number={},
  pages={520-525},
  abstract={The rapid evolution of technology has transformed the landscape of education, making it essential for students to stay up-to-date with industry-relevant skills. The project presents a web-based platform to enhance campus placement preparation for pre-final and final-year engineering students of various computer-related faculties. The platform uses Generative AI to assess student skill levels in various core and important subjects under the computer domain. By categorizing students into Beginner, Intermediate, or Advanced levels, the platform delivers personalized learning resources and tutorial recommendations as per the user's needs while tracking the overall progress. The system provides visual insights through graphical analysis of student performance to improve employability and better equip students for competitive placement processes. Additionally, it also delivers responsive feedback for the overall achievement and progress of the user. Through various self-designed recommendation and evaluation algorithms, the system adapts to student's learning needs, ensuring an optimized and dynamic learning experience.},
  keywords={Visualization;Generative AI;Engineering profession;Heuristic algorithms;Education;Focusing;Tutorials;Logic;Engineering students;Monitoring;Generative AI;Recommendation Model;Progressive Flow Logic;Personalization;Flask;SQL;Placement Preparation},
  doi={10.1109/ICDT63985.2025.10986583},
  ISSN={},
  month={March},}@ARTICLE{10874155,
  author={Tracy, Kaitlyn and Spantidi, Ourania},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Impact of GPT-Driven Teaching Assistants in VR Learning Environments}, 
  year={2025},
  volume={18},
  number={},
  pages={192-205},
  abstract={Virtual reality (VR) has emerged as a transformative educational tool, enabling immersive learning environments that promote student engagement and understanding of complex concepts. However, despite the growing adoption of VR in education, there remains a significant gap in research exploring how generative artificial intelligence (AI), such as generative pretrained transformer can further enhance these experiences by reducing cognitive load and improving learning outcomes. This study examines the impact of an AI-driven instructor assistant in VR classrooms on student engagement, cognitive load, knowledge retention, and performance. A total of 52 participants were divided into two groups experiencing a VR lesson on the bubble sort algorithm, one with only a prescripted virtual instructor (control group), and the other with the addition of an AI instructor assistant (experimental group). Statistical analysis of postlesson quizzes and cognitive load assessments was conducted using independent t-tests and analysis of variance (ANOVA), with the cognitive load being measured through a postexperiment questionnaire. The study results indicate that the experimental group reported significantly higher engagement compared to the control group. While the AI assistant did not significantly improve postlesson assessment scores, it enhanced conceptual knowledge transfer. The experimental group also demonstrated lower intrinsic cognitive load, suggesting the assistant reduced the perceived complexity of the material. Higher germane and general cognitive loads indicated that students were more invested in meaningful learning without feeling overwhelmed.},
  keywords={Artificial intelligence;Cognitive load;Training;Chatbots;Load modeling;Immersive learning;Generative Pre-trainer transformer;Generative AI;Cultural differences;Computer science;Generative artificial intelligence (GenAI);human–computer interaction;interactive learning environments;learning efficacy;learning outcomes;virtual reality (VR)},
  doi={10.1109/TLT.2025.3539179},
  ISSN={1939-1382},
  month={},}@ARTICLE{10546929,
  author={Liang, Hao and Zhang, Jiaxin and Li, Yunqin and Wang, Bowen and Huang, Jingyong},
  journal={IEEE Access}, 
  title={Automatic Estimation for Visual Quality Changes of Street Space via Street-View Images and Multimodal Large Language Models}, 
  year={2024},
  volume={12},
  number={},
  pages={87713-87727},
  abstract={Estimating Visual Quality of Street Space (VQoSS) is pivotal for urban design, environmental sustainability, civic engagement, etc. Recent advancements, notably in deep learning, have enabled large-scale analysis. However, traditional deep learning approaches are hampered by extensive data annotation requirements and limited adaptability across diverse VQoSS tasks. Multimodal Large Language Models (MLLMs) have recently demonstrated proficiency in various computer vision tasks, positioning them as promising tools for automated VQoSS assessment. In this paper, we pioneer the application of MLLMs to VQoSS change estimation, with our empirical findings affirming their effectiveness. In addition, we introduce Street Quality Generative Pre-trained Transformer (SQ-GPT), a model that distills knowledge from the current most powerful but inaccessible (not free) GPT-4V, requiring no human efforts. SQ-GPT approaches GPT-4V’s performance and is viable for large-scale VQoSS change estimation. In a case study of Nanjing, we showcase the practicality of SQ-GPT and knowledge distillation pipeline. Our work promises to be a valuable asset for future urban studies research.},
  keywords={Visualization;Task analysis;Estimation;Deep learning;Image color analysis;Data models;Context modeling;Smart cities;Large language models;Smart city;visual quality;deep learning;multimodal large language models},
  doi={10.1109/ACCESS.2024.3408843},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10589969,
  author={Huang, Guimin and Liang, Xinxian},
  booktitle={2024 6th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={Generative AI Research of Education from 2013 to 2023}, 
  year={2024},
  volume={},
  number={},
  pages={125-130},
  abstract={Generative AI offers a new possibility for teaching and learning, where the role of the teacher will be affected and the way students learn will potentially be disrupted. This study analyzed the Wos database of relevant literature over the past 10 years (January 2013-November 2023) using the visual analysis software CiteS pace, with the aim of providing an overview of generative-time AI research in the field of education, revealing the main research patterns and trends characterizing it. The results of the study reveal the authors, regions, journals, and references that have made significant contributions. In addition, keyword co-occurrence, burst words, and timeline maps were generated to identify key hotspots in this research area.},
  keywords={Computer science;Visualization;Generative AI;Education;Market research;Software;Visual databases;generative AI;education;LLM;AIGC;ChatGPT;research trends},
  doi={10.1109/CSTE62025.2024.00030},
  ISSN={},
  month={April},}@INPROCEEDINGS{10665264,
  author={Charney, Max},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Fostering Diversity and Knowledge in Artificial Intelligence: An Inclusive Platform of Career Insights and Resources from Conversations with Leaders in the Field}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={Computer science has recently experienced a surge in popularity with the release of generative artificial intelligence models. Yet, while the popular imagination has been captured, evidence indicates that pre-college students, especially those from underrepresented populations, lack adequate education about careers in the field. Effective methods for gaining understanding include shadowing professionals or acquiring internships, yet these means are often not attainable or realistic for many students. Overall, this insufficient education can lead to future disadvantages, including future workforce disparities. To address these problems, Computer Science Next (CSNext) is an organization that was founded in early 2024 to convey insights from the current to the next generation of computer scientists. CSNext's first project will be a series of video interviews with leaders in artificial intelligence intended for a high school student audience. Video interviews will be released for free, and responses will be synthesized to share meaningful and insightful commonalities and responses. In addition, a list of the resources discussed in the interview will be cataloged alongside the videos and indexed for the site in its entirety. Particular attention will be focused on inclusivity, including underrepresented minorities, when selecting interview candidates.},
  keywords={Computer science;Engineering profession;Education;Organizations;Oral communication;Interviews;Artificial intelligence;Artificial intelligence education;Career exploration;Expert discourse;Inclusivity},
  doi={10.1109/ISEC61299.2024.10665264},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{10343985,
  author={Tsoeu, Mohohlo and Maladzi, Rendani and Mthombeni, Nomcebo and Moloi, Katleho and Mashifana, Tebogo and Nemavhola, Fulufhelo},
  booktitle={2023 World Engineering Education Forum - Global Engineering Deans Council (WEEF-GEDC)}, 
  title={Engineering, the Profession in Trouble: Lack of Programme Development Standards That Support the AI Chatbot? A System View}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={As the world embraces the transformative potential of artificial intelligence (AI), large language models (LLM), and conversational agents also known as chatbots, the engineering profession stands at a crucial juncture. This paper critically examines the current state of engineering education and its readiness to incorporate AI chatbots effectively. Focusing on the lack of standardized programme development that supports AI chatbots, this paper sheds light on the implications of this gap for engineering education. Standardization is defined as the degree to which educational programmes meet common national and international quality standards. By synthesizing existing literature, this study investigates the challenges, opportunities, and strategies required to bridge this divide and ensure that engineering programmes are adequately equipped to produce graduates who can harness the power of AI chatbots. We found that strong and continuing trends are emerging in the use of AI and chatbots in engineering education and industry. We further noted that current standards from accreditation bodies need to respond to enable AI and chatbot incorporation from curriculum to pedagogical levels of engineering education. Industry-academia partnerships are vital in managing the integration of AI into engineering education.},
  keywords={Knowledge engineering;Industries;Navigation;Focusing;Chatbots;Market research;Accreditation;AI;chatbots;artificial intelligence;education;standards;programmes;development;curricula;accreditation},
  doi={10.1109/WEEF-GEDC59520.2023.10343985},
  ISSN={2837-5025},
  month={Oct},}@INPROCEEDINGS{10764947,
  author={Wu, Di and Mu, Fangwen and Shi, Lin and Guo, Zhaoqiang and Liu, Kui and Zhuang, Weiguang and Zhong, Yuqi and Zhang, Li},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={iSMELL: Assembling LLMs with Expert Toolsets for Code Smell Detection and Refactoring}, 
  year={2024},
  volume={},
  number={},
  pages={1345-1357},
  abstract={Detecting and refactoring code smells is challenging, laborious, and sustaining. Although large language models have demonstrated potential in identifying various types of code smells, they also have limitations such as input-output token restrictions, difficulty in accessing repository-level knowledge, and performing dynamic source code analysis. Existing learning-based methods or commercial expert toolsets have advantages in handling complex smells. They can analyze project structures and contextual information in-depth, access global code repositories, and utilize advanced code analysis techniques. However, these toolsets are often designed for specific types and patterns of code smells and can only address fixed smells, lacking flexibility and scalability. To resolve that problem, we propose iSMELL, an ensemble approach that employs various code smell detection toolsets via Mixture of Experts (MoE) architecture for comprehensive code smell detection, and enhances the LLMs with the detection results from expert toolsets for refactoring those identified code smells. First, we train a MoE model that, based on input code vectors, outputs the most suitable expert tool for identifying each type of smell. Then, we select the recommended toolsets for code smell detection and obtain their results. Finally, we equip the prompts with the detection results from the expert toolsets, thereby enhancing the refactoring capability of LLMs for code with existing smells, enabling them to provide different solutions based on the type of smell. We evaluate our approach on detecting and refactoring three classical and complex code smells, i.e., Refused Bequest, God Class, and Feature Envy. The results show that, by adopting seven expert code smell toolsets, iSMELL achieved an average F1 score of 75.17% on code smell detection, outperforming LLMs baselines by an increase of 35.05% in F1 score. We further evaluate the code refactored by the enhanced LLM. The quantitative and human evaluation results show that iSMELL could improve code quality metrics and conduct satisfactory refactoring toward the identified code smells. We believe that our proposed solution could provide new insights into better leveraging LLMs and existing approaches to resolving complex software tasks.},
  keywords={Measurement;Learning systems;Codes;Source coding;Scalability;Large language models;Feature extraction;Vectors;Software;Software engineering},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{10795109,
  author={Cooper, Nathan and Tufano, Rosalia and Bavota, Gabriele and Poshyvanyk, Denys},
  booktitle={2024 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={On the Generalizability of Transformer Models to Code Completions of Different Lengths}, 
  year={2024},
  volume={},
  number={},
  pages={375-387},
  abstract={The programming landscape is nowadays being reshaped by the advent of Large Language Models (LLMs) able to automate code-related tasks related to code implementation (e.g., code completion) and comprehension (e.g., code summarization). Such a paradigm shift comes with a number of implications related to how software will be written, maintained, and evolved. Also, these LLMs are extremely expensive to train, posing questions on their sustainability over time. Given their training cost, their ability to generalize, namely their ability to work on task instances different from those on which they have been trained, is an aspect worth being investigated. Previous work already showed that transformer models can successfully support code completion in a cross-project setting. However, it is unclear whether LLM are able to generalize to inputs having lengths not seen during training. For example, it is known that training a model on short instances allows to substantially reduce the training cost. However, the extent to which such a model would provide good performance on sequences having lengths not seen during training is not known. Many recent works in Natural Language Processing (NLP) tackled this problem in the context of decoder-only LLMs, i.e., xPOS and ALiBi. To assess if these solutions extend to encoder-decoder LLMs usually adopted in the code-related tasks, we present a large empirical study evaluating this generalization property of these and other encoding schemes proposed in the literature, namely Sinusoidal, xPOS, ALiBi, and T5. We found that none of these solutions successfully generalize to unseen lengths and that the only safe solution is to ensure the representativeness in the training set of all lengths likely to be encountered at inference time.},
  keywords={Training;Software maintenance;Codes;Costs;Transformers;Encoding;Natural language processing;Sustainable development;Context modeling;Software engineering;DL4SE;Code Completion},
  doi={10.1109/ICSME58944.2024.00042},
  ISSN={2576-3148},
  month={Oct},}@ARTICLE{10410841,
  author={Mubin, Omar and Alnajjar, Fady and Trabelsi, Zouheir and Ali, Luqman and Parambil, Medha Mohan Ambali and Zou, Zhao},
  journal={IEEE Access}, 
  title={Tracking ChatGPT Research: Insights From the Literature and the Web}, 
  year={2024},
  volume={12},
  number={},
  pages={30518-30532},
  abstract={This article presents a scientometric and literature analysis of current research on ChatGPT, a conversational AI technology developed by OpenAI. Using various databases, 103 relevant articles were retrieved and analyzed through scientometric, quantitative, and application-based approaches. A Google trend analysis and comparison with other generative AI and chatbot technologies were also carried out. The study provides insights into the distribution of ChatGPT publications across different countries and regions, the network of co-occurring keywords, authorship analysis, article typology, and publishing entities. The findings offer a comprehensive overview of the current state of ChatGPT research, highlighting key directions for future research. The study finds that ChatGPT has gained significant attention and interest in online platforms, particularly in technology, education, and healthcare, and highlights potential ethical and legal concerns related to its use. Its applications extend to several literary and text generation areas. We do note that the sample of extracted publications is lower than anticipated due to the niche area of investigation. The article is relevant to researchers, practitioners, and policymakers interested in the field of AI-powered language models, especially ChatGPT.},
  keywords={Chatbots;Bibliometrics;Education;Artificial intelligence;Task analysis;Market research;Search engines;Natural language processing;Open Access;ChatGPT;artificial intelligence;natural language processing;NLM},
  doi={10.1109/ACCESS.2024.3356584},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10565716,
  author={Sobral, Sónia Roll},
  booktitle={2023 XIII International Conference on Virtual Campus (JICV)}, 
  title={Why ChatGPT Isn't Introductory Programming Freshmen's Best Friend}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={The emergence of ChatGPT brought a lot of controversy in society and academia due to the ease with which students can effortlessly perform work. This paper investigates whether a freshman student in an introductory programming unit using Python benefits from using ChatGPT, even as an aid. The methodology used was the application of three written tests of one semester - using Python programming language -, answered by ChatGPT (free version), analysed, and compared with a “good” solution of each one. Strangely, or maybe not, errors and problems were found in the solutions provided by ChatGPT that are the same ones that self-taught student (those who learn on YouTube and websites around the Internet world) make.},
  keywords={Video on demand;Programming;Chatbots;Internet;Web sites;Python;ChatGPT;Python;introductory programming},
  doi={10.1109/JICV59748.2023.10565716},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10734614,
  author={Li, Zhiming and Cao, Yushi and Xu, Xiufeng and Jiang, Junzhe and Liu, Xu and Teo, Yon Shin and Lin, Shang-Wei and Liu, Yang},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={LLMs for Relational Reasoning: How Far are We?}, 
  year={2024},
  volume={},
  number={},
  pages={119-126},
  abstract={Large language models (LLMs) have revolutionized many areas (e.g. natural language processing, software engineering, etc.) by achieving state-of-the-art performance on extensive downstream tasks. Aiming to achieve robust and general artificial intelligence, there has been a surge of interest in investigating the reasoning ability of the LLMs. Whereas the textual and numerical reasoning benchmarks adopted by previous works are rather shallow and simple, it is hard to conclude that the LLMs possess strong reasoning ability by merely achieving positive results on these benchmarks. Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks. In this work, we conduct an in-depth assessment of several state-of-the-art LLMs’ reasoning ability based on the inductive logic programming (ILP) benchmark, which is broadly recognized as a representative and challenging measurement for evaluating logic program induction/synthesis systems as it requires inducing strict cause-effect logic to achieve robust deduction on independent and identically distributed (IID) and out-of-distribution (OOD) test samples. Our evaluations illustrate that compared with the neural program induction systems which are much smaller in model size, the state-of-the-art LLMs are much poorer in terms of reasoning ability by achieving much lower performance and generalization using either natural language prompting or truth-value matrix prompting.1},
  keywords={Large language models;Pipelines;Reinforcement learning;Benchmark testing;Cognition;Planning;Logic;Surges;Standards;Software engineering;Large Language Models;Relational Reasoning;Program Induction},
  doi={},
  ISSN={},
  month={April},}@ARTICLE{10677538,
  author={Bernardino, Maicon and Cargnelutti, Rodrigo and de Souza Garcia, Renato and Silva, Williamson},
  journal={IEEE Revista Iberoamericana de Tecnologias del Aprendizaje}, 
  title={The Use of ChatGPT in Improving and Reviewing Scientific Paper Writing: An Exploratory Study}, 
  year={2024},
  volume={19},
  number={},
  pages={120-128},
  abstract={Software Engineering students enrolled in the Problem Solving I (PSI) course experience a Requirements Engineering (RE) approach to education. As part of one of the PSI assessments, students must develop a manuscript on RE. Following submission and presentation, we conducted an exploratory study to assess students’ perception of using ChatGPT to support improving and reviewing their scientific paper writing. Based on the results obtained from the participants (n = 40), we highlight the different ways to use ChatGPT to support the learning process. We conclude that ChatGPT and other AI tools can and should be explored by students and professors in the academic setting. However, evaluating the generated responses with caution and discernment is essential. Moreover, to enhance the overall experience, it is crucial to pose precise questions that yield accurate responses; this, in essence, constitutes the primary challenge.},
  keywords={Chatbots;Artificial intelligence;Software engineering;Problem-solving;Codes;Computer science education;Educational courses;ChatGPT;scientific paper writing;exploratory study;software engineering education},
  doi={10.1109/RITA.2024.3458848},
  ISSN={1932-8540},
  month={},}@INPROCEEDINGS{10929431,
  author={Dian Martha, Ati Suci and Widowati, Sri and Rahayu, Desy Puspa and Nursyawal, Muhammad Ilham and Hariz, Rayhan Rizqial},
  booktitle={2024 International Conference on Information Technology Systems and Innovation (ICITSI)}, 
  title={Examining Usability and Student Experience of ChatGPT as a Learning Tool on Moodle in Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={8-13},
  abstract={The integration of ChatGPT into Moodle has revolutionized teaching and learning practices. However, assessing the usability of this integration is essential for understanding its effectiveness and the challenges of using ChatGPT in Moodle, as well as its contribution to enhancing students' learning experiences. This study evaluates the usability of ChatGPT and students' experiences with it on the Moodle platform. Utilizing a mixed-methods approach, the research combines quantitative data from a survey-based questionnaire with qualitative insights from semi-structured interviews. A One-Group Posttest-Only design was employed in this research. Quantitative data were collected using the CUQ and UEQ+ questionnaires adapted for an Indonesian context. The CUQ score of 66.4 indicates that the usability of ChatGPT in Moodle is in the "fairly good" category. Nonetheless, specific areas require enhancement, including personality traits, error handling, and onboarding procedures. The results from the UEQ+ revealed positive outcomes across seven measured criteria, indicating favorable user experiences in aspects such as ease of use, efficiency, dependability, stimulation, intuitive use, content quality, and overall usability. Overall, students reported feeling notably supported by the presence of ChatGPT in Moodle; however, further improvements are needed to enhance the learning experience even more. The article's final section addresses the study's limitations and offers recommendations for future research.},
  keywords={Technological innovation;Education;Chatbots;User experience;Usability;Interviews;Information technology;Testing;ChatGPT;Moodle;usability;student experience;CUQ;UEQ+},
  doi={10.1109/ICITSI65188.2024.10929431},
  ISSN={2996-1084},
  month={Dec},}@INPROCEEDINGS{10690334,
  author={Bekkar, Hibat-Allah and Chtouki, Yousra},
  booktitle={2024 10th International Conference on Smart Computing and Communication (ICSCC)}, 
  title={Chatbots in Education: A Systematic Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={637-644},
  abstract={Artificial intelligence (AI) has rapidly transitioned from theoretical concepts to practical applications across various sectors, including education. This paper presents a systematic literature review focusing on the use of chatbots, particularly those based on large language models (LLMs), in educational settings. The review examines existing literature, surveys, and studies on the topic, exploring the capabilities of LLM-based chatbots in personalizing tutoring, automating assessments, and providing immediate feedback. Additionally, the paper discusses the challenges of integrating these technologies. Key findings highlight the significant potential of chatbots to enhance educational experiences by offering personalized learning, accessible tools, and interactive tutoring systems. We also gathered and visualized existing studies related to user acceptance and satisfaction using chatbots. The paper concludes with recommendations for future research to address existing challenges and optimize the use of LLM-based chatbots in education.},
  keywords={Surveys;Measurement;Large language models;Education;Data preprocessing;Focusing;Chatbots;Transformers;Real-time systems;Prompt engineering;Chatbots;e-Tutor;AI in Education;LLMs;Education;eLearning;Transformer Model},
  doi={10.1109/ICSCC62041.2024.10690334},
  ISSN={},
  month={July},}@INPROCEEDINGS{10894980,
  author={Raghi, K R and Sudha, K and M, Sreeram A and Joshua S, Steve},
  booktitle={2024 International Conference on Emerging Research in Computational Science (ICERCS)}, 
  title={Software Development Automation Using Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The Software Development Lifecycle (SDLC) is a structured process that guides the development of software projects, encompassing phases from planning to deployment. Traditionally, the SDLC has relied on manual input, making it prone to delays, errors, and inefficiencies. With the recent advancements in Generative AI (GenAI) and Large Language Models (LLMs) such as GPT, it is now feasible to automate substantial portions of the SDLC. This paper presents a novel approach to automating the SDLC using LLMs and the Langchain framework, aiming to streamline the entire software development process. By au-tomating key phases, including project planning, requirements gathering, code generation, testing, and deployment, this research explores how AI can minimize human intervention and accelerate software development timelines. The paper also discusses the potential advantages of AI-driven SDLC automation, such as improved efficiency, consistency, and scalability, while addressing challenges related to its integration. The proposed approach offers a glimpse into the future of software engineering, where AI plays a central role in transforming how software is developed and delivered.},
  keywords={Automation;Generative AI;Scientific computing;Scalability;Manuals;Software;Planning;Software development management;Testing;Software engineering;Software Development Lifecycle (SDLC);Generative AI (GenAI);Large Language Models (LLMs);GPT;Langchain;SDLC automation;AI-driven software development;code generation},
  doi={10.1109/ICERCS63125.2024.10894980},
  ISSN={},
  month={Dec},}@ARTICLE{10980222,
  author={Zhang, Zherui and Xu, Rongtao and Wang, Changwei and Xu, Wenhao and Chen, Shunpeng and Xu, Shibiao and Xu, Guangyuan and Guo, Li},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={DFMC:Feature-Driven Data-Free Knowledge Distillation}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Data-Free Knowledge Distillation (DFKD) enables knowledge transfer from teacher networks without access to the real dataset. However, generator-based DFKD methods often suffer from insufficient diversity or low-confidence in synthetic images, negatively impacting student network performance. This paper introduces DFMC, a generative feature-driven framework to mitigate the inherent limitations of DFKD. We propose exploiting semantic description between generative feature domains to guide augmentation strategies, avoiding random abstract inputs caused by inconsistent semantic quality. Then, by applying noise to the generative features, we produce contrastive learning pairs indirectly, limiting the sampling range of the feature domain to encourage the student network to learn domain-invariant features. Finally, we guide the student network to deeply mimic the teacher’s layer-wise implicit classification behavior for the augmented synthetic images. Extensive experiments across various datasets and downstream tasks demonstrate the effectiveness of DFMC, achieving significant improvements while preventing student networks from overfitting to semantic ambiguous images.},
  keywords={Semantics;Knowledge engineering;Generators;Contrastive learning;Training;Synthetic data;Noise;Knowledge transfer;Circuits and systems;Diversity methods;Data-Free Knowledge Distillation;Feature Augmentation;Contrastive Learning},
  doi={10.1109/TCSVT.2025.3565616},
  ISSN={1558-2205},
  month={},}@INPROCEEDINGS{10222927,
  author={Jin, Ying and Chen, Yinpeng and Wang, Jianfeng and Wang, Lijuan and Hwang, Jenq-Neng and Liu, Zicheng},
  booktitle={2023 IEEE International Conference on Image Processing (ICIP)}, 
  title={Zero-Shot Human-Object Interaction (HOI) Classification by Bridging Generative and Contrastive Image-Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={1970-1974},
  abstract={Existing studies in Human-Object Interaction (HOI) classification rely on costly human-annotated labels. The goal of this paper is to study a new zero-shot setup to remove the dependency on ground-truth labels. We propose a novel Heterogenous Teacher-Student (HTS) framework and a new loss function. HTS employs a generative pretrained image captioner as the teacher and a contrastive pre-trained classifier as the student. HTS combines the discriminability from generative pre-training and efficiency from contrastive pre-training. To facilitate learning of HOI in this setup, we introduce pseudo-label filtering which aggregates HOI probabilities from multiple regional captions to supervise the student. To enhance the multi-label learning of the student on few-shot classes, we design LogSumExp (LSE)-Sign loss which features a dynamic gradient re-weighting mechanism. Eventually, the student achieves 49.6 mAP on the HICO dataset without using ground truth, becoming a new state-of-the-art method that outperforms supervised approaches. Code is available.},
  keywords={Training;High-temperature superconductors;Image recognition;Codes;Filtering;Aggregates;HOI Classification;Scene Understanding;Image Captioning;Contrastive Pre-training},
  doi={10.1109/ICIP49359.2023.10222927},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10819214,
  author={Paredes-Vargas, Alfredo and Salinas-Llorca, Piero and Santisteban, José},
  booktitle={2024 IEEE 4th International Conference on Advanced Learning Technologies on Education & Research (ICALTER)}, 
  title={Natural Language Processing Algorithms for Academic Content Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={This study has conducted several activities to analyze and compare the performance of five Natural Language Processing (NLP) models: GPT-3, T5, ERNIE, BERT, and XLNet for generating academic content in universities located in Lima, Peru. Some NLP models, including GPT and BERT, were assessed based on accuracy, quality, speed, and customization capabilities. The research examined the use of various algorithms for academic tasks like essay and summary creation. The findings show that all models perform adequately; however, some excel in generating coherent content tailored to different academic styles, thereby optimizing the time of both students and teachers. In conclusion, the ERNIE model emerges as one of the best, as it enables the generation of diverse and high-quality content efficiently.},
  keywords={Measurement;Hands;Analytical models;Solid modeling;Accuracy;Education;Linguistics;Natural language processing;Reliability;Context modeling;algorithm;SCORM;NLP;academic content;higher education},
  doi={10.1109/ICALTER65499.2024.10819214},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10578742,
  author={Hammer, Sabine and Ottinger, Sarah and Zönnchen, Benedikt and Hohendanner, Michel and Hobelsberger, Martin and Thurner, Veronika},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={ChatGPT in Higher Education: Perceptions of Computer Science-Related Students}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={In the field of education ChatGPT has sparked both admiration and controversy. This study explores students' perspectives, specifically focusing on those in computer science-related fields. We investigated their motivations, trust, perceptions of utility, and reliability of ChatGPT by conducting two surveys-one at the beginning and another at the end of the semester. During the semester, students were encouraged to engage with ChatGPT. Our findings highlight the tool's multifaceted use in an academic settings, establishing it as a valuable resource for a variety of learning tasks. Most students have incorporated ChatGPT into their regular academic activities and view it as a beneficial aid. They perceive it as a multi-task solver and anticipate significant advancements in its writing assistance features in the near future. Many, not only attribute high accuracy to it but think that it adheres to appropriate content and structural norms. Our results suggest that active confrontation with ChatGPT enhances understanding of its capabilities, limitations and autoregressive nature. Consequently, we recommend an approach of informed engagement that includes the distinction between language processing and genuine language understanding and a carefully crafted terminology.},
  keywords={Accuracy;Terminology;Computational modeling;Focusing;Writing;Chatbots;Multitasking;ChatGPT;large language models;higher education;educational technology},
  doi={10.1109/EDUCON60312.2024.10578742},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10778529,
  author={Andonov, Venko},
  booktitle={2024 12th International Scientific Conference on Computer Science (COMSCI)}, 
  title={Enhancing University Students’ Activities with Interactive Immediate Feedback Using Customized LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={One of the significant issues for the students is getting timely feedback on their work so that they can understand their mistakes and improve their knowledge iteratively. There have been significant results in this area through automated evaluation, but they require a strongly defined structure of the expected results, which has its limitations. We propose using customized large language models as the core of an assignment evaluation software architecture that is used for automated evaluation and feedback generation on a variety of tasks in an introductory Java programming course. The model is implemented and tested, achieving significantly better results than using general-purpose models.},
  keywords={Java;Software architecture;Computational modeling;Large language models;Software;Programming profession;Context modeling;education;learning systems;large language models},
  doi={10.1109/COMSCI63166.2024.10778529},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10761147,
  author={Arin, Ikrar and Farkhan, Arsyil and Muhamad, Fahmi and Anjani, Fairuz Thahirah},
  booktitle={2024 2nd International Conference on Technology Innovation and Its Applications (ICTIIA)}, 
  title={Analysis of the Impact of ChatGPT Utilization on the Levels of Laziness and Productivity}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This study aims to analyze the effect of using ChatGPT on student laziness and productivity levels. The research focuses on how students utilize ChatGPT for various academic tasks such as research, writing, and problem-solving. Laziness is measured through self-reported procrastination and task avoidance behaviors. Using the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) model, we examined factors influencing ChatGPT adoption and its impact on academic behaviors. The research method used is quantitative, with data collected through distributed questionnaires to students who actively use ChatGPT. The results show that Habit and Price Value have a significant positive effect on Behavioral Intention, and Behavioral Intention has a significant positive effect on Student Productivity. However, Effort Expectancy, Facilitating Conditions, Hedonic Motivation, Performance Expectancy, and Social Influence have an insignificant negative effect on Behavioral Intention. Additionally, behavioral intention has an insignificant negative effect on the level of laziness, contrary to the hypothesis's direction.},
  keywords={Productivity;Technological innovation;Costs;Education;Distributed databases;Writing;Chatbots;Problem-solving;Artificial intelligence;ChatGPT;Student;Productivity;Academic Laziness;Technology Acceptance;Higher Education},
  doi={10.1109/ICTIIA61827.2024.10761147},
  ISSN={},
  month={Sep.},}@ARTICLE{11024027,
  author={Kumar, Akshi and Sharma, Aditi and Sangwan, Saurabh Raj},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={DynaMentA: Dynamic Prompt Engineering and Weighted Transformer Architecture for Mental Health Classification Using Social Media Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Mental health classification is inherently challenging, requiring models to capture complex emotional and linguistic patterns. Although large language models (LLMs) such as ChatGPT, Mental-Alpaca, and MentaLLaMA show promise, they are not trained on clinically grounded data and often overlook subtle psychological cues. Their predictions tend to overemphasize emotional intensity, while failing to capture contextually relevant indicators that are critical for accurate mental health assessment. This article introduces dynamic prompt engineering and weighted transformer architecture dynamic prompt engineering and weighted transformer architecture for mental health classification (DynaMentA), a novel dual-layer transformer framework that integrates the strengths of BioGPT and decoding-enhanced BERT with disentangled attention (DeBERTa) to address these challenges. BioGPT captures fine-grained biomedical indicators, while DeBERTa provides context-aware disambiguation. The ensemble mechanism dynamically weights their outputs, guided by a simulated feedback loop that refines the predictions during training. Unlike previous studies that treat classification statically, DynaMentA incorporates dynamic prompt engineering to better align with evolving linguistic and emotional signals. Evaluated on three benchmark datasets, DepSeverity, suicide versus depression classification natural language (SDCNL), and Dreaddit, DynaMentA achieves precision of 92.6%, 91.9% F1-score, and 0.94 AUC-ROC, consistently outperforming the existing benchmark, including general-purpose LLMs and domain-specific mental health models. This scalable and interpretable framework establishes a state-of-the-art methodology for computational mental health analysis in high-stakes applications, such as suicide risk assessment and crisis intervention and early detection of severe depressive episodes.},
  keywords={Mental health;Transformers;Biological system modeling;Linguistics;Prompt engineering;Computer architecture;Adaptation models;Depression;Computational modeling;Social networking (online);Artificial intelligence (AI) in mental health;deep learning for social systems;mental health classification;social media data analysis;weighted transformer models},
  doi={10.1109/TCSS.2025.3569400},
  ISSN={2329-924X},
  month={},}@INPROCEEDINGS{10825945,
  author={Wang, Bingjiao and Zhang, Yong and Zeng, Qinglei},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Resources Construction and LLM Fine-tuning for Education of Computer Science}, 
  year={2024},
  volume={},
  number={},
  pages={1655-1663},
  abstract={The limited inference capabilities of large language models in the field of computer science significantly hinder their application in computer education question-answering tasks. To address this issue, this paper focuses on three key areas: constructing domain-specific datasets, enhancing these datasets, and fine-tuning large language models to improve their performance in computer education question answering. The foundational dataset is sourced from university and online question banks, consisting of over 1600 entries, including 678 multiple-choice questions, 502 true/false questions, and 509 fill-in-the-blank questions. These questions span 11 disciplines, such as artificial intelligence, software engineering, and digital logic. Additionally, this study uses a large model for data augmentation, expanding the scope and scale of the base dataset. The augmented content is sourced from Baidu Baike and GPT-generated text, ultimately increasing the dataset to over 10000 entries. Based on this expanded dataset, the study employs LoRA technology to fine-tune the LLaMA2-7B model. Experimental results demonstrate that the performance of the fine-tuned model significantly outperforms other baselines across various task types.},
  keywords={Computational modeling;Large language models;Education;Web and internet services;Data augmentation;Data models;Question answering (information retrieval);Logic;Programming profession;Software engineering;data augmentation with large language models;fine-tuning;dataset construction;computer science Q&A},
  doi={10.1109/BigData62323.2024.10825945},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10987407,
  author={Seetaworn, Supitsara and Phenhiran, Phuree and Ngokpol, Perapard and Innoy, Montira and Ingboon, Sorayuth and Utasri, Tharathon and Takhom, Akkharawoot},
  booktitle={2025 IEEE International Conference on Cybernetics and Innovations (ICCI)}, 
  title={Leveraging Knowledge Graphs for Personalized Internship Recommendations: A Case Study on Software Engineering Courses}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Internships play a vital role in bridging academic learning with industry requirements. This paper presents a knowledge graph-based framework for generating personalized internship recommendations by integrating course syllabi, student competencies, and job descriptions. The approach leverages structured knowledge representation and graph traversal to dynamically match students' academic progress with relevant opportunities. Additionally, Large Language Models (LLMs) are employed for entity extraction to enhance recommendation accuracy. A case study involving Software Engineering subjects within a Programme of Innovative Engineering demonstrates the framework's ability to provide tailored internship suggestions and identify skill gaps. The results indicate that knowledge graphs offer a scalable and adaptable solution for aligning academic curricula with evolving industry needs.},
  keywords={Industries;Technological innovation;Accuracy;Large language models;Knowledge graphs;Cybernetics;Software engineering;Internship Recommendation;Skill Mapping;Knowledge Graph;Large Language Models;Graph Traversal},
  doi={10.1109/ICCI64209.2025.10987407},
  ISSN={},
  month={April},}@ARTICLE{10681241,
  author={Zhou, Yijie and Cheng, Xianhui and Zhang, Qiming and Wang, Lei and Ding, Wenchao and Xue, Xiangyang and Luo, Chunbo and Pu, Jian},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={ALGPT: Multi-Agent Cooperative Framework for Open-Vocabulary Multi-Modal Auto-Annotating in Autonomous Driving}, 
  year={2024},
  volume={},
  number={},
  pages={1-15},
  abstract={Large Language Models (LLMs) have achieved impressive progress in decision-making and task automation for intelligent agents. However, multiple agents must cooperate to complete tasks in complex real-world applications, such as auto-annotating in autonomous driving. The primary challenges lie in how multiple agents effectively communicate and collaborate in a multi-modal environment and how to automatically refine annotating results to reduce human intervention. These challenges also hinder LLMs from fully evolving into embodied intelligent agents. Driven by these motivations, we propose ALGPT, a multi-agent cooperative framework for open-vocabulary multi-modal auto-annotation in autonomous driving. ALGPT dynamically assembles agent teams with different roles, and agents cooperate to complete annotation tasks according to requirements. By leveraging Chain of Thought (CoT) and In-Context Learning (ICL) techniques, ALGPT's reasoning capabilities are enhanced, allowing it to develop suitable plans autonomously without human intervention. Furthermore, drawing from project management standards, we introduce project management documents and Standard Operating Procedures (SOPs), which further align ALGPT's behavior with human expectations and mitigate the impact of GPT illusions caused by the cascading effects of multiple GPTs. The source code will be released at https://github.com/Fudan-ProjectTitan/OpenAnnotate.},
  keywords={Annotations;Intelligent agents;Autonomous vehicles;Manuals;Cognition;Three-dimensional displays;Standards;Automatic annotation;autonomous driving;multi-agents;multi-modal data annotation},
  doi={10.1109/TIV.2024.3461651},
  ISSN={2379-8904},
  month={},}@INPROCEEDINGS{10605652,
  author={Dudysheva, Elena V. and Veryaev, Anatoly A.},
  booktitle={2024 4th International Conference on Technology Enhanced Learning in Higher Education (TELE)}, 
  title={Enhancing Interactive Information Support in Student Interdisciplinary Project Training: A Socio-Ecological Perspective of the Digital Environment}, 
  year={2024},
  volume={},
  number={},
  pages={246-251},
  abstract={Interactive information support tools play a pivotal role in project-based training, particularly when students engage in independent practical tasks outside the classroom over extended periods. This study investigates the socio-ecological conditions within the digital environment and explores the characteristics of interactive electronic tools that can enhance the effectiveness of independent work of students. The digital environment offers significant prospects for interactive educational content, educational communication, and information support. Socio-ecological aspects manifest through explicit and implicit interactions among actors within the educational process. These aspects can be effectively studied using hierarchical models within the learning ecology framework. Intelligent information support tools hold promises for enhancing teaching efficiency, especially when experts together lecturers engage in remote monitoring and asynchronous communication with students. Leveraging generative neural models for information support services further augments this potential. Additionally, integrating digital gamification methods based on mobile and immersive technologies complements intelligent learning tools. Experimental work with future teachers has revealed that socio-environmental factors significantly impact students' independent work and foster novel forms of communication within open digital environments. Ecological models of educational communication can serve as the foundation for socio-ecological education, facilitating personal adaptation to cultural and historical experiences.},
  keywords={Training;Asynchronous communication;Adaptation models;Biological system modeling;Ecology;Global communication;Cultural differences;interdisciplinary project training;interactive learning tools;intellectual tools of information support;effects of social ecology;learning ecology systems;digital gamification;semiotics of educational communications},
  doi={10.1109/TELE62556.2024.10605652},
  ISSN={},
  month={June},}@INPROCEEDINGS{10633294,
  author={Ahmed, Fatma Refaat and Al-Yateem, Nabeel and Rushdan, Esraa and Saifan, Ahmad Rajeh and Rahman, Syed and Mottershead, Richard and Hijazi, Heba and Subu, Muhammad Arsyad and Bani-Issa, Wegdan and Dias, Jacqueline Maria and Aburuz, Mohannad Eid},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Health Sciences students and educators experience with using ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1926-1928},
  abstract={This study investigates the experiences, challenges, and opportunities presented by ChatGPT AI in health sciences education, focusing on self-directed learning among students and educators at the University of Sharjah, UAE. Utilizing a descriptive qualitative research design, the study engaged participants through semi-structured interviews to explore diverse perspectives on ChatGPT's application in health sciences education. Results indicate mixed reactions: while users appreciate ChatGPT for its efficiency in academic tasks, concerns were raised about its offline functionality, linguistic inclusivity, ethical considerations, and potential impact on learning integrity and skill acquisition. Non-users expressed apprehension towards dependency on AI, diminished learning engagement, and academic dishonesty. The study concludes that while ChatGPT offers significant benefits in terms of resourcefulness and efficiency, its integration into educational settings necessitates careful consideration of accessibility, ethical standards, and the maintenance of academic integrity. These findings underline the need for a balanced approach to adopting AI technologies in education, highlighting the importance of addressing both the opportunities and challenges they present to foster an enriching learning environment.},
  keywords={Ethics;Education;Learning (artificial intelligence);Linguistics;Chatbots;Software;Maintenance;Artificial Intelligence;ChatGPT;Health Sciences Education;Technology Acceptance},
  doi={10.1109/COMPSAC61105.2024.00305},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{10542754,
  author={Baksa, Tanja and Konecki, Mario and Konecki, Mladen},
  booktitle={2024 12th International Conference on Information and Education Technology (ICIET)}, 
  title={High School Students' Perception of AI and Its Future Impact on Education}, 
  year={2024},
  volume={},
  number={},
  pages={215-219},
  abstract={Different artificial intelligence (AI) based technologies and systems are gaining in a variety of uses, including personal assistants, chatbots, different suggestion engines, smart appliances etc. Usage of this technology is accompanied by various positive views, but also by a fair share of skepticism. Since ChatGPT has been introduced, there have been rising debates regarding AI and its effects on education, employment, ethics, security, and other areas. One of the important questions is how young people view this new technology and all its implications. The purpose of this study was to learn more about how high school students view and feel about AI. Research regarding AI was conducted among 124 high school students in classes I through IV (aged 15 to 19). Although new technologies are something they embrace, students also find that no AI technology can completely replace human beings in education. Despite having different viewpoints on the matter, they are optimistic about new technologies and think that AI tools would be beneficial for future teaching and learning.},
  keywords={Chaos;Ethics;Education;Employment;Aging;Chatbots;Security;artificial intelligence;high school students;perception of AI;AI in education},
  doi={10.1109/ICIET60671.2024.10542754},
  ISSN={},
  month={March},}@ARTICLE{10659742,
  author={Zhou, Xin and Xu, Bowen and Kim, Kisub and Han, DongGyun and Nguyen, Hung Huu and Le-Cong, Thanh and He, Junda and Le, Bach and Lo, David},
  journal={IEEE Transactions on Software Engineering}, 
  title={Leveraging Large Language Model for Automatic Patch Correctness Assessment}, 
  year={2024},
  volume={50},
  number={11},
  pages={2865-2883},
  abstract={Automated Program Repair (APR) techniques have shown more and more promising results in fixing real-world bugs. Despite the effectiveness, APR techniques still face an overfitting problem: a generated patch can be incorrect although it passes all tests. It is time-consuming to manually evaluate the correctness of generated patches that can pass all available test cases. To address this problem, many approaches have been proposed to automatically assess the correctness of patches generated by APR techniques. These approaches are mainly evaluated within the cross-validation setting. However, for patches generated by a new or unseen APR tool, users are implicitly required to manually label a significant portion of these patches (e.g., 90% in 10-fold cross-validation) in the cross-validation setting before inferring the remaining patches (e.g., 10% in 10-fold cross-validation). To mitigate the issue, in this study, we propose LLM4PatchCorrect, the patch correctness assessment by adopting a large language model for code. Specifically, for patches generated by a new or unseen APR tool, LLM4PatchCorrect does not need labeled patches of this new or unseen APR tool for training but directly queries the large language model for code to get predictions on the correctness labels without training. In this way, LLM4PatchCorrect can reduce the manual labeling effort when building a model to automatically assess the correctness of generated patches of new APR tools. To provide knowledge regarding the automatic patch correctness assessment (APCA) task to the large language model for code, LLM4PatchCorrect leverages bug descriptions, execution traces, failing test cases, test coverage, and labeled patches generated by existing APR tools, before deciding the correctness of the unlabeled patches of a new or unseen APR tool. Additionally, LLM4PatchCorrect prioritizes labeled patches from existing APR tools that exhibit semantic similarity to those generated by new APR tools, enhancing the accuracy achieved by LLM4PatchCorrect for patches from new APR tools. Our experimental results showed that LLM4PatchCorrect can achieve an accuracy of 84.4% and an F1-score of 86.5% on average although no labeled patch of the new or unseen APR tool is available. In addition, our proposed technique significantly outperformed the prior state-of-the-art.},
  keywords={Computer bugs;Codes;Task analysis;Large language models;Feature extraction;Training;Manuals;Automatic patch correctness assessment;large language models of code;in-context learning},
  doi={10.1109/TSE.2024.3452252},
  ISSN={1939-3520},
  month={Nov},}@INPROCEEDINGS{10485053,
  author={Yin, Junqi and Dash, Sajal and Wang, Feiyi and Shankar, Mallikarjun Arjun},
  booktitle={SC23: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={FORGE: Pre-Training Open Foundation Models for Science}, 
  year={2023},
  volume={},
  number={},
  pages={1-13},
  abstract={Large language models (LLMs) are poised to revolutionize the way we conduct scientific research. However, both model complexity and pre-training cost are impeding effective adoption for the wider science community. Identifying suitable scientific use cases, finding the optimal balance between model and data sizes, and scaling up model training are among the most pressing issues that need to be addressed. In this study, we provide practical solutions for building and using LLM-based foundation models targeting scientific research use cases. We present an end-to-end examination of the effectiveness of LLMs in scientific research, including their scaling behavior and computational requirements on Frontier, the first Exascale supercomputer. We have also developed for release to the scientific community a suite of open foundation models called FORGE with up to 26B parameters using 257B tokens from over 200M scientific articles, with performance either on par or superior to other state-of-the-art comparable models. We have demonstrated the use and effectiveness of FORGE on scientific downstream tasks. Our research establishes best practices that can be applied across various fields to take advantage of LLMs for scientific discovery.},
  keywords={Training;Costs;Computational modeling;High performance computing;Buildings;Pressing;Data models},
  doi={10.1145/3581784.3613215},
  ISSN={2167-4337},
  month={Nov},}@INPROCEEDINGS{11018890,
  author={Venkatraman, S and Bamrah, Sumneet Kaur and Rani, D Pushgara},
  booktitle={2025 International Conference on Computing and Communication Technologies (ICCCT)}, 
  title={Automated Multilingual Translation of Exam Question Papers Using Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The research article undertakes an experimental analysis of utilizing conversational/generative AI tools for translating question papers from English to other Indian languages, as frequently seen in the question papers of many Indian universities/colleges and competitive recruitment examinations. This automation of question paper translation shall offload a portion of the workload of academic teachers who are into preparing question papers for various types of examinations. A desktop application of GUI type is developed leveraging artificial intelligence backed ChatGPT and Claude AI as a ready to use zero cost application.},
  keywords={Translation;Costs;Automation;Accuracy;Generative AI;Chatbots;Communications technology;Multilingual;Recruitment;Graphical user interfaces;AI;Artificial Intelligence;ChatGPT;Claude AI;conversational;generative;teachers},
  doi={10.1109/ICCCT63501.2025.11018890},
  ISSN={2995-3197},
  month={April},}@ARTICLE{10856008,
  author={Abdullahi, Shamsu and Usman Danyaro, Kamaluddeen and Zakari, Abubakar and Abdul Aziz, Izzatdin and Amila Wan Abdullah Zawawi, Noor and Adamu, Shamsuddeen},
  journal={IEEE Access}, 
  title={Time-Series Large Language Models: A Systematic Review of State-of-the-Art}, 
  year={2025},
  volume={13},
  number={},
  pages={30235-30261},
  abstract={Large Language Models (LLMs) have transformed Natural Language Processing (NLP) and Software Engineering by fostering innovation, streamlining processes, and enabling data-driven decision-making. Recently, the adoption of LLMs in time-series analysis has catalyzed the emergence of time-series LLMs, a rapidly evolving research area. Existing reviews provide foundational insights into time-series LLMs but lack a comprehensive examination of recent advancements and do not adequately address critical challenges in this domain. This Systematic Literature Review (SLR) bridges these gaps by analysing state-of-the-art contributions in time-series LLMs, focusing on architectural innovations, tokenisation strategies, tasks, datasets, evaluation metrics, and unresolved challenges. Using a rigorous methodology based on PRISMA guidelines, over 700 studies from 2020 to 2024 were reviewed, with 59 relevant studies selected from journals, conferences, and workshops. Key findings reveal advancements in architectures and novel tokenization strategies tailored for temporal data. Forecasting dominates the identified tasks with 79.66% of the selected studies, while classification and anomaly detection remain underexplored. Furthermore, the analysis reveals a strong reliance on datasets from the energy and transportation domains, highlighting the need for more diverse datasets. Despite these advancements, significant challenges persist, including tokenization inefficiencies, prediction hallucinations, and difficulties in modelling long-term dependencies. These issues hinder the robustness, scalability, and adaptability of time-series LLMs across diverse applications. To address these challenges, this SLR outlines a research roadmap emphasizing the improvement of tokenization methods, the development of mechanisms for capturing long-term dependencies, the mitigation of hallucination effects, and the design of scalable, interpretable models for diverse time-series tasks.},
  keywords={Time series analysis;Forecasting;Measurement;Tokenization;Systematic literature review;Systematics;Databases;Transformers;Search problems;Anomaly detection;Time-series;large language models;forecasting;tokenization;time-series LLMs},
  doi={10.1109/ACCESS.2025.3535782},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10736116,
  author={Jovanovic, Jelena},
  booktitle={2024 19th Conference on Computer Science and Intelligence Systems (FedCSIS)}, 
  title={The Interplay of Learning Analytics and Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={35-44},
  abstract={The widespread use of digital systems and tools in education has opened up opportunities for collecting, measuring, and analysing data about user (learner, teacher) interactions with a variety of learning resources and activities, with the ultimate objective of better understanding learning and advancing both learning outcomes and the overall learning experience. This promise motivated the development of Learning Analytics (LA) as a research and practical field and the use of insights derived from learning trace data for evidence-based decision making in a variety of educational settings. While LA has made a significant contribution to better understanding of learning and the environments in which it takes place, many open questions and challenges remain. Furthermore, new opportunities and challenges continue to emerge with the ever-changing modalities of teaching and learning, the latest of which are associated with the rapid development and accessibility of Artificial Intelligence (AI). Taking the cyclical model of LA as its exploration framework, this paper examines how key components of the LA model – namely data, methods, and actions – relate to and may benefit from the latest developments in AI, and especially Generative AI. Aiming for evidence-based analysis and discussion of the interplay between LA and AI, the paper relies on the latest empirical research in LA and the related research fields of AI in Education and Educational Data Mining.},
  keywords={Analytical models;Data privacy;Generative AI;Digital systems;Education;Decision making;Learning (artificial intelligence);Data models;Stakeholders;Public policy;Learning Analytics;Artificial Intelligence in Education;Generative AI},
  doi={10.15439/2024F5859},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10314211,
  author={Li, Yihao and Xu, Jialong and Zhu, Yinghua and Liu, Huashuo and Liu, Pan},
  booktitle={2023 10th International Conference on Dependable Systems and Their Applications (DSA)}, 
  title={The Impact of ChatGPT on Software Engineering Education: A Quick Peek}, 
  year={2023},
  volume={},
  number={},
  pages={595-596},
  abstract={Since its public launch at the end of 2022, ChatGPT has garnered global attention, showcasing the diverse capabilities of AI in tackling human tasks. Its rapid growth and widespread adoption have permeated every corner of our daily routine. This paper provides a quick peek at the impact of ChatGPT from the perspective of software engineering education. Specifically, to make our case study creative and interesting, we compare the impact answered by ChatGPT with the real feedback from existing literature. In this way, we explore the potential of ChatGPT as a teaching and learning tool in software engineering.},
  keywords={Education;Chatbots;Task analysis;Artificial intelligence;Software engineering;ChatGPT;software engineering;education;teaching and learning},
  doi={10.1109/DSA59317.2023.00087},
  ISSN={2767-6684},
  month={Aug},}@INPROCEEDINGS{10959761,
  author={Cheng, Yiduo and Wang, Tongbang},
  booktitle={2024 International Conference on Intelligent Education and Intelligent Research (IEIR)}, 
  title={The Impact of AIGC on Modern Education: Transforming Learning and Teaching Methods}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper examines the transformative influence of artificial intelligence generated content (AIGC) on modern education, focusing on its applications for both learners and educators. By leveraging cutting-edge algorithms such as GAN, Diffusion and Transformer, AIGC technologies like ChatGPT and DALL-E enable automated content creation, interactive learning, and multimedia generation. The paper explores the diverse roles AIGC plays in improving educational processes, proposing a methodology of using AIGC to assist learning and teaching. It also discusses the challenges, including the risk of misinformation, academic integrity concerns, the changing dynamics of teacher-student relationships and uncertain results. This study emphasizes the need for ethical integration and critical thinking to maximize the positive effects of AIGC in education.},
  keywords={Ethics;Education;Focusing;Transforms;Learning (artificial intelligence);Chatbots;Transformers;Market research;Planning;Fake news;artificial intelligence generated content (AIGC);chatGPT;personalized learning;adaptive teaching strategies;teacher-student dynamics},
  doi={10.1109/IEIR62538.2024.10959761},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10441978,
  author={Liao, Fei},
  booktitle={2023 3rd International Conference on Electronic Information Engineering and Computer (EIECT)}, 
  title={Public Perception and Sentiment of ChatGPT: Machine Learning Analysis on Weibo Posts}, 
  year={2023},
  volume={},
  number={},
  pages={579-583},
  abstract={ChatGPT, a large, pre-trained language model, which is developed by OpenAI, has exerted a great influence on society in all aspects since its launch. Knowing the adopters’ perspectives, preferences and sentiment is of critical significance for a technological company to promote and improve its products. Such social media as YouTube and Weibo, offer a convenient and time-saving channel for opinion mining. In this paper, 67,985 Weibo posts ranging from December 1, 2022 to September 30, 2023 were analyzed to explore the main topics and sentiment of users by employing machine learning techniques, including latent Dirichlet allocation (LDA) topic modeling algorithm and sentiment analysis. The results suggest that more than half of the adopters expressed a positive attitude towards all topics. However, a small portion of users have expressed worry and concern about the impact of ChatGPT on education and career compared to the other two topics, the development of the AI industry and the introduction of ChatGPT. This paper, while further proving the applicability of social media to explore the public’s opinion toward a new technology, offers insights into and contributes to the development and popularity of ChatGPT by figuring out Chinese users’ perspectives and sentiment.},
  keywords={Industries;Sentiment analysis;Social networking (online);Education;Blogs;Machine learning;Chatbots;topic modeling;sentiment analysis;ChatGPT;Weibo posts;machine learning},
  doi={10.1109/EIECT60552.2023.10441978},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10709091,
  author={Sihan, Sun and Shiming, Ma},
  booktitle={2024 IEEE 2nd International Conference on Image Processing and Computer Applications (ICIPCA)}, 
  title={Optimizing Logistic Regression for Predicting Teacher Job Satisfaction: An AI-Driven Approach to Faculty Development}, 
  year={2024},
  volume={},
  number={},
  pages={206-210},
  abstract={This study focuses on the development and optimization of a logistic regression model to predict teacher job satisfaction, emphasizing the role of artificial intelligence technology in enhancing the accuracy of educational data analysis. By applying Generative Adversarial Networks (GAN) and Random Forest algorithms to enhance and optimize data from 453 teacher surveys, this research demonstrates the effective use of computer models in addressing complex educational issues. The optimized model not only excels in predicting teacher satisfaction but also provides insights for educational management, aiding in the improvement of teachers' working environments and professional development. This work not only proves the potential of deep learning technologies in the field of education but also offers a new perspective and tools for future educational research and practices using artificial intelligence.},
  keywords={Surveys;Logistic regression;Analytical models;Data analysis;Computational modeling;Predictive models;Prediction algorithms;Generative adversarial networks;Data models;Artificial intelligence;Logistic regression model;teacher job satisfaction;Generative Adversarial Networks;Random Forest algorithm;artificial intelligence;educational data analysis},
  doi={10.1109/ICIPCA61593.2024.10709091},
  ISSN={},
  month={June},}@INPROCEEDINGS{10633327,
  author={Li, Yishu and Keung, Jacky and Ma, Xiaoxue and Chong, Chun Yong and Zhang, Jingyu and Liao, Yihan},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={LLM-Based Class Diagram Derivation from User Stories with Chain-of-Thought Promptings}, 
  year={2024},
  volume={},
  number={},
  pages={45-50},
  abstract={In agile requirements engineering, user stories are the primary means of capturing project requirements. However, deriving conceptual models, such as class diagrams, from user stories requires significant manual effort. This paper explores the potential of leveraging Large Language Models (LLMs) and a tailored Chain-of- Thought (CoT) prompting technique to automate this task. We conducted a comprehensive preliminary study to investigate different prompting techniques applied to the task. The study involved comparing LLM-based approaches with guided and unguided human extraction to evaluate the effectiveness of the proposed LLM-based techniques. Our findings demonstrate that LLM-based approaches, particularly when combined with well-crafted few-shot prompts, outperform guided human extraction in identifying classes. However, we also identified areas of suboptimal performance through qualitative analysis. The proposed CoT prompting technique offers a promising pathway to automate the derivation of class diagrams in agile projects, reducing the reliance on manual effort. Our study contributes valuable insights and directions for future research in this field.},
  keywords={Accuracy;Large language models;Computational modeling;Manuals;Software;Requirements engineering;Task analysis;Requirements engineering;user story;large language models;chain of thought prompting},
  doi={10.1109/COMPSAC61105.2024.00017},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{10892909,
  author={Ghimire, Sujan and Chowdhury, Muhtasim Alam and Tsang, Ryan and Yarnell, Richard and Heckert, Emma and Carpenter, Jaeden and Lin, Yu-Zheng and Mamun, Muntasir and DeMara, Ronald F. and Rafatirad, Setareh and Satam, Pratik and Salehi, Soheil},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Interactive Framework for Cybersecurity Education and Future Workforce Development}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This research-to-practice paper presents a novel pedagogical tool for hardware cybersecurity education and workforce development. The growing importance of hardware security has made it essential for individuals and organizations to understand hardware security principles and best practices. However, the current educational curriculum falls short of fulfilling these emerging demands due to the rapidly changing hardware security landscape and limited opportunities for hands-on training. To address these challenges, we propose and have developed the Interactive Hardware and Cybersecurity (I-HaC) Educational Framework, a pedagogical educational framework that supplements existing courses by leveraging generative AI for individualized instruction related to hardware and cybersecurity, data mining, and applied Machine Learning (ML), as well as data visualization to enhance cybersecurity education and workforce development. The framework is designed to be utilized by graduate and undergraduate Electrical and Computer Engineering (ECE) and Computer Science (CS) students for a comprehensive introduction to cybersecurity exploits and countermeasures in an interactive manner with hands-on components. Using I-HaC, we have developed tailored lab components for a diverse range of students and intend to release I-HaC as open-source for the benefit of the ECE and CS education community.},
  keywords={Training;Generative AI;Databases;Hardware security;Data visualization;Organizations;Machine learning;Ontologies;Computer security;Protection;National Vulnerability Database (NVD);Com-mon Vulnerability and Exposure (CVE);Common Weakness Enumeration (CWE);Hardware Security;Cybersecurity Education;Future Workforce Development},
  doi={10.1109/FIE61694.2024.10892909},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10708253,
  author={Rezgui, Kalthoum},
  booktitle={2024 10th International Conference on Control, Decision and Information Technologies (CoDIT)}, 
  title={Large Language Models for Healthcare: Applications, Models, Datasets, and Challenges}, 
  year={2024},
  volume={},
  number={},
  pages={2366-2371},
  abstract={Large Language Models (LLMs) are being increasingly explored and used in healthcare for their potential applications. These models show the capacity to impact clinical care, research, and medical education significantly. In this research, we shed light on the transformative potential of LLMs in reshaping the healthcare landscape, emphasizing their role in enhancing patient care, improving decision-making processes, and advancing medical research. While the application of LLMs in healthcare presents immense opportunities, this research, also, addresses critical challenges and limitations. Concerns regarding the accuracy, reliability, and ethical implications of LLMs in medical contexts are highlighted, emphasizing the need for continuous monitoring and evaluation to ensure patient safety and data privacy. By exploring the opportunities and challenges associated with LLMs in healthcare, this study contributes to a deeper understanding of the implications and future directions of this technology in the healthcare sector.},
  keywords={Ethics;Privacy;Technological innovation;Regulators;Large language models;Decision making;Medical services;Safety;Reliability;Medical diagnostic imaging;Healthcare;Large Language Models;Applications;Challenges},
  doi={10.1109/CoDIT62066.2024.10708253},
  ISSN={2576-3555},
  month={July},}@INPROCEEDINGS{10852443,
  author={Pasupuleti, Rajesh and Vadapalli, Ravi and Mader, Christopher and Timothy, Norris},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={Popular LLM-Large Language Models in Enterprise Applications}, 
  year={2024},
  volume={},
  number={},
  pages={125-131},
  abstract={For the public, understanding Large Language Models (LLMs) can be likened to recognizing how a well-trained assistant works—one that has read an extensive library of information on virtually every topic imaginable. Imagine an assistant that not only reads and remembers all this information but also learns the nuances of how words and ideas are connected across different contexts. This assistant can then use this knowledge to write articles, answer questions, compose emails, or even generate creative stories, all in a manner that feels surprisingly human. This capability comes from what's known as "transformer architecture," a type of design that helps the model pay attention to different parts of the text as it reads, making it adept at understanding and generating language. LLMs are a breakthrough in technology because they can understand and produce language with a level of subtlety and complexity that was previously unachievable, making them valuable tools across various industries. The paper aims to provide a comprehensive analysis of the transformative impact of LLMs across various enterprise sectors. It intends to contribute to the understanding of how LLMs can enhance efficiency, innovation, and decision-making processes in industries such as healthcare, finance, education, and in the software engineering sector. It also provides a comprehensive overview of current popular LLMs in Enterprise applications, in various domains, and discusses the Ethical, Technical, and Regulatory challenges, future trends, and developments in this dynamic field.},
  keywords={Industries;Technological innovation;Image recognition;Large language models;Finance;Medical services;Transformers;Market research;Libraries;Software engineering;Large Language Models (LLMs);Natural Language Processing (NLP);Popular LLMs;Transformer Architecture;Artificial Intelligence;Deep Learning;Machine Learning;Enterprise LLM applications},
  doi={10.1109/FLLM63129.2024.10852443},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10556432,
  author={Sergeyuk, Agnia and Lvova, Olga and Titov, Sergey and Serova, Anastasiia and Bagirov, Farid and Kirillova, Evgeniia and Bryksin, Timofey},
  booktitle={2024 IEEE/ACM 32nd International Conference on Program Comprehension (ICPC)}, 
  title={Reassessing Java Code Readability Models with a Human-Centered Approach}, 
  year={2024},
  volume={},
  number={},
  pages={225-235},
  abstract={To ensure that Large Language Models (LLMs) effectively support user productivity, they need to be adjusted. Existing Code Readability (CR) models can guide this alignment. However, there are concerns about their relevance in modern software engineering since they often miss the developers’ notion of readability and rely on outdated code. This research assesses existing Java CR models for LLM adjustments, measuring the correlation between their and developers’ evaluations of AI-generated Java code. Using the Repertory Grid Technique with 15 developers, we identified 12 key code aspects influencing CR that were consequently assessed by 390 programmers when labeling 120 AI-generated snippets. Our findings indicate that when AI generates concise and executable code, it’s often considered readable by CR models and developers. However, a limited correlation between these evaluations underscores the importance of future research on learning objectives for adjusting LLMs and on the aspects influencing CR evaluations included in predictive models.},
  keywords={Productivity;Surveys;Java;Codes;Correlation;Predictive models;Data models;Code Readability;Code Readability Models;Repertory Grid Technique;AI-Generated Code;Human-Computer Interaction},
  doi={},
  ISSN={2643-7171},
  month={April},}@INPROCEEDINGS{10589832,
  author={Barclay, Peter J and Sami, Ashkan},
  booktitle={2024 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Investigating Markers and Drivers of Gender Bias in Machine Translations}, 
  year={2024},
  volume={},
  number={},
  pages={455-464},
  abstract={Implicit gender bias in Large Language Models (LLMs) is a well-documented problem that needs to be better understood in order to be addressed effectively. Implications of gender introduced into automatic translations can perpetuate real-world biases in Software Engineering and other domains. However, some LLMs use heuristics or post-processing to mask such bias, which makes investigation more difficult. Here, we examine bias in language models via back-translation, using the DeepL online translation service to investigate the bias evinced when repeatedly translating a set of 56 Software Engineering tasks used in a previous study. Each statement starts with ‘she’, and is translated first into a ‘genderless’ intermediate language then back into English; we then examine pronoun-choice in the back-translated texts. We believe this approach provides a useful alternative to large-scale surveys in mapping biases. We expand prior research in the following ways: (1) by comparing results across five intermediate languages, namely Finnish, Indonesian, Estonian, Turkish and Hungarian; (2) by proposing a novel metric for assessing the variation in gender implied in repeated translations of the same phrase, avoiding the over-interpretation of individual pronouns, apparent in earlier work; (3) by investigating sentence features that drive bias; (4) and by comparing results from three time-lapsed datasets to establish the reproducibility of the approach. We found that some languages display similar patterns of pronoun use, falling into three loose groups, but that patterns vary between groups; this underlines the need to work with multiple languages. We also identify the main verb appearing in a sentence as a likely significant driver of implied gender in the translations. Moreover, we see a good level of replicability in the results, and establish that our variation metric proves robust despite an obvious change in the behaviour of the DeepL translation API during the course of the study. These results show that the back-translation method can provide further insights into bias in language models.},
  keywords={Surveys;Analytical models;Sensitivity;Software;Reproducibility of results;Machine translation;Task analysis;back-translation;machine translation;large language model;gender bias},
  doi={10.1109/SANER60148.2024.00054},
  ISSN={2640-7574},
  month={March},}@INPROCEEDINGS{10765115,
  author={Siddiq, Mohammed Latif and Da Silva Santos, Joanna Cecilia and Devareddy, Sajith and Muller, Anna},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW)}, 
  title={Sallm: Security Assessment of Generated Code}, 
  year={2024},
  volume={},
  number={},
  pages={54-65},
  abstract={With the growing popularity of Large Language Models (LLMs) in software engineers’ daily practices, it is important to ensure that the code generated by these tools is not only functionally correct but also free of vulnerabilities. Although LLMs can help developers to be more productive, prior empirical studies have shown that LLMs can generate insecure code. There are two contributing factors to the insecure code generation. First, existing datasets used to evaluate LLMs do not adequately represent genuine software engineering tasks sensitive to security. Instead, they are often based on competitive programming challenges or classroom-type coding tasks. In real-world applications, the code produced is integrated into larger codebases, introducing potential security risks. Second, existing evaluation metrics primarily focus on the functional correctness of the generated code while ignoring security considerations. Therefore, in this paper, we described Sallm, a framework to benchmark LLMs’ abilities to generate secure code systematically. This framework has three major components: a novel dataset of security-centric Python prompts, configurable assessment techniques to evaluate the generated code, and novel metrics to evaluate the models’ performance from the perspective of secure code generation.CCS Concepts• Security and privacy → Software security engineering; • Software and its engineering → Software verification and validation; • Computing methodologies → Natural language processing.},
  keywords={Measurement;Codes;Large language models;Programming;Transformers;Software;Natural language processing;Security;Software engineering;Python;security evaluation;large language models;pre-trained transformer model;metrics},
  doi={},
  ISSN={2151-0849},
  month={Oct},}@INPROCEEDINGS{10298494,
  author={Dipongkor, Atish Kumar and Moran, Kevin},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={A Comparative Study of Transformer-Based Neural Text Representation Techniques on Bug Triaging}, 
  year={2023},
  volume={},
  number={},
  pages={1012-1023},
  abstract={Bug report management has been shown to be an important and time consuming software maintenance task. Often, the first step in managing bug reports is related to triaging a bug to the appropriate developer who is best suited to understand, localize, and fix the target bug. Additionally, assigning a given bug to a particular part of a software project can help to expedite the fixing process. However, despite the importance of these activities, they are quite challenging, where days can be spent on the manual triaging process. Past studies have attempted to leverage the limited textual data of bug reports to train text classification models that automate this process - to varying degrees of success. However, the textual representations and machine learning models used in prior work are limited by their expressiveness, often failing to capture nuanced textual patterns that might otherwise aid in the triaging process. Recently, large, transformer-based, pre-tained neural text representation techniques (i.e., large language models or LLMs) such as BERT and CodeBERT have achieved greater performance with simplified training procedures in several natural language processing tasks, including text classification. However, the potential for using these techniques to improve upon prior approaches for automated bug triaging is not well studied or understood. Therefore, in this paper we offer one of the first investigations that fine-tunes transformer-based language models for the task of bug triaging on four open source datasets, spanning a collective 53 years of development history with over 400 developers and over 150 software project components. Our study includes both a quantitative and qualitative analysis of effectiveness. Our findings illustrate that DeBERTa is the most effective technique across the triaging tasks of developer and component assignment, and the measured performance delta is statistically significant compared to other techniques. However, through our qualitative analysis, we also observe that each technique possesses unique abilities best suited to certain types of bug reports.},
  keywords={Training;Software maintenance;Computer bugs;Text categorization;Manuals;Machine learning;Transformers;Bug Triaging;Transformer;LLMs;Text-Embedding;DL4SE},
  doi={10.1109/ASE56229.2023.00217},
  ISSN={2643-1572},
  month={Sep.},}@INPROCEEDINGS{10554146,
  author={Ivanov, Rosen and Velkova, Victoria},
  booktitle={2024 IEEE International Conference on Automation, Quality and Testing, Robotics (AQTR)}, 
  title={Microservice-Based Interface to ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In today’s digitally connected world, the emergence of conversational artificial intelligence powered by generative language models has ushered in a new era of human-computer interaction. Chatbots using these technologies are increasingly being used in a variety of scientific as well as social domains. These intelligent conversational agents, powered by advances in generative language models, offer a wide range of applications from customer support and healthcare to software development and education. This paper discusses the development of a microservice that works as an interface to ChatGPT through the GPT API. The goal is to facilitate the integration of next generation chatbots to distributed architecture services. Access to the microservice is implemented using an Advanced Message Queuing Protocol (AMQP) message broker. To conduct the experiments, a microservice was developed that provides a REST interface to the proposed microservice for clients that do not support the AMQP protocol.},
  keywords={Protocols;Microservice architectures;Chatbots;Museums;Reliability;Robots;Programming profession;Chatbots;Microservices;MSA;AMQP;GPT API},
  doi={10.1109/AQTR61889.2024.10554146},
  ISSN={1844-7872},
  month={May},}@INPROCEEDINGS{10678704,
  author={Mitra, Modhurita and de Vos, Martine G. and Cortinovis, Nicola and Ometto, Dawa},
  booktitle={2024 IEEE 20th International Conference on e-Science (e-Science)}, 
  title={Generative AI for Research Data Processing: Lessons Learnt From Three Use Cases}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={There has been enormous interest in generative AI since ChatGPT was launched in 2022. However, there are concerns about the accuracy and consistency of the outputs of generative AI. We have carried out an exploratory study on the application of this new technology in research data processing. We identified tasks for which rule-based or traditional machine learning approaches were difficult to apply, and then performed these tasks using generative AI.We demonstrate the feasibility of using the generative AI model Claude 3 Opus in three research projects involving complex data processing tasks:1)Information extraction: We extract plant species names from historical seedlists (catalogues of seeds) published by botanical gardens.2)Natural language understanding: We extract certain data points (name of drug, name of health indication, relative effectiveness, cost-effectiveness, etc.) from documents published by Health Technology Assessment organisations in the EU.3)Text classification: We assign industry codes to projects on the crowdfunding website Kickstarter.We share the lessons we learnt from these use cases: How to determine if generative AI is an appropriate tool for a given data processing task, and if so, how to maximise the accuracy and consistency of the results obtained.},
  keywords={Industries;Drugs;Accuracy;Crowdfunding;Codes;Generative AI;Machine learning;Generative AI;Large Language Models;artificial intelligence;data processing;accuracy of results;consistency of results;reliability of research method},
  doi={10.1109/e-Science62913.2024.10678704},
  ISSN={2325-3703},
  month={Sep.},}@INPROCEEDINGS{10555675,
  author={Colavito, Giuseppe and Lanubile, Filippo and Novielli, Nicole and Quaranta, Luigi},
  booktitle={2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR)}, 
  title={Leveraging GPT-like LLMs to Automate Issue Labeling}, 
  year={2024},
  volume={},
  number={},
  pages={469-480},
  abstract={Issue labeling is a crucial task for the effective management of software projects. To date, several approaches have been put forth for the automatic assignment of labels to issue reports. In particular, supervised approaches based on the fine-tuning of BERT-like language models have been proposed, achieving state-of-the-art performance. More recently, decoder-only models such as GPT have become prominent in SE research due to their surprising capabilities to achieve state-of-the-art performance even for tasks they have not been trained for. To the best of our knowledge, GPT-like models have not been applied yet to the problem of issue classification, despite the promising results achieved for many other software engineering tasks. In this paper, we investigate to what extent we can leverage GPT-like LLMs to automate the issue labeling task. Our results demonstrate the ability of GPT-like models to correctly classify issue reports in the absence of labeled data that would be required to fine-tune BERT-like LLMs.CCS CONCEPTS• Software and its engineering → Documentation; Software evolution; Maintaining software; • Information systems → Clustering and classification;},
  keywords={Annotations;Computational modeling;Scalability;Supervised learning;Manuals;Software;Data models;LLM;Issue Labeling;GPT;Software Maintenance and Evolution;Labeling Unstructured Data},
  doi={},
  ISSN={2574-3864},
  month={April},}@ARTICLE{10381724,
  author={Vives, Luis and Cabezas, Ivan and Vives, Juan Carlos and Reyes, Nilton German and Aquino, Janet and Cóndor, Jose Bautista and Altamirano, S. Francisco Segura},
  journal={IEEE Access}, 
  title={Prediction of Students’ Academic Performance in the Programming Fundamentals Course Using Long Short-Term Memory Neural Networks}, 
  year={2024},
  volume={12},
  number={},
  pages={5882-5898},
  abstract={In recent years, there has been evidence of a growing interest on the part of universities to know in advance the academic performance of their students and allow them to establish timely strategies to avoid desertion and failure. One of the biggest challenges to predicting student performance is presented in the course “Programming Fundamentals” of Computer Science, Software Engineering, and Information Systems Engineering careers in Peruvian universities for high student dropout rates. The objective of this research was to explore the efficiency of Long-Short Term Memory Networks (LSTM) in the field of Educational Data Mining (EDM) to predict the academic performance of students during the seventh, eighth, twelfth, and sixteenth weeks of the academic semester, which allowed us to identify students at risk of failing the course. This research compares several predictive models, such as Deep Neural Network (DNN), Decision Tree (DT), Random Forest (RF), Logistic Regression (LR), Support Vector Classifier (SVM), and K-Nearest Neighbor (KNN). A major challenge machine learning algorithms face is a class imbalance in a dataset, resulting in over-fitting to the available data and, consequently, low accuracy. We use Generative Adversarial Networks (GAN) and Synthetic Minority Over-sampling Technique (SMOTE) to balance the data needed in our proposal. From the experimental results based on accuracy, precision, recall, and F1-Score, the superiority of our model is verified concerning a better classification, with 98.3% accuracy in week 8 using LSTM-GAN, followed by DNN-GAN with 98.1% accuracy.},
  keywords={Predictive models;Radio frequency;Prediction algorithms;Machine learning algorithms;Static VAr compensators;Classification algorithms;Data mining;Educational data mining;generative adversarial networks;long-short term memory;synthetic minority over-sampling technique},
  doi={10.1109/ACCESS.2024.3350169},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10837600,
  author={Mormul, Yevhenii and Przybyszewski, Jan and Siriburanon, Teerachot and Healy, John and Cuffe, Paul},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Gauging the Capability of Artificial Intelligence Chatbot Tools to Answer Textbook Coursework Exercises in Circuit Design Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Powerful chatbots, based on intensively-trained large language models, have recently become available for consumer use. The ability of such chatbots to provide credible textual responses to sophisticated engineering problems has been demonstrated in various subfields. This paper seeks to gauge the extent to which such a chatbot can be prompted to complete a set of homework and project exercises for university-level courses in analog, digital, mixed -signal, and signal processing classes. The purpose of this paper is to delineate and clearly articulate the present capabilities of artificial intelligence tools to complete coursework taks across the field of circuit theory. Building on these research findings, this paper suggests practical ways to mitigate artifical intelligence chatbot tools' disription to academic integrity and genuine learning in universities.},
  keywords={Training;Large language models;Buildings;Signal processing;Chatbots;Circuit synthesis;Information technology;Standards;Circuit theory},
  doi={10.1109/ITHET61869.2024.10837600},
  ISSN={2473-2060},
  month={Nov},}
@INPROCEEDINGS{10401818,
  author={Yousri, Ramez and Safwat, Soha},
  booktitle={2023 International Conference on Computer and Applications (ICCA)}, 
  title={How Big Can It Get? A comparative analysis of LLMs in architecture and scaling}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Large Language models (LLMs) are increasingly becoming an integral part of our society. They play important roles in education, marketing and healthcare. These models exhibit emergent behavior when scaled, however such scaling might have its disadvantages as well. As a way to combat such disadvantages, new architectures and types of models have been designed. In this paper, we show the different architectural decisions when it comes to building LLMs as well as discuss how big a model needs to be in order to be specialized in a certain area or sector. We show that most specialized models are small in size yet outperform larger models in specific domain tasks.},
  keywords={Analytical models;Computational modeling;Computer architecture;Medical services;Transformers;Data models;Task analysis;Large language models;Transformers;NLP;Specialized models;LLM size},
  doi={10.1109/ICCA59364.2023.10401818},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11016366,
  author={Mohammed, Crista and Sarjusingh, Wayne and Rocke, Sean},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Uses of Generative AI in Engineering, Technology, and Computing Classrooms: Findings From the IEEE FIE Conference Proceedings}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Generative AI (GAI) can be leveraged to good effect in engineering, technology, and computing (ETC) classrooms but with pre-conditions; among these include teacher preparedness. One dimension of teacher preparedness is knowing how GAI is used in classrooms like their own. This paper responds to that need. The paper surveys the literature to answer three questions: in formal instructional interventions, what were the tasks for which GAI was used; what methods did scholars use to evaluate the GAI instructional set; and what were some of the identified challenges and opportunities regarding the use of GAI in ETC classrooms? Taking account of quality and recency of scholarship, and the need to focus on ETC practices, a rapid review of IEEE FIE conference proceedings for 2023 and 2024 was undertaken. Of the 1,181 papers published in both conference proceedings, and after a two-stage screening process, 20 papers were selected for synthesis. Of the 20 papers examined in this review, we found seven patterns of research design. The most common was the learning and teaching intervention followed by gathering student feedback. While we expect that a bigger corpus will yield additional research designs, these seven provide a start for defining a typology of research design investigating student use of GAI. The review revealed eight distinct categories of use ranging from software development, the most common, with over 26 distinct tasks, to data classification and data analysis, each with two distinct tasks. GAI was found to be used for many low-cognitive tasks like generating bibliographies to cognitivelydemanding uses like design and modeling. The studies reported recurring concerns about using GAI, like perpetuating bias, and hallucinations. One striking empirical finding is that previous ways of accomplishing ETC tasks, like using MATLAB and hand analysis, may be quicker and easier than using GAI. The scholarship advocates for broad and deep GAI literacy programs, addressing GAI abilities, limitations, ethics of use, and prompt design. Moreover, instructors are encouraged to be GAI literate themselves. This know-how is central to designing meaningful GAI-based tasks which seek to prepare students for an increasingly AI-infused world and workplace.},
  keywords={Surveys;Hands;Ethics;Reviews;Generative AI;Scholarships;Employment;Engineering education;MATLAB;Software development management;engineering education;engineering;technology and computing education;generative AI},
  doi={10.1109/EDUCON62633.2025.11016366},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10661085,
  author={Williams, Randi and Ali, Safinah and Alcantara, Raúl and Burghleh, Tasneem and Alghowinem, Sharifa and Breazeal, Cynthia},
  booktitle={2024 19th ACM/IEEE International Conference on Human-Robot Interaction (HRI)}, 
  title={Doodlebot: An Educational Robot for Creativity and AI Literacy}, 
  year={2024},
  volume={},
  number={},
  pages={772-780},
  abstract={Today, Artificial Intelligence (AI) is prevalent in everyday life, with emerging technologies like AI companions, autonomous vehicles, and AI art tools poised to significantly transform the future. The development of AI curricula that shows people how AI works and what they can do with it is a powerful way to prepare everyone, and especially young learners, for an increasingly AI-driven world. Educators often employ robotic toolkits in the classroom to boost engagement and learning. However, these platforms are generally unsuitable for young learners and learners without programming expertise. Moreover, these platforms often serve as either programmable artifacts or pedagogical agents, rarely capitalizing on the opportunity to support students in both capacities. We designed Doodlebot, a mobile social robot for hands-on AI education to address these gaps. Doodlebot is an effective tool for exploring AI with grade school (K-12) students, promoting their understanding of AI concepts such as perception, representation, reasoning and generation. We begin by elaborating Doodlebot’s design, highlighting its reliability, user-friendliness, and versatility. Then, we demonstrate Doodlebot’s versatility through example curricula about AI character design, autonomous robotics, and generative AI accessible to young learners. Finally, we share the results of a preliminary user study with elementary school youth where we found that the physical Doodlebot platform was as effective and user-friendly as the virtual version. This work offers insights into designing interactive educational robots that can inform future AI curricula and tools.CCS CONCEPTS• Human-centered computing → Collaborative and social computing devices.},
  keywords={Social computing;Educational robots;Statistical analysis;Social robots;Prototypes;Transforms;Reliability engineering;Social robots;education;creativity;collaboration},
  doi={},
  ISSN={2167-2121},
  month={March},}@ARTICLE{10991962,
  author={Xue, Mingfu and Chen, Kewei and Zhang, Leo Yu and Zhang, Yushu and Liu, Weiqiang},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={An Active Authorization Control Method for Deep Reinforcement Learning Model Based on GANs and Adaptive Trigger}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In recent years, deep reinforcement learning (DRL) has found widespread applications across diverse scenarios. Since the DRL training process requires substantial time and financial costs, well-trained DRL policies should be considered as intellectual property (IP) which deserves proper protection. However, to date, there are only a few studies on IP protection on DRL and the existing methods are limited to passive copyright verification. In this paper, we propose the first active authorization control method for DRL which can proactively protect deep reinforcement learning policy. The DRL policy trained with this method can be used by authorized users normally, but cannot be used by unauthorized users (i.e., the protected policy’s performance for unauthorized users is paralyzed). Specifically, we train a trigger injection network and a discriminator network based on generative adversarial networks (GANs). During the DRL policy training phase, we use trigger injection network to insert sample-specific triggers to all observations and use triggered observations to train the protected policy. Our approach is applicable across various deep reinforcement learning algorithms. We conduct effectiveness experiments on different DRL policies trained using different DRL algorithms, and the experimental results revealed that the performance of authorized users is on par with the performance of clean DRL policy trained normally (baseline), whereas the performance of unauthorized users significantly deviates from that of the baseline. Specifically, the authorized performance of protected Breakout-DQN, Breakout-A2C, MsPacman-DQN and MsPacman-A2C policies are 416.4 (baseline 397.8), 403.0 (baseline 415.0), 2552.0 (baseline 2472.0), and 1964.0 (baseline 1828.0). Comparatively, the unauthorized performance of protected Breakout-DQN, Breakout-A2C, MsPacman-DQN and MsPacman-A2C policies are only 4.4 (baseline 397.8), 2.0 (baseline 415.0), 74.0 (baseline 2472.0), and 514.0 (baseline 1828.0). Furthermore, the experiments demonstrate that the proposed method exhibits robustness against pruning, fine-tuning, and adaptive attacks.},
  keywords={Watermarking;Authorization;Deep reinforcement learning;Training;Protection;Intellectual property;Approximation algorithms;Data mining;Autoencoders;Robustness;Trustworthy Artificial Intelligence;deep reinforcement learning;intellectual property protection;active authorization control;backdoor attack},
  doi={10.1109/TIFS.2025.3567915},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{11016386,
  author={Johri, Aditya and Schleiss, Johannes and Ranade, Nupoor},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Lessons for GenAI Literacy from a Field Study of Human-GenAI Augmentation in the Workplace}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Generative artificial intelligence (GenAI) is increasingly becoming a part of work practices across the technology industry and being used across a range of industries. This has necessitated the need to better understand how GenAI is being used by professionals in the field so that we can better prepare students for the workforce. An improved understanding of the use of GenAI in practice can help provide guidance on the design of GenAI literacy efforts including how to integrate it within courses and curriculum, what aspects of GenAI to teach, and even how to teach it. This paper presents a field study that compares the use of GenAI across three different functions - product development, software engineering, and digital content creation - to identify how GenAI is currently being used in the industry. This study takes a human augmentation approach with a focus on human cognition and addresses three research questions: how is GenAI augmenting work practices; what knowledge is important and how are workers learning; and what are the implications for training the future workforce. Findings show a wide variance in the use of GenAI and in the level of computing knowledge of users. In some industries GenAI is being used in a highly technical manner with deployment of fine-tuned models across domains. Whereas in others, only off-the-shelf applications are being used for generating content. This means that the need for what to know about GenAI varies, and so does the background knowledge needed to utilize it. For the purposes of teaching and learning, our findings indicated that different levels of GenAI understanding needs to be integrated into courses. From a faculty perspective, the work has implications for training faculty so that they are aware of the advances and how students are possibly, as early adopters, already using GenAI to augment their learning practices.},
  keywords={Industries;Training;Generative AI;Employment;Learning (artificial intelligence);Intellectual property;Human augmentation;Product development;Engineering education;Software engineering;generative artificial intelligence;engineering education;computing education;AI literacy;workplace studies},
  doi={10.1109/EDUCON62633.2025.11016386},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10406630,
  author={Chu, R. and Lim, S. C. Johnson},
  booktitle={2023 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)}, 
  title={Education and Training for Future Engineering Teachers in the Age of Artificial Intelligence: A Bibliometric Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={416-420},
  abstract={Engineering teachers play an important role in engineering education to develop the next generation of engineering human resources. In this sense, the education and training of engineering teachers are important. The recent development of artificial intelligence (AI), especially generative AI, has impacted many industries, including education. Thus, this paper aimed to explore existing research focuses and trends in the field of education and training of future engineering teachers in the age of artificial intelligence (AI). Based on scholarly publications obtained between the years 2018 and 2023, a bibliometric analysis has been performed, which includes analysis such as keyword co-occurrence analysis and thematic-based content analysis. The analysis in this paper is performed using bibliometric software named VOSViewer. The results from the analysis have identified five research hotspots in this field based on keyword clustering, with each hotspot discussed. Finally, this paper concludes with some elaborations on limitations and future work.},
  keywords={Training;Bibliometrics;Market research;Software;Artificial intelligence;Engineering education;Next generation networking;Artificial intelligence;education;training;engineering teachers;bibliometric analysis},
  doi={10.1109/IEEM58616.2023.10406630},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10605444,
  author={Gao, Bo and Wei, Qingsong and Liu, Yong and Goh, Rick Siow Mong},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Unveiling the Potential of ChatGPT in Detecting Machine Unauditable Bugs in Smart Contracts: A Preliminary Evaluation and Categorization}, 
  year={2024},
  volume={},
  number={},
  pages={1481-1486},
  abstract={Smart contracts are becoming an integral part of decentralized applications, yet exploitable bugs in these contracts pose significant threats, often leading to considerable monetary losses. Traditional tools often struggle to identify these bugs, with a recent study indicating that 80% of them are classified as Machine Unauditable Bugs (MUBs), rendering conventional approaches ineffective in addressing such cases. In practice, identifying MUBs requires seasoned expertise and is time-intensive, often stalling project progress. In this work, we present a preliminary evaluation of the performance of ChatGPT, a state-of-the-art large language model, especially in detecting MUBs. Our study first investigates the effectiveness and limitations of ChatGPT in detecting various categories of MUBs with two kinds of prompts, general prompts and guidance prompts, on 246 real-world MUBs collected from Code4rena between 2021 and 2022. Subsequently, we compared the leading tool, SPCON, with ChatGPT on 17 CVE contracts with access control issues (a category of MUBs), and found that ChatGPT exhibited comparable performance but better usability over SPCON. We summarize the implications of our findings for the broader community, shedding light on the model’s capabilities, limitations and potentials in detecting smart contract bugs. Our evaluation dataset and results are released at Github1.},
  keywords={Access control;Large language models;Computer bugs;Smart contracts;Chatbots;Rendering (computer graphics);Decentralized applications;ChatGPT;Exploitable bugs;Effortless usage},
  doi={10.1109/CAI59869.2024.00266},
  ISSN={},
  month={June},}@INPROCEEDINGS{10429948,
  author={Kumar, Yulia and Gordon, Zachary and Morreale, Patricia and Li, J. Jenny and Hannon, Brendan},
  booktitle={2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security Companion (QRS-C)}, 
  title={Love the Way You Lie: Unmasking the Deceptions of LLMs}, 
  year={2023},
  volume={},
  number={},
  pages={875-876},
  abstract={Within the dynamic realm of Artificial Intelligence (AI), models like ChatGPT, Bard, and Bing are renowned for replicating human language. However, their emergence sparks debate over biases and trustworthiness. This research delves into the predominant inaccuracies in chatbots that tend to mislead novices and explores the possibility of establishing an AI Reliability (AIR) framework to fortify trust in these entities. Errors are categorized as factual inaccuracies, misinformation, fabricated data, and deviations from topics, among others. The in-progress AIR Framework offers a meticulous approach to assess chatbot accuracy, leveraging the experiences of nearly 100 CS/IT students with mainly ChatGPT. Recognizing the limitations and hallucinations of these models is essential as they become integral to our lives, underscoring the imperative for responsible and reliable AI.},
  keywords={Atmospheric modeling;Software quality;Chatbots;Software reliability;Sparks;Security;Artificial intelligence;Large Language Models (LLMs);AI Reliability (AIR) Framework;AI bias;AI Misinformation;Ethics of AI},
  doi={10.1109/QRS-C60940.2023.00049},
  ISSN={2693-9371},
  month={Oct},}@INPROCEEDINGS{10725418,
  author={De Silva, D. I. and Athukorala, K. S. N.},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Sinhala-Centric Java Assistance Tool for Entry-Level Programmers}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Programming plays a significant role in computer science and information technology. For example, novice programmers often find it challenging to use the Java programming language due to language barriers. Creating a learning environment that considers the linguistic needs of students can be highly beneficial. By adapting our teaching practices to accommodate different types of learners, we can improve performance. Therefore, this study suggests methods for learning programming using Sinhala as the medium of instruction. Azure Translator is integrated to translate Sinhala questions into English and provide Sinhala explanations, enabling users to receive Java code customized to their specific needs. The system uses ChatGPT 4 integration to generate code. Additionally, the system can transform English code explanations into Sinhala, giving learners access to instructional material whenever they need it. The created tool explains programming principles, logic, and syntax in both Sinhala and English for Java code segments in a simple, concise, and thorough manner. Furthermore, the Java-based Sinhala assistance tool offers explanations of essential Java programming concepts in Sinhala, ensuring comprehensive coverage of both basic and more complex topics. After entering a question in Sinhala, the system displays the relevant Java code along with explanations in Sinhala.},
  keywords={Java;Codes;Transforms;Programming;Syntactics;Linguistics;Chatbots;Logic;Information technology;Faces;Sinhala;Java;assistance tool;entry-level;programmers},
  doi={10.1109/ICCCNT61001.2024.10725418},
  ISSN={2473-7674},
  month={June},}@INPROCEEDINGS{10350777,
  author={Morales, Sergio and Planas, Elena and Clarisó, Robert and Gogolla, Martin},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={Generative AI in Model-Driven Software Engineering Education: Friend or Foe?}, 
  year={2023},
  volume={},
  number={},
  pages={110-113},
  abstract={The availability and effectiveness of generative AI tools challenge the currently established methods for learning, teaching and assessment. In this paper, we discuss their potential impact for model-driven software engineering education, both from the point of view of educators and students. The discussion highlights several opportunities and risks, which support the need of a critical perspective in the application of these tools.},
  keywords={Learning systems;Adaptation models;Plagiarism;Education;Data models;Software;Reproducibility of results;Generative AI;education;software engineering;model-driven software engineering;modeling},
  doi={10.1109/MODELS-C59198.2023.00034},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10893133,
  author={Axelsson, Andreas and Wallgren, Daniel Tomas and Verma, Udit and Cajander, Åsa and Daniels, Mats and Eckerdal, Anna and McDermott, Roger},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={From Assistance to Misconduct: Unpacking the Complex Role of Generative AI in Student Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This research-to-practice full paper discusses students' views on the role of generative artificial intelligence (GenAI) in their learning. The rapid integration of GenAI in educational settings has prompted significant interest in its implications for learning and academic integrity. This study investigates the adoption and impact of GenAI tools among computing students at a university, focusing on how they are utilized for educational purposes and their ethical implications. Semi-structured interviews with nine computing students were used to examine GenAI's specific use and timing. Additionally, it explores students' perceptions of the trustworthiness of GenAI outputs and identifies the students' ethical boundaries concerning its use in academic work. The findings reveal that while GenAI tools might enhance learning efficiency and provide substantial educational support, they raise significant ethical concerns, particularly regarding academic misconduct. The study highlights the need for educational strategies to navigate the challenges posed by GenAI technologies. Finally, three recommendations for computing education are outlined. This research contributes to the ongoing discourse on GenAI in education by describing the student's reflections on GenAI.},
  keywords={Ethics;Generative AI;Navigation;Education;Focusing;Learning (artificial intelligence);Debugging;Reflection;Timing;Interviews;Generative AI;Student learning;Cheating;Motivation;Misconduct},
  doi={10.1109/FIE61694.2024.10893133},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10578858,
  author={Lehmann, Alexander and Landes, Dieter},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Extracting Metadata from Learning Videos for Ontology-Based Recommender Systems Using Whisper & GPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In modern education, individualized learning environments play a vital role by allowing learners to tailor their learning paths based on personal needs, interests, and abilities. Achieving effective individualization relies on dynamic adaptation of the learning path, typically facilitated by recommender systems. These systems offer personalized suggestions, commonly employing content-based or collaborative filtering approaches. However, traditional recommender systems often lack consideration of the semantics of learning elements. To address this limitation, ontology-based recommender systems integrate semantic modeling, establishing additional connections within a domain to enhance precision and context in recommendations. Notably, these systems mitigate the cold start problem and are particularly advantageous in learning environments with limited data. While videos are prevalent in learning platforms, their unstructured nature poses challenges for processing. This paper introduces an innovative approach, leveraging Large Language Models, specifically GPT, to extract metadata from learning videos. The proposed method intelligently augments videos and links them to a domain ontology, enabling the integration of videos into ontology-based recommender systems. The application of this approach is demonstrated through a case study in software engineering education, showcasing its potential to enhance individualized learning experiences in specific domains. The presented method offers an automated alternative to manual video processing, aligning with the evolving landscape of education technology.},
  keywords={Large language models;Semantics;Manuals;Metadata;Ontologies;Engineering education;Recommender systems;learning analytics;adaptive learning environments;generative AI;large language models;ontology-based recommender systems;learning videos},
  doi={10.1109/EDUCON60312.2024.10578858},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10837616,
  author={Sterbini, Andrea and Temperini, Marco},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Open-Source or Proprietary Language Models? An Initial Comparison on the Assessment of an Educational Task}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Open-source Small and medium Language Models (SLMs) are becoming more and more available, and allow researchers to fine tune and explore their application with more freedom than the proprietary ones. We compare the performances of many recent SLMs with two proprietary models from OpenAI, on two didactic tasks regarding the automatic assessment of algorithm descriptions submitted for an under-graduate course, involving training on Computer Programming. In particular, as the submission is part of a formative peer-assessment workflow, where peers grade three descriptions each, and suggest improvements, we are interested in two tasks: a) discriminating non-algorithms descriptions from algorithm descriptions, and b) grading the clearness of the submitted descriptions (which is related to an effective usefulness during peer-assessment). We see that the tasks are solved with varied performances by the tested Models, and that a proprietary Model can be leader on a task, whereas some SLMs are better at the other task. Then we also show some strategies, to improve the grading/classifying performances. The development of Language Models that are Open Source, Open trained, and overall smaller than the available proprietary ones, is currently at an early stage: nonetheless a conclusion can be that these systems may already have their say, when compared with large, proprietary Language Models.},
  keywords={Training;Computational modeling;Programming;Information technology;Technology Enhanced Learning;Peer Assessment;Automated Assessment;Algorithm Description Quality;Natural language processing;Transformer-based Large and Small Language Models;Open-Source Language Models},
  doi={10.1109/ITHET61869.2024.10837616},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{11016326,
  author={Lenke, Michael and Schulte, Carsten},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Enhancing AI Interaction through Co-Construction: A Multi-Faceted Workshop Framework}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The boom of research topics such as AI literacy and explainable AI (XAI) intensified political discussions about the right for meaningful explanations of the logic involved leave no doubt about the necessity of AI education. However, technologies that we find in our every lives often hide architectural aspects to make their benefits accessible for everyone. Additionally, performance seems to trade-off for explainability, leading to a black-box system not understandable for users and sometimes even experts. To address this issue this paper introduces a workshop framework designed to enhance interactions with large language models (LLMs) - in particular ChatGPT. With emphasis on observation, analysis and hands-on interaction, the workshop framework pursues three different goals: (1) as an event for scientific research, (2) as a learning event and (3) as science communication work to integrate the public more closely into research. Pre-post-test data suggests a shift in participants' interaction patterns when using ChatGPT. Participants not only questioned the AI's responses but also reflected on their own understanding, asking follow-up questions or offering suggestions on how to better explain concepts to the AI.},
  keywords={Explainable AI;Conferences;Large language models;Closed box;Games;Chatbots;Logic;Engineering education;Monitoring;Testing},
  doi={10.1109/EDUCON62633.2025.11016326},
  ISSN={2165-9567},
  month={April},}@ARTICLE{10187129,
  author={Revanesh, M. and Rudra, Bhawana and Guddeti, Ram Mohana Reddy},
  journal={IEEE Access}, 
  title={An Optimized Question Classification Framework Using Dual-Channel Capsule Generative Adversarial Network and Atomic Orbital Search Algorithm}, 
  year={2023},
  volume={11},
  number={},
  pages={75736-75747},
  abstract={The advancement in education has emphasized the need to evaluate the quality of the examination questions and the cognitive levels of students. Many educational institutions now acknowledge Bloom’s taxonomy-based students’ cognitive levels evaluating subject-related learning. Therefore, in this paper, a novel optimized Examination Question Classification framework, referred to as QC-DcCapsGAN-AOSA, is proposed by combining the Dual-channel Capsule generative Adversarial Network (DcCapsGAN) with Atomic Orbital Search Algorithm (AOSA) for preprocessing a real-time online dataset of university examination questions, thus identify the key features from the raw data using Term Frequency Inverse Document Frequency (TF-IDF) and finally classifying the examination questions. Atomic Orbital Search Algorithm is used to fine-tune the parameters’ weights of the DcCapsGAN, and then uses these weights to categorize questions as Knowledge Level, Comprehension Level, Application Level, Analysis Level, Synthesis Level, and Evaluation Level. Experimental results demonstrate the superiority of the proposed method (QC-DcCapsGAN-AOSA) when compared to the state-of-the-art methods such as QC-LSTM-CNN and QC-BiGRU-CNN with an accuracy improvement of 23.65% and 29.04%, respectively.},
  keywords={Feature extraction;Generative adversarial networks;Taxonomy;Artificial intelligence;Classification algorithms;Visualization;Electronic learning;Testing;Atomic orbital search algorithm (AOSA);dual-channel capsule generative adversarial network (DcCapsGAN);online examination question classification;term frequency-inverse document frequency (TF-IDF)},
  doi={10.1109/ACCESS.2023.3296911},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10975838,
  author={Guoan, Zhao and Mengting, Pan and Shaobo, Wang},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Exploring Educators' Multidimensional Perspectives on Generative AI's Impact in Education: A Study Using Q Methodology}, 
  year={2025},
  volume={},
  number={},
  pages={350-355},
  abstract={The rapid development of generative AI has attracted significant attention in education. This study uses Q methodology to explore educators' views on AI's impact across five key dimensions: educational theory, learning outcomes, educational technology, educational ethics, and pedagogy. The analysis identifies three educator groups: (1) Education Stalwarts Emphasizing Humanistic Care (F1), who prioritize values like critical thinking, self-motivation, and social responsibility; (2) Education Reformers Advocating Technological Integration (F2), who support AI-driven innovations; and (3) Education Explorers Focused on Learning Experiences (F3), who emphasize personalized, technology-enhanced learning. Although perspectives on AI integration vary, there is agreement that education should promote human progress and personal growth. This study contributes to the ongoing discourse by advocating for a balanced approach that integrates tradition with innovation to enhance educational outcomes.},
  keywords={Technological innovation;Ethics;Generative AI;Collaboration;Educational technology;Information technology;Q methodology;generative AI;educators' perspectives;educational impact},
  doi={10.1109/ICEIT64364.2025.10975838},
  ISSN={},
  month={March},}@INPROCEEDINGS{10864428,
  author={Khennouche, Feriel and Elmir, Youssef and Djebari, Nabil and Boubchir, Larbi and Laouid, Abdelkader and Bounceur, Ahcene},
  booktitle={2024 International Conference on Computational Intelligence and Network Systems (CINS)}, 
  title={Comparative Analysis and Application of Large Language Models on FAQ Chatbots}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents a comprehensive evaluation of advanced large language models (LLMs) including GPT, BART, BERT, and T5, fine-tuned using a specialized FAQ dataset from ESTIN, a higher education institution. The study aims to assess the performance of these LLM models in generating accurate and contextually relevant responses to common queries. These models were evaluated using key metrics such as evaluation loss (eval loss) and ROUGE scores (ROUGE-1 and ROUGE-2), which measure the alignment between the generated responses and the reference answers. The experiment results show that BERT outperforms the other models, achieving a lowest eval loss and highest ROUGE-1 and ROUGE-2 scores, making it the most effective model in this context. The findings underscore the potential of BERT in educational AI applications. Finally, some future research directions are discussed, including the integration of additional models and the enhancement of the FAQ dataset to further improve performance.},
  keywords={Analytical models;Accuracy;Reviews;Large language models;Education;Loss measurement;Question answering (information retrieval);Computational intelligence;Context modeling;Network systems;LLM;fine-tunning;FAQ Chatbot;GPT;BART;T5;BERT},
  doi={10.1109/CINS63881.2024.10864428},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10610554,
  author={Macaluso, Annabella and Cote, Nicholas and Chitta, Sachin},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Toward Automated Programming for Robotic Assembly Using ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={17687-17693},
  abstract={Despite significant technological advancements, the process of programming robots for adaptive assembly remains labor-intensive, demanding expertise in multiple domains and often resulting in task-specific, inflexible code. This work explores the potential of Large Language Models (LLMs), like ChatGPT, to automate this process, leveraging their ability to understand natural language instructions, generalize examples to new tasks, and write code. In this paper, we suggest how these abilities can be harnessed and applied to real-world challenges in the manufacturing industry. We present a novel system that uses ChatGPT to automate the process of programming robots for adaptive assembly by decomposing complex tasks into simpler subtasks, generating robot control code, executing the code in a simulated workcell, and debugging syntax and control errors, such as collisions. We outline the architecture of this system and strategies for task decomposition and code generation. Finally, we demonstrate how our system can autonomously program robots for various assembly tasks in a real-world project.},
  keywords={Robotic assembly;Codes;Debugging;Chatbots;Encoding;Cognition;Task analysis},
  doi={10.1109/ICRA57147.2024.10610554},
  ISSN={},
  month={May},}@INPROCEEDINGS{10438742,
  author={Wei, Shuohuan and Luo, Yong and Chen, Shuoqi and Huang, Tingting and Xiang, Yixue},
  booktitle={2023 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)}, 
  title={Deep research and analysis of ChatGPT based on multiple testing experiments}, 
  year={2023},
  volume={},
  number={},
  pages={123-131},
  abstract={The intelligent chat robots, represented by ChatGPT, are rapidly entering the daily learning and life of college students and gradually playing an extremely important role. In this situation, how to explore the role of intelligent chat robots for college students, while exploring the advantages and disadvantages of ChatGPT, guiding college students to actively and effectively use this tool, and leveraging the application value of chat robots in talent cultivation has become a very urgent task at present. On this basis, through case studies, experimental analysis, testing experiments, and other methods, the role and value of ChatGPT are studied and explored, providing reference suggestions for talent cultivation models of college students, and promoting the healthy and rapid development of smart education in universities.},
  keywords={Educational technology;Chatbots;Knowledge discovery;Task analysis;Distributed computing;Robots;Testing;ChatGPT;intelligent chat robot;test experiment;wisdom education},
  doi={10.1109/CyberC58899.2023.00030},
  ISSN={2833-8898},
  month={Nov},}@INPROCEEDINGS{10555858,
  author={Das, Joy Krishan and Mondal, Saikat and Roy, Chanchal K.},
  booktitle={2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR)}, 
  title={Investigating the Utility of ChatGPT in the Issue Tracking System: An Exploratory Study}, 
  year={2024},
  volume={},
  number={},
  pages={217-221},
  abstract={Issue tracking systems serve as the primary tool for incorporating external users and customizing a software project to meet the users’ requirements. However, the limited number of contributors and the challenge of identifying the best approach for each issue often impede effective resolution. Recently, an increasing number of developers are turning to AI tools like ChatGPT to enhance problem-solving efficiency. While previous studies have demonstrated the potential of ChatGPT in areas such as automatic program repair, debugging, and code generation, there is a lack of study on how developers explicitly utilize ChatGPT to resolve issues in their tracking system. Hence, this study aims to examine the interaction between ChatGPT and developers to analyze their prevalent activities and provide a resolution. In addition, we assess the code reliability by confirming if the code produced by ChatGPT was integrated into the project’s codebase using the clone detection tool NiCad. Our investigation reveals that developers mainly use ChatGPT for brainstorming solutions but often opt to write their code instead of using ChatGPT-generated code, possibly due to concerns over the generation of "hallucinated" code, as highlighted in the literature.},
  keywords={Codes;Cloning;Debugging;Maintenance engineering;Chatbots;Turning;Software;ChatGPT;Issue Tracking;NiCad;Code Clone},
  doi={},
  ISSN={2574-3864},
  month={April},}@INPROCEEDINGS{10554763,
  author={Saǧlam, Timur and Hahner, Sebastian and Schmid, Larissa and Burger, Erik},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={Automated Detection of AI-Obfuscated Plagiarism in Modeling Assignments}, 
  year={2024},
  volume={},
  number={},
  pages={297-308},
  abstract={Plagiarism is a widespread problem in computer science education, exacerbated by the impracticability of manual inspection in large courses. Even worse, tools based on large language models like ChatGPT have made it easier than ever to obfuscate plagiarized so-lutions. Additionally, most plagiarism detectors only apply to code, and only a few approaches exist for modeling assignments, which lack broad resilience to obfuscation attacks. This paper presents a novel approach for automated plagiarism detection in modeling assignments that combines automated analysis with human inspection. We evaluate our approach with real-world assignments and plagiarism obfuscated by ChatGPT. Our results show that we achieve a significantly higher detection rate for AI-generated attacks and a broader resilience than the state-of-the-art.},
  keywords={Training;Plagiarism;Computational modeling;Inspection;Chatbots;Tokenization;Computer science education;Plagiarism Detection;Obfuscation;ChatGPT;Artificial Intelligence},
  doi={10.1145/3639474.3640084},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{11015358,
  author={Bui, Nguyen Tuan Anh and Nguyen, Linh and Nguyen, Ngoc Dang Khoa and Hoang, Cuong Chi},
  booktitle={2024 International Conference on Logistics and Industrial Engineering (ICLIE)}, 
  title={Generative AI-driven Digital Transformation in Education: Systematic Review and Future Research Directions}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative artificial intelligence (AI) has emerged as a transformative force in multiple disciplines, particularly in education amidst the post-COVID-19 era. The systematic review synthesizes findings from 59 peer-reviewed articles published from 2014 to 2024. Through a rigorous analysis, we delve into several benefits and challenges associated with Generative AI-driven digital transformation in education. Notably, Generative AI offers numerous benefits for educational institutions such as tailored learning experiences, improved student engagement, cost-effective learning solutions and so forth. Nevertheless, reaping such benefits often necessitates grappling with challenges, including technological intricacies, ethical consideration and pedagogical implications. These findings gleaned from this review serve as an invaluable resource for researchers and practitioners seeking to harness Generative AI’s potential to optimize teaching and learning performance. Such a review also lays a robust foundation for future research endeavors, paving the way for continued advancements in this domain.},
  keywords={Ethics;Generative AI;Digital transformation;Education;Force;Industrial engineering;Systematic literature review;Logistics;Generative AI;education sector;digital transformation;systematic literature review},
  doi={10.1109/ICLIE61478.2024.11015358},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10959667,
  author={Muhamad, Gilang Aulia and Alsulami, Bassma Saleh and Thabit, Khalid Omar},
  booktitle={2025 2nd International Conference on Advanced Innovations in Smart Cities (ICAISC)}, 
  title={Innovating NCAAA Accreditation: A Smart Education Management System Powered by Generative Pre-trained Transformer}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This study introduces a smart education management system designed to enhance the accreditation processes mandated by the National Commission for Academic Accreditation & Assessment (NCAAA) for postgraduate programs. By leveraging Generative Pre-trained Transformer (GPT) models, the system efficiently generates comprehensive course reports and dynamic assessment questions, aligning them with the cognitive levels defined in Bloom's Taxonomy. Automating these critical but labor-intensive tasks significantly improves the efficiency of accreditation processes in academic settings. Initial testing within the Computer Science Department at King Abdulaziz University (KAU) demonstrated the system's robustness and scalability, indicating its potential for broader application across universities. The integration of Artificial Intelligence (AI) not only streamlines administrative processes but also improves the quality of educational assessments through alignment with Bloom's Taxonomy. This study emphasizes the transformative potential of AI in educational accreditation, setting a new benchmark for future research and development in integrating AI technologies for smart education management systems.},
  keywords={Technological innovation;Smart cities;Scalability;Taxonomy;Educational technology;Benchmark testing;Transformers;Accreditation;Artificial intelligence;Standards;smart education;accreditation;generative pre-trained transformer},
  doi={10.1109/ICAISC64594.2025.10959667},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11005250,
  author={Alaswad, Sara and Kalganova, Tatiana and Awad, Wasan},
  booktitle={2024 International Conference on IT Innovation and Knowledge Discovery (ITIKD)}, 
  title={Developing a Framework for Using Large Language Models for Viva Assessments in Higher Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper presents a comprehensive framework for evaluating Large Language Models (LLMs) based on educational performance areas and established evaluation metrics. The study bridges the gap between traditional academic assessment criteria and modern AI evaluation techniques, aligning metrics such as coherence, relevance, completeness, and creativity with performance areas like problem definition, methodology, and product outcomes. Drawing insights from experimental results, the framework highlights the top 10 evaluation metrics frequently observed and emphasizes their significance in assessing AI -generated responses. A critical analysis identifies limitations in the initial framework proposed by ChatGPT, leading to refined strategies for more comprehensive evaluation. The refined framework addresses limitations of subjectivity, overlapping criteria, and weighting mechanisms, offering a dynamic evaluation model for both technical and educational contexts. The findings contribute to advancing interdisciplinary evaluation methodologies and offer valuable insights for educators, researchers, and developers in optimizing LLM applications for educational purposes.},
  keywords={Measurement;Technological innovation;Feedback loop;Large language models;Education;Evaluation models;Chatbots;Knowledge discovery;Real-time systems;Creativity;LLM;higher education;VIVA;academic assessment;evaluation metrics;ChatGPT},
  doi={10.1109/ITIKD63574.2025.11005250},
  ISSN={},
  month={April},}@INPROCEEDINGS{11016452,
  author={Brändle, Marcus and Bahr, Tobias and Arnold, Jonas Benedikt and Zinn, Bernd},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={A Comparative Study of Epistemological Beliefs and AI Chatbot Usage Among Early Adopters and Later Users in Higher Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={With the increasing integration of artificial intelligence in education, the relationship between students' learning strategies and their engagement with AI chatbots are of interest. This exploratory study examines the relationships between learning strategies, epistemological beliefs, and motivational orientations concerning AI chatbot usage, as well as the actual usage patterns among students, which has been identified as a research gap. Some studies show that especially India has a high usage of ChatGPT and other countries e. g. Germany how low usage rates. Thus, we operationalized Indian student as so-called early adopters and German students as later users to compare the two subgroups. The study consists of $\mathbf{N = 1 3 5}$ students from various disciplines across multiple German universities ($\mathrm{n}=91$; later users) and an Indian university ($\mathrm{n}=44$; early adopters). The findings indicate that students in subgroup 2 (Indian students) can be considered early adopters, utilizing AI chatbots more frequently and exhibiting less elaborated epistemological beliefs compared to later users. Early adopters perceive AI chatbots as a comprehensive source of knowledge. In contrast, later users reported less frequent use of AI chatbots. While no significant correlation was found between epistemological beliefs and learning strategies in relation to students' usage frequency, the differences in epistemological beliefs between the two subgroups suggest that frequent use of AI chatbots could potentially decrease students' epistemological sophistication and thus impact their learning strategies.},
  keywords={Correlation;Learning (artificial intelligence);Educational technology;Chatbots;Artificial intelligence;Engineering education;Education;Educational technology;Chatbot;Artificial intelligence;Epistemological Beliefs},
  doi={10.1109/EDUCON62633.2025.11016452},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10343391,
  author={Wolfschwenger, Patrick and Sabitzer, Barbara and Lavicza, Zsolt},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Integrating Cloud-Based AI in Software Engineers' Professional Training and Development}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Artificial Intelligence (AI) has recently gained immense popularity. With impressive capabilities and versatility, large language models have quickly become a valuable tool for a wide range of applications, from chatbots and language translation to content creation and research. Generative AI can aid in the creation of computer code and provide information on a wide range of technical topics. This work-in-progress brings AI to vocational training by incorporating Cloud Computing (CC) services into a professional training and development program for software engineers, concentrating on practical skills development, hands-on experience and job-specific competencies. The approach is evaluated in the context of action research, with an emphasis on the potential benefits and challenges of code generation.},
  keywords={Cloud computing;Codes;Computational modeling;Learning (artificial intelligence);Vocational training;Chatbots;Software;Artificial Intelligence;Cloud Computing;Professional Training and Development;Lifelong Learning},
  doi={10.1109/FIE58773.2023.10343391},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10896159,
  author={Garzarella, Silvia and Vallasciani, Giacomo and Cascarano, Pasquale and Hajahmadi, Shirin and Cervellati, Elena and Marfia, Gustavo},
  booktitle={2025 IEEE International Conference on Artificial Intelligence and eXtended and Virtual Reality (AIxVR)}, 
  title={An Extended Reality Platform Powered by Large Language Models: A Case Study on Teaching Dance Costumes}, 
  year={2025},
  volume={},
  number={},
  pages={369-375},
  abstract={In this paper, we present an Extended Reality (XR) platform powered by Large Language Models (LLMs), designed to support education in dance history and cultural heritage. The platform here applied to a case study on a dance costume, allows users to interact with 3D models, annotate them, and explore their historical and cultural contexts collaboratively. Using features like image-to-LLM queries, users can gain insights into costume details and performance history, and the annotation tools enable uploading multimedia resources, thereby simulating an archival research environment. By integrating LLMs, the platform provides tailored information and context on demand, enriching the user experience with detailed explanations about objects, such as costume construction, usage, and cultural significance.},
  keywords={Solid modeling;Three-dimensional displays;Extended reality;Annotations;Large language models;User experience;Cultural differences;History;Context modeling;Extended Reality;Artificial Intelligence;LLM;Dance;Cultural Heritage},
  doi={10.1109/AIxVR63409.2025.00069},
  ISSN={2771-7453},
  month={Jan},}@ARTICLE{10558738,
  author={Radke, Richard J.},
  journal={IEEE Signal Processing Magazine}, 
  title={A Signal Processor Teaches Generative Artificial Intelligence [SP Education]}, 
  year={2024},
  volume={41},
  number={2},
  pages={6-10},
  abstract={How did an “old dog” signal processing professor approach learning and teaching the “new tricks” of generative artificial intelligence (AI)? This article overviews my recent experience in preparing and delivering a new course called “Computational Creativity,” reflecting on the methods I adopted compared to a traditional equations-on-a-whiteboard course. The technical material is qualitatively different from traditional signal processing, and the types of students who took the class and their approach to learning were different too. I learned a lot from the experience but also came away with bigger questions about the role of educators in the age of generative AI.},
  keywords={Generative AI;Education;Learning (artificial intelligence);Signal processing;Creativity;Educational courses;Creativity;Computational modeling},
  doi={10.1109/MSP.2024.3388166},
  ISSN={1558-0792},
  month={March},}@INPROCEEDINGS{10671366,
  author={Rai, Laxmisha and Khatiwada, Smriti and Deng, Chunrao and Liu, Fasheng},
  booktitle={2024 IEEE 7th International Conference on Electronic Information and Communication Technology (ICEICT)}, 
  title={Cross-Language Code Development with Generative AI: A Source-to-Source Translation Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={562-565},
  abstract={Since the release of ChatGPT in November 2022, there is growing interest around the world on exploring the capabilities of generative AI tools. In addition to text, image, audio, and video generation, these tools are also able to generate program codes. In this paper, strategies for students, programmers and enthusiasts to understand the prompting methods to generate codes in multiple languages by translating source code written in one language to another target language using generative AI is explored. The prompts are created to test the ability of generative AI to create codes in C, Java, C++, and Python. Some of the methods of generating the complete program using limited original source code statements is presented. In summary, while generating source code in a target language, generative AI tools downplay the significance of accuracy of statements written in original language, syntax, semantics, as well as missing statements in a program. Irrespective of these, generative AI tools are still able to generate complete code in a target language by correcting errors.},
  keywords={Java;Codes;Generative AI;Source coding;Semantics;Syntactics;Chatbots;Generative AI;translation;source code;programming;cross-language code},
  doi={10.1109/ICEICT61637.2024.10671366},
  ISSN={2836-7782},
  month={July},}@INPROCEEDINGS{10864116,
  author={Da Silva, Fabiano Tavares and De Araújo, Felipe Rocha and Bezerra, Erick Costa},
  booktitle={2024 5th International Conference on Artificial Intelligence and Computer Engineering (ICAICE)}, 
  title={A Comparative Study of Bug Triage Representation and Classification Approaches from Canonical to Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={86-93},
  abstract={Bug triage is the task of assigning newly reported bugs to the proper developers or team for resolution. This is a critical point in software maintenance as it directly influences the time and correct allocation that impact the efficiency and effectiveness of the software process. In a global aspect, the number of teams/developers is extensive, which brings a challenge for bug triage. Traditional approaches to assign bugs struggle with the complexity of the problem. This paper proposes a comparative assessment for different text representation combined with text classification approaches for automated bug report triage by incorporating Large Language Models (LLMs) into the classification pipeline to surpass the limitations of canonical methods. Traditional classification methods were compared with LLM-enhanced models across accuracy metric. The results demonstrate an improvement in triage accuracy when utilizing the fine-tuned LLM, highlighting their potential to provide developer-appropriate bug assignments.},
  keywords={Training;Software maintenance;Accuracy;Large language models;Computer bugs;Text categorization;Pipelines;Market research;Resource management;Software development management;bug report triage;LLM;S-BERT},
  doi={10.1109/ICAICE63571.2024.10864116},
  ISSN={},
  month={Nov},}@ARTICLE{11020711,
  author={Feng, Yingchaojie and Chen, Zhizhang and Kang, Zhining and Wang, Sijia and Tian, Haoyu and Zhang, Wei and Zhu, Minfeng and Chen, Wei},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={JailbreakLens: Visual Analysis of Jailbreak Attacks Against Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={The proliferation of large language models (LLMs) has underscored concerns regarding their security vulnerabilities, notably against jailbreak attacks, where adversaries design jailbreak prompts to circumvent safety mechanisms for potential misuse. Addressing these concerns necessitates a comprehensive analysis of jailbreak prompts to evaluate LLMs' defensive capabilities and identify potential weaknesses. However, the complexity of evaluating jailbreak performance and understanding prompt characteristics makes this analysis laborious. We collaborate with domain experts to characterize problems and propose an LLM-assisted framework to streamline the analysis process. It provides automatic jailbreak assessment to facilitate performance evaluation and support analysis of components and keywords in prompts. Based on the framework, we design JailbreakLens, a visual analysis system that enables users to explore the jailbreak performance against the target model, conduct multi-level analysis of prompt characteristics, and refine prompt instances to verify findings. Through a case study, technical evaluations, and expert interviews, we demonstrate our system's effectiveness in helping users evaluate model security and identify model weaknesses.},
  keywords={Analytical models;Security;Safety;Visualization;Taxonomy;Training;Semantics;Ethics;Large language models;Interviews;Jailbreak attacks;visual analytics;large language models},
  doi={10.1109/TVCG.2025.3575694},
  ISSN={1941-0506},
  month={},}@INPROCEEDINGS{10607367,
  author={Gabriella, Amanda and Gui, Anderes and Chanda, Razib Chandra},
  booktitle={2024 IEEE Symposium on Industrial Electronics & Applications (ISIEA)}, 
  title={The Use of Chatbot and its Impact on Academic Achievement}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, the adoption of chatbot technology has garnered significant interest for its potential to revolutionize various domains, including education. This study aims to analyse the use of chatbots, specifically ChatGPT, and their impact on students' academic achievement in learning programming languages. The research investigates the influence of AI chatbots on learning motivation, self-efficacy, and academic achievement. Data collection was conducted using purposive sampling techniques, with a questionnaire prepared via Google Forms. Invitations to participate in the survey were distributed through social media platforms such as email, WhatsApp, Facebook, and Instagram. The study targeted students in the JABODETABEK area pursuing bachelor's or associate degrees, with a total of 400 respondents participating. To analyse the data, SmartPLS Version 4.0 was utilized. The results indicate that the use of ChatGPT positively impacts students' learning motivation. Increased learning motivation, in turn, positively influences students' academic achievement. Additionally, self-efficacy has a significant positive effect on academic achievement. The findings of this study provide valuable insights for stakeholders aiming to make chatbots more user-friendly for students to enhance their academic performance. Furthermore, these results enrich the existing literature on chatbot use with valuable information that can serve as a reference for future studies.},
  keywords={Surveys;Computer languages;Freeware;Social networking (online);Chatbots;Web sites;Stakeholders;ChatGPT;Learning Motivation;Self-efficacy;Academic Achievement;Programming Languages},
  doi={10.1109/ISIEA61920.2024.10607367},
  ISSN={2472-7660},
  month={July},}@INPROCEEDINGS{10870993,
  author={Zrelli, Rim and Misson, Henrique Amaral and Ben Attia, Maroua and de Magalhaes, Felipe Gohring and Shabah, Abdo and Nicolescu, Gabriela},
  booktitle={2024 International Workshop on Rapid System Prototyping (RSP)}, 
  title={Advancing Formal Verification: Fine-Tuning LLMs for Translating Natural Language Requirements to CTL Specifications}, 
  year={2024},
  volume={},
  number={},
  pages={21-27},
  abstract={In the domain of formal verification, translating natural language (NL) requirements into Computation Tree Logic (CTL) specifications presents a notable challenge due to the disparity between human-readable documents and formal specifications. This paper introduces a novel approach that leverages Large Language Models (LLMs) to automate this translation process, thereby enhancing the accuracy and efficiency of formal verification practices. We fine-tune three state-of-the-art LLMs—LLAMA3, Mistral, and Qwen2—with a particular focus on optimizing the Mistral model due to its superior performance. Our methodology is supported by the Natural2CTL dataset, consisting of 2,095 NL requirements and their corresponding CTL specifications. We employ evaluation metrics such as validation loss, accuracy, semantic similarity, and Structural Operator Jaccard Similarity (SOJS) for a comprehensive assessment of model performance. Additionally, a comparative analysis with human translators, trained in CTL logic, underscores the LLMs’ potential to match or even surpass human accuracy in translating NL requirements into formal specifications. Our findings reveal that the fine-tuned Mistral model significantly outperforms the other LLMs and human participants, demonstrating superior accuracy in generating CTL specifications. This study advances the field of formal verification by proposing a scalable solution to the NL-to-CTL translation challenge, setting a new benchmark for the integration of AI tools in complex specification tasks.},
  keywords={Measurement;Translation;Accuracy;Large language models;Conferences;Semantics;Benchmark testing;Logic;Formal specifications;Formal verification;Formal Verification;CTL;Automated Translation;LLMs;Model Fine-Tuning;AI Integration},
  doi={10.1109/RSP64122.2024.10870993},
  ISSN={2150-5519},
  month={Oct},}@INPROCEEDINGS{10803425,
  author={Ünlü, Hüseyin and Tenekeci, Samet and Çiftçi, Can and Oral, İbrahim Baran and Atalay, Tunahan and Hacaloğlu, Tuna and Musaoğlu, Burcu and DemirǶrs, Onur},
  booktitle={2024 50th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={Predicting Software Functional Size Using Natural Language Processing: An Exploratory Case Study}, 
  year={2024},
  volume={},
  number={},
  pages={188-193},
  abstract={Software Size Measurement (SSM) plays an essential role in software project management as it enables the acquisition of software size, which is the primary input for development effort and schedule estimation. However, many small and medium-sized companies cannot perform objective SSM and Software Effort Estimation (SEE) due to the lack of resources and an expert workforce. This results in inadequate estimates and projects exceeding the planned time and budget. Therefore, organizations need to perform objective SSM and SEE using minimal resources without an expert workforce. In this research, we conducted an exploratory case study to predict the functional size of software project requirements using state-of-the-art large language models (LLMs). For this aim, we fine-tuned BERT and BERT_SE with a set of user stories and their respective functional size in COSMIC Function Points (CFP). We gathered the user stories included in different project requirement documents. In total size prediction, we achieved 72.8% accuracy with BERT and 74.4% accuracy with BERT_SE. In data movement-based size prediction, we achieved 87.5% average accuracy with BERT and 88.1% average accuracy with BERT_SE. Although we use relatively small datasets in model training, these results are promising and hold significant value as they demonstrate the practical utility of language models in SSM.},
  keywords={Training;Schedules;Accuracy;Estimation;Project management;Companies;Predictive models;Size measurement;Software;Natural language processing;software size measurement;natural language processing;COSMIC;BERT;functional size;software engineering;NLP},
  doi={10.1109/SEAA64295.2024.00036},
  ISSN={2376-9521},
  month={Aug},}@INPROCEEDINGS{10646888,
  author={Oh, Sanghak and Lee, Kiho and Park, Seonhye and Kim, Doowon and Kim, Hyoungshick},
  booktitle={2024 IEEE Symposium on Security and Privacy (SP)}, 
  title={Poisoned ChatGPT Finds Work for Idle Hands: Exploring Developers’ Coding Practices with Insecure Suggestions from Poisoned AI Models}, 
  year={2024},
  volume={},
  number={},
  pages={1141-1159},
  abstract={AI-powered coding assistant tools (e.g., ChatGPT, Copilot, and IntelliCode) have revolutionized the software engineering ecosystem. However, prior work has demonstrated that these tools are vulnerable to poisoning attacks. In a poisoning attack, an attacker intentionally injects maliciously crafted insecure code snippets into training datasets to manipulate these tools. The poisoned tools can suggest insecure code to developers, resulting in vulnerabilities in their products that attackers can exploit. However, it is still little understood whether such poisoning attacks against the tools would be practical in real-world settings and how developers address the poisoning attacks during software development. To understand the real-world impact of poisoning attacks on developers who rely on AI-powered coding assistants, we conducted two user studies: an online survey and an in-lab study. The online survey involved 238 participants, including software developers and computer science students. The survey results revealed widespread adoption of these tools among participants, primarily to enhance coding speed, eliminate repetition, and gain boilerplate code. However, the survey also found that developers may misplace trust in these tools because they overlooked the risk of poisoning attacks. The in-lab study was conducted with 30 professional developers. The developers were asked to complete three programming tasks with a representative type of AI-powered coding assistant tool (e.g., ChatGPT or IntelliCode), running on Visual Studio Code. The in-lab study results showed that developers using a poisoned ChatGPT-like tool were more prone to including insecure code than those using an IntelliCode-like tool or no tool. This demonstrates the strong influence of these tools on the security of generated code. Our study results highlight the need for education and improved coding practices to address new security issues introduced by AI-powered coding assistant tools.},
  keywords={Surveys;Codes;Chatbots;Encoding;Software;Security;Task analysis;Large language model;AI-powered coding assistant tools;poisoning attacks;software development;usable security;code generation},
  doi={10.1109/SP54263.2024.00046},
  ISSN={2375-1207},
  month={May},}@INPROCEEDINGS{10975875,
  author={Zhu, Haoran and Cooper-Stachowsky, Michael and Kamal, Zille Huma},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Enhancing Contextual Understanding in AI-Powered Tutoring: Evaluating the Oliver System for Effective Learning Support}, 
  year={2025},
  volume={},
  number={},
  pages={530-535},
  abstract={In recent years, advancements in conversational AI have led to the development of intelligent tutoring systems to enhance learning experiences through interactive conversation. This paper presents Oliver, an innovative virtual teaching assistant and course management system that leverages contextual memory and response strategies designed to promote active learning and critical thinking. Unlike traditional models that frequently offer direct answers, Oliver encourages exploration and comprehension. We also evaluated Oliver against ChatGPT-4o mini in a controlled environment with over 100 real class interactions by using Bloom's Taxonomy as a framework. Results indicate that Oliver retains lecture-related context and promotes learning more effectively, with 90% of responses fostering higher-order thinking and critical engagement, compared to 60% from ChatGPT-4o mini. These findings underscore Oliver's potential to serve as a powerful tool in education, supporting learners in developing deeper cognitive skills rather than relying on rote memorization.},
  keywords={Learning management systems;Adaptive systems;Conversational artificial intelligence;Taxonomy;Memory management;Active learning;Learning (artificial intelligence);Oral communication;Educational technology;Information technology;Artificial Intelligence in Education;Blend Learning;Educational Technology;Learning Management Systems (LMS);Technology-Enhanced Learning},
  doi={10.1109/ICEIT64364.2025.10975875},
  ISSN={},
  month={March},}@INPROCEEDINGS{10780832,
  author={Gozali, Muhammad Rizqy Al and Revel, Devin and Christian},
  booktitle={2024 International Conference on Information Management and Technology (ICIMTech)}, 
  title={Beyond Chatting an Analysis of the Full Potential Use of Chat Generative AI for University Students in the Greater Jakarta Area}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the realm of education the rising popularity of Chat Generative Artificial Intelligence (AI) has sparked interest in its potential to enhance learning experiences. This technology, known for generating text that resembles speech offers an opportunity for students to hone their questioning skills and leverage it for their academic pursuits. A study conducted in Greater Jakarta encompassing DKI Jakarta, West Java and Banten delves into how students utilize Chat Generative AI to support their journeys. Specifically, the research aims to explore how this tool influences students ability to formulate questions and engage with content. By conducting a survey, the study sheds light on the frequency, context and nature of using Generative AI in a setting. The findings aim to inform educators researchers and developers, about the advantages of incorporating this technology into education practices to enhance the learning experience. Through an analysis of survey data this paper underscores the usage trends and advantages of employing AI chat platforms to create personalized learning environments.},
  keywords={Surveys;Privacy;Generative AI;Education;Learning (artificial intelligence);Security;Problem-solving;Pupils;Particle swarm optimization;Standards;Chat Generative Artificial Intelligence (AI);Insights;Competence},
  doi={10.1109/ICIMTech63123.2024.10780832},
  ISSN={2837-2778},
  month={Aug},}@ARTICLE{10783450,
  author={Hwang, Hyo-Seok and Kim, Yoojoong and Seok, Junhee},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Generative Adversarial Soft Actor–Critic}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={In deep reinforcement learning (RL), learning stochastic and multimodal policies are crucial for various tasks, but most continuous control algorithms model the policy using a deterministic or unimodal Gaussian distribution. Despite being designed to inherently learn a stochastic policy under the maximum entropy RL framework, soft actor–critic (SAC) also uses a factorized Gaussian policy for tractable optimization, which not only restricts the expressiveness of the policy but also ignores correlations among the components of the action vector. In this article, we revisit the approach of employing normalizing flow for SAC policy, justified by the change of variable theorem, and then propose a state-dependent nonvolume preserving (SD-NVP) architecture suitable for SAC learning. In addition, we introduce a generative adversarial SAC (GASAC) that implicitly defines and optimizes various divergences without calculating the normalization constant through a generative adversarial loss. Experimental results on multigoal environment and MuJoCo continuous control tasks suite demonstrate that GASAC model multimodal policy and learn policy more stably in terms of cumulative return.},
  keywords={Entropy;Mathematical models;Generative adversarial networks;Training;Stochastic processes;Vectors;Optimization;Measurement;Computational modeling;Predictive models;Continuous control;deep learning;deep reinforcement learning (RL);generative model},
  doi={10.1109/TNNLS.2024.3493113},
  ISSN={2162-2388},
  month={},}@ARTICLE{10886944,
  author={Hao, Pengfei and Wang, Hongqiu and Yang, Guang and Zhu, Lei},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Enhancing Visual Reasoning with LLM-Powered Knowledge Graphs for Visual Question Localized-Answering in Robotic Surgery}, 
  year={2025},
  volume={},
  number={},
  pages={1-17},
  abstract={Expert surgeons often have heavy workloads and cannot promptly respond to queries from medical students and junior doctors about surgical procedures. Thus, research on Visual Question Localized-Answering in Surgery (Surgical-VQLA) is essential to assist medical students and junior doctors in understanding surgical scenarios. Surgical-VQLA aims to generate accurate answers and locate relevant areas in the surgical scene, requiring models to identify and understand surgical instruments, operative organs, and procedures. A key issue is the model's ability to accurately distinguish surgical instruments. Current Surgical-VQLA models rely primarily on sparse textual information, limiting their visual reasoning capabilities. To address this issue, we propose a framework called Enhancing Visual Reasoning with LLM-Powered Knowledge Graphs (EnVR-LPKG) for the Surgical-VQLA task. This framework enhances the model's understanding of the surgical scenario by utilizing knowledge graphs of surgical instruments constructed by the Large Language Model (LLM). Specifically, we design a Fine-grained Knowledge Extractor (FKE) to extract the most relevant information from knowledge graphs and perform contrastive learning with the extracted knowledge graphs and local image. Furthermore, we design a Multi-attention-based Surgical Instrument Enhancer (MSIE) module, which employs knowledge graphs to obtain an enhanced representation of the corresponding surgical instrument in the global scene. Through the MSIE module, the model can learn how to fuse visual features with knowledge graph text features, thereby strengthening the understanding of surgical instruments and further improving visual reasoning capabilities. Extensive experimental results on the EndoVis-17-VQLA and EndoVis-18-VQLA datasets demonstrate that our proposed method outperforms other state-of-the-art methods. We will release our code for future research.},
  keywords={Surgery;Instruments;Visualization;Knowledge graphs;Feature extraction;Computational modeling;Medical diagnostic imaging;Data mining;Training;Bioinformatics;Large Language Model;contrastive learning;surgical visual question localized-answering;knowledge graph},
  doi={10.1109/JBHI.2025.3538324},
  ISSN={2168-2208},
  month={},}@INPROCEEDINGS{10527664,
  author={Varalakshmi, P. and Bugatha, N. Meena Kumari},
  booktitle={2024 Third International Conference on Intelligent Techniques in Control, Optimization and Signal Processing (INCOS)}, 
  title={AI-Powered Resume Based QA Tailoring for Success in Interviews}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In today's competitive job market, individuals encounter the challenge of aligning their skills with suitable job opportunities that match their interests. To tackle this, the system utilizes Natural Language Processing (NLP), leveraging Large Language Models (LLM) such as BERT, T5, ROBERTA, and XLNET. Through the analysis of resumes and job descriptions, it extracts keywords and generates Q&A, significantly increasing the likelihood of finding a role that aligns with their skills and aspirations. Achieving semantic accuracy, it delivers meaningful question and answer generation with an impressive 97% accuracy compared to previous works. This support empowers students and job seekers to confidently showcase their strengths, facilitating a more impactful journey towards securing meaningful employment. Additionally, the system provides a comprehensive analysis of the performance of each model.},
  keywords={Analytical models;Resumes;Semantics;Employment;Signal processing;Natural language processing;Interviews;Contextually linked;Text Summarization;NER;GPT-2;Web Scarping;BERT;T5;XLNET;ROBERTA;Semantic Accuracy},
  doi={10.1109/INCOS59338.2024.10527664},
  ISSN={},
  month={March},}@INPROCEEDINGS{10564292,
  author={Ghimire, Aashish and Edwards, John},
  booktitle={2024 Intermountain Engineering, Technology and Computing (IETC)}, 
  title={Generative AI Adoption in the Classroom: A Contextual Exploration Using the Technology Acceptance Model (TAM) and the Innovation Diffusion Theory (IDT)}, 
  year={2024},
  volume={},
  number={},
  pages={129-134},
  abstract={The burgeoning development of generative artificial intelligence (GenAI) and the widespread adoption of large language models (LLMs) in educational settings have sparked considerable debate regarding their efficacy and acceptability. Despite the potential benefits, the assimilation of these cutting-edge technologies among educators exhibits a broad spectrum of attitudes, from enthusiastic advocacy to profound skepticism. This study aims to dissect the underlying factors influencing educators' perceptions and acceptance of GenAI and LLMs. We conducted a survey among educators and analyzed the data through the frameworks of the Technology Acceptance Model (TAM) and Innovation Diffusion Theory (IDT). Our investigation reveals a strong positive correlation between the perceived usefulness of GenAI tools and their acceptance, underscoring the importance of demonstrating tangible benefits to educators. Additionally, the perceived ease of use emerged as a significant factor, though to a lesser extent, influencing acceptance. Our findings also show that the knowledge and acceptance of these tools is not uniform, suggesting that targeted strategies are required to address the specific needs and concerns of each adopter category to facilitate broader integration of AI tools in education.},
  keywords={Surveys;Technological innovation;Technology acceptance model;Correlation;Generative AI;Computational modeling;Education;Generative Artificial Intelligence (GenAI);Large Language Models (LLMs);Technology Acceptance Model (TAM);Innovation Diffusion Theory (IDT)},
  doi={10.1109/IETC61393.2024.10564292},
  ISSN={},
  month={May},}@INPROCEEDINGS{10816908,
  author={Joshi, Raghav and Bubna, Yash and Sahana, M. and Shruthiba, A.},
  booktitle={2024 8th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS)}, 
  title={An Approach to Intelligent Information Extraction and Utilization from Diverse Documents}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In this study, an innovative tool called DOCUFYme is introduced, designed to transform how interactions with and insights from various documents are handled. Leveraging advanced NLP methodologies and the Retrieval-Augmented Generation (RAG) framework, DOCUFYme facilitates efficient and precise information extraction across different fields such as engineering, science, medicine, and agriculture. Unlike conventional NLP systems that depend on predefined rules, this system employs existing metrics (like BLEU) and Large Language Models (LLMs) to achieve a deeper semantic understanding. Additionally, the architecture supports seamless integration of new features and domain-specific modules, enhancing the adaptability and relevance across different document types. The effectiveness of DOCUFYme is validated through multiple case studies and assessments based on real-world applications, including research, corporate knowledge management, healthcare, and education. This positions DOCUFYme as a pivotal tool for intelligent information extraction, bridging knowledge gaps and facilitating access to global knowledge.},
  keywords={Measurement;Retrieval augmented generation;Semantics;Transforms;Medical services;Information retrieval;Natural language processing;Data mining;Standards;Software engineering;Natural Language Processing (NLP);Retrieval-Augmented Generation (RAG);LLMs;Information Extraction;Document Processing;Artificial Intelligence (AI);Vector Embeddings;Text Chunking;Query Processing;Embeddings & Vectorization;Code Summarization},
  doi={10.1109/CSITSS64042.2024.10816908},
  ISSN={2767-1097},
  month={Nov},}@ARTICLE{11008449,
  author={Ge, Qihang and Sun, Wei and Zhang, Yu and Li, Yunhao and Ji, Zhongpeng and Sun, Fengyu and Jui, Shangling and Min, Xiongkuo and Zhai, Guangtao},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={LMM-VQA: Advancing Video Quality Assessment with Large Multimodal Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The explosive growth of videos on streaming media platforms has underscored the urgent need for effective video quality assessment (VQA) algorithms to monitor and perceptually optimize the quality of streaming videos. However, VQA remains an extremely challenging task due to the diverse video content and the complex spatial and temporal distortions, thus necessitating more advanced methods to address these issues. Nowadays, large multimodal models (LMMs), such as GPT-4V, have exhibited strong capabilities for various visual understanding tasks, motivating us to leverage the powerful multimodal representation ability of LMMs to solve the VQA task. Therefore, we propose an Large Multi-Modal based Video Quality Assessment (LMM-VQA) model, which introduces a novel spatiotemporal visual modeling strategy for quality-aware feature extraction. Specifically, we reformulate the quality regression problem into a question and answering (Q&A) task and construct Q&A prompts for VQA instruction tuning. Then, we design a spatiotemporal vision encoder to extract spatial and temporal features to represent the quality characteristics of videos, which are subsequently mapped into the language space by the spatiotemporal projector for modality alignment. Finally, the aligned visual tokens and the quality-inquired text tokens are aggregated as inputs for the large language model (LLM) to generate the quality score as well as the quality level. Extensive experiments demonstrate that LMM-VQA achieves state-of-the-art performance across five VQA benchmarks, exhibiting an average improvement of 5% in generalization ability over existing methods. Furthermore, due to the advanced design of the spatiotemporal encoder and projector, LMM-VQA also performs exceptionally well on general video understanding tasks, further validating its effectiveness. Our code will be released at https://github.com/Sueqk/LMM-VQA.},
  keywords={Feature extraction;Visualization;Quality assessment;Video recording;Spatiotemporal phenomena;Distortion;Training;Sun;Tuning;Three-dimensional displays},
  doi={10.1109/TCSVT.2025.3571788},
  ISSN={1558-2205},
  month={},}@INPROCEEDINGS{10496969,
  author={Yu, Hao and Guo, Yunyun},
  booktitle={2023 5th International Workshop on Artificial Intelligence and Education (WAIE)}, 
  title={Harnessing the Potential of Chat GPT in Education: Unveiling its Value, Navigating Challenges, and Crafting Mitigation Pathways}, 
  year={2023},
  volume={},
  number={},
  pages={48-52},
  abstract={In the evolving landscape of educational technology, Chat GPT emerges as a transformative force, leveraging natural language processing to revolutionize various facets of education. This paper delves into the multifaceted contributions of Chat GPT, highlighting its capacity to foster multi-scenario applications, bolster comprehensive educational support systems, and enhance educational teaching management. It also elucidates the realistic challenges posed by Chat GPT to the contemporary education ecosystem, offering nuanced mitigation strategies. This exploration furnishes valuable insights, paving the way for informed advancements in educational paradigms and serving as a pivotal reference for subsequent research.},
  keywords={Training;Navigation;Biological system modeling;Education;Force;Ecosystems;Educational technology;Chat GPT;Artificial Intelligence;Educational Innovation;Value Realization;Challenge Navigation;Strategic Mitigation},
  doi={10.1109/WAIE60568.2023.00016},
  ISSN={},
  month={Sep.},}@ARTICLE{10816507,
  author={Yang, Liner and Yuan, Jiaxin and Kong, Cunliang and Yu, Jingsi and Chong, Ruining and Liu, Zhenghao and Yang, Erhong},
  journal={IEEE Transactions on Big Data}, 
  title={Tailored Definitions With Easy Reach: Complexity-Controllable Definition Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-12},
  abstract={The task of complexity-controllable definition generation refers to providing definitions with different readability for words in specific contexts. This task can be utilized to help language learners eliminate reading barriers and facilitate language acquisition. However, the available training data for this task remains scarce due to the difficulty of obtaining reliable definition data and the high cost of data standardization. To tackle those challenges, we introduce a general solution from both the data-driven and method-driven perspectives. We construct a large-scale standard Chinese dataset, COMPILING, which contains both difficult and simple definitions and can serve as a benchmark for future research. Besides, we propose a multitasking framework SimpDefiner for unsupervised controllable definition generation. By designing a parameter-sharing scheme between two decoders, the framework can extract the complexity information from the non-parallel corpus. Moreover, we propose the SimpDefiner guided prompting (SGP) method, where simple definitions generated by SimpDefiner are utilized to construct prompts for GPT-4, hence obtaining more realistic and contextually appropriate definitions. The results demonstrate SimpDefiner's outstanding ability to achieve controllable generation and better results could be achieved when GPT-4 is incorporated.},
  keywords={Dictionaries;Complexity theory;Annotations;Chatbots;Big Data;Training data;Decoding;Costs;Standards;Semantics;Controllable text generation;definition generation;unsupervised style transfer},
  doi={10.1109/TBDATA.2024.3522805},
  ISSN={2332-7790},
  month={},}@ARTICLE{10806880,
  author={Onuoha, Chibuike and Luo, Shihao and Thang, Truong Cong and Dang, Vu Hai and Nam, Nguyen Duc and Huong, Truong Thu},
  journal={IEEE Consumer Electronics Magazine}, 
  title={QoE Assessment for Prompt-based Videos: Acceptability and Quality Factors}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={The development of video technology and consumer devices has resulted in a boom of user-generated clips on various social networking services. The recent OpenAI Sora model can revolutionize the production of consumer videos, simply using prompts. However, videos generated using prompts usually contain new artifacts induced by generative AI. In addition, while various researchers have conducted extensive quality assessments on AI-generated videos, studies specifically focused on the Quality of Experience (QoE) of such videos remain limited. Given the increasing role of generative AI in media production, it is crucial to evaluate how users perceive and interact with these videos. In this paper, we present the first study on the acceptability assessment (also known as Customer Satisfaction Score) of prompt-based videos, which are generated by OpenAI Sora. In the assessment, subjects were asked to rate the video's alignment, perceptual quality, aesthetic quality, and whether the video is acceptable or not. The results show that, though the videos are visually impressive, not many videos are actually acceptable to users. Also, the relationship between acceptability and the other quality aspects is complex and non-linear. Especially, it is found that perceptual quality contributes the most to acceptability, while alignment is the least significant contributor. In addition, we identify over ten quality factors that cause low acceptability of prompt-based videos. Lastly, results from objective evaluation show that the performances of current quality metrics are insufficient to automatically monitor the quality and alignment of prompt-based videos.},
  keywords={Streaming media;Quality of experience;Quality assessment;Consumer electronics;Generative AI;Video recording;Standards;Semantics;Reliability;Production},
  doi={10.1109/MCE.2024.3519777},
  ISSN={2162-2256},
  month={},}@INPROCEEDINGS{10975835,
  author={Oraño, Jannie Fleur V. and Nogra, James Arnold and Mangmang, Geraldine B.},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Analyzing the Landscape of Generative and Open AI in Education: A Text Analytics Exploration of Scopus Publications}, 
  year={2025},
  volume={},
  number={},
  pages={84-90},
  abstract={Generative artificial intelligence (GAI) fundamentally reshaped the educational landscape by introducing innovative tools that enhanced learning outcomes and experiences. In this paper, a thorough examination of key terms surrounding GAI in education was undertaken from Scopus literature through sophisticated text analytics techniques such as word cloud generation and semantic analysis. The most used terms in the findings were “learning,” “ChatGPT,” and “language models,” representing the growing prominence of AI-driven educational solutions. Sentiment analysis revealed that authors had positive opinions about GAI and its potential benefits in developing individual learning paths and automating routines. However, concerns regarding ethics and job displacement were also highlighted. The study outlined important academic centers for GAI research, with significant contributions from Stanford University and publications in outlets such as “Lecture Notes in Computer Science.” Geographically, countries like China and India emerged as relevant in GAI research. Further thematic exploration demonstrated a predominantly positive attitude toward GAI's capability to transform pedagogical methodologies. Therefore, this research underscored the importance of text analytics in understanding GAI's role in education and called for strategic partnerships to advance innovation and equity in the global educational landscape.},
  keywords={Text mining;Sentiment analysis;Ethics;Technological innovation;Generative AI;Semantics;Transforms;Tag clouds;Stakeholders;Next generation networking;text analytics;generative ai;sentiment analysis;academia},
  doi={10.1109/ICEIT64364.2025.10975835},
  ISSN={},
  month={March},}@INPROCEEDINGS{10565703,
  author={Cotino Arbelo, Andrea E. and González-González, Carina S. and Molina Gil, Jezabel M.},
  booktitle={2023 XIII International Conference on Virtual Campus (JICV)}, 
  title={Embracing the Future: Unveiling the Revolution of Human-AI Interaction in the Digital Education Era}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={The recent and emerging introduction of generative AI in all areas of society poses new challenges to be overcome, particularly in the educational setting. The intimate and affective relationship that may develop between students and generative AI devices raises critical questions about the psychological and emotional impact of such interactions. This issue becomes particularly significant when the interactions with AI-based systems begin at an early age, and these systems assume roles as digital tutors, digital secretaries, motivator agents, and/or mentors. The aim of this work in progress was to address a recent challenge within the digital educational context: the psychological and emotional impact that the introduction of AI-based systems in digital education may have on students. However, we have faced limitations in terms of data availability and resources, particularly when addressing the issue from early ages, where there is a notable lack of studies. Although the results may not have been significant, the research has provided a general overview and a solid theoretical foundation for future studies in this field. Therefore, we suggest conducting more rigorous studies with representative samples and complete data, alongside developing reliable and validated methodologies and assessment tools to address the issues involved.},
  keywords={Generative AI;Education;Knowledge based systems;Psychology;Medical services;Reliability theory;Solids;Human-AI Interaction;Artificial Intelligence;Human-Computer Interaction;Affective Computing;Digital Education},
  doi={10.1109/JICV59748.2023.10565703},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10795074,
  author={Sridhara, Giriprasad and Roychowdhury, Sujoy and Soman, Sumit and G., Ranjani H. and Britto, Ricardo},
  booktitle={2024 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Icing on the Cake: Automatic Code Summarization at Ericsson}, 
  year={2024},
  volume={},
  number={},
  pages={689-700},
  abstract={This paper presents our findings on the automatic summarization of Java methods within Ericsson, a global telecommunications company. We evaluate the performance of an approach called Automatic Semantic Augmentation of Prompts (ASAP), which uses a Large Language Model (LLM) to generate leading summary comments (Javadocs) for Java methods. ASAP enhances the LLM's prompt context by integrating static program analysis and information retrieval techniques to identify similar exemplar methods along with their developer-written Javadocs, and serves as the baseline in our study. In contrast, we explore and compare the performance of four simpler approaches that do not require static program analysis, information retrieval, or the presence of exemplars as in the ASAP method. Our methods rely solely on the Java method body as input, making them lightweight and more suitable for rapid deployment in commercial software development environments. We conducted experiments on an Ericsson software project and replicated the study using two widely-used open-source Java projects, Guava and Elasticsearch, to ensure the reliability of our results. Performance was measured across eight metrics that capture various aspects of similarity. Notably, one of our simpler approaches performed as well as or better than the ASAP method on both the Ericsson project and the open-source projects. Additionally, we performed an ablation study to examine the impact of method names on Javadoc summary generation across our four proposed approaches and the ASAP method. By masking the method names and observing the generated summaries, we found that our approaches were statistically significantly less influenced by the absence of method names compared to the baseline. This suggests that our methods are more robust to variations in method names and may derive summaries more comprehensively from the method body than the ASAP approach.},
  keywords={Measurement;Java;Software maintenance;Codes;Semantics;Text summarization;Information retrieval;Telecommunications;Software reliability;Software development management;Automated Code Summarization;Large Language Models;Generative AI;Program Comprehension;Software Maintenance;Industry Study},
  doi={10.1109/ICSME58944.2024.00073},
  ISSN={2576-3148},
  month={Oct},}@INPROCEEDINGS{10585387,
  author={Omirgaliyev, Ruslan and Kenzhe, Damir and Mirambekov, Suienish},
  booktitle={2024 IEEE AITU: Digital Generation}, 
  title={Simulating Life: The Application of Generative Agents in Virtual Environments}, 
  year={2024},
  volume={},
  number={},
  pages={181-187},
  abstract={This research explores the innovative integration of Large Language Models (LLMs) in game development, focusing on the autonomous creation, development, and governance of a virtual village by AI agents within a 2D game environment. The core of this study lies in observing and analyzing the interactions and societal development among AI agents, utilizing advanced algorithms for generative behavior modeling and dynamic skill tree learning. These AI agents are endowed with human-like decision-making capabilities, enabled by LLMs, allowing them to engage in complex social interactions and contribute to emergent societal structures within the game. The uniqueness of this project stems from its approach to simulating lifelike social dynamics in a virtual setting, thus addressing a gap in existing research and marking a significant contribution to the interdisciplinary fields of artificial intelligence and game development. By comparing AI-generated societal behaviors with human social interactions, the study delves into the potential of AI to mirror or enhance human social structures, offering a fresh perspective on the capabilities of AI in game development. This research not only aims to push the boundaries of AI applications in game development but also seeks to provide valuable insights into the potential for AI-driven simulations in studying complex social and behavioral dynamics.},
  keywords={Analytical models;Large language models;Heuristic algorithms;Decision making;Virtual environments;Focusing;Games;Large Language Models;Game Development;Artificial Intelligence Agents;Virtual Societies;Autonomous Agents;Social Dynamics Simulation},
  doi={10.1109/IEEECONF61558.2024.10585387},
  ISSN={},
  month={April},}@INPROCEEDINGS{10527283,
  author={de la Torre, Alejandra and Baldeon-Calisto, Maria},
  booktitle={2024 12th International Symposium on Digital Forensics and Security (ISDFS)}, 
  title={Generative Artificial Intelligence in Latin American Higher Education: A Systematic Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The utilization of Artificial Intelligence (AI) and Generative AI (GenAI) in higher education has increased importantly in the last years. Studies show that AI holds promise in enhancing the learning experiences for both students and educators, offering personalized learning and assessment opportunities. This study conducts a systematic review on the application of AI within Latin American higher education. To this end, we synthesized 25 papers published between 2021 and 2023, encompassing AI's utilization in Mexico, Colombia, Ecuador, Brazil, Peru, Chile, Argentina, and Bolivia. The analysis addresses three key inquiries: the prevalent applications of AI in Latin American education, the perceptions of AI and GenAI models among educators and students, and the particular challenges encountered by Latin American institutions in AI implementation. This systematic review offers an updated understanding of AI's role in Latin American higher education, with a particular emphasis on the latest AI technologies.},
  keywords={Training;Technological innovation;Systematics;Reviews;Generative AI;Navigation;Bibliographies;Artificial intelligence;Generative models;Chat-GPT;Latin America;Higher education;Systematic literature review},
  doi={10.1109/ISDFS60797.2024.10527283},
  ISSN={2768-1831},
  month={April},}@INPROCEEDINGS{10629560,
  author={Guo, Muhan},
  booktitle={2024 5th International Conference on Mechatronics Technology and Intelligent Manufacturing (ICMTIM)}, 
  title={Java Web Programming with ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={834-838},
  abstract={With the rapid development of artificial intelligence (AI), ChatGPT is an important technical breakthrough in the field of natural language processing (NLP). ChatGPT, as a large-scale language model, focuses on the task of conversation generation and has attracted wide attention in academia and industry. Meanwhile, it brings opportunities and challenges to Java Web programming. Compared with previous studies that investigated the ability of ChatGPT to solve small-scale Java programming problems that emphasized basic concepts, this paper explores how well ChatGPT can produce sequential Java code to construct the complete Web project. A series of experiments based on the user-login study case are conducted to evaluate the performance of ChatGPT-generated code. Through thorough experimental analysis, the generated code is characterized by high readability, good quality, and complete functionality. However, ChatGPT's performance degrades when instructions contain limited text information. In conclusion, ChatGPT has the potential to be an important assistant for developers, greatly improving efficiency and productivity in the software development process.},
  keywords={Productivity;Java;Codes;Mechatronics;Oral communication;Programming;Chatbots;Artificial intelligence;ChatGPT;Java Web programming;Natural language processing},
  doi={10.1109/ICMTIM62047.2024.10629560},
  ISSN={},
  month={April},}@INPROCEEDINGS{10752300,
  author={Manish, Vazzula and Manchala, Yugandhar and Vijayalata, Y. and Chopra, Sudeep Banerjee and Reddy, Kothi Yashwanth},
  booktitle={2024 IEEE Region 10 Symposium (TENSYMP)}, 
  title={Optimizing Resume Parsing Processes by Leveraging Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In the present era of internet revolution, organizations have to go through numerous resumes in order to identify the most suitable candidates for their Job Description (JD), while ensuring that no acquisition of talent is overlooked through human mistakes. Thus, tools like Applicant Tracking Systems (ATS) have taken over the human process of resume screening, enabling assessment of thousands of resumes in a matter of seconds. Although these technologies are incredibly effective, they are not flawless. Consequently, highly qualified individuals may miss out on said opportunities if their resumes are not formatted correctly. Therefore, individuals must ensure that their resume is appropriately structured prior to submitting it to any organization. The study centers on the present literature and suggests an enhanced approach for parsing resumes by leveraging Large Language Models (LLMs).},
  keywords={Large language models;Resumes;Organizations;Cleaning;Data mining;IEEE Regions;Large Language Model(LLM);Natural Lan-guage Processing (NLP);Deep Learning (DL);Automated Re-sume Parsing;Applicant Tracking Systems (ATS);Software as a Service (SaaS);Human Resources (HR)},
  doi={10.1109/TENSYMP61132.2024.10752300},
  ISSN={2642-6102},
  month={Sep.},}@INPROCEEDINGS{10932399,
  author={Kailash Varma, Nadimpalli Madana and Aryan, Adla and Dhanush, Pagilla and Manikanta, Rangisetti and Chandhu, Nalla and Arora, Gagan Deep},
  booktitle={2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN)}, 
  title={Developing an AI-Based Library Assistant: Enhancing Book Retrieval with Natural Language Processing and Machine Learning}, 
  year={2025},
  volume={},
  number={},
  pages={136-140},
  abstract={The current college library system is hindered by inefficiencies in book searching, availability updates, identity verification, and checkout processes, resulting in delays and errors that negatively impact student experiences. This research paper presents an AI-based librarian system designed to address these challenges through automation and digital transformation. Leveraging a Large Language Model (LLM), the proposed system facilitates personalized interactions between students and library resources. Upon student verification, the AI librarian provides real-time information on book availability, location, and tailored recommendations, significantly reducing the time spent on manual searches. The streamlined checkout process allows for automated book issuance and instant confirmation notifications, minimizing human error and enhancing record- keeping. This innovative solution not only improves operational efficiency but also enriches the user experience by offering a user-friendly interface and timely assistance. Future enhancements, such as voice integration and mobile application support, are suggested to further modernize library services. This research underscores the potential of AI technologies to revolutionize library management and improve service delivery in academic settings.},
  keywords={Knowledge engineering;Automation;Large language models;Manuals;Libraries;Natural language processing;User experience;Real-time systems;Mobile applications;Usability;AI-based librarian;library automation;Large Language Model (LLM);personalized recommendations;student identification;library management system;natural language processing},
  doi={10.1109/CICTN64563.2025.10932399},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10597810,
  author={Cavalleri, Emanuele and Mesiti, Marco},
  booktitle={2024 IEEE 40th International Conference on Data Engineering (ICDE)}, 
  title={Construction and Enhancement of an RNA-Based Knowledge Graph for Discovering New RNA Drugs}, 
  year={2024},
  volume={},
  number={},
  pages={5639-5643},
  abstract={Cutting-edge technologies in RNA biology are pushing the study of fundamental biological processes and human diseases and accelerate the development of new drugs tailored to the patient's biomolecular characteristics. Even if many structured and unstructured data sources report the interaction among different RNA molecules and some other biomedical entities (e.g., drugs, diseases, genes), we still lack a comprehensive and well-described RNA-centered Knowledge Graph (KG) that contains such information and sophisticated services that support the user in its creation, maintenance, and enhancement. This PhD project aims to create a biomedical KG (named RNA-KG) to represent, and eventually infer, biological, experimentally validated interactions between different RNA molecules. We also wish to enhance the KG content and develop sophisticated services designed ad-hoc to support the user in predicting uncovered relationships and identifying new RNA-based drugs. Services will rely on deep learning methods that consider the heterogeneity of the graph and the presence of an ontology that describes the possible relationships existing among the involved entities. Moreover, we will consider Large Language Models (LLMs) in combination with RNA-KG for interacting with the user with the ground truth information contained in our KG for extracting relationships from unstructured data sources.},
  keywords={Drugs;Knowledge engineering;Deep learning;RNA;Soft sensors;Large language models;Knowledge graphs;Biomedical knowledge graphs;Graph representation learning;LLMs;RNA therapeutics},
  doi={10.1109/ICDE60146.2024.00453},
  ISSN={2375-026X},
  month={May},}@ARTICLE{11015551,
  author={Skalka, Ján and Przybyła-Kasperek, Małgorzata and Smyrnova-Trybulska, Eugenia and Klimeš, Cyril and Farana, Radim and Dagienė, Valentina and Dolgopolovas, Vladimiras},
  journal={IEEE Access}, 
  title={Artificial Intelligence Literacy Structure and the Factors Influencing Student Attitudes and Readiness in Central Europe Universities}, 
  year={2025},
  volume={13},
  number={},
  pages={93235-93258},
  abstract={This study examines the structure of artificial intelligence (AI) literacy and factors influencing students’ attitudes, readiness, and perceived relevance of AI in higher education at Central European universities. The research, based on data from 1,195 students enrolled in various study programs between 2022 and 2024, examines how variables such as gender, academic discipline, and year of study influence perceptions related to AI. A validated questionnaire targeting constructs including satisfaction, readiness, and relevance of AI was used. Non-parametric statistical methods were used to identify significant differences between groups, including Kruskal-Wallis and Mann-Whitney tests with Dunn-Bonferroni post hoc analysis. The findings reveal consistent differences across genders and disciplines, with males and IT students demonstrating significantly higher readiness and satisfaction with AI. Furthermore, satisfaction levels fluctuated over time, peaking in 2023 – likely influenced by the widespread adoption of tools like ChatGPT. Correlation analysis further highlighted the subtle interrelationships between constructs across different subgroups. The study underscores the importance of tailored AI education strategies and calls for targeted interventions to ensure equitable engagement with AI across diverse student populations.},
  keywords={Artificial intelligence;Ethics;Education;Engineering profession;Problem-solving;Chatbots;Europe;Collaboration;Social sciences;Learning (artificial intelligence);Artificial intelligence;AI literacy;AI relevance;technology adoption;higher education},
  doi={10.1109/ACCESS.2025.3573575},
  ISSN={2169-3536},
  month={},}@ARTICLE{11005735,
  author={Deng, Zehang and Ma, Wanlun and Han, Qing-Long and Zhou, Wei and Zhu, Xiaogang and Wen, Sheng and Xiang, Yang},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={Exploring DeepSeek: A Survey on Advances, Applications, Challenges and Future Directions}, 
  year={2025},
  volume={12},
  number={5},
  pages={872-893},
  abstract={The rapid advancement of large models has led to the development of increasingly sophisticated models capable of generating diverse, personalized, and high-quality content. Among these, DeepSeek has emerged as a pivotal open-source initiative, demonstrating high performance at significantly lower computation costs compared to closed-source counterparts. This survey provides a comprehensive overview of the DeepSeek family of models, including DeepSeek-V3 and DeepSeek-R1, covering their core innovations in architecture, system pipeline, algorithm, and infrastructure. We explore their practical applications across various domains, such as healthcare, finance, and education, highlighting their impact on both industry and society. Further-more, we examine potential security, privacy, and ethical concerns arising from the widespread deployment of these models, emphasizing the need for responsible AI development. Finally, we outline future research directions to enhance the performance, safety, and scalability of DeepSeek models, aiming to foster further advancements in the open-source large model community.},
  keywords={Surveys;Technological innovation;Ethics;Computational modeling;Pipelines;Finance;Medical services;Computer architecture;Safety;Security;DeepSeek;large language model;large multimodal model},
  doi={10.1109/JAS.2025.125498},
  ISSN={2329-9274},
  month={May},}@INPROCEEDINGS{10650776,
  author={Wang, Yu and Liu, Xin and Lu, Xuesong and Zhou, Aoying},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={iiPCS: Intent-Based In-Context Learning for Project-Specific Code Summarization}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Recent years have witnessed growing research interest in automatic source code summarization due to its beneficial potential in software development and maintenance tasks. In the past few years, various deep learning models have been developed to leverage structural and textual features in the code for generating meaningful and succinct summaries. However, the summaries generated by traditional deep learning models often have syntax errors or are meaningless. The emergence of large language models provides an opportunity to overcome the problem. However, the quality of the summaries largely depends on the in-context learning examples of code-summary pairs. In this work, we develop iiPCS, an LLM-based method for code summarization. We retrieve relevant code-summary pairs as in-context learning examples from the same project of the target code, which ensures to generate more project-specific summaries, and use the predicted intent of the target code to pick few-shot examples, which ensures to generate summaries with the correct intent. Experimental results show that iiPCS can generate code summaries with higher quality compared to traditional methods using deep learning and recent methods using LLMs.},
  keywords={Deep learning;Codes;Source coding;Large language models;Semantics;Neural networks;Syntactics;Code Summarization;Large Language Models;Project-specific Summaries;In-context Learning;Developer Intent},
  doi={10.1109/IJCNN60899.2024.10650776},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10765003,
  author={Wu, Yueming and Liu, Chengwei and Xu, Zhengzi and Zhang, Lyuye and Zhang, Yiran and Zhu, Zhiling and Liu, Yang},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={The Software Genome Project: Unraveling Software Through Genetic Principles}, 
  year={2024},
  volume={},
  number={},
  pages={2319-2323},
  abstract={Open-source software is crucial to modern development, but its complexity creates challenges in quality, security, and management. Current governance approaches excel at collaboration but struggle with decentralized management and security. With the rise of large language models (LLM)-based software engineering, the need for a finer-grained understanding of software composition is more urgent than ever. To address these challenges, inspired by the Human Genome Project, we treat the software source code as software DNA and propose the Software Genome Project (SGP), which is geared towards the secure monitoring and exploitation of open-source software. By identifying and labeling integrated and classified code features at a fine-grained level, and effectively identifying safeguards for functional implementations and non-functional requirements at different levels of granularity, the SGP could build a comprehensive set of software genome maps to help developers and managers gain a deeper understanding of software complexity and diversity. By dissecting and summarizing functional and undesirable genes, SGP could help facilitate targeted software optimization, provide valuable insight and understanding of the entire software ecosystem, and support critical development tasks such as open source governance. SGP could also serve as a comprehensive dataset with abundant semantic labeling to enhance the training of LLMs for code. Based on these, we expect SGP to drive the evolution of software development towards more efficient, reliable, and sustainable software solutions.CCS Concepts• Software and its engineering → Software design engineering.},
  keywords={Codes;Ecosystems;Genomics;Software;Complexity theory;Security;Labeling;Bioinformatics;Open source software;Software engineering;Software Genes;Software Composition;OSS Governance},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{10740416,
  author={Yabaku, Mounika and Pombo, Nuno and Ouhbi, Sofia},
  booktitle={2024 IEEE 18th International Conference on Application of Information and Communication Technologies (AICT)}, 
  title={Exploring the Potential Use of Generative AI in Software Engineering Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The integration of Generative AI into software engineering education marks a transformative shift in teaching methodologies. This paper explores its potential, highlighting the benefits of enhancing student engagement, creativity, and efficiency while preparing them for industry challenges. Through a comprehensive analysis of 13 popular generative AI tools, we examine their roles in various software engineering tasks such as requirements analysis, design, coding, debugging, and testing. This paper contributes to the broader discourse on the future of software engineering education by offering evidence-based recommendations for leveraging generative AI to create adaptive and forward-thinking instructional strategies.},
  keywords={Generative AI;Education;Debugging;Software;Requirements engineering;Software measurement;Usability;Software engineering;Testing;Software development management;Generative AI;Large Language Models (LLMs);Software Engineering Education;Pedagogical Innovation;AIDriven Educational Tools},
  doi={10.1109/AICT61888.2024.10740416},
  ISSN={2472-8586},
  month={Sep.},}@INPROCEEDINGS{10893388,
  author={Mackay, Sean and Eiselt, Kurt and Decker, Adrienne},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Two Sides of the Same Coin: Differing Approaches to Generative AI in Two Computer Science Classrooms}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice paper explores two differing approaches to the use of artificial intelligence tools in computer science classrooms. Artificial Intelligence (AI), while not a new technology, has seen a rise in popularity over the past two years, with companies such as OpenAI, Google, and Microsoft making readily available generative AI tools for anyone to use. This surge in AI popularity has led to a rise in its use in educational settings, in some cases allowed and in others discouraged or disallowed. A debate has risen among academics, particularly in higher education, about what AI's place in education is, with some educators actively encouraging its use while others view the use of AI as a form of academic dishonesty. Given AI is only advancing and is becoming more prevalent, it will only continue to become a more dominant force throughout education and the world at large. This paper presents two educators' distinct viewpoints and experiences on how AI should be handled in computer science courses (absolutely forbidden vs. decriminalized). The goal of this paper is to present different perspectives as well as concrete experiences we have had with AI in our own classrooms to encourage others to consider their own positions on its use and its implications for their own learning environments. While the debate on the place of AI in education is a long way from being settled, educators need to think about making choices, clearly articulating policies, and evaluating the positives and negatives of positions about AI in their classrooms.},
  keywords={Codes;Generative AI;Affordances;Education;Force;Companies;Internet;Computer science education;Surges;Programming profession;academic integrity;LLM's;course policies;AI in education},
  doi={10.1109/FIE61694.2024.10893388},
  ISSN={2377-634X},
  month={Oct},}@INBOOK{10952004,
  author={Pandey, Shubham and Patel, Archana and Pokhariyal, Purvi},
  booktitle={Artificial Intelligence for Risk Mitigation in the Financial Industry}, 
  title={Exploring the Role of ChatGPT in the Law Enforcement and Banking Sectors}, 
  year={2024},
  volume={},
  number={},
  pages={327-347},
  abstract={Summary <p>This chapter explores the role of ChatGPT, a powerful artificial intelligence (AI) tool, in the law enforcement and banking sectors. ChatGPT has the potential to revolutionize these industries by offering a wide range of applications and benefits. In law enforcement, ChatGPT can assist in investigative analysis, risk assessment, virtual training, and crime prevention. In the banking sector, it can provide customer support, aid in fraud detection, assist with risk assessment and compliance, and offer personalized financial advice. However, the implementation of ChatGPT also raises concerns related to privacy, security, and the need for human oversight. Therefore, it is crucial to address these concerns and establish regulatory frameworks to govern the use of advanced technologies effectively. This chapter aims to provide legal and technical recommendations to regulate ChatGPT's usage and mitigate associated risks.</p>},
  keywords={Chatbots;Banking;Law enforcement;Artificial intelligence;Translation;Risk management;Fraud;Transformers;Risk mitigation;Oral communication},
  doi={10.1002/9781394175574.ch13},
  ISSN={},
  publisher={Wiley},
  isbn={9781394175567},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10952004},}@INPROCEEDINGS{10967276,
  author={Liao, Zhifang and Liu, Pei and Lan, Peng and Sun, Ke},
  booktitle={2024 31st Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={DupLLM:Duplicate Pull Requests Detection Based on Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={121-130},
  abstract={As the scale of projects expands, the concurrent development model adopted by the open source community leads to an increasingly prominent problem of repetitive pull requests (PRs). The large number of rejections caused by duplicate pull requests increases the review workload of project maintainers and reduces the efficiency of pull request review. Therefore, it is very necessary to conduct automated duplicate PR detection. In this study, we propose DupLLM, a framework designed to detect duplicate PRs. The framework generates refined sum-maries by feeding the content of individual PRs into a large language model (LLM). Subsequently, the resulting summary is vectorized, converting the textual content into a numerical representation. The similarity between PRs is evaluated by calculating the similarity score between PR summary vectors. Ultimately, the model showed better performance than the best existing model, achieving an effect of 0.929 on P@l. This confirms that LLM can also achieve equivalent results in the field of duplicate PR detection as deep learning is used to train on this task, providing a new direction for the application of LLM in the field of software engineering.},
  keywords={Training;Deep learning;Codes;Reviews;Large language models;Merging;Vectors;Numerical models;Software engineering;Software development management;LLM;Pull Request;GitHub;duplicate Pull Request detection},
  doi={10.1109/APSEC65559.2024.00023},
  ISSN={2640-0715},
  month={Dec},}@INPROCEEDINGS{10574587,
  author={Shan, J and Eliyas, Sherin},
  booktitle={2024 3rd International Conference on Artificial Intelligence For Internet of Things (AIIoT)}, 
  title={Exploring AI Facial Recognition for Real-time Emotion Detection: Assessing Student Engagement in Online Learning Environments}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={AI facial recognition for real-time emotion detection in online learning environments intends to analyze students’ sentiments throughout online classes, recognizing emotions such as focused, neutral, distracted, enraged, thrilled, or dissatisfied states. The proposed approach uses a generative model trained by conditional Generative Adversarial Networks (cGAN) to accomplish De-expression Residue Learning (DeRL), a facial expression recognition technique. DeRL prioritizes gathering residue for delicate emotion recognition by filtering expressive material and storing it in intermediary layers. This technology gives educators and researchers real-time insights into students’ emotional states, allowing for a more thorough understanding of collective student involvement through the lens of socially shared control of learning. Experiments on seven facial expression databases, including two pre-training datasets, indicate that DeRL outperforms other methods in accurately recognizing and classifying students’ emotions. The findings emphasize its ability to capture subtle feelings during online learning. The discussion dives into theoretical and practical implications, highlighting AI’s potential to enhance the evaluation of student participation in online learning environments. The study concludes by providing relevant information for building tailored learning experiences, indicating a possible avenue for incorporating AI in the classroom.},
  keywords={Emotion recognition;Filtering;Databases;Face recognition;Buildings;Learning (artificial intelligence);Generative adversarial networks;Facial Expression Identification;Psychological Control;Socially Integrated Supervision;Pre-training;De-expression Residue Learning;Synchronous online education;Computer-supported interactive education;conditional Generative Adversarial;Network;Student Self-regulation},
  doi={10.1109/AIIoT58432.2024.10574587},
  ISSN={},
  month={May},}@BOOK{10522580,
  author={Ping, David},
  booktitle={The Machine Learning Solutions Architect Handbook: Practical strategies and best practices on the ML lifecycle, system design, MLOps, and generative AI},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Design, build, and secure scalable machine learning (ML) systems to solve real-world business problems with Python and AWS Purchase of the print or Kindle book includes a free PDF eBookKey FeaturesGo in-depth into the ML lifecycle, from ideation and data management to deployment and scalingApply risk management techniques in the ML lifecycle and design architectural patterns for various ML platforms and solutionsUnderstand the generative AI lifecycle, its core technologies, and implementation risksBook DescriptionDavid Ping, Head of GenAI and ML Solution Architecture for global industries at AWS, provides expert insights and practical examples to help you become a proficient ML solutions architect, linking technical architecture to business-related skills. You'll learn about ML algorithms, cloud infrastructure, system design, MLOps , and how to apply ML to solve real-world business problems. David explains the generative AI project lifecycle and examines Retrieval Augmented Generation (RAG), an effective architecture pattern for generative AI applications. You’ll also learn about open-source technologies, such as Kubernetes/Kubeflow, for building a data science environment and ML pipelines before building an enterprise ML architecture using AWS. As well as ML risk management and the different stages of AI/ML adoption, the biggest new addition to the handbook is the deep exploration of generative AI. By the end of this book , you’ll have gained a comprehensive understanding of AI/ML across all key aspects, including business use cases, data science, real-world solution architecture, risk management, and governance. You’ll possess the skills to design and construct ML solutions that effectively cater to common use cases and follow established ML architecture patterns, enabling you to excel as a true professional in the field.What you will learnApply ML methodologies to solve business problems across industriesDesign a practical enterprise ML platform architectureGain an understanding of AI risk management frameworks and techniquesBuild an end-to-end data management architecture using AWSTrain large-scale ML models and optimize model inference latencyCreate a business application using artificial intelligence services and custom modelsDive into generative AI with use cases, architecture patterns, and RAGWho this book is forThis book is for solutions architects working on ML projects, ML engineers transitioning to ML solution architect roles, and MLOps engineers. Additionally, data scientists and analysts who want to enhance their practical knowledge of ML systems engineering, as well as AI/ML product managers and risk officers who want to gain an understanding of ML solutions and AI risk management, will also find this book useful. A basic knowledge of Python, AWS, linear algebra, probability, and cloud infrastructure is required before you get started with this handbook.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781805124825},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10522580},}@INPROCEEDINGS{10550837,
  author={Samarakoon, Pramodya and Asanka, Dinesh and Jayalal, Shantha and Jayalath, Nirasha},
  booktitle={2024 International Research Conference on Smart Computing and Systems Engineering (SCSE)}, 
  title={Analyzing the Learning Effectiveness of Generative AI for Software Development for Undergraduates in Sri Lanka}, 
  year={2024},
  volume={7},
  number={},
  pages={1-7},
  abstract={As the demand for skilled software developers continues to rise, the integration of Generative Artificial Intelligence (Generative AI) in educational settings has garnered attention. This research investigates the effectiveness of Generative AI in enhancing coding proficiency in a diverse cohort of participants. The study employs pre-, mid-, and post-tests to measure coding skills, employing a nuanced analysis across various demographic variables. The findings reveal a substantial increase in average scores, indicating positive impacts of Generative AI on coding abilities. The N-Gain value of 0.33 signifies a medium learning gain, establishing Generative AI as a valuable tool in coding education. A detailed exploration of demographic variables, including gender, age, academic level, A/L stream, A/L district, and preferred programming language, provides insights into the intersectionality of these factors with learning outcomes. This research contributes to the discourse on the impact of Generative AI on coding skills, offering practical insights for educators, policymakers, and practitioners. The study recommends tailored interventions to address specific demographic variables, fostering a more inclusive and effective learning environment.},
  keywords={Computer languages;Generative AI;Atmospheric measurements;Education;Systems engineering and theory;Particle measurements;Encoding;Generative AI;Learning Effectiveness;Software Development Education;Undergraduate Students},
  doi={10.1109/SCSE61872.2024.10550837},
  ISSN={2613-8662},
  month={April},}@INPROCEEDINGS{10762540,
  author={Hartato, Frandi and Yahya, Jovan and Enrico Christiano Hartono, Liem and Sudiana},
  booktitle={2024 International Seminar on Application for Technology of Information and Communication (iSemantic)}, 
  title={Art in the Era of Algorithms: Is Generative AI a Friend or Foe for 2D Artists?}, 
  year={2024},
  volume={},
  number={},
  pages={190-195},
  abstract={This research investigates the transformative impact of AI technologies such as DALL-E, ChatGPT, and other generative AI tools on the arts, particularly focusing on their implications for 2D artwork. These advancements have democratized the creation of 2D art, making it more accessible, but they have also raised concerns about the value of original talent and the potential impact on careers in the arts. The study employs the Technology Acceptance Model (TAM) to evaluate the acceptance and impact of generative AI among individuals in creative fields, including students, lecturers, and professionals. Data collected from 127 respondents through structured surveys indicate high levels of engagement with generative AI, reflecting significant curiosity and usage rates. Analysis using SmartPLS 4.0 Tools validated the initial research model, demonstrating that generative AI significantly influences perceived usefulness, perceived ease of use, and behavioral intention in 2D art creation. These findings underscore the critical need to consider AI's evolving role in the arts, its impact on perceptions of creativity and talent, and its broader implications for the creative industry. The study tested seven hypotheses, with six accepted and one rejected. This indicates that while factors like user computer self-efficacy and quality information significantly influence the perceived usefulness and ease of use of generative AI, ease of use alone does not necessarily lead to a positive attitude towards its use. However, perceived usefulness significantly contributes to a positive attitude towards using generative AI. Additionally, a positive attitude towards generative AI influences the behavioral intention to use it, thereby enhancing skills and providing inspiration for creating artwork.},
  keywords={Surveys;Seminars;Productivity;Industries;Java;Art;Technology acceptance model;Generative AI;Focusing;Chatbots;Artificial Intelligence;Generative AI;2D Artist;TAM Model;SEM-PLS},
  doi={10.1109/iSemantic63362.2024.10762540},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10971486,
  author={Marefat, Alireza and Nishar, Abbaas Alif Mohamed and Ashok, Ashwin},
  booktitle={SoutheastCon 2025}, 
  title={Text2Net: Transforming Plain-text to a Dynamic Interactive Network Simulation Environment}, 
  year={2025},
  volume={},
  number={},
  pages={625-630},
  abstract={This paper introduces Text2Net, an innovative text-based network simulation engine that leverages natural language processing (NLP) and large language models (LLMs) to transform plain-text descriptions of network topologies into dynamic, interactive simulations. Text2Net simplifies the process of configuring network simulations, eliminating the need for users to master vendor-specific syntaxes or navigate complex graphical interfaces. Through qualitative and quantitative evaluations, we demonstrate Text2Net's ability to significantly reduce the time and effort required to deploy network scenarios compared to traditional simulators like EVE-NG. By automating repetitive tasks and enabling intuitive interaction, Text2Net enhances accessibility for students, educators, and professionals. The system facilitates hands-on learning experiences for students that bridge the gap between theoretical knowledge and practical application. The results showcase its scalability across various network complexities, marking a significant step toward revolutionizing network education and professional use cases, such as proof-of-concept testing.},
  keywords={Protocols;Navigation;Scalability;Transforms;Routing;Rapid prototyping;Natural language processing;Virtual private networks;Pattern matching;Testing;Network Simulation and Emulation;Educational Technology;AI in Education;Interactive Learning Environments;Network Configuration Automation;AI-driven Network},
  doi={10.1109/SoutheastCon56624.2025.10971486},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{11009556,
  author={Liu, Kai},
  booktitle={2025 7th International Conference on Software Engineering and Computer Science (CSECS)}, 
  title={A Stylistic Comparative Study for Evaluating Neural Machine Translation Technologies}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Neural network-based online machine translation technologies have brought great convenience to foreign language teaching and research. However, performance evaluation of these translation technology models from the perspective of stylistic comparisons are currently scarce. In this study, Wenxin 4.0, DeepSeek-V3, and ChatGPT are used to translate a selection from an ancient Chinese story, and a stylistic comparison is conducted among the three versions of translation. By analyzing the transitivity processes of the original text, along with the three translated versions, it is found that the translations processed by the three technological models are closely similar to the original text in terms of the number and type distribution of transitivity processes. Nevertheless, there were certain differences in the use of mental and behavioral processes compared to the original text. Comparing the semantic configuration, as well as the stylistic feature distributions of the translated versions and the original text, is conducive to examining the differences in existing online translation technology models, both at home and abroad, when handling document-level translation units. This provides a basis for performance evaluation to support technological updates.},
  keywords={Performance evaluation;Fans;Translation;Computational modeling;Semantics;Education;Neural machine translation;Linguistics;Machine translation;Software engineering;Online Machine Translation;Technological Model;Semantic Configuration;Interlingual Translation;Stylistic Comparison;Performance Evaluation},
  doi={10.1109/CSECS64665.2025.11009556},
  ISSN={},
  month={March},}@INPROCEEDINGS{10731435,
  author={Mannava, Vivek and Mitrevski, Alex and Plöger, Paul G.},
  booktitle={2024 33rd IEEE International Conference on Robot and Human Interactive Communication (ROMAN)}, 
  title={Exploring the Suitability of Conversational AI for Child-Robot Interaction}, 
  year={2024},
  volume={},
  number={},
  pages={1821-1827},
  abstract={Current approaches in education, while aiming to be universally effective, often struggle to fully adapt to the unique needs and communication styles of individual children; this disparity can limit the children’s engagement and hinder their learning progress. Similarly, parents or guardians, despite their good intentions, may also be unable to provide consistent and personalized support to each child. In this work, we investigate the use of conversational systems for socially assistive robots (SARs) as a potential solution to this problem, as such systems have the potential to allow children to interact and learn at their own pace, in a way that aligns with their communication preferences. To ensure that the robot’s language is suitable for children, we present a system that leverages a combination of natural language processing (NLP) techniques, including dialog management, child-friendly language generation, and context-aware response adaptation; to achieve this, our system combines Rasa for dialog management, GPT-3.5 for language generation, and textstat for language complexity evaluation. We evaluate the suitability of the generated language for a young audience through two user studies with adult participants, one in which the conversational system was embodied in a robot and involved direct interaction between a human and a robot, and another where participants evaluated conversational transcripts from the first study. Our results suggest that the system has the potential to maintain engaging and safe conversations, and adapt its language to individual needs.},
  keywords={Education;Oral communication;Assistive robots;Natural language processing;Complexity theory;Robots},
  doi={10.1109/RO-MAN60168.2024.10731435},
  ISSN={1944-9437},
  month={Aug},}@INPROCEEDINGS{10260821,
  author={Birkmeier, Dominik Q. and Beck, Martina},
  booktitle={2023 IEEE 31st International Requirements Engineering Conference (RE)}, 
  title={Digital Design - Shaping a Sustainable Digital Future Requires a New Holistic Design Approach}, 
  year={2023},
  volume={},
  number={},
  pages={255-263},
  abstract={In today's digital age, businesses of all sizes face the challenge of adapting to the rapid pace of technological advancements, including new possibilities like ChatGPT, AI in general, Voice User Interfaces, and the Metaverse. In our experience, many companies still lack awareness of the need for digital transformation or are simply not ready for it. The integration of physical and digital products has led to an increase in complexity for both users and companies, necessitating a holistic design approach to encapsulate this complexity and shape a sustainable digital future. While traditional requirements engineering with solution-neutral requirements has been the norm, it is not sufficient for these new core issues. Digital design, with its emphasis on user centered design, technological possibilities, and a comprehensive understanding of the digital ecosystem, fills this gap in requirements engineering. By incorporating digital design competence in every project, companies can design sustainable digital solutions that integrate seamlessly with the user's needs and the company's goals. In this paper, we propose a new field of competence: Digital Design. Within this field we suggest a new model for Shaping, Exploring, and Implementing innovative digital products. As we discuss the steps that science and practice must take to ensure that every project incorporates digital design competence, our paper provides insights for both academia and industry.},
  keywords={Industries;Shape;Metaverse;User centered design;Companies;User interfaces;Information age;digital design;digital innovation;awareness;readiness;sustainability;shaping;exploring;implementing},
  doi={10.1109/RE57278.2023.00033},
  ISSN={2332-6441},
  month={Sep.},}@INPROCEEDINGS{10408241,
  author={Tolk, Andreas and Barry, Philip and Loper, Margaret L. and Rabadi, Ghaith and Scherer, William T. and Yilmaz, Levent},
  booktitle={2023 Winter Simulation Conference (WSC)}, 
  title={Chances and Challenges of ChatGPT and Similar Models for Education in M&S}, 
  year={2023},
  volume={},
  number={},
  pages={3332-3346},
  abstract={This position paper summarizes the inputs of a group of experts from academia and industry presenting their view on chances and challenges of using ChatGPT within Modeling and Simulation education. The experts also address the need to evaluate continuous education as well as education of faculty members to address scholastic challenges and opportunities while meeting the expectation of industry. Generally, the use of ChatGPT is encouraged, but it needs to be embedded into an updated curriculum with more emphasis on validity constraints, systems thinking, and ethics.},
  keywords={Industries;Ethics;Education;Chatbots;Systems thinking;Artificial intelligence},
  doi={10.1109/WSC60868.2023.10408241},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{10628480,
  author={Arora, Chetan and Herda, Tomas and Homm, Verena},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference (RE)}, 
  title={Generating Test Scenarios from NL Requirements Using Retrieval-Augmented LLMs: An Industrial Study}, 
  year={2024},
  volume={},
  number={},
  pages={240-251},
  abstract={Test scenarios are specific instances of test cases that describe a sequence of actions to validate a particular software functionality. By outlining the conditions under which the software operates and the expected outcomes, test scenarios ensure that the software functionality is tested in an integrated manner. Test scenarios are crucial for systematically testing an application under various conditions, including edge cases, to identify potential issues and guarantee overall performance and reliability. Manually specifying test scenarios is tedious and requires a deep understanding of software functionality and the underlying domain. It further demands substantial effort and investment from already time- and budget-constrained requirements engineers and testing teams. This paper presents an automated approach (RAGTAG) for test scenario generation using Retrieval-Augmented Generation (RAG) with Large Language Models (LLMs). RAG allows the integration of specific domain knowledge with LLMs' generation capabilities. We evaluate RAGTAG on two industrial projects from Austrian Post with bilingual requirements in German and English. Our results from an interview survey conducted with four experts on five dimensions – relevance, coverage, correctness, coherence and feasibility, affirm the potential of RAGTAG in automating test scenario generation. Specifically, our results indicate that, despite the difficult task of analyzing bilingual requirements, RAGTAG is able to produce scenarios that are well-aligned with the underlying requirements and provide coverage of different aspects of the intended functionality. The generated scenarios are easily understandable to experts and feasible for testing in the project environment. The overall correctness is deemed satisfactory; however, gaps in capturing exact action sequences and domain nuances remain, underscoring the need for domain expertise when applying LLMs.},
  keywords={Surveys;Large language models;Coherence;Software systems;Software reliability;Scenario generation;Requirements engineering;Requirements Engineering;Requirements-driven Testing;Test Scenarios;Large Language Models (LLMs);Industry Study},
  doi={10.1109/RE59067.2024.00031},
  ISSN={2332-6441},
  month={June},}@INPROCEEDINGS{10336257,
  author={Kumar, Abhishek and Das, Partha Pratim and Pratim Chakrabarti, Partha},
  booktitle={2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Summarize Me: The Future of Issue Thread Interpretation}, 
  year={2023},
  volume={},
  number={},
  pages={341-345},
  abstract={Understanding issue threads is an essential aspect of software maintenance and development, aiding developers in effectively addressing and managing software-related issues. These threads typically contain an issue description, comments discussing possible solutions, and often culminate in a pull request where the proposed changes are elaborated. Even though they are crucial, understanding issue threads can be a lot of work because they are often long and complex, particularly in big projects. This paper, therefore, aims to automate the process of issue thread summarization using advanced AI models, specifically the GPT-3.5-Turbo, reducing the time spent and improving the efficiency of the interpretation process. Our approach taps into the potential of the zero-shot learning methodology, enabling the model to produce context-specific summaries without reliance on prior examples. Additionally, we have developed an algorithm that determines the most effective length for these summaries, which enhances their clarity and relevance. The performance of the model is assessed using automated metrics, including ROUGE and BART scores, for extractive and abstractive summary evaluation respectively. Further, we may like to add that summaries of around 30% to 40% of the total size of the issue thread appears to be sufficient, though it varies slightly from case to case. The model’s successful generation of brief, clear, and pertinent summaries not only boosts team communication and project management but also lays the groundwork for its future integration into a comprehensive tool for simplified exploration and comprehension of complex software repositories.},
  keywords={Measurement;Software maintenance;Zero-shot learning;Project management;Artificial intelligence;Context modeling;Issue Thread Summarization;Machine Learning;Software maintenance;Zero-shot learning;ROUGE and BART scores},
  doi={10.1109/ICSME58846.2023.00042},
  ISSN={2576-3148},
  month={Oct},}@INPROCEEDINGS{10534929,
  author={Zhou, Ethan Phoenix},
  booktitle={2023 IEEE MIT Undergraduate Research Technology Conference (URTC)}, 
  title={The Fallibility of AI Content Detectors}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={With the release of ChatGPT, faculty started adopting AI content detectors to identify AI-generated content. However, faulty detector results led to wrongful accusations against some students. This study evaluates AI content detectors' performance in distinguishing human-written from AI-generated content. Three detectors, Writer, ZeroGPT, and OpenAI Text Classifier, were tested on three types of writing samples: human-written, human written and edited by ChatGPT, and fully AI-generated. Data was categorized into AI-generated, maybe AI, and human-written outputs for each detector. Statistical analysis, including chi-square tests, assessed detector outputs and text sample sources' relationship. Results revealed that only ZeroGPT's outputs depended on the sources but only correctly classified 47.2% of human-written texts.},
  keywords={Statistical analysis;Social networking (online);Fault detection;Text categorization;Detectors;Writing;Chatbots;AI Content Detectors;Statistical Analysis;Inappropriate AI Use},
  doi={10.1109/URTC60662.2023.10534929},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10435711,
  author={Song, Wei and Gan, Lu and Bao, Tie},
  booktitle={2023 3rd International Conference on Communication Technology and Information Technology (ICCTIT)}, 
  title={Software Defect Prediction via Code Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={97-102},
  abstract={Software defect prediction has been effective practice to improve software quality and avoid attacks. Traditional defect prediction models with static or other features cannot understand syntactic and semantic structures well. Recently, large language models like GPT-series show impressive energy on considerable number of tasks. In the realm of software engineering, it has been shown that code language models largely benefit a broad set of code-related downstream tasks. In this paper, we employ code language models with distinct architectures for defect prediction. we propose a unified bi-modal input representation to enhance the comprehension of semantic information. Furthermore, a new bi-modal dataset is proposed based on the PROMISE repository and the engineering files. A large number of experiments are conducted on both within and cross project for evaluation and comparison. The results demonstrate the effectiveness of our proposed method for software defect prediction, which outperforms the state-of-the-art baselines. Among the three architectures, encoder-only achieve the most effective and efficient.},
  keywords={Codes;Semantics;Computer architecture;Predictive models;Syntactics;Software;Task analysis;software defect prediction;code language models;bi-modal representation;semantic information},
  doi={10.1109/ICCTIT60726.2023.10435711},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10956758,
  author={Mawardi, Viny Christanti and Kevin Jonathan, J M and Syahwalina, Jane and Monika, Sesilia and Widoatmodjo, Sawidji and Wijaya, Erik},
  booktitle={2024 Ninth International Conference on Informatics and Computing (ICIC)}, 
  title={Dataset Alignment for Fine-Tuning Large Language Models for PJOK Educational Chatbot}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={BERT is one of the methods in LLMs that can be used to build chatbots. The resulting chatbot is like a question-and-answer system. There are three main stages in adapting BERT for a specific domain: dataset collection, creation, and fine-tuning. BERT is one of the models that has been pre-trained on a very large corpus of text. For Indonesian, there is already IndoBert which has been pre-trained with 220 million words. If it can be adapted to a specific domain, then BERT needs to be fine-tuned with a new dataset that must be prepared in advance. In this research, a chatbot was created using the BERT method and collecting a dataset of PJOK subjects. In this research, a dataset was collected to meet the needs of an educational chatbot in the field of sports and health for elementary school students. The dataset collection involved students, teachers, and student assistants to align it with elementary school textbooks. The result of this research is an alignment dataset containing 300 elementary school physical education (PJOK) questions, complete with context sourced from textbooks. This research successfully produced an alignment dataset with an accuracy of 84 percent.},
  keywords={Training;Accuracy;Large language models;User interfaces;Data collection;Chatbots;Data models;Tokenization;Informatics;Sports;chatbot;BERT;dataset alignment;elementary;PJOK},
  doi={10.1109/ICIC64337.2024.10956758},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10541497,
  author={Tateiwa, Yuichiro},
  booktitle={2024 7th International Conference on Information and Computer Technologies (ICICT)}, 
  title={Development of Dialogue Feature between Participants and ChatGPT in Network Security Exercise System}, 
  year={2024},
  volume={},
  number={},
  pages={479-484},
  abstract={The author confirmed that ChatGPT can provide advice including specific implementation examples on computer network management by dialogue with ChatGPT. According to this confirmation, it is expected that in network security exercises, ChatGPT will be able to resolve participants' network troubles in place of instructors or teaching assistants. In the network security exercises provided by the author, participants perform various communication experiments in a virtual network consisting of virtual machines as nodes. This paper describes a method for collecting network configuration information and conveying it to ChatGPT based on a custom YANG model, as well as a user interface for facilitating dialogue between participants and ChatGPT.},
  keywords={Performance evaluation;Computational modeling;Unified modeling language;Prototypes;Network security;User interfaces;Chatbots;ChatGPT;Network;Security;e-learning;Exercise;YANG model;Large Language Models;Virtual Machine;Dialogue},
  doi={10.1109/ICICT62343.2024.00084},
  ISSN={2769-4542},
  month={March},}@ARTICLE{11020639,
  author={Cervantes, Pablo and Sekikawa, Yusuke and Sato, Ikuro and Shinoda, Koichi},
  journal={IEEE Access}, 
  title={Integrating Generative and Contrastive Approaches for Human Action Recognition}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This study introduces a novel approach to unsupervised skeleton-based human action recognition by integrating generative and contrastive learning methods. We propose a decomposition of representations, allowing for the preservation of detailed motion information for the generative learning objective while also extracting action features for the contrastive learning objective. By swapping contrastive representations between positive pairs (coining the name SwapCLR), we ensure that the generative and contrastive representations are complementary and both objectives contribute to learning a strong representation for downstream tasks like action recognition. Additionally, we address the challenge of noisy data in skeleton-based action recognition with a new saturating reconstruction loss, significantly reducing the impact of noise common to key-point detections. Our method demonstrates state-of-the-art performance in unsupervised action recognition on the NTU and PKU-MMD datasets, while also enabling generative downstream tasks such as motion in-painting and motion generation. Overall, these experimental results confirm the method’s effectiveness and suggest its applicability to a variety of action analysis tasks.},
  keywords={Reactive power;Noise;Training;Noise measurement;Skeleton;Contrastive learning;Data models;Training data;Three-dimensional displays;Human activity recognition;Generative and Contrastive;Representation Learning;Unsupervised 3D Action Recognition},
  doi={10.1109/ACCESS.2025.3575707},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10836262,
  author={Al-Ahmad, Ahmad and Kahtan, Hasan and Tahat, Luay and Tahat, Tarek},
  booktitle={2024 International Conference on Decision Aid Sciences and Applications (DASA)}, 
  title={Enhancing Software Engineering with AI: Key Insights from ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Artificial intelligence (AI) is currently a prominent topic in the field of software engineering. AI has greatly transformed software engineering by providing advanced tools that may boost the effectiveness and efficiency of various stages of the system development life cycle. In this paper, we examine the role of AI by focusing primarily on ChatGPT, an OpenAI language model. The research explores how ChatGPT can assist in software engineering tasks such as code generation, bug fixing, and documentation development. Through an analysis of real-world scenarios, the case study highlights the benefits and challenges of using AI tools in these three areas. The findings show that although AI can accelerate the output and simplify processes, its application must be carefully considered because it has issues in terms of lack of context awareness regarding performance considerations, project-specific requirements, its inability to access real-time logs or inspect environments, and its tendency to produce documentation that doesn't capture the necessary details for complex systems.},
  keywords={Productivity;Codes;Computer bugs;Documentation;Software quality;Chatbots;Real-time systems;Artificial intelligence;Software engineering;Software development management;Artificial Intelligence;Software Engineering;ChatGPT;Code Generation;Documentation Generation},
  doi={10.1109/DASA63652.2024.10836262},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10309699,
  author={Lee, Chang-Shing and Wang, Mei-Hui and Chen, Chih-Yu and Reformat, Marek and Nojima, Yusuke and Kubota, Naoyuki},
  booktitle={2023 IEEE International Conference on Fuzzy Systems (FUZZ)}, 
  title={Knowledge Graph-Based Genetic Fuzzy Agent for Human Intelligence and Machine Co-Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper proposes a novel approach for evaluating the co-learning performance of human intelligence (HI) and machine intelligence (MI) using a Knowledge Graph-based genetic fuzzy agent. The agent utilizes a Knowledge Graph structure to represent a specific knowledge domain related to human learning and employs a genetic fuzzy learning mechanism to construct a personalized learning model. Human learners can engage in co-learning with machines using state-of-the-art AI tools such as the Meta AI S2ST Taiwanese-English language model and the OpenAI ChatGPT text model. The proposed approach was evaluated using human learning data from an undergraduate computer science course and a series of Taiwanese and English language translation experience activities. The experimental results indicate that the proposed approach can effectively enhance the co-learning process for both human and machine learners.},
  keywords={Computer science;Learning systems;Human intelligence;Computational modeling;Speech recognition;Genetics;Chatbots;Knowledge Graph;Genetic Algorithm;Fuzzy Agent;MetaAI S2ST;Human Intelligence;OpenAI ChatGPT},
  doi={10.1109/FUZZ52849.2023.10309699},
  ISSN={1558-4739},
  month={Aug},}@ARTICLE{10718294,
  author={Feng, Wenyan and Li, Yuhang and Ma, Chunhao},
  journal={IEEE Access}, 
  title={Examining Non-English Foreign Language Education Through Social Media: Discourse and Psychological Analysis Based on Text Mining}, 
  year={2024},
  volume={12},
  number={},
  pages={152568-152578},
  abstract={Based on data from Weibo, the largest social media platform in China, this study employs a composite text mining approach to analyze public discussions about learning non-English foreign languages in recent years, with a focus on the emergence of ChatGPT as a pivotal influence. Through topic modeling and psychological characteristics analysis using the Linguistic Inquiry and Word Count (LIWC) dictionary, this research uncovers key topics and psychological traits associated with discussions on Weibo about non-English foreign language education. Identified topics include Employment, Regrets, Cultural Exchange, and Going Abroad, among others. Analysis of language use reveals significant shifts in psychological characteristics following the rise of ChatGPT, with complex interrelations between these traits and variations across different discussion phases. This study offers valuable insights into Chinese public interest in non-English foreign language education, contributing to the development and refinement of foreign language education in China. It also validates a composite methodology that can be applied to research on language education. The findings provide guidance for optimizing foreign language education in the context of rapidly evolving technology.},
  keywords={Psychology;Employment;Education;Blogs;Dictionaries;Text analysis;Classification algorithms;Chatbots;Virtual assistants;Videos;Natural languages;Linguistics;Non-English;foreign language education;psychological characteristics;topics;linguistic inquiry and word count (LIWC)},
  doi={10.1109/ACCESS.2024.3481049},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10645920,
  author={Dinu, Ion George and Mihăescu, Cristian and Rebedea, Traian},
  booktitle={2024 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Matching Problem Statements to Editorials in Competitive Programming}, 
  year={2024},
  volume={},
  number={},
  pages={171-175},
  abstract={Competitive programming presents challenges for students seeking to enhance programming and algorithmic skills. This research introduces a system that efficiently matches problem statements to editorials that describe the solution, helping students find relevant learning resources. The main component of this system is our learning-to-rank model, which achieves a P@1 score of 0.93, indicating its proficiency in identifying the most relevant editorial for a specific problem statement. While our model is smaller in scale compared to general models like GPT-4, it distinguishes itself with comparable results and notable computational efficiency. Additionally, we have developed a new dataset of 1550 competitive programming problem statements and their editorials. Integrated into a competitive programming platform, it has the potential to evolve into an adaptive learning system, customizing paths based on individual user performance. Our code and data are public at https://github.com/DinuGeorge0019/MatchingProblemStatementsToEditorialsInCP.},
  keywords={Analytical models;Adaptive learning;Adaptation models;Codes;Computational modeling;Source coding;Computational efficiency;learning system;competitive programming;learning-to-rank;text analysis;large language models;natural language processing;neural networks},
  doi={10.1109/ICALT61570.2024.00056},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{10685830,
  author={Lee, Lap-Kei and Chan, Eric Ho and Tong, Kyler Kin-Lik and Wong, Nardo Kwun-Hei and Wu, Ben Shing-Yan and Fung, Yin-Chun and Fong, Edmond King Sing and Leong Hou, U and Wu, Nga-In},
  booktitle={2024 International Symposium on Educational Technology (ISET)}, 
  title={Utilizing Virtual Reality and Generative AI Chatbot for Job Interview Simulations}, 
  year={2024},
  volume={},
  number={},
  pages={209-212},
  abstract={Stress and anxiety experienced by interviewees, particularly fresh graduates, would significantly impact their performance in job interviews. Due to the increased affordability and user-friendliness of virtual reality (VR), VR has seen a surge in its application within the educational sector. This paper presents the design and implementation of a job interview simulation system, leveraging VR and a generative AI chatbot to provide an immersive environment for computer science graduates in Hong Kong. The system aims to help graduates practice and familiarize themselves with various real-world scenarios of a job interview in English, Mandarin, and Cantonese, tailored to the unique language requirements of Hong Kong’s professional environment. The system comprises three core modules: a mock question and answer reading module, an AI speech analysis module, and a virtual interview module facilitated by the generative AI chatbot, ChatGPT. We anticipate that the proposed simulator will provide valuable insights to education practitioners on utilizing VR and generative AI for job interview training, extending beyond computer science graduates.},
  keywords={Computer science;Training;Speech analysis;Generative AI;Anxiety disorders;Virtual reality;Educational technology;job interview simulation;virtual reality;generative AI;chatbot;human computer interaction},
  doi={10.1109/ISET61814.2024.00048},
  ISSN={2766-2144},
  month={July},}@INPROCEEDINGS{10837603,
  author={Ward, Anthony and Manoharan, Sathiamoorthy and Ye, Xinfeng},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Exploring Academic Integrity in the Age of Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Traditionally, statistics suggest that around 30% of students resort to cheating when presented with the opportunity. This alarming trend often goes unnoticed by instructors, as many do not actively monitor for such misconduct. However, the onset of the pandemic saw a surge in cheating incidents, mainly due to the shift to online learning environments where supervision was more challenging. Despite this, instances of cheating remained detectable, albeit with some effort. As we transition out of the pandemic era, a new challenge has emerged in the form of generative AI technology, which has dramatically altered the landscape of academic dishonesty. With the advent of sophisticated generative AI models, it has become virtually impossible to discern between authentic student work and AI-generated content in unsupervised settings. Consequently, there has been a noticeable decline in detected cheating cases compared to pre-pandemic levels, largely attributed to the widespread use of generative AI tools. Traditional plagiarism detection software such as Turnitin and MOSS, once considered reliable safeguards against academic dishonesty, have become obsolete in the face of these advanced AI systems. The unique solutions produced by generative AI render such detection methods ineffective, posing a significant challenge to maintaining academic integrity in the modern educational landscape. This paper explores the nature of academic misconduct incidents in the context of two universities across the globe: one in the United Kingdom and the other in New Zealand.},
  keywords={Training;Generative AI;Pandemics;Plagiarism;Market research;Software;Software reliability;Surges;Information technology;Monitoring;academic integrity;generative AI;cheating incidents;student assessment;plagiarism detection},
  doi={10.1109/ITHET61869.2024.10837603},
  ISSN={2473-2060},
  month={Nov},}@ARTICLE{10530465,
  author={Muniyandi, Amutha Prabakar and Balusamy, Balamurugan and Dhanaraj, Rajesh Kumar and Ellappan, Vijayan and Murali, S. and Sathyamoorthy, Malathy and Nkenyereye, Lewis},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Privacy Preserved Reinforcement Learning Model Using Generative AI for Personalized E-Learning}, 
  year={2024},
  volume={70},
  number={3},
  pages={6157-6165},
  abstract={Artificial intelligence algorithms are taking important roleplays in online recommendation models for achieving a high probability of success and these systems are slowly occupying modern learning systems. Modernized learning environments are designed based on personalized E-Learning system, due to the availability of enriched content and flexibility in the learning system. This paper proposed a personalized enriched course recommendation method for an e-learning environment using reinforcement techniques. The proposed method uses an Improved Artificial Bee Colony Optimisation (IABCO) algorithm-based generative AI model for preparing the course recommendations and this recommendation part will act as an Agent in the proposed personalized learning method. The proposed method uses IABCO algorithm for generating enriched course list based on personalized recommendation gather from customers and reinforcement learning model is used to evaluate the suggested course list. The proposed method is experimented with a dataset of online course offering website, which contains 3523 course details and 200 students are taken from various levels of learning maturity. The performance evaluation for the proposed system is measured based on success and accuracy rate of selection from the recommended course list. The average success rate and accuracy for the proposed method is 86.5% and 95.6% compared to the existing AI-based recommendation methods.},
  keywords={Electronic learning;Education;Artificial intelligence;Reinforcement learning;Recommender systems;Consumer electronics;Generative AI;Reinforcement learning;generative AI;artificial bee colony optimisation;privacy preserved learning system;course enriched learning system},
  doi={10.1109/TCE.2024.3398824},
  ISSN={1558-4127},
  month={Aug},}@ARTICLE{11006373,
  author={Ranjan, Sakshi and Mishra, Dheeraj and Singh, Sanjay Kumar},
  journal={IEEE Transactions on Computational Biology and Bioinformatics}, 
  title={Mitigating Catastrophic Forgetting in Molecular Property Prediction via Refresh Learning and Pareto Optimization}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Continual Learning (CL) enables Large Language Models (LLMs) to adapt to new episodes and data streams without forgetting previously acquired knowledge, a critical requirement for dynamic fields like Molecular property Prediction (MP). LLMs, however, often face Catastrophic Forgetting (CF), where learning new information erodes prior knowledge, particularly when data distributions shift significantly between episodes, as seen in chemical, genomic, and proteomic datasets. To address CF, the existing replay-based techniques use memory buffers to store past episode data but often overlook the relationships between episodes, resulting in sub-optimal performance when revisiting earlier episodes. To this, the paper proposes a Multi-task Learning (MTL) framework that reconciles existing CL techniques into a unified hierarchical gradient aggregation framework. It builds a novel framework using the ChemBERTa model, namely MTL-PORL (Multi-task Learner-Pareto Optimized Refresh Learning), i.e., Refresh Learning (RL), inspired by neuroscience, where the brain discards outdated information to enhance retention and facilitate new learning with Pareto Optimization (PO) for MP. The hyper-gradient approach in the MTL-PORL leverages unlearning current data before relearning it, acting as a flexible plug-in that enhances existing CL methods. The MTL-PORL exhibits Anytime Average Accuracy (91.63%, 94.89%, and 92.67%), Test Accuracy (92.48%, 96.48%, and 96.86%), and Forgetting Measure (-0.0048, -0.0045, and -0.0063) on the BBBP, bitter, and sweet datasets, respectively. The comprehensive empirical analysis highlighted significant improvements in sequential learning compared to existing methods, addressing the stability-plasticity trade-off and effectiveness of RL.},
  keywords={Adaptation models;Drugs;Computational modeling;Data models;Predictive models;Drug discovery;Diffusion tensor imaging;Multitasking;Bioinformatics;Pareto optimization;Drug Discovery;Refresh Learning;Catastrophic Forgetting;Multi-task Learner;Simplified Input Line Entry System (SMILES)},
  doi={10.1109/TCBBIO.2025.3571046},
  ISSN={2998-4165},
  month={},}@INPROCEEDINGS{10975892,
  author={Zhong, Chaocheng and Ye, Feihong and Wang, Zihan and Jigeer, Aerman and Zhan, Zehui},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Interdisciplinary-QG: An LLM-Based Framework for Generating High-Quality Interdisciplinary Test Questions with Knowledge Graphs and Chain-of-Thought Reasoning}, 
  year={2025},
  volume={},
  number={},
  pages={68-78},
  abstract={As interdisciplinary education gains prominence in global educational reforms, the design of high-quality interdisciplinary test items remains a challenge due to the complexity of knowledge integration, question difficulty control, and the inefficiency of manual generation. To address these issues, this study introduces Interdisciplinary-QG, an automated interdisciplinary question generation framework based on GPT-4. The framework integrates knowledge graph-enhanced retrieval-based generation with chain-of-thought reasoning and employs a structured BRTE (Background-Role-Task-Example) prompt template, enhancing both accuracy and interdisciplinary coherence. A case study in chemistry demonstrates that Interdisciplinary-QG effectively constructs interdisciplinary knowledge structures and generates high-quality test items with both depth and breadth. Experimental results show that it outperforms the general-purpose LLM ChatGLM in validity, efficiency, and interdisciplinary integration. This study provides new insights into leveraging AI for interdisciplinary education.},
  keywords={Chemistry;Large language models;Education;Knowledge graphs;Manuals;Coherence;Question generation;Cognition;Complexity theory;Information technology;Interdisciplinary Education;Automated Question Generation;Large Language Models;Knowledge Graphs},
  doi={10.1109/ICEIT64364.2025.10975892},
  ISSN={},
  month={March},}@INPROCEEDINGS{10401848,
  author={Elshiny, Reyam Magdy and Hamdy, Abeer},
  booktitle={2023 International Conference on Computer and Applications (ICCA)}, 
  title={Automatic Question Generation Using Natural Language Processing and Transformers}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Online education’s rapid growth and the rise of E-learning tools have raised the demand for creating assessments and challenging questions for learners which require significant effort to create suitable content for testing. Consequently, automatic question generation aims to automate the creation of different types of questions in the shortest period of time possible by applying minimal human effort all using natural language processing and transformers. This paper proposes different methodologies to generate questions like true or false, fill in the blanks, matching, multiple-choice, and “Wh-” questions specified from a given context. Transformer models including GPT, T5, and BERT are used to achieve the methodologies needed to generate such questions. The system, tested through surveys, generated an 80% satisfaction rate among teacher participants and showed potential to generate questions similar to ChatGPT’s.},
  keywords={Surveys;Electronic learning;Transformers;Libraries;Tuning;Context modeling;Testing;transformers;question generation;natural language processing;GPT;BERT;T5},
  doi={10.1109/ICCA59364.2023.10401848},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10837671,
  author={Nafil, Khalid and Lefdaoui, Youssef},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Innovative Approach to Agile Education: Generative AI-Supported Planning Poker Simulation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study investigates the integration of generative AI into the Scrum planning poker process within an educational environment. Through the Character.ai platform, Students interacted with AI agents, including a Scrum Master and three Developers, using their mobile devices to conduct Planning Poker sessions. Quantitative criteria were developed to assess Agent interactions, Student participation, Collaboration, Communication, and Decision-making Patterns. Initial findings reveal encouraging levels of Student engagement and effective utilization of AI-supported techniques during the sessions. These results highlight the potential of generative AI to enhance educational experiences, particularly within the context of Agile project management methodologies.},
  keywords={Training;Generative AI;Decision making;Collaboration;Agile project management;Mobile handsets;Planning;Information technology;Planning Poker;Scrum;Character.ai;Generative AI;Education},
  doi={10.1109/ITHET61869.2024.10837671},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10892813,
  author={Baradari, Dünya and Han, Harry and Xia, Julia and Strelecki, Carey Ann},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Beyond Imagination: Leveraging Generative AI to Enhance Learning Through Story World Analogies}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This innovative practice full paper describes ConceptualTales, a conversational AI that explains STEM and social science concepts using analogies from popular story worlds and Socratic reasoning. The disconnect between conventional teaching strategies and student engagement is a persistent challenge in educational systems, particularly STEM fields. Traditional methods often fail to resonate with students, rendering the learning process monotonous and detached from their personal interests. Concurrently, students are enthusiastic about and dedicated to fictional worlds such as Marvel, Harry Potter, and Disney. This observation forms the basis for our innovative practice: integrating these beloved narratives into educational content through generative AI. ConceptualTales was tried with middle and high school students in the USA and China and received overwhelmingly positive feedback. Our system combines fiction-inspired learning, analogical reasoning, and Socratic questions, to make educational content personal and interesting to students.},
  keywords={Conversational artificial intelligence;Generative AI;Social sciences;Education;Rendering (computer graphics);Cognition;STEM;analogies;concepts;generative AI;story worlds;narratives;artificial intelligence in education (AIinEd)},
  doi={10.1109/FIE61694.2024.10892813},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10387629,
  author={Vaid, Abhishek and Andreopoulos, William B.},
  booktitle={2023 Fifth International Conference on Transdisciplinary AI (TransAI)}, 
  title={Real-Time Attention-Based Conversational Agent}, 
  year={2023},
  volume={},
  number={},
  pages={114-117},
  abstract={Neural Machine Translation (NMT) is a prominent natural language processing technique that is being used to develop conversational AI technology. Traditional industrial chatbots often rely on scripted responses and lack the ability to provide real-time data-driven interactions. Developing advanced AI chatbots like Google Bard or ChatGPT are out of reach for smaller or medium-sized organizations due to their scale and associated costs. Chatbots are majorly restricted by the data on which they were trained on and have no knowledge of current events. This research project intends to research and develop an approach that enables chatbots to provide live and up-to-date information in their responses and can be developed in minimalistic costs so that even smaller or medium-level organizations can afford to provide interactive AI chatbots. We experiment with various techniques in terms of the type of data being used to harness live capabilities. We focus on optimizing the hyperparameters required for building a conversational AI agent and leverage open-source technologies to minimize costs. To ensure flexibility and affordability, we adopt a microservice architecture that combines Attention based NMT models and Transformer Models with live API services features, leveraging the RASA actions API. This approach allows us to develop a prototype of an advanced chatbot that goes beyond the traditional scripted responses by providing real-time information to users and being affordable to develop.},
  keywords={Costs;Microservice architectures;Prototypes;Organizations;Chatbots;Transformers;Real-time systems;Neural Machine Translation;Conversational AI},
  doi={10.1109/TransAI60598.2023.00028},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11022196,
  author={Du, Haizhou and Li, Wenhao and Ding, Xiaoyu and Huo, Huan},
  booktitle={2024 8th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Can LLMs Understand Parallel and Distributed Machine Learning Algorithms in AIoT?}, 
  year={2024},
  volume={},
  number={},
  pages={501-510},
  abstract={The Internet of Things technology has evolved from standalone tools to open systems supporting parallel and distributed computing. In particular, federated learning (FL) has become a key solution as a distributed team of parallel training methods in the artificial intelligence of things (AIoT). Academia and industry formed a significant consensus on efficient reproducing and rapidly deploying federated learning in the AIoT. The current best practice typically resorts to three approaches: 1) looking for publicly open-source algorithmic prototypes, 2) contacting the authors to get a private prototype, and 3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes, and private prototypes are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor-consuming and error-prone. In this paper, we propose reproducing FL research results using the emerging large language models (LLMs). In particular, we first prove its feasibility with an experiment in which three students with essential parallel and distributed machine learning knowledge reproduce different FL algorithms published in prominent conferences and journals by prompt engineering ChatGPT-4. Finally, our experimental results focus on the efficiency and quality of reproducing code. We report the experiment’s observations and discuss future open research questions of this paper. Additionally, we verify the better robustness of reproduced codes with different data poisoning attacks via extensive experiments. This work also raises no ethical issue.},
  keywords={Training;Machine learning algorithms;Codes;Federated learning;Large language models;Prototypes;Transforms;Robustness;Internet of Things;Artificial intelligence;large language models;federated learning;algorithm reproducibility;distributed machine learning},
  doi={10.1109/ACAIT63902.2024.11022196},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10662985,
  author={Liao, Yiwen and Jiang, Yuchao and Chen, Zhangpeng and Suleiman, Basem},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={FeedbackPulse: GPT-Enabled Feedback Assistant for Software Engineering Educators}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={In response to the growing enrolment in software engineering programs, there is a pressing need for scalable methods to provide effective feedback for students. We designed a GPT-driven interactive assistant, FeedbackPulse, to aid educators in delivering high-quality feedback and alleviating their workload. FeedbackPulse provides real-time, personalised feedback suggestions to educators for improving their feedback to students. Preliminary evaluations of FeedbackPulse in a software engineering course have demonstrated its promising capabilities.},
  keywords={Pressing;Real-time systems;Software engineering},
  doi={10.1109/CSEET62301.2024.10662985},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10963119,
  author={Upeksha, Sanduni and Samarasinghe, Dumindu T. and Sanochana, Mithun and Samarathunga, Sapni S. and Rajamanthri, Lochana and Samarakkody, Takshila and Aluthwala, Chathuni},
  booktitle={2025 5th International Conference on Advanced Research in Computing (ICARC)}, 
  title={The Influence of Generative AI on work-life balance among female software professionals in Sri Lanka}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This study explores the role of generative artificial intelligence on work-life balance among female software professionals in Sri Lanka's software industry. This qualitative study explores the influence of Generative Artificial Intelligence (GenAI) tools on workload, productivity, and overall well-being to show how these technologies uniquely shape professional and personal lives within this demographic group. Data were gathered through semi-structured interviews with 15 female software professionals from various job roles, including software engineers, quality assurance engineers, system engineers, Development and Operations (DevOps) engineers, and project managers. Using thematic analysis, findings disclose that generative AI is mostly utilized for automation, communication and collaboration, creativity and innovation, and decision support, with ChatGPT being the most widely used tool. These tools will enable professionals to streamline the workload, increase efficiency, reduce overtime, and maintain healthy working conditions. The insights of this study yield important implications for employers and government organizations such as the Department of Labor, explicitly pointing out how generative AI can be instrumented to create a favorable work environment. Thus, by applying generative AI solutions, the key stakeholders of the Sri Lankan software industry can create work conditions crucial for the work-life balance of women to enhance organizational performance as well as the work-related well-being of female software professionals.},
  keywords={Industries;Productivity;Employee welfare;Training;Technological innovation;Generative AI;Software;Teamwork;Stakeholders;Creativity;Female Software Professionals;Generative AI;Software Industry;Work-Life Balance},
  doi={10.1109/ICARC64760.2025.10963119},
  ISSN={},
  month={Feb},}@INBOOK{10952278,
  author={Orange, Erica},
  booktitle={AI + The New Human Frontier: Reimagining the Future of Time, Trust + Truth}, 
  title={Shifting from Education to Learning}, 
  year={2024},
  volume={},
  number={},
  pages={170-176},
  abstract={Summary <p>At the older ages, schools and educational institutions in the United States and elsewhere are announcing bans on ChatGPT out of fear that students could use the technology to complete their assignments. Learning for Justice's digital literacy framework sheds light on crucial focus areas that educators and students must address when integrating AI into education. The changing world of work brings the importance of vocational education and training to the forefront. A 2023 Intelligent.com survey finds 1 in 6 Gen Zers may switch from white&#x2010;collar to blue&#x2010;collar jobs due to fears about AI. The way Gen Alphas interact with robots and voice&#x2010;activated devices is beginning to represent a more complex relationship&#x2014;often an emotional one. As more toys teach coding and programming, non&#x2010;digital toys that incorporate kinesthetic learning are a good way to enhance creativity, design thinking, personal expression, and conceptualization.</p>},
  keywords={Artificial intelligence;Education;Chatbots;Engineering profession;Encoding;Brain modeling;Vocational training;Technological innovation;Surveys;Software},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394276998},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10952278},}@INPROCEEDINGS{10882269,
  author={Waikar, Rahul and Tamhane, Shraddhesh and Tale, Tanmai and Talekar, Rujul and Tangde, Ayush and Singla, Tanish and Kalokhe, Tanishka},
  booktitle={2024 International Conference on Artificial Intelligence and Quantum Computation-Based Sensor Application (ICAIQSA)}, 
  title={Student Career Guidance Using Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This conceptualisation involves developing an online application software that incorporates generative AI in providing counselling information on career based on the users' interests, skills and expectations. Face to face counselling on the other hand has its constraints in terms of scale and accessibility but this form of career counseling by use of the present artificial intelligence also aspires to break barriers and provide a leveling ground for all students. This information includes the grade level, expected career, academic interests, skills, and hobbies users offer. The AI provides and explains several occupations, good as well as specific ones, which enables students to consider more jobs. It also provides the best colleges available, required degrees, expected income and future scope. When career awareness has been limited to competitive fields, the application enables students to think pragmatically about the options available to them. The HTML, CSS, and JavaScript-based user interface enables the input of several attributes by students and reception of associated AI career suggestions. The inputs are then passed through a generative AI API running on a Node server to improve the usability of the response. This innovative method teaches students using artificial intelligence and using behavioral counseling principles and provides students with clear, evidence-based information regarding their future occupations.},
  keywords={Employee welfare;Hands;Quantum computing;Engineering profession;Generative AI;User interfaces;Servers;Application software;Usability;Faces;API;Career guidance;Generative AI;Node.js;Web-based application},
  doi={10.1109/ICAIQSA64000.2024.10882269},
  ISSN={},
  month={Dec},}@BOOK{10769388,
  author={Dell, Dr. Scott and Akpan, Dr. Mfon},
  booktitle={ChatGPT and AI for Accountants: A practitioner's guide to harnessing the power of GenAI to revolutionize your accounting practice},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Elevate your accounting skills by applying ChatGPT across audit, tax, consulting, and beyondKey FeaturesLeverage the impact of AI on modern accounting, from audits to corporate governanceUse ChatGPT to streamline your accounting tasks with practical hands-on techniquesUnderstand the impact of AI in accounting through in-depth chapters covering various domains, including ethical considerations and data analyticsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionIn the fast-paced AI world, accounting professionals are increasingly challenged by the complexities of AI. Many struggle to integrate these advanced tools into their workflows, leading to a sense of overwhelm. ChatGPT for Accounting bridges this gap by not only simplifying AI concepts but also offering practical insights for its application in various accounting domains. This book takes you from the foundational principles of Generative Artificial Intelligence (GAI) to its practical applications in audits, tax planning, practice management, fraud examination, financial analysis, and beyond. Each chapter equips you with essential skills, showing you how AI can revolutionize internal control systems, enhance recruitment processes, streamline marketing plans, optimize tax strategies, and boost efficiency in audits. You’ll then advance to exploring the role of AI in forensic accounting, financial analysis, managerial accounting, and corporate governance, while also addressing ethical and security implications. Concluding with a reflective outlook on the promises and challenges of AI, you’ll gain a holistic view of the future of accounting. By the end of this book, you’ll be equipped with the knowledge to harness the power of AI effectively and ethically, transforming your accounting practice and staying ahead in the ever-evolving landscape.What you will learnUnderstand the fundamentals of AI and its impact on the accounting sectorGrasp how AI streamlines and enhances the auditing process for high accuracyUncover the potential of AI in simplifying tax processes and ensuring complianceGet to grips with using AI to identify discrepancies and prevent financial fraudMaster the art of AI-powered data analytics for informed decision-makingGain insights into seamlessly integrating AI tools within existing accounting systemsStay ahead in the evolving landscape of AI-led accounting tools and practicesWho this book is forWhether you're a seasoned accounting professional, a C-suite executive, a business owner, an accounting educator, a student of accounting, or a technology enthusiast, this book provides the knowledge and insights you need to navigate the changing landscape in applying GAI technology to make a difference in all you do. An appreciation and understanding of the accounting process and concepts will be beneficial.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835462256},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10769388},}@INPROCEEDINGS{10172807,
  author={Ronanki, Krishna},
  booktitle={2023 IEEE/ACM 45th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)}, 
  title={Towards an AI-centric Requirements Engineering Framework for Trustworthy AI}, 
  year={2023},
  volume={},
  number={},
  pages={278-280},
  abstract={Ethical guidelines are an asset for artificial intel-ligence(AI) development and conforming to them will soon be a procedural requirement once the EU AI Act gets ratified in the European parliament. However, developers often lack explicit knowledge on how to apply these guidelines during the system development process. A literature review of different ethical guidelines from various countries and organizations has revealed inconsistencies in the principles presented and the terminology used to describe such principles. This research begins by identifying the limitations of existing ethical AI development frameworks in performing requirements engineering(RE) processes during the development of trustworthy AI. Recommendations to address those limitations will be proposed to make the frameworks more applicable in the RE process to foster the development of trustworthy AI. This could lead to wider adoption, greater productivity of the AI systems, and reduced workload on humans for non-cognitive tasks. Considering the impact of some of the newer foundation models like GitHub Copilot and ChatGPT, the vision for this research project is to work towards the development of holistic operationalisable RE guidelines for the development and implementation of trustworthy AI not only on a product level but also on process level.},
  keywords={Productivity;Ethics;Terminology;Organizations;Requirements engineering;Artificial intelligence;Task analysis;Trustworthy AI;EU AI Act;Requirements Engineering;Frameworks;AI co-worker;Ethical AI;Guidelines},
  doi={10.1109/ICSE-Companion58688.2023.00075},
  ISSN={2574-1934},
  month={May},}@INPROCEEDINGS{10773545,
  author={P, Vedanta S and Rao, Madhav},
  booktitle={2024 9th International Conference on Computer Science and Engineering (UBMK)}, 
  title={PsychSynth: Advancing Mental Health AI Through Synthetic Data Generation and Curriculum Training}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The number of Mental-health help seekers are on rise over recent years, but the medical practitioners are limited due to which the healthcare system is heavily loaded and thereby the outcome is not promising. Advanced AI Technology is expected to ease this problem, however completely relying on the tools is reported to not work with the help seekers. Hence technology to assist help seekers and allow the healthcare system to screen the needy ones from the large pool of distress candidates should make the system efficient a nd effective.H owever for establishing the AI supportive system, two challenges exists: one is the large pool of dataset with diversity, and other is the AI model to respond to a context-aware situations. Expecting large dataset for training model from medical community needs further infrastructure support to make it digitally available with embedded annotations. Relying patiently for the dataset will miss the opportunity to serve the distress patients. Hence synthetic dataset generation and its validation from medical experts is an alternative for training robust and reliable model. Besides, context-aware curriculum inspired AI based summarizer model is found appropriate to adopt for this use-case where relevant features meant for diagnosing the problem is extracted from the improvised input text. The proposed curriculum trained AI model helps in transforming the improvised text inputs fed from the distress individuals to a summarized version representing domain expert form, embedded with symptoms related features for further classification. The synthetic data-set g eneration through OpenAI's GPT-40 models and Nemotron models are further evaluated with BERT based classifier m odels a nd curriculum based AI model. The training of the classifier m odels are also evaluated for synthetic and real-world dataset, which was scrapped from Reddit forum. Around 800 stream of real-world posts were evaluated from the medical experts and their findings related to sympotoms and annotations were employed to fine-tune the classifier and summarizer m odel. It was found t hat the fine-tuned models and training of BERT models from the merged dataset composed of synthetic ones with the medical practitioners annotated dataset were found to perform better than others. The summarizer model fetching shorter version of domain expert output enhanced the classification accuracy by 5 % for the real-world data. The effort is a step towards developing AI assistant to screen large posts of submissions from distress individuals and arrange for the necessary connects for the needy ones with the medical experts. The models and pruned datasets are made freely available for further usage to the researchers community.},
  keywords={Training;Adaptation models;Accuracy;Social networking (online);Computational modeling;Feature extraction;Data models;Artificial intelligence;Medical diagnostic imaging;Synthetic data;Generative AI;GPT;Synthetic Data;Domain Expert;Curriculum based;Summarizer model;BERT;Context-A ware;Mental Health;Distress},
  doi={10.1109/UBMK63289.2024.10773545},
  ISSN={2521-1641},
  month={Oct},}
@INPROCEEDINGS{10578921,
  author={},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={CodeWizardry}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={Gamification stands as a promising remedy to the challenges posed by traditional e-learning systems, as it advocates for the infusion of game elements and mechanisms to elevate motivation, engagement, and the overall learning experience for students. The concept of gamification in e-learning represents a paradigm shift, proposing a transition from traditional methods towards to more interactive approach. By seamlessly integrating game elements, educators aim to not only enhance motivation but also foster a deeper understanding of the subject matter by making the learning process more playful. Meanwhile, the introduction of ChatGPT into academic environments has sparked intense discussions on its transformative potential. Its versatile capabilities across various writing styles raise questions about the implications for creativity, originality, and the role of human intellect in the face of advancing AI technologies. The rapid ascent of ChatGPT, marked by its overwhelming success within a short span, underscores the urgent need for a comprehensive examination of the impact and ethical considerations associated with. For all the above, we propose “CodeWizardy” as an innovative platform for learning programming by mixing in games and AI.},
  keywords={Chatbots;Education;Codes;Games;Artificial intelligence;Problem-solving;Encoding;Gamification;Artificial Intelligence;ChatGPT;E-learning;Gamified Teaching Method},
  doi={10.1109/EDUCON60312.2024.10578921},
  ISSN={2165-9567},
  month={May},}@BOOK{10695822,
  author={Sidahmed, Elandaloussi and Pascale, Zaraté},
  booktitle={Strategic Support Systems for Crisis Management: A Literature Review},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Strategic Support Systems for Crisis Management presents a literature review of Strategic Decision Support Systems (SDSS). The chosen SDSS case study is COVID-19 crisis management and its impact on sectors such as health, education, and the economy. This monograph addresses the following questions: What are the different architectures of defined Strategic DSS and which SDSS is better to deal with each crisis? The monograph begins by discussing a comprehensive methodology for the literature review and providing an overview of the study background. Section 4 is devoted to discussing the most important studies in SDSS technologies. SDSS models are presented in Section 5. Section 6 explores the application of generative AI, and specifically ChatGPT, in the context of COVID-19 pandemic decision support systems. Section 7 provides a brief discussion of the conducted surveys. Finally, Section 8 summarizes the monograph and provides some concluding remarks.},
  keywords={},
  doi={},
  ISSN={},
  publisher={now},
  isbn={9781638283935},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10695822},}@ARTICLE{10985773,
  author={Adornetto, Carlo and Mora, Adrian and Hu, Kai and Garcia, Leticia Izquierdo and Atchade-Adelomou, Parfait and Greco, Gianluigi and Pastor, Luis Alberto Alonso and Larson, Kent},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Generative Agents in Agent-Based Modeling: Overview, Validation, and Emerging Challenges}, 
  year={2025},
  volume={},
  number={},
  pages={1-20},
  abstract={The advent of Generative Agents (GAs) based on Large Language Models (LLMs) has significantly influenced the evolution of Agent-Based Modeling (ABM), offering new perspectives across various domains, including engineering and social sciences. This paper provides an extensive overview of the integration of GAs into ABMs, emphasizing the advancements and emerging challenges in their validation. Traditional ABMs, characterized by their simplistic yet powerful approach to modeling complex systems, have been redefined with the introduction of GAs. This new generation of agents is often equipped with conversational capabilities. These agents, capable of simulating believable human behaviors and interactions, present unique opportunities and hurdles, especially in urban simulations and social dynamics. We explore the nuanced differences between traditional ABMs and ABMs populated by GAs—called GABMs. We delve into the state-of-the-art implementations of GAs, and review various validation methods. Through this comprehensive examination, we aim to shed light on the potential and limitations of GAs, advocating for the design of hybrid ABM-GABM approaches and systematic validation.},
  keywords={Biological system modeling;Behavioral sciences;Reviews;Urban areas;Large language models;Terminology;Predictive models;Media;Mathematical models;Decision making;Agent-Based Models;Generative Agents;Generative AI;Large Language Models},
  doi={10.1109/TAI.2025.3566362},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{10386894,
  author={Kumar, Akit and Lakshmi Devi, M.S. and Saltz, Jeffrey S.},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Bridging the Gap in AI-Driven Workflows: The Case for Domain-Specific Generative Bots}, 
  year={2023},
  volume={},
  number={},
  pages={2421-2430},
  abstract={The widespread adoption of generative AI tools, such as ChatGPT, has resulted in its extensive use in a broad range of situations. However, language models often generate inaccurate or misleading responses, negatively impacting its use. Developing domain-specific bots for specific work situations could enhance accuracy and robustness, enabling more effective use of Generative AI in a work context. To help explore this possibility, we developed a data science process-expert generative AI assistant (bot) and evaluated its efficacy. We observed that the bot significantly improved efficiency, guided the exploration of new concepts within data science project management, and fostered creativity. Moreover, the constant availability of the bot allowed access to expertise whenever needed. Furthermore, responses indicated people viewed the bot as a collaborative tool that enabled communication and comprehension of complex questions. In addition, a Likert-scale analysis showed that the bot has the potential to impact the data science field positively. In summary, this research underscores the value of domain-specific bots and the potential impact on data science project management, as well as in other domains.},
  keywords={Generative AI;Collaborative tools;Project management;Data science;Big Data;Chatbots;Robustness;Data Science;Generative AI;CRISP-DM;Chat Bots},
  doi={10.1109/BigData59044.2023.10386894},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10292037,
  author={Rukmono, Satrio Adi and Ochoa, Lina and Chaudron, Michel R.V.},
  booktitle={2023 IEEE International Conference on Data and Software Engineering (ICoDSE)}, 
  title={Achieving High-Level Software Component Summarization via Hierarchical Chain-of-Thought Prompting and Static Code Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={7-12},
  abstract={Comprehension of software systems is key to their successful maintenance and evolution. This comprehension comes at different levels of abstraction: At the low level, one must focus on comprehending functions; while at the high level, one must abstract and comprehend the system's requirements. Diverse Automated Source Code Summarization (ASCS) techniques have been proposed to comprehend systems at the lower level. However, techniques for abstracting higher-level explanations fall short. Research on related fields, such as software architecture recovery, has tried to address system comprehension at the higher level by attempting to detect abstractions of design decisions from source code. Nevertheless, this is an on-going effort and many steps in the process are still unsolved. In this paper, we lever-age the emergent abilities of Large Language Models (LLMs) together with the achievements in the ASCS and static code analysis fields to design an approach that produces component-level summaries of software systems. Particularly, we address the unreliability of LLMs in performing reasoning by applying a chain-of-thought prompting strategy, which allows us to emulate inductive reasoning. We follow a bottom-up approach, where we start by comprehending lower-level software abstractions (e.g., functions), and then we compose these findings-in a cascading style-to comprehend higher-level ones (e.g., classes, components). We demonstrate the feasibility of our approach by applying it to the open-source Java project JHotDraw version 5.1. We believe our approach offers a stepping stone in developing robust automated software summarization approaches that can be applied generally across domains and types of software system.},
  keywords={Analytical models;Java;Codes;Software architecture;Source coding;Maintenance engineering;Software systems;comprehension of software systems;automated source code summarization;static analysis;large language models;chain-of-thought prompting},
  doi={10.1109/ICoDSE59534.2023.10292037},
  ISSN={2640-0227},
  month={Sep.},}@INPROCEEDINGS{10430054,
  author={Liu, Jinrun and Tang, Xinyu and Li, Linlin and Chen, Panpan and Liu, Yepang},
  booktitle={2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security Companion (QRS-C)}, 
  title={ChatGPT vs. Stack Overflow: An Exploratory Comparison of Programming Assistance Tools}, 
  year={2023},
  volume={},
  number={},
  pages={364-373},
  abstract={Programmers often seek help from Q&A websites to resolve issues they encounter during programming. Stack Overflow has been a widely used platform for this purpose for over a decade. Recently, revolutionary AI-powered platforms like ChatGPT have quickly gained popularity among programmers for their efficient and personalized programming assistance via natural language interactions. Both platforms can offer valuable assistance to programmers, but it's unclear which is more effective at enhancing programmer productivity. In our paper, we conducted an exploratory user study to compare the performance of Stack Overflow and ChatGPT in enhancing programmer productivity. Two groups of students with similar programming abilities were instructed to use the two platforms to solve three different types of programming tasks: algorithmic challenges, library usage, and debugging. During the experiments, we measured and compared the quality of code produced and the time taken to complete tasks for the two groups. The results show that, concerning code quality, ChatGPT outperforms Stack Overflow significantly in helping complete algorithmic and library-related tasks, while Stack Overflow is better for debugging tasks. Regarding task completion speed, the ChatGPT group is obviously faster than the Stack Overflow group in the algorithmic challenge, but the two groups have a similar performance in the other two tasks. Additionally, we conducted a post-experiment survey with the participants to understand how the platforms have helped them complete the programming tasks. We analyzed the questionnaires to summarize ChatGPT and Stack Overflow's strengths and weaknesses pointed out by the participants. By comparing these, we identified the reasons behind the two platforms' divergent performances in programming assistance.},
  keywords={Productivity;Codes;Debugging;Programming;Chatbots;Libraries;Task analysis;ChatGPT;Stack Overflow;programming;user study},
  doi={10.1109/QRS-C60940.2023.00105},
  ISSN={2693-9371},
  month={Oct},}@ARTICLE{10945362,
  author={Aloudat, Mohammad Z. and Aboumadi, Abdulla and Soliman, Abdelrahman and Al-Mohammed, Hasan Abbas and Al-Ali, Muhammed and Mahgoub, Asma and Barhamgi, Mahmoud and Yaacoub, Elias},
  journal={IEEE Access}, 
  title={Metaverse Unbound: A Survey on Synergistic Integration Between Semantic Communication, 6G, and Edge Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={58302-58350},
  abstract={With a focus on edge learning, blockchain, sixth generation (6G) wireless systems, semantic communication, and large language models (LLMs), this survey paper examines the revolutionary integration of cutting-edge technologies within the metaverse. This thorough examination highlights the critical role these technologies play in improving realism and user engagement on three main levels: technical, virtual, and physical. While the virtual layer focuses on building immersive experiences, the physical layer highlights improvements to the user interface through augmented reality (AR) goggles and virtual reality (VR) headsets. Blockchain-powered technical layer enables safe, decentralized communication. The survey highlights how the metaverse has the potential to drastically change how people interact in society by exploring applications in a variety of fields, such as immersive education, remote work, and entertainment. Concerns about privacy, scalability, and interoperability are raised, highlighting the necessity of continued study to realize the full potential of the metaverse. For scholars looking to broaden the reach and significance of the metaverse in the digital age, this paper is a useful tool.},
  keywords={Metaverse;Surveys;Semantic communication;6G mobile communication;Blockchains;Digital twins;Large language models;Wireless communication;Systematic literature review;Internet;Metaverse;semantic communication;6G wireless systems;edge learning;blockchain technology;large language models (LLMs);extended reality (XR);digital twin technology},
  doi={10.1109/ACCESS.2025.3555753},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10892994,
  author={Neupane, Subash and Hossain, Elias and Keith, Jason and Tripathi, Himanshu and Ghiasi, Farbod and Golilarz, Noorbakhsh Amiri and Amirlatifi, Amin and Mittal, Sudip and Rahimi, Shahram},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={From Questions to Insightful Answers: Building an Informed Chatbot for University Resources}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research-to-practice full paper presents Bark-plug v.2, a Large Language Model (LLM)-based chatbot system built using Retrieval Augmented Generation (RAG) pipelines to enhance the user experience and access to information within academic settings. The objective of Barkplug v.2 is to provide information to users about various campus resources, including academic departments, programs, campus facilities, and student resources at a university setting in an interactive fashion. Our system leverages university data as an external data corpus and ingests it into our RAG pipelines for domain-specific question-answering tasks. We evaluate the effectiveness of our system in generating accurate and pertinent responses for Mississippi State University, as a case study, using quantitative measures, employing frameworks such as Retrieval Augmented Generation Assessment (RAGAS). Furthermore, we evaluate the usability of this system via subjective satisfaction surveys using the System Usability Scale (SUS). Our system demonstrates impressive quantitative performance, with a mean RAGAS score of 0.96, and satisfactory user experience, as validated by usability assessments.},
  keywords={Surveys;Measurement;Accuracy;Large language models;Retrieval augmented generation;Pipelines;Chatbots;User experience;Reliability;Usability;Chatbot;LLM;RAG;University resources;information access},
  doi={10.1109/FIE61694.2024.10892994},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10549015,
  author={Choudhuri, Rudrajit and Liu, Dylan and Steinmacher, Igor and Gerosa, Marco and Sarma, Anita},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE)}, 
  title={How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={2270-2282},
  abstract={Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.},
  keywords={Productivity;Uncertainty;Generative AI;Navigation;Chatbots;Task analysis;Standards;Empirical Study;Software Engineering;Generative AI;ChatGPT},
  doi={10.1145/3597503.3639201},
  ISSN={1558-1225},
  month={April},}@INPROCEEDINGS{10115963,
  author={Oh, Jane M. C. and Trettel, Ian A. and Fifield, Michael G. and Scandore, Steve F.},
  booktitle={2023 IEEE Aerospace Conference}, 
  title={Mars Project Software Systems Engineering Improvements}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={Increasingly challenging missions are characterized by an expansion of the mission-critical role of software. In the Mars projects, Entry, Descent, and Landing (EDL) are software controlled. EDL relies on software timing and functionality, leading to such things as second chance flight software operating as a copilot on the backup flight computer. Therefore, much of the project risk lies in robustness of software. Within the laboratory, the Project Software Systems Engineering (PSSE) has the responsibility of planning, systems engineering, and overseeing all project software while development organizations deliver domain specific software, such as Command & Data Handling (C&DH) software, Sample Recovery Helicopter (SRH), Guidance, Navigation, & Control (GN&C) software, Vision Compute Element (VCE) software, Ground Data System (GDS) software, Simulation Support Equipment (SSE) software, etc. The software lifecycle chosen for Mars project software development is the incremental lifecycle, wherein the content and scope of each software release will be built upon the delivered capabilities of previous releases to achieve incremental functionality. In this context, the challenge stems from the surge in detail and complexity where current software systems engineering practices will be hard-pressed to keep up. This paper describes an assessment of software systems engineering processes, specifically in the NASA Mars Science Laboratory Curiosity Rover, Mars 2020 Perseverance Rover, and the planned Mars Sample Retrieval Lander, and identifies potential efficiencies and improvements. It also describes the innovations in Mars project software systems engineering and makes recommendations as to how these evolved and what new methods and techniques should be infused into flight projects at the laboratory.},
  keywords={Space vehicles;Mars;Technological innovation;Organizations;Software systems;Aircraft navigation;Robustness},
  doi={10.1109/AERO55745.2023.10115963},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{10621527,
  author={Eberhardt, Gergely and Milánkovich, Ákos},
  booktitle={2024 20th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)}, 
  title={VulnGPT: Enhancing Source Code Vulnerability Detection Using AutoGPT and Adaptive Supervision Strategies}, 
  year={2024},
  volume={},
  number={},
  pages={450-454},
  abstract={In this paper, we present a novel approach to vulnerability detection in source code using a collaborative setup built on top of AutoGPT, with a controller and an evaluator AI working together. The controller oversees the evaluation process and adds a layer of self-critique to the GPT- 4 model, while the evaluator AI conducts the security assessment. By following a step-by-step interaction process, the controller prompts the evaluator AI to verify identified vulnerabilities, enabling the AI to self-correct and improve its accuracy. We discuss the results of our approach, which demonstrates the potential for effective vulnerability detection and highlights areas for improvement. Our research aims to advance the development of AI-driven security evaluation techniques to enhance the overall quality of vulnerability detection, which can be used in various areas such as IoT.},
  keywords={Adaptive systems;Accuracy;Source coding;Process control;Collaboration;Security;Internet of Things;vulnerability detection;source code;automation;GPT},
  doi={10.1109/DCOSS-IoT61029.2024.00072},
  ISSN={2325-2944},
  month={April},}@INPROCEEDINGS{10933434,
  author={Turan, Ahmet Serdar and Köksoy, Bedirhan and Paşaoğlu, Ali},
  booktitle={2025 4th International Conference on Sentiment Analysis and Deep Learning (ICSADL)}, 
  title={An Artificial Intelligence Approach for Analyzing Students' Academic Performance Using Machine Learning Algorithms}, 
  year={2025},
  volume={},
  number={},
  pages={927-932},
  abstract={This paper investigates the effect of midterm and short quizzes on the success scores at the end of the course through machine learning methods. Data from 3,427 students in the Faculty of Engineering and Natural Sciences of Istanbul Rumeli University, recorded from the year 2019 to 2024, were analyzed, and of that, 1,547 records were qualified for machine learning after applying specific filtering criteria. Due to insufficient data, 6,300 synthetic records were generated using the Generative Adversarial Networks (GAN) method. To ensure high-quality data generation and stable training, a Wasserstein GAN with Gradient Penalty (WGAN-GP) was implemented, enhancing the synthetic dataset's diversity and reliability. In this paper, the algorithms of Random Forest (RF), AdaBoost, Linear Regression (LR), K-Nearest Neighbors (KNN), and Support Vector Machines (SVM) were used for the classification and prediction of course success. Among these, the most accurate performance, quantified for example by R2 score, Mean Absolute Error and Mean Squared Error, was given by RF, with a probability of being correct at 83.81%. The results indicate that midterm exams have a significantly stronger influence on predicting course success, while short quizzes play an important role in maintaining consistent student engagement and reinforcing foundational concepts. Future studies will aim for data diverseness by adding more features and comparing new methods, such as Artificial Neural Networks with hyperparameter optimization.},
  keywords={Support vector machines;Radio frequency;Machine learning;Artificial neural networks;Nearest neighbor methods;Generative adversarial networks;Prediction algorithms;Classification algorithms;Random forests;Synthetic data;Random Forest;Machine Learning;Generative Adversarial Networks;Artificial Neural Networks},
  doi={10.1109/ICSADL65848.2025.10933434},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10727139,
  author={Mishra, Shyamal and Chatterjee, Preetha},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)}, 
  title={Exploring ChatGPT for Toxicity Detection in GitHub}, 
  year={2024},
  volume={},
  number={},
  pages={6-10},
  abstract={Fostering a collaborative and inclusive environment is crucial for the sustained progress of open source development. However, the prevalence of negative discourse, often manifested as toxic comments, poses significant challenges to developer well-being and productivity. To identify such negativity in project communications, especially within large projects, automated toxicity detection models are necessary. To train these models effectively, we need large software engineering-specific toxicity datasets. However, such datasets are limited in availability and often exhibit imbalance (e.g., only 6 in 1000 GitHub issues are toxic) [1], posing challenges for training effective toxicity detection models. To address this problem, we explore a zero-shot LLM (ChatGPT) that is pretrained on massive datasets but without being fine-tuned specifically for the task of detecting toxicity in software-related text. Our preliminary evaluation indicates that ChatGPT shows promise in detecting toxicity in GitHub, and warrants further investigation. We experimented with various prompts, including those designed for justifying model outputs, thereby enhancing model interpretability and paving the way for potential integration of ChatGPT-enabled toxicity detection into developer communication channels.},
  keywords={Training;Productivity;Toxicology;Collaboration;Communication channels;Chatbots;Software;Software development management;Software engineering;LLM;software engineering;chatgpt;incivility},
  doi={10.1145/3639476.3639777},
  ISSN={2832-7632},
  month={April},}@ARTICLE{9732669,
  author={Fu, Michael and Tantithamthavorn, Chakkrit},
  journal={IEEE Transactions on Software Engineering}, 
  title={GPT2SP: A Transformer-Based Agile Story Point Estimation Approach}, 
  year={2023},
  volume={49},
  number={2},
  pages={611-625},
  abstract={Story point estimation is a task to estimate the overall effort required to fully implement a product backlog item. Various estimation approaches (e.g., Planning Poker, Analogy, and expert judgment) are widely-used, yet they are still inaccurate and may be subjective, leading to ineffective sprint planning. Recent work proposed Deep-SE, a deep learning-based Agile story point estimation approach, yet it is still inaccurate, not transferable to other projects, and not interpretable. In this paper, we propose GPT2SP, a Transformer-based Agile Story Point Estimation approach. Our GPT2SP employs a GPT-2 pre-trained language model with a GPT-2 Transformer-based architecture, allowing our GPT2SP models to better capture the relationship among words while considering the context surrounding a given word and its position in the sequence and be transferable to other projects, while being interpretable. Through an extensive evaluation on 23,313 issues that span across 16 open-source software projects with 10 existing baseline approaches for within- and cross-project scenarios, our results show that our GPT2SP approach achieves a median MAE of 1.16, which is (1) 34%-57% more accurate than existing baseline approaches for within-project estimations; (2) 39%-49% more accurate than existing baseline approaches for cross-project estimations. The ablation study also shows that the GPT-2 architecture used in our approach substantially improves Deep-SE by 6%-47%, highlighting the significant advancement of the AI for Agile story point estimation. Finally, we develop a proof-of-concept tool to help practitioners better understand the most important words that contributed to the story point estimation of the given issue with the best supporting examples from past estimates. Our survey study with 16 Agile practitioners shows that the story point estimation task is perceived as an extremely challenging task. In addition, our AI-based story point estimation with explanations is perceived as more useful and trustworthy than without explanations, highlighting the practical need of our Explainable AI-based story point estimation approach.},
  keywords={Estimation;Transformers;Computer architecture;Planning;Task analysis;Training;Artificial intelligence;Agile story point estimation;AI for SE;explainable AI},
  doi={10.1109/TSE.2022.3158252},
  ISSN={1939-3520},
  month={Feb},}@INPROCEEDINGS{10316094,
  author={Jankovic, Antonio and Mincic, Dunja and Petrovic, Nenad and Tosic, Milorad},
  booktitle={2023 16th International Conference on Advanced Technologies, Systems and Services in Telecommunications (TELSIKS)}, 
  title={ChatGPT Assisted Development of Laravel Applications}, 
  year={2023},
  volume={},
  number={},
  pages={340-343},
  abstract={Rapid progress in machine learning has given rise to a multitude of approaches for various application domains. However, comparing the functionality and effectiveness of these approaches is crucial to obtain accurate and reliable results. In this study, we aim to explore the potential of ChatGPT, a cutting-edge conversational AI model, for coding applications. Our primary goal is to evaluate the effectiveness of ChatGPT in handling coding-related tasks. By conducting a systematic evaluation of the ten functions encompassed in our original dataset, we aim to gauge the effectiveness of ChatGPT in handling various coding tasks in case of Laravel Controller functions. This will enable us to critically examine the capabilities of ChatGPT in the context of our specific coding applications. Additionally, we conduct a survey among university students with a goal to assess adoption level of AI-based code assistance tools.},
  keywords={Surveys;Codes;Systematics;Debugging;Writing;Chatbots;Encoding;ChatGPT;code completion;Large Language Model (LLM);Laravel},
  doi={10.1109/TELSIKS57806.2023.10316094},
  ISSN={},
  month={Oct},}@BOOK{10251209,
  author={Webber, Emily and Olgiati, Andrea},
  booktitle={Pretrain Vision and Large Language Models in Python: End-to-end techniques for building and deploying foundation models on AWS},
  year={2023},
  volume={},
  number={},
  pages={},
  abstract={Master the art of training vision and large language models with conceptual fundaments and industry-expert guidance. Learn about AWS services and design patterns, with relevant coding examplesKey FeaturesLearn to develop, train, tune, and apply foundation models with optimized end-to-end pipelinesExplore large-scale distributed training for models and datasets with AWS and SageMaker examplesEvaluate, deploy, and operationalize your custom models with bias detection and pipeline monitoringBook DescriptionFoundation models have forever changed machine learning. From BERT to ChatGPT, CLIP to Stable Diffusion, when billions of parameters are combined with large datasets and hundreds to thousands of GPUs, the result is nothing short of record-breaking. The recommendations, advice, and code samples in this book will help you pretrain and fine-tune your own foundation models from scratch on AWS and Amazon SageMaker, while applying them to hundreds of use cases across your organization. With advice from seasoned AWS and machine learning expert Emily Webber, this book helps you learn everything you need to go from project ideation to dataset preparation, training, evaluation, and deployment for large language, vision, and multimodal models. With step-by-step explanations of essential concepts and practical examples, you’ll go from mastering the concept of pretraining to preparing your dataset and model, configuring your environment, training, fine-tuning, evaluating, deploying, and optimizing your foundation models. You will learn how to apply the scaling laws to distributing your model and dataset over multiple GPUs, remove bias, achieve high throughput, and build deployment pipelines. By the end of this book, you’ll be well equipped to embark on your own project to pretrain and fine-tune the foundation models of the future.What you will learnFind the right use cases and datasets for pretraining and fine-tuningPrepare for large-scale training with custom accelerators and GPUsConfigure environments on AWS and SageMaker to maximize performanceSelect hyperparameters based on your model and constraintsDistribute your model and dataset using many types of parallelismAvoid pitfalls with job restarts, intermittent health checks, and moreEvaluate your model with quantitative and qualitative insightsDeploy your models with runtime improvements and monitoring pipelinesWho this book is forIf you’re a machine learning researcher or enthusiast who wants to start a foundation modelling project, this book is for you. Applied scientists, data scientists, machine learning engineers, solution architects, product managers, and students will all benefit from this book. Intermediate Python is a must, along with introductory concepts of cloud computing. A strong understanding of deep learning fundamentals is needed, while advanced topics will be explained. The content covers advanced machine learning and cloud techniques, explaining them in an actionable, easy-to-understand way.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781804612545},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10251209},}@BOOK{10824697,
  author={Chan, Stanley H.},
  booktitle={Tutorial on Diffusion Models for Imaging and Vision},
  year={2025},
  volume={},
  number={},
  pages={},
  abstract={The astonishing growth of generative tools in recent years has empowered many exciting applications in text-to-image generation and text-to-video generation. The underlying principle behind these generative tools is the concept of diffusion, a particular sampling mechanism that has overcome some shortcomings that were deemed difficult in the previous approaches. The goal of this monograph is to discuss the essential ideas underlying the diffusion models. The target audience includes undergraduate and graduate students who are interested in doing research on diffusion models or applying these models to solve other problems.},
  keywords={},
  doi={},
  ISSN={},
  publisher={now},
  isbn={9781638284338},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10824697},}@INPROCEEDINGS{10823414,
  author={De Silva, D. I. and Athukorala, K. S. N.},
  booktitle={2024 8th International Conference on Business and Information Management (ICBIM)}, 
  title={Transformer-Based Sinhala Java Programming Learning Tool}, 
  year={2024},
  volume={},
  number={},
  pages={105-110},
  abstract={Programming is a fundamental aspect of computer science, yet it presents significant language challenges for non-native English-speaking students. This study focuses on developing a Java programming assistance tool tailored for Sri Lankan novice programmers who are native Sinhala speakers. The primary challenge addressed is the difficulty these students face when using English-based programming resources. To overcome this, the study introduces an innovative assistance tool that integrates a custom transformer-based Sinhala- English translation model with advanced AI technology, specifically ChatGPT, for real-time code generation and explanations in Sinhala. The tool is designed to accept queries in Sinhala and provide relevant Java snippets or explanations of Java code in Sinhala. The system architecture includes a user-friendly front-end built on Flask, a robust back-end API, and an accurate translation model with an 83 % accuracy rate. Usability tests with ten beginner Sinhala-speaking programmers demonstrated significant improvements in their understanding and retention of programming concepts, with an average increase in test scores by 25%. This tool enhances programming education accessibility for Sinhala speakers, promoting a more inclusive global coding community.},
  keywords={Java;Translation;Codes;Accuracy;Education;Chatbots;Transformers;Real-time systems;Artificial intelligence;Programming profession;Programming;Java Code;Sinhala-English translator;language barrier;APIs;Transformers;ChatGPT},
  doi={10.1109/ICBIM63313.2024.10823414},
  ISSN={},
  month={Aug},}@ARTICLE{10050506,
  author={Lijo, Ruben and Quevedo, Eduardo and Castro, Jose Juan and Horta, Ricard},
  journal={IEEE Access}, 
  title={Impact of Electrical Engineering Didactic Videos During Emergency Remote Learning}, 
  year={2023},
  volume={11},
  number={},
  pages={19622-19634},
  abstract={This article demonstrates that didactic videos have the potential to enhance quality perception, performance and interest in engineering education. Emergency Remote Learning (ERL) imposed challenging conditions on education, and its impact was especially noticeable in the Science, Technology, Engineering and Mathematics (STEM) disciplines. This is mainly due to intrinsic cognitive load associated with the high presence of abstract concepts and to difficulties to establish connections among subjects to foster generative processing. Suitable integration of multimedia resources might be beneficial in both regards. The use of didactic videos as pedagogical aid is expected to yield positive results in electrical engineering education, mitigating the impact caused by ERL situations. Using concept maps to identify key concepts in the Electrical Engineering BSc, this article proposes the creation and integration of nine videos to enhance conceptual learning and the creation of links among subjects. This study encompassed three academic years (from 2019 to 2022), covering pre-ERL, ERL and post-ERL scenarios, and considering a total sample of 157 students. By using a Mixed Methods research design, this study has demonstrated how the integration of didactic videos mitigated the negative effects of the unprecedented ERL conditions, with positive impact on students’ perception on videos’ implications in enhancing their interest and understanding of the subject’s concepts.},
  keywords={Videos;STEM;Deep learning;Streaming media;Electrical engineering education;Electric potential;Design methodology;Cognitive load;Distance learning;Electronic learning;Conceptual learning;distance learning;educational technology;electrical engineering education;emergency remote learning;STEM;videos;YouTube},
  doi={10.1109/ACCESS.2023.3248299},
  ISSN={2169-3536},
  month={},}@ARTICLE{10804767,
  author={Faruqui, Nuruzzaman and Thatoi, Priyabrata and Choudhary, Rohit and Roncevic, Ivana and Alqahtani, Hamed and Sarker, Iqbal H. and Khanam, Shapla},
  journal={IEEE Access}, 
  title={AI-Analyst: An AI-Assisted SDLC Analysis Framework for Business Cost Optimization}, 
  year={2024},
  volume={12},
  number={},
  pages={195188-195203},
  abstract={Managing the System Development Lifecycle (SDLC) is a complex task because of its involvement in coordinating diverse activities, stakeholders, and resources while ensuring project goals are met efficiently. The complex nature of the SDLC process leaves plenty of scope for human error, which impacts the overall business cost. This paper introduces AI-Analyst, an AI-assisted framework developed using the transformer-based model with more than 150 million parameters to assist with SDLC management. It minimizes manual effort errors, optimizes resource allocation, and improves decision-making processes, resulting in substantial cost savings. The statistical analysis shows that it saves around 53.33% of costs in an experimental project. The transformer model has been trained with a uniquely prepared dataset tailored for SDLC through transfer learning. It achieved impressive results, with an accuracy of 91.5%, precision of 91.9%, recall of 91.3%, and an F1-score of 91.5%, demonstrating its high reliability and performance. The perplexity score of 15 further indicates the model’s strong language understanding capabilities to retrieve relations from complex characteristics of Natural Language Processing (NLP). The AI-Analyst framework represents a significant advancement in integrating Large Language Models (LLMs) into SDLC, offering a scalable and cost-effective solution for optimizing business processes.},
  keywords={Mathematical models;Transformers;Costs;Vectors;Business;Unified modeling language;Training;Optimization;Testing;Systematic literature review;Transformer model;large language model;system development lifecycle;transfer learning;artificial intelligence;business cost optimization;project management automation;system analyst;LLM;SDLC;AI;PMP},
  doi={10.1109/ACCESS.2024.3519423},
  ISSN={2169-3536},
  month={},}@INBOOK{10744999,
  author={Arellano, Karen Chappell},
  booktitle={Collaborative Intelligence: How Humans and AI Are Transforming Our World}, 
  title={12 AI in Warfighting}, 
  year={2024},
  volume={},
  number={},
  pages={287-314},
  abstract={Increasing numbers of artificial intelligence-related academic articles<superscript>1</superscript> and the recent news covering AI developments, including OpenAI&#x0027;s GPT-3, DALLE 2, and DARPA&#x0027;s AI dogfight (Heaven 2020; Knight 2020; Marcus, Davis, and Aaronson 2022) might give one a growing sense of an AI race or even an AI revolution (Makridakis 2017). Both private and public sectors accelerate development of AI, where the promise of AI grows in fields as diverse as health care, education, transportation, human resources, or even the battlefield, raising questions over widespread acceptance of and partnering for this emerging technology. From concerns over machine learning (ML) bias, to fears over loss of privacy or increased security threats, to the anxiety that human decision making and jobs will be replaced by AI, worry persists that development and deployment of AI systems are speeding ahead, sparking a new technological revolution without serious ethical consideration.},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262381178},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10744999},}@INPROCEEDINGS{10882426,
  author={Gupta, Abha and Bhardwaj, Ekta and Sirawag, Neeraj and Pandey, Suvrat and Mehta, Riya},
  booktitle={2024 International Conference on Artificial Intelligence and Quantum Computation-Based Sensor Application (ICAIQSA)}, 
  title={Jarvis: AI-Enhanced Desktop Virtual Assistant}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents the development and evaluation of “Jarvis: AI-Enhanced Desktop Virtual Assistant,” a multi- functional system designed to automate daily tasks through voice commands and natural language processing (NLP). Leveraging advanced technologies such as OpenAI's GPT-4, machine learning models, Optical Character Recognition (OCR), and web automation tools, Jarvis integrates voice, text, and graphical interface interactions to deliver an intuitive user experience. With a 95% accuracy in voice command recognition and a 98% task completion rate, Jarvis efficiently handles diverse operations, including code generation, web scraping, and GUI automation. Key functionalities are supported by PyTorch-based neural networks for intent recognition, ListenJs for voice input, and Selenium for web automation, while EasyOCR enhances its ability to interact with graphical elements. The system's ability to engage in natural conversations, execute Python code dynam- ically, and correct errors iteratively demonstrates its robustness and versatility. Future improvements in GUI automation, NLP contextual understanding, and deep learning integration will further enhance its capabilities, positioning Jarvis as a valuable tool in various sectors such as public safety, education, and productivity.},
  keywords={Automation;Codes;Accuracy;Virtual assistants;Optical character recognition;Speech recognition;Oral communication;Natural language processing;User experience;Graphical user interfaces;OpenAI Integration;Speech to Text;Voice Assistant;Voice Recognition},
  doi={10.1109/ICAIQSA64000.2024.10882426},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10551980,
  author={Glebova, Anna},
  booktitle={2024 7th International Conference on Information Technologies in Engineering Education (Inforino)}, 
  title={Current Trends in the Global Information Technology Market in Engineering Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The author considers the prerequisites and directions for the development of the global market for information technologies in higher education, analyze the impact of the changed geopolitical situation in Europe on the provision of Russian higher engineering education with modern information technologies. The purpose of the study is to determine current trends in the development of the Russian information technology market in engineering education. The object of the study is the direction of development of the global market of information technologies in engineering education, the subject of the study is the possibility of developing the Russian segment of the market of information technologies in engineering education in accordance with global trends. As the results of the study, the article presents the identified directions for the development of the Russian segment of the information technology market in engineering education: 1) the use of artificial intelligence technology (for example, ChatGPT), 2) the introduction of virtual reality technologies in engineering education, 3) gamification of the learning process, 4) using mobile devices for learning.},
  keywords={Solid modeling;Globalization;Learning (artificial intelligence);Virtual reality;Market research;Software;Object recognition;EdTech;global information technology market;Russian information technology market;higher engineering education;recommended software},
  doi={10.1109/Inforino60363.2024.10551980},
  ISSN={},
  month={April},}@ARTICLE{10820190,
  author={Amin, Md Faizul Ibne and Watanobe, Yutaka and Rahman, Md Mostafizer and Shirafuji, Atsushi},
  journal={IEEE Access}, 
  title={Source Code Error Understanding Using BERT for Multi-Label Classification}, 
  year={2025},
  volume={13},
  number={},
  pages={3802-3822},
  abstract={Programming is an essential skill in computer science and across a wide range of engineering disciplines. However, errors, often referred to as ‘bugs’ in code, can be challenging to identify and rectify for both students learning to program and experienced professionals. Understanding, identifying, and effectively addressing these errors are critical aspects of programming education and software development. To aid in understanding and classifying these errors, we propose a multi-label error classification approach for source code using fine-tuned BERT models (BERT_Uncased and BERT_Cased). The models achieved average classification accuracies of 90.58% and 90.80%, exact match accuracies of 48.28% and 49.13%, and weighted F1 scores of 0.796 and 0.799, respectively. Precision, Recall, Hamming Loss, and ROC-AUC metrics further evaluate the effectiveness of our models. Additionally, we employed several combinations of large language models (CodeT5, CodeBERT) with machine learning classifiers (Decision Tree, Random Forest, Ensemble Learning, ML-KNN), demonstrating the superiority of our proposed approach. These findings highlight the potential of multi-label error classification to advance programming education, software engineering, and related research fields.},
  keywords={Programming;Programming profession;Codes;Multi label classification;Accuracy;Education;Transformers;Measurement;Computer bugs;Data models;Multi-label classification;BERT;CodeT5;CodeBERT;decision tree;random forest;ML-KNN;ensemble learning;data analysis;educational big data;error classification;learning analytics;programming learning;software engineering},
  doi={10.1109/ACCESS.2024.3525061},
  ISSN={2169-3536},
  month={},}@ARTICLE{9808269,
  author={Lv, Yancheng and Lin, Lin and Liu, Jie and Guo, Hao and Tong, Changsheng},
  journal={Neural Computation}, 
  title={Research on Imbalanced Data Classification Based on Classroom-Like Generative Adversarial Networks}, 
  year={2022},
  volume={34},
  number={4},
  pages={1045-1073},
  abstract={Most of the research on machine learning classification methods is based on balanced data; the research on imbalanced data classification needs improvement. Generative adversarial networks (GANs) are able to learn high-dimensional complex data distribution without relying on a prior hypothesis, which has become a hot technology in artificial intelligence. In this letter, we propose a new structure, classroom-like generative adversarial networks (CLGANs), to construct a model with multiple generators. Taking inspiration from the fact that teachers arrange teaching activities according to students' learning situation, we propose a weight allocation function to adaptively adjust the influence weight of generator loss function on discriminator loss function. All the generators work together to improve the degree of discriminator and training sample space, so that a discriminator with excellent performance is trained and applied to the tasks of imbalanced data classification. Experimental results on the Case Western Reserve University data set and 2.4 GHz Indoor Channel Measurements data set show that the data classification ability of the discriminator trained by CLGANs with multiple generators is superior to that of other imbalanced data classification models, and the optimal discriminator can be obtained by selecting the right matching scheme of the generator models.},
  keywords={},
  doi={10.1162/neco_a_01470},
  ISSN={0899-7667},
  month={March},}@ARTICLE{10744050,
  author={de León Languré, Alejandro and Zareei, Mahdi},
  journal={IEEE Access}, 
  title={Improving Text Emotion Detection Through Comprehensive Dataset Quality Analysis}, 
  year={2024},
  volume={12},
  number={},
  pages={166512-166536},
  abstract={As Artificial Intelligence assistants like OpenAI’s Chat-GPT or Google’s Gemini become increasingly integrated into our daily lives, their ability to understand and respond to human emotions expressed in natural language becomes essential. Affective computing, including text emotion detection (TED), has become crucial for human-computer interaction. However, the quality of datasets used for training supervised machine learning algorithms in TED often receives insufficient attention, potentially impacting model performance and comparability. This study addresses this gap by proposing a comprehensive framework for assessing dataset quality in TED. We introduce 14 quantitative metrics across four dimensions: representativity, readability, structure, and part-of-speech tag distribution, and investigate their impact on model performance. We conduct experiments on datasets with varying quality characteristics Using Bidirectional Long Short-Term Memory (BiLSTM) and Bidirectional Encoder Representations from Transformers (BERT) models. Our findings demonstrate that changes in these quality metrics can lead to statistically significant variations in model performance, with most metrics showing over 5% impact on prediction accuracy. Notably, pre-trained models like BERT exhibit more robustness to dataset quality variations than models trained from scratch. These results underscore the importance of considering and reporting dataset quality metrics in TED research, as they significantly influence model performance and generalizability. Our study lays the groundwork for more rigorous dataset quality assessment in affective computing, potentially leading to more reliable and comparable TED models in the future.},
  keywords={Measurement;Emotion recognition;Accuracy;Indexes;Encoding;Computational modeling;Bidirectional control;Training;Recurrent neural networks;Predictive models;Natural language processing;Text detection;Affective computing;natural language processing;sentiment analysis;text emotion detection;text emotion recognition},
  doi={10.1109/ACCESS.2024.3491856},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10786604,
  author={Borasi, Raffaella},
  booktitle={2024 IEEE Western New York Image and Signal Processing Workshop (WNYISPW)}, 
  title={AI Implications for Education and Educators}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={The main goal of this paper is to propose a framework to better understand and capitalize on the many implications of Artificial Intelligence (AI) for education, especially but not limited to the most recent developments of Generative Artificial Intelligence (GenAI). Four complementary categories are identified, each presenting diverse opportunities and challenges:1)Leveraging AI to improve instruction: This involves using AI to create new and more powerful learning opportunities for learners – at all levels of schools and across subject areas as well as instructional contexts.2)Promoting AI Literacy: This involves helping everyone develop sufficient understanding of AI to function in a society where AI is increasingly used.3)Rethinking workforce preparation: This involves responding to the need to change how we prepare future workers, once uses of AI take over functions previously performed by humans in specific occupations.4)Leveraging AI to support educators’ own work: While the focus of the previous three categories is on student learning, here the focus shifts on educators’ using AI in their work to increase their productivity and well-being.In what follows, I will examine each of these areas using conceptual analysis, building on findings from relevant research studies I have been involved in, as well as recent conversations within an interdisciplinary group of faculty, staff and students as part of an internal planning grant for the University of Rochester. For each area, after a brief introduction I will identify and discuss a few key elements; selected illustrations, in most cases reporting findings from relevant research projects, will also be provided in separate “boxes” so they can be read independently.For further information about this paper please contact the author.},
  keywords={Productivity;Generative AI;Conferences;Education;Buildings;Oral communication;Signal processing;Planning;Artificial intelligence},
  doi={10.1109/WNYISPW63690.2024.10786604},
  ISSN={2471-9242},
  month={Nov},}@INPROCEEDINGS{10397917,
  author={Fegade, Atul and Raut, Rajesh and Deshpande, Amruta and Mittal, Amit and Kaul, Natashaa and Khanna, Vandana},
  booktitle={2023 6th International Conference on Contemporary Computing and Informatics (IC3I)}, 
  title={Unleashing the Power of Generative Artificial Intelligence: Exploring its Boundless Potential and Overcoming Challenges in Academic Environments}, 
  year={2023},
  volume={6},
  number={},
  pages={1243-1249},
  abstract={Integrating generative artificial intelligence tools can allow one to manage and develop novel business methods efficiently. With the introduction of self-learning generative artificial intelligence (GAI) tools, the corporate world is trying to figure out the applications and their business implications. Major technology companies like Microsoft, Google, Facebook, etc., have shown enormous interest in investing in ventures developing generative AI tools/models. These tools/models can be experimented with, and their business use is being explored. The study aims to explore the potential uses of generative AI (GAI) in academics through its current capabilities and applications. The study also highlights the potential challenges and concerns arising from using generative AI in academics. The study has used descriptive and quantitative methods to answer the research questions. The study has used a questionnaire based on the Likert scale to measure the significance of indirect variables, viz. perceived ease of use (PEOU) and perceived trust (PT) on direct variable adoption of generative artificial intelligence (AGAI) in academics. The sample size consists of 100 students and 100 university professors. The study Mentions that perceived ease of use (PEOU) positively influences GAI (AGAI) adoption. Also, perceived trust (PT) has a predictive ability of AGIA when controlling for PEOU. The use of generative AI in a few years will become imperative in most human lives, which makes it mandatory to explore the possible ways of its adoption in the mainstream rather than avoiding or restricting its usage in academics.},
  keywords={Ethics;Generative AI;Social networking (online);Education;Transforms;Internet;Business;Generative Artificial Intelligence;ChatGPT;BARD;Generative Adversarial Networks;Education;Plagiarism;Academic Integrity},
  doi={10.1109/IC3I59117.2023.10397917},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10825415,
  author={D’Amico, Simone and De Santo, Alessia and Mercorio, Fabio and Mezzanzanica, Mario},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Enriching Skill Taxonomies through Vector Space Models}, 
  year={2024},
  volume={},
  number={},
  pages={2297-2302},
  abstract={Hierarchical taxonomies serve as fundamental structures for reasoning with hierarchical concepts across various domains such as healthcare, finance, and economy. However, maintaining their relevance and accuracy is a labor-intensive and error-prone task, demanding experts to identify and revise novel concepts constantly. In this context, distributional semantics techniques offer a promising avenue by suggesting terms likely to be associated with existing concepts. In our study, we propose a method to enhance taxonomies by adding related terms using contextual word embedding as encoders. We introduce VESPATE (VEctor SPAce model for Taxonomy Enrichment), a system designed to automatically expand any given hierarchical taxonomy with new terms using three generative models. Additionally, we integrate VESPATE with human validation to identify and select the most suitable terms for inclusion in the taxonomy. VESPATE was deployed within an EU project to enrich the official European Skill taxonomy, ESCO, with 40K+ digital terms gathered from the Web, aligning ESCO skills with current labor market needs. A total of 924 terms were selected through VESPATE, with 757 new terms subsequently validated by domain experts as correctly matched. Our framework, employing a pool of LLMs as encoders, helped us mitigate the limitations of the generative model, reducing the potential for errors and ensuring precise results in taxonomy enrichment. Additionally, the implementation of VESPATE consistently decreased the human effort required for the project. We evaluated the robustness of our system against a baseline constructed using ESCO’s hierarchy, achieving a 81% Positive Predictive Value (PPV) when combining all three models.},
  keywords={Accuracy;Large language models;Jobs listings;Taxonomy;Semantics;Finance;Medical services;Predictive models;Vectors;Robustness;Automated Taxonomy Enrichment;Labor Market Intelligence;Large Language Models;NLP},
  doi={10.1109/BigData62323.2024.10825415},
  ISSN={2573-2978},
  month={Dec},}@ARTICLE{10620649,
  author={Couto, Gustavo Claudio Karl and Antonelo, Eric Aislan},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={Hierarchical Generative Adversarial Imitation Learning With Mid-Level Input Generation for Autonomous Driving on Urban Environments}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={Deriving robust control policies for realistic urban navigation scenarios is not a trivial task. In an end-to-end approach, these policies must map high-dimensional images from the vehicle's cameras to low-level actions such as steering and throttle. While pure Reinforcement Learning (RL) approaches are based exclusively on engineered rewards, Generative Adversarial Imitation Learning (GAIL) agents learn from expert demonstrations while interacting with the environment, which favors GAIL on tasks for which a reward signal is difficult to derive, such as autonomous driving. However, training deep networks directly from raw images on RL tasks is known to be unstable and troublesome. To deal with that, this work proposes a hierarchical GAIL-based architecture (hGAIL) which decouples representation learning from the driving task to solve the autonomous navigation of a vehicle. The proposed architecture consists of two modules: a GAN (Generative Adversarial Net) which generates an abstract mid-level input representation, which is the Bird's-Eye View (BEV) from the surroundings of the vehicle; and the GAIL which learns to control the vehicle based on the BEV predictions from the GAN as input. hGAIL is able to learn both the policy and the mid-level representation simultaneously as the agent interacts with the environment. Our experiments made in the CARLA simulation environment have shown that GAIL exclusively from cameras (without BEV) fails to even learn the task, while hGAIL, after training exclusively on one city, was able to autonomously navigate successfully in 98% of the intersections of a new city not used in training phase. Videos and code available at: https://sites.google.com/view/hgail},
  keywords={Trajectory;Cameras;Training;Task analysis;Urban areas;Generative adversarial networks;Cloning;Autonomous Driving;Generative Adversarial Imitation Learning;CARLA Simulator;Bird's-Eye View},
  doi={10.1109/TIV.2024.3436587},
  ISSN={2379-8904},
  month={},}@INPROCEEDINGS{10894718,
  author={Otsuka, Ami and Sasaki, Akira and Ito, Atsushi},
  booktitle={2024 IEEE 15th International Conference on Cognitive Infocommunications (CogInfoCom)}, 
  title={“Interactive AI for Software Development Learning: Shifting Focus to Requirement Specification”}, 
  year={2024},
  volume={},
  number={},
  pages={000121-000126},
  abstract={We propose a new approach to programming learning. Specifically, it is a learning method centered on creating requirement specifications using OpenAI’s interactive AI, ChatGPT, which enables learners to gain a deeper understanding of the overall program design and structure and aims at learning through the experience of creating and publishing their software. To this end, we clarify the current programming learning status and problems, propose new learning methods, and evaluate their effectiveness. Furthermore, we will develop a vision for the future based on them. We then provide insights into how programming education should evolve and how advanced technologies such as interactive AI should be used.},
  keywords={Learning systems;Publishing;Learning (artificial intelligence);Chatbots;Software;Programming profession;Software development management;software development model;specification description;software engineering;study material for studying programming;conversational Artificial Intelligence},
  doi={10.1109/CogInfoCom63007.2024.10894718},
  ISSN={2473-5671},
  month={Sep.},}@ARTICLE{10494340,
  author={Cámara, Javier and Troya, Javier and Montes-Torres, Julio and Jaime, Francisco J.},
  journal={IEEE Software}, 
  title={Generative AI in the Software Modeling Classroom: An Experience Report With ChatGPT and Unified Modeling Language}, 
  year={2024},
  volume={41},
  number={6},
  pages={73-81},
  abstract={The use of generative AI chatbots in formative assessment can effectively gauge learning progress, increase the academic performance of students compared to a traditional methodology, and raise student awareness about the tradeoffs of employing generative AI in their work.},
  keywords={Unified modeling language;Chatbots;Software development management;Generative AI;Object oriented modeling;Educational courses;Curriculum development;Computer science education;Unified modeling language;Modeling},
  doi={10.1109/MS.2024.3385309},
  ISSN={1937-4194},
  month={Nov},}@INPROCEEDINGS{10685655,
  author={Huang, Jingxiu and Wei, Yufeng and Zhang, Lixin and Chen, Weirui},
  booktitle={2024 International Symposium on Educational Technology (ISET)}, 
  title={Evaluating generative artificial intelligence in answering course-related open questions: A pilot study}, 
  year={2024},
  volume={},
  number={},
  pages={64-69},
  abstract={ChatGPT, which has been discussed in public in recent years, was launched in November 2022, with a continuously expanding market size. Generative Artificial Intelligence (GAI) has been developing rapidly in China. However, we have little knowledge of how well the GAIs are performing at answering course-related open questions, especially in Chinese. Therefore, this study aims to analyze the performances of GAIs in answering course-related open questions from both machine and manual evaluation perspectives. The results from this study showed that GAIs got unsatisfactory scores in this situation. Two different aspects of comparison of GAIs’ scores are discussed. More study on evaluating the performance of GAI is needed to investigate the capabilities of answering course-related open questions in the future.},
  keywords={Generative AI;Manuals;Educational technology;Chatbots;GAI;automatic evaluation;manual evaluation;course-related open questions},
  doi={10.1109/ISET61814.2024.00022},
  ISSN={2766-2144},
  month={July},}@INPROCEEDINGS{10345880,
  author={Virvou, Maria and Tsihrintzis, George A.},
  booktitle={2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)}, 
  title={Pre-made Empowering Artificial Intelligence and ChatGPT: The Growing Importance of Human AI-Experts}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper investigates the augmented responsibility of human Artificial Intelligence experts in the era of empowered pre-made Artificial Intelligence (AI). The responsible and ethical use of pre-made AI is of paramount importance in this evolving technology. AI systems have the potential to impact numerous aspects of society, ranging from healthcare and finance to education and IoT. The decisions made by AI algorithms can have significant consequences for individuals, communities, and even entire industries. Using a comparison to the way widely available medicines require a prescription from medical doctors, human AI experts assume the role of evaluating, recommending, and overseeing the implementation of AI systems, even when pre-built AI solutions may seem user-friendly on the surface. The paper has explored the expanded responsibilities of human AI experts within two contemporary scenarios involving pre-made AI, encompassing LLMs and ChatGPT. These AI technologies are applied in two principal manners: initially, as standalone AI products readily accessible to a wide audience, and secondly, as elements undergoing exploration for integration into other AI-driven software and Intelligent Information Systems (IIS), with the goal of enhancing natural language processing (NLP) features within user interfaces. In all cases, the expertise of human AI professionals is indispensable, and their role is augmented. These professionals bear an increased responsibility for ensuring the responsible and ethical deployment of AI technologies, with a focus on human-centered design, bias mitigation, validation and accuracy estimation of the results, transparency promotion, and the necessary balance between automation and human oversight. This paper performs a review on pre-made AI and ChatGPT together with custom-based AI and shows that recent advance require an augmented role of human AI experts},
  keywords={Industries;Ethics;Medical services;User interfaces;Chatbots;Software;Requirements engineering;Responsible Artificial Intelligence;Human-centered AI;AI-Empowered Software Engineering;ChatGPT;Large Language Models (LLMs);Generative AI;e-learning Requirements Engineering in AI;Artificial Intelligence;Intelligent Information Systems},
  doi={10.1109/IISA59645.2023.10345880},
  ISSN={},
  month={July},}@INPROCEEDINGS{10734642,
  author={Georgopoulou, Maria Sofia and Krouska, Akrivi and Troussas, Christos and Sgouropoulou, Cleo},
  booktitle={2024 9th South-East Europe Design Automation, Computer Engineering, Computer Networks and Social Media Conference (SEEDA-CECNSM)}, 
  title={Redefining the Concept of Literacy: a DigCompEdu extension for Critical Engagement with AI tools}, 
  year={2024},
  volume={},
  number={},
  pages={98-102},
  abstract={Artificial Intelligence (AI) is rapidly transforming our world, and education is no exception. The growing popularity and use of AI systems calls for a new understanding of what it means to be literate in the modern world. Thus, it is crucial for individuals to develop AI-driven critical thinking skills to effectively interact with these technologies. However, existing research focuses mainly on the "how" of AI integration, with limited exploration of the "why" and "how" of fostering critical engagement with AI tools. In this article, we propose an extension to DigCompEdu that aligns with the UNESCO pillars of education. This extension highlights five key elements that challenge critical thinking capabilities in relation to AI: "know-what," "know-who," "know-where," "know-how," and "know-why". By combining critical thinking skills with AI functionalities, educators can empower students to become responsible and informed digital citizens in the era of generative AI.},
  keywords={Design automation;Social networking (online);Generative AI;Education;Europe;Computer networks;Artificial intelligence;literacy;Artificial Intelligence;DigCompEdu;four pillars of education;critical engagement;digital citizens},
  doi={10.1109/SEEDA-CECNSM63478.2024.00026},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11007383,
  author={Kashyap, Ria Kamala and Phalachandra, Prithvi and Kulkarni, Prerana Prashant and Narayan, Rohan and Prasad, V R Badri},
  booktitle={2024 Intelligent Systems and Machine Learning Conference (ISML)}, 
  title={Silent Conversations: A Deep Dive into using CNN and ChatGPT for deriving meaning from Language Gestures}, 
  year={2024},
  volume={},
  number={},
  pages={651-656},
  abstract={For the community who are deaf or hard of hearing, sign language serves as a major means of communication. However, their inability to properly communicate is frequently hampered by a lack of resources and qualified translators. Computer vision and image processing methods, such as Convolutional Neural Networks, a more recent advancement in the field of computer vision, can be utilized to address this problem. The aim of translating sign language is to enable communication between those who are deaf and those who are hearing by precisely identifying, categorizing, and analyzing the hand motions used in sign language. To close the communication gap, this project attempts to develop a technology that can automatically convert Indian sign language into Textual Context. Using techniques like CNN for image classification and generative AI (ChatGPT) for sentence formation, which are techniques and tools known for their high degree of accuracy, we can develop an effective solution.},
  keywords={Sign language;Computer vision;Translation;Accuracy;Generative AI;Auditory system;Oral communication;Linguistics;Chatbots;Convolutional neural networks;Classification;Convolutional Neural Network;Generative AI;ChatGPT},
  doi={10.1109/ISML60050.2024.11007383},
  ISSN={},
  month={May},}@INPROCEEDINGS{10350098,
  author={Heidrich, David and Schreiber, Andreas},
  booktitle={2023 IEEE Working Conference on Software Visualization (VISSOFT)}, 
  title={Visualizing Source Code as Comics Using Generative AI}, 
  year={2023},
  volume={},
  number={},
  pages={40-44},
  abstract={The architecture and inner structure of software is often only implicitly available in the form of its source code and thus not tangible and intuitively easy to understand for non-programmers and laymen. Our goal is to create visualizations as automatically as possible, with which such people can neverthe-less understand the software or parts of the software and get a feel for the structure of the software and how its methods work. Especially for newcomers to software projects, for management or even for students and pupils, it can be helpful to get a non-technical insight into the software. We use the concept of visualizing information as comics to present aspects of the software as strikingly as possible, as comics are an effective way to present complex systems and interrelationships for certain target groups. For this purpose, we present a method to generate comics from source code. Our semi-automated process is based on generating a prompt for an LLM from source code, which in turn generates a prompt for a comic image generation using the text-to-image model Stable Diffusion. We show that generative AI methods can be used to rapidly generate human-compatible artistic representations from source code. However, further research is needed to validate the understandability of the results.},
  keywords={Visualization;Image synthesis;Source coding;Computer architecture;Software;Artificial intelligence;Pupils;visualization;software visualization;comics;generative ai;stable diffusion},
  doi={10.1109/VISSOFT60811.2023.00014},
  ISSN={2832-6555},
  month={Oct},}@INPROCEEDINGS{10346594,
  author={Markus, Anna M. and Ovinova, Lada N. and Dmitrusenko, Inna N. and Shraiber, Elena G.},
  booktitle={2023 International Conference on Quality Management, Transport and Information Security, Information Technologies (IT&QM&IS)}, 
  title={Application of Artificial Intelligence Technology in Teaching English Language to Engineering Bachelors}, 
  year={2023},
  volume={},
  number={},
  pages={147-151},
  abstract={Neural networks function and interact in different areas. Artificial Intelligence (AI) technologies are applied in teaching foreign languages in the modern educational system. The purpose of the study was to identify the possibilities of using available artificial intelligence services in teaching the English language in the academic environment. The study used theoretical analysis of pedagogical literature and the questionnaire-diagnostic method. The System Usability Scale (SUS) and Technology Acceptance Model (TAM) were chosen as diagnostic tools for analyzing the characteristics of AI services (Scribble Diffusion, Metavoice, Pictory, ChatGPT). The study involved 96 undergraduate engineering bachelors from South Ural State University. The degree of students' satisfaction with the implementation of AI services was analyzed through the questionnaire. The presented results of the ascertaining experiment confirmed the feasibility and the effectiveness of integrating AI services in teaching the English language to engineering bachelors in the educational process.},
  keywords={Knowledge engineering;Technological innovation;Technology acceptance model;Education;Neural networks;Writing;Chatbots;artificial intelligence;AI technology;foreign languages;engineering bachelors},
  doi={10.1109/ITQMTIS58985.2023.10346594},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10581765,
  author={Yu, Chao and Zhu, Xiao and Xu, Tianyu and Zhu, Wenhao},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Enhancing Sentence Representation with a Transfer Task Enhancement Auxiliary Network}, 
  year={2024},
  volume={},
  number={},
  pages={1764-1767},
  abstract={Contrastive Learning of Sentence Embeddings (CSE) has gained significant traction in the realm of Natural Language Processing (NLP), proving to be particularly effective in applications like sentence similarity assessment and text retrieval, where supervised methods are currently achieving the best performance. We have identified a trend: although supervised sentence representation methods show remarkable effectiveness in semantic similarity assessments, their performance tends to decline in transfer tasks. In order to solve this problem, we propose to use transfer task enhancement auxiliary network, named TEAnet. Our method leverages rationales generated by large language models to guide smaller models, specifically by jointly conducting classification loss training during the contrastive training process. Our experiments demonstrate that the auxiliary network approach enhances performance on the transfer task while maintaining the semantic similarity task of training.},
  keywords={Training;Seminars;Large language models;Semantics;Transfer learning;Contrastive learning;Market research;contrastive learning;sentence embeddings;large language models},
  doi={10.1109/AINIT61980.2024.10581765},
  ISSN={},
  month={March},}@INPROCEEDINGS{10892948,
  author={Aguinalde, Pauline and Shin, Jinnie and Carroll, Bruce F. and Crippen, Kent J.},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Leveraging Large Language Models to Automatically Investigate Core Tasks Within Undergraduate Engineering Work-Integrated Learning Experiences}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This full research paper aims to investigate methods for systematically identifying core tasks within undergraduate engineering work-integrated learning (WIL) opportunities, such as internships and co-ops. It achieves this by automatically analyzing WIL opportunities using transformer models. A dataset of 4,833 engineering internship postings from the last ten years was obtained through a partnership with the University's Career Connections Center. From this, a subset of 374 aerospace engineering internships, yielding 1,913 unique job tasks, was extracted for human labeling. We applied the Llama 2 architecture, a sophisticated pre-trained LLM, to extract a list of specific responsibilities and tasks from the internship postings. The job tasks were used to train an automated classification system to map each task to the established seven ABET student outcomes. Each job task was human-labeled by three subject matter experts, achieving a high level of inter-rater reliability of 0.998, according to Krippendorff's alpha. RoBERTa resulted in the optimal model indicating a label ranking average precision of 0.892 on the validation set and 0.857 on the testing set. Our findings provide novel insights into understanding the evolving skill expectations of undergraduate interns, offering a basis for tailoring engineering education to address these demands. Furthermore, the automated analysis of internship tasks demonstrates the potential for a scalable way to address the gap in understanding the core responsibilities within WIL experiences.},
  keywords={Industries;Training;Analytical models;Accuracy;Subject matter experts;Text categorization;Standards organizations;Transformer cores;Transformers;Aerospace engineering;work-integrated learning;internships;natural language processing;aerospace engineering;ABET},
  doi={10.1109/FIE61694.2024.10892948},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10714517,
  author={Turchi, Tommaso},
  booktitle={2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={FlowPilot: A Generative AI-Driven Visual Language for Computational Thinking Education}, 
  year={2024},
  volume={},
  number={},
  pages={353-355},
  abstract={This paper introduces FlowPilot, a novel flow-based visual programming language designed to enhance Computational Thinking (CT) education. FlowPilot leverages generative AI to create a dynamic, browser-based environment where users can construct programs using natural language descriptions. By integrating AI-driven block generation with a flow-based visual interface, FlowPilot supports key CT pillars such as abstraction and decomposition. This approach offers a unique platform for learners to explore programming concepts at various levels of complexity, fostering a deeper understanding of computational processes.},
  keywords={Visualization;Computer languages;Generative AI;Natural languages;Education;Complexity theory;Programming profession;Visual Programming;Computational Thinking;Generative AI},
  doi={10.1109/VL/HCC60511.2024.00046},
  ISSN={1943-6106},
  month={Sep.},}@INPROCEEDINGS{10957038,
  author={He, Long and Kang, Lai and Geng, Mingyang},
  booktitle={2025 International Conference on Electrical Automation and Artificial Intelligence (ICEAAI)}, 
  title={An Empirical Study on Large Language Models for Aerospace Question Answering}, 
  year={2025},
  volume={},
  number={},
  pages={1295-1300},
  abstract={The application of knowledge-based question answering (QA) systems in the aerospace sector is crucial, providing essential support in training, fault analysis, and operational manual development. These systems enhance efficiency and safety by enabling rapid, precise answers to complex technical questions, aiding in maintaining system reliability. However, limited empirical research has focused on assessing the performance of QA systems specifically tailored for aerospace, leaving an important knowledge gap in understanding their domain-specific effectiveness. This oversight may stem from the sector's unique demands for accuracy and the technical specialization required. Addressing the challenges of building an aerospace QA system requires a model with in-depth technical comprehension, able to deliver precise and contextually relevant answers across a wide range of specialized questions. Moreover, constructing a comprehensive dataset for such complex, evolving knowledge domains presents additional hurdles. This study provides an empirical assessment of three large language models—Gemma2, LLaMA, and Phi3—on a carefully curated dataset of 300 aerospace questions. Using expert human evaluation to validate model performance, we identify each model's strengths, limitations, and practical applicability in aerospace QA. Our findings highlight that while these models show promise in answering aerospace-specific questions, their accuracy, logical structure, and depth of procedural understanding vary. These insights contribute valuable guidance for future improvements in knowledge transfer, operational support, and technical training tools within the aerospace industry.},
  keywords={Training;Analytical models;Adaptation models;Accuracy;Large language models;Question answering (information retrieval);Safety;Reliability;Aerospace industry;Knowledge transfer;Aerospace Question Answering;Large Language Models;Empirical Analysis},
  doi={10.1109/ICEAAI64185.2025.10957038},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10677925,
  author={Peng, Fei and Fu, Huiyuan and Ming, Anlong and Wang, Chuanming and Ma, Huadong and He, Shuai and Dou, Zifei and Chen, Shu},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={AIGC Image Quality Assessment via Image-Prompt Correspondence}, 
  year={2024},
  volume={},
  number={},
  pages={6432-6441},
  abstract={In the rapidly evolving landscape of deep learning, generative models such as Generative Adversarial Networks (GANs) and diffusion models have significantly advanced the capabilities of Artificial Intelligence Generated Content (AIGC). These technologies have streamlined the creative process, enabling AI to autonomously produce a diverse range of content with minimal human input. Despite the remarkable progress in AI-generated images (AIGIs), evaluating the quality of AIGIs remains a complex challenge. Traditional image quality assessment (IQA), focusing on aspects like distortion and blurriness, are insufficient for capturing the correspondence between AIGIs and their prompts. To address this, we propose a novel AIGC image quality assessment (AIGCIQA) framework that emphasizes the correspondence between images and prompts. Utilizing the CLIP model’s pre-trained image and text encoders, our method effectively measures the correspondence between visual and textual inputs. By transforming the assessment into classification probabilities and subsequently into a precise regression task, our method enhances the CLIP model’s performance in AIGCIQA. Our method’s effectiveness is confirmed by its first place in the image track of the NTIRE 2024 Quality Assessment for AI-Generated Content challenge and its state-of-the-art (SOTA) performance on benchmark datasets AGIQA-1K, AGIQA-3K, and AIG-CIQA2023. This research represents a significant advancement in the field, offering an efficient and versatile tool for the evaluation of AIGIs and contributing to the ongoing development of AIGC technologies. Our codes are available at https://github.com/pf0607/IPCE.},
  keywords={Image quality;Visualization;Refining;Focusing;Benchmark testing;Streaming media;Generative adversarial networks},
  doi={10.1109/CVPRW63382.2024.00644},
  ISSN={2160-7516},
  month={June},}@INPROCEEDINGS{10465950,
  author={Katrojwar, Himanshu R. and Atkar, Siddhesh D. and Raut, Shreepad R. and Bhoge, Harsh N. and Agrawal, Rahul and Dhule, Chetan},
  booktitle={2023 International Conference on Advances in Computation, Communication and Information Technology (ICAICCIT)}, 
  title={Comprehensive Study on ChatGPT Sentiment Analysis and Visualization}, 
  year={2023},
  volume={},
  number={},
  pages={1244-1248},
  abstract={The rapid growth of artificial intelligence (AI) is poised to reshape industries and societal aspects, driven by its ability to simulate human intelligence and perform tasks requiring humanlike thinking and learning. ChatGpt has been leading this growth since its inception, enhancing user experience and garnering over 100 million users by February 2023. Social Networking sites have been a source for sharing the sentiments. This research explores tweets on ChatGpt in the field of sentiment analysis and its integration with data visualization techniques to enhance the comprehension of textual data. The research proposed a holistic approach by exploring the methodologies such as data collection, data preprocessing, tokenization, sentiment analysis using Natural Language Processing, accuracy assessment and visualization. For training and testing a dataset has been gathered from Kaggle which daily gets updated. The proposed study gives comprehensive results about sentiments on ChatGPT and explores different visualization techniques.},
  keywords={Training;Sentiment analysis;Social networking (online);Data visualization;Learning (artificial intelligence);Chatbots;User experience;Artificial Intelligence;ChatGpt;GPT;Sentiment;Visualization;Natural Language Processing;Twitter;Analysis},
  doi={10.1109/ICAICCIT60255.2023.10465950},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10487259,
  author={Kim, Dae-Kyoo and Chen, Jingshu and Ming, Hua and Lu, Lunjin},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={Assessment of ChatGPT's Proficiency in Software Development}, 
  year={2023},
  volume={},
  number={},
  pages={2637-2644},
  abstract={This paper presents an assessment of ChatGPT's proficiency in software development, using an online tour reservation system (TORS) as a case study. The findings indicate that ChatGPT has significant potential in software development, demonstrating its capabilities in assisting various activities throughout the development process, including requirements analysis, domain modeling, design modeling, and implementation. Notably, the model performed well in implementation, generating more than 90% of the code and fixing a majority of errors. It also demonstrated its capability in making design decisions in the design phase. However, the study also identified non-trivial limitations, such as a lack of traceability and inconsistencies among produced artifacts, which required human involvement. Overall, the results suggest that when combined with human developers, ChatGPT can serve as a valuable tool in software development. It has the potential to enhance productivity and efficiency in various aspects of the development process, while acknowledging the need for human expertise to mitigate the limitations.},
  keywords={Productivity;Analytical models;Codes;Chatbots;Software;assessment;ChatGPT;generative artificial intelligence;software development},
  doi={10.1109/CSCE60160.2023.00421},
  ISSN={},
  month={July},}@INPROCEEDINGS{10628503,
  author={Hassani, Shabnam and Sabetzadeh, Mehrdad and Amyot, Daniel and Liao, Jain},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference (RE)}, 
  title={Rethinking Legal Compliance Automation: Opportunities with Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={432-440},
  abstract={As software-intensive systems face growing pressure to comply with laws and regulations, providing automated support for compliance analysis has become paramount. Despite advances in the Requirements Engineering (RE) community on legal compliance analysis, important obstacles remain in developing accurate and generalizable compliance automation solutions. This paper highlights some observed limitations of current approaches and examines how adopting new automation strategies that leverage Large Language Models (LLMs) can help address these shortcomings and open up fresh opportunities. Specifically, we argue that the examination of (textual) legal artifacts should, first, employ a broader context than sentences, which have widely been used as the units of analysis in past research. Second, the mode of analysis with legal artifacts needs to shift from classification and information extraction to more end-to-end strategies that are not only accurate but also capable of providing explanation and justification. We present a compliance analysis approach designed to address these limitations. We further outline our evaluation plan for the approach and provide preliminary evaluation results based on data processing agreements (DPAs) that must comply with the General Data Protection Regulation (GDPR). Our initial findings suggest that our approach yields substantial accuracy improvements and, at the same time, provides justification for compliance decisions.},
  keywords={Automation;Accuracy;Law;Large language models;Information retrieval;Data processing;Regulation;Legal Compliance;Legal Requirements;Large Language Models;GPT-4;GDPR},
  doi={10.1109/RE59067.2024.00051},
  ISSN={2332-6441},
  month={June},}@INPROCEEDINGS{10842863,
  author={Jaiswal, Priyanka and Dhomne, Anushree and Rawarkar, Sakshi and Bulkunde, Sanket and Lanjewar, Sarvesh and Mundel, Vedant},
  booktitle={2024 2nd DMIHER International Conference on Artificial Intelligence in Healthcare, Education and Industry (IDICAIEI)}, 
  title={Interactive Coding Platform with Code Summarizer}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study presents a Code Summarizer cum Explanation Tool which helps as the student specially those who are beginner in the world of coding to understand other’s solution for a given problem statement. Our approach involves the utilization of this state-of- the-art language model, widely acknowledged for its prowess in handling various text- related tasks such as code generation and summarization. In this study we have use an open-sourced state-of-the art large language model which is used for many downstream text related task such as code generation, code summarisation, etc. and consist of 7 Billion parameters (weights & biases) developed by Technology Innovation Institute (TIIUAE). We fine-tuned the said model on our custom dataset for code explanation task. We have fine-tuned the model for 1 epoch which took approximate 3 hours on 590 steps. As a result we have obtained a brief summary, when given code as a prompt input. By bridging the gap between theoretical understanding and practical application, our Code Summarizer/Explanation Tool can become an useful tool for beginners on their coding journey.},
  keywords={Industries;Technological innovation;Codes;Art;Atmospheric modeling;Large language models;Education;Medical services;User interfaces;Encoding;Code summarization;Falcon 7B;CodeBERT;Natural Language;Transfer Learning;Large Language Model},
  doi={10.1109/IDICAIEI61867.2024.10842863},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10795351,
  author={Khelifi, Jasem and Chouchen, Moataz and Ouni, Ali and Wang, Dong and Kula, Raula Gaikovina and Hamza, Salma and Mkaouer, Mohamed Wiem},
  booktitle={2024 IEEE International Conference on Source Code Analysis and Manipulation (SCAM)}, 
  title={GitRev: An LLM-Based Gamification Framework for Modern Code Review Activities}, 
  year={2024},
  volume={},
  number={},
  pages={235-241},
  abstract={Modern code review (MCR) is recognized as an effective software quality assurance practice that is broadly adopted by open-source and commercial software projects. MCR is most effective when developers follow best practices, as it improves code quality, enhances knowledge transfer, increases team awareness and shares code ownership. However, prior work highlights that poor code review practices are common and often manifest in the form of low review participation and engagement, shallow review, and toxic communications. To address these issues, we introduce GitRev, a novel approach that applies gamification mechanisms to boost developer motivation and engagement. GitRev is built on top of a Large Language Model (LLM), used as a points-based reward system that leverages the code change context, and code review activities. We implement GitRev as a GitHub app with a web browser extension that consists of a client-side web browser extension that gamifies the GitHub user interface, and a server-side composed of a Node.js server for authentication and data management. To evaluate GitRev, we conduct a controlled experiment with 86 graduate and undergraduate students. Results indicate the promising potential of our approach for improving the code review process and developers' engagement. GitRev is publicly available at https://anonymous.40pen.science/r/GitRev-OB74},
  keywords={Codes;Reviews;Source coding;Large language models;Software quality;User interfaces;Browsers;Servers;Knowledge transfer;Software development management;Modern Code Review;GitHub;Gamification},
  doi={10.1109/SCAM63643.2024.00031},
  ISSN={2470-6892},
  month={Oct},}@INPROCEEDINGS{10810102,
  author={Henry, Matthew Martianus and Heryanto, Nur Adhianti and Isnan, Mahmud and Nugroho, Kuncahyo Setyo and Pardamean, Bens},
  booktitle={2024 9th International Conference on Information Technology and Digital Applications (ICITDA)}, 
  title={Automatic Multiple Choice Question Generation: A Systematic Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Despite their drawbacks, multiple-choice questions (MCQ) have been widely used to assess the students' understanding of lectures through examinations. The development of automatic MCQ generation is beneficial, especially for educators. As a starting point for further development, a Systematic Literature Review (SLR) is conducted to uncover current trends, future challenges, and opportunities in automatic MCQ generation. Previously, an SLR was conducted, but it lacks coverage of the utilization of transformer-based models. This SLR covers the development of automatic MCQ generation using either traditional or advanced approaches such as Transformers. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses framework was used to gather the data from Scopus, IEEE Xplore, SpringerLink, arXiv, and Semantic Scholar. The included articles must be open-access computer science conference papers or journal articles and written in English less than five years ago. Four independent reviewers analyzed the research workflow, evaluation metric, and dataset used in each study. There are 18 included studies, where 17% (n = 3) studies are from 2024, 33% (n = 6) studies are from 2023, 22% (n = 4) studies are from 2022, 11% (n = 2) studies are from 2021, and 17% (n = 3) studies are from 2020. There are 33% (n = 6) of the studies used the traditional feature-based engineering approach, 39% (n = 7) of the studies used the Transformer-based model fine-tuning approach, and the remaining used novel approaches. The study found that BERT variants are the most utilized Transformer-based model in automatic MCQ. The research notes some challenges, but also open various opportunities for further research, including Large Language Model (LLM) utilization for automatic MCQ generation, the utilization BERT-based models for standardized machine-learned evaluation metrics, and the initiative for the creation of an MCQ dataset benchmark.},
  keywords={Measurement;Semantics;Reinforcement learning;Benchmark testing;Ontologies;Transformers;Question generation;Prompt engineering;Standards;Systematic literature review;Multiple choice question;question generation;systematic literature review;Transformer model},
  doi={10.1109/ICITDA64560.2024.10810102},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10808018,
  author={Chen, Qunqiang and Qian, Mei and Zheng, Hao and Huang, Rujuan},
  booktitle={2024 5th International Conference on Intelligent Computing and Human-Computer Interaction (ICHCI)}, 
  title={Research on WeChat Question and Answer Applet Based on “Big Language Model”}, 
  year={2024},
  volume={},
  number={},
  pages={371-376},
  abstract={Accompanied by the rapid development of the artificial intelligence industry, the world's major Internet companies have begun to release their own big language models, the rapid development of artificial intelligence is driving a technological revolution, and it will eventually evolve into a social change. People can use these big language models to facilitate work and learning. In the future, human teachers can teach with the help of AI robots to realize the collaboration between the virtual world and the real world, and synchronize the classroom teaching tasks. Software development engineers can improve the quality of their code with the help of AI. Artificial intelligence applied to smart bionics to provide patients with bionic organs will bring about a number of medical changes. Everyone can enjoy the dividends of the rapid development of the artificial intelligence industry, but it is inevitable that many problems will arise while it continues to develop. Finally, this paper develops a certain introduction to the development of AI Q&A software with the help of a large language model.},
  keywords={Industries;Computational modeling;Biological system modeling;Large language models;Force;Software;Data models;Artificial intelligence;Robots;Software development management;Large language model;The development of AI Q&A software},
  doi={10.1109/ICHCI63580.2024.10808018},
  ISSN={},
  month={Sep.},}@ARTICLE{10880482,
  author={Li, Na and Zhou, Chunyi and Gao, Yansong and Chen, Hui and Zhang, Zhi and Kuang, Boyu and Fu, Anmin},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Machine Unlearning: Taxonomy, Metrics, Applications, Challenges, and Prospects}, 
  year={2025},
  volume={},
  number={},
  pages={1-21},
  abstract={Personal digital data is a critical asset, and governments worldwide have enforced laws and regulations to protect data privacy. Data users have been endowed with the “right to be forgotten” (RTBF) of their data. In the course of machine learning (ML), the forgotten right requires a model provider to delete user data and its subsequent impact on ML models upon user requests. Machine unlearning (MU) emerges to address this, which has garnered ever-increasing attention from both industry and academia. Specifically, MU allows model providers to eliminate the influence of unlearned data without retraining the model from scratch, ensuring the model behaves as if it never encountered this data. While the area has developed rapidly, there is a lack of comprehensive surveys to capture the latest advancements. Recognizing this shortage, we conduct an extensive exploration to map the landscape of MU including the (fine-grained) taxonomy of unlearning algorithms under centralized and distributed settings, debate on approximate unlearning, verification and evaluation metrics, and challenges and solutions across various applications. We also focus on the motivations, challenges, and specific methods for deploying unlearning in large language models (LLMs), as well as the potential attacks targeting unlearning processes. The survey concludes by outlining potential directions for future research, hoping to serve as a beacon for interested scholars.},
  keywords={Data models;Surveys;Measurement;Training;Electronic mail;Data privacy;Taxonomy;General Data Protection Regulation;Computational modeling;Approximation algorithms;Data privacy;federated learning (FL);large language model (LLM);machine learning (ML);machine unlearning (MU)},
  doi={10.1109/TNNLS.2025.3530988},
  ISSN={2162-2388},
  month={},}@INPROCEEDINGS{10590542,
  author={Bessas, Nikos and Tzanaki, Eleni and Vavougios, Dionisios and Plagianakos, Vassilis P.},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Implementing AI in Physics Lessons in the High School}, 
  year={2023},
  volume={},
  number={},
  pages={1775-1779},
  abstract={ChatGPT is a relatively recent application, free to the general public, released at the end of November 2022 and rooted in artificial intelligence. The educational community is still debating how such an application could be used in the teaching and learning area, with the facilities it offers and the risks it entails. The purpose of this paper is to present how such an application responds to physics topics at the high school level, and to suggest ways to use it properly. In order to cover the issue comprehensively, it is approached from both the teacher's and the student's point of view.},
  keywords={Ethics;Data privacy;Scientific computing;Education;Learning (artificial intelligence);Chatbots;Task analysis;Artificial Intelligence;ChatGPT;Physics;Education;Teaching;Learning},
  doi={10.1109/CSCI62032.2023.00293},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{10992488,
  author={Milliken, Louis and Kang, Sungmin and Yoo, Shin},
  booktitle={2025 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Beyond pip Install: Evaluating LLM Agents for the Automated Installation of Python Projects}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Many works have recently proposed the use of Large Language Model (LLM) based agents for performing ‘repository level’ tasks, loosely defined as a set of tasks whose scopes are greater than a single file. This has led to speculation that the orchestration of these repository-level tasks could lead to software engineering agents capable of performing almost independently of human intervention. However, of the suite of tasks that would need to be performed by this autonomous software engineering agent, we argue that one important task is missing, which is to fulfil project level dependency by installing other repositories. To investigate the feasibility of this repository level installation task, we introduce a benchmark of of repository installation tasks curated from 40 open source Python projects, which includes a ground truth installation process for each target repository. Further, we propose Installamatic, an agent which aims to perform and verify the installation of a given repository by searching for relevant instructions from documentation in the repository. Empirical experiments reveal that that 55% of the studied repositories can be automatically installed by our agent at least one out of ten times. Through further analysis, we identify the common causes for our agent's inability to install a repository, discuss the challenges faced in the design and implementation of such an agent and consider the implications that such an agent could have for developers.},
  keywords={Correlation;Large language models;Documentation;Benchmark testing;Software;Python;Software engineering;LLMs;installation;documentation},
  doi={10.1109/SANER64311.2025.00009},
  ISSN={2640-7574},
  month={March},}@INPROCEEDINGS{10859640,
  author={Bao, Ailisi and Wei, Tianyi},
  booktitle={2024 IEEE 4th International Conference on Data Science and Computer Application (ICDSCA)}, 
  title={3D X-ray Image Reconstruction Based on Collaborative Neural Radiance Field and Ensemble Learning}, 
  year={2024},
  volume={},
  number={},
  pages={677-683},
  abstract={This research examines the utilization of an integrated learner model that combines Generative Adversarial Network (GAN) and Neural Radiation Field (NeRF) for image reconstruction. The advancement of deep learning technology has led to significant progress in image reconstruction, particularly in addressing conventional issues such as image blurring, noise interference, and high computational demands. This work presents a model that integrates GRAF (Generated Radiation Field) with a unified learner designed to deduce anatomical 3D structures from a limited number or a single observation of X-rays. The model is trained using three distinct configurations of GAN models to enhance its stability and performance. In a generative adversarial network, the generator (G) strives to make counterfeit data that is indistinguishable from authentic data, whereas the discriminator (D) endeavors to differentiate between the genuine data and the counterfeit data generated by G. Through this adversarial training technique, the two entities iteratively co-evolve during the game to enhance model performance. The experimental results indicate that the model attains a peak signal-to-noise ratio (PSNR) of 35.01 and a structural similarity index (SSIM) of 0.928, demonstrating superior image quality and enhanced structural similarity. This research examines the model's potential and limitations in addressing the characteristics and issues of imaging data.},
  keywords={Image quality;Solid modeling;Adaptation models;Three-dimensional displays;PSNR;Computational modeling;Noise;Generative adversarial networks;Data models;Image reconstruction;3D image reconstruction;NeRF;ensemble learning;GAN},
  doi={10.1109/ICDSCA63855.2024.10859640},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10810553,
  author={Wangwiwattana, Chatchai and Jantarick, Worawut},
  booktitle={2024 8th International Conference on Information Technology (InCIT)}, 
  title={Building Intelligent Academic Service Agents: FAQ Extraction and Chatbots With Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={370-375},
  abstract={This study proposes an academic chatbot system utilizing large language models (LLMs) to assist students with university-related tasks. The system is designed to simplify the maintenance of school information by extracting FAQs directly from instant messaging platforms. To ensure safety and reliability, the system incorporates a two-step filtering process. In this study, 300 real-world conversations were analyzed, resulting in the extraction of 95 registrar-related Q&A pairs that were subsequently trained into the system. The system’s performance was evaluated based on three key metrics: context relevance, answer relevance, and groundedness. The results demonstrated high satisfaction levels, with scores of 0.94, 0.93, and 0.92, respectively.},
  keywords={Measurement;Large language models;Customer services;Education;Oral communication;Instant messaging;Chatbots;Safety;Maintenance;Information technology;Large Language Models (LLMs);education;chatbot},
  doi={10.1109/InCIT63192.2024.10810553},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10989036,
  author={Ji, Suhwan and Lee, Sanghwa and Lee, Changsup and Han, Yo-Sub and Im, Hyeonseung},
  booktitle={2025 IEEE Conference on Software Testing, Verification and Validation (ICST)}, 
  title={Impact of Large Language Models of Code on Fault Localization}, 
  year={2025},
  volume={},
  number={},
  pages={302-313},
  abstract={Identifying the point of error is imperative in software debugging. Traditional fault localization (FL) techniques rely on executing the program and using the code coverage matrix in tandem with test case results to calculate a suspiciousness score for each method or line. Recently, learning-based FL techniques have harnessed machine learning models to extract meaningful features from the code coverage matrix and improve FL performance. These techniques, however, require compilable source code, existing test cases, and specialized tools for generating the code coverage matrix for each programming language of interest. In this paper, we propose, for the first time, a simple but effective sequence generation approach for fine-tuning large language models of code (LLMCs) for FL tasks. LLMCs have recently received much attention for various software engineering problems. In line with these, we leverage the innate understanding of code that LLMCs have acquired through pre-training on large code corpora. Specifically, we fine-tune 13 representative encoder, encoder-decoder, and decoder-based LLMCs (across 7 different architectures) for FL tasks. Unlike previous approaches, LLM Cs can analyze code sequences that do not compile. Still, they have a limitation on the length of the input data. Therefore, for a fair comparison with existing FL techniques, we extract methods with errors from the project-level benchmark, Defects4J, and analyze them at the line level. Experimental results show that LLMCs fine-tuned with our approach successfully pinpoint error positions in 50.6%, 64.2%, and 72.3% of 1,291 methods in Defects4J for Top-1/3/5 prediction, outperforming the best learning-based state-of-the-art technique by up to 1.35, 1.12, and 1.08 times, respectively. We also conduct an in-depth investigation of key factors that may affect the FL performance of LLMCs. Our findings suggest promising research directions for FL and automated program repair tasks using LLMCs.},
  keywords={Location awareness;Software testing;Codes;Large language models;Source coding;Computer architecture;Benchmark testing;Feature extraction;Software debugging;Software engineering;Fault Localization;Vulnerability Detection;Large Language Model of Code;Fine-Tuning;Deep Learning},
  doi={10.1109/ICST62969.2025.10989036},
  ISSN={2159-4848},
  month={March},}@ARTICLE{10918845,
  author={Li, Haoyang and Wang, Zan and Liang, Wei and Wang, Yizhuo},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={X's Day: Personality-Driven Virtual Human Behavior Generation}, 
  year={2025},
  volume={31},
  number={5},
  pages={3514-3524},
  abstract={Developing convincing and realistic virtual human behavior is essential for enhancing user experiences in virtual reality (VR) and augmented reality (AR) settings. This paper introduces a novel task focused on generating long-term behaviors for virtual agents, guided by specific personality traits and contextual elements within 3D environments. We present a comprehensive framework capable of autonomously producing daily activities autoregressively. By modeling the intricate connections between personality characteristics and observable activities, we establish a hierarchical structure of Needs, Task, and Activity levels. Integrating a Behavior Planner and a World State module allows for the dynamic sampling of behaviors using large language models (LLMs), ensuring that generated activities remain relevant and responsive to environmental changes. Extensive experiments validate the effectiveness and adaptability of our approach across diverse scenarios. This research makes a significant contribution to the field by establishing a new paradigm for personalized and context-aware interactions with virtual humans, ultimately enhancing user engagement in immersive applications. Our project website is at: https://behavior.agent-x.cn/.},
  keywords={Behavioral sciences;Three-dimensional displays;Solid modeling;Psychology;Training;Generators;Real-time systems;Multi-agent systems;Decision making;Complexity theory;Personality-driven Behavior;Behavior Generation;Contextual Scene},
  doi={10.1109/TVCG.2025.3549574},
  ISSN={1941-0506},
  month={May},}@INPROCEEDINGS{10703784,
  author={Gudaparthi, Hemanth and Niu, Nan and Zhang, Jianzhang and Savolainen, Juha},
  booktitle={2024 IEEE International Conference on Information Reuse and Integration for Data Science (IRI)}, 
  title={Applying Cluster Hypothesis to the Next Release Problem}, 
  year={2024},
  volume={},
  number={},
  pages={258-263},
  abstract={The aim of the next release problem (NRP) is to decide the most suitable subset of candidate requirements to include in the software system’s upcoming version. To advance the automation degree of contemporary NRP solutions, we investigate in this paper the cluster hypothesis where we balance the to-be-released candidates with the already implemented features. Clustering the balanced set gives rise to a fully automatic NRP solution, using only the features’ natural language descriptions and a project’s release history. Our experiments on a total of $\mathbf{1, 2 9 6}$ requirements from four real-world systems’ 78 NRP instances show that å k-means best fulfills the cluster hypothesis, and also outperforms the zero-shot learning capability of large language models (LLMs) in solving the NRP.},
  keywords={Automation;Large language models;Zero shot learning;Natural languages;Data science;Software;Data models;Rough surfaces;History;strategic release planning;requirements prioritization;machine learning;large language models},
  doi={10.1109/IRI62200.2024.00060},
  ISSN={2835-5776},
  month={Aug},}@ARTICLE{10902362,
  author={Fidelangeli, Alessia and Galli, Federico and Loreggia, Andrea and Pisano, Giuseppe and Rovatti, Riccardo and Santin, Piera and Sartor, Giovanni},
  journal={IEEE Access}, 
  title={The Summarization of Italian Tax-Law Decisions: The Case of the PRODIGIT Project}, 
  year={2025},
  volume={13},
  number={},
  pages={38833-38855},
  abstract={This paper presents an innovative approach to the automated summarization of tax-law decisions developed within the PRODIGIT project. The work addresses the growing challenge of managing large volumes of judicial rulings, which often hinder access to relevant legal precedents. We introduce a hybrid methodology that combines extractive and abstractive summarization techniques, with a particular emphasis on the application of large language models (LLMs) for abstractive summarization. Our approach includes designing and evaluating various prompt-based configurations, leading to the development of a “combined summarization” method, where distinct summary components are generated and integrated into a cohesive text. Experimental results, validated by tax law experts, demonstrate that this method yields the most comprehensive and accurate summaries. Additionally, we explore the integration of these summaries into semantic search functions, enabling users to retrieve and comprehend relevant case law efficiently. Our findings highlight the potential of AI-driven summarization tools to enhance legal transparency, promote judicial consistency, and support the work of judges, lawyers, and legal scholars.},
  keywords={Law;Finance;Large language models;Hands;Databases;Europe;Text summarization;Prototypes;Natural language processing;Informatics;Tax law;artificial intelligence;abstractive summarization;extractive summarization;large language models},
  doi={10.1109/ACCESS.2025.3545419},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11014940,
  author={Duarte, Carlos Eduardo},
  booktitle={2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Automated Microservice Pattern Instance Detection Using Infrastructure-as-Code Artifacts and Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={161-166},
  abstract={Documenting software architecture is essential to preserve architecture knowledge, even though it is frequently costly. Architecture pattern instances, including microservice pattern instances, provide important structural software information. Practitioners should document this information to prevent knowledge vaporization. However, architecture patterns may not be detectable by analyzing source code artifacts, requiring the analysis of other types of artifacts. Moreover, many existing pattern detection instance approaches are complex to extend. This article presents our ongoing PhD research, early experiments, and a prototype for a tool we call MicroPAD for automating the detection of microservice pattern instances. The prototype uses Large Language Models (LLMs) to analyze Infrastructure-as-Code (IaC) artifacts to aid detection, aiming to keep costs low and maximize the scope of detectable patterns. Early experiments ran the prototype thrice in 22 GitHub projects. We verified that 83% of the patterns that the prototype identified were in the project. The costs of detecting the pattern instances were minimal. These results indicate that the approach is likely viable and, by lowering the entry barrier to automating pattern instance detection, could help democratize developer access to this category of architecture knowledge. Finally, we present our overall research methodology, planned future work, and an overview of MicroPAD's potential industrial impact.},
  keywords={Costs;Software architecture;Large language models;Source coding;Microservice architectures;Prototypes;Computer architecture;Software;Knowledge management;Software development management;software architecture;architecture patterns;architecture documentation;pattern identification;knowledge retrieval;microservices;microservice patterns},
  doi={10.1109/ICSA-C65153.2025.00030},
  ISSN={2768-4288},
  month={March},}@INPROCEEDINGS{10956736,
  author={Arista, Artika and Shuib, Liyana and Ismail, Maizatul Akmar},
  booktitle={2024 International Conference on Informatics, Multimedia, Cyber and Information System (ICIMCIS)}, 
  title={Systematic Literature Review and Bibliometric Analysis on Ethical Policies for Generative Artificial Intelligence (GAI) in Higher Education Institutions (HEIs)}, 
  year={2024},
  volume={},
  number={},
  pages={454-459},
  abstract={Generative Artificial Intelligence (GAI) has revolutionized higher education with features like instant feedback, resource and material creation, adaptive learning, interactivity, and more. However, GAI also brings with it a number of serious challenges that raise ethical and moral concerns regarding academic integrity. To carry out this transition process, it will be necessary to develop clear guidelines that adhere to integrity standards and ethical codes of higher education institutions. In addition to offering responses to a number of research questions, the purpose of this study is to further the current discourse surrounding the moral guidelines for GAI in higher education. Using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) technique and Bibliometric Analysis using VOSviewer, 37 related research studies were reviewed and evaluated. The results demonstrate that the number of articles published has been increasing over time, with the largest number of scientific publications occurring in 2024. This can be explained by the fact that, despite the fact that GAI offers benefits and drawbacks for the educational sector, particularly for higher education, it also makes clear how important it is for professionals and organizations to use GAI tools in order to handle ethical issues by continuously developing policies. By creating norms and policies, future ethical problems with GAI in education may be more accurately predicted. The engagement and dedication of academic experts and other relevant stakeholders are essential to achieving this goal of increasing public awareness and effectively utilizing GAI technology.},
  keywords={Ethics;Generative AI;Education;Bibliometrics;Standards organizations;Organizations;Multimedia databases;Stakeholders;Systematic literature review;Guidelines;Systematic Literature Review;Bibliometric Analysis;Ethical Policies;Generative Artificial Intelligence (GAI);Higher Education Institutions (HEIs)},
  doi={10.1109/ICIMCIS63449.2024.10956736},
  ISSN={2837-5203},
  month={Nov},}@INPROCEEDINGS{10607286,
  author={Chen, Chiung-Hui},
  booktitle={2024 9th International Conference on Big Data Analytics (ICBDA)}, 
  title={Web3.0 Generative Art- A Co-Creation System in Environmental Sustainability Concept Form}, 
  year={2024},
  volume={},
  number={},
  pages={264-269},
  abstract={In 2021, the first year of Metaverse, Web3.0 ecosystems emerged as a result of the Internet's de-centralized evolution. In the Web3.0 space, there has been a very active advancement of the generative art non-fungible token, which is a special asset stored on a blockchain that allows creators to buy and sell assets and verify ownership. In other words, as it reconstructs the interpersonal relationship, the generative art non-fungible token must carry cultural values to be meaningful, and waiting to observe artificial intelligence generative art in the future requires a new mindset and posture. Design thinking is a design-based approach to solve today's complex problems. This study thus addresses the new Web3.0 ecosystem and introduces environmental sustain ability issues and computational thinking in the form of generative art to discuss the possibilities of future design thinking. By linking with social information, this study also creates an intersection with heterogeneous knowledge and stimulates a new thinking pattern that is different from previous ones. This project of design and research in the Metaverse virtual environment is still a novel topic. Reviewing past literature indicates that relevant papers are very scarce, and more resources are urgently needed for research in this field.},
  keywords={Art;Metaverse;Ecosystems;Green products;Big Data;Internet;Nonfungible tokens;blockchain;Web3.0;generative art;collaboration;sustainability},
  doi={10.1109/ICBDA61153.2024.10607286},
  ISSN={},
  month={March},}@INPROCEEDINGS{10500608,
  author={Montezuma, Julio Ricardo Martinez and Chong, Mario},
  booktitle={2024 IEEE World Engineering Education Conference (EDUNINE)}, 
  title={Generative Artificial Intelligence Impact on Education and Industry: An Ethical Dimension}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={This research stresses the importance of ethics in addressing ethical challenges and serving as a crucial guide in industry and education. It is recommended that organizations integrate ethical principles into their guiding documents and encourage ethical reflection among students. Ethics plays a crucial role in the generative artificial intelligence (GAI) responsible application for the benefit of society. The ethics use is essential in weighing up GAI's strengths and weaknesses.},
  keywords={Industries;Training;Ethics;Technological innovation;Generative AI;Education;Collaboration;Generative Artificial Intelligence;Ethics in Technology;Educational Innovation;Industrial Automation;Ethical Challenges},
  doi={10.1109/EDUNINE60625.2024.10500608},
  ISSN={},
  month={March},}@INPROCEEDINGS{10359304,
  author={Viet, Tung Do and Markov, Konstantin},
  booktitle={2023 12th International Conference on Awareness Science and Technology (iCAST)}, 
  title={Using Large Language Models for Bug Localization and Fixing}, 
  year={2023},
  volume={},
  number={},
  pages={192-197},
  abstract={As part of their learning journey, students frequently encounter challenges and make errors, especially with algorithmic programming questions. Regrettably, providing tailored solutions for these mistakes can impose a significant burden on instructors in terms of time and effort. To address this, automated program repair (APR) techniques have been explored to generate such fixes automatically. Previous research has investigated the use of symbolic and neural approaches for APR in the educational domain. However, both types of approaches necessitate substantial engineering endeavors or extensive data and training. In this study, we propose the utilization of a large language model trained on code to construct an APR system specifically designed for student programs. Our system has the capability to rectify semantic errors by employing a few-shot example generation pipeline solely based on the input code. We assess the performance of our system on one dataset of algorithm implementations, namely QuixBugs. The results demonstrate that the novel example generation pipeline not only enhances the overall system’s performance but also ensures its stability.},
  keywords={Location awareness;Training;Codes;Computer bugs;Semantics;Pipelines;Maintenance engineering;bug localization;bug fixing;program repair;large language model;few-shot prompting;in-context learning},
  doi={10.1109/iCAST57874.2023.10359304},
  ISSN={2325-5994},
  month={Nov},}@INPROCEEDINGS{10652301,
  author={U, Dharaneswaran S and T, Jaswanth Reddy and S, Julius Fusic and M, Balamurali and H, Hemraj N},
  booktitle={2024 IEEE Students Conference on Engineering and Systems (SCES)}, 
  title={Optimizing Drone Construction: Topology Optimization and Generative Design}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study investigates and compares the efficacy of two cutting-edge design methodologies, namely topology optimization and generative design, in the context of optimizing drone construction. Drones play a pivotal role in numerous industries, and enhancing their design efficiency is crucial for improved performance and functionality. The research focuses on evaluating the advantages, limitations, and implications of these methodologies with respect to design complexity, manufacturability, and overall performance. The findings provide valuable insights for engineers seeking optimal solutions in the construction of drones. The proposed work provides a comparative assessment of topology optimization and generative design methodologies in the field of drone designing. By thoroughly exploring the comparative assessment of topology optimization and generative design, this study aims to provide engineers with a roadmap for making informed decisions in the design and construction of efficient and high-performance drones.},
  keywords={Industries;Design methodology;Topology;Complexity theory;Optimization;Drones;boundary conditions;topology optimization;generative design;base design;structural analysis},
  doi={10.1109/SCES61914.2024.10652301},
  ISSN={},
  month={June},}@ARTICLE{10403908,
  author={Ozkan-Okay, Merve and Akin, Erdal and Aslan, ÖMER and Kosunalp, Selahattin and Iliev, Teodor and Stoyanov, Ivaylo and Beloev, Ivan},
  journal={IEEE Access}, 
  title={A Comprehensive Survey: Evaluating the Efficiency of Artificial Intelligence and Machine Learning Techniques on Cyber Security Solutions}, 
  year={2024},
  volume={12},
  number={},
  pages={12229-12256},
  abstract={Given the continually rising frequency of cyberattacks, the adoption of artificial intelligence methods, particularly Machine Learning (ML), Deep Learning (DL), and Reinforcement Learning (RL), has become essential in the realm of cybersecurity. These techniques have proven to be effective in detecting and mitigating cyberattacks, which can cause significant harm to individuals, organizations, and even countries. Machine learning algorithms use statistical methods to identify patterns and anomalies in large datasets, enabling security analysts to detect previously unknown threats. Deep learning, a subfield of ML, has shown great potential in improving the accuracy and efficiency of cybersecurity systems, particularly in image and speech recognition. On the other hand, RL is again a subfield of machine learning that trains algorithms to learn through trial and error, making it particularly effective in dynamic environments. We also evaluated the usage of ChatGPT-like AI tools in cyber-related problem domains on both sides, positive and negative. This article provides an overview of how ML, DL, and RL are applied in cybersecurity, including their usage in malware detection, intrusion detection, vulnerability assessment, and other areas. The paper also specifies several research questions to provide a more comprehensive framework to investigate the efficiency of AI and ML models in the cybersecurity domain. The state-of-the-art studies using ML, DL, and RL models are evaluated in each Section based on the main idea, techniques, and important findings. It also discusses these techniques’ challenges and limitations, including data quality, interpretability, and adversarial attacks. Overall, the use of ML, DL, and RL in cybersecurity holds great promise for improving the effectiveness of security systems and enhancing our ability to protect against cyberattacks. Therefore, it is essential to continue developing and refining these techniques to address the ever-evolving nature of cyber threats. Besides, some promising solutions that rely on machine learning, deep learning, and reinforcement learning are susceptible to adversarial attacks, underscoring the importance of factoring in this vulnerability when devising countermeasures against sophisticated cyber threats. We also concluded that ChatGPT can be a valuable tool for cybersecurity, but it should be noted that ChatGPT-like tools can also be manipulated to threaten the integrity, confidentiality, and availability of data.},
  keywords={Computer security;Deep learning;Security;Fraud;Prediction algorithms;Telecommunication traffic;Reinforcement learning;Machine learning;Artificial intelligence;Cyberattacks and solutions;deep learning;machine learning;reinforcement learning;AI tools},
  doi={10.1109/ACCESS.2024.3355547},
  ISSN={2169-3536},
  month={},}@ARTICLE{10310078,
  author={Ren, Xiongfei and Tong, Lili and Zeng, Jia and Zhang, Chen},
  journal={China Communications}, 
  title={AIGC scenario analysis and research on technology roadmap of Internet industry application}, 
  year={2023},
  volume={20},
  number={10},
  pages={292-304},
  abstract={The explosion of ChatGPT is considered to be a milestone in the normalization of artificial intelligence education applications. On the technical line, the cross-modal AI generation application based on human feedback system is accelerated. In the business model, the scenes to realize interactive functions are constantly enriched. This paper reviews the evolution process of AIGC, closely follows the current situation of the coexistence of business acceleration and technical worries in the application of artificial intelligence education, analyzes the application of AIGC education in 7 subdivided fields, and analyzes the optimization direction of application cases from the perspective of perception-cognition-creation technology maturity matrix. The 3 recommendations and 2 follow-up research directions will promote the scientific application of artificial intelligence education in the AIGC period.},
  keywords={Education;Artificial intelligence;Biological system modeling;Chatbots;Computational modeling;Production;Data models;AIGC;artificial intelligence education application;large model},
  doi={10.23919/JCC.fa.2023-0359.202310},
  ISSN={1673-5447},
  month={Oct},}@INPROCEEDINGS{10345786,
  author={Vazquez, Hernan C. and Diaz-Pace, J. Andres and Tommasel, Antonela},
  booktitle={2023 XLIX Latin American Computer Conference (CLEI)}, 
  title={The JavaScript Package Selection Task: A Comparative Experiment Using ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={When developing Java Script (JS) applications, the assessment and selection of JS packages have become challenging for developers due to the growing number of technology options available. Given a technology need, a common developers' strat-egy is to query Web repositories via search engines (e.g., NPM, Google) and shortlist candidate JS packages. However, these engines might return a long list of results. Furthermore, these results should be ranked according to the developer's criteria. To address these problems, we developed a recommender system called AIDT that assists developers in the package selection task. AIDT relies on meta-search and machine learning techniques to infer the relevant packages for a query. An initial evaluation of AIDT showed good search effectiveness. Recently, the emergence of ChatGPT has opened new opportunities for this kind of assistants, as reported by some experiments. Anyway, human developers should judge whether the recommendations (e.g., JS packages) of these tools are fit to purpose. In this paper, we report on a user study in which we used both AIDT and ChatGPT on a sample of JS-related queries, compared their results, and also validated them against developers' criteria and expectations for the task. Our initial findings show that ChatGPT is not yet on par with AIDT or even human efforts for the task at hand, but the model is flexible to be improved and furthermore, it can provide good arguments for its package choices.},
  keywords={Computational modeling;Machine learning;Search engines;Predictive models;Chatbots;Internet;Metasearch;Package Selection;JavaScript;Recommender System;GPT Model;User Study},
  doi={10.1109/CLEI60451.2023.10345786},
  ISSN={2771-5752},
  month={Oct},}@INPROCEEDINGS{10734659,
  author={Pister, Kaiser and Paul, Dhruba Jyoti and Brophy, Patrick and Joshi, Ishan},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={PromptSet: A Programmer’s Prompting Dataset}, 
  year={2024},
  volume={},
  number={},
  pages={62-69},
  abstract={The rise of capabilities expressed by large language models has been quickly followed by the integration of the same complex systems into application level logic. Algorithms, programs, systems, and companies are built around structured prompting to black box models where the majority of the design and implementation lies in capturing and quantifying the ‘agent mode’. The standard way to shape a closed language model is to prime it for a specific task with a tailored prompt, often initially handwritten by a human. The textual prompts co-evolve with the codebase, taking shape over the course of project life as artifacts which must be reviewed and maintained, just as the traditional code files might be. Unlike traditional code, we find that prompts do not receive effective static testing and linting to prevent runtime issues. In this work, we present a novel dataset called PromptSet, with more than 61,000 unique developer prompts used in open source Python programs. We perform analysis on this dataset and introduce the notion of a static linter for prompts. Released with this publication is a HuggingFace dataset and a Github repository to recreate collection and processing efforts, both under the name pisterlabs/promptset.CCS CONCEPTS• Computing methodologies → Natural language generation.},
  keywords={Codes;Runtime;Shape;Large language models;Natural language generation;Logic;Standards;Testing;Software development management;Python;Prompt Management;Large Language Models;Dataset;Information systems;Ethnography;Taxonomy},
  doi={},
  ISSN={},
  month={April},}@ARTICLE{10981607,
  author={Zhu, Hancheng and Shi, Ju and Shao, Zhiwen and Yao, Rui and Sun, Kunyang and Li, Leida},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Progressively Generated Text-Assisted Image Aesthetic Quality Assessment}, 
  year={2025},
  volume={},
  number={},
  pages={1-13},
  abstract={Image Aesthetic Quality Assessment (IAQA) aims to simulate user perceptions to judge the aesthetic quality of images. Due to the high subjectivity of users and the complexity of image aesthetics, modeling IAQA solely at the image level is a compromise. Consequently, existing methods mainly focus on multimodal-based models and achieve effective performance. These methods explore aesthetic comments on images to characterize users and serve as auxiliary text information for multimodal modeling. Unfortunately, this may suffer from two limitations. One limitation is that aesthetic comments are often unavailable for an unknown image in the test phase, and another limitation is that the semantic information of these comments may be uncertain and fuzzy. Therefore, this paper proposes a progressively generated text-assisted image aesthetic quality assessment method, aiming to address the lack of aesthetic comments and the fuzziness of aesthetic judgments in these comments. Specifically, we first adopt a Multimodal Large Language Model (MLLM) to generate aesthetic comments on images by simulating user perceptions and utilize the generated comments to characterize their aesthetic perception to assist in the pre-training of our multimodal-based IAQA model. Then, we design an attribute prediction module to determine the attribute levels of aesthetic judgments and utilize text template construction to further generate explicit descriptions of image aesthetics. Finally, we leverage the generated attribute descriptions to further assist in training our IAQA model. By progressively generating textual auxiliary descriptions of aesthetics for images, the proposed model can gradually determine the aesthetic quality of the images. Massive experimental results indicate that the proposed method outperforms existing mainstream methods on multiple IAQA datasets.},
  keywords={Training;Quality assessment;Image color analysis;Feature extraction;Semantics;Social networking (online);Lighting;Visualization;Deep learning;Adaptation models;Aesthetic quality assessment;attribute prediction;fuzzy description;multimodal modeling;progressively generated text},
  doi={10.1109/TFUZZ.2025.3566145},
  ISSN={1941-0034},
  month={},}@ARTICLE{11027910,
  author={Ye, Fei and Bors, Adrian G.},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Training a Dynamic Growing Mixture Model for Lifelong Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={Lifelong learning (LLL) defines a training paradigm that aims to continuously acquire and capture new concepts from a sequence of tasks without forgetting. Recently, dynamic expansion models (DEMs) have been proposed to address catastrophic forgetting under the LLL paradigm. However, the efficiency of DEMs lacks a thorough explanation based on theoretical analysis. In this article, we develop a new theoretical framework that interprets the forgetting process of the DEM as increasing the statistical discrepancy distance between the distribution of the probabilistic representation of the new data and the previously learned knowledge. The theoretical analysis shows that adding new components to a mixture model represents a trade-off between model complexity and its performance. Inspired by the theoretical analysis, we introduce a new DEM, called the growing mixture model (GMM), where generative data components are added according to the novelty of the incoming task information compared to what is already known. A new component selection mechanism considering the model’s already acquired knowledge is employed for updating new DEM’s components, promoting efficient future task learning. We also train a compact student model with samples drawn through the generative mechanisms of the GMM, aiming to accumulate cross-domain representations over time. By employing the student model, we can significantly reduce the number of parameters and make quick inferences during the testing phase.},
  keywords={Data models;Continuing education;Training;Mixture models;Generative adversarial networks;Analytical models;Adaptation models;Linear programming;Computational modeling;Testing;Continual learning;dynamic expansion model (DEM);lifelong generative modeling;lifelong learning (LLL)},
  doi={10.1109/TNNLS.2025.3569156},
  ISSN={2162-2388},
  month={},}@INPROCEEDINGS{10689798,
  author={Singh, Gulbir and Srivastava, Vivek and Kumar, Suneet and Bhatnagar, Vivek and Dhondiyal, Shiv Ashish},
  booktitle={2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC)}, 
  title={Understanding the Ethical Implications of Generative AI: A Multi-Disciplinary Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1714-1719},
  abstract={The capacity of generative Artificial Intelligence (AI) to develop material such as writing, graphics, and music is one of its defining characteristics. Generative AI has applications in a broad variety of fields, including but not limited to the following: art, literature, software development, education, product design, healthcare, finance, gaming, entertainment, and many more. From the viewpoint of many disciplines, this research study presents the implications of generative AI, considering the technical, educational, legal, and social aspects of the area. By combining concepts from various domains, this article aims to present a comprehensive understanding of the ethical concerns posed by generative AI. Additionally, the research will provide viable frameworks for resolving these issues.},
  keywords={Ethics;Art;Generative AI;Law;Reviews;Education;Oral communication;Product design;Creativity;Software development management;Generative AI;Artificial Intelligence;Ethics;Machine Learning},
  doi={10.1109/ICESC60852.2024.10689798},
  ISSN={2996-5357},
  month={Aug},}@ARTICLE{11017583,
  author={Rahimi, Fatema and Sadeghi-Niaraki, Abolghasem and Choi, Soo-Mi},
  journal={IEEE Access}, 
  title={Generative AI Meets Virtual Reality: A Comprehensive Survey on Applications, Challenges, and Future Direction}, 
  year={2025},
  volume={13},
  number={},
  pages={94893-94909},
  abstract={The integration of generative artificial intelligence (AI) with virtual reality (VR) is reshaping how immersive environments are designed, personalized, and experienced. Unlike traditional VR systems that rely on static and pre-scripted content, Generative VR leverages AI-driven content generation, multimodal interaction, and contextual adaptation to create dynamic virtual spaces. This paper presents a comprehensive survey of the core components, applications, and challenges associated with Generative VR. It explores its transformative impact across education, healthcare, industrial training, entertainment, and emerging fields such as environmental conservation and virtual tourism. While Generative VR enhances user engagement and realism, it also introduces critical challenges, including computational scalability, ethical concerns, AI explainability, and real-time performance constraints. The paper further identifies key research gaps and future directions, such as AI-driven multi-user collaboration, cognitive load management, and cross-domain interoperability. By addressing these challenges and advancing the integration of AI with VR, Generative VR has the potential to reshape human-computer interaction, unlocking new possibilities for creativity, accessibility, and intelligent virtual ecosystems.},
  keywords={Generative AI;Artificial intelligence;Virtual reality;Three-dimensional displays;Real-time systems;Scalability;Ethics;Bibliometrics;Technological innovation;Surveys;Generative AI;virtual reality;generative VR},
  doi={10.1109/ACCESS.2025.3574779},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10581306,
  author={Aamana and Ain, Qurat Ul and Nisa, Sardar Un},
  booktitle={2024 International Conference on Engineering & Computing Technologies (ICECT)}, 
  title={Beyond Agile: NLP-Driven Quality Attributes Retrieval Using ChatGPT in Software Development Strategies}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study explores Agile Software Development (ASD) methodologies' effectiveness in achieving quality software products. It investigates the underexplored application of ChatGPT as a Quality Attribute Extractor in ASD. Utilizing hard prompt techniques, ChatGPT extracts quality attributes from user stories without fine-tuning, enhancing understanding through few-shot and zero-shot Prompt Engineering. This innovative approach bridges NLP advancements with agile methodologies, facilitating efficient quality assessment in software development processes.},
  keywords={Natural languages;Decision making;Agile software development;Software quality;Chatbots;Software systems;Quality assessment;Quality Attributes;User Stories;Natural Language Processing (NLP);ChatGPT;Software Development Strategies;Prompt-based Techniques;Agile Software Development},
  doi={10.1109/ICECT61618.2024.10581306},
  ISSN={},
  month={May},}@ARTICLE{11027082,
  author={Zhang, Ye and Gao, Qing and Hu, Rong and Ding, Qingtang and Li, Boyang and Guo, Yulan},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Differentiable Prior-Driven Data Augmentation for Sensor-Based Human Activity Recognition}, 
  year={2025},
  volume={},
  number={},
  pages={1-13},
  abstract={Sensor-based human activity recognition (HAR) usually suffers from the problem of insufficient annotated data, due to the difficulty in labeling the intuitive signals of wearable sensors. To this end, recent advances have adopted handcrafted operations or generative models for data augmentation. The handcrafted operations are driven by some physical priors of human activities, e.g., action distortion and strength fluctuations. However, these approaches may face challenges in maintaining semantic data properties. Although the generative models have better data adaptability, it is difficult for them to incorporate important action priors into data generation. This article proposes a differentiable prior-driven data augmentation framework for HAR. First, we embed the handcrafted augmentation operations into a differentiable module, which adaptively selects and optimizes the operations to be combined together. Then, we construct a generative module to add controllable perturbations to the data derived by the handcrafted operations and further improve the diversity of data augmentation. By integrating the handcrafted operation module and the generative module into one learnable framework, the generalization performance of the recognition models is enhanced effectively. Extensive experimental results with three different classifiers on five public datasets demonstrate the effectiveness of the proposed framework. Project page: https://github.com/crocodilegogogo/DriveData-Under-Review.},
  keywords={Human activity recognition;Data augmentation;Data models;Adaptation models;Data collection;Noise;Training;Generative adversarial networks;Semantics;Solid modeling;Differentiable framework;generative models;handcrafted operations;prior-driven data augmentation;sensor-based human activity recognition (HAR)},
  doi={10.1109/TCSS.2025.3565414},
  ISSN={2329-924X},
  month={},}@INPROCEEDINGS{11013092,
  author={Abdel-Rahem, Rami A. and Hadi, Wael and Al-Remawi, Mayyas and Aburub, Faisal and Jamal, Naser},
  booktitle={2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA)}, 
  title={A Survey on Some Artificial Intelligence Learning Tools at the University of Petra}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This research explores the perspectives of 105 instructors from the University of Petra (UOP), specifically from the Faculties of Arts and Science (FAS) and Information Technology (FIT), regarding personalized learning (PL) and generative artificial intelligence (GAI) tools. The study examines instructors' views on the theoretical foundations of these technologies, their perceived need for training in the use of such tools, and their opinions on the benefits of PL in education. The primary objective is to gain insights into faculty members' attitudes toward integrating AI tools into the educational process at UOP. The findings from this survey are expected to inform strategies for enhancing AI adoption in education at UOP and other institutions. This investigation will aid the university in preparing for the emerging era of AI-driven education.},
  keywords={Training;Surveys;Technological innovation;Generative AI;Learning (artificial intelligence);Artificial intelligence;Information technology;Stress;Computational intelligence;Best practices;Artificial Intelligence;Personalized Learning;Generative AI;University of Petra;Instructors Training},
  doi={10.1109/ICCIAA65327.2025.11013092},
  ISSN={},
  month={April},}@INPROCEEDINGS{10435553,
  author={Wang, Hongchang and Ma, Qingxin},
  booktitle={2023 3rd International Conference on Electronic Information Engineering and Computer Science (EIECS)}, 
  title={Domain Knowledge Enhanced BERT for Chinese Named Entity Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={406-409},
  abstract={Digitalization of educational resources and revolutionizing knowledge frameworks are essential in achieving smart education. Knowledge graphs play a pivotal role in addressing knowledge representation, correlation, and sharing within digital education. Named Entity Recognition (NER) is a fundamental task in constructing knowledge graphs. This study introduces a Domain Knowledge-Enhanced BERT Chinese NER model, DK-BERT-CRF (Domain Knowledge BERT CRF), to address the deficiency of lexical information features within the Chinese NER task using the BERT pre-trained model. To construct an automated labeling dataset, we perform an automated labeling dataset construction based on ChatGPT, focusing on the example of computer science's data structures. We conduct experiments and evaluations using this dataset and the general CLUENER2020 dataset. Comparative experiments with BERT+CRF and BiLSTM+CRF are also conducted. The experimental results demonstrate that the DK-BERT-CRF model, enriched with domain knowledge, exhibits an improved F1 score compared to the other two models. Particularly, the DK-BERT-CRF model showcases enhanced F1 scores on the computer science data structure dataset after the incorporation of domain knowledge.},
  keywords={Computer science;Annotations;Computational modeling;Knowledge graphs;Data structures;Labeling;Task analysis;Smart Education;Knowledge Graph;Named Entity Recognition;BERT;ChatGPT},
  doi={10.1109/EIECS59936.2023.10435553},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10837679,
  author={Ranasinghe, Harshani and Gide, Ergun and ElKhodr, Mahmoud},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={The Significance of GenAI Empowered ERP Systems Course Teaching in Quality Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper aims to analyse the significance of Generative Artificial Intelligence (GenAI) Empowered Enterprise Resource Planning (ERP) systems as a course in higher education. With the advancement of GenAI technology, ERP systems are capable of automating and streamlining business operations across various industries. The usage of ERP systems has become prevalent in small to medium-sized organizations worldwide, akin to the utilization of office packages for day-to-day operations. Therefore, Fundamental knowledge and understanding of GenAI Empowered ERP system concepts is an advantageous skill for undergraduate and graduate students as potential job seekers in various industries.},
  keywords={Training;Industries;Generative AI;Decision making;Customer satisfaction;Curriculum development;Organizations;Enterprise resource planning;Information technology;ERP systems;GenAI;Higher Education;Systematic review;Job market;Quality},
  doi={10.1109/ITHET61869.2024.10837679},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10928044,
  author={Hesham, Alaa and Hamdy, Abeer},
  booktitle={2024 International Conference on Computer and Applications (ICCA)}, 
  title={Fine-Tuning GPT-4o-Mini for Programming Questions Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Creating programming questions that are both meaningful and educationally relevant is a critical task in computer science education. This paper introduces a fine-tuned GPT4o-mini model (C2Q). It is designed to generate meaningful questions by leveraging semantic feature extraction and well- crafted prompts. The approach addresses the limitations of traditional generative models, offering a deeper understanding of programming code and producing questions that are precise, diverse, and relevant to a given code snippets. The proposed framework incorporates essential code elements, such as control structures and method attributes, to generate questions that align with programming concepts. Evaluation metrics used were BLEU, ROUGE-1, and ROUGE-L to evaluate the model's performance. The findings reveal that the model achieves better structural coherence and conceptual relevance while focusing on contextual understanding over exact term matching. This work highlights the potential of the proposed approach to advance teaching and assessment methods in computer science.},
  keywords={Measurement;Codes;Computational modeling;Semantics;Natural language generation;Focusing;Feature extraction;Question generation;Prompt engineering;Programming profession;Generative models;Natural Language Processing;Natural Language Generation;Question generation;Prompt Engineering},
  doi={10.1109/ICCA62237.2024.10928044},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10397753,
  author={Tyagi, Deepanshu and Tanwar, Sarvesh and Mittal, Neetu and Badotra, Sumit},
  booktitle={2023 6th International Conference on Contemporary Computing and Informatics (IC3I)}, 
  title={Analyse and Evaluate Quixbugs with Open AI Codex and Powering Next Generation Application}, 
  year={2023},
  volume={6},
  number={},
  pages={165-170},
  abstract={The paper investigates the ordinary language age limits of massive language models, with applications to the development of two types of learning tools commonly found in programming courses. We construct programming workouts and code explanations, reviewing these abstractly and statistically, using the Open AI Codex as the massive language model. Our findings indicate that the majority of the content so given is both unique and sensible, and that it is occasionally ready to use without any guarantees. While rehearsing, we discovered that it is astonishingly simple to affect both the programming ideas and the practical subjects they include simply by offering expressions of commitment to the model. Findings indicate massively generative computer intelligence models have fundamental value.},
  keywords={Training;Codes;Smoothing methods;Computational modeling;Programming;Artificial intelligence;Robots;GPT-3;Open AI;Codex;Java;Security;Intelligence;Application},
  doi={10.1109/IC3I59117.2023.10397753},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10949557,
  author={Mo, Jiayun and Ann, Ong Chin},
  booktitle={2024 4th International Conference on Robotics, Automation and Artificial Intelligence (RAAI)}, 
  title={Towards Responsible and Ethical AI Chatbot in Education: A Guideline for Developers}, 
  year={2024},
  volume={},
  number={},
  pages={52-58},
  abstract={With the expansion of generative Artificial Intelligence (AI) and the penetration of AI chatbots into every aspect of people's daily lives, discussions and issues related to AI ethics and responsibility began to arise simultaneously. A large portion of AI users remain ignorant of such ethical discussions, while a significant percentage of developers lack precautionary measures to prevent irresponsible AI behaviors. An increasing number of companies and organizations are taking action to address the problems. Despite the efforts, prominent issues still prevail. Most existing solutions are too general and theoretical; few are narrowed down to examine the specific application scenario of AI chatbots in education. In response, this study aims to address the arising concerns and the lack of a satisfying solution. After conducting an extensive literature review and performing a detailed analysis of survey data, this study develops a comprehensive guideline about AI ethics and responsible AI, which specifically targets undergraduate developers and guides them during their development of AI chatbots used in education. This guideline successfully bridges the knowledge gap, raises awareness about AI ethics, and acts as the first guideline for undergraduate students, influencing future development practices.},
  keywords={Surveys;Ethics;Systematics;Generative AI;Educational robots;Education;Chatbots;Artificial intelligence;Guidelines;Systematic literature review;Chatbot Development;Ethical AI Framework;Responsible AI;Digital Trust;Secure Development},
  doi={10.1109/RAAI64504.2024.10949557},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10604584,
  author={Rosales, Shomira and Reátegui, Ruth and Toledo, Charlie Cárdenas},
  booktitle={2023 Fourth International Conference on Information Systems and Software Technologies (ICI2ST)}, 
  title={A Topic Modeling Approach to Analyze Teaching Innovation Projects}, 
  year={2023},
  volume={},
  number={},
  pages={46-53},
  abstract={Topic modeling is a data mining strategy that permit to automatically extract the topics discussed in a given corpus. The objective of this study is to discover the topics that are common in a set of educational innovation projects proposed by university teachers. The LDA algorithm, which is a generative probabilistic model, was used. To identify the correct number of topics the coherence and perplexity metrics were applied. Ten topics were obtained, which, among other aspects, reflect the careers and subjects that work the most in educational innovation projects, as well as the methodologies, strategies and resources that teachers use in their projects.},
  keywords={Measurement;Technological innovation;Vocabulary;Engineering profession;Education;Ontologies;Probabilistic logic;Text mining;topic modeling;LDA;higher-educational institutions},
  doi={10.1109/ICI2ST62251.2023.00014},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10999036,
  author={Sharma, Madhav and Bansal, Payal and Dutta, Ritam and Saini, Hukum Chand and Chaudhary, Shalini and Das, Debmitra},
  booktitle={2nd International Conference on Pervasive Computing Advances and Applications (PerCAA 2024)}, 
  title={Advancements in deep learning: from theory to application using natural language processing}, 
  year={2024},
  volume={2024},
  number={},
  pages={123-128},
  abstract={Deep analyzing has witnessed excellent enhancements in modern-day-day years, mainly in its software program to natural language processing (NLP). This paper offers an entire assessment of the evolution of deep learning strategies, tracing their journey from theoretical foundations to sensible packages in NLP. The theoretical underpinnings of deep getting to know, which incorporates neural network architectures together with convolution neural networks and recurrent neural networks are mentioned, highlighting their capability to capture complicated styles in data. We delve into the stressful conditions faced via manner of conventional NLP techniques and the way deep reading has addressed the ones demanding conditions with the useful resource of allowing greater nuanced records of language via techniques which encompass phrase embeddings and interest mechanisms. Moreover, the paper explores contemporary upgrades in deep studying models tailored specially for NLP obligations, together with transformers and pre-informed language fashions like BERT, GPT, and XLNet. These models have revolutionized the arena through achieving extraordinarily-modern-day regular overall performance throughout severa NLP benchmarks, starting from sentiment assessment and named entity recognition to gadget translation and question answering.},
  keywords={},
  doi={10.1049/icp.2025.0781},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10825682,
  author={Nweke, Francis and Azmee, Abm Adnan and Al Hafiz Khan, Md Abdullah and Pei, Yong and Thomas, Dominic and Nandan, Monica},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Explainable Multi-Label Classification Framework for Behavioral Health Based on Domain Concepts}, 
  year={2024},
  volume={},
  number={},
  pages={6528-6537},
  abstract={Behavioral health, which covers mental health, lifestyle choices, addictions, and crises, poses serious issues in the community. Thus, appropriately analyzing and classifying behavioral health data is crucial for making informed health-care decisions. Traditional deep learning and natural language processing approaches struggle to effectively identify behavioral health issues because the data is unstructured, complex, and lacks sufficient context. Furthermore, subject matter experts must be consulted to ensure effective identification. In this work, we proposed a deep learning-based framework consisting of several modules: A) domain concept encoder converts the keywords and their evidence types to vectors, which were predefined by a subject matter expert; B) the semantic representation encoder (SRE) is trained on the vectors to learn the relationship between them; C) transformed-based feature learner is an advanced learner that extracts feature embeddings from documents and generates attention weights since it has more context given the incorporated relationship weights; D) The behavioral health multilabel classifier utilizes feature embeddings to classify a document into one or more behavioral health classes; and E) The LLM-enabled explainer provides explanations based on attention weights and classifications. Our proposed framework outperformed state-of-the-art models in multilabel behavioral health case classification while also providing explanations for each classification. Which is crucial in behavioral health analysis.},
  keywords={Deep learning;Subject matter experts;Semantics;Multi label classification;Mental health;Medical services;Feature extraction;Vectors;Natural language processing;Data models;explainable model;deep learning;behavioral health},
  doi={10.1109/BigData62323.2024.10825682},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10775064,
  author={Joshi, Atharva and Pede, Shailaja and Kolekar, Prathmesh and Metkar, Aditya},
  booktitle={2024 8th International Conference on Computing, Communication, Control and Automation (ICCUBEA)}, 
  title={Resume Parsing and Skill Extraction using Custom Pattern Matching algorithm and Gemini API}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the realm of contemporary recruitment, efficient resume parsing is essential for talent acquisition. This paper investigates resume parsing using advanced OCR technology and NLP methods. We begin with preprocessing, enhancing scanned resumes for legibility. Leveraging the Tesseract OCR engine, we convert images to machine-readable text. Through NLP techniques with spaCy, we extract key information like personal details, education, experience, and skills.Our approach integrates the Gemini Pro Vision API for semantic analysis and question-answering. This enriches our framework, enabling deeper insights and implicit attribute inference. Empirical validation across diverse datasets demonstrates the robustness of our methodology. This work sheds light on performance metrics and challenges in automated resume parsing, paving the way for future enhancements.},
  keywords={Visualization;Technological innovation;Machine learning algorithms;Resumes;Optical character recognition;Semantics;Robustness;Data mining;Pattern matching;Recruitment;Optical Character Recognition (OCR);Text Detection;Gemini Pro API;Natural Language Processing (NLP);Semantic analysis;spaCy;Tesseract OCR engine;Talent acquisition},
  doi={10.1109/ICCUBEA61740.2024.10775064},
  ISSN={2771-1358},
  month={Aug},}@BOOK{10559429,
  author={Jha, Ashish Ranjan},
  booktitle={Mastering PyTorch: Create and deploy deep learning models from CNNs to multimodal models, LLMs, and beyond},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Master advanced techniques and algorithms for machine learning with PyTorch using real-world examples Updated for PyTorch 2.x, including integration with Hugging Face, mobile deployment, diffusion models, and graph neural networks Purchase of the print or Kindle book includes a free eBook in PDF formatKey FeaturesUnderstand how to use PyTorch to build advanced neural network modelsGet the best from PyTorch by working with Hugging Face, fastai, PyTorch Lightning, PyTorch Geometric, Flask, and DockerUnlock faster training with multiple GPUs and optimize model deployment using efficient inference frameworksBook DescriptionPyTorch is making it easier than ever before for anyone to build deep learning applications. This PyTorch deep learning book will help you uncover expert techniques to get the most out of your data and build complex neural network models. You’ll build convolutional neural networks for image classification and recurrent neural networks and transformers for sentiment analysis. As you advance, you'll apply deep learning across different domains, such as music, text, and image generation, using generative models, including diffusion models. You'll not only build and train your own deep reinforcement learning models in PyTorch but also learn to optimize model training using multiple CPUs, GPUs, and mixed-precision training. You’ll deploy PyTorch models to production, including mobile devices. Finally, you’ll discover the PyTorch ecosystem and its rich set of libraries. These libraries will add another set of tools to your deep learning toolbelt, teaching you how to use fastai to prototype models and PyTorch Lightning to train models. You’ll discover libraries for AutoML and explainable AI (XAI), create recommendation systems, and build language and vision transformers with Hugging Face. By the end of this book, you'll be able to perform complex deep learning tasks using PyTorch to build smart artificial intelligence models.What you will learnImplement text, vision, and music generation models using PyTorchBuild a deep Q-network (DQN) model in PyTorchDeploy PyTorch models on mobile devices (Android and iOS)Become well versed in rapid prototyping using PyTorch with fastaiPerform neural architecture search effectively using AutoMLEasily interpret machine learning models using CaptumDesign ResNets, LSTMs, and graph neural networks (GNNs)Create language and vision transformer models using Hugging FaceWho this book is forThis deep learning with PyTorch book is for data scientists, machine learning engineers, machine learning researchers, and deep learning practitioners looking to implement advanced deep learning models using PyTorch. This book is ideal for those looking to switch from TensorFlow to PyTorch. Working knowledge of deep learning with Python is required.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781801079969},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10559429},}@INPROCEEDINGS{10912174,
  author={Pandey, Tanya and Yadav, Armaan and Sharma, Janvi and Singhal, Shefali},
  booktitle={2024 2nd International Conference on Advances in Computation, Communication and Information Technology (ICAICCIT)}, 
  title={Design based Retrieval Augmented Generation Oriented Education Chatbot: Edubot}, 
  year={2024},
  volume={1},
  number={},
  pages={1278-1283},
  abstract={Chatbot, a system which focuses on utilizing advanced natural language processing (NLP) techniques. This research aims to provide a comprehensive understanding of Chatbot, including its background, evolution and future application, with the focus mainly on its impact on education. The landscape of scientific research has been transformed by artificial intelligence (AI) and machine learning. This research explores OpenAI’s chatbot, which leverages advanced techniques in Natural Language Processing (NLP), Supervised Learning, and Reinforcement Learning to understand and generate text that closely resembles human-written content. As per state-of-art, an interface has been developed along with dataset creation. A small level BOT that would use a self-made database on Pinecone which has been integrated into it. The interface will take the queries from the user and provide a suitable and accurate answer by using the RAG & LLM algorithm.},
  keywords={Technological innovation;Retrieval augmented generation;Education;Supervised learning;Reinforcement learning;Chatbots;User experience;Information and communication technology;Reliability;Testing;Retrieval Augmented Generation (RAG);Hugging face;Pinecone DB;Mistral X86;Natural Language Processing;LLM},
  doi={10.1109/ICAICCIT64383.2024.10912174},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10663002,
  author={Braun, Peter},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={A Method and Software to Create SCORM Units for Computer Science Courses}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={Producing learning videos for flipped classrooms is a time-consuming and manual task. This paper presents a method and software to create SCORM units for computer science courses. The method consists of a common structure for learning videos, a Python script to create SCORM units, and ChatGPT for quiz creation. The software is based on the open-source software FFmpeg for video production. The results after 40 learning units show that producing a learning video can be automated to a great extent.},
  keywords={Computer science;Electronic learning;Education;Production;Manuals;Recording;Online services;flipped classroom;learning units;video production},
  doi={10.1109/CSEET62301.2024.10663002},
  ISSN={2377-570X},
  month={July},}@BOOK{10769232,
  author={Gonzalez, Leondra R. and Baltes, Angela and Stubberfield, Aaren},
  booktitle={Cracking the Data Science Interview: Unlock insider tips from industry experts to master the data science field},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Rise above the competition and excel in your next interview with this one-stop guide to Python, SQL, version control, statistics, machine learning, and much moreKey FeaturesAcquire highly sought-after skills of the trade, including Python, SQL, statistics, and machine learningGain the confidence to explain complex statistical, machine learning, and deep learning theoryExtend your expertise beyond model development with version control, shell scripting, and model deployment fundamentalsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionThe data science job market is saturated with professionals of all backgrounds, including academics, researchers, bootcampers, and Massive Open Online Course (MOOC) graduates. This poses a challenge for companies seeking the best person to fill their roles. At the heart of this selection process is the data science interview, a crucial juncture that determines the best fit for both the candidate and the company. Cracking the Data Science Interview provides expert guidance on approaching the interview process with full preparation and confidence. Starting with an introduction to the modern data science landscape, you’ll find tips on job hunting, resume writing, and creating a top-notch portfolio. You’ll then advance to topics such as Python, SQL databases, Git, and productivity with shell scripting and Bash. Building on this foundation, you'll delve into the fundamentals of statistics, laying the groundwork for pre-modeling concepts, machine learning, deep learning, and generative AI. The book concludes by offering insights into how best to prepare for the intensive data science interview. By the end of this interview guide, you’ll have gained the confidence, business acumen, and technical skills required to distinguish yourself within this competitive landscape and land your next data science job.What you will learnExplore data science trends, job demands, and potential career pathsSecure interviews with industry-standard resume and portfolio tipsPractice data manipulation with Python and SQLLearn about supervised and unsupervised machine learning modelsMaster deep learning components such as backpropagation and activation functionsEnhance your productivity by implementing code versioning through GitStreamline workflows using shell scripting for increased efficiencyWho this book is forWhether you're a seasoned professional who needs to brush up on technical skills or a beginner looking to enter the dynamic data science industry, this book is for you. To get the most out of this book, basic knowledge of Python, SQL, and statistics is necessary. However, anyone familiar with other analytical languages, such as R, will also find value in this resource as it helps you revisit critical data science concepts like SQL, Git, statistics, and deep learning, guiding you to crack through data science interviews.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781805120193},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10769232},}@INPROCEEDINGS{10356369,
  author={Jones, Alyse M. and Johnson, Amos and Headley, William C.},
  booktitle={MILCOM 2023 - 2023 IEEE Military Communications Conference (MILCOM)}, 
  title={Demoing the RFRL Gym: A Reinforcement Learning Testbed for Wireless Communications}, 
  year={2023},
  volume={},
  number={},
  pages={235-236},
  abstract={Radio Frequency Reinforcement Learning (RFRL) is anticipated to be a widely leveraged technology in the next generation of wireless communication systems, particularly 6G systems and next-gen military communications. To support education, research, and innovation in RFRL technologies, an open source simulation and analysis tool specifically for simulating wireless communications applications (both commercial and military) is under development that leverages the well-known OpenAI Gymnasium framework. In this demonstration, the current feature-complete functionalities of the RFRL Gym are showcased, particularly the ability to train and evaluate open-source Gymnasium-compatible RL algorithms against a series of representative user-defined wireless scenarios. In particular, scenarios representing dynamic spectrum access scenarios, as well as jamming/anti-jamming scenarios, will be demoed. Additionally, two simulation modes of the RFRL Gym will be demonstrated, namely a high-level abstracted gamified mode for researchers with minimal background in wireless communications and a low-level expert mode simulating real wireless signals, channels, and sensing for researchers with expertise in wireless communications concepts. The goal of this demonstration is two-fold. First, to showcase and solicit feedback on how RFRL Gym can be helpful to experts in the field to test and evaluate candidate RL algorithms for next-generation wireless systems. Second, to showcase and solicit feedback on how RFRL Gym can be helpful to develop a better understanding of RF and RL concepts for researchers with minimal expertise in the area.},
  keywords={Wireless communication;Military communication;Radio frequency;Wireless sensor networks;Technological innovation;Heuristic algorithms;Reinforcement learning},
  doi={10.1109/MILCOM58377.2023.10356369},
  ISSN={2155-7586},
  month={Oct},}@INBOOK{10952453,
  author={Khan, Rehan and Khan, Shadab Pasha and Ali, Syed Adnan},
  booktitle={Conversational Artificial Intelligence}, 
  title={Conversational AI}, 
  year={2024},
  volume={},
  number={},
  pages={249-268},
  abstract={Summary <p>Artificial intelligence (AI) has been used to develop conversational AI chatbots, which can understand and respond to natural language input. These chatbots utilize techniques such as natural language processing (NLP), natural language understanding (NLU), and natural language generation (NLG) to understand and respond to user input. The human&#x2013;computer interaction (HCI) aspect of chatbots has also been an essential area of research, as the goal is to create chatbots that can have natural and seamless conversations with users. One such example of a conversational AI chatbot is ChatGPT, which has been trained on a large dataset and can generate human&#x2010;like responses. In this chapter, we have discussed the origin and subsequent developments in the field of conversational AI. Framework breakthroughs like Rasa and GPT&#x2010;3 allow the integration of AI, NLP, NLU, NLG, and HCI in the development of chatbots, providing the potential for more sophisticated and human&#x2010;like conversations. These conversational AI chatbots are being used in a wide range of applications, from customer service and e&#x2010;commerce to healthcare and education. As technology continues to advance, we can expect to see even more natural and intuitive conversational AI chatbots in the future.</p>},
  keywords={Chatbots;Oral communication;Virtual assistants;Artificial intelligence;Natural language generation;Faces;Linguistics;History;Psychiatry;Meteorology},
  doi={10.1002/9781394200801.ch16},
  ISSN={},
  publisher={Wiley},
  isbn={9781394200795},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10952453},}@BOOK{10948547,
  author={Ramaswami, Yoni and Williamson, Dael and Govaere, Jan},
  booktitle={Time Series Analysis with Spark: A practical guide to processing, modeling, and forecasting time series with Apache Spark},
  year={2025},
  volume={},
  number={},
  pages={},
  abstract={Master the fundamentals of time series analysis with Apache Spark and Databricks and uncover actionable insights at scaleKey FeaturesQuickly get started with your first models and explore the potential of Generative AILearn how to use Apache Spark and Databricks for scalable time series solutionsEstablish best practices to ensure success from development to production and beyondPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionWritten by Databricks Senior Solutions Architect Yoni Ramaswami, whose expertise in Data and AI has shaped innovative digital transformations across industries, this comprehensive guide bridges foundational concepts of time series analysis with the Spark framework and Databricks, preparing you to tackle real-world challenges with confidence. From preparing and processing large-scale time series datasets to building reliable models, this book offers practical techniques that scale effortlessly for big data environments. You’ll explore advanced topics such as scaling your analyses, deploying time series models into production, Generative AI, and leveraging Spark's latest features for cutting-edge applications across industries. Packed with hands-on examples and industry-relevant use cases, this guide is perfect for data engineers, ML engineers, data scientists, and analysts looking to enhance their expertise in handling large-scale time series data. By the end of this book, you’ll have mastered the skills to design and deploy robust, scalable time series models tailored to your unique project needs—qualifying you to excel in the rapidly evolving world of big data analytics.What you will learnUnderstand the core concepts and architectures of Apache SparkClean and organize time series dataChoose the most suitable modeling approach for your use caseGain expertise in building and training a variety of time series modelsExplore ways to leverage Apache Spark and Databricks to scale your modelsDeploy time series models in productionIntegrate your time series solutions with big data tools for enhanced analyticsLeverage GenAI to enhance predictions and uncover patternsWho this book is forIf you are a data engineer, ML engineer, data scientist, or analyst looking to enhance your skills in time series analysis with Apache Spark and Databricks, this book is for you. Whether you’re new to time series or an experienced practitioner, this guide provides valuable insights and techniques to improve your data processing capabilities. A basic understanding of Apache Spark is helpful, but no prior experience with time series analysis is required.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781803247175},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10948547},}@INPROCEEDINGS{10303509,
  author={Monteiro, Walbert Cunha and Dos Santos, Diego Hortêncio and De Sousa, Thiago Augusto Soares and Queiroz, Vinicius Favacho and De Araújo, Tiago Davi Oliveira and Meiguins, Bianchi Serique},
  booktitle={2023 27th International Conference Information Visualisation (IV)}, 
  title={Workload Evaluation to Create Data Visualization Using ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={136-141},
  abstract={The value of good data visualization has already been shown in several scenarios. Still, it is not always easy to obtain it, as it depends on factors such as the dataset, the amount of data, task types, the user profile, the type of interaction, etc. To mitigate the challenges addressed, automated or semi-automated systems have been proposed, emphasizing rule-based/heuristic approaches and machine-learning models. However, many of these applications require specialized knowledge and present results (data visualizations) that are not flexible for customization. Papers have highlighted the ease of tools like ChatGPT in creating various tasks, including creating data charts. This facility, in addition to the intelligent computational model involved, is also due to the expressiveness used in the requests to execute the tasks by the users since these tools use Natural Language Interfaces. Despite adopting these tools overgrowing in different scenarios of society, studies on the best way to use them, integrate them into existing processes, or evaluative studies on their effectiveness or efficiency are still incipient. Thus, this paper will evaluate the workload for creating data visualization using ChatGPT 3.5. For assessment, the NASA Task Load Index (Nasa TLX) methodology was applied, and users with experience creating data visualization created two proposed scenarios. The preliminary results showed high temporal and mental demand, mainly due to the vocabulary used and the completeness of the user instructions. The average time to create and perform InfoVis tasks in two proposed evaluation scenarios was 33 and 44 minutes, and 14 queries were applied on average for both scenarios. The direct consequence was that the users have redone the requests and improved the instructions at each new iteration, and all users completed the proposed tasks.},
  keywords={Vocabulary;Computational modeling;NASA;Natural languages;Data visualization;Machine learning;Chatbots;Information Visualization;ChatGPT;Interface Natural Language;Nasa-TLX},
  doi={10.1109/IV60283.2023.00032},
  ISSN={2375-0138},
  month={July},}@ARTICLE{10646341,
  author={Mejía, Jezreel and Terrón-Macias, Victor and Muñoz, Mirna and Terrón-Hernández, Miguel and Canseco-Pérez, Miguel},
  journal={IEEE Access}, 
  title={VSEST 29110 Tool: Using ChatGPT to Evaluate the Implementation of the ISO/IEC 29110 Work Products}, 
  year={2024},
  volume={12},
  number={},
  pages={120935-120948},
  abstract={The global software industry is predominantly composed of micro, small, and medium-sized enterprises (MSMEs), highlighting the need for software quality management to ensure the proper functioning and quality of the software. This research focuses on the evaluation of the implementation of the ISO/IEC 29110 standard work products, which is a standard tailored by the ISO/IEC specifically for MSMEs, which improves the software development process by implementing two processes in its basic profile: Project Management (PM) and Software Implementation (SI). Despite this standard being tailored specifically for this type of enterprise, implementing ISO/IEC 29110 faces several challenges, such as a lack of knowledge and difficulties in adequately implementing the work products regarding the compliance of standard criteria, among others. To address these challenges, we introduce VSEST 29110, a web tool designed to evaluate the ISO/IEC 29110 standard implementation work products by leveraging Artificial Intelligence (AI) technologies, specifically the ChatGPT model, provide detailed feedback on compliance with standard criteria, offer suggestions for improvement based on ChatGPT analysis and streamline the implementation process for MSMEs. To achieve this, our research incorporates a systematic literature review and validation through a case study by document analysis, demonstrating VSEST 29110’s effectiveness in enhancing compliance and providing comprehensive feedback compared to auditor recommendations, which impacts 69.33% on average.},
  keywords={ISO Standards;IEC Standards;Artificial intelligence;Software development management;Chatbots;Text analysis;ISO/IEC 29110 standard;LLMs;ChatGPT;implementation process improvement},
  doi={10.1109/ACCESS.2024.3449252},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10893453,
  author={FalvoJr, Venilton and Da Silva Marcolino, Anderson and Bruno, Diego Renan and Martins Falvo, Catherine Helen and Osório, Fernando Santos and Barbosa, Ellen Francine},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Enhancing Learning Objects Accessibility Through Speech-To-Text Based Architecture: A Comprehensive Triangulation Study}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This full research paper expands on the results and discussions from a case study conducted within a Brazilian EdTech company. It focuses on the accuracy of AI-based speech recognition models for automatic transcription of video lectures, aiming to improve the accessibility of Learning Objects (LOs), especially the audible ones. Previous work assessed the quality of automatic transcriptions in English, Portuguese, and Spanish from Speech- To- Text (STT) services provided by major market players (Amazon, Google, IBM, Microsoft, and OpenAI), using a quantitative approach based on lexical similarity algorithms. Statistically significant differences were identified between the providers and languages evaluated, indicating that STT service can affect the quality of audible OAs enriched with transcriptions or subtitles. This study introduces a new dimension of analysis by incorporating the perceptions of technology students on the accuracy of automatic transcriptions, gathered through an anonymous survey with 56 participants. The survey captured mainly quantitative data using a Likert scale on the accuracy of transcriptions. To provide a comprehensive analysis, this study employs a data triangulation approach, integrating (1) quantitative data from lexical similarity methods, (2) quantitative data from the survey, and (3) findings from a complementary review of the literature. The qualitative analysis, applying Grounded Theory principles to both the survey data and the bibliographic review, enables the exploration of emerging themes and enriches the understanding of factors influencing the quality of automatic transcriptions. This effort underscores the importance of a user-centered perspective and demonstrates the complexity of evaluating STT technologies, pointing to the necessity for future research that combines quantitative and qualitative methods. Additionally, it highlights the relevance of STT in various educational contexts and the need to align such technologies with principles of accessibility and inclusion. By aiming to create more accessible LOs, this work emphasizes the need to develop solutions that ensure inclusion and equity in educational access, reflecting a concerted effort to meet the diverse needs of learners and promote a more welcoming and inclusive learning environment.},
  keywords={Surveys;Measurement;Accuracy;Data analysis;Reviews;Companies;Internet;Complexity theory;Speech to text;Speech-To-Text (STT);Software Architecture;Learning Objects (LOs);Accessibility;Data Triangulation},
  doi={10.1109/FIE61694.2024.10893453},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{11005596,
  author={Routray, Sudhir K.},
  journal={IEEE Computer Graphics and Applications}, 
  title={Ethical Considerations and Implications of Generative AI in Computer Graphics}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Generative AI has immense potential to create diverse computer graphics for various applications, but it also raises significant ethical issues. This paper examines the ethical landscape of using generative AI in computer graphics, highlighting key concerns such as the authenticity of generated content, intellectual property rights, and cultural appropriation. Additional ethical challenges include algorithmic bias in graphics generation, representation, privacy, inclusivity, and the impact on human-computer interaction and artistic integrity. The displacement of creative professionals, erosion of trust in visual media, and psychological effects of AI-generated content further complicate the ethical debate. Addressing these issues requires a comprehensive approach that integrates technological innovation with regulatory oversight, ethical education, and collaboration among stakeholders. By carefully considering these ethical dimensions, we can fully leverage generative AI's potential in computer graphics while mitigating its risks.},
  keywords={Generative AI;Ethics;Artificial intelligence;Technological innovation;Creativity;Intellectual property;Training;Data models;Cultural differences;Computational modeling},
  doi={10.1109/MCG.2025.3570722},
  ISSN={1558-1756},
  month={},}@INPROCEEDINGS{10158670,
  author={Krutilla, Zsolt and Kovari, Attila},
  booktitle={2023 IEEE 17th International Symposium on Applied Computational Intelligence and Informatics (SACI)}, 
  title={How we can use text classification in the Back-Office environment of a bank as ‘business as usual’ solution}, 
  year={2023},
  volume={},
  number={},
  pages={000209-000214},
  abstract={Natural Language Processing nowadays provides scientists with many research areas and opportunities, but as with most applied sciences, our goal in Natural Language Processing is to refine the underlying science and technology until it can be used reliably for business purposes. Transformer models, such as GPT or BERT, are currently showing outstanding results in the field of natural-language processing, but they require huge computational power and data to teach, but these conditions can only be met by larger research centers and large companies, and their inaccuracy makes them unsuitable for use as a ‘business as usual’ (BAU) solution. In this paper, we present a solution that is able to overcome these problems by focusing on accuracy and usability, and that can also bring a new perspective to the process of teaching deep learning models.},
  keywords={Uncertainty;Text categorization;Manuals;Logic gates;Transformers;Natural language processing;Reliability;natural language processing;transformers;generative pre-trained transformers;text analytics;document classification},
  doi={10.1109/SACI58269.2023.10158670},
  ISSN={2765-818X},
  month={May},}@INPROCEEDINGS{10868958,
  author={Shi, Yuxuan and Huang, Wen and Sang, Yijing},
  booktitle={2024 4th International Conference on Educational Technology (ICET)}, 
  title={A Narrative Review of Utilizing Generative Artificial Intelligence in Classroom Instructions}, 
  year={2024},
  volume={},
  number={},
  pages={419-422},
  abstract={This review examines the utilization of Generative Artificial Intelligence (GAI) in classroom instructions, emphasizing its transformative potential in education. After reviewing 23 relevant articles, we identified three themes: application advantages, possible risks, and future paths. Specifically, GAI has the potential to facilitate personalized learning, promote communication, and promoting education equity. However, concerns over content validity, ethical issues, and the risk of diminished innovation necessitate careful consideration. Additionally, prior literature suggests improving instructional evaluation methods, enhancing AI literacy, and addressing ethical challenges to maximize GAI's benefits and drive continuous educational innovation.},
  keywords={Technological innovation;Ethics;Reviews;Generative AI;Learning (artificial intelligence);Educational technology;generative artificial intelligence;classroom instruction;literature review},
  doi={10.1109/ICET62460.2024.10868958},
  ISSN={},
  month={Sep.},}@ARTICLE{10664616,
  author={Hong, Yifan and Shi, Chuanqi and Chen, Junyang and Wang, Huan and Wang, Di},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Multitask Asynchronous Metalearning for Few-Shot Anomalous Node Detection in Dynamic Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-12},
  abstract={Few-shot anomalous node detection in dynamic networks has been extensively investigated in the field of research. In this few-shot scenario, the detection of these anomalous nodes is particularly challenging due to the continuously evolving network topology and data distribution over time, which is known as concept drift. Concept drift refers to the phenomenon where the underlying concepts or patterns in the data generation process change over time, leading to varying data distributions across different periods. Due to these changes in data distribution, the patterns learned during training may become invalid under the new data distribution. Existing models primarily aim to enhance the representation of evolving node attributes and relationships to mitigate the impact of concept drift in few-shot scenarios. However, the scarcity of anomalous samples further limits the model’s ability to learn new patterns, thereby reducing its effectiveness in addressing concept drift in few-shot scenarios. To address this challenge, we propose the multitask asynchronous metalearning framework (MAMF), which aims to mitigate bias induced by concept drift in few-shot anomalous node detection. Our framework consists of four main components: a feature extractor, an anomaly simulator, an asynchronous learner, and a type detector. The feature extractor captures the relative variations of each node in an evolving graph stream. The anomaly simulator uses generative adversarial models to learn anomaly distributions and generate samples at different time intervals. The asynchronous learner samples from various time distributions to create metatasks for anomalous node detection, allowing it to adapt to changes between these distributions. To aid in few-shot anomalous node detection, the type detector is used for anomaly type recognition. Our framework achieves AUC improvements of 5.12%, 6.87%, and 1.91% over the best existing methods on Wikipedia, Reddit, and Mooc datasets, respectively, demonstrating its effectiveness and robustness in adapting to concept drift and detecting anomalous nodes.},
  keywords={Concept drift;Adaptation models;Metalearning;Data models;Feature extraction;Anomaly detection;Training data;Anomalous node detection;concept drift;graph neural networks;metalearning;multitask learning},
  doi={10.1109/TCSS.2024.3442238},
  ISSN={2329-924X},
  month={},}@INPROCEEDINGS{10882421,
  author={Joshi, Deepali and Tekade, Shreyash and Zanzane, Sayee and Sakharwade, Dhawal and Tripathi, Ankur and Tiwadi, Shivam},
  booktitle={2024 International Conference on Artificial Intelligence and Quantum Computation-Based Sensor Application (ICAIQSA)}, 
  title={Generative AI-Driven Chatbot for Personalized University Information and Assistance}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper outlines the development of a generative AI-driven chatbot for university admissions and general inquiries, using a Retrieval-Augmented Generation (RAG) framework. By embedding university-related documents into a vector database and indexing them with FAISS, the system efficiently retrieves information and generates precise, context-aware responses. The chatbot improves user experience by providing accurate answers to prospective students and other users, showcasing the potential of generative AI in educational settings for managing inquiries effectively},
  keywords={Quantum computing;Accuracy;Generative AI;Databases;Retrieval augmented generation;Chatbots;User experience;Vectors;Indexing;Generative AI;Retrieval-Augmented Generation (RAG);University Chatbot;Natural Language Processing (NLP);Information Retrieval},
  doi={10.1109/ICAIQSA64000.2024.10882421},
  ISSN={},
  month={Dec},}
@ARTICLE{10643089,
  author={Srivastava, Akchay and Memon, Atif},
  journal={IEEE Access}, 
  title={Toward Robust Evaluation: A Comprehensive Taxonomy of Datasets and Metrics for Open Domain Question Answering in the Era of Large Language Models}, 
  year={2024},
  volume={12},
  number={},
  pages={117483-117503},
  abstract={Open Domain Question Answering (ODQA) within natural language processing involves building systems that answer factual questions using large-scale knowledge corpora. Recent advances stem from the confluence of several factors, such as large-scale training datasets, deep learning techniques, and the rise of large language models. High-quality datasets are used to train models on realistic scenarios and enable the evaluation of the system on potentially unseen data. Standardized metrics facilitate comparisons between different ODQA systems, allowing researchers to objectively track advancements in the field. Our study presents a thorough examination of the current landscape of ODQA benchmarking by reviewing 52 datasets and 20 evaluation techniques across textual and multimodal modalities. We introduce a novel taxonomy for ODQA datasets that incorporates both the modality and difficulty of the question types. Additionally, we present a structured organization of ODQA evaluation metrics along with a critical analysis of their inherent trade-offs. Our study aims to empower researchers by providing a framework for the robust evaluation of modern question-answering systems. We conclude by identifying the current challenges and outlining promising avenues for future research and development.},
  keywords={Internet;Task analysis;Online services;Encyclopedias;Taxonomy;Artificial intelligence;Large language models;Machine learning;Natural language processing;Question answering (information retrieval);Artificial intelligence;datasets;large language models;machine learning;metrics;multimodal;natural language processing;open domain question answering;review;taxonomy},
  doi={10.1109/ACCESS.2024.3446854},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10793131,
  author={Giordani, Jeremiah and Xu, Ziyang and Colby, Ella and Ning, August and Godala, Bhargav Reddy and Chaturvedi, Ishita and Zhu, Shaowei and Chon, Yebin and Chan, Greg and Tan, Zujun and Collier, Galen and Halverson, Jonathan D. and Deiana, Enrico Armenio and Liang, Jasper and Sossai, Federico and Su, Yian and Patel, Atmn and Pham, Bangyen and Greiner, Nathan and Campanoni, Simone and August, David I.},
  booktitle={SC24: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Revisiting Computation for Research: Practices and Trends}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={In the field of computational science, effectively supporting researchers necessitates a deep understanding of how they utilize computational resources. Building upon a decade-old survey that explored the practices and challenges of research computation, this study aims to bridge the understanding gap between providers of computational resources and researchers who rely on them. This study revisits key survey questions and gathers feedback on open-ended topics from over a hundred interviews. Quantitative analyses of present and past results illuminate the landscape of research computation. Qualitative analyses, including careful use of large language models, highlight trends and challenges with concrete evidence. Given the rapid evolution of computational science, this paper offers a toolkit with methodologies and insights to simplify future research and ensure ongoing examination of the landscape. This study, with its findings and toolkit, guides enhancements to computational systems, deepens understanding of user needs, and streamlines reassessment of the computational landscape.},
  keywords={Surveys;Data analysis;Scientific computing;Statistical analysis;Large language models;High performance computing;Buildings;Market research;Solids;Interviews},
  doi={10.1109/SC41406.2024.00076},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10210230,
  author={Chen, Zhenyu},
  booktitle={2023 IEEE/ACIS 23rd International Conference on Computer and Information Science (ICIS)}, 
  title={Education Reform of Software Engineering in the Age of A.I: Keynote Address}, 
  year={2023},
  volume={},
  number={},
  pages={2-2},
  abstract={In the age of artificial intelligence (A.I.), software engineering is facing unprecedented changes. Software developers need to have a deep understanding of, especially large model technologies, since the traditional software development model cannot meet the new needs. Moreover, software engineering also needs to pay more attention to the value of data. The data-driven software development models are growing, and data analysis and machine learning technologies have also been widely used. Software development requires higher efficiency, quality, and flexibility. New methods such as agile development and DevOps have emerged. Software testing also needs to be more intelligent, and test automation has become an essential part in software engineering. This speech focuses on sharing the opportunities and challenges brought by GPT and other big models to software development and testing. It also looks forward to the changes brought by A.I. to software engineering education and how we coped. The reform of software engineering is an inevitable trend, and software developers need to constantly learn new technologies and master new methods in the age of A.I.},
  keywords={Software;Software engineering;Education;Software testing;Web and internet services;Optimization;Mobile applications},
  doi={10.1109/ICIS57766.2023.10210230},
  ISSN={},
  month={June},}@ARTICLE{10993463,
  author={Ma, Zeyuan and Guo, Hongshu and Gong, Yue-Jiao and Zhang, Jun and Tan, Kay Chen},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Toward Automated Algorithm Design: A Survey and Practical Guide to Meta-Black-Box-Optimization}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In this survey, we introduce Meta-Black-Box-Optimization (MetaBBO) as an emerging avenue within the Evolutionary Computation (EC) community, which incorporates Meta-learning approaches to assist automated algorithm design. Despite the success of MetaBBO, the current literature provides insufficient summaries of its key aspects and lacks practical guidance for implementation. To bridge this gap, we offer a comprehensive review of recent advances in MetaBBO, providing an in-depth examination of its key developments. We begin with a unified definition of the MetaBBO paradigm, followed by a systematic taxonomy of various algorithm design tasks, including algorithm selection, algorithm configuration, solution manipulation, and algorithm generation. Further, we conceptually summarize different learning methodologies behind current MetaBBO works, including reinforcement learning, supervised learning, neuroevolution, and in-context learning with Large Language Models. A comprehensive evaluation of the latest representative MetaBBO methods is then carried out, alongside an experimental analysis of their optimization performance, computational efficiency, and generalization ability. Based on the evaluation results, we meticulously identify a set of core designs that enhance the generalization and learning effectiveness of MetaBBO. Finally, we outline the vision for the field by providing insight into the latest trends and potential future directions. Relevant literature will be continuously collected and updated at https://github.com/MetaEvo/Awesome-MetaBBO.},
  keywords={Optimization;Surveys;Training;Metalearning;Performance gain;Heuristic algorithms;Supervised learning;Reviews;Recurrent neural networks;Glass box;Meta-Black-Box-Optimization;Evolutionary Computation;Black-Box-Optimization;Learning to Optimize},
  doi={10.1109/TEVC.2025.3568053},
  ISSN={1941-0026},
  month={},}@INPROCEEDINGS{10137767,
  author={Alamleh, Hosam and AlQahtani, Ali Abdullah S. and ElSaid, AbdElRahman},
  booktitle={2023 Systems and Information Engineering Design Symposium (SIEDS)}, 
  title={Distinguishing Human-Written and ChatGPT-Generated Text Using Machine Learning}, 
  year={2023},
  volume={},
  number={},
  pages={154-158},
  abstract={The use of sophisticated Artificial Intelligence (AI) language models, including ChatGPT, has led to growing concerns regarding the ability to distinguish between human-written and AI-generated text in academic and scholarly settings. This study seeks to evaluate the effectiveness of machine learning algorithms in differentiating between human-written and AI-generated text. To accomplish this, we collected responses from Computer Science students for both essay and programming assignments. We then trained and evaluated several machine learning models, including Logistic Regression (LR), Decision Trees (DT), Support Vector Machines (SVM), Neural Networks (NN), and Random Forests (RF), based on accuracy, computational efficiency, and confusion matrices. By comparing the performance of these models, we identified the most suitable one for the task at hand. The use of machine learning algorithms for detecting text generated by AI has significant potential for applications in content moderation, plagiarism detection, and quality control for text generation systems, thereby contributing to the preservation of academic integrity in the face of rapidly advancing AI-driven content generation.},
  keywords={Support vector machines;Training;Machine learning algorithms;Computational modeling;Plagiarism;Quality control;Chatbots;TextOriginClassifier;ChatGPT;human-written text;AI-generated text;machine learning;academic integrity;content detection;AI;NLP;TF-IDF},
  doi={10.1109/SIEDS58326.2023.10137767},
  ISSN={},
  month={April},}@INPROCEEDINGS{10369130,
  author={Nihal, K. Sai and Pallavi, L. and Raj, Ritik and Babu, Chunduri Madhu and Mishra, Binod},
  booktitle={2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Enhancing Soft Skill Development with ChatGPT and VR: An Exploratory Study}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This research paper explores the significance of soft skills in predicting and enhancing future success. It emphasizes the use of current technologies, particularly virtual reality (VR) training methods, to address the lack of experience in employees and students. VR simulations have proven effective and efficient, surpassing traditional methods. The paper also discusses the emergence of AI, like ChatGPT, for training, but acknowledges the challenges of accuracy, biases, and ethics. To use VR training, one needs to think about factors like the equipment, the expense, and the ability to expand. Organizations can leverage AI and VR training to create impactful solutions by navigating these drawbacks.},
  keywords={Training;Ethics;Solid modeling;Virtual reality;Organizations;Chatbots;Software;Virtual Reality(VR);Soft-skills;ChatGPT;Students;Employees},
  doi={10.1109/RMKMATE59243.2023.10369130},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10663016,
  author={Olmez, Muhammet Mustafa and Gehringer, Edward},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Automation of Test Skeletons Within Test-Driven Development Projects}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={In addressing the need for test case generation in software projects and the validation and repair processes, various algorithms and AI models are increasingly being applied with novel approaches. On the other hand, despite the established effectiveness of the Test-Driven Development (TDD) approach in testing and development, there is still a lack of research examining the impact of human-machine interaction on software validation and coding. This paper introduces a tool, the test-skeleton generator, which utilizes an OpenAI model to generate test skeletons. These skele-tons include test names, signatures, and scenario descriptions, omitting the actual test bodies. To explore the implications of this tool, an empirical experiment involving student participation was conducted to assess the conversion of test skeletons into functional tests with human-machine interaction. The study reveals significant insights, indicating that human-machine interaction plays a crucial role in shaping both the testing and programming phases, encouraging students to prioritize writing tests before modifying source code. Teams adopting this approach demonstrate a tendency to produce more tests, leading to higher code coverage. Additionally, our research underscores the growing potential of AI language models to generate tests that closely resemble those written by human developers. Notably, human-machine interaction has proven its significant positive impact on the validation and repair process of AI -generated tests.},
  keywords={Human computer interaction;Source coding;Human-machine systems;Software algorithms;Maintenance engineering;Writing;Programming;Test skeletons;Test-driven development;test generation;Human-machine interaction;AI tool},
  doi={10.1109/CSEET62301.2024.10663016},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10195137,
  author={Ortega, Eduardo and Tran, Michelle and Bandeen, Grace},
  booktitle={2023 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={AI Digital Tool Product Lifecycle Governance Framework through Ethics and Compliance by Design†}, 
  year={2023},
  volume={},
  number={},
  pages={353-356},
  abstract={The acceleration of Artificial Intelligence (AI) has brought forward new digital tools that have had a wide impact across society. However, AI digital tools (such as ChatGPT, midjourney, DALL-E 2) have brought forward legal and ethical concerns. — Internationally, public, and private leaders are introducing regulatory frameworks to address data governance for such these AI digital tools (i.e., Global Data Protection Regulation, the European AI Act, Blueprint for an AI Bill of Rights, NIST Risk Management Framework, etc.). We recognize that these AI digital tools are a vital aspect of future technological development, but they require input from various sectors in addressing ethics and compliance design. We survey the current landscape of published AI-specific regulatory frameworks and known engineering design process methods. Using a product lifecycle approach, we also introduce a trans-disciplinary framework to address AI ethics and compliance via design. This product lifecycle approach considers several principles: a Human-Centered Design for Risk Assessment, Functional Safety and Risk Management Standardization, and Continuous Governance throughout Product Lifecycle. Establishing risk management throughout AI product lifecycles can ensure accountability for AI product use cases. In addition, by utilizing previous Functional Safety considerations we can create safety mechanisms throughout the product lifecycle of AI digital tools. Finally, establishing in-field testing for continuous governance will enable the flexibility for new compliance standards and transparency. We establish this governance framework to aid in new compliance strategies for these emerging issues with AI digital tools.},
  keywords={Surveys;Ethics;Law;NIST;Regulation;Safety;Risk management;Ethics;Compliance;AI;Risk Management;Human-Centered-Design;Engineering Design Thinking},
  doi={10.1109/CAI54212.2023.00155},
  ISSN={},
  month={June},}@INPROCEEDINGS{10822765,
  author={Yujiao, Li and Jie, Yang and Ming, Xiao},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Research on the Emotional Impact of Restorative Environments Based on Facial Emotion Recognition Systems and Sora Model Virtual Reality Technology}, 
  year={2024},
  volume={},
  number={},
  pages={5638-5645},
  abstract={In recent years, the positive impact of virtual reality restorative environments on mental health has been confirmed by numerous studies. This study employed OpenAI's Sora model to create three types of virtual videos with restorative effects: natural, animal, and human environments. Using a facial emotion recognition system built with Keras, OpenCV, and PyQt5, along with the fer2013 facial expression database, and the psychological indicator detection technology of the PAD emotion scale, we conducted an experiment with 24 college students to assess their emotional responses and intensity to these three types of virtual videos in immersive virtual reality scenarios. We also collected subjective and objective physiological data from participants after they experienced different restorative virtual videos and analyzed the data using statistical methods.The results indicate that the three types of virtual videos generated by the Sora model had a positive impact on the participants' emotions. Most participants experienced a significant increase in positive emotions such as gentleness and surprise after watching the virtual natural environment videos, while negative emotions like anxiety and unease were effectively alleviated. Further analysis showed that the animal and natural environments were more effective in emotional regulation than the human environment.This study innovatively investigates the application of AI technology, particularly the Sora model, in virtual reality restorative environments, paving new directions for the exploration and application of AI technology in the emotional regulation of college students and providing new insights for future research.},
  keywords={Solid modeling;Analytical models;Emotion recognition;Animals;Anxiety disorders;Data models;Regulation;Physiology;Artificial intelligence;Videos;Artificial intelligence;Restorative environment;College students;Emotional regulation;Mental health},
  doi={10.1109/BIBM62325.2024.10822765},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10653003,
  author={Jetter, Antonie J and Agrawal, Ameeta and Hongchai, Dahm Mongkol and Weber, Charles M. and Tao, Yufei},
  booktitle={2024 Portland International Conference on Management of Engineering and Technology (PICMET)}, 
  title={Training Practitioners for Real-time Product Development Using Generative Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={A workshop to train practitioners in real-time new product development (NPD) using generative artificial intelligence (AI) was conducted. Three teams of graduate students in Engineering and Technology Management (many with work experience as managers and engineers) were given minimalist instructions to develop a product concept and a preliminary marketing plan for a product of their choosing within six hours using ChatGPT, search engines, and other Internet-based tools. The product was to be novel, and the plan was to include customer identification, market analysis, generating personas, and a 15-minute presentation at the end of the workshop. The goal was to 'inspire a sales force'. A panel of judges, which included the authors and an external marketing professional, determined the strengths, weaknesses, and viability of the development efforts of the teams. The results of the workshop validated the utility of AI in NPD for multiple industries. The panel rated the output of the effort of the teams as ‘highly creative’ and potentially viable in the real world. The most significant contribution of the workshop was demonstrating the speed at which product development activity could be performed.},
  keywords={Training;Industries;Technology management;Generative AI;Conferences;Force;Search engines},
  doi={10.23919/PICMET64035.2024.10653003},
  ISSN={2159-5100},
  month={Aug},}@ARTICLE{10988654,
  author={Ding, Yuyang and Qiao, Dan and Li, Juntao and Xu, Jiajie and Chao, Pingfu and Zhou, Xiaofang and Zhang, Min},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Towards DS-NER: Unveiling and Addressing Latent Noise in Distant Annotations}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={Distantly supervised named entity recognition (DS-NER) has emerged as a cheap and convenient alternative to traditional human annotation methods, enabling the automatic generation of training data by aligning text with external resources. Despite the many efforts in noise measurement methods, few works focus on the latent noise distribution between different distant annotation methods. In this work, we explore the effectiveness and robustness of DS-NER by two aspects: (1) distant annotation techniques, which encompasses both traditional rule-based methods and the innovative large language model supervision approach, and (2) noise assessment, for which we introduce a novel framework. This framework addresses the challenges by distinctly categorizing them into the unlabeled-entity problem (UEP) and the noisy-entity problem (NEP), subsequently providing specialized solutions for each. Our proposed method achieves significant improvements on eight real-world distant supervision datasets originating from three different data sources and involving four distinct annotation techniques, confirming its superiority over current state-of-the-art methods.},
  keywords={Annotations;Noise measurement;Noise;Training;Chatbots;Large language models;Data mining;Nearest neighbor methods;Named entity recognition;Data models;Distantly supervised learning;Named entity recognition;Noise measurement},
  doi={10.1109/TKDE.2025.3567204},
  ISSN={1558-2191},
  month={},}@INPROCEEDINGS{10893167,
  author={Hooper, Kerrie and Lunn, Stephanie J.},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Values in Education: Exploration of Artificial Intelligence Ethics Syllabi Using Natural Language Processing Analyses}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={With new technologies come additional responsibilities. Examining Artificial Intelligence (AI) through an ethical lens has become increasingly important and significant. Advancements in AI have led numerous organizations, such as IEEE, to develop AI ethics guidelines for consideration in academia and industry. Additionally, higher education has an essential role in fostering innovation and developing skilled professionals who will work on topics that span social, philosophical, scientific, and technical spheres. To assess the content being covered in tertiary classrooms, we utilized a Natural Language Processing (NLP) approach for analysis. This study examines $(\mathrm{n}=45)$ AI ethics syllabi that were publicly available online. The course description, topics, department, and year were some important features captured from each syllabus. Using various NLP tools for analysis, a general exploration of AI ethics curricula was conducted. Through supervised clustering, k-means clustering, and latent Dirichlet Allocation (LDA), various patterns in the contents of the AI ethics syllabus were found. Some of these include trends and patterns from syllabi across various academic departments, years, and the pre-post Chat-GPT era. Cluster evaluation was also done on the unsupervised clusters using various metrics to determine the viability of the clusters. The LDA analysis enabled a review of topics that are consistent among the clusters, which helped highlight salient areas of focus in AI ethics syllabi. The findings from this study can serve to inform administrators and educators, acting as a baseline for including language around AI ethics topics and uncovering potential topical gaps in the contents of AI ethics syllabi. They can also provide insight into how different academic departments, like computer science and philosophy, may approach the topic. Such understanding is critical to ensuring the next generation of graduates not only considers how to utilize AI but also promotes doing so responsibly and with regard to its societal implications},
  keywords={Ethics;Technological innovation;Philosophical considerations;Reviews;Education;Organizations;Natural language processing;Resource management;Artificial intelligence;Next generation networking;artificial intelligence;AI;ethics;natural language processing;clustering},
  doi={10.1109/FIE61694.2024.10893167},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{11028073,
  author={Rajesh, Shaun George and Madangarli, Smriti Vipin and Pisharady, Gauri Santosh and Subrahmanyam, Rolla},
  journal={IEEE Access}, 
  title={Enhancement of Virtual Assistants through MultiModal AI for Emotion Recognition}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Emotion recognition is becoming increasingly critical for enhancing human-computer interactions, as emotions play a vital role in shaping human interactions and overall well-being. Machines that can detect and respond to emotional cues similar to humans are essential in multiple industries. Emotionally responsive agents find applications in education, healthcare, gaming, marketing, customer service, human-robot interaction, and entertainment. This study explores the potential of enhancing virtual assistants through multimodal Artificial Intelligence (AI), utilizing various emotion recognition techniques to create more empathetic and effective systems. The proposed methodology makes use of facial expressions and textual cues to enhance the emotional awareness of the system and achieve user satisfaction through empathetic conversation. The Facial Emotion Recognition (FER) model achieved 71% real-time accuracy, whereas the Textual Emotion Recognition (TER) model achieved 59% validation accuracy, demonstrating effective Multimodal Emotion Recognition (MER). Unlike prior multimodal emotion-aware systems, our lightweight architecture ensures real-time inference and uniquely integrates facial and textual emotion recognition with DialoGPT-based response generation — demonstrating compatibility with large language models for empathetic dialogue.},
  keywords={Emotion recognition;Virtual assistants;Accuracy;Real-time systems;Deep learning;Computational modeling;Artificial intelligence;Visualization;Data models;Chatbots;virtual assistants;large language models;facial emotion recognition;BERT;computer vision;neural networks},
  doi={10.1109/ACCESS.2025.3577664},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10701449,
  author={Osińska, Veslava and Szalach, Adam and Piotrowski, Dominik M.},
  booktitle={2024 Progress in Applied Electrical Engineering (PAEE)}, 
  title={Eye tracking as a tool for analysing human -AI image interactions}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={In recent years, artificial intelligence (AI) has significantly advanced fields like computer vision, image description, and generation, proving particularly relevant in creative areas such as generative art. This research aimed to explore AI’s capabilities in creating and describing images compared to human perception. It included a comparative analysis of visual perception using eyetracking techniques in two settings: a VR art gallery created for the BITSCOPE project and a stationary ET study of individual images. The images, sourced from the BITSCOPE project’s CHIST-ERA IV collection, were initially described by an expert following specific instructions, which were then used by AI to generate corresponding images. The eyetracking study focused on key areas and gaze plot sequences, using a gaze plot similarity metric based on topology and path length, enabled by the size of the research group.},
  keywords={Computer vision;Visualization;Art;Phase measurement;Atmospheric measurements;Gaze tracking;Time measurement;Topology;Artificial intelligence;Visual perception;artificial intelligence;eyetracking;virtual reality;computer vision},
  doi={10.1109/PAEE63906.2024.10701449},
  ISSN={2837-8326},
  month={June},}@INPROCEEDINGS{10612458,
  author={Kumar, Umang and S, Shenbaga Raj and P, Kasirajan and Sivakamasundari, G.},
  booktitle={2024 International Conference on Expert Clouds and Applications (ICOECA)}, 
  title={Smart PDF Inquiry Hub: A Comprehensive Solution for Efficient PDF Document Querying and Information Extraction}, 
  year={2024},
  volume={},
  number={},
  pages={192-198},
  abstract={With the exponential growth of digital documents, navigating through extensive PDF files to extract specific information can be time-consuming and challenging. This project addresses this issue by providing a seamless solution for users to upload PDF documents, input queries, and receive relevant responses swiftly. The ‘Smart PDF Inquiry Hub’ is a user-friendly application designed to streamline the process of querying information within PDF documents. The application utilizes advanced text processing techniques to handle PDF content effectively. It automatically extracts text, divides it into manageable chunks, and stores them in a Vector Store for quick retrieval. Users can input queries related to the document, initiating a similarity search to find relevant sections within the PDF. The “Smart PDF Inquiry Hub” incorporates advanced question-answering models from OpenAI. These models analyze user queries and extract text chunks to produce precise responses. With a user-friendly Streamlit interface, users can effortlessly upload documents, ask questions, and receive insightful answers. It serves as an invaluable tool for researchers, students, professionals, and anyone dealing with large volumes of PDF documents. By harnessing the power of text processing and machine learning, this application empowers users to efficiently navigate and extract knowledge from PDFs, saving time and enhancing productivity.},
  keywords={Visualization;Accuracy;Navigation;Machine learning;User interfaces;Portable document format;Information retrieval;Portable Document Format information retrieval;text processing;machine learning;similarity search;question answering;Streamlit;Open Artificial Intelligence;Vector Store;information retrieval;natural language processing},
  doi={10.1109/ICOECA62351.2024.00045},
  ISSN={},
  month={April},}@INPROCEEDINGS{10913604,
  author={Sampaio, Telmo and Oliveira, Pedro Filipe and Matos, Paulo},
  booktitle={2024 International Conference on Engineering and Emerging Technologies (ICEET)}, 
  title={Development of a Chatbot to Support an University Institutional Website}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Currently, the institutional website of the Polytechnic Institute of Bragança (IPB) lacks an interactive system that allows users to obtain information quickly and efficiently. With the increase in the use of online services and the preference of students for instant interactions, there is a growing need for tools that facilitate communication and access to information. This work proposes the development of a chatbot to support the IPB website, with the aim of improving user experience and providing quick and accurate answers to their queries. The main objective of this project is to create an intelligent chatbot capable of understanding and responding to a wide range of questions related to IPB. To achieve this, modern natural language processing and machine learning technologies such as Streamlit, Langchain, and OpenAI are used. The system includes an automated Web Scraper to keep information up-to-date, an architecture based on efficient document segmentation, and an administrative back office for monitoring and management. This development represents a significant advance in how users interact with the IPB website, offering a more efficient and accessible communication channel. The chatbot has the potential to reduce the workload of administrative staff while improving user satisfaction by providing accurate and instant answers to their questions.},
  keywords={Accuracy;Interactive systems;Machine learning;Communication channels;Chatbots;Solids;User experience;Service-oriented architecture;Monitoring;chatbot;webscraper;machine-learning;stream-lit},
  doi={10.1109/ICEET65156.2024.10913604},
  ISSN={2831-3682},
  month={Dec},}@INPROCEEDINGS{10245872,
  author={Qi, Junwei and Deng, Yuhao and Wang, Qingchun and Yang, Zhen and Li, Yingsong},
  booktitle={2023 IEEE 6th International Conference on Electronic Information and Communication Technology (ICEICT)}, 
  title={No-Reference Image Quality Assessment Based on Active Reasoning Module}, 
  year={2023},
  volume={},
  number={},
  pages={274-278},
  abstract={We present a no-reference image-quality - assessment algorithm based on active reasoning module. This algorithm has three modules: the feature extraction module, the active reasoning module, and the quality assessment module. The active reasoning module incorporates the generator component of the generative adversarial network and enhances its structure with the Res2Net architecture. By integrating this module into the backbone feature extraction network, we improve the receptive field of each convolutional layer, enabling the network to capture information at different scales of the image. To preserve the texture information of the image, we input the gradient map of the distorted image, the distorted image itself, and the image features generated by the generator into the quality assessment module, which has a multi-feature regression networks. This module establishes a mapping model from image-feature to image-quality scores. We conducted experimental analysis of this algorithm on three widely used public datasets, confirming the excellent performance and superiorities of the presented algorithm. The results validate the effectiveness of the designed algorithm and its ability to assess image quality accurately.},
  keywords={Image quality;Training;Feature extraction;Generative adversarial networks;Distortion;Cognition;Generators;no-reference image-quality-assessment (IQA);IGM;transformer;Res2Net},
  doi={10.1109/ICEICT57916.2023.10245872},
  ISSN={2836-7782},
  month={July},}@INPROCEEDINGS{10589162,
  author={Garcia, Manuel B. and Revano, Teodoro F. and Maaliw, Renato R. and Lagrazon, Pitz Gerald G. and Valderama, Arlene Mae C. and Happonen, Ari and Qureshi, Basit and Yilmaz, Ramazan},
  booktitle={2023 IEEE 15th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management (HNICEM)}, 
  title={Exploring Student Preference between AI-Powered ChatGPT and Human-Curated Stack Overflow in Resolving Programming Problems and Queries}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Among computer programmers and developers, the user-oriented question-and-answer website of Stack Overflow is a useful platform for sourcing solutions to programming problems, exchanging insights, and accessing a wealth of shared knowledge. However, the timeliness of responses on this platform is frequently a limiting factor that ChatGPT could potentially address. The goal of this study was to explore the preferences of novice programmers between these platforms for finding answers to their programming questions. Anchored in the Technology Acceptance Model (TAM) and the Information Foraging Theory (IFT), the study investigates users' perceptions of usefulness, ease of use, information scent, cognitive effort, as well as overall preferences. Our findings show discernible variations in preferences within the group of students (i.e., application and website developers). In line with these results, we discussed theoretical and practical implications and suggested a dual-pronged approach to leverage both environments as coding assistants in computer programming education.},
  keywords={Knowledge engineering;Technology acceptance model;Limiting;Chatbots;Reservoirs;Reliability;Problem-solving;ChatGPT;Stack Overflow;Computer Programming;Large Language Models;Artificial Intelligence;Problem Solving},
  doi={10.1109/HNICEM60674.2023.10589162},
  ISSN={2770-0682},
  month={Nov},}@INPROCEEDINGS{10840155,
  author={Gunawan, Alifi Lazuardi and Bachtiar, Fitra Abdurrachman and Setiawan, Budi Darma},
  booktitle={2024 12th Electrical Power, Electronics, Communications, Controls and Informatics Seminar (EECCIS)}, 
  title={Comparison of Q&A Classification Using BiLSTM Based on Closed Domain Knowledge}, 
  year={2024},
  volume={},
  number={},
  pages={202-207},
  abstract={The Faculty of Computer Science, Universitas Brawijaya (Filkom UB) is committed to providing quality services for the users especially internal and external stakeholders, one of which is through the HaloFilkom service. HaloFilkom services have limitations in terms of time. HaloFilkom services are not available 24 hours due to limited working hours. Questions asked by users are not answered directly. This weakness in the HaloFilkom system can be overcome by using a chatbot system. Chatbot is an interactive system that works with natural human language and can work 24 hours. Thus, the current study explores the basic chatbot model by classifying the Q&A in the closed domain knowledge. The dataset in this research is in the form of pairs of questions and answers regarding various topics at the Filkom UB. The knowledge is preprocessed using text preprocessing which includes case folding, tokenization, padding, and tensorization. One of the chatbot models is a generative model. Creating a generative chatbot model can be done using the Seq2Seq model mechanism which consists of an encoder and decoder. The model created consists of four different architectures, namely a model with an LSTM encoder without attention and with attention and a BiLSTM model encoder without attention and with attention. Hyperparameter tuning was conducted to obtain the best hyperparameter combination. The experiment results show the best hyperparameter combination obtained is hidden size 448, drop out rate 0.5, learning rate 0.001, batch size 64, and teacher force 0. The model with the best loss is obtained with a BiLSTM encoder architecture without an attention mechanism with a train loss of 0.120. The model with the highest BLEU Score was obtained by a model with a BiLSTM encoder architecture without an attention mechanism with a BLEU Score of 0.8587 on the training data. Testing using prompt testing obtained an average BLEU Score of 0.3745 on the BiLSTM encoder without an attention mechanism model. Finally, the best model architecture obtained in this research is BiLSTM encoder without an attention mechanism.},
  keywords={Attention mechanisms;Force;Bidirectional long short term memory;Training data;Computer architecture;Chatbots;Data models;Space exploration;Tuning;Testing;q&a;text preprocessing;LSTM;BiLSTM;Seq2Seq;closed domain},
  doi={10.1109/EECCIS62037.2024.10840155},
  ISSN={2835-2777},
  month={Oct},}@ARTICLE{10526434,
  author={Trivedi, Chandan and Bhattacharya, Pronaya and Prasad, Vivek Kumar and Patel, Viraj and Singh, Arunendra and Tanwar, Sudeep and Sharma, Ravi and Aluvala, Srinivas and Pau, Giovanni and Sharma, Gulshan},
  journal={IEEE Open Journal of Industry Applications}, 
  title={Explainable AI for Industry 5.0: Vision, Architecture, and Potential Directions}, 
  year={2024},
  volume={5},
  number={},
  pages={177-208},
  abstract={The Industrial Revolution has shifted toward Industry 5.0, reinventing the Industry 4.0 operational process by introducing human elements into critical decision processes. Industry 5.0 would present massive customization via transformative technologies, such as cyber-physical systems (CPSs), artificial intelligence (AI), and big data analytics. In Industry 5.0, the AI models must be transparent, valid, and interpretable. AI models employ machine learning and deep learning mechanisms to make the industrial process autonomous, reduce downtime, and improve operational and maintenance costs. However, the models require explainability in the learning process. Thus, explainable AI (EXAI) adds interpretability and improves the diagnosis of critical industrial processes, which augments the machine-to-human explanations and vice versa. Recent surveys of EXAI in industrial applications are mostly oriented toward EXAI models, the underlying assumptions. Still, fewer studies are conducted toward a holistic integration of EXAI with human-centric processes that drives the Industry 5.0 applicative verticals. Thus, to address the gap, we propose a first-of-its-kind survey that systematically untangles EXAI integration and its potential in Industry 5.0 applications. First, we present the background of EXAI in Industry 5.0 and CPSs and a reference EXAI-based Industry 5.0 architecture with insights into large language models. Then, based on the research questions, a solution taxonomy of EXAI in Industry 5.0 is presented, which is ably supported by applicative use cases (cloud, digital twins, smart grids, augmented reality, and unmanned aerial vehicles). Finally, a case study of EXAI in manufacturing cost assessment is discussed, followed by open issues and future directions. The survey is designed to extend novel prototypes and designs to realize EXAI-based real-time Industry 5.0 applications.},
  keywords={Fifth Industrial Revolution;Artificial intelligence;Surveys;Fourth Industrial Revolution;Data models;Predictive models;Industries;Automation;cobots;cyber-physical systems (CPSs);digital twins (DTs);explainable artificial intelligence (EXAI);Industry 5.0},
  doi={10.1109/OJIA.2024.3399057},
  ISSN={2644-1241},
  month={},}@ARTICLE{10486845,
  author={McDonald, Carol and Carmicino, Bonny and Schildmeyer, Katy and Scott, Emma and Dabolina, Inga},
  journal={Position, Posture, and Pose Definitions for 3D Body Processing}, 
  title={Position, Posture, and Pose Definitions for 3D Body Processing}, 
  year={2024},
  volume={},
  number={},
  pages={1-47},
  abstract={The interchangeable use of the terms position, posture, and pose causes confusion for 3D body processing (3DBP) applications. This paper reviews current definitions and contextual use of these terms to suggest standardized nomenclature for posture and pose. This paper also reviews and discusses possible standard definitions for location, body regions, landmarks, and anatomical relationships. With large language models being central to artificial intelligence (AI), standardized terminology is imperative to all digitization efforts. Replicating, or cloning of, actual posture is a known challenge inhibiting cloned human body models, optimized virtual try-on, and critical fit assessment. 3DBP applications need to be sophisticated enough to accept and utilize unique actual postures, in a given pose, which may vary drastically from a predetermined norm. The discussion builds off of current ISO standards to an open discussion for standards toward posture-improved human body models inclusive of widely varying morphology.},
  keywords={3DBP;3D body processing;body models;definitions;pose;posture;standardized terminology;terminology},
  doi={},
  ISSN={},
  month={March},}@ARTICLE{9878171,
  author={Picinini Méxas, Rodrigo and Rodrigues Leta, Fabiana and Gonzalez Clua, Esteban Walter},
  journal={IEEE Latin America Transactions}, 
  title={Comparison of Reinforcement and Imitation Learning algorithms in autonomous sailboat Digital Twins}, 
  year={2022},
  volume={20},
  number={9},
  pages={2153-2161},
  abstract={This project aims to study the performance of two reinforcement machine learning algorithms, namely the Proximal Policy Optimization and Soft Actor Critic, in the simulation of autonomous sailboats and their response to different wind directions while avoiding obstacles detected by image analysis and following defined target check-points. Also, the effect of the imitation learning algorithms Behavioral Cloning and Generative Adversarial Imitation Learning combined with the first mentioned algorithms is studied. The proposed scenarios consist of areas filled with random static or moving obstacles and with the presence of favorable or crosswinds. The motivation for the project comes from the lack of studies of the mentioned algorithms in autonomous sailboats, issue which the current study tries to address. The Unity platform and ML-Agents machine learning toolkit are used for development and the methodology that guides the project can be similarly applied to other reinforcement learning problems. Through agent training, it is possible to compare the results and observe that the Proximal Policy Optimization obtains better performance within the proposed scenarios, both with and without the support of imitation learning algorithms.},
  keywords={Q-learning;Optimization;Python;Machine learning algorithms;Collision avoidance;Visualization;Tornadoes;reinforcement learning;imitation learning;autonomous sailboat;unmanned surface vehicle},
  doi={10.1109/TLA.2022.9878171},
  ISSN={1548-0992},
  month={Sep.},}@INPROCEEDINGS{10398656,
  author={Vasiliniuc, Mircea-Serban and Groza, Adrian},
  booktitle={2023 IEEE 19th International Conference on Intelligent Computer Communication and Processing (ICCP)}, 
  title={Case study: using AI-assisted code generation in mobile teams}, 
  year={2023},
  volume={},
  number={},
  pages={339-346},
  abstract={We evaluate the performance of AI-assisted programming in mobile development teams that are focused on native mobile languages like Kotlin and Swift. The case study involves 16 participants and 2 technical reviewers, from a software development department and it is designed to understand the impact of using Large Language Models trained for code generation in particular phases of the team, more specifically, technical onboarding and technical stack switch. The study uses technical problems dedicated to each phase and requests solutions from the participants with and without using AI-Code generators. It measures time, correctness, and ‘technical integration’ using a new proposed metric ReviewerScore, extracted from industry standards, the code reviewer of merge/pull requests.The output is converted and analyzed together with feedback from the participants in an attempt to determine if using AI-assisted programming tools will have an impact on getting developers onboard in a project or helping them with a smooth transition between the two native development environments of mobile development, Android and iOS. The study was performed between May and June 2023 with members of the mobile department of a software development company based in Cluj-Napoca, with Romanian ownership and management.},
  keywords={Codes;Switches;Writing;Programming;Generators;Software;Encoding;BigCode;Machine Learning (ML);Large Language Models (LLM);Mobile Development;Swift;Kotlin;Software Development Industry;Code Generation;Text-to-Code},
  doi={10.1109/ICCP60212.2023.10398656},
  ISSN={2766-8495},
  month={Oct},}@ARTICLE{10443461,
  author={Shao, Yunna and Xiang, Bangmeng},
  journal={IEEE Access}, 
  title={Enhancing Bug Report Summaries Through Knowledge-Specific and Contrastive Learning Pre-Training}, 
  year={2024},
  volume={12},
  number={},
  pages={37653-37662},
  abstract={Bug reports are crucial in software maintenance, with concise summaries significantly enhancing the efficiency of bug triagers and ultimately contributing to the development of high-quality software products. Contemporary methods for automatic bug report summarization primarily utilize neural networks’ robust learning capabilities. However, these approaches often produce suboptimal summaries due to two primary limitations: 1) the difficulty in assimilating the domain-specific knowledge inherent in bug reports, and 2) the limitations of purely supervised learning in comprehending the comprehensive context of bug reports. To address the above two problems, in this paper, we propose a new approach for bug report summarization, namely KSCLP, which leverages large language models and domain-specific pre-training strategies, i.e., Knowledge-Specific and Contrastive Learning Pre-training. Specifically, the Knowledge-Specific strategy allows to pre-train KSCLP on project-specific bug reports corpus, by which the model can fully learn internal knowledge of bug reports, learning bug report-aware representation. As for the Contrastive Learning strategy, it performs a sequence-level pre-training for KSCLP, helping it capture the semantic information of bug reports on a global level. Upon completion of the pre-training phase, KSCLP undergoes further refinement through a Sequence-to-Sequence framework specifically tailored for bug report summarization. The efficacy of KSCLP is rigorously evaluated against five baseline models using a publicly available dataset. The empirical results demonstrate that KSCLP outperforms all baselines, achieving remarkable improvements by up to 23.73, 13.97, and 20.89 points in ROUGE-1, ROUGE-2, and ROUGE-L metrics, thereby setting new benchmarks in the field of bug report summarization.},
  keywords={Computer bugs;Task analysis;Codes;Self-supervised learning;Software maintenance;Semantics;Representation learning;Domain specific languages;Computer bugs;Software packages;Bug report summarization;domain-specific pre-training;software maintenance;representation learning},
  doi={10.1109/ACCESS.2024.3368915},
  ISSN={2169-3536},
  month={},}@INBOOK{10880614,
  author={Sharma, Riya and Singh, Balraj and Khamparia, Aditya},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Machine Learning and Generative AI Techniques for Sentiment Analysis with Applications}, 
  year={2025},
  volume={},
  number={},
  pages={183-208},
  abstract={Summary <p>This chapter presents a thorough investigation and examination of machine learning and generative artificial intelligence (AI)&#x2010;based sentiment analysis approaches in the context of social media. As more and more companies use social media platforms for customer involvement and service delivery, it is critical to comprehend the feelings and viewpoints that people are expressing. Although sentiment analysis is a machine learning technique that is skilled in identifying positive and negative sentiment polarities within textual data, due to technological advancements and an increase in the number of data, AI models are becoming popular nowadays. This chapter explores the different approaches used in sentiment analysis, using publications, journals, and scientific research articles. Sentiment analysis can turn an enormous amount of raw data from social media&#x2014;a rich supply of user&#x2010;generated content in a variety of formats, including text, photos, videos, and audio&#x2014;into insightful understandings. To better understand machine learning and generative AI, the study classifies popular research methods and applications from a range of domains.</p>},
  keywords={Sentiment analysis;Social networking (online);Classification algorithms;Unsupervised learning;Lexicon;Training data;Support vector machines;Supervised learning;Probabilistic logic;Principal component analysis},
  doi={10.1002/9781394280735.ch10},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10880614},}@INBOOK{10880623,
  author={Singh, Sudhanshu and Singh, Suruchi and Raghuvanshi, C.S.},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Generating Synthetic Medical Data Using GAI}, 
  year={2025},
  volume={},
  number={},
  pages={51-71},
  abstract={Summary <p>The scene of clinical examination is going through a change in outlook, filled by the extraordinary force of Generative Computerized reasoning (GAI). This part dives into the interesting domain of Producing Manufactured Clinical Information utilizing GAI, investigating reforming healthcare enormous potential. We set out on an excursion directed by the four mainstays of imagination, decisive reasoning, cooperation, and correspondence.</p> <p>Creativity ignites our exploration, as we envision a kaleidoscope of possibilities. From crafting realistic patient populations to simulating intricate disease progressions, GAI paints a vibrant canvas of synthetic data, unconstrained by the limitations of real&#x2010;world cohorts.</p> <p>Decisive reasoning fills in as our compass, guaranteeing we explore this early field with reasonability. We dig into the moral contemplations, possible predispositions, and generalizability challenges intrinsic in manufactured information age. By fundamentally assessing these angles, we prepare for mindful and effective applications. Joint effort turns into the extension that associates assorted points of view. We investigate the collaboration between clinical experts, information researchers, and simulated intelligence trained professionals, underscoring the force of interdisciplinary groups in saddling the maximum capacity of GAI for clinical information age. Correspondence shapes the extension between the specialized complexities and the more extensive clinical local area. We endeavor to introduce complex ideas in an open and drawing in way, cultivating an exchange that engages specialists, clinicians, and general society to comprehend and use the extraordinary force of manufactured clinical information. This section isn't only a specialized piece; it is a solicitation to an ensemble of innovativeness, decisive reasoning, joint effort, and correspondence. Together, we can open the tremendous capability of GAI in creating manufactured clinical information, pushing medical care towards a future overflowing with conceivable outcomes. <ul> <li>Crafted with Creativity Imagine a world where AI conjures realistic patient cohorts, mirroring the intricate tapestry of human health and disease. We'll investigate GAI's kaleidoscope of strategies, from Contingent Generative Ill&#x2010;disposed Organizations (cGANs) that paint clear pictures of clinical imaging to Variational Autoencoders (VAEs) that murmur the mysteries concealed inside hereditary information. We should release our creative mind and investigate the unfamiliar regions of engineered information age, where illness displaying and drug revelation waltz connected at the hip.</li> <li>Fueled by Critical Thinking But venturing into the synthetic realm demands a discerning eye. We'll fastidiously take apart the moral contemplations and expected traps of GAI&#x2010;produced information, guaranteeing it fills in as a dependable reflection, not a mutilated mirror, of human wellbeing. We'll consider the fragile dance between information constancy and security, and investigate strategies to relieve inclination and guarantee the mindful utilization of this incredible asset.</li> <li>Rooted in Collaboration This journey is not meant to be traversed alone. We'll praise the soul of coordinated effort, cultivating associations between specialists, clinicians, and simulated intelligence specialists. Envision interdisciplinary groups, where clinical aptitude guides artificial intelligence advancement, and man&#x2010;made intelligence bits of knowledge enlighten clinical practice. We'll investigate open&#x2010;source stages and information sharing drives, building spans that prepare for aggregate advancement.</li> <li>Articulated with Clarity Our narrative unfolds with clear, concise language, accessible to a diverse audience. We'll make an interpretation of perplexing specialized ideas into absorbable exposition, guaranteeing that the groundbreaking capability of GAI resounds with everybody, from prepared scientists to inquisitive understudies.</li> <li>Creative Ideas for the Chapter Patient Avatar Generation: Describe a GAI system that creates personalized patient avatars, complete with medical histories, genetic profiles, and virtual responses to treatment interventions. Disease Progression Simulation: Showcase a GAI model that simulates the real&#x2010;time progression of complex diseases, enabling researchers to test treatment strategies in a virtual environment. Drug Discovery Acceleration: Explore how GAI&#x2010;generated synthetic data can be used to virtually screen millions of potential drug candidates, significantly accelerating the drug discovery process. Personalized Medicine Advancements: Discuss how synthetic data can be used to tailor treatment plans to individual patients, ushering in a new era of personalized medicine. Ethical Considerations and Societal Impact: Dedicate a section to the ethical considerations and potential societal impacts of GAI&#x2010;generated medical data, fostering responsible and inclusive applications.</li> </ul> </p>},
  keywords={Biomedical imaging;Diseases;Data privacy;Autoencoders;Artificial intelligence;Paints;Genetics;Generators;Ethics;Wrist},
  doi={10.1002/9781394280735.ch3},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10880623},}@ARTICLE{10772566,
  author={Obite, Felix and Krayani, Ali and Alam, Atm S. and Marcenaro, Lucio and Nallanathan, Arumugam and Regazzoni, Carlo},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Exploring Active Inference for Efficient Resource Allocation in UAV-Enabled Cognitive NOMA Uplink}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={The integration of unmanned aerial vehicles (UAVs), cognitive radio (CR), and non-orthogonal multiple access (NOMA) presents a promising solution to significantly enhance the performance of future wireless networks. Achieving this integration requires cognitive self-awareness for intelligent resource allocation. In this paper, we address the problem of sum rate maximization in UAV-enabled cognitive NOMA uplink systems through the joint optimization of subchannel assignment and power allocation, while considering the UAV’s mobility. The traditional approach to finding the optimal solution requires an iterative or exhaustive search across all possible combinations of subchannel assignment, power allocation, and UAV position at each time slot, leading to excessive computational complexity. Furthermore, machine learning models, often trained on datasets that do not fully capture the complexity of real-world scenarios, struggle to handle non-stationary events effectively. To solve this nonconvex optimization challenge, we draw inspiration from active inference in cognitive neuroscience and propose a novel data-driven approach called the Active Generalized Dynamic Bayesian Network (Active-GDBN). The main idea is to process the unknown nonlinear input of an exhaustive search optimization algorithm using an Active-GDBN framework. This framework leverages a probabilistic generative model to learn the complex relationships and dependencies among subchannel assignments, power distributions, and the UAV’s mobility. The model is facilitated by continuous neuronal message passing in both discrete and continuous states to predict the optimal configuration. Numerical results show that the proposed approach achieves sum rate performance near the optimal exhaustive search and surpasses other baseline approaches.},
  keywords={NOMA;Autonomous aerial vehicles;Resource management;Wireless networks;Optimization;Throughput;Heuristic algorithms;Computational modeling;Uplink;Inference algorithms;Active inference;generalized dynamic Bayesian network (GDBN);resource allocation;UAV;cognitive-NOMA},
  doi={10.1109/TCCN.2024.3510577},
  ISSN={2332-7731},
  month={},}@INPROCEEDINGS{11016327,
  author={Ordoumpozanis, Kostas and Apostolidis, Hippokratis},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={A Second-Generation Agentic Framework for Generative Ai-Driven Augmented Reality Educational Games}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This paper presents a multi-agent collaborative framework with human-in-the-loop integration for creating educational augmented reality (AR) serious games. It provides a detailed analysis of the system's internal modules, agents, and tools, highlighting its complexity. This work focuses on the design phase, while implementation of the framework is yet to be developed. The framework consists of four main modules: Data Management,Narrative Crafting, Content Generation, and Game Creation. It uses the Scratch-pad as a shared memory to manage agent communication and long-context data, guiding agents step-by-step in the game-building process. The framework also incorporates short- and long-term memory to improve agent performance over time. Additionally, it integrates Generative AI (Gen-AI) models for asset creation in immersive games. The analysis reveals the system's complexity and the numerous hyper-parameters that need further study at both technical and user experience levels. This study invites other researchers to contribute to this framework, aiming to develop a collaborative educational tool that removes technical barriers and empowers teachers and students to create and engage with immersive interactive learning experiences.},
  keywords={Generative AI;Memory management;Collaboration;Games;Transforms;Human in the loop;User experience;Complexity theory;Serious games;Augmented reality;AI Agents;Augmented Reality;Serious Games;Short-term;long-term;memory},
  doi={10.1109/EDUCON62633.2025.11016327},
  ISSN={2165-9567},
  month={April},}@ARTICLE{10964151,
  author={Yang, Wanting and Xiong, Zehui and Guo, Song and Mao, Shiwen and Kim, Dong In and Debbah, Merouane},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Efficient Multi-user Offloading of Personalized Diffusion Models: A DRL-Convex Hybrid Solution}, 
  year={2025},
  volume={},
  number={},
  pages={1-17},
  abstract={Generative diffusion models like Stable Diffusion are at the forefront of the thriving field of generative models today, celebrated for their robust training methodologies and high-quality photorealistic generation capabilities. These models excel in producing rich content, establishing them as essential tools in the industry. Building on this foundation, the field has seen the rise of personalized content synthesis as a particularly exciting application. However, the large model sizes and iterative nature of inference make it difficult to deploy personalized diffusion models broadly on local devices with heterogeneous computational power. To address this, we propose a novel framework for efficient multi-user offloading of personalized diffusion models. This framework accommodates a variable number of users, each with different computational capabilities, and adapts to the fluctuating computational resources available on edge servers. To enhance computational efficiency and alleviate the storage burden on edge servers, we propose a tailored multi-user hybrid inference approach. This method splits the inference process for each user into two phases, with an optimizable split point. Initially, a cluster-wide model processes low-level semantic information for each user's prompt using batching techniques. Subsequently, users employ their personalized models to refine these details during the later phase of inference. Given the constraints on edge server computational resources and users' preferences for low latency and high accuracy, we model the joint optimization of each user's offloading request handling and split point as an extension of the Generalized Quadratic Assignment Problem (GQAP). Our objective is to maximize a comprehensive metric that balances both latency and accuracy across all users. To solve this NP-hard problem, we transform the GQAP into an adaptive decision sequence, model it as a Markov decision process, and develop a hybrid solution combining deep reinforcement learning with convex optimization techniques. Simulation results validate the effectiveness of our framework, demonstrating superior optimality and low complexity compared to traditional methods. All related code, datasets, and fine-tuned models are available at https://github.com/wty2011jl/E-MOPDM.},
  keywords={Computational modeling;Diffusion models;Noise reduction;Servers;Measurement;Adaptation models;Accuracy;Semantics;Optimization;Inference algorithms;Diffusion model;edge offloading;generalized quadratic assignment problem;DRL;AIGC service;hybrid inference},
  doi={10.1109/TMC.2025.3560582},
  ISSN={1558-0660},
  month={},}@ARTICLE{10536869,
  author={Rekanar, Kaavya and Ahmed, Abbirah and Mohandas, Reenu and Sistu, Ganesh and Eising, Ciarán and Hayes, Martin},
  journal={IEEE Access}, 
  title={Subjective Scoring Framework for VQA Models in Autonomous Driving}, 
  year={2024},
  volume={12},
  number={},
  pages={141306-141323},
  abstract={The development of vision and language transformer models has paved the way for Visual Question Answering (VQA) models and related research. There are metrics to assess the general accuracy of VQA models but subjective assessment of the answers generated by the models is necessary to gain an in-depth understanding and a framework for subjective assessment is required. This work develops a novel scoring system based on the subjectivity of the question and analyses the answers provided by the model using multiple types of natural language processing models (bert-base-uncased, nli-distilBERT-base, all-mpnet-base-v2 and GPT-2) and sentence similarity benchmark metrics (Cosine Similarity). A case study detailing the use of the proposed subjective scoring framework on three prominent VQA models- ViLT, ViLBERT, and LXMERT using an automotive dataset is also presented. The framework proposed aids in analyzing the shortcomings of the discussed VQA models from a driving perspective and the results achieved help determine which model would work best when fine-tuned on a driving-specific VQA dataset.},
  keywords={Autonomous vehicles;Measurement;Visualization;Analytical models;Intelligent vehicles;Data models;Task analysis;Semantics;Question answering (information retrieval);Visualization;Semantic analysis;scoring framework;subjective assessment;VQA models},
  doi={10.1109/ACCESS.2024.3404349},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10143584,
  author={Rao, Jian and Qiu, Chuqi and Xiong, Mengzhen},
  booktitle={2022 3rd International Conference on Information Science and Education (ICISE-IE)}, 
  title={Research on Image Processing and Generative Teaching in the Context of AIGC}, 
  year={2022},
  volume={},
  number={},
  pages={20-25},
  abstract={AIGC, meaning AI-generated content, is discussed in this paper, mainly in the form of painting, without discussing the automation of music composition and text-writing poetry, etc. While generative art has aesthetic characteristics, more content needs to be studied in the context of computer information science, with a particular emphasis on computer vision and computer graphics. The article focuses on a comparative analysis of two models, diffusion algorithms and generative adversarial networks, and their application to tools. The practical part of image processing uses a combination of case studies and questionnaires to demonstrate the lack of methodology, teaching experience, and introductory learning materials for non-computer professionals in the emerging field, and to explain “filter mapping” through Processing, a visual programming software. The author’s reflections on the generated content combine the self-similarity of the “Uncanny Valley effect” and the “Dunning Kruger effect” lineage, comparing the “self-organizing” (machine) simulation personification and the “life form” (human) simulation personification. The process of cognitive assimilation of a “living organism” (human) is used to understand the new human-machine associative relationship.},
  keywords={Information science;Visualization;Art;Image processing;Education;Semantics;Software;AIGC;Disco Diffusion;Processing;Generative art;semantic mapping},
  doi={10.1109/ICISE-IE58127.2022.00011},
  ISSN={},
  month={Nov},}@ARTICLE{10684193,
  author={Kuhail, Mohammad Amin and Berengueres, Jose and Taher, Fatma and Khan, Sana Zeb and Siddiqui, Ansah},
  journal={IEEE Access}, 
  title={Designing a Haptic Boot for Space With Prompt Engineering: Process, Insights, and Implications}, 
  year={2024},
  volume={12},
  number={},
  pages={134235-134255},
  abstract={Recent literature indicates the potential of applying Artificial Intelligence (AI) tools to enhance ideation outcomes and optimize functionality across various engineering disciplines. However, a comprehensive understanding of applying AI in the design process is lacking, particularly regarding projects involving innovative design. Here, we address the integration of AI in a case study project. The project goal is to design a haptic boot to be used on Mars. We apply a popular AI tool, ChatGPT-3.5, to each design step, from the requirement gathering phase to the prototyping and testing phase. To assess the merit of the AI contributions, we asked eight domain experts to give qualitative feedback. The results indicate that current AI tools can provide a valuable starting point in the requirements and design phases. However, we noted instances of hallucinations and poor traceability. Finally, the experts’ evaluation points out that the AI-proposed requirements and design are missing key elements expected as an outcome in an engineering design process. This study offers insight into the practical application of AI through a specific engineering design process.},
  keywords={Artificial intelligence;Prompt engineering;Haptic interfaces;Education;Chatbots;Industries;Software engineering;AI;ChatGPT;design;engineering;space;haptics},
  doi={10.1109/ACCESS.2024.3449396},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10987974,
  author={Patil, Bhavesh and Yadav, Gitanjali B and Buchade, Amar and Borkar, Soham and Bhosale, Shreyash and Honbute, Vikrant},
  booktitle={2025 International Conference on Emerging Smart Computing and Informatics (ESCI)}, 
  title={Dynamic StarCraft: Multi-Agent Generative AI for Immersive Experiences}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The present research reveals a unique educational approach through the use of Generative Artificial Intelligence (GenAI) with the focus on storytelling with children. It is shown that by adding GenAI narrative co-creation, voice-over synthesis, and video audition to the system, the learning process becomes interesting. We understand how the audience creates the stories with which they will perform, how the stories are narrated in audio created with advanced text-to-speech systems, and how images for the narratives are generated with text-to-video. Our assessment is however concerned with the level of the languages used in writing the stories, how the stories written were pronounced and the images that were produced, as we point out the ability of the tool to entertain young learners.},
  keywords={Measurement;Generative AI;Refining;Pipelines;Layout;Media;Writing;Software;Text to speech;Text to video;GenAI;LLM;Text-To-Speech(TTS);Text-to-Video(TTV);TTM},
  doi={10.1109/ESCI63694.2025.10987974},
  ISSN={2996-1815},
  month={March},}@INPROCEEDINGS{10489028,
  author={Saeed, Abdullah and Dhanda, Namrata and Rao, Ansh Samuel and Verma, Rajat},
  booktitle={2024 2nd International Conference on Disruptive Technologies (ICDT)}, 
  title={AI-Enabled Semantic Web}, 
  year={2024},
  volume={},
  number={},
  pages={1136-1141},
  abstract={The paper presents a comprehensive study on the development of an AI-enabled Semantic Search application using a Full Stack approach. The project integrates cutting-edge technologies, such as Next.js, Langchain, Pinecone, and ChatGPT, to create a robust and efficient information retrieval system. The methodology begins by setting up the essential imports and utility functions for Langchain and Pinecone. Diverse data types are then loaded seamlessly using specialized loaders. The project's core involves the creation of a Pinecone index and successfully uploading documents, which establishesa powerful and accessible database. The application's user interface can be enriched with advanced UI features. These features enhance the aesthetic appeal and interactivity of the platform, facilitating user navigation and query formulation. The implemented technique discusses the challenges of developing an AI-enabled Semantic Search application, such as the need to deal with large volumes of data and the complexity of natural language processing, and suggests solutions to these challenges, such as using distributed computing and machine learning techniques. The culmination of these efforts is a comprehensive Semantic Search application that leverages the capabilities of AI and modern web technologies to deliver an immersive, efficient, and personalized information retrieval experience. This research contributes to the advancement of full-stack development practices and demonstrates the potential of integrating AI technologies to enhance user interactions with data-rich platforms.},
  keywords={Semantic Web;Systematics;Semantic search;Navigation;Transforms;Search engines;User interfaces;LangChain;LLMs;Semantic Search;Text Embedding;Web},
  doi={10.1109/ICDT61202.2024.10489028},
  ISSN={},
  month={March},}@ARTICLE{10213396,
  author={Bull, Christopher and Kharrufa, Ahmed},
  journal={IEEE Software}, 
  title={Generative Artificial Intelligence Assistants in Software Development Education: A Vision for Integrating Generative Artificial Intelligence Into Educational Practice, Not Instinctively Defending Against It}, 
  year={2024},
  volume={41},
  number={2},
  pages={52-59},
  abstract={The use of Generative AI in software development is gaining traction. But what are the potentials and implications on software development education? We gathered insights on the use of Generative AI from professional software developers and make some pedagogical recommendations.},
  keywords={Codes;Chatbots;Software development management;Programming profession;Artificial intelligence;Generative AI;Computer science education;Social implications of technology;Programming profession;Educational programs;Education;Software engineering;Problem-solving;Training},
  doi={10.1109/MS.2023.3300574},
  ISSN={1937-4194},
  month={March},}@ARTICLE{10598190,
  author={Carvalko, Joseph R.},
  journal={IEEE Transactions on Technology and Society}, 
  title={Generative AI, Ingenuity, and Law}, 
  year={2024},
  volume={5},
  number={2},
  pages={169-182},
  abstract={This paper discusses generative pre-trained transformer technology and its intersection with forms of creativity and law. It highlights the potential of generative AI to change considerable elements of society, including modes of creative endeavors, problem-solving, employment, education, justice, medicine, and governance. The author emphasizes the need for policymakers and experts to join in regulating against the potential risks and implications of this technology. The European Commission has taken steps to address the risks of AI through the European AI Act (EIA), which categorizes AI uses based on their potential harm. The legislation aims to ensure scrutiny and control in extreme cases like autonomous weapons or medical devices. However, the author criticizes the lack of meaningful AI oversight in the United States and argues that time has come for government to step in and offer meaningful regulation given the technology’s (1) rate of diffusion (2) virtually uncountable product permutations, the purposes, extent and depths to which it is anticipated to penetrate institutional and daily life.},
  keywords={Generative AI;Artificial intelligence;Ethics;Internet;Chatbots;Deep learning;Neural networks;Regulation;Problem-solving;Employment;Education;Europe;Creativity;Social implications of technology;Risk management;Artificial intelligence;computation and language;deep learning neural networks;NLP;LLM;OpenAI;ChatGPT;generative AI;generative pretrained transformer;transformer-based AI;European AI Act;EIA;technology ethics},
  doi={10.1109/TTS.2024.3413591},
  ISSN={2637-6415},
  month={June},}@INPROCEEDINGS{10836028,
  author={Ahmed, Waqas and Sentosa, Ilham and Hizam, Sheikh Muhamad and Mat, Che Rosmawati Che and Hernandez, Martin Spraggon},
  booktitle={2023 International Conference on Data, Information and Computing Science (CDICS)}, 
  title={Evaluating the Acceptance of Enhanced Generative AI Services}, 
  year={2023},
  volume={},
  number={},
  pages={73-77},
  abstract={The rapid advancement of artificial intelligence (AI) has introduced a spectrum of generative AI services that promise to enhance various professional and personal tasks. This study aims to explore the factors influencing users’ intentions to transition from basic to premium generative AI services, focusing on Performance Expectancy (PE), Technology Self-Efficacy (TSE), Personal Innovativeness (PI), and Social Influence (SI). A survey of 193 individuals, primarily university students with an IT background, revealed that PE, TSE, and SI significantly affect the Behavioral Intention (BI) to adopt enhanced services, with SI being the most influential. Contrary to expectations, PI did not predict BI, indicating that innovation alone does not drive the adoption of advanced AI capabilities. The findings suggest that the practicality of AI tools, user confidence in their technical skills, and the persuasive power of social networks are pivotal in the decision-making process for upgrading AI services. This research contributes to the understanding of AI adoption patterns and provides insights for developers and marketers to tailor user experiences and educational initiatives that align with user needs and social dynamics. It also underscores the importance of addressing ethical considerations as AI continues to permeate various aspects of society.},
  keywords={Surveys;Technological innovation;Ethics;Generative AI;Social networking (online);Decision making;Focusing;Chatbots;Generative AI;ChatGPT;Technology Acceptance;User Behavior;Social Influence},
  doi={10.1109/CDICS61497.2023.00022},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10972692,
  author={Bosser, Anne-Gwenn and Cascarano, Pasquale and Lacoche, Jérémy and Hajahmadi, Shirin and Stanescu, Ana and Sörös, Gábor},
  booktitle={2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={Preface to the First Workshop on GenAI-XR: Generative Artificial Intelligence meets Extended Reality}, 
  year={2025},
  volume={},
  number={},
  pages={129-130},
  abstract={The GenAI-XR workshop aims to explore the intersection of Generative Artificial Intelligence (GenAI) and Extended Reality (XR), examining their combined potential to revolutionize various sectors including entertainment, arts, education, factory work, healthcare, architecture, and others. The workshop will provide a platform for researchers, industry professionals, and practitioners to discuss innovative methods of integrating GenAI into XR environments, enhancing immersive experiences, and personalizing interactions in real time. Through presentation and discussion sessions, participants will gain insights into the latest developments, challenges, and future directions at the intersection of GenAI and XR.},
  keywords={Three-dimensional displays;Extended reality;Generative AI;Conferences;Education;Entertainment industry;Medical services;User interfaces;Real-time systems;Production facilities;IndexTerms: Generative Artificial Intelligence;Extended Reality;Artificial Intelligence and Extended Reality Integration;Personalized Interactions;Adaptive Environments;Context-Aware Systems},
  doi={10.1109/VRW66409.2025.00033},
  ISSN={},
  month={March},}@INPROCEEDINGS{10569755,
  author={Vlahović, N. and Košanski, M. and Glavan, Lj. Milanović},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Reinventing Mobile-assisted Language Learning using Natural Language Processing}, 
  year={2024},
  volume={},
  number={},
  pages={398-403},
  abstract={Mobile-assisted Language Learning (MALL) is a trend in language acquisition through informal learning supported by mobile devices. The transition from the previous generation of software solutions, Computer-Assisted Language Learning applications or CALL applications, was characterized usually by direct translation of known functionalities from stationary hardware to mobile hardware without taking into account all of the capabilities of mobile devices while creating and implementing various mechanisms for language acquisitions. Additionally, natural language processing technologies have reached level of maturity even more recently and as such have not been used on a larger scope to enrich the approaches to language acquisition. In this paper we will investigate several possible concepts that utilize natural language processing capabilities with mobile technology in order to provide more variety and enhance engagement in informal language learning process. The main goal of the paper is to present several types of activities that aim to reinvent mobile-assisted language learning using generative AI for text-to-speech and speech-to-text functionalities provided by natural language processing. Additionally, we will also present a study of attitudes of students toward the presented solutions and innovations. Results testify that student population assesses these approaches as useful, refreshing and engaging.},
  keywords={Surveys;Technological innovation;Sociology;Prototypes;Natural language processing;Software;Mobile handsets;Educational software;Foreign Language Learning;Natural language processing (NLP);Generative AI;Informal Learning;Software engineering},
  doi={10.1109/MIPRO60963.2024.10569755},
  ISSN={2623-8764},
  month={May},}@INPROCEEDINGS{9870312,
  author={Tao, Ning and Ventresque, Anthony and Saber, Takfarinas},
  booktitle={2022 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Multi-objective Grammar-guided Genetic Programming with Code Similarity Measurement for Program Synthesis}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Grammar-Guided Genetic Programming (G3P) is widely recognised as one of the most successful approaches for program synthesis, i.e., the task of automatically discovering an executable piece of code given user intent. G3P has been shown capable of successfully evolving programs in arbitrary languages that solve several program synthesis problems based only on a set of input/output examples. Despite its success, the restriction on the evolutionary system to only leverage input/output error rate during its assessment of the programs it derives limits its scalabil-ity to larger and more complex program synthesis problems. With the growing number and size of open software repositories and generative artificial intelligence approaches, there is a sizeable and growing number of approaches for retrieving/generating source code (potentially several partial snippets) based on textual problem descriptions. Therefore, it is now, more than ever, time to introduce G3P to other means of user intent (particularly textual problem descriptions). In this paper, we would like to assess the potential for G3P to evolve programs based on their similarity to particular target codes of interest (obtained using some code retrieval/generative approach). Through our experimental evaluation on a well-known program synthesis benchmark, we have shown that G3P successfully manages to evolve some of the desired programs with all four considered similarity measures. However, in its default configuration, G3P is not as successful with similarity measures as it is with the classical input/output error rate when solving program synthesis problems. Therefore, we propose a novel multi-objective G3P approach that combines the similarity to the target program and the traditional input/output error rate. Our experiments show that compared to the error-based G3P, the multi-objective G3P approach could improve the success rate of specific problems and has great potential to improve on the traditional G3P system.},
  keywords={Codes;Error analysis;Measurement uncertainty;Genetic programming;Evolutionary computation;Benchmark testing;Software;Program Synthesis;Grammar-Guided Genetic Programming;Code Similarity;Multi-Objective Optimization},
  doi={10.1109/CEC55065.2022.9870312},
  ISSN={},
  month={July},}@ARTICLE{10908885,
  author={Zhu, Dandan and Zhang, Kaiwei and Min, Xiongkuo and Zhai, Guangtao and Yang, Xiaokang},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={ScanDTM: A Novel Dual-Temporal Modulation Scanpath Prediction Model for Omnidirectional Images}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Scanpath prediction for omnidirectional images aims to effectively simulate the human visual perception mechanism to generate dynamic realistic fixation trajectories. However, the majority of scanpath prediction methods for omnidirectional images are still in their infancy as they fail to accurately capture the time-dependency of viewing behavior and suffer from sub-optimal performance along with limited generalization capability. A desirable solution should achieve a better trade-off between prediction performance and generalization ability. To this end, we propose a novel dual-temporal modulation scanpath prediction (ScanDTM) model for omnidirectional images. Such a model is designed to effectively capture long-range time-dependencies between various fixation regions across both internal and external time dimensions, thereby generating more realistic scanpaths. In particular, we design a Dual Graph Convolutional Network (Dual-GCN) module comprising a semantic-level GCN and an image-level GCN. This module servers as a robust visual encoder that captures spatial relationships among various object regions within an image and fully utilizes similar images as complementary information to capture similarity relations across relevant images. Notably, the proposed Dual-GCN focuses on modeling temporal correlations from both local and global perspectives within the internal time dimension. Furthermore, drawing inspiration from the promising generalization capabilities of diffusion models across various generative tasks, we introduce a novel diffusion-guided saliency module. This module formulates the prediction issue as a conditional generative process for the saliency map, utilizing extracted semantic-level and image-level visual features as conditions. With the well-designed diffusion-guided saliency module, our proposed ScanDTM model acting as an external temporal modulator, we can progressively refine the generated scanpath from the noisy map. We conduct extensive experiments on several benchmark datasets, and the results demonstrate that our ScanDTM model significantly outperforms other competitors. Meanwhile, when applied to tasks such as saliency prediction and image quality assessment, our ScanDTM model consistently achieves superior generalization performance.},
  keywords={Visualization;Predictive models;Feature extraction;Modulation;Solid modeling;Correlation;Trajectory;Electronic mail;Training;Face recognition;Scanpath prediction;dual graph convolutional network;diffusion model;dual temporal modulator;omnidirectional image},
  doi={10.1109/TCSVT.2025.3545908},
  ISSN={1558-2205},
  month={},}@INPROCEEDINGS{10590319,
  author={Gao, Weizheng and Allagan, Julian D. and Gao, Shanzhen and Su, Jianning and Malomo, Olumide and Eyob, Ephrem and Adekoya, Adeyemi},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Problem-Solving Using Logic and Reasoning, Mathematics, Algorithms, Python and Generative AI}, 
  year={2023},
  volume={},
  number={},
  pages={371-377},
  abstract={Problem-solving is essential in various fields, including business, technology, and everyday life. It often involves a combination of experience, knowledge, intuition, and rational analysis. Furthermore, it requires integrating disciplines such as logic and reasoning, mathematics, algorithms, Python, and generative AI in today's complex world. We will provide detailed descriptions of how to solve problems based on integrating previously mentioned disciplines. Later, we will discuss how to guide students through making intelligent investment decisions.},
  keywords={Generative AI;Scientific computing;Programming;Mathematics;Cognition;Problem-solving;Logic;Problem-Solving;intelligent decision-making;generative AI;ChatGPT;Python Programming Language;logic and reasoning;mathematics;algorithms},
  doi={10.1109/CSCI62032.2023.00066},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{11004879,
  author={Chaudhary, Jyoti and A V, Vijaya Kumar and K, Manikannan and Sapatnekar, Amol and Barve, Amit and Maranan, Ramya},
  booktitle={2025 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={Enhanced Software Defect Prediction using Quantum Hamiltonian Generative Adversarial Network for Improved Software Performance Reliability}, 
  year={2025},
  volume={},
  number={},
  pages={1047-1052},
  abstract={The development of software systems with high quality and decreased maintenance costs depends on Software Defect Prediction (SDF). The current dataset qualities combined with feature redundancies make confident fault detection difficult through conventional methods. Current defect prediction techniques display multiple deficits through inaccurate results along with many false alarms and dataset bias. A high-performance quantum-inspired method must be researched in working to create an accurate precision model. The project will create the Enhanced Software Defect Prediction using Quantum Hamiltonian Generative Adversarial Network for Improved Software Performance Reliability (DBO-QH-GAN) model. Several software metrics need to be retrieved from the PROMISE datasets before this process can be initiated. The second step includes Fuzzy K- Top Matcher (FK- TM) functionality that removes undesirable noise factors such as redundant features and missing values as well as outliers. The Botox Optimization (BotO) algorithm selects five essential metrics that encompass cyclomatic complexity as well as Halstead measures and coupling and code churn and historical defect density. These preprocessed set of characteristics are fed to a Quantum Hamiltonian Generative Adversarial Network (QH-GAN) which identifies the defects from probabilistic thresholding and thereafter optimized using Duck Bevy Optimization (DBO) to achieve the optimal possible performance. Accuracy of the model was 99.2%, precision was 99.4%, and recall was 99.1 %. The DBO-QH-GAN model sets new standards for defect prediction by providing an improved enhancement of reliability along with decreased maintenance cost.},
  keywords={Quantum computing;Costs;Accuracy;Software performance;Predictive models;Generative adversarial networks;Software reliability;Maintenance;Optimization;Standards;Botox Optimization;Duck Bevy Optimization;Fuzzy K-Top Matcher;Quantum Hamiltonian Generative Adversarial Network;PROMISE;Software Defect Prediction},
  doi={10.1109/ICICT64420.2025.11004879},
  ISSN={2767-7788},
  month={April},}@INPROCEEDINGS{10796462,
  author={Albano, Norberto and Brignone, Sandro},
  booktitle={2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={Exploring Bias in Text-to-Image Models: From Body Representation of Teenage Students to Perspectives for the Aging Society}, 
  year={2024},
  volume={},
  number={},
  pages={1212-1217},
  abstract={Starting from the results of a study on body shaming conducted between Italy and Romania in ay 2020/21, this investigation explores the presence of bias in images produced by generative Text-To-Image (TTI) models. Specifically, it proposes an analysis and evaluation of the representation of adolescent students' bodies in the outputs of two different TTI systems, highlighting social, cultural, and technological factors. The findings reveal significant biases in the representations of students, with notable differences between the platforms examined, and underline the need for targeted educational interventions to counter distorted perceptions of the body. This research provides a reflective contribution on the impact of TTIs on society and on the representation of body image that extends to different social and demographic categories, among these, the elderly, who are often victims or passive users of these technologies.},
  keywords={Training;Biological system modeling;Social sciences;Text to image;Neural engineering;Aging;Metrology;Cultural differences;Older adults;Investment;Artificial Intelligence;TTI Models;Fairness;Bias;Body Representation and Perception;Body Shaming;Education and Awareness},
  doi={10.1109/MetroXRAINE62247.2024.10796462},
  ISSN={},
  month={Oct},}@ARTICLE{10777917,
  author={Staron, Miroslaw and Abraháo, Silvia and Serebrenik, Alexander and Penzenstadler, Birgit and Horkoff, Jennifer and Honnenahalli, Chetan},
  journal={IEEE Software}, 
  title={Laws, Ethics, and Fairness in Software Engineering}, 
  year={2025},
  volume={42},
  number={1},
  pages={110-113},
  abstract={Software engineering in the era of generative AI, large data sets and superfast pace of software development often tends to focus on technology, tools and methods, putting aside us, software engineers. In this column, we focus on softer aspects of software engineering and report from two conferences: 28th International Conference on Evaluation and Assessment in Software Engineering (EASE 2024) and 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM 2024). The selection of papers provides a glimpse on handling privacy, documenting ethical considerations in AI models and trustworthy AI.},
  keywords={Ethics;Privacy;Generative AI;Software measurement;Software engineering;Software development management;Artificial intelligence},
  doi={10.1109/MS.2024.3469488},
  ISSN={1937-4194},
  month={Jan},}@INPROCEEDINGS{9835627,
  author={Chakrabarty, Krishnendu},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={EDAML 2022 Invited Speaker 4: Fault Criticality Assessment in AI Accelerators}, 
  year={2022},
  volume={},
  number={},
  pages={1185-1185},
  abstract={Summary form only. The ubiquitous application of deep neural networks (DNN) has led to a rise in demand for AI accelerators. DNN-specific functional criticality analysis identifies faults that cause measurable and significant deviations from acceptable requirements such as the inferencing accuracy. This talk will examine the problem of classifying structural faults in the processing elements (PEs) of systolic-array accelerators. The speaker will first present a two-tier machine-learning (ML) based method to assess the functional criticality of faults. The problem of minimizing misclassification will be addressed by utilizing generative adversarial networks (GANs). The two- tier ML/GAN-based criticality assessment method leads to less than 1% test escapes during functional criticality evaluation of structural faults. While supervised learning techniques can be used to accurately estimate fault criticality, it requires a considerable amount of ground truth for model training. The speaker will therefore present a neural-twin framework for analyzing fault criticality with a negligible amount of ground-truth data. A recently proposed misclassification-driven training algorithm will be used to sensitize and identify biases that are critical to the functioning of the accelerator for a given application workload. The proposed framework achieves up to 100% accuracy in fault-criticality classification in 16-bit and 32-bit PEs by using the criticality knowledge of only 2% of total faults in a PE.},
  keywords={Circuit faults;AI accelerators;Technological innovation;Distributed processing;Circuits and systems},
  doi={10.1109/IPDPSW55747.2022.00197},
  ISSN={},
  month={May},}@ARTICLE{10669782,
  author={Castelo, Sonia and Rulff, Joao and Solunke, Parikshit and McGowan, Erin and Wu, Guande and Roman, Iran and Lopez, Roque and Steers, Bea and Sun, Qi and Bello, Juan and Feest, Bradley and Middleton, Michael and Mckendrick, Ryan and Silva, Claudio},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={HuBar: A Visual Analytics Tool to Explore Human Behavior Based on fNIRS in AR Guidance Systems}, 
  year={2025},
  volume={31},
  number={1},
  pages={119-129},
  abstract={The concept of an intelligent augmented reality (AR) assistant has significant, wide-ranging applications, with potential uses in medicine, military, and mechanics domains. Such an assistant must be able to perceive the environment and actions, reason about the environment state in relation to a given task, and seamlessly interact with the task performer. These interactions typically involve an AR headset equipped with sensors which capture video, audio, and haptic feedback. Previous works have sought to facilitate the development of intelligent AR assistants by visualizing these sensor data streams in conjunction with the assistant's perception and reasoning model outputs. However, existing visual analytics systems do not focus on user modeling or include biometric data, and are only capable of visualizing a single task session for a single performer at a time. Moreover, they typically assume a task involves linear progression from one step to the next. We propose a visual analytics system that allows users to compare performance during multiple task sessions, focusing on non-linear tasks where different step sequences can lead to success. In particular, we design visualizations for understanding user behavior through functional near-infrared spectroscopy (fNIRS) data as a proxy for perception, attention, and memory as well as corresponding motion data (acceleration, angular velocity, and gaze). We distill these insights into embedding representations that allow users to easily select groups of sessions with similar behaviors. We provide two case studies that demonstrate how to use these visualizations to gain insights about task performance using data collected during helicopter copilot training tasks. Finally, we evaluate our approach through an in-depth examination of a think-aloud experiment with five domain experts.},
  keywords={Data visualization;Behavioral sciences;Functional near-infrared spectroscopy;Sensors;Time series analysis;Data models;Visual analytics;Perception & Cognition;Application Motivated Visualization;Temporal Data;Image and Video Data;AR/VR/Immersive},
  doi={10.1109/TVCG.2024.3456388},
  ISSN={1941-0506},
  month={Jan},}@INPROCEEDINGS{10943733,
  author={Mukherjee, Anjishnu and Zhu, Ziwei and Anastasopoulos, Antonios},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Crossroads of Continents: Automated Artifact Extraction for Cultural Adaptation with Large Multimodal Models}, 
  year={2025},
  volume={},
  number={},
  pages={1755-1764},
  abstract={We present a comprehensive three-phase study to ex-amine (1) the cultural understanding of Large Multimodal Models (LMMs) by introducing Dalle Street, a large-scale dataset generated by DALL-E 3 and validated by hu-mans, containing 9, 935 images of 67 countries and 10 concept classes, (2) the underlying implicit and potentially stereotypical cultural associations with a cultural artifact extraction task, and (3) an approach to adapt cultural representation in an image based on extracted associations using a modular pipeline, Cultureadapt. We find disparities in cultural understanding at geographic sub-region levels with both open-source (LLaVA) and closed-source (GPT-4V) models on Dalle Street and other existing benchmarks, which we try to understand using over 18, 000 artifacts that we identify in association to different coun-tries. Our findings reveal a nuanced picture of the cultural competence of LMMs, highlighting the need to develop culture-aware systems.11Dataset and code are available: https://github.com/iamshnoo/crossroads},
  keywords={Cultural competence;Adaptation models;Computer vision;Codes;Computational modeling;Pipelines;Benchmark testing;Cultural differences;Continents;Artificial intelligence;cultural localization;cultural bias analysis;llm;multimodal;culture;dataset},
  doi={10.1109/WACV61041.2025.00178},
  ISSN={2642-9381},
  month={Feb},}@INPROCEEDINGS{10932270,
  author={Desai, Arun and Kulkarni, Anagha},
  booktitle={2025 1st International Conference on AIML-Applications for Engineering & Technology (ICAET)}, 
  title={Unleashing the Potential of Ontology in Skill Extraction}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Research reveals ontology's ability to extract information about skills from online job sites by giving a structured and semantically rich representation of skills. The study talks about more accurate and thorough skill profiling by systematically building ontological models that allow for an indepth knowledge of the complex links between skills, abilities, and domains. In this research, we study papers from different methods like supervised learning, unsupervised learning, and LLMs. The paper begins by providing not only an overview what is new in ontology generation but also its application in the context of skill extraction. It then delves into the challenges and opportunities associated with ontology-based skill extraction, highlighting the ways of processing natural language in bridging the gap between unstructured text and the formal representation of skills and competencies. Furthermore, the paper presents a comprehensive framework for ontology-driven skill extraction, emphasizing the importance of contextual awareness and the identification of implicit skills that may not be explicitly stated in the source text. The potential implications of this approach are manifold, as it could significantly impact various aspects of the talent management ecosystem.},
  keywords={Manifolds;Accuracy;Biological system modeling;Supervised learning;Natural languages;Ecosystems;Machine learning;Ontologies;Data mining;Unsupervised learning;Ontology;skill extraction;skills;Jobs;Machine Learning},
  doi={10.1109/ICAET63349.2025.10932270},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10777249,
  author={De Silva, D. I. and Athukorala, K. S. N.},
  booktitle={2024 International Conference on Information and Communication Technology for Development for Africa (ICT4DA)}, 
  title={Sinhala Java Development Aid with Machine Translation Integration}, 
  year={2024},
  volume={},
  number={},
  pages={194-199},
  abstract={Programming plays a vital role in computer science. However, beginners often face challenges such as limited availability of programming resources and language barriers. A Sinhala programming aid specifically designed for new Java programmers is proposed to address these issues. Ensuring translator accuracy is essential to overcoming the language barrier. To assist with translations, a transformer-based model was trained on a Java-specific dataset, achieving an accuracy of 84%. This model assists in generating the responses based on questions that have been translated and integrated with the ChatGPT. This two-in-one application lets users submit Java code to get explanations in Sinhala, or input queries in Sinhala to get equivalent Java code snippets, effectively removing linguistic barriers from the learning process. The system architecture includes a robust back-end API, an advanced translation model that guarantees accurate and contextually relevant translations, and an easy-to-use front-end developed with Flask. Usability and functionality testing were conducted with ten novice Sinhala-speaking programmers. Their feedback was instrumental in improving the tool's usability and efficacy. This study addresses the integration of several technologies to improve the accessibility of programming instruction for Sinhala-speaking learners. It also elaborates on the development process, from basic concept to execution phases. By providing a localized learning environment, the proposed technology simplifies learning programming and aids in concept retention while promoting a more inclusive global coding community.},
  keywords={Java;Accuracy;Codes;Quality assurance;Systems architecture;Programming;Transformers;Chatbots;Usability;Testing;Java developers;machine translation model;programming aid;Flask;ChatGPT},
  doi={10.1109/ICT4DA62874.2024.10777249},
  ISSN={},
  month={Nov},}@ARTICLE{10812818,
  author={Guo, Qi and Pang, Shanmin and Jia, Xiaojun and Liu, Yang and Guo, Qing},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Efficient Generation of Targeted and Transferable Adversarial Examples for Vision-Language Models via Diffusion Models}, 
  year={2025},
  volume={20},
  number={},
  pages={1333-1348},
  abstract={Adversarial attacks, particularly targeted transfer-based attacks, can be used to assess the adversarial robustness of large visual-language models (VLMs), allowing for a more thorough examination of potential security flaws before deployment. However, previous transfer-based adversarial attacks incur high costs due to high iteration counts and complex method structure. Furthermore, due to the unnaturalness of adversarial semantics, the generated adversarial examples have low transferability. These issues limit the utility of existing methods for assessing robustness. To address these issues, we propose AdvDiffVLM, which uses diffusion models to generate natural, unrestricted and targeted adversarial examples via score matching. Specifically, AdvDiffVLM uses Adaptive Ensemble Gradient Estimation (AEGE) to modify the score during the diffusion model’s reverse generation process, ensuring that the produced adversarial examples have natural adversarial targeted semantics, which improves their transferability. Simultaneously, to improve the quality of adversarial examples, we use the GradCAM-guided Mask Generation (GCMG) to disperse adversarial semantics throughout the image rather than concentrating them in a single area. Finally, AdvDiffVLM embeds more target semantics into adversarial examples after multiple iterations. Experimental results show that our method generates adversarial examples 5x to 10x faster than state-of-the-art (SOTA) transfer-based adversarial attacks while maintaining higher quality adversarial examples. Furthermore, compared to previous transfer-based adversarial attacks, the adversarial examples generated by our method have better transferability. Notably, AdvDiffVLM can successfully attack a variety of commercial VLMs in a black-box environment, including GPT-4V. The code is available at https://github.com/gq-max/AdvDiffVLM},
  keywords={Diffusion models;Semantics;Robustness;Closed box;Noise;Image quality;Adaptation models;Electronic mail;Glass box;Focusing;Adversarial attack;visual language models;diffusion models;score matching},
  doi={10.1109/TIFS.2024.3518072},
  ISSN={1556-6021},
  month={},}@ARTICLE{10849613,
  author={Parikh, Nishant Ashokkumar},
  journal={IEEE Engineering Management Review}, 
  title={Managing AI-First Products: Roles, Skills, Challenges, and Strategies of AI Product Managers}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Artificial Intelligence (AI) is revolutionizing industries, offering significant opportunities for innovation while introducing unique complexities in product management. Despite its transformative potential, research on the distinct responsibilities, challenges, and skills required of AI Product Managers (AI PMs) remains limited, leaving a critical gap in understanding how to effectively manage AI-driven products. This study addresses this gap using a grounded theory approach to analyze the evolving roles of AI PMs and propose strategies for managing the complexities of AI-first product development. Central to this study is the introduction of the AI PM Archetype Persona Framework, which encompasses expanded responsibilities, specific challenges and mitigation strategies, essential skills and competencies, AI product lifecycle management, personality traits, and the application of generative AI tools in product management. These findings provide actionable insights for practitioners and organizations, enabling them to tackle AI challenges, refine product lifecycle strategies, and foster sustainable innovation in an AI-driven market landscape.},
  keywords={Artificial intelligence;Interviews;Ethics;Product development;Prevention and mitigation;Generative AI;Complexity theory;Technological innovation;Navigation;Encoding;AI product life cycle;AI product manager;AI product manager archetype persona;AI product manager challenges;AI product manager skills},
  doi={10.1109/EMR.2025.3530942},
  ISSN={1937-4178},
  month={},}@INPROCEEDINGS{10859219,
  author={Liem, Cynthia C. S. and Taşcılar, Doğa and Demetriou, Andrew M.},
  booktitle={2024 International Conference on Content-Based Multimedia Indexing (CBMI)}, 
  title={A Quest Through Interconnected Datasets: Lessons From Highly-Cited ICASSP Papers}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={As audio machine learning outcomes are deployed in societally impactful applications, it is important to have a sense of the quality and origins of the data used. Noticing that being explicit about this sense is not trivially rewarded in academic publishing in applied machine learning domains, and neither is included in typical applied machine learning curricula, we present a study into dataset usage connected to the top-5 cited papers at the International Conference on Acoustics, Speech, and Signal Processing (ICASSP). In this, we conduct thorough depthfirst analyses towards origins of used datasets, often leading to searches that had to go beyond what was reported in official papers, and ending into unclear or entangled origins. Especially in the current pull towards larger, and possibly generative AI models, awareness of the need for accountability on data provenance is increasing. With this, we call on the community to not only focus on engineering larger models, but create more room and reward for explicitizing the foundations on which such models should be built.},
  keywords={Publishing;Generative AI;Annotations;Machine learning;Signal processing;Data models;Acoustics;Speech processing;Indexing;Annotation practices;data quality;data provenance;responsible research;applied machine learning},
  doi={10.1109/CBMI62980.2024.10859219},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10475599,
  author={Karkiner, Zeynep and Yaman, Begum and Zengin, Begum and Cavli, Feride Nursena and Sert, Mustafa},
  booktitle={2024 IEEE 18th International Conference on Semantic Computing (ICSC)}, 
  title={ParsyBot: Chatbot for Baskent University Related FAQs}, 
  year={2024},
  volume={},
  number={},
  pages={168-175},
  abstract={Reading regulations and instructions may take lots of time and sometimes it results in disappointments. To avoid this issue, people are prone to use sources that provide fast and accurate answers while accessing the information. Chatbots, are one of the most popular trend topics nowadays, and may adapted into various fields e.g., healthcare, finance, and education. This paper proposes the development of ParsyBot which is a Turkish chatbot designed to inform users about the regulations, admissions, departments, scholarships, and social clubs of Baskent University. Furthermore, users may ask via voice in Turkish this feature is not common among the other chatbots. ParsyBot uses a pre-trained BERT model which is specifically trained with regulations and instructions of Baskent University. Parsybot runs on web and mobile platforms to make it available for everyone. Our experiments on the utilized dataset, ParsyBot, reached 0.81 in METEOR, and 0.24 in ROGUE-1, which are promising compared to the ChatGPT 3.5.},
  keywords={Scholarships;Semantics;Education;Finance;Medical services;Chatbots;Market research;Chatbot;BERT;NLP;Mobile Application},
  doi={10.1109/ICSC59802.2024.00033},
  ISSN={2472-9671},
  month={Feb},}@ARTICLE{10541859,
  author={Lyu, Yunbo and Kang, Hong Jin and Widyasari, Ratnadira and Lawall, Julia and Lo, David},
  journal={IEEE Transactions on Software Engineering}, 
  title={Evaluating SZZ Implementations: An Empirical Study on the Linux Kernel}, 
  year={2024},
  volume={50},
  number={9},
  pages={2219-2239},
  abstract={The SZZ algorithm is used to connect bug-fixing commits to the earlier commits that introduced bugs. This algorithm has many applications and many variants have been devised. However, there are some types of commits that cannot be traced by the SZZ algorithm, referred to as “ghost commits”. The evaluation of how these ghost commits impact the SZZ implementations remains limited. Moreover, these implementations have been evaluated on datasets created by software engineering researchers from information in bug trackers and version controlled histories. Since Oct 2013, the Linux kernel developers have started labelling bug-fixing patches with the commit identifiers of the corresponding bug-inducing commit(s) as a standard practice. As of v6.1-rc5, 76,046 pairs of bug-fixing patches and bug-inducing commits are available. This provides a unique opportunity to evaluate the SZZ algorithm on a large dataset that has been created and reviewed by project developers, entirely independently of the biases of software engineering researchers. In this paper, we apply six SZZ implementations to 76,046 pairs of bug-fixing patches and bug-introducing commits from the Linux kernel. Our findings reveal that SZZ algorithms experience a more significant decline in recall on our dataset ($\downarrow 13.8\%$↓13.8%) as compared to prior findings reported by Rosa et al., and the disparities between the individual SZZ algorithms diminish. Moreover, we find that 17.47% of bug-fixing commits are ghost commits. Finally, we propose Tracing-Commit SZZ (TC-SZZ), that traces all commits in the change history of lines modified or deleted in bug-fixing commits. Applying TC-SZZ to all failure cases, excluding ghost commits, we found that TC-SZZ could identify 17.7% of them. Our further analysis based on git log found that 34.6% of bug-inducing commits were in the function history, 27.5% in the file history (but not in the function history), and 37.9% not in the file history. We further evaluated the effectiveness of ChatGPT in boosting the SZZ algorithm's ability to identify bug-inducing commits in the function history, in the file history and not in the file history.},
  keywords={History;Software algorithms;Kernel;Linux;Computer bugs;Codes;Chatbots;SZZ;defect prediction;empirical study;ChatGPT},
  doi={10.1109/TSE.2024.3406718},
  ISSN={1939-3520},
  month={Sep.},}@INPROCEEDINGS{10133863,
  author={Narrain, Jigisha M and Taneja, Vanshika and Atrey, Sanjana B and Sivaram, Jahnavi and Singh, Dinesh},
  booktitle={2023 Winter Summit on Smart Computing and Networks (WiSSCoN)}, 
  title={Extractive Summarization - A Comparison of Pre-Trained Language Models and Proposing a Hybrid Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1-12},
  abstract={The automatic summarization of technical articles is a field that has garnered a fair amount of interest, and one that enjoys a significant portion of NLP-related research. As a whole, automatic summarization can be split into two broad categories - extractive and abstractive. Extractive summarization implies that important and relevant sentences are picked from the article as is, and inserted in the summary. Abstractive summarization, on the other hand, requires contextual understanding of the document, and rearranging and shortening the sentences, while maintaining the core essence of the article. Multiple algorithms have been proposed for both these classes of automatic summarization. In the recent past, the emergence of pre-trained language models for NLP tasks have been heralded by the creation of attention mechanisms and Transformers. These models implement encoder-decoder structures, and have far wider applications than previously utilised algorithms. Four such pretrained models are - BERT, BART, XLNet and GPT-2. In this project, we use transfer learning to fit these models on our corpus of Medium articles, fine-tuning them for the task of summarization. Further, we generate online summaries of the data, and use ROUGE metrics to evaluate the accuracy of the model-generated summaries alongside those. We also implement the popular Word2Vec model on the same data, and compare its result with the ones obtained from the attention based models, once again using ROUGE metrics. In addition, we explore the effectiveness of a hybrid approach to the summarization task, by using different combinations of the models on the same article to investigate the results of the same.},
  keywords={Measurement;Computational modeling;Transfer learning;Natural languages;Bit error rate;Transformer cores;Transformers;natural language processing;machine learning;automatic summarization;language model;attention mechanism;BERT;BART;XLNet;GPT-2;hybrid model;word2vec},
  doi={10.1109/WiSSCoN56857.2023.10133863},
  ISSN={},
  month={March},}@INPROCEEDINGS{10233997,
  author={Kale, Sumedh S. and Andreopoulos, William B.},
  booktitle={2023 IEEE Ninth International Conference on Big Data Computing Service and Applications (BigDataService)}, 
  title={Job Tailored Resume Content Generation}, 
  year={2023},
  volume={},
  number={},
  pages={40-47},
  abstract={Generally candidates apply to multiple jobs with a single resume and do not tend to customize their resume to match the job description. This hampers their chances of getting a resume shortlisted for the job. The project aims to help such candidates build job tailored resumes that help them create a customized and targeted resume for a specific job. The tool specifically targets candidates’ employment work history for resume content generation. We create a synthetic dataset built from candidates’ employment history and online job descriptions. We use natural language processing (NLP) techniques to extract and organize the dataset, experiment with multiple dataset variations and cite ways to effectively build the dataset for the proposed task. We then use natural language generation by fine tuning GPT-2 for the task of resume content generation. Finally we evaluate the fine tuned model on various metrics and report our findings.},
  keywords={Measurement;Resumes;Employment;Computer architecture;Transformers;Natural language processing;History;content generation;natural language generation;natural language processing;generative AI;transformers},
  doi={10.1109/BigDataService58306.2023.00012},
  ISSN={},
  month={July},}@INPROCEEDINGS{10570106,
  author={Moeini, Mobina and Ahmadian, Rouhollah and Ghatee, Mehdi},
  booktitle={2024 8th International Conference on Smart Cities, Internet of Things and Applications (SCIoT)}, 
  title={Calibrated SVM for Probabilistic Classification of In-Vehicle Voices into Vehicle Commands via Voice-to-Text LLM Transformation}, 
  year={2024},
  volume={},
  number={},
  pages={180-188},
  abstract={With the rapid advancement of artificial intelligence technologies in human life, particularly within the automotive industry, the popularity of smart vehicles has increased. Designing an intelligent car cabin capable of seamless interactions with both the driver and the vehicle emerges as a crucial solution to address human-vehicle interaction challenges. This project aims to implement a digital voice assistant that recognizes vehicle commands. It utilizes three main techniques: speech-to-text conversion, text classification, and calibrating the classifier in order to detect out-of-distribution (OOD) sentences. Using Vosk, an LLM model, voices in the vehicle environment are converted into text format. Then, after pre-processing the text, an SVM classifies them. Using Platt scaling the SVM classifier outputs become calibrated, which makes them probabilistic. The experimental result shows that the proposed model achieves command recognition with 96.43% accuracy, 96.83% precision, 96.43% recall, 96.39% F1-score, and 0.1437 cross-entropy loss. Furthermore, the optimal threshold for OOD sentences is 0.4.},
  keywords={Support vector machines;Industries;Smart cities;Text categorization;Personal voice assistants;Probabilistic logic;Internet of Things;Driver Assistant;Voice Assistant;Command Recognition;Automotive Systems;LLM;Vosk;SVM},
  doi={10.1109/SCIoT62588.2024.10570106},
  ISSN={},
  month={May},}@INPROCEEDINGS{10944943,
  author={Hu, Jiekang and Li, Yakai and Xiang, Zhaoxi and Ma, Luping and Jia, Xiaoqi and Huang, Qingjia},
  booktitle={2024 IEEE 23rd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)}, 
  title={LLM4MDG: Leveraging Large Language Model to Construct Microservices Dependency Graph}, 
  year={2024},
  volume={},
  number={},
  pages={859-869},
  abstract={Microservices architecture has gained popularity in modern software development due to its scalability and flexibility. However, understanding the complexity of interactions and dependencies between services presents significant challenges, which complicates the identification and analysis of errors within microservice applications. To gain insights into the architecture and interdependencies of microservices applications, prior studies have developed dependency graphs to illustrate the relationships among services. However, the methods used to construct these dependency graphs are not suitable for common microservices applications and suffer from insufficient data granularity. To address these shortcomings, we introduce LLM4MDG, an in-novative framework for constructing microservices dependency graphs using an LLM-driven multi-agent system. By leveraging optimized prompt engineering and principles of knowledge graphs, LLM4MDG can effectively identify and interpret service interactions across diverse microservice ecosystems, achieving high accuracy and adaptability across various scenarios. We also present a new open-source dataset comprising 47 microservices applications, annotated by domain experts, to validate our frame-work. Evaluation results demonstrate that LLM4MDG achieves an 88.3% accuracy in identifying data dependencies in the Train Ticket project, a benchmark application with over 80 service instances. This study provides a robust solution for constructing dependency graphs and facilitating better system understanding and management.},
  keywords={Accuracy;Large language models;Scalability;Microservice architectures;Computer architecture;Knowledge graphs;Prompt engineering;Security;Software development management;Multi-agent systems;Microservice Architecture;Large Language Model;Prompt Engineering;Data Dependencies;Knowledge Graph},
  doi={10.1109/TrustCom63139.2024.00128},
  ISSN={2324-9013},
  month={Dec},}@ARTICLE{10737883,
  author={Moser, Brian B. and Shanbhag, Arundhati S. and Raue, Federico and Frolov, Stanislav and Palacio, Sebastian and Dengel, Andreas},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Diffusion Models, Image Super-Resolution, and Everything: A Survey}, 
  year={2024},
  volume={},
  number={},
  pages={1-21},
  abstract={Diffusion models (DMs) have disrupted the image super-resolution (SR) field and further closed the gap between image quality and human perceptual preferences. They are easy to train and can produce very high-quality samples that exceed the realism of those produced by previous generative methods. Despite their promising results, they also come with new challenges that need further research: high computational demands, comparability, lack of explainability, color shifts, and more. Unfortunately, entry into this field is overwhelming because of the abundance of publications. To address this, we provide a unified recount of the theoretical foundations underlying DMs applied to image SR and offer a detailed analysis that underscores the unique characteristics and methodologies within this domain, distinct from broader existing reviews in the field. This article articulates a cohesive understanding of DM principles and explores current research avenues, including alternative input domains, conditioning techniques, guidance mechanisms, corruption spaces, and zero-shot learning approaches. By offering a detailed examination of the evolution and current trends in image SR through the lens of DMs, this article sheds light on the existing challenges and charts potential future directions, aiming to inspire further innovation in this rapidly advancing area.},
  keywords={Image quality;Superresolution;Diffusion models;Surveys;Computational modeling;Faces;Degradation;Training;Standards;Reviews;Diffusion models (DMs);super-resolution (SR);survey},
  doi={10.1109/TNNLS.2024.3476671},
  ISSN={2162-2388},
  month={},}@INBOOK{10897226,
  author={Islam, Mohammad Rubyet},
  booktitle={Generative AI, Cybersecurity, and Ethics}, 
  title={Introduction}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Summary <p>In today's fast&#x2010;paced digital world, the intersection of generative artificial intelligence (GenAI), cybersecurity, and ethics presents both thrilling opportunities and significant challenges. This book embarks on an exciting journey, showcasing how GenAI enhances digital security while addressing the ethical dilemmas that arise. From safeguarding personal data to thwarting complex cyberattacks, understanding the link between AI and cybersecurity is more crucial than ever. As we unlock GenAI's potential, we also encounter new ethical challenges, necessitating responsible harnessing of these advanced technologies. This introductory chapter explores pivotal themes in GenAI, cybersecurity, and ethics, laying the foundation for a comprehensive examination of this captivating subject.</p>},
  keywords={Artificial intelligence;Deep learning;Biological neural networks;Virtual assistants;Technological innovation;Propulsion;Programming;Generative AI;Data visualization;Virtual environments},
  doi={10.1002/9781394279326.ch1},
  ISSN={},
  publisher={Wiley},
  isbn={9781394279319},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10897226},}@INBOOK{10834115,
  author={Dubey, Shival and Sikarwar, Shailendra Singh},
  booktitle={AI in Disease Detection: Advancements and Applications}, 
  title={Applications of AI in Cancer Detection &#x2014; A Review of the Specific Ways in which AI Is Being Used to Detect and Diagnose Various Types of Cancer}, 
  year={2025},
  volume={},
  number={},
  pages={147-166},
  abstract={Summary <p>The mixing of superior deep learning strategies has profoundly impacted the sector of sickness identification, promising sizable advancements in diagnostic accuracy and performance. This paper explores the utilization of multi&#x2010;scale convolutional layers, interest mechanisms, switch learning, generative adversarial networks (GANs), and self&#x2010;supervised learning in the healthcare domain. These techniques collectively beautify the capability of convolutional neural networks (CNNs) to discover and diagnose diseases from medical pix with extraordinary precision. Multi&#x2010;scale convolutional layers allow the models to capture features at numerous scales, improving the sensitivity and specificity of disease detection, mainly in situations like most cancers. Attention mechanisms similarly refine this process by allowing models to focus on the most applicable components of an picture, mirroring the meticulous examination by healthcare professionals.</p> <p>Transfer learning, leveraging training fashions, extensively reduces the reliance on tremendous, categorized datasets, thereby expediting the development process and enhancing version accuracy. This approach has shown outstanding success throughout distinctive imaging modalities, from X&#x2010;rays to CT scans, improving the adaptability and robustness of diagnostic models. GANs contribute via producing artificial records to augment schooling datasets, addressing the challenge of limited data availability and enhancing model performance, specifically in uncommon disease scenarios. Self&#x2010;supervised learning, which trains fashions on unlabeled records via proxy duties, has demonstrated comparable performance to absolutely supervised fashions while requiring fewer categorized samples, therefore lowering the need for luxurious and time&#x2010;eating data annotation.</p> <p>Innovations in those areas have not only improved the technical performance of disease identification models but also opened new avenues for his or her application. Future research should explore multimodal learning, which mixes data from various assets, including genomic information and digital health data, imparting a more complete diagnostic perspective. The implementation of federated learning guarantees data privacy while enhancing model training via decentralized records assets. Explainable AI (XAI) techniques enhance model interpretability, fostering extra consider and popularity amongst healthcare professionals. Moreover, the integration of AI with wearable devices for continuous fitness tracking and the improvement of real&#x2010;time adaptive learning fashions hold tremendous promise for revolutionizing patient care and disease control.</p> <p>This comprehensive method to leveraging superior deep learning methodologies in disorder identification underscores the transformative potential of AI in healthcare. With the aid of addressing modern&#x2010;day demanding situations and exploring progressive answers, we can pave the way for greater accuracy, efficiency, and personalized diagnostic systems, in the end enhancing patient results and advancing current care in medical exercise.</p>},
  keywords={Artificial intelligence;Cancer detection;Medical services;Cancer;Technological innovation;Oncology;Accuracy;Medical diagnostic imaging;Collaboration;Bioinformatics},
  doi={10.1002/9781394278695.ch7},
  ISSN={},
  publisher={IEEE},
  isbn={9781394278688},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10834115},}@ARTICLE{10893855,
  author={Vyas, Piyush and Vyas, Gitika},
  journal={IT Professional}, 
  title={Generative Artificial Intelligence: Current Trends, Issues, and Challenges}, 
  year={2025},
  volume={27},
  number={1},
  pages={20-26},
  abstract={This article explores the landscape of generative artificial intelligence (GAI), aiming to elucidate the current discourse, trends, and challenges. Given the scarcity of literature, the study undertakes a literature search, conducting a thorough examination to compile relevant information. By shedding light on GAI’s current trends, issues, and challenges, this work underscores the requirement of comprehending the intricacies of GAI for its ethical and appropriate deployment across diverse sectors. This study reveals the urgency for further research, emphasizing the need for in-depth investigations to facilitate the development of the next generation of GAI models. More exploration is needed to ensure the responsible and ethical realization of GAI’s full potential in shaping societal landscapes. Moreover, explainability, security, intellectual property, data privacy, finance, and ethics are crucial issues associated with GAI.},
  keywords={Ethics;Data privacy;Generative AI;Finance;Intellectual property;Market research;Security;Next generation networking;Market research;Intellectual property;Social factors},
  doi={10.1109/MITP.2024.3516058},
  ISSN={1941-045X},
  month={Jan},}@INPROCEEDINGS{10968966,
  author={Kaur, Parneet and Gupta, Deepali and Uppal, Mudita},
  booktitle={2025 10th International Conference on Signal Processing and Communication (ICSC)}, 
  title={Generative AI Meets IoT: A Bibliometric Mapping of Research and Development}, 
  year={2025},
  volume={},
  number={},
  pages={434-439},
  abstract={Computer technology has transformed the way people interact online within society. The integration of (GIoT) combines Artificial Intelligence (AI) and Internet of Things (IoT) technology, offering numerous benefits in many fields for innovation and growth. GIoT helps with real-time applications for data prediction and alerts. Based on the authors' understanding and searches in scholarly databases, less bibliometric analysis has yet been performed on Generative Artificial Intelligence (GAI) for the IoT, even though such analyses are crucial for research development in this field. This study conducted a thorough bibliometric examination of GAI applications in the IoT over the period from 2014 to 2024. The analysis is based on a dataset of 296 documents sourced from the Scopus database. The bibliometric review was conducted using the Biblioshiny application, a tool available within the Bibliometric package in the R programming language. Top literature sources, major fields of study, nations, well-known authors, popular subjects, authorship, citations, author-keywords, and co-keywords were all subjected to bibliometric analysis.},
  keywords={Technological innovation;Computer languages;Generative AI;Databases;Reviews;Bibliometrics;Signal processing;Real-time systems;Internet of Things;Research and development;Generative Artificial Intelligence;Generative Internet of Things;bibliometric analysis},
  doi={10.1109/ICSC64553.2025.10968966},
  ISSN={2643-444X},
  month={Feb},}@INBOOK{10676369,
  author={Daim, Tugrul U. and Zamani, Mehdi and Naeini, Ali B. and Alsoubaie, Fayez and Zhang, Hao and Yal&#xe7;&#x131;n, Haydar},
  booktitle={Future-Oriented Technology Assessment: A Manager's Guide with Case Applications}, 
  title={Technology Intelligence: Geothermal Energy}, 
  year={2025},
  volume={},
  number={},
  pages={151-220},
  abstract={Summary <p>The increasing demand of power energy need for sustainable energy sources has made geothermal energy a viable substitute. However, the creation of novel technologies is necessary for the efficient use of geothermal energy. In this study, therefore, it is essential to determine the current level of technology in this area and to examine the patterns and trends in technological development. The methodology used to go through patent data analysis, The research goal was to provide a comprehensive overview of geothermal energy technology currently available, as well as its future prospects.</p> <p>This study provides a novel method of mapping technology related to geothermal energy through the examination of patent data by implementing a generative probabilistic model of text mining such as Latent Dirichlet Allocation (LDA) and social network analysis to identify significant technology clusters and trace their evolutionary history. Analyzing cutting&#x2010;edge topics that could push further advancements in geothermal energy technologies demonstrated the technology's unique position in the current context.</p> <p>The results also demonstrated how crucial it is to maintain these critical topics in order to support long&#x2010;term technological advancement. Geothermal energy technology decision&#x2010;makers can benefit from the information provided in this report to guide their strategic planning and investments.</p>},
  keywords={Heating systems;Earth;Geothermal energy;Thermodynamics;Springs;Resistance heating;Electricity},
  doi={10.1002/9781119909880.ch7},
  ISSN={},
  publisher={IEEE},
  isbn={9781119909866},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10676369},}@INBOOK{10834092,
  author={Iqbal, Mohammed Ismail and Kaushik, Priyanka},
  booktitle={AI in Disease Detection: Advancements and Applications}, 
  title={Deep Learning for Disease Detection &#x2014; A Deep Dive into Deep Learning Techniques Such as Convolutional Neural Networks (CNNs) and Their Use in Disease Detection}, 
  year={2025},
  volume={},
  number={},
  pages={99-122},
  abstract={Summary <p>The mixing of superior deep learning strategies has deeply affected the sector of disease identification, promising sizeable advancements in diagnostic accuracy and performance. This chapter explores the utilization of multiscale convolutional layers, interest mechanisms, switch learning, generative adverse networks (GANs), and self&#x2010;supervised learning in the healthcare domain. These techniques collectively beautify the capability of convolutional neural networks (CNNs) to discover and diagnose diseases from medical pix with extraordinary precision. Multiscale convolutional layers allow the models to capture features at numerous scales, improving the sensitivity and specificity of ailment detection, mainly in situations like most cancers. Attention mechanisms similarly refine this process by allowing models to focus on the most applicable components of an image, mirroring the meticulous examination by human professionals.</p> <p>The chapter discusses deep learning, leveraging pre&#x2010;educated models, which extensively reduces the reliance on tremendous, categorized datasets, thereby expediting the development process and enhancing version accuracy. This approach has shown outstanding success throughout distinctive imaging modalities, from X&#x2010;rays to CT scans, improving the adaptability and robustness of diagnostic models. GANs contribute via producing artificial records to augment schooling datasets, addressing the challenge of limited data availability and enhancing model performance, specifically in uncommon disease scenarios. Self&#x2010;supervised learning, which trains models on unlabeled records via proxy duties, has demonstrated comparable performance to absolutely supervised models while requiring fewer categorized samples, therefore lowering the need for luxurious and time&#x2010;eating data annotation.</p> <p>Innovations in these areas have not only enhanced the technical performance of disease detection models but also expanded their potential applications. Future studies instructions consist of the exploration of multimodal learning, which mixes data from various assets including genomic information and digital health data, imparting a more complete diagnostic perspective. The implementation of federated learning guarantees data privacy while enhancing version training via decentralized records assets. Explainable AI (XAI) techniques enhance version interpretability, fostering more consideration and popularity amongst healthcare professionals. Moreover, the integration of AI with wearable devices for continuous fitness tracking, and the improvement of real&#x2010;time adaptive knowledge of models, hold tremendous promise for revolutionizing patient care and disease control.</p> <p>This comprehensive method to leveraging superior deep learning methodologies in disorder identification underscores the transformative potential of AI in healthcare. With the aid of addressing modern&#x2010;day demanding situations and exploring progressive answers, we can pave the way for greater accurate, efficient, and personalized diagnostic systems, in the end enhancing patient outcomes by using advanced AI and deep learning to enhance diagnostic accuracy, treatment efficiency, and patient outcomes, ultimately setting a new benchmark for best practices in healthcare.</p>},
  keywords={Diseases;Medical diagnostic imaging;Deep learning;Accuracy;Data models;Transfer learning;Training;Magnetic resonance imaging;Explainable AI;Data augmentation},
  doi={10.1002/9781394278695.ch5},
  ISSN={},
  publisher={IEEE},
  isbn={9781394278688},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10834092},}@ARTICLE{10838616,
  author={},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Consistency-Heterogenity Balanced Fake News Detection via Cross-modal Matching}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Generating synthetic content through Generative AI (GAI) presents considerable hurdles for current fake news detection methodologies. Many existing detection approaches concentrate on feature-based multi-modal fusion, neglecting semantic relationships such as correlations and diversities. In this study, we introduce an innovative cross-modal matching-driven approach to reconcile semantic relevance (text-image consistency) and semantic gap (text-image heterogeneity) in multimodal fake news detection. Unlike the conventional paradigm of multi-modal fusion followed by detection, our approach integrates textual modality, visual modality (images), and text embedded within images (auxiliary modality) to construct an end-to-end framework. This framework considers the relevance of contents across different modalities while simultaneously addressing the gap in structures, achieving a delicate balance between consistency and heterogeneity. Consistency is fostered by evaluating inter-modality correlation via pairwise-similarity scores, while heterogeneity is addressed by employing cross-attention mechanisms to account for inter-modality diversity. To achieve equilibrium between consistency and heterogeneity, we employ attention-guided enhanced modality interaction and similarity-based dynamic weight assignment to establish robust frameworks. Comparative experiments conducted on the Chinese Weibo dataset and the English Twitter dataset demonstrate the effectiveness of our approach, surpassing the state-of-the-art by 7% to 13%.},
  keywords={Feature extraction;Fake news;Semantics;Visualization;Correlation;Social networking (online);Artificial intelligence;Blogs;Data mining;Accuracy;multimodal fake news detection;cross-modal matching;text-image consistency;text-image heterogentiy},
  doi={10.1109/TAI.2025.3527921},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{11016553,
  author={Browning, Jonathan W. and McKeever, Stephen and Ferrario, Maria Angela and O'Neill, Ian and Stewart, Darryl},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Creating Sustainable Solutions: An Inclusive Hackathon Leveraging GenAI in a Local Context}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper presents the design and implementation of a two-week hackathon at a large prestigious UK university, focused on creating sustainable solutions leveraging generative artificial intelligence (genAI). The hackathon deviated from the traditional one to three-day format, providing an extended period for ideation, development, and public voting. The event aimed to foster innovation, engage the local community in sustainability efforts, and augment participants' problem-solving capabilities through the use of genAI. The hackathon incorporated inclusivity measures based on evidence-based recommendations, ensuring diverse participation and a supportive environment. The participants could choose from four challenges to create a solution around that were based on local sustainability issues: housing regeneration, promoting sustainable and active travel, revitalizing the city center, and increasing re-naturing within the city. Teams were formed using a mix of self-selection and pre-assignment. Participants had access to comprehensive resources, including workshops on jupyter notebooks, genAI, video creation, and support from mentors. The final outputs each team was expected to produce was a 90 second video that detailed the challenge, their proposed solution, how they used open data, how they used genAI either in their solution or in their work process, as well as any files required for their solution to run/compile. The video was also to be used for the public vote, to decide the people's choice award, and hence could be promotional in nature but everyone in the team had to contribute to it in a meaningful way. Thus, they do not have to appear in it but could write a script or edit, etc. Judging criteria focused on the quality of the presentation, creativity, effective use of open data, and engagement with genAI. The event concluded with awards for the most polished solution, most creative idea, best use of open data, best use of genAI, best overall, and a people's choice award decided by a public vote. This paper contributes to the body of knowledge on leveraging genAI for sustainability and offers insights into develoning inclusive and impactful hackathons.},
  keywords={Technological innovation;Generative AI;Urban areas;Particle measurements;Teamwork;Problem-solving;Sustainable development;Hackathon;Open data;Creativity;generative AI;hackathon;innovation;student engagement;sustainability},
  doi={10.1109/EDUCON62633.2025.11016553},
  ISSN={2165-9567},
  month={April},}@INBOOK{10834125,
  author={Verma, Nikhil and Sharma, Tripti and Kaur, Bobbinpreet},
  booktitle={AI in Disease Detection: Advancements and Applications}, 
  title={Explanation of Machine Learning Algorithms Used in Disease Detection, Such as Decision Trees and Neural Networks}, 
  year={2025},
  volume={},
  number={},
  pages={27-52},
  abstract={Summary <p>Machine learning (ML) as a tool in disease diagnosis has come of age. However, in voluminous medical data, outclasses in analysis for digging out hidden patterns helpful for early detection. Current methodologies are effective, notwithstanding their limitations. This chapter thus presents a new approach &#x2013; a &#x201c;symphony of innovation&#x201d; &#x2013; by redefining disease detection to integrate the established methods with truly groundbreaking advancements systematically.</p> <p>This symphony goes beyond established, well&#x2010;rehearsed routines of current ML practices. It introduces AI orchestration as a new conductor that would work in harmony with all other components involved in the disease detection workflow and adapt to the workflow. Picture a network of hospitals, each equipped with patient data as if playing a concert together. Federated learning is a way to train ML models on this &#x201c;decentralized data,&#x201d; unlocking its power for improved disease detection, especially in the case of rare or geographically isolated cases, while protecting patient privacy in the process &#x2013; just like each hospital keeping its sheet music confidential. Another innovation in this symphony is active learning. Traditionally, training ML models require massive amounts of meticulously labeled data. Active learning algorithms act as a discerning conductor that identifies the most informative data points, reducing the need for manual labeling. This reduces not only the workload for medical professionals but also enables more efficient and targeted data collection.</p> <p>Static models can become useless with a changing healthcare environment and patient populations. This symphony is introducing algorithms of continuous learning. These algorithms function much like an adaptable maestro, continuously ingesting new data streams and dynamically refining their predictions to provide perpetual improvement in disease detection accuracy from day one &#x2013; to keep up with the evolving landscape in healthcare.</p> <p>Generative adversarial networks will elevate the level of innovation further. Now, imagine having to compose a host of entirely new musical pieces &#x2013; all those that would enhance the repertoire of an orchestra. GANs are capable of generating synthetic, false, anonymous patient data. In this way, researchers can train ML models on more extensive and more diverse datasets without being faced with questions about privacy, which is very useful in case of rare diseases with minimal real&#x2010;world data.</p> <p>This symphony of innovation, however, does not end with technological progress but is also reflected in the harmonious concurrence of man's brain and machine expertise.</p> <p>XAI techniques focused on the medical domain will turn out to be critical. As a model, such techniques are bound to provide transparent and interpretable explanations for their predictions, engendering trust and acceptance among medical professionals. Picture a program accompanying a complex musical piece that lets an audience &#x2013; here, doctors &#x2013; understand the intricacies of the performance. AI&#x2010;empowered clinical decision support systems are real&#x2010;time companions for a doctor in arriving at a diagnosis and instituting treatment. They study patient data, offer possible diagnoses, and suggest treatment options. Picture an AI assistant that can provide insights in real&#x2010;time and help doctors make more learned decisions about the clinical history of their patients. The ultimate goal of this symphony is personalized medicine. Armed with a patient's case history, genomic data, and data related to lifestyle habits, AI can predict their individual disease risk and hence help in the formulation of targeted interventions. Proactive healthcare &#x2013; prevention before manifestation of the actual disease &#x2013; is within reach.</p> <p>This vision in disease detection goes beyond the conventionally adopted methods in disease detection. With AI orchestration, human&#x2010;machine collaboration, and ethical concerns, we can unleash the promise of healthcare with very early diagnoses and a treatment regime that makes a difference &#x2013; leading to a genuinely healthful future for all. Such a symphony of innovation is taking to the streets and on course to rewrite the score relating to disease detection; every advancement within its repertoire seems to act as a note of hope in this fight for global health.</p>},
  keywords={Diseases;Medical diagnostic imaging;Medical services;Technological innovation;Predictive models;Accuracy;Prediction algorithms;Heuristic algorithms;Feature extraction;Decision trees},
  doi={10.1002/9781394278695.ch2},
  ISSN={},
  publisher={IEEE},
  isbn={9781394278688},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10834125},}@ARTICLE{10130818,
  author={Cortiñas-Lorenzo, Karina and Lacey, Gerard},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Toward Explainable Affective Computing: A Review}, 
  year={2024},
  volume={35},
  number={10},
  pages={13101-13121},
  abstract={Affective computing has an unprecedented potential to change the way humans interact with technology. While the last decades have witnessed vast progress in the field, multimodal affective computing systems are generally black box by design. As affective systems start to be deployed in real-world scenarios, such as education or healthcare, a shift of focus toward improved transparency and interpretability is needed. In this context, how do we explain the output of affective computing models? and how to do so without limiting predictive performance? In this article, we review affective computing work from an explainable AI (XAI) perspective, collecting and synthesizing relevant papers into three major XAI approaches: premodel (applied before training), in-model (applied during training), and postmodel (applied after training). We present and discuss the most fundamental challenges in the field, namely, how to relate explanations back to multimodal and time-dependent data, how to integrate context and inductive biases into explanations using mechanisms such as attention, generative modeling, or graph-based methods, and how to capture intramodal and cross-modal interactions in post hoc explanations. While explainable affective computing is still nascent, existing methods are promising, contributing not only toward improved transparency but, in many cases, surpassing state-of-the-art results. Based on these findings, we explore directions for future research and discuss the importance of data-driven XAI and explanation goals, and explainee needs definition, as well as causability or the extent to which a given method leads to human understanding.},
  keywords={Affective computing;Training;Data models;Computational modeling;Task analysis;Terminology;Predictive models;Affective computing;explainable AI (XAI);multimodal machine learning;review},
  doi={10.1109/TNNLS.2023.3270027},
  ISSN={2162-2388},
  month={Oct},}@ARTICLE{10839294,
  author={Yang, Bolin and Deng, Jie and Liang, Xiaoxuan and Chen, Zhenghan and Wu, Ruoxue},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={DOGMH: A Diffusion and Optimization Approach for Generative Molecular Health Informatics in Consumer Electronics}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This is a task of computational chemistry and pharmaceutical development, with rapidly growing relevance for consumer healthcare electronics: deducing three-dimensional molecular structures from two-dimensional diagrams. In this paper, we introduce a new generative model, DOGMH, specifically tailored for applications on consumer electronic devices, which considerably increases the accuracy in this process. DOGMH borrows from the diffusion mechanisms of classical nonequilibrium thermodynamics and treats atoms as individual particles, excelling in the inversion of the diffusion process-turning noise into organized molecular structures. Our approach leverages a specially tailored bilevel optimization technique that ensures roto-translational invariance and allows for efficient processing on resource-constrained consumer devices. We show that DOGMH outperforms existing methods in terms of both conformational synthesis and distance distribution accuracy. DOGMH also provides the ability to create AI-enabled interactive 3D visualizations of molecular structures for consumer health education. Our work paves the way for advanced molecular informatics capabilities in consumer-grade devices and will potentially revolutionize personal healthcare management through AI-enhanced insights. By bridging the gap between complex molecular modeling and consumer electronics, DOGMH will open up a new frontier in intelligent, molecularly aware health devices accessible to the general public.},
  keywords={Computational modeling;Accuracy;Optimization;Proteins;Noise;Consumer electronics;Training;Three-dimensional displays;Medical services;Predictive models;Molecular structure prediction;Consumer healthcare electronics;AI-generated content;Edge computing},
  doi={10.1109/TCE.2025.3528966},
  ISSN={1558-4127},
  month={},}@INPROCEEDINGS{9882932,
  author={Rivera, Miguel Angel Bello and Flores, Perfecto Malaquías Quintero and Loaiza, Rodolfo Eleazar Pérez and Rivera, Leticia Gómez},
  booktitle={2022 IEEE Mexican International Conference on Computer Science (ENC)}, 
  title={Analysis of Audio Signals Using Deep Learning Algorithms Applied to COVID Diagnostic Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years the application of deep learning algorithms in the subdomain of audio analysis has grown rapidly, however it is a topic that can be complex for students and researchers who have a first approach and want to develop an application in this field. The use of deep learning techniques applied to audio signals has allowed the development of a wide variety of useful tools in our daily lives, from virtual assistants to medical applications. This article presents a literature review of the main techniques that have been used in recent years for analysis, feature extraction and classification from audio spectra or spectrograms, as well as examples of application in the context of the COVID-19 pandemic in which multiple related projects have emerged, such as diagnostic systems. The techniques addressed are recurrent neural networks (RNN), convolutional neural networks (CNN) and generative adversarial networks (GAN). It is intended that the reader will be able to acquire this knowledge from a simple perspective and that this information will be useful in their research or development.},
  keywords={Silicon;Deep learning;Convolutional neural networks;Computer science;COVID-19;Visualization;Recurrent neural networks},
  doi={10.1109/ENC56672.2022.9882932},
  ISSN={2332-5712},
  month={Aug},}@INPROCEEDINGS{10569447,
  author={Haramina, Emilia and Paladin, Mateo and Petričušić, Zdravko and Posarić, Fran and Drobnjak, Antun and Botički, Ivica},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Learning Algorithms Concepts in a Virtual Reality Escape Room}, 
  year={2024},
  volume={},
  number={},
  pages={2057-2062},
  abstract={Although the standard way to learn algorithms is by coding, learning through games is another way to obtain knowledge while having fun. Virtual reality is a computer-generated three-dimensional environment in which the player is fully immersed by having external stimuli mostly blocked out. In the game presented in this paper, players are enhancing their algorithms skills by playing an escape room game. The goal is to complete the room within the designated time by solving puzzles. The puzzles change for every playthrough with the use of generative artificial intelligence to provide every player with a unique experience. There are multiple types of puzzles such as. time complexity, sorting algorithms, searching algorithms, and code execution. The paper presents the results of a study indicating students’ preference for learning through gaming as a method of acquiring algorithms knowledge.},
  keywords={Codes;Generative AI;Virtual environments;External stimuli;Games;Learning (artificial intelligence);Encoding;learning;education;extended reality;virtual reality;generative artificial intelligence;escape room;puzzles;user testing;user experience;user study},
  doi={10.1109/MIPRO60963.2024.10569447},
  ISSN={2623-8764},
  month={May},}@INBOOK{10529827,
  author={},
  booktitle={Smart Edge Computing: An Operation Research Perspective}, 
  title={Edge Computing with Operations Research Using IoT Devices in Healthcare}, 
  year={2024},
  volume={},
  number={},
  pages={65-95},
  abstract={Summary <p>This chapter gives a systematic review of the reputation of edge computing in healthcare. It discusses the systematic review of artificial intelligence (AI) techniques used in the edge healthcare system. Three sections of AI, namely machine learning, deep learning and the generative adversarial network, focus on providing detailed descriptions. The chapter describes the rise of smartphone&#x2010;based healthcare technology and discusses the classification of mobile device applications according to their functionalities. The medical calculator, drug discovery, disease treatment and diagnosis are the most used applications by nursing students, healthcare professionals and medical advisors. IoT collects information from the user through sensors in devices and smartphones. The Cloud helps to store those data quickly and efficiently. Medical practitioners use these technologies to provide a modernized and effective treatment, keeping people updated about their health information for healthy living.</p>},
  keywords={Medical services;Edge computing;Internet of Things;Operations research;Servers;Monitoring;Cloud computing},
  doi={10.1002/9781394277599.ch4},
  ISSN={},
  publisher={Wiley},
  isbn={9781394277575},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10529827},}@ARTICLE{9925159,
  author={Albuquerque Filho, José Edson De and Brandão, Laislla C. P. and Fernandes, Bruno José Torres and Maciel, Alexandre M. A.},
  journal={IEEE Access}, 
  title={A Review of Neural Networks for Anomaly Detection}, 
  year={2022},
  volume={10},
  number={},
  pages={112342-112367},
  abstract={Anomaly detection is a critical issue across several academic fields and real-world applications. Artificial neural networks have been proposed to detect anomalies from different input types, but there is no clear guide to deciding which model to use in a specific case. Therefore, this study examines the most relevant Neural Network Outlier Detection algorithms in the literature, compares their benefits and drawbacks in some application scenarios, and displays their outcomes in benchmark datasets. The initial search revealed 1422 papers on projects completed between 2017 and 2021. These papers were further narrowed based on title, abstract, quality assessment, inclusion, and exclusion criteria, remaining 76 articles. Finally, we reviewed these publications and verified that Autoencoder Neural Network, Convolutional Neural Network, Recurrent Neural Network, and Generative Adversarial Network have promisor outcomes for outlier detection, the advantages of these neural networks for outlier detection, and the significant challenges of outlier detection strategies.},
  keywords={Anomaly detection;Neural networks;Behavioral sciences;Protocols;Systematics;Machine learning;Quality assessment;Anomaly detection;neural networks;outlier detection;systematic review},
  doi={10.1109/ACCESS.2022.3216007},
  ISSN={2169-3536},
  month={},}@ARTICLE{10433498,
  author={Jamil, Azhar and Saif-Ur-Rehman and Mahmood, Khalid and Villar, Monica Gracia and Prola, Thomas and Diez, Isabel De La Torre and Samad, Md Abdus and Ashraf, Imran},
  journal={IEEE Access}, 
  title={Deep Learning Approaches for Image Captioning: Opportunities, Challenges and Future Potential}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Generative intelligence relies heavily on the integration of vision and language. Much of the research has focused on image captioning, which involves describing images with meaningful sentences. Typically, when generating sentences that describe the visual content, a language model and a vision encoder are commonly employed. Because of the incorporation of object areas, properties, multi-modal connections, attentive techniques, and early fusion approaches like bidirectional encoder representations from transformers (BERT), these components have experienced substantial advancements over the years. This research offers a reference to the body of literature, identifies emerging trends in an area that blends computer vision as well as natural language processing in order to maximize their complementary effects, and identifies the most significant technological improvements in architectures employed for image captioning. It also discusses various problem variants and open challenges. This comparison allows for an objective assessment of different techniques, architectures, and training strategies by identifying the most significant technical innovations, and offers valuable insights into the current landscape of image captioning research.},
  keywords={Visualization;Feature extraction;Convolutional neural networks;Context modeling;Task analysis;Surveys;Computational modeling;Deep learning;Artificial intelligence;Natural language processing;Image processing;Image capture;Image captioning;deep learning;image processing;artificial intelligence},
  doi={10.1109/ACCESS.2024.3365528},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10638598,
  author={Lambertenghi, Stefano Carlo and Stocco, Andrea},
  booktitle={2024 IEEE Conference on Software Testing, Verification and Validation (ICST)}, 
  title={Assessing Quality Metrics for Neural Reality Gap Input Mitigation in Autonomous Driving Testing}, 
  year={2024},
  volume={},
  number={},
  pages={173-184},
  abstract={Simulation-based testing of automated driving systems (ADS) is the industry standard, being a controlled, safe, and cost-effective alternative to real-world testing. Despite these advantages, virtual simulations often fail to accurately replicate real-world conditions like image fidelity, texture representation, and environmental accuracy. This can lead to significant differences in ADS behavior between simulated and real-world domains, a phenomenon known as the sim2real gap. Researchers have used Image-to-Image (I2I) neural translation to mitigate the sim2real gap, enhancing the realism of simulated environments by transforming synthetic data into more authentic representations of real-world conditions. However, while promising, these techniques may potentially introduce artifacts, distortions, or inconsistencies in the generated data that can affect the effectiveness of ADS testing. In our empirical study, we investigated how the quality of image-to-image (I2I) techniques influences the mitigation of the sim2real gap, using a set of established metrics from the literature. We evaluated two popular generative I2I architectures, pix2pix and CycleGAN, across two ADS perception tasks at a model level, namely vehicle detection and end-to-end lane keeping, using paired simulated and real-world datasets. Our findings reveal that the effectiveness of I2I architectures varies across different ADS tasks, and existing evaluation metrics do not consistently align with the ADS behavior. Thus, we conducted task-specific fine-tuning of perception metrics, which yielded a stronger correlation. Our findings indicate that a perception metric that incorporates semantic elements, tailored to each task, can facilitate selecting the most appropriate I2I technique for a reliable assessment of the sim2real gap mitigation.},
  keywords={Measurement;Software testing;Prevention and mitigation;Vehicle detection;Computer architecture;Software reliability;Task analysis;autonomous vehicles testing;generative adversarial networks;sim2real;reality gap},
  doi={10.1109/ICST60714.2024.00024},
  ISSN={2159-4848},
  month={May},}@INPROCEEDINGS{10489462,
  author={Dixit, Krishna Kant and Aswal, Upendra Singh and Saravanan, V. and Sararswat, Manishn and Shalini, N and Srivastava, Amit},
  booktitle={2023 International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)}, 
  title={Data Augmentation with Generative Adversarial Networks for Deep Learning in Healthcare}, 
  year={2023},
  volume={1},
  number={},
  pages={1-6},
  abstract={In order to overcome the difficulties caused by small datasets, this study investigates the combination of Generative Adversarial Networks (GANs) for healthcare information augmentation. Using a descriptive method with additional data gathering, we apply an approach based on a deductive and an interpretivist framework. The findings include a robustness test, a visual assessment, a comparative efficiency study, and an objective evaluation. Technical nuances and ethical implications are highlighted in our critical study. Suggestions support improving GAN structures, verifying robustness, and fostering responsible implementation. Subsequent research ought to concentrate on customized GANs for particular medical modalities, moral principles, and real-time therapeutic implementations.},
  keywords={Industries;Deep learning;Ethics;Visualization;Technological innovation;Medical services;Generative adversarial networks;deep learning;generative neural networks;healthcare;moral concerns},
  doi={10.1109/ICAIIHI57871.2023.10489462},
  ISSN={},
  month={Dec},}@ARTICLE{10508385,
  author={Ali Raza, Syed and Habib, Usman and Usman, Muhammad and Ashraf Cheema, Adeel and Sajid Khan, Muhammad},
  journal={IEEE Access}, 
  title={MMGANGuard: A Robust Approach for Detecting Fake Images Generated by GANs Using Multi-Model Techniques}, 
  year={2024},
  volume={12},
  number={},
  pages={104153-104164},
  abstract={Recent advances in Generative Adversarial Networks (GANs) have produced synthetic images with high visual fidelity, making them nearly indistinguishable from human-created images. These synthetic images referred to as deepfakes, have become a major source of misinformation due to social media. Technology is advancing rapidly, so reliable methods for distinguishing real from fake images are needed. The current detection mechanisms require image forensics tools such as error level analysis (ELA), and clone detection to detect manipulated images. These approaches are limited because they require forensics expertise to use, are manual in application nature, and are unscalable, creating a need for a framework for a scalable tool that experts and non-experts can use to combat the spread of manipulated images and preserve digital visual information authenticity. We approach this problem with a multi-model ensemble framework using the transfer learning method to effectively detect fake images. The proposed approach named Multi-Model GAN Guard (MMGANGuard)integrates four models into an ensemble framework to identify GAN-generated image characteristics to improve deepfake detection. The Gram-Net architecture, ResNet50V2, and DenseNet201 models are used with co-occurrence matrices using transfer learning for MMGANGuard. Through comprehensive experiments, the proposed model demonstrates promising results in detecting the deepfake with high accuracy on the StyleGAN dataset. For automated detection of deepfake-generated images, the proposed model exceeded 97% accuracy, 98.5% TPR, 98.4% TPR, and 95.6% TPR in these evaluations, eliminating the need for manual assessment which is promising for future research in this domain.},
  keywords={Deepfakes;Predictive models;Social networking (online);Neurons;Image coding;Computer architecture;Data analysis;Deep learning;Generative adversarial networks;Deep fake;data analytics;deep learning;GANs;StyleGAN;detection;multi-model},
  doi={10.1109/ACCESS.2024.3393842},
  ISSN={2169-3536},
  month={},}@ARTICLE{10347559,
  author={Feng, Kai and Cook, Marco M. and Marnerides, Angelos K.},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Sizzler: Sequential Fuzzing in Ladder Diagrams for Vulnerability Detection and Discovery in Programmable Logic Controllers}, 
  year={2024},
  volume={19},
  number={},
  pages={1660-1671},
  abstract={Programmable Logic Controllers (PLCs) constitute the basis of Industrial Control Systems (ICSs) underpinning sectors ranging from nuclear, up to energy and manufacturing. Currently, PLC vulnerability assessment practices employed by ICS operators are limited due to their reliance on empirical observations of visible code crashes prompted by PLC compilers. In parallel, the prevalent PLC firmware dependency on proprietary vendor routines restricts the composition of generic vulnerability detection or discovery schemes for zero-day threat vectors. In this work, we propose Sizzler: a novel vendor-independent vulnerability discovery framework specific to PLC applications operating with logic realised through ladder diagrams. Sizzler extends the current state of the art by proposing the optimal synergy of a mutation-based fuzzing strategy using Sequential Generative Adversarial Network (SeqGAN). By virtue of critical vendor restrictions on emulating PLC firmware, we also refine the Quick Emulator (QEMU)’s General Purpose I/O (GPIO) and the Inter-Integrated Circuit (I2C) protocols to evaluate and compare Sizzler across 30 PLC ladder diagram programs compiled from LDmicro and OpenPLC projects over five widely used Micro-Controller Units (MCUs). It is noteworthy that Sizzler has successfully identified vulnerabilities in ladder diagrams within a relatively short time frame based on our proprietary dataset and secured a CVE-ID. Moreover, through a comparison of Sizzler with prevalent fuzzing techniques over the commonly used Magma and LAVA-M datasets we exhibit its wider applicability on embedded systems and identify its limitations.},
  keywords={Fuzzing;Codes;Microprogramming;Emulation;Integrated circuits;Hardware;Protocols;Industrial control systems;programmable logic controllers;fuzzing;vulnerability discovery},
  doi={10.1109/TIFS.2023.3340615},
  ISSN={1556-6021},
  month={},}@ARTICLE{11029979,
  author={Wang, Haiyan and Wang, Bingjie and Huang, Wenbo and Liu, Yibin and Du, Yu and Hung, Guang-Uei and Hu, Zhanli and Mok, Greta S. P.},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Deep-learning-based Partial Volume Correction in 99mTc-TRODAT-1 SPECT for Parkinson's Disease: A Preliminary Study on Clinical Translation}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={99mTc-TRODAT-1 SPECT is effective for the early detection of Parkinson's disease (PD). However, SPECT images suffer from severe partial volume effect, which impairs tissue boundary clarity and subsequent quantification accuracy. This work proposes an anatomical prior- and segmentation-free deep learning (DL)-based partial volume correction (PVC) method using an attentionbased conditional generative adversarial network (Att-cGAN) for 99mTc-TRODAT-1 SPECT. A population of 454 digital brain phantoms modelling anatomical and 99mTc-TRODAT activity variations in different PD categories are used to generate realistic SPECT projections using the SIMIND Monte Carlo code, and then reconstructed using ordered subset expectation maximization algorithm. The dataset is split into 320, 44 and 90 used for training, validation, and testing. Att-cGAN, cGAN and U-Net are implemented based on simulated data, then directly tested on 100 retrospectively collected clinical 99mTc-TRODAT data, with same acquisition and reconstruction parameters as in simulations. Non-DL PVC methods of Van-Cittert and iterative Yang are implemented for comparison. Physical and clinical metrics, as well as a no-gold standard technique (NGST) are applied to evaluate different PVC methods in the absence of clinical ground truth. Att-cGAN yields superior PVC performance in simulations as compared to other methods in physical and clinical evaluations. NGST assessment is generally consistent with the clinical metric evaluation. For the clinical study, Att-cGAN also obtains better NGST result than others striatal compartments can be discriminated on DLbased processed images. DL-PVC method is feasible for clinical PD SPECT using highly realistic simulated data.},
  keywords={Single photon emission computed tomography;Image reconstruction;Data models;Training;Imaging phantoms;Image segmentation;Phantoms;Diseases;Artificial intelligence;Image resolution;Parkinson's disease;SPECT;partial volume correction;deep learning},
  doi={10.1109/JBHI.2025.3578526},
  ISSN={2168-2208},
  month={},}@ARTICLE{10807241,
  author={Zhang, Fan and Wang, Luyao and Zhang, Xinhong},
  journal={Big Data Mining and Analytics}, 
  title={Desensitized Financial Data Generation Based on Generative Adversarial Network and Differential Privacy}, 
  year={2025},
  volume={8},
  number={1},
  pages={103-117},
  abstract={Artificial intelligence has been widely used in the financial field, such as credit risk assessment, fraud detection, and stock prediction. Training deep learning models requires a significant amount of data, but financial data often contains sensitive information, some of which cannot be disclosed. Acquiring large amounts of financial data for training deep learning models is a pressing issue that needs to be addressed. This paper proposes a Noise Visibility Function-Differential Privacy Generative Adversarial Network (NVF-DPGAN) model, which generates privacy preserving data similar to the original data, and can be applied to data augmentation for deep learning. This study conducts experiments using financial data from China Stock Market & Accounting Research (CSMAR) database. It compares the generated data with real data from various perspectives, including mean, probability density distribution, and correlation. The experimental results show that the two datasets exhibit similar characteristics. A time series forecasting model is trained on the generated data and the real data separately, and their prediction results are closely aligned. NVF-DPGAN model is feasible and practical in terms of financial data enhancement and privacy protection. This method can also be generalized to other fields, such as the privacy protection of medical data.},
  keywords={Deep learning;Training;Differential privacy;Noise;Data enhancement;Time series analysis;Generative adversarial networks;Data models;Protection;Stock markets;data desensitization;Generative Adversarial Network (GAN);differential privacy;noise visibility function},
  doi={10.26599/BDMA.2024.9020047},
  ISSN={2097-406X},
  month={February},}@INPROCEEDINGS{10546023,
  author={Mohseni, Milad and Thilagham, K T and K, Aravinda and Kumar, B Santhosh and Nagpal, Amandeep and Geetha, B. T.},
  booktitle={2024 IEEE 13th International Conference on Communication Systems and Network Technologies (CSNT)}, 
  title={Deep Learning Applications in Microscopy and Holography for near-field Signal Processing}, 
  year={2024},
  volume={},
  number={},
  pages={612-618},
  abstract={Focusing on near-field signal processing, we provide a novel and comprehensive strategy for improving picture quality, obtaining super-resolution, and performing quantitative analysis in the disciplines of microscopy and holography. Three deep learning algorithms—Enhanced ImageNet (EINet), HoloReconGAN, and QuantSegNet—are combined in this method to maximize their potential. In order to improve images, super-resolve them, and analyze them quantitatively, many algorithms have been developed. In order to better comprehend each method, mathematical equations are provided to describe the main steps involved. With the use of convolutional neural networks, noise is reduced and finer features are brought into focus with the help of the Enhanced ImageNet (EINet) method. To accomplish super-resolution and 3D reconstruction from holographic data, HoloReconGAN combines generative adversarial networks (GANs) with variational autoencoders (VAEs). Label-free segmentation and quantitative analysis of structures in microscopy and holography pictures are the focus of QuantSegNet, a semantic segmentation network. Our suggested technique has been shown to outperform six established methods over a broad variety of assessment criteria. Image quality, noise suppression, feature recognition, computational efficiency, and resilience are just few of the areas where it shines. It's also faster, uses less memory, is more accurate, easier to use, cheaper, and faster. Applications in several scientific fields might be facilitated, and the area of microscopy and holography as a whole could see significant advancements as a result.},
  keywords={Deep learning;Technological innovation;Three-dimensional displays;Statistical analysis;Microscopy;Superresolution;Noise reduction;3D reconstruction;deep learning;holography;image enhancement;image quality;microscopy;near-field signal processing;quantitative analysis;super-resolution;label-free segmentation;robustness;computational efficiency;memory efficiency;accuracy},
  doi={10.1109/CSNT60213.2024.10546023},
  ISSN={2473-5655},
  month={April},}@INBOOK{10494663,
  author={Kaushik, Keshav},
  booktitle={Applying Artificial Intelligence in Cybersecurity Analytics and Cyber Threat Detection}, 
  title={Leveraging Deep Learning Techniques for Securing the Internet of Things in the Age of Big Data}, 
  year={2024},
  volume={},
  number={},
  pages={311-325},
  abstract={There is a growing need for adequate procedures to make sure that smart devices are resistant to different threats and assaults on the <term definitionRef="#c15-tdef-0001" type="abbreviation" xml:id="c15-term-0001">Internet of Things</term> (<termDefinition xml:id="c15-tdef-0001">IoT</termDefinition>) ecosystem as they continue to permeate many facets of our everyday lives. <term definitionRef="#c15-tdef-0002" type="abbreviation" xml:id="c15-term-0002">Deep learning</term> (<termDefinition xml:id="c15-tdef-0002">DL</termDefinition>) is proving to be one of the most effective and practical approaches in this area for addressing various IoT security issues. The massive increase in IoT device numbers makes them the primary source of data. Big data is being generated in enormous quantities via IoT. Big data analytics are used to harness the enormous volume of data and turn it into useful insights to maximize IoT's effectiveness. This elevates the IoT above simple monitoring equipment. IoT and big data combine nicely to provide analysis and insights. Big data analytics pushes the computer architecture to the margins for real&#x2010;time decision making because of the IoT.The chapter discusses the application of DL techniques for addressing the security challenges on the IoT systems. IoT security is a complex and challenging field, where the amount of data is constantly increasing, and traditional security approaches may not be sufficient. DL approaches have emerged as a promising tool for addressing these challenges. The author provides an overview of various DL techniques, such as anomaly detection, intrusion detection, malware detection, botnet detection, attack attribution, vulnerability assessment, and privacy&#x2010;preserving techniques. Convolutional neural networks, recurrent neural networks, autoencoders, and generative adversarial networks are just a few examples of DL architectures that are discussed in the author's discussion on the importance of DL in IoT security. Furthermore, the author discusses the big data challenges in IoT security and how DL can help address those challenges. Finally, the author discusses the future scope of DL in IoT security and the promising areas where DL can make significant contributions to ensuring the security and integrity of IoT systems.},
  keywords={Internet of Things;Security;Big Data;Organizations;Real-time systems;Memory;Recurrent neural networks},
  doi={10.1002/9781394196470.ch15},
  ISSN={},
  publisher={Wiley},
  isbn={9781394196456},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10494663},}@INPROCEEDINGS{10883930,
  author={Jain, Alok and William, P. and Ayasrah, Firas Tayseer and Lakshmi, G. Prasanna and Diwan, Tarun Dhar},
  booktitle={2024 11th International Conference on Software Defined Systems (SDS)}, 
  title={Analyzing Automatic Code Generation for Learning Models in Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={50-58},
  abstract={Independent code generation models produced by generative AI provide a new way to software development. These models automatically generate code using machine learning based on input samples. This study examines the fundamentals, applications, problems, and future prospects of AI-related automated code generation technologies. Model-based software, domain-specific code, and testing procedures are examples of these research topics. Performance analysis and assessment are used to assess the efficacy, efficiency, and reliability of several automated code generating methods. The fact that these models have pros and cons and room for development is highlighted.},
  keywords={Analytical models;Codes;Generative AI;Training data;Software;Software reliability;Performance analysis;Research and development;Software development management;Testing;Automatic code generation;Generative AI;machine learning;software development;testing methodologies;model-based development;domain-specific code generation},
  doi={10.1109/SDS64317.2024.10883930},
  ISSN={},
  month={Dec},}@ARTICLE{11015914,
  author={Wang, Yihao and Zhang, Yu and Qiao, Dewen and Guo, Songtao and Liu, Yu and Zhao, Chenhao and Gu, Tao and Ding, Qiaoqiao and Zhang, Xiaoqun and Chen, Xuetao},
  journal={IEEE Internet of Things Journal}, 
  title={EESyn-CTP: Edge-End Collaboration for Patient-Friendly CTP Image Synthesis}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In the field of medical imaging driven by the Internet of Things (IoT), with the rapid growth of the number of medical devices and the widespread application of edge computing (EC) technology, efficient collaborative computing on resource-constrained end medical devices has become the key to improving diagnostic efficiency, thereby bringing a more patient-friendly diagnosis and treatment experience. Computed tomography perfusion (CTP) images play an irreplaceable role in the assessment of brain tissue ischemia in patients with acute ischemic stroke (AIS), with high diagnostic accuracy in identifying ischemic lesions and distinguishing infarction from penumbra, but it has the disadvantages of high radiation dose and high cost. To this end, we propose a CTP image synthesis framework based on edge-end collaboration (EESyn-CTP), which aims to use non-contrast CT (NCCT), CT angiography (CTA), and delayed CTA (CTA+8s) images to synthesize CTP images with arbitrary time to optimize AIS diagnosis. The framework consists of two stages: the pre-training stage on the edge server and the fine-tuning stage on the end device. Specifically, we first deploy a temporal residual generative network, t-UNet, on the edge server for pre-training. This process utilizes multiple CTP images, which share similar perfusion features with CTA, CTA+8s, and NCCT images, to effectively learn the gap in perfusion information between the inputs and outputs. Subsequently, the pre-trained t-UNet model parameters are frozen and broadcast to the edge medical device. A UNet adapter is introduced before the model, and fine-tuning is performed on the adapter weights using real NCCT, CTA, and CTA+8s images as input. This approach facilitates the synthesis of CTP images at arbitrary time points. Finally, experiments on an internal data set showed that the quality of Syn-CTP images synthesized by the EESyn-CTP framework is comparable to that of real CTP images and significantly reduces computation latency and energy overhead.},
  keywords={Image edge detection;Artificial intelligence;Biomedical imaging;Computed tomography;Collaboration;Accuracy;Optimization;Medical diagnostic imaging;Internet of Things;Image synthesis;Internet of Things;edge computing;computed tomography perfusion;acute ischemic stroke;CT angiography},
  doi={10.1109/JIOT.2025.3573756},
  ISSN={2327-4662},
  month={},}@ARTICLE{10789626,
  author={Rodrigues Perche Mahlow, Felipe and Zanella, André Felipe and Cruz Castañeda, William Alberto and Aparecida Sarzi-Ribeiro, Regilene},
  journal={IEEE Latin America Transactions}, 
  title={Illustrating Classic Brazilian Books using a Text-To-Image Diffusion Model}, 
  year={2024},
  volume={22},
  number={12},
  pages={1000-1008},
  abstract={In recent years, Generative Artificial Intelligence (GenAI) has undergone a profound transformation in addressing intricate tasks involving diverse modalities such as textual, auditory, visual, and pictorial generation. Within this spectrum, text-to-image (TTI) models have emerged as a formidable approach to generating varied and aesthetically appealing compositions, spanning applications from artistic creation to realistic facial synthesis, and demonstrating significant advancements in computer vision, image processing, and multimodal tasks. The advent of Latent Diffusion Models (LDMs) signifies a paradigm shift in the domain of AI capabilities. This article delves into the feasibility of employing the Stable Diffusion LDM to illustrate literary works. For this exploration, seven classic Brazilian books have been selected as case studies. The objective is to ascertain the practicality of this endeavor and to evaluate the potential of Stable Diffusion in producing illustrations that augment and enrich the reader's experience. We will outline the beneficial aspects, such as the capacity to generate distinctive and contextually pertinent images, as well as the drawbacks, including any shortcomings in faithfully capturing the essence of intricate literary depictions. Through this study, we aim to provide a comprehensive assessment of the viability and efficacy of utilizing AI-generated illustrations in literary contexts, elucidating both the prospects and challenges encountered in this pioneering application of technology.},
  keywords={Artificial intelligence;Image synthesis;Diffusion models;Training;Visualization;Text to image;Noise reduction;Computational modeling;Refining;Ethics;image generation;diffusion models;text-to-image;illustration},
  doi={10.1109/TLA.2024.10789626},
  ISSN={1548-0992},
  month={Dec},}@ARTICLE{9965611,
  author={Zhu, Ziye and Tong, Hanghang and Wang, Yu and Li, Yun},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={BL-GAN: Semi-Supervised Bug Localization via Generative Adversarial Network}, 
  year={2023},
  volume={35},
  number={11},
  pages={11112-11125},
  abstract={Various automated bug localization technologies have recently emerged that require adequate bug-fix records available to train a predictive model. However, many projects in practice might not provide these necessities, especially for new projects in the first release, due to the expensive human effort for constructing a large amount of bug-fix records. Aiming to capture the potential relevance distribution between the bug report and code file from a limited number of available bug-fix records, we present the first semi-supervised bug localization model named BL-GAN in this paper. For this purpose, the promising Generative Adversarial Network is introduced in BL-GAN, in which synthetic bug-fix records close to the real ones are constructed by searching the project directory tree to generate file paths instead of traversing the contents of all code files. For processing bug reports, the proposed BL-GAN adopts an attention-based Transformer architecture to capture semantic and sequence information. In order to capture the proprietary structural information in code files, BL-GAN incorporates a novel multilayer Graph Convolutional Network to process the source code in a graphical view. Extensive experiments on large-scale real-world datasets reveal that our model BL-GAN significantly outperforms the state-of-the-art on all evaluation measures.},
  keywords={Computer bugs;Codes;Location awareness;Generative adversarial networks;Generators;Task analysis;Feature extraction;Bug localization;bug report;semi-supervised learning;generative adversarial network},
  doi={10.1109/TKDE.2022.3225329},
  ISSN={1558-2191},
  month={Nov},}@ARTICLE{10290887,
  author={Makris, Nikolaos and Mitrou, Nikolaos},
  journal={IEEE Access}, 
  title={Multisubject Analysis and Classification of Books and Book Collections, Based on a Subject Term Vocabulary and the Latent Dirichlet Allocation}, 
  year={2023},
  volume={11},
  number={},
  pages={120881-120898},
  abstract={In this paper, a new method for automatically analyzing and classifying books and book collections according to the subjects they cover is presented. It is based on a combination of the LDA method for discovering latent topics in the collection, on the one hand, and the description of subjects by means of a subject term vocabulary, on the other. Books, topics and subjects, all are modelled as bag-of-words, with specific distributions over the underlying word vocabulary. The Table of Contents (ToC) was used to describe the books, instead of their entire body, while subject (or standard) documents are produced by a subject term hierarchy of the respective disciplines. Frequency-of-terms in the documents and word-generative probabilistic models (as the ones postulated by LDA) were integrated into a consistent statistical framework. Using Bayesian statistics and simple marginalization equations we were able to transform the expressions of the books from distributions over unlabeled topics (derived by the LDA) to distributions over labeled subjects representing the respective disciplines (Physical sciences, Health sciences, Mathematics, etc). More specifically, the necessary theoretical basis is firstly established, with each subject formally defined by the respective branch of a subject term hierarchy (much like a ToC) or the respective bag of words (single words and biwords) produced by flattening the hierarchy branch; flattening is realized by taking all the terms of the nodes and leaves of the branch with repetitions allowed. Being confined within a closed set of subjects, we are able to invert the frequency-of-terms in each subject [also interpreted as the probability of generating a term ( $w_{n}$ ) when sampling the subject ( $s_{i}$ ) and denoted by Pr{ $w_{n}\vert $   $s_{i}$ })] and express each term as a weighted mixture (or probability distribution) of subjects, denoted by Pr{ $s_{i}\vert $   $w_{n}$ }. This is the key idea of the proposed method. Then, any document (dm) can be expressed as a weighted mixture of subjects (or the respective distribution, denoted by Pr{ $s_{i}\vert \text{d}_{m}$ }) by simply summing up the distributions of the individual terms contained in the document. This is made possible by virtue of some simple formulas that have been formally proven for the union of documents ( $\Pr \left \{{{\mathrm {s}_{i}\vert (\mathbf {d}}_{1}\mathrm {\cup }\mathbf {d}_{2}) }\right \})$  and for the union of subjects  $(\Pr \left \{{{\mathrm {(\mathbf {s}}}_{i}\mathrm {\cup }\mathbf {s}_{j}\mathrm {)\vert \mathbf {d}} }\right \})$ . Since not all vocabulary terms are found in a particular set of books, nor, conversely, all corpus words are included in the subject vocabulary either, two important measures come to the foreground and are calculated with the proposed formulation: the coverage of a book or a corpus by the subject term vocabulary and, conversely, the vocabulary coverage by a set of books. These measures are useful for updating/enriching the subject term vocabulary, whenever it happens that documents with new subjects are included in the corpus under analysis. Following the theoretical formulation, the derived results are combined with the LDA in order to further facilitate our multisubject analysis task: using the subject term vocabulary, LDA is applied on the corpus under study and results in expressing each book (bm), as a probability distribution over hidden topics (denotedby  $\text{Pr}\left\{\mathbf{t}_k \mid \mathbf{b}_m\right\}$ ). In the same framework, each topic  $\left(\mathbf{t}_k\right)$  is expressed as a probability distribution over words  $\left(\text{Pr}\left\{w_n \mid \mathbf{t}_k\right\}\right)$ . Having estimated each word's probability distribution over subjects  $\left(\text{Pr}\left\{\mathbf{s}_i \mid w_n\right\}\right)$ , we can express each discovered topic as a weighted mixture of subjects  $\left[\text{Pr}\left\{\mathbf{s}_i \mid \mathbf{t}_k\right\}=\sum_n \text{Pr}\left\{w_n \mid \mathbf{t}_k\right\} \text{Pr}\left\{\mathbf{s}_i \mid w_n\right\}\right]$  and, by using that, we express each book in the same manner  $\left[\text{Pr}\left\{\mathbf{s}_i \mid \mathbf{b}_m\right\}=\sum_k \text{Pr}\left\{\mathbf{t}_k \mid \mathbf{b}_m\right\} \text{Pr}\left\{\mathbf{s}_i \mid \mathbf{t}_k\right\}\right]$ . This is a very clear and formal way towards obtaining the desired result. The proposed methodology was applied to a Springer's e-book collection with more than 50,000 books, while a subject term hierarchy developed by KALLIPOS, a project creating openaccess e-books, was used for the proof of concept. A number of experiments were conducted to showcase the validity and usefulness of the proposed approach.},
  keywords={Vocabulary;Probability distribution;Task analysis;Resource management;Ensemble learning;Recurrent neural networks;Probabilistic logic;Artificial intelligence;digital libraries;classification algorithms;latent Dirichlet allocation;multi-subject classification;statistical natural language processing;subject headings;university coursebooks;Springer ebooks;Kallipos project},
  doi={10.1109/ACCESS.2023.3326722},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10725605,
  author={Ranjit, Gayathri and Subramoniam, Suresh and Jnaneswar, K},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Evidences of AI powered Use Cases and Challenges in E-tailing from leading Indian E-tailers}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The paper highlights the usage and challenges of artificial intelligence in etailing, citing use cases from leading Indian etailers like Amazon and Flipkart. Both organizations have embraced artificial intelligence in a number of ways to improve its operations and enhance customer experience. AI has emerged as a powerful tool that has significantly impacted etailers throughout the globe and especially in India. The results of the study show that both etailers have harnessed the transformative capabilities of AI to secure a strong market position. While Amazon employs machine learning, chatbot assistants, product recommendations, and generative AI, Flipkart applies AI for customized search, issue detection, Microsoft partnership, project Mira to name a few. This article is a reflection of how these leading Indian e-tailers has devoted resources to developing AI capabilities and also exposes the challenges involved like security risks, perception regarding ethics, technology integration, culture wars and quality of data.},
  keywords={Technological innovation;Companies;Machine learning;Reflection;Product design;Quality assessment;Electronic commerce;Security;Artificial intelligence;Guidelines;artificial intelligence;e-tailing;machine learning;chatbot;generative AI;Mira},
  doi={10.1109/ICCCNT61001.2024.10725605},
  ISSN={2473-7674},
  month={June},}@ARTICLE{10988859,
  author={Liu, Chenyang and Chen, Keyan and Zhao, Rui and Zou, Zhengxia and Shi, Zhenwei},
  journal={IEEE Geoscience and Remote Sensing Magazine}, 
  title={Text2Earth: Unlocking text-driven remote sensing image generation with a global-scale dataset and a foundation model}, 
  year={2025},
  volume={},
  number={},
  pages={2-23},
  abstract={Recently, generative foundation models (GFMs) have significantly advanced large-scale text-driven natural image generation and become a prominent research trend across various vertical domains. However, in the remote sensing field, there is still a lack of research on large-scale text-to-image (text2image) generation technology. Existing remote sensing image‒text datasets are small in scale and confined to specific geographic areas and scene types. Besides, existing text2image methods have struggled to achieve global-scale, multiresolution controllability, and unbounded image generation. To address these challenges, this article presents two key contributions: the Git-10M dataset and the Text2Earth foundation model. Git-10M is a global-scale image‒text dataset consisting of 10.5 million image‒text pairs, five times larger than the previous largest one. The dataset covers a wide range of geographic scenes and contains essential geospatial metadata, significantly surpassing existing datasets in both size and diversity. Building on Git-10M, we propose Text2Earth, a 1.3 billion-parameter GFM based on the diffusion framework to model global-scale remote sensing scenes. Text2Earth integrates a resolution guidance mechanism, enabling users to specify image resolutions. A dynamic condition adaptation (DCA) strategy is proposed for training and inference to improve image generation quality. Text2Earth not only excels in zero-shot text2image generation but also demonstrates robust generalization and flexibility across multiple tasks, including unbounded scene construction, image editing, and cross-modal image generation. This robust capability surpasses previous models restricted to basic fixed sizes and limited scene types. On the previous text2image benchmark dataset, Text2Earth outperforms previous models, with a significantly improved +26.23 Fréchet inception distance (FID) score and +20.95% zero-shot classification overall accuracy (Cls-OA) metric. Our project page is https://chen-yang-liu.github.io/Text2Earth/.},
  keywords={Remote sensing;Image resolution;Image synthesis;Training;Foundation models;Diffusion models;Visualization;Spatial resolution;Noise reduction;Metadata},
  doi={10.1109/MGRS.2025.3560455},
  ISSN={2168-6831},
  month={},}@INPROCEEDINGS{10350585,
  author={Song, Hao and Panjvani, Karim and Liu, Zhigang and Amar, Huzaifa and Kochian, Leon and Ye, Shengjian and Yang, Xuan and Feurtado, J. Allan and Chavda, Krunal and Chimbo Huatatoca, Karina Angela and Eramian, Mark},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}, 
  title={Plant Root Occlusion Inpainting with Generative Adversarial Network}, 
  year={2023},
  volume={},
  number={},
  pages={531-539},
  abstract={Three-dimensional (3D) image analysis represents the state-of-the art for phenotyping in the fields of biology and plant science including studies of root system architecture. A widely used approach for capturing root architecture in 3D involves growth of roots in hydroponic media and capture of optical camera views via a stepper-motor-based rotation system. However, the introduction of structures to support 3D root growth system leads to significant occlusion of the roots during image acquisition, thereby causing the complexity and introducing inaccuracy of subsequent operations such as 3D modeling and root traits calculation. Instead of using a traditional manual sketching methods, this project proposes an automatic root gaps detection and inpainting method based on a Generative Adversarial Networks (GAN). The model was trained and evaluated using two distinct maize datasets, both of which were enriched with manually annotated segmentation and inpainting labels. The quantitative analysis of the inpainting results demonstrated variation in the performance of the GAN model. However, promising outcomes were observed with certain instances achieving Intersection of Union (IoU) and Dice Similarity Coefficient (DSC) values surpassing 0.9 with specific images or patches exhibiting lower accuracy and reproducibly. Despite this variability, the overall model performance maintained an average range of 0.8-0.9. Our GAN model presents a robust, effective and automatic solution for inpainting plant root gaps, leading to improved accuracy within the phenotyping pipeline. Moreover, the model demonstrates a great generality for inpainting other root system of species or cultivars beyond those encountered during training. The performance of the model exhibits superiority when confronted with less intricate root structures, but it produces less accurate results when confronted with complex root systems with large gaps or high root density.},
  keywords={Training;Analytical models;Three-dimensional displays;Statistical analysis;Plants (biology);Pipelines;Systems architecture;Deep Learning;Inpainting;Generative Adversarial Network;Plant Root;Root System Architecture;Plant Root Phenotyping},
  doi={10.1109/ICCVW60793.2023.00060},
  ISSN={2473-9944},
  month={Oct},}@ARTICLE{10980460,
  author={Zhang, Junkang and Fang, Faming and Wang, Tingting and Zhang, Guixu and Song, Haichuan},
  journal={IEEE Transactions on Multimedia}, 
  title={FrDiff: Framelet-based Conditional Diffusion Model for Multispectral and Panchromatic Image Fusion}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={The process of fusing low-resolution multispectral (LRMS) and high-resolution panchromatic (PAN) imagery, commonly referred to as pansharpening, is intended to generate high-resolution multispectral (HRMS) imagery. Typically, most pre-existing pansharpening frameworks mainly emphasize the straightforward learning of the mapping relationship among PAN and LRMS images to HRMS images. However, a key limitation of these frameworks is their potential overemphasis on spatial information, particularly the enhancement of low-frequency components. As a result, such an oversight potentially hinders the model's ability to simultaneously restore both spectral and spatial details. To address this issue, we propose a novel pansharpening model based on the denoising diffusion probabilistic model (DDPM), dubbed FrDiff. Specifically, we build a framelet-based conditional diffusion model that leverages the generative power of diffusion models to produce more refine results. Different from conventional methods directly inferring HRMS images, our strategy is designed to project their framelet coefficients, utilizing the available PAN and LRMS images as resources. This approach enables the separation of high-frequency and low-frequency components through framelet transformation, which are subsequently recombined to create a novel set of conditional embeddings that feed into the diffusion process. At the same time, the powerful predictive power of the diffusion model is exploited to simultaneously recover the high-frequency and low-frequency components of the HRMS. Moreover, we introduce a framelet-oriented cross-attention module dedicated to honing spectral fidelity. This module is crucial for improving the spectral precision of the HRMS images, ensuring a balanced emphasis on both spatial and spectral enhancements. Quantitative and qualitative experiments on multiple benchmark datasets demonstrate that the proposed method achieves more robustness and high-quality results than other state-of-the-art pansharpening methods.},
  keywords={Pansharpening;Diffusion models;Spatial resolution;Remote sensing;Noise reduction;Multiresolution analysis;Training;Image restoration;Image fusion;Deep learning;Convolutional neural network;diffusion model;pansharpening;framelet transform},
  doi={10.1109/TMM.2025.3565985},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10122084,
  author={Stürmer, Matthias},
  booktitle={2023 Ninth International Conference on eDemocracy & eGovernment (ICEDEG)}, 
  title={Keynote - AI for the Public Sector and the Case of Legal NLP}, 
  year={2023},
  volume={},
  number={},
  pages={1-2},
  abstract={Recent innovations such as ChatGPT have increased public interest in artificial intelligence (AI). The keynote explained why AI is not just a short-term hype but has a long history of spanning several eras. A recent revolution has been in the field of Natural Language Processing (NLP). This interdisciplinary field of research is also known as computational linguistics. It is usually implemented by specific NLP tasks, ranging from simple processing steps such as tokenization, stemming, lemmatization to Part of Speech (PoS) tagging and topic modeling. A second, more complex set of NLP tasks includes Namend Entity Recognition (NER), information retrieval, relationship extraction, sentiment analysis, text similarity, and coreference resolution. Finally, the most challenging NLP tasks are considered Question Answering (QA), text summarization, text simplification, text generation, text translation, and chatbots. NLP has especially great potential in the public sector. For example, a new multilingual legal language model for more than 20 languages, developed for the Swiss Federal Court, offers opportunities to increase accessibility of legal documents for citizens while preserving the digital sovereignty of government institutions. These technical results of the National Research Program (NRP) 77 project “Open Justice versus Privacy” are published on Hugging Face, a platform for sharing openly available machine learning models and datasets. Today, it is mostly private companies that build such Large Language Models (LLM), because it requires a large amount of computational resources and highly skilled engineers. For example, to train the new LLaMA model, Meta AI (Facebook) needed more than $30 million worth of graphical processing units (GPU). In addition, 450 MWh of electricity worth about $90,000 was needed to process the data on these GPUs. Negative for innovation and the environment, Meta AI released the LLaMA model only under a non-commercial license. This means that startups and other companies cannot use the model for their own services. This calls for a discussion about how “open” today's machine learning models should be and what “open” actually means in the age of AI. The keynote presentation therefore included a proposal of 5 elements of such machine learning models that need to be openly available and licensed under an official open license in order to speak of an Open AI Model. This term is used by the United Nations definition of Digital Public Goods. These five elements include 1) model architecture (detailed scientific publications), 2) hyperparameters (built configuration), 3) training data (labeled and unlabeled datasets), 4) model weights and intermediate checkpoints (parameters), and 5) source code to build the model (programming scripts etc.). A truly openly available AI model is BLOOM, an LLM from the BigScience initiative. It was built by more than 1000 researchers from over 70 countries, trained on an infrastructure that would have cost EUR 3 million. BLOOM was released on July 12th, 2022 on Hugging Face and is licensed under the Responsible AI License (RAIL), a new type of AI license that incorporates ethical aspects while preserving the openness of the machine learning elements described.},
  keywords={},
  doi={10.1109/ICEDEG58167.2023.10122084},
  ISSN={2573-1998},
  month={April},}@INPROCEEDINGS{10398616,
  author={Muresan, Smaranda},
  booktitle={2023 IEEE 19th International Conference on Intelligent Computer Communication and Processing (ICCP)}, 
  title={Keynote Lecture: Human-centric Natural Language Processing for Social Good and Responsible Computing}, 
  year={2023},
  volume={},
  number={},
  pages={vii-vii},
  abstract={Large language models (LLMs) constitute a paradigm shift in Natural Language Processing and its applications across all domains. To move towards human-centric NLP designed for social good and responsible computing, I argue we need knowledge-aware NLP systems and human-AI collaboration frameworks. NLP systems that interact with humans need to be knowledge aware (e.g., linguistic, commonsense, sociocultural norms) and context aware (e.g., social, perceptual) so that they communicate better and in a safer and more responsible fashion with humans. Moreover, NLP systems should be able to collaborate with humans to create high-quality datasets for training and/or evaluating NLP models, to help humans solve tasks, and ultimately to align better with human values. In this talk, I will give a brief overview of my research agenda in the context of NLP for social good and responsible computing (e.g., misinformation detection, NLP for education and public health, building NLP technologies with language and culture diversity in mind). I will highlight key innovations on theory-guided and knowledge-aware models that allow us to address two important challenges: lack of training data, and the need to model commonsense knowledge. I will also present some of our recent work on human-AI collaboration frameworks for building high-quality datasets for various tasks such as generating visual metaphors or modeling cross-cultural norms similarities and differences.},
  keywords={},
  doi={10.1109/ICCP60212.2023.10398616},
  ISSN={2766-8495},
  month={Oct},}@ARTICLE{10319928,
  author={Sánchez-Gordón, Mary and Tovar, Edmundo and Colomo-Palacios, Ricardo and Piedra, Nelson and Castro, Manuel},
  journal={Computer}, 
  title={Educating Augmented Programmers}, 
  year={2023},
  volume={56},
  number={12},
  pages={100-104},
  abstract={There is an artificial intelligence-based technology that has the potential to augment the work of human programmers. This article discusses some capabilities built around generative artificial intelligence and large language models that impact programming education.},
  keywords={Computer languages;Programming environments;Artificial intelligence;Human factors;Computer science education},
  doi={10.1109/MC.2023.3313325},
  ISSN={1558-0814},
  month={Dec},}@ARTICLE{10547114,
  author={Bego, Campbell R. and Nwokeji, Joshua C. and Trytten, Deborah A.},
  journal={IEEE Transactions on Education}, 
  title={FIE-TOE Guest Editorial Grand Challenges in Engineering and Computing Education: Beyond the Pandemic}, 
  year={2024},
  volume={67},
  number={3},
  pages={333-335},
  abstract={The promise of engineering and computing education is to prepare and fully equip students to solve societal problems that are complex, open-ended, and/or poorly defined [1]. So far, engineering and computing educators have made notable progress toward fulfilling this promise. However, established practices are constantly tested by new challenges like those caused by the coronavirus pandemic and breakthroughs in generative artificial intelligence. For engineering and computing education to achieve its full potential and deliver its promise, these new challenges have to be elicited, analyzed, and addressed.},
  keywords={Special issues and sections;Engineering education;Computer science education;Social factors;Problem-solving;Curriculum development;Generative AI;Pandemics;Social implications of technology},
  doi={10.1109/TE.2024.3382848},
  ISSN={1557-9638},
  month={June},}@ARTICLE{10660597,
  author={Reisman, Sorel},
  journal={Computer}, 
  title={Generative Artificial Intelligence and Problematic Student E-Mails}, 
  year={2024},
  volume={57},
  number={9},
  pages={124-127},
  abstract={Students often challenge their instructors via e-mail. This, in turn, requires instructors to respond with tact. Can generative artificial intelligence be harnessed to compose tactful replies to the toughest student criticism?},
  keywords={Generative AI;Electronic mail;Writing;Professional communication;Artificial intelligence;Education},
  doi={10.1109/MC.2024.3422548},
  ISSN={1558-0814},
  month={Sep.},}@ARTICLE{10639261,
  author={Joshi, Rajiv and Ziegler, Matthew and Han, Jin-Ping and Maghraoui, Kaoutar El},
  journal={IEEE Circuits and Systems Magazine}, 
  title={6th IBM IEEE CAS/EDS AI Compute Symposium (AICS’23) [CASS Conference Highlights]}, 
  year={2024},
  volume={24},
  number={3},
  pages={49-53},
  abstract={The 6th IBM IEEE CAS/EDS AI Compute Symposium was held hybrid at the T. J. Watson Research Center on 28 November 2023. The event was extremely successful and well attended by over 2000 folks from all over the world (in-person and virtual). The symposium featured 8 distinguished speakers (7 from industry and 1 from academia), over 30 student in-person posters, best poster awards, and a panel discussion. The registration list spanned citizens of 53 countries. The theme of the symposium, “From Chips to Chiplets,” turned out to be an opportune and important topic for the current semiconductor industry direction. The symposium served as an educational as well as a brainstorming session for industry/academia/students across the world. The symposium covered a range of topics from emerging device technology, innovative circuits, chip and chiplet architecture, advanced packaging technologies, such as 2D to 3D packaging elements, and how these topics drive the rapid growth of AI and generative AI. Dr. Rajiv Joshi, General Chair and IEEE Life Fellow opened the symposium with welcoming remarks along with the goals and accomplishments of this symposium under the auspices of CAS and IBM.},
  keywords={},
  doi={10.1109/MCAS.2024.3395580},
  ISSN={1558-0830},
  month={thirdquarter},}@ARTICLE{10718671,
  author={Gupta, Varun and Gupta, Chetna},
  journal={Computer}, 
  title={Navigating the Landscape of AI-Generated Text Detection: Issues and Solutions for Upholding Academic Integrity}, 
  year={2024},
  volume={57},
  number={11},
  pages={118-123},
  abstract={Artificial intelligence (AI) generative tools offer students significant opportunities, albeit posing challenges to academic integrity. Given the constant advancements in generative AI, AI detection, and AI humanizer technologies, we provide three proactive strategies toward assuring such integrity.},
  keywords={},
  doi={10.1109/MC.2024.3445068},
  ISSN={1558-0814},
  month={Nov},}
@ARTICLE{10547095,
  author={Reisman, Sorel},
  journal={Computer}, 
  title={Practical Classroom Use of Generative Artificial Intelligence—A Case Study}, 
  year={2024},
  volume={57},
  number={6},
  pages={110-114},
  abstract={This article describes the author’s unsuccessful attempt to use current generative artificial intelligence tools to reduce instructors’ workloads by creating course syllabi that reference no cost resources.},
  keywords={Generative AI;Performance evaluation;Educational technology;Educational courses;Costs;Quality assessment;Software tools},
  doi={10.1109/MC.2024.3382453},
  ISSN={1558-0814},
  month={June},}@ARTICLE{10660605,
  author={Kshetri, Nir and Voas, Jeffrey},
  journal={Computer}, 
  title={Adapting to Generative Artificial Intelligence: Approaches in Higher Education Institutions}, 
  year={2024},
  volume={57},
  number={9},
  pages={128-133},
  abstract={Generative artificial intelligence (GAI) is reshaping higher education institutions (HEIs). HEIs are responding with policies, leveraging GAI to optimize operations, update curricula, and develop multidisciplinary programs, showcasing a proactive approach to transformative educational practices.},
  keywords={Generative AI;Educational programs;Educational institutions;Curriculum development},
  doi={10.1109/MC.2024.3422589},
  ISSN={1558-0814},
  month={Sep.},}@INPROCEEDINGS{10332336,
  author={Vidmar, Matjaz and Fleck, James and Williams, Robin},
  booktitle={2023 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)}, 
  title={AI and Data in Engineering and Innovation: Towards a Sustainable Future?}, 
  year={2023},
  volume={},
  number={},
  pages={1-2},
  abstract={29th International Conference on Engineering, Technology, and Innovation (ICE 2023) touched upon the critical issues in engineering of the generative AI era. By looking at the key challenges in data-driven project management and sustainable development, the overarching theme emerging from the event was one of adaptation to AI and data tools as essential part of the work process and supporting new approaches in engineering, technology development and innovation and entrepreneurship. This points to a promising future ahead, where digital transformation reaches the extended engineering disciplines, which is the theme of the following ICE conference. Having said that, the use of digital tools also presents a number of problems, from data-driven biases to challenges of interdisciplinary, inter-organisational and inter-entity collaborations.},
  keywords={ICE 2023;artificial intelligence;sustainability;data;interdisciplinarity},
  doi={10.1109/ICE/ITMC58018.2023.10332336},
  ISSN={2693-8855},
  month={June},}@ARTICLE{10458714,
  author={Togelius, Julian and Yannakakis, Georgios N.},
  journal={Proceedings of the IEEE}, 
  title={Choose Your Weapon: Survival Strategies for Depressed AI Academics [Point of View]}, 
  year={2024},
  volume={112},
  number={1},
  pages={4-11},
  abstract={As someone who does artificial intelligence (AI) research in a university, you develop a complicated relationship with the corporate AI research powerhouses, such as Google DeepMind, OpenAI, and Meta AI. Whenever you see one of these papers that train some kind of gigantic neural net model to do something you were not even sure a neural network could do, unquestionably pushing the state-of-the-art and reconfiguring your ideas of what is possible, you get conflicting emotions. On the one hand, it is very impressive. Good on you for pushing AI forward. On the other hand, how could we possibly keep up? As an AI academic, leading a laboratory with a few Ph.D. students and (if you are lucky) some postdoctoral fellows, perhaps with a few dozen graphics processing units (GPUs) in your laboratory, this kind of research is simply not possible to do.},
  keywords={Research and development;Artificial intelligence;Deep learning;Ethics;Education;Philosophical considerations;Scientific publishing;Business;Cultural aspects;Social implications of technology;Social factors;Human factors;Industries},
  doi={10.1109/JPROC.2024.3364137},
  ISSN={1558-2256},
  month={Jan},}@ARTICLE{10111517,
  author={Dix, Jürgen and Zhang, Zhongfei},
  journal={IEEE Intelligent Systems}, 
  title={AI’s 10 to Watch, 2022}, 
  year={2023},
  volume={38},
  number={2},
  pages={3-14},
  abstract={IEEE Intelligent Systems is promoting young and aspiring artificial intelligence (AI) scientists and recognizing the rising stars as “AI‘s 10 Watch.” This biennial 2022 edition is slightly different from the previous editions: We solicited submissions from individuals who had obtained their Ph.D. up to 10 years prior (as opposed to 5 years in all of the previous editions). This led to more applications of the highest quality. The selection committee finally had to select 10 outstanding contributors from a pool of 30+ highly competitive and strong nominations, which made the selection decisions rather difficult. After a careful and detailed selection process through many rounds of discussions via e-mails and live meetings, the committee voted unanimously on a short list of 10 top candidates who have all demonstrated outstanding achievements in different areas of AI. The selection was based solely on scientific quality, reputation, impact, and expert endorsements accumulated since their Ph.D. It is our honor and privilege to announce the following 2022 class of “AI’s 10 to Watch.”• Bo Li. She is working on trustworthy machine learning (ML) at the intersection of ML, security and privacy, and game theory. She was able to integrate domain knowledge and logical reasoning abilities into data-driven statistical ML models to improve learning robustness with guarantees, and she has designed scalable privacy-preserving data-publishing frameworks for high-dimensional data. Her work has provided rigorous guarantees for the trustworthiness of learning systems and been deployed in industrial applications. She is an assistant professor with the University of Illinois at Urbana-Champaign.• Tongliang Liu. He is working in the fields of trustworthy ML. His work in theories and algorithms of ML with noisy labels has led to significant contributions and influence in the fields of ML, computer vision, natural language processing (NLP), and data mining, as large-scale datasets in those fields are prone to suffering severe label errors. He is a senior lecturer at the School of Computer Science, University of Sydney, and a visiting associate professor at the Department of Machine Learning, Mohamed bin Zayed University of Artificial Intelligence.• Liqiang Nie. He is the dean of and a professor with the School of Computer Science and Technology, Harbin Institute of Technology (Shenzhen). He works on multimedia content analysis and search, with a particular emphasis on data-driven multimodal learning and knowledge-guided multimodal reasoning. He pioneered the explicit modeling of consistent, complementary, and partial alignment relationships among modalities.• Soujanya Poria. He is an assistant professor at Singapore University of Technology and Design (SUTD). His seminal research on fusing information from textual, audio, and visual modalities for diverse behavioral and affective tasks significantly improved systems reliant on multimodal data, paving the way to various novel research avenues. His latest works are on information extraction, vision–language reasoning, and understanding human conversations in terms of common sense-based, context-grounded causal explanations.• Deqing Sun. He is a staff research scientist at Google. He has made significant contributions to computer vision, in particular in motion estimation. His work on optical flow (“Classic+NL” and “PWC-Net”) has been very influential and has been powering commercial applications such as Super SloMo in NVIDIA’s RTX platform, Face Unblur, and Fusion Zoom on Google’s Pixel phone.• Yizhou Sun. She is a pioneer in heterogeneous information network (HIN) mining, with a recent focus on deep graph learning, neural symbolic reasoning, and providing neural solutions to multiagent dynamical systems. Her work has a wide spectrum of applications, ranging from e-commerce, health care, and material science to hardware design. She is currently an associate professor at the University of California, Los Angeles (UCLA).• Jiliang Tang. He is a University Foundation Professor at Michigan State University. He works on graph ML and trustworthy AI and their applications in education and biology. His contributions to these fields include highly cited algorithms, well-received systems, and popular books.• Zhangyang “Atlas” Wang. He works on efficient and reliable ML. Recently, his core research theme is to leverage, understand, and expand the role of sparsity, from classical optimization to modern neural networks (NNs), whose impacts span the efficient training/inference of large-foundation models, robustness and trustworthiness, generative AI, graph learning, and more.• Hongzhi Yin. He has worked on trustworthy data intelligence to turn data into privacy-preserving, robust, explainable, and fair intelligent services in various industries and scenarios. He is also a leading expert researching and developing next-generation intelligent systems and algorithms for lightweight on-device predictive analytics as well as recommendation and decentralized ML on massive and heterogeneous data. He is an associate professor and ARC Future Fellow at the University of Queensland.• Liang Zheng. He is a senior lecturer at the Australian National University and works on data-centric computer vision, where he seeks to improve the quality of training and validation data, predict test data difficulty without labels, and more. These efforts provide a complementary perspective to model-centric developments. He has also made significant contributions to object re-identification and the broader smart city initiative through the introduction of widely used benchmarks and baseline methods.},
  keywords={Intelligent systems;Artificial intelligence;Companies;Computer applications},
  doi={10.1109/MIS.2023.3252919},
  ISSN={1941-1294},
  month={March},}
