@inproceedings{10.1145/3715669.3725868,
author = {Mohamed, Suad and Ismail, Najma and Amaya Hernandez, Kimberly and Parvin, Abdullah and Oliver, Michael and Parra, Esteban},
title = {Design of An Eye-Tracking Study Towards Assessing the Impact of Generative AI Use on Code Summarization},
year = {2025},
isbn = {9798400714870},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715669.3725868},
doi = {10.1145/3715669.3725868},
abstract = {As large language models (LLMs) become more integrated into software engineering and computer science education, it is crucial to understand their impact on student learning. While recent research has explored student perceptions of generative AI, little is known about how these tools influence students’ cognitive processes during programming tasks, such as code comprehension, a valuable skill in software development and maintenance. This paper presents the design of a study that aims to investigate how computer science students interact with LLMs, such as Google’s Gemini, in the context of code summarization using eye-tracking. This study will examine differences in visual attention, fixation behaviors, and performance of students engaged in code summarization with and without AI assistance across varying experience levels.},
booktitle = {Proceedings of the 2025 Symposium on Eye Tracking Research and Applications},
articleno = {80},
numpages = {8},
keywords = {Code Summarization, Eye tracking, empirical study, code comprehension, Large Language Models, AI4SE},
location = {
},
series = {ETRA '25}
}

@article{10.5555/3715602.3715614,
author = {Rhee, Junghwan and Shrestha, Aakankshya and Qian, Gang and Zuo, Fei and Fu, Jicheng and Park, Myungah and Qu, Xianshan and Mylavarapu, Goutam and Sung, Hong},
title = {An Evaluation on the Impact of Large Language Models on Computer Science Curricula},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {Since their introduction, large language model (LLM) services have been widely used in our society, including the computer science education area. While this technology provides various types of intelligent assistance to users, its capabilities and impact on computer science education regarding students' learning need further study. In this paper, we present our manual assessment of LLM services' ability to solve questions in various course assignments and projects in our computer science curriculum. Based on the result of the study, we provide our observations of the extent of LLM services' impact on different computer science disciplines. Suggestions are summarized and offered to computer science instructors on the possible strategies for dealing with LLMs in current and future computer science curriculum designs.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {70–80},
numpages = {11}
}

@inproceedings{10.1145/3641555.3705215,
author = {Niousha, Rose and O'Neill, Abigail and Chen, Ethan and Malhotra, Vedansh and Akram, Bita and Norouzi, Narges},
title = {LLM-KCI: Leveraging Large Language Models to Identify Programming Knowledge Components},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705215},
doi = {10.1145/3641555.3705215},
abstract = {Identifying Knowledge Components (KCs) in computer science education improves curriculum design and teaching strategies. We introduce a framework using Large Language Models to identify KCs from programming assignments automatically. Our framework helps educators align assignments with course objectives. GPT-4 identifies relevant KCs well, though there's a low match with expert-generated KCs at the course level. At the problem level, performance is lower, but key KCs are reasonably identified.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1557–1558},
numpages = {2},
keywords = {cs1, knowledge component, large language model},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649405.3659473,
author = {Cipriano, Bruno Pereira},
title = {Towards the Integration of Large Language Models in an Object-Oriented Programming Course},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659473},
doi = {10.1145/3649405.3659473},
abstract = {The advent of Large Language Models (LLMs) has created multiple challenges for the Computer Science Education Community. This research project aims at integrating LLMs into Object-Oriented Programming courses, by generating and evaluating new teaching methodologies and tools suitable for this paradigm's specificities.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {832–833},
numpages = {2},
keywords = {bard, gpt-3.5, gpt-4, large language models, object-oriented programming},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3699538.3699588,
author = {Pereira Cipriano, Bruno and Silva, Miguel and Correia, Rodrigo and Alves, Pedro},
title = {Towards the Integration of Large Language Models and Automatic Assessment Tools: Enhancing Student Support in Programming Assignments},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699588},
doi = {10.1145/3699538.3699588},
abstract = {The rise of Large Language Models (LLMs) has sparked discussion in Computer Science Education (CSE) due to their ability to generate code from text prompts. Students may rely on these tools, neglecting core skills like computational thinking and program design. Thus, it’s crucial to responsibly integrate them into computer science courses.To address this, we integrated an open-source Automatic Assessment Tool with GPT, enabling students to receive LLM assistance on their programming assignments. This tool can be adopted and improved by educators, promoting more responsible integration of LLMs in CSE.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {52},
numpages = {2},
keywords = {large language models, automatic assessment tools, feedback},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3641554.3701917,
author = {Wang, Kevin Shukang and Lawrence, Ramon},
title = {Quantitative Evaluation of Using Large Language Models and Retrieval-Augmented Generation in Computer Science Education},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701917},
doi = {10.1145/3641554.3701917},
abstract = {Generative artificial intelligence (GenAI) is transforming Computer Science education, and every instructor is reflecting on how AI will impact their courses. Instructors must determine how students may use AI for course activities and what AI systems they will support and encourage students to use. This task is challenging with the proliferation of large language models (LLMs) and related AI systems. The contribution of this work is an experimental evaluation of the performance of multiple open-source and commercial LLMs utilizing retrieval-augmented generation in answering questions for computer science courses and a cost-benefit analysis for instructors when determining what systems to use. A key factor is the time an instructor has to maintain their supported AI systems and the most effective activities for improving their performance. The paper offers recommendations for deploying, using, and enhancing AI in educational settings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1183–1189},
numpages = {7},
keywords = {artificial intelligence, human-in-the-loop, large language model, question answering, retrieval-augmented generation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3661167.3661273,
author = {Mezzaro, Simone and Gambi, Alessio and Fraser, Gordon},
title = {An Empirical Study on How Large Language Models Impact Software Testing Learning},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661273},
doi = {10.1145/3661167.3661273},
abstract = {Software testing is a challenging topic in software engineering education and requires creative approaches to engage learners. For example, the Code Defenders game has students compete over a Java class under test by writing effective tests and mutants. While such gamified approaches deal with problems of motivation and engagement, students may nevertheless require help to put testing concepts into practice. The recent widespread diffusion of Generative AI and Large Language Models raises the question of whether and how these disruptive technologies could address this problem, for example, by providing explanations of unclear topics and guidance for writing tests. However, such technologies might also be misused or produce inaccurate answers, which would negatively impact learning. To shed more light on this situation, we conducted the first empirical study investigating how students learn and practice new software testing concepts in the context of the Code Defenders testing game, supported by a smart assistant based on a widely known, commercial Large Language Model. Our study shows that students had unrealistic expectations about the smart assistant, “blindly” trusting any output it generated, and often trying to use it to obtain solutions for testing exercises directly. Consequently, students who resorted to the smart assistant more often were less effective and efficient than those who did not. For instance, they wrote 8.6% fewer tests, and their tests were not useful in 78.0% of the cases. We conclude that giving unrestricted and unguided access to Large Language Models might generally impair learning. Thus, we believe our study helps to raise awareness about the implications of using Generative AI and Large Language Models in Computer Science Education and provides guidance towards developing better and smarter learning tools.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {555–564},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, Generative AI, Smart Learning Assistant},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3641554.3701873,
author = {Thorgeirsson, Sverrir and Ewen, Tracy and Su, Zhendong},
title = {What Can Computer Science Educators Learn From the Failures of Top-Down Pedagogy?},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701873},
doi = {10.1145/3641554.3701873},
abstract = {While educational researchers in various disciplines are grappling with how to develop policies and pedagogical approaches that address the use of generative artificial intelligence, the challenge is particularly complex in computer science education where the new technology is changing the core of the field. In this paper, we take a look at the pedagogy of other subjects with a longer history than computer science and a more extensive body of educational research to collect insights on how this challenge can be met. We begin by drawing from recent neurological research to find domains that share cognitive commonalities with computer programming and then build upon comparisons that others have made to literacy and mathematics education. We then consider how the "reading wars" and "math wars" have shaped these fields, which we see as conflicts between less effective top-down pedagogy and more effective bottom-up pedagogy, and reflect on what would be comparable approaches in teaching computing. We find that approaches that make heavy use of large language models without teaching fundamentals can be compared to the top-down pedagogy of reading and mathematics and are likely to be ineffective on their own. Therefore, we advise against the exclusive use of such approaches with novices. However, we also acknowledge that the social science surrounding computer science education is complex and that effectiveness only tells a part of the story, with other factors such as engagement, motivation and social dynamics also being important.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1127–1133},
numpages = {7},
keywords = {bottom-up pedagogy, computer science education, generative artificial intelligence, large language models, literacy, math wars, phonics, position paper, reading, reading wars, top-down pedagogy, whole language},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3715602.3715619,
author = {Hong, Alexander and Hong, Gongbing},
title = {The Effectiveness of Coding LLMs and the Challenges in Teaching CS1/2: A Case Study},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {This paper presents a case study that evaluates the effectiveness of coding Large Language Models (LLMs) in introductory computer science courses at the university level. The study assesses six different AI-powered code generators. The evaluation focuses on the accuracy of these AI code generators in solving ten programming problems from a set of problems that instructors at Duke University can assign to students for weekly completion. The results demonstrate the effectiveness of coding LLMs in solving these problems.Based on the findings, the paper discusses the challenges faced by the computer science education community and potential strategies to address them. The advent of coding LLMs poses significant challenges to traditional teaching and learning methods in computer science. These challenges include the need for strategies to mitigate any negative impact of LLMs on the learning process. At the same time, these code LLMs also offer tremendous opportunities for enhancing teaching and learning.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {122–131},
numpages = {10}
}

@inproceedings{10.1145/3649409.3691090,
author = {Folajimi, Yetunde},
title = {From GPT to BERT: Benchmarking Large Language Models for Automated Quiz Generation},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691090},
doi = {10.1145/3649409.3691090},
abstract = {This study evaluates the effectiveness of four leading large language models (LLMs), GPT-3, GPT-4, GPT-4o, and BERT, in generating quiz questions for Java and Python programming courses. We aim to recognize how LLMs can effectively produce educationally valuable questions that meet specific pedagogical criteria, including technical precision, relevance to course objectives, linguistic clarity, and pedagogical appropriateness. Each model was prompted to generate 200 Java and 200 Python quiz questions, totaling 1600 unique questions. These questions are currently being evaluated based on both quantitative and qualitative assessments by a team of computer science educators. Preliminary findings suggest that GPT-4 outperforms BERT in terms of technical precision. Further analysis is ongoing to assess the performance of the models in generating contextually appropriate and educationally useful questions, offering insights into their potential integration into computer science curricula. This work seeks to contribute to the broader discourse on the utility of LLMs in educational settings, specifically within the scope of automated content creation to enhance teaching and assessment methodologies in computer science education.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {312–313},
numpages = {2},
keywords = {automated assessment, computer science education, formative assessment, large language models, personalized quizzes, quiz questions generation},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3706599.3720291,
author = {Jamie, Pooriya and HajiHashemi, Reyhaneh and Alipour, Sharareh},
title = {Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720291},
doi = {10.1145/3706599.3720291},
abstract = {Integrating large language models (LLMs) like ChatGPT into computer science education offers transformative potential for complex courses such as data structures and algorithms (DSA). This study examines ChatGPT as a supplementary tool for teaching assistants (TAs), guided by structured prompts and human oversight, to enhance instruction and student outcomes. A controlled experiment compared traditional TA-led instruction with a hybrid approach where TAs used ChatGPT-4o and ChatGPT o1 to generate exercises, clarify concepts, and provide feedback. Structured prompts emphasized problem decomposition, real-world context, and code examples, enabling tailored support while mitigating over-reliance on AI. Results demonstrated the hybrid approach’s efficacy, with students in the ChatGPT-assisted group scoring 16.50 points higher on average and excelling in advanced topics. However, ChatGPT’s limitations necessitated TA verification. This framework highlights the dual role of LLMs: augmenting TA efficiency while ensuring accuracy through human oversight, offering a scalable solution for human-AI collaboration in education.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {567},
numpages = {7},
keywords = {LLMs, ChatGPT, Teaching Assistant, Data Structures and Algorithms Course, Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3701716.3715199,
author = {Zhang, Yifan and Zhao, Xinkui and Wang, Zuxin and Zhou, Zhengyi and Cheng, Guanjie and Deng, Shuiguang and Yin, Jianwei},
title = {SortingHat: Redefining Operating Systems Education with a Tailored Digital Teaching Assistant},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715199},
doi = {10.1145/3701716.3715199},
abstract = {Operating Systems (OS) courses are among the most challenging in computer science education due to the complexity of internal structures and the diversity of running environments. Traditional teaching methods often fail to address the diverse backgrounds, learning speeds, and practical needs of students. To tackle these challenges, we present SortingHat, a personalized digital teaching assistant tailored specifically for OS education. SortingHat integrates advanced AI technologies, including a retrieval-augmented generation (RAG) framework and multi-agent reinforcement learning (MARL), to deliver adaptive, scalable, and effective educational support. SortingHat features a 3D digital human interface powered by large language models (LLMs) to provide personalized, empathetic, and context-aware guidance. It generates tailored exercises based on each student's learning history and academic performance, reinforcing weak areas and challenging advanced concepts. Additionally, the system incorporates a robust evaluation pipeline that ensures fair, consistent, and unbiased grading of student submissions while delivering personalized, actionable feedback for improvement. By combining personalized guidance, adaptive content creation, and automated assessment, SortingHat transforms OS education into an engaging, immersive, and scalable experience.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2951–2954},
numpages = {4},
keywords = {digital human, education, large language models, multi agent reinforcement learning, retrieval augmented generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3649409.3691094,
author = {Feng, Ty and Liu, Sa and Ghosal, Dipak},
title = {CourseAssist: Pedagogically Appropriate AI Tutor for Computer Science Education},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691094},
doi = {10.1145/3649409.3691094},
abstract = {The growing enrollments in computer science courses and increase in class sizes necessitate scalable, automated tutoring solutions to adequately support student learning. While Large Language Models (LLMs) like GPT-4 have demonstrated potential in assisting students through question-answering, educators express concerns over student overreliance, miscomprehension of generated code, and the risk of inaccurate answers. Rather than banning these tools outright, we advocate for a constructive approach that harnesses the capabilities of AI while mitigating potential risks. This poster introduces CourseAssist, a novel LLM-based tutoring system tailored for computer science education. Unlike generic LLM systems, CourseAssist uses retrieval-augmented generation, user intent classification, and question decomposition to align AI responses with specific course materials and learning objectives, thereby ensuring pedagogical appropriateness of LLMs in educational settings. We evaluated CourseAssist against a baseline of GPT-4 using a dataset of 50 question-answer pairs from a programming languages course, focusing on the criteria of usefulness, accuracy, and pedagogical appropriateness. Evaluation results show that CourseAssist significantly outperforms the baseline, demonstrating its potential to serve as an effective learning assistant. We have also deployed CourseAssist in 6 computer science courses at a large public R1 research university reaching over 500 students. Interviews with 20 student users show that CourseAssist improves computer science instruction by increasing the accessibility of course-specific tutoring help and shortening the feedback loop on their programming assignments. Future work will include extensive pilot testing at more universities and exploring better collaborative relationships between students, educators, and AI that improve computer science learning experiences.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {310–311},
numpages = {2},
keywords = {AI tutor, computer science education, intelligent tutoring systems, large language models, pedagogical appropriateness, question answering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@article{10.5555/3722479.3722506,
author = {Liao, Weidong and Guzide, Osman},
title = {Enhancing Undergraduate Computing Education with LMMs and ChatGPT-4o},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {Large Language Models (LLMs) and ChatGPT have significantly impacted programming practices and computer science education. The rapid advancements in natural language processing, recurrent neural networks, and Transformer architectures have captured the attention of students and educators alike. These tools aid students in brainstorming, coding, analyzing code, and writing reports. Although concerns about cheating and plagiarism persist, these tools also provide educators with novel ways to create and assess assignments. Despite some hesitancy among educators to integrate these AI tools into the classroom, the advert and development of Large MultiModal Models (LMMs), the enhancement of LLMs that can deal with multimedia inputs and outputs, illustrates a significant evolution in generative AI capabilities.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {62},
numpages = {1}
}

@inproceedings{10.1145/3626253.3633409,
author = {Hazzan, Orit and Erez, Yael},
title = {Generative AI in Computer Science Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633409},
doi = {10.1145/3626253.3633409},
abstract = {Generative AI has the potential to become disruptive technology for computer science education. Therefore, computer science educators must be familiar with the threats they should deal with and with the opportunities that generative-AI opens for the computer science education community. In the workshop, we explore the integration of several generative-AI tools and applications in computer science education. Activities include lesson design, code development, test design and assessment. We address the students' and the educators' perspectives. In addition, we explore computer science practices and soft skills to be applied with these tools as well as immediate and future applications and implications for computer science education and for the society. AT the end of the workshop, the participants will be able to use these generative AI tools in their daily educational computer science activities and beyond.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1899},
numpages = {1},
keywords = {ai, assessment, computer science education, curriculum design, disruptive technology, generative ai, skills},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641555.3705064,
author = {Erez, Yael and Ayali, Lilach and Hazzan, Orit},
title = {Evolution of Students' Attitudes Towards the Use of Generative AI Tools in a CS1 Course: Implications for Instructors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705064},
doi = {10.1145/3641555.3705064},
abstract = {Recent advancements in large language model-based generative artificial intelligence (GenAI) tools have transformed computer science education, presenting both opportunities and challenges. A study investigating students' attitudes toward these tools was conducted during an Introduction to Computer Science course. The target of the study was to gauge students' evolving attitudes toward using GenAI tools in the course, before, during and after ChatGPT was gradually assimilated into homework assignments. The study refers to three phases: preliminary phase, assimilation phase, and calibration stage, which currently takes place. Findings show that, in the preliminary phase, students appreciated the efficiency of GenAI tools offered but were concerned about developing a dependency on these tools and about ''cheating''. Findings from the assimilation phase indicate that consistent, guided exposure to GenAI tools positively shifted students' views, alleviating initial concerns and promoting a positive attitude toward using GenAI tools in the course. The targets of the calibration phase are: a) to examine how to leverage independent learning by formulating clear guidelines that can build trust in the technology and help overcome concerns regarding reliability and credibility; b) to check how GenAI can help students in a Introduction to Computer Science course acquire skills such as critical thinking and code comprehension. The study offers insights for educators on the integration of GenAI tools into computer science courses to enhance learning while maintaining academic integrity.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1740},
numpages = {1},
keywords = {critical thinking, cs1, generative ai, introduction to computer science, mixed methods, program comprehension, skills, students' attitudes},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.5555/3712729.3712987,
author = {Shin, Jinnie and Cruz-Castro, Laura and Yang, Zhenlin and Castelblanco, Gabriel and Aggarwal, Ashish and Leite, Walter L. and Carroll, Bruce F.},
title = {Understanding Optimal Interactions between Students and a Chatbot during a Programming Task},
year = {2025},
isbn = {9798331534202},
publisher = {IEEE Press},
abstract = {This study explores integrating Large Language Models (LLMs) into computer science education by examining undergraduate interactions with a GPT-4-based chatbot during a formative assignment in an introductory course. We aim to delineate optimal help-seeking behaviors and ascertain if effective problem-navigating strategies correlate with improved learning outcomes. Using descriptive statistics and Structural Topic Modeling (STM), we analyze the types of questions posed and their connection to task completion success. Findings reveal a positive association between the number of attempts and help requests, indicating more engaged students seek assistance. STM analysis shows high-ability students address abstract concepts early, while lower-ability students focus on syntax-related issues. These insights underscore the need to evaluate interaction behaviors to optimize chatbot use in education, leading to proposed guidelines to enhance chatbot utilization, promoting responsible use and maximizing educational advantages.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {3106–3117},
numpages = {12},
location = {Orlando, Florida, USA},
series = {WSC '24}
}

@article{10.5555/3715602.3715612,
author = {Crandall, Johannah L. and Crandall, Aaron S.},
title = {Large Language Model-Supported Software Testing with the CS Matrix Taxonomy},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {New breakthroughs in code synthesis from Generative Pre-Trained Transformers (GPT) and Large Language Model (LLM) algorithms are driving significant changes to software engineering education. Having algorithms able to generate components of a software project means that software developers will need stronger skills in requirements specification to guide code generation as well as stronger skills in code review, testing, and integration to incorporate AI-generated code into projects. Shifts in industry and classroom practices are already occurring with the availability of inline code generation tools like GitHub's Copilot, which makes discussion of pedagogical strategies in this area a timely topic. Of immediate concern in computer science education is the potential for LLM-generated code and code help to undermine the learning of CS students. In order to avoid such undermining in even intentional uses of LLM-enhanced learning supports, it is necessary to clarify the roles such supports need to play in the pedagogical process. The Computer Science Matrix Taxonomy provides a strong framework for organizing software testing learning outcomes as well as delineating the operational space in which LLM-based feedback tools should operate to support those learning outcomes. In this paper, the authors operationalize the CS Matrix Taxonomy for software testing learning outcomes and illustrate the integration of LLM-generated test strategy suggestions as an extension of the peer coding/testing model. The work includes examples of AI-generated code testing suggestions that students would use to help guide their own code synthesis for assignments or projects.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {49–58},
numpages = {10}
}

@inproceedings{10.1145/3641555.3705282,
author = {\v{R}echt\'{a}\v{c}kov\'{a}, Anna and Maximova, Alexandra and Pitts, Griffin},
title = {Finding Misleading Identifiers in Novice Code Using LLMs},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705282},
doi = {10.1145/3641555.3705282},
abstract = {Clear, well-chosen names for variables and functions significantly enhance code readability and maintainability. In computer science education, teaching students to select appropriate identifiers is a critical task, especially in CS1. This study explores how large language models (LLMs) could assist in teaching this skill. While prior research has explored the use of LLMs in programming education, their precision and consistency in teaching code quality, particularly identifier selection, remains largely unexplored. For this purpose, this study investigated how well different LLMs can detect and report misleading identifiers. In a dataset of 33 code samples, we manually labeled misleading identifiers. On this dataset, we then tested five different LLMs on their ability to detect these misleading identifiers, measuring the overall accuracy, precision, recall, and f-score. Results revealed that the most successful model, GPT-4o, was able to correctly detect most of the manually flagged misleading variable names. However, it also tended to flag issues with variable identifiers in cases where the human evaluators would not, and refined prompting was not able to discourage this behavior.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1595–1596},
numpages = {2},
keywords = {automated feedback, code quality, misleading identifiers, novice programmers},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706599.3720282,
author = {Mhasakar, Manas and Baker-Ramos, Rachel and Carter, Benjamin and Helekahi-Kaiwi, Evyn-Bree and Hester, Josiah},
title = {"I Would Never Trust Anything Western": Kumu (Educator) Perspectives on Use of LLMs for Culturally Revitalizing CS Education in Hawaiian Schools},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720282},
doi = {10.1145/3706599.3720282},
abstract = {As large language models (LLMs) become increasingly integrated into educational technology, their potential to assist in developing curricula has gained interest among educators. Despite this growing attention, their applicability in culturally responsive Indigenous educational settings like Hawai‘i’s public schools and Kaiapuni (immersion language) programs, remains understudied. Additionally, ‘undefinedlelo Hawai‘i, the Hawaiian language, as a low-resource language, poses unique challenges and concerns about cultural sensitivity and the reliability of generated content. Through surveys and interviews with kumu (educators), this study explores the perceived benefits and limitations of using LLMs for culturally revitalizing computer science (CS) education in Hawaiian public schools with Kaiapuni programs. Our findings highlight AI’s time-saving advantages while exposing challenges such as cultural misalignment and reliability concerns. We conclude with design recommendations for future AI tools to better align with Hawaiian cultural values and pedagogical practices, towards the broader goal of trustworthy, effective, and culturally grounded AI technologies.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {13},
numpages = {10},
keywords = {Culturally responsive pedagogy, Artificial Intelligence in education, Culturally-relevant CS, Hawaiian Immersion Language Schools, Large Language Models, Human-centered AI, Education technology, Indigenous knowledge, Low-resource languages},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3636555.3636882,
author = {Dunder, Nora and Lundborg, Saga and Wong, Jacqueline and Viberg, Olga},
title = {Kattis vs ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636882},
doi = {10.1145/3636555.3636882},
abstract = {AI-powered education technologies can support students and teachers in computer science education. However, with the recent developments in generative AI, and especially the increasingly emerging popularity of ChatGPT, the effectiveness of using large language models for solving programming tasks has been underexplored. The present study examines ChatGPT’s ability to generate code solutions at different difficulty levels for introductory programming courses. We conducted an experiment where ChatGPT was tested on 127 randomly selected programming problems provided by Kattis, an automatic software grading tool for computer science programs, often used in higher education. The results showed that ChatGPT independently could solve 19 out of 127 programming tasks generated and assessed by Kattis. Further, ChatGPT was found to be able to generate accurate code solutions for simple problems but encountered difficulties with more complex programming tasks. The results contribute to the ongoing debate on the utility of AI-powered tools in programming education.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {821–827},
numpages = {7},
keywords = {Academic Integrity, Automated Grading, ChatGPT, Programming Education},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3641555.3705125,
author = {Zhang, Shan and Meshram, Pragati Shuddhodhan and Ganapathy Prasad, Priyadharshini and Israel, Maya and Bhat, Suma},
title = {An LLM-Based Framework for Simulating, Classifying, and Correcting Students' Programming Knowledge with the SOLO Taxonomy},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705125},
doi = {10.1145/3641555.3705125},
abstract = {Novice programmers often face challenges in designing computational artifacts and fixing code errors, which can lead to task abandonment and over-reliance on external support. While research has explored effective meta-cognitive strategies to scaffold novice programmers' learning, it is essential to first understand and assess students' conceptual, procedural, and strategic/conditional programming knowledge at scale. To address this issue, we propose a three-model framework that leverages Large Language Models (LLMs) to simulate, classify, and correct student responses to programming questions based on the SOLO Taxonomy. The SOLO Taxonomy provides a structured approach for categorizing student understanding into four levels: Pre-structural, Uni-structural, Multi-structural, and Relational. Our results showed that GPT-4o achieved high accuracy in generating and classifying responses for the Relational category, with moderate accuracy in the Uni-structural and Pre-structural categories, but struggled with the Multi-structural category. The model successfully corrected responses to the Relational level. Although further refinement is needed, these findings suggest that LLMs hold significant potential for supporting computer science education by assessing programming knowledge and guiding students toward deeper cognitive engagement.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1681–1682},
numpages = {2},
keywords = {computer science education, large language model, solo taxonomy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3704749,
author = {Hare, Brian K. and Gladbach, Joan and Shah, S. Jawad and Xu, Dianxiang},
title = {Building AI-Powered Responsible Workforce by Integrating Large Language Models into Computer Science Curriculum},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704749},
doi = {10.1145/3641555.3704749},
abstract = {Software development is undergoing a revolutionary transformation, fueled by remarkable advancements in Large Language Models (LLMs). This wave of innovation is reshaping the entire landscape and holds the promise of streamlining the development process, leading to increased productivity and efficiency. By providing text prompts, developers can now receive entirely generated code outputs, representing a fundamental shift in how software is built. This paradigm change can accelerate development cycles and unlock new levels of creativity and ingenuity, resulting in the realization of novel applications and business outcomes. However, this paradigm shift also brings new challenges and necessitates acquiring additional skills for software developers to fully harness the capabilities of LLM-powered tools. These skills include prompt engineering for software development, structural complexity management, debugging of AI errors, and compliance with ethical guidelines and principles.The special session will introduce our NSF-sponsored 3-year project, which aims to integrate LLMs into the standard CS curriculum. To the best of our knowledge, this project is among the first department-level initiatives to renovate CS curriculum, rather than individual courses, with the new developments of LLMs. Our project focuses on (a) enhancing students' problem-solving and programming skills by leveraging LLMs as a learning tool in core programming courses, (b) improving students' software development skills by integrating LLM-powered tools into the software engineering course sequence, and (c) educating students on ethical and responsible AI practices. The special session will discuss the objectives and methods of our project, as well as the current results and lessons learned.This NSF-supported project aims to integrate LLMs into the standard CS curriculum. The revolutionized computer science education will cultivate a new generation of AI-powered responsible developers. The objectives are to enhance student programming, software development, and problem-solving skills; educate students on ethical and responsible AI practices; and develop faculty development materials and workshops. Our presentation will discuss the objectives and methods of our project, currently in year 1 of a 3-year timeline.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1709–1710},
numpages = {2},
keywords = {AI, curriculum development, large language models, undergraduate education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701867,
author = {Yeh, Thomas Y. and Tran, Karena and Gao, Ge and Yu, Tyler and Fong, Wai On and Chen, Tzu-Yi},
title = {Bridging Novice Programmers and LLMs with Interactivity},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701867},
doi = {10.1145/3641554.3701867},
abstract = {While Large Language Models (LLMs) enable experienced programmers to increase their productivity, LLMs' impact on learning and productivity for novices is currently unclear. Recent work showed novice programmers struggle with prompting LLMs for code generation and suggested that the use of LLMs in CS education could exacerbate existing equity issues. Educators are now faced with the difficult question of whether and when to incorporate the use of LLMs into the CS curriculum without adversely impacting student learning and equity. To address these concerns, we study the effects of using an interactive LLM on code generation with novice programmers. We find that using our interactive LLM improves the accuracy of code generation over the baseline LLM. Additionally, after using the interactive LLM, novices write improved prompts even when using the baseline LLM. Based on our findings, we plan to create iGPTs, a set of customized, interactive LLMs spanning CS education learning goals as templates to facilitate LLM integration for improving student learning and retention.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1295–1301},
numpages = {7},
keywords = {cs1, generative ai, llms, novice programmers},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705201,
author = {Bejarano, Andres and Dickey, Ethan and Setsma, Rhianna},
title = {Implementing the AI-Lab Framework: Enhancing Introductory Programming Education for CS Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705201},
doi = {10.1145/3641555.3705201},
abstract = {The advent of generative AI tools presents novel opportunities and challenges in computer science education, particularly in introductory programming courses. This study explores the implementation of AI-Lab, a framework designed to guide students in the effective and ethical use of generative AI, in this case ChatGPT, in academic settings without compromising skill development. Conducted during Spring 2024, our use of the intervention targeted over 500 Computer Science and Data Science majors enrolled in their major-specific Data Structures and Algorithms courses. The AI-Lab framework enabled students to develop both conceptual questions and c++ and Python programs by interacting with ChatGPT and iteratively correcting its errors. Focus groups and post-intervention surveys revealed a generally positive experience. Students appreciated the ability to leverage AI for tasks outside their major, recognizing the value of understanding correct solutions through AI-assisted programming. Moreover, the guided use of generative AI by professors alleviated concerns regarding academic dishonesty, fostering a supportive learning environment. Despite these benefits, students expressed awareness of the potential drawbacks of over-reliance on AI, noting the risk of impeding their professional growth. Nevertheless, they acknowledged the practical utility of AI for non-major related tasks. This study highlights the importance of incorporating structured AI training in curricula to balance skill development and ethical AI usage, offering insights for broader applications in higher education.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1383–1384},
numpages = {2},
keywords = {ai lab, ai-assisted programming, ai-lab framework, ethical ai usage, generative ai in education, skill development with ai, structured ai training},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705252,
author = {Tadimalla, Sri Yash and Maher, Mary Lou},
title = {Sociotechnical AI Education Course Design for CS Majors and Non-Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705252},
doi = {10.1145/3641555.3705252},
abstract = {As generative AI increasingly integrates into society and education, the number of institutions implementing AI usage policies and offering introductory AI courses is rising. These introductory AI courses mustn't replicate the "gateway/weed-out" phenomenon observed in introductory computer science courses like CS1 and CS2. Literature in computer science education suggests that interventions such as summer camps, bridge courses, and socio-technical courses have improved the sense of belonging and retention among students from underrepresented groups, thereby broadening participation in computer science. Building on previous work to create a socio-technical curriculum for all ages and education levels, this paper presents a course for teaching introductory AI concepts that adopts a socio-technical approach, complete with weekly activities and content designed for broad access. The course has been taught as a 1-credit general education course, primarily for freshmen and first-year students from various majors, and a 3-credit course for CS majors at all levels.This paper provides a curriculum and resources to teach a socio-technical introductory AI course. This approach is important because it not only democratizes AI education across diverse student backgrounds but also equips all students with the critical socio-technical multidisciplinary perspective necessary to navigate and shape the future ethical landscape of AI technology.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1631–1632},
numpages = {2},
keywords = {AI curriculum, AI education, intro to AI, socio-technical AI literacy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626252.3630789,
author = {Liu, Mengqi and M'Hiri, Faten},
title = {Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630789},
doi = {10.1145/3626252.3630789},
abstract = {As the prominence of Large Language Models (LLMs) grows in various sectors, their potential in education warrants exploration. In this study, we investigate the feasibility of employing GPT-3.5 from OpenAI, as an LLM teaching assistant (TA) or a virtual TA in computer science (CS) courses. The objective is to enhance the accessibility of CS education while maintaining academic integrity by refraining from providing direct solutions to current-semester assignments. Targeting Foundations of Programming (COMP202), an undergraduate course that introduces students to programming with Python, we have developed a virtual TA using the LangChain framework, known for integrating language models with diverse data sources and environments. The virtual TA assists students with their code and clarifies complex concepts. For homework questions, it is designed to guide students with hints rather than giving out direct solutions. We assessed its performance first through a qualitative evaluation, then a survey-based comparative analysis, using a mix of questions commonly asked on the COMP202 discussion board and questions created by the authors. Our preliminary results indicate that the virtual TA outperforms human TAs on clarity and engagement, matching them on accuracy when the question is non-assignment-specific, for which human TAs still proved more reliable. These findings suggest that while virtual TAs, leveraging the capabilities of LLMs, hold great promise towards making CS education experience more accessible and engaging, their optimal use necessitates human supervision. We conclude by identifying several directions that could be explored in future implementations.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {743–749},
numpages = {7},
keywords = {adaptive teaching, chatgpt, cs education, gpt, llm, machine learning, novice programmers, openai, programming},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3706468.3706500,
author = {Duan, Zhangqi and Fernandez, Nigel and Hicks, Alexander and Lan, Andrew},
title = {Test Case-Informed Knowledge Tracing for Open-ended Coding Tasks},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706500},
doi = {10.1145/3706468.3706500},
abstract = {Open-ended coding tasks, which ask students to construct programs according to certain specifications, are common in computer science education. Student modeling can be challenging since their open-ended nature means that student code can be diverse. Traditional knowledge tracing (KT) models that only analyze response correctness may not fully capture nuances in student knowledge from student code. In this paper, we introduce Test case-Informed Knowledge Tracing for Open-ended Coding (TIKTOC), a framework to simultaneously analyze and predict both open-ended student code and whether the code passes each test case. We augment the existing CodeWorkout dataset with the test cases used for a subset of the open-ended coding questions, and propose a multi-task learning KT method to simultaneously analyze and predict 1) whether a student’s code submission passes each test case and 2) the student’s open-ended code, using a large language model as the backbone. We quantitatively show that these methods outperform existing KT methods for coding that only use the overall score a code submission receives. We also qualitatively demonstrate how test case information, combined with open-ended code, helps us gain fine-grained insights into student knowledge.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {238–248},
numpages = {11},
keywords = {Computer Science Education, Large Language Models, Open-ended Coding Questions, Test Cases},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3639474.3640084,
author = {Sa\u{g}lam, Timur and Hahner, Sebastian and Schmid, Larissa and Burger, Erik},
title = {Automated Detection of AI-Obfuscated Plagiarism in Modeling Assignments},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640084},
doi = {10.1145/3639474.3640084},
abstract = {Plagiarism is a widespread problem in computer science education, exacerbated by the impracticability of manual inspection in large courses. Even worse, tools based on large language models like ChatGPT have made it easier than ever to obfuscate plagiarized solutions. Additionally, most plagiarism detectors only apply to code, and only a few approaches exist for modeling assignments, which lack broad resilience to obfuscation attacks. This paper presents a novel approach for automated plagiarism detection in modeling assignments that combines automated analysis with human inspection. We evaluate our approach with real-world assignments and plagiarism obfuscated by ChatGPT. Our results show that we achieve a significantly higher detection rate for AI-generated attacks and a broader resilience than the state-of-the-art.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {297–308},
numpages = {12},
keywords = {plagiarism detection, obfuscation, ChatGPT, artificial intelligence},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3626253.3635543,
author = {Glynn, Colin and Hed, Emily and Pexa, Abbigail and Pohlmann, Tyler and Rahal, Imad and Hesse, Robert},
title = {CAET: Code Analysis and Education Tutor},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635543},
doi = {10.1145/3626253.3635543},
abstract = {The introduction of OpenAI's ChatGPT in 2022 kickstarted the release of Generative Artificial Intelligence (GAI) applications to the public domain. Such chat interfaces are based on large language models (LLMs) and possess a vast array of abilities spanning conversation, the writing and debugging of code, the writing of papers, and the creation of images, music, and songs. With students now having access to a myriad of GAI tools, academia has been permanently altered.Our proposed system, named Code Analysis and Education Tutor (CAET), integrates GAI into early Computer Science education by providing students with an ethical alternative to existing GAI tools. CAET is designed to assist students with programming tasks in a manner tailored to their individual needs without jeopardizing the integrity of their learning. A point of uniqueness from existing works is CAET's ability to display or hide generated code based on its pertinence to the problem at hand. After subjecting multiple GAI models to common programming errors and queries, we settled on OpenAI's GPT-3.5 Turbo model due to its comprehensive capabilities and cost-effectiveness. Overall, CAET underscored the model's conversational dynamics and provided insights for creating a more personalized learning experience for students in an introductory computer science course.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1656–1657},
numpages = {2},
keywords = {computer science education, generative artificial intelligence, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641555.3705080,
author = {Morales, Jamie and Raman, Preeti},
title = {Prompt-Engineering Strategies for Minimizing Bias in Large Language Model Outputs: Applications in Computing Education},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705080},
doi = {10.1145/3641555.3705080},
abstract = {As large language models (LLMs) increasingly permeate educational applications, concerns about the perpetuation of bias persist. We present our preliminary work on developing prompt-engineering strategies to mitigate bias in content generated by LLMs in computer science (CS) education. This work investigates both empirical insights into fairness-aware prompt formulation and actionable takeaways for educators. We focus on an initial list of prompting strategies for mitigating bias and explore their impact on educational content generation. Recent research has shown the efficacy of prompt-base debiasing [1] as well as the potential disadvantages of using prompts that have not been mitigated for bias, from user dissatisfaction [2] to unsafe outputs [5, 6]. Additionally, a growing body of empirical work points to the idea that certain properties of in-context examples such as flow [7], illustration [3], and order [4] could either improve or derail LLM performance. Our study leverages these findings in the context of generating educational content. The goal is to promote fairness-aware approaches which can be applied to the automated generation of learning materials and the development of LLM-based educational tools. This work also contributes practical insights on prompt-engineering to the evolving curriculum of Ethics in Artificial Intelligence (AI).},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1743},
numpages = {1},
keywords = {bias, education, ethics, generative ai, in-context examples, language model, language technology, llm, nlp, prompt-engineering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626252.3630803,
author = {Joshi, Ishika and Budhiraja, Ritvik and Dev, Harshal and Kadia, Jahnvi and Ataullah, Mohammad Osama and Mitra, Sayan and Akolekar, Harshal D. and Kumar, Dhruv},
title = {ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses for Solving Undergraduate Computer Science Questions},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630803},
doi = {10.1145/3626252.3630803},
abstract = {This research paper aims to analyze the strengths and weaknesses associated with the utilization of ChatGPT as an educational tool in the context of undergraduate computer science education. ChatGPT's usage in tasks such as solving assignments and exams has the potential to undermine students' learning outcomes and compromise academic integrity. This study adopts a quantitative approach to demonstrate the notable unreliability of ChatGPT in providing accurate answers to a wide range of questions within the field of undergraduate computer science. While the majority of existing research has concentrated on assessing the performance of Large Language Models in handling programming assignments, our study adopts a more comprehensive approach. Specifically, we evaluate various types of questions such as true/false, multi-choice, multi-select, short answer, long answer, design-based, and coding-related questions. Our evaluation highlights the potential consequences of students excessively relying on ChatGPT for the completion of assignments and exams, including self-sabotage. We conclude with a discussion on how can students and instructors constructively use ChatGPT and related tools to enhance the quality of instruction and the overall student experience.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {625–631},
numpages = {7},
keywords = {chatgpt, computer science, education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3545947.3569630,
author = {MacNeil, Stephen and Tran, Andrew and Leinonen, Juho and Denny, Paul and Kim, Joanne and Hellas, Arto and Bernstein, Seth and Sarsa, Sami},
title = {Automatically Generating CS Learning Materials with Large Language Models},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3569630},
doi = {10.1145/3545947.3569630},
abstract = {Recent breakthroughs in Large Language Models (LLMs), such as GPT-3 and Codex, now enable software developers to generate code based on a natural language prompt. Within computer science education, researchers are exploring the potential for LLMs to generate code explanations and programming assignments using carefully crafted prompts. These advances may enable students to interact with code in new ways while helping instructors scale their learning materials. However, LLMs also introduce new implications for academic integrity, curriculum design, and software engineering careers. This workshop will demonstrate the capabilities of LLMs to help attendees evaluate whether and how LLMs might be integrated into their pedagogy and research. We will also engage attendees in brainstorming to consider how LLMs will impact our field.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1176},
numpages = {1},
keywords = {code generation, computer science education, copilot, explanations, large language models},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3641554.3701863,
author = {Raihan, Nishat and Siddiq, Mohammed Latif and Santos, Joanna C.S. and Zampieri, Marcos},
title = {Large Language Models in Computer Science Education: A Systematic Literature Review},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701863},
doi = {10.1145/3641554.3701863},
abstract = {Large language models (LLMs) are becoming increasingly better at a wide range of Natural Language Processing tasks (NLP), such as text generation and understanding. Recently, these models have extended their capabilities to coding tasks, bridging the gap between natural languages (NL) and programming languages (PL). Foundational models such as the Generative Pre-trained Transformer (GPT) and LLaMA series have set strong baseline performances in various NL and PL tasks. Additionally, several models have been fine-tuned specifically for code generation, showing significant improvements in code-related applications. Both foundational and fine-tuned models are increasingly used in education, helping students write, debug, and understand code. We present a comprehensive systematic literature review to examine the impact of LLMs in computer science and computer engineering education. We analyze their effectiveness in enhancing the learning experience, supporting personalized education, and aiding educators in curriculum development. We address five research questions to uncover insights into how LLMs contribute to educational outcomes, identify challenges, and suggest directions for future research.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {938–944},
numpages = {7},
keywords = {code generation, cs education, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3660650.3660668,
author = {Rajabi, Parsa},
title = {Experience Report: Adopting AI-Usage Policy in Software Engineering Education},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660668},
doi = {10.1145/3660650.3660668},
abstract = {This report examines the introduction of an AI-usage policy within a Software Engineering course, aiming to overcome the challenges of incorporating generative AI (genAI) tools in academic settings. As the debate around the impact of technologies like ChatGPT in education continues, this policy represents a proactive stance, addressing both the opportunities and risks associated with AI tool usage. With N=86 students, this course implemented a policy that promotes responsible AI use through guidelines and an "AI-usage disclosure" form for coursework submissions. This approach sought to improve AI literacy, ensure academic integrity, and mitigate potential academic misconduct cases. Despite challenges, including adherence to AI disclosures and the evolving definition of AI tools, the policy promoted a more inclusive learning environment and encouraged a deeper understanding of AI’s role and limitations in computer science education. The findings highlight the need for ongoing policy revisions to adapt to technological advancements, emphasizing the pilot as an essential step towards integrating AI responsibly in educational contexts.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {19},
numpages = {2},
keywords = {AI in Education, AI-usage Policy, Academic Integrity, ChatGPT, Software Engineering Education},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3663649.3664368,
author = {Aerts, Willem and Fletcher, George and Miedema, Daphne},
title = {A Feasibility Study on Automated SQL Exercise Generation with ChatGPT-3.5},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664368},
doi = {10.1145/3663649.3664368},
abstract = {SQL is the standard for database query languages and is taught in most introductory database courses. Query languages are illustrated and tested through toy examples: small, accessible, instances of databases. These are not always engaging, but coming up with new examples and questions is time-consuming. Existing research in Computer Science Education has shown that Large Language Models (LLMs) can generate coding exercises. However, this has not been demonstrated for SQL yet but could save teachers much time. In this paper, we study whether it is feasible to have ChatGPT-3.5 generate database schemas and associated SQL questions for teachers through a two-part study. Through a survey of educators, we found that creating a story and database schema for the SQL part is more time-consuming than the questions themselves. In our prompt engineering study, we identified prompts that were successful at creating database schemas, mock data, and exercises. However, although ChatGPT could help reduce the time required to create exams, some participants indicated that they are skeptical about using LLMs.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {13–19},
numpages = {7},
keywords = {Assessment, ChatGPT, Education, LLM, SQL},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{10.1145/3674399.3674423,
author = {Xu, Ke and Yi, Hanxiao and Xu, Zichen and Wu, Dan},
title = {Data-driven Contribution-based Disciplinary Assessment System},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674399.3674423},
doi = {10.1145/3674399.3674423},
abstract = {A scientific disciplinary assessment system is crucial for nurturing high-quality disciplines within Computer Science. Computer Science Education (CSE) emphasizes the need for a scientific and comprehensive assessment method that guides the development of the discipline, with a particular focus on practical contributions. However, traditional assessment systems tend to prioritize the theoretical outcomes. Moreover, data expansion demands significant effort and time from educational professionals, making it challenging to conduct a thorough evaluation of the disciplines. To tackle these issues, we introduce a data-driven, contribution-based disciplinary assessment system. This system takes into account both theoretical and practical contributions to provide a holistic evaluation. Our proposed system employs a contribution-based assessment approach to establish a correct evaluative direction, steering discipline construction to align with societal needs. It also incorporates intelligent algorithms and a Large Language Model (LLM), leveraging their substantial computational power in the evaluation process. This integration alleviates the workload of educational professionals by automating the collection and analysis of information. The paper outlines a detailed implementation plan that integrates contribution evaluation theory with intelligent technologies, aiming to foster the ongoing advancement of CSE education.},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2024},
pages = {42–47},
numpages = {6},
keywords = {Big Data-driven, Contribution-Based Evaluation Method, Disciplinary assessment},
location = {Changsha, China},
series = {ACM-TURC '24}
}

@article{10.5555/3665464.3665476,
author = {Alrifai, Rad},
title = {Using Generative AI to Design Programming Assignments in Introduction to Computer Science},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {Programming stands as an essential requisite in computer science education. Recognizing the challenges students face in learning programming effectively, the proposed assignment aims to integrate generative artificial intelligence (AI) tools to teach students introductory programming constructs. Generative AI has gained an increasing popularity in recent years. Several available Generative AI implementations can now help students learn programming essentials and debugging skills.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {103–106},
numpages = {4}
}

@inproceedings{10.1145/3641554.3701858,
author = {Tran, Minh and Gonzalez-Maldonado, David and Zhou, Elaine and Franklin, Diana},
title = {Can GPT Help? Supporting Teachers to Brainstorm Customized Instructional Scratch Projects},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701858},
doi = {10.1145/3641554.3701858},
abstract = {While many recent studies have explored how large language models can transform computer science instruction from the instructor perspective, they are primarily at the college level. Thus, little is known about using large language models towards curriculum development and teacher supports outside of the college setting. Given the emphasis placed on culturally responsive teaching at the K-8 level and well-documented evidence of insensitive and inaccurate language model outputs from a cultural perspective, it is imperative to perform systematic and principled research before considering their use in this setting.This paper explores the potential of teachers using large language models to brainstorm instructional Scratch projects. Specifically, we use GPT-3 to mimic structured projects from an existing computer science curriculum but situate the generated projects in different contexts/themes. We qualitatively analyze 300 project ideas generated by GPT and find 81% of the generated ideas satisfy our metrics for technical alignment and theme quality. We identify two major weaknesses: code complexity of generated projects and presence of potential insensitive elements that would require human filtering. We conclude that, while not ready as a student-facing solution, teachers could use GPT to effectively brainstorm customized instructional materials.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1134–1140},
numpages = {7},
keywords = {curriculum customization, k-8, large language models, scratch programming, teacher supports},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3657604.3662036,
author = {Lyu, Wenhan and Wang, Yimeng and Chung, Tingting (Rachel) and Sun, Yifan and Zhang, Yixuan},
title = {Evaluating the Effectiveness of LLMs in Introductory Computer Science Education: A Semester-Long Field Study},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662036},
doi = {10.1145/3657604.3662036},
abstract = {The integration of AI assistants, especially through the development of Large Language Models (LLMs), into computer science education has sparked significant debate, highlighting both their potential to augment student learning and the risks associated with their misuse. An emerging body of work has looked into using LLMs in education, primarily focusing on evaluating the performance of existing models or conducting short-term human subject studies. However, very little work has examined the impacts of LLM-powered assistants on students in entry-level programming courses, particularly in real-world contexts and over extended periods. To address this research gap, we conducted a semester-long, between-subjects study with 50 students using CodeTutor, an LLM-powered assistant developed by our research team. Our study results show that students who used CodeTutor (the "CodeTutor group" as the experimental group) achieved statistically significant improvements in their final scores compared to peers who did not use the tool (the "control group"). Within the CodeTutor group, those without prior experience with LLM-powered tools demonstrated significantly greater performance gain than their counterparts. We also found that students expressed positive feedback regarding CodeTutor's capability to comprehend their queries and assist in learning programming language syntax. However, they had concerns about CodeTutor's limited role in developing critical thinking skills. Over the course of the semester, students' agreement with CodeTutor's suggestions decreased, with a growing preference for support from traditional human teaching assistants. Our findings also show that students turned to CodeTutor for different tasks, including programming task completion, syntax comprehension, and debugging, particularly seeking help for programming assignments. Our analysis further reveals that the quality of user prompts was significantly correlated with CodeTutor's response effectiveness. Building upon these results, we discuss the implications of our findings for the need to integrate Generative AI literacy into curricula to foster critical thinking skills, and turn to examining the temporal dynamics of user engagement with LLM-powered tools. We further discuss the discrepancy between the anticipated functions of tools and students' actual capabilities, which sheds light on the need for tailored strategies to improve educational outcomes.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {63–74},
numpages = {12},
keywords = {field study, large language models, tutoring},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3723010.3723012,
author = {Borghoff, Uwe M. and Minas, Mark and Schopp, Jannis},
title = {Generative AI in Student Software Development Projects: A User Study on Experiences and Self-Assessment},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723012},
doi = {10.1145/3723010.3723012},
abstract = {The way software is developed is changing rapidly due to the general availability of generative AI tools. As a result, the software engineering education that is part of every computer science program needs to change. Especially in software engineering courses, such AI tools need to be used and practiced in a meaningful and useful way. The programming project is one such course at our university, and the curriculum will be expanded accordingly in the future. In this paper we describe our approach and a user study among the participants of the last programming project, in which we collected experiences with the use of current AI tools, in particular highlighting their usefulness and limitations. Our study focuses on identifying which aspects of the course students used AI tools for, evaluating successful applications, and uncovering remaining challenges.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {161–170},
numpages = {10},
keywords = {software development project course, software engineering education, AI support, AI-based tutoring, experiments},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3643795.3648379,
author = {Rasnayaka, Sanka and Wang, Guanlin and Shariffdeen, Ridwan and Iyer, Ganesh Neelakanta},
title = {An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648379},
doi = {10.1145/3643795.3648379},
abstract = {Large Language Models (LLMs) represent a leap in artificial intelligence, excelling in tasks using human language(s). Although the main focus of general-purpose LLMs is not code generation, they have shown promising results in the domain. However, the usefulness of LLMs in an academic software engineering project has not been fully explored yet. In this study, we explore the usefulness of LLMs for 214 students working in teams consisting of up to six members. Notably, in the academic course through which this study is conducted, students were encouraged to integrate LLMs into their development tool-chain, in contrast to most other academic courses that explicitly prohibit the use of LLMs.In this paper, we analyze the AI-generated code, prompts used for code generation, and the human intervention levels to integrate the code into the code base. We also conduct a perception study to gain insights into the perceived usefulness, influencing factors, and future outlook of LLM from a computer science student's perspective. Our findings suggest that LLMs can play a crucial role in the early stages of software development, especially in generating foundational code structures, and helping with syntax and error debugging. These insights provide us with a framework on how to effectively utilize LLMs as a tool to enhance the productivity of software engineering students, and highlight the necessity of shifting the educational focus toward preparing students for successful human-AI collaboration.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {111–118},
numpages = {8},
keywords = {LLM for code generation, software engineering},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3626253.3635408,
author = {Xiang, Lili},
title = {SQL Query Evaluation with Large Language Model and Abstract Syntax Trees},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635408},
doi = {10.1145/3626253.3635408},
abstract = {SQL stands as the foundational language for data analysis and manipulation, playing a pivotal role in the database learning process. Proficiency in SQL is essential for students seeking to excel in data-related fields. However, the conventional approaches to assessing SQL queries rely heavily on manual grading, and the automated assessment tools are usually producing only binary decisions for the submitted queries. Our primary research objective is to develop effective methods for evaluating the quality of the SQL queries. To meet this objective, we introduce two approaches: structure-based analysis and evaluation by an instruction tuned large language model (LLM). The first approach deconstructs queries into Abstract Syntax Trees (AST) and employs cosine similarity to assess student submissions. The second approach utilizes a pre-trained LLM: FLAN-T5, fine-tuned for predicting the quality of student submissions. These methodologies are tested on a SQL dataset, and our experimental findings evaluate against a grading rubric with categories ranging from "good" to "unacceptable". The experimental results demonstrate that we can enhance the grading efficiency by applying these approaches and illustrate the ability of utilizing LLM to classify the assessed SQL statements more accurately. In addition, this research contributes to Computer Science (CS) education by integrating these approaches into our team's automated SQL statement assessment tool, improving the learning experience and evaluation process.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1890},
numpages = {1},
keywords = {abstract syntax trees, auto-grader, cs education, large language model, sql},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630927,
author = {Kirova, Vassilka D. and Ku, Cyril S. and Laracy, Joseph R. and Marlowe, Thomas J.},
title = {Software Engineering Education Must Adapt and Evolve for an LLM Environment},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630927},
doi = {10.1145/3626252.3630927},
abstract = {In the era of artificial intelligence (AI), generative AI, and Large Language Models (LLMs) in particular, have become increasingly significant in various sectors. LLMs such as GPT expand their applications, from content creation to advanced code completion. They offer unmatched opportunities but pose unique challenges to the software engineering domain. This paper discusses the necessity and urgency for software engineering education to adapt and evolve to prepare software engineers for the emerging LLM environment. While existing literature and social media have investigated AI's integration into various educational spheres, there is a conspicuous gap in examining the specifics of LLMs' implications for software engineering education. We explore the goals of software engineering education, and changes to software engineering, software engineering education, course pedagogy, and ethics. We argue that a holistic approach is needed, combining technical skills, ethical awareness, and adaptable learning strategies. This paper seeks to contribute to the ongoing conversation about the future of software engineering education, emphasizing the importance of adapting and evolving to remain in sync with rapid advancements in AI and LLMs. It is hoped that this exploration will provide valuable insights for educators, curriculum developers, and policymakers in software engineering.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {666–672},
numpages = {7},
keywords = {chatgpt, generative ai, large language models (llms), responsible ai, software engineering, software engineering education, software engineering ethics, software ethics},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3706598.3713644,
author = {Rogers, Kantwon and Davis, Michael and Maharana, Mallesh and Etheredge, Pete and Chernova, Sonia},
title = {Playing Dumb to Get Smart: Creating and Evaluating an LLM-based Teachable Agent within University Computer Science Classes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713644},
doi = {10.1145/3706598.3713644},
abstract = {This work presents the iterative design and evaluation of a large-language-model (LLM) based teachable agent, MatlabTutee, that facilitates learning-by-teaching (LBT) experiences within university computer science courses. We detail four different experiments, with a total of 119 students, where we refine our system, compare it to human-facilitated LBT experiences, and deploy it in two, month-long in-the-wild environments. We find that our system is able to successfully convey a learner persona similar to a human pretending to be novice while also providing comparable LBT benefits. These benefits include helping students identify areas for improvement, develop a more accurate assessment of their own abilities, and improve their overall attitudes toward computer science. We also explore how students choose to adopt our system into their study habits while situated in real university courses.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {126},
numpages = {22},
keywords = {Computer Science Education, LLM, Teachable Agent, Deception, Learning by Teaching, University Students, Longitudinal},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641554.3701829,
author = {Liu, Runda and Chen, Shengqi and Chen, Jiajie and Niu, Songjie and Ma, Yuchun and Tang, Xiaofeng},
title = {Iterative Design of a Teaching Assistant Training Program in Computer Science Using the Agile Method},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701829},
doi = {10.1145/3641554.3701829},
abstract = {Facing soaring enrollment and disruptive educational technologies, computing education increasingly relies on the contributions of teaching assistants (TAs), hence the critical importance of high-quality TA training. However, the design and implementation of TA training in computer science face substantial barriers, such as the lack of experienced TA trainers and the scarcity of relevant training materials.This experience report describes the design and implementation of a peer-led computer science TA training program that began in 2022 and has since undergone three iterations, inspired by the approach of agile software development. The current program consists of 10 sessions, organized to serve TAs in three respective stages of professional development. The iterations involved updating and enrichment of the syllabus, transitioning from lecture-centered to discussion-centered training, and discussions of emerging topics in computing education such as the use of large language models (LLMs). Participant feedback showed that TAs approved the iterative design of the training, while identifying areas for further improvement. We summarize lessons learned from the iterative process, reflect on the role of peer TA trainers, and discuss plans for future iterations.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {680–686},
numpages = {7},
keywords = {agile, ta training, teaching assistant},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3686852.3686864,
author = {Dakshit, Sagnik},
title = {Faculty Perspectives on the Potential of RAG in Computer Science Higher Education},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3686864},
doi = {10.1145/3686852.3686864},
abstract = {The emergence of Large Language Models (LLMs) has significantly impacted the field of Natural Language Processing and has transformed conversational tasks across various domains because of their widespread integration in applications and public access. The discussion surrounding the application of LLMs in education has raised ethical concerns, particularly concerning plagiarism and policy compliance. Despite the prowess of LLMs in conversational tasks, the limitations of reliability and hallucinations exacerbate the need to guardrail conversations, motivating our investigation of RAG in computer science higher education. We developed Retrieval Augmented Generation (RAG) applications for the two tasks of virtual teaching assistants and teaching aids. In our study, we collected the ratings and opinions of faculty members in undergraduate and graduate computer science university courses at various levels, using our personalized RAG systems for each course. This study is the first to gather faculty feedback on the application of LLM-based RAG in education. The investigation revealed that while faculty members acknowledge the potential of RAG systems as virtual teaching assistants and teaching aids, certain barriers and features are suggested for their full-scale deployment. These findings contribute to the ongoing discussion on the integration of advanced language models in educational settings, highlighting the need for careful consideration of ethical implications and the development of appropriate safeguards to ensure responsible and effective implementation.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {19–24},
numpages = {6},
keywords = {Education, Large Language Models, Learning, Neural Networks, Retrieval Augmented Generation},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@article{10.1145/3712003,
author = {He, Junda and Treude, Christoph and Lo, David},
title = {LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision, and the Road Ahead},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712003},
doi = {10.1145/3712003},
abstract = {Integrating Large Language Models (LLMs) into autonomous agents marks a significant shift in the research landscape by offering cognitive abilities that are competitive with human planning and reasoning. This article explores the transformative potential of integrating Large Language Models into Multi-Agent (LMA) systems for addressing complex challenges in software engineering (SE). By leveraging the collaborative and specialized abilities of multiple agents, LMA systems enable autonomous problem-solving, improve robustness, and provide scalable solutions for managing the complexity of real-world software projects. In this article, we conduct a systematic review of recent primary studies to map the current landscape of LMA applications across various stages of the software development lifecycle (SDLC). To illustrate current capabilities and limitations, we perform two case studies to demonstrate the effectiveness of state-of-the-art LMA frameworks. Additionally, we identify critical research gaps and propose a comprehensive research agenda focused on enhancing individual agent capabilities and optimizing agent synergy. Our work outlines a forward-looking vision for developing fully autonomous, scalable, and trustworthy LMA systems, laying the foundation for the evolution of Software Engineering 2.0.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {124},
numpages = {30},
keywords = {Large Language Models, Autonomous Agents, Multi-Agent Systems, Software Engineering}
}

@inproceedings{10.1145/3649405.3659504,
author = {Bernstein, Seth and Denny, Paul and Leinonen, Juho and Littlefield, Matt and Hellas, Arto and MacNeil, Stephen},
title = {Analyzing Students' Preferences for LLM-Generated Analogies},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659504},
doi = {10.1145/3649405.3659504},
abstract = {Introducing students to new concepts in computer science can often be challenging, as these concepts may differ significantly from their existing knowledge and conceptual understanding. To address this, we employed analogies to help students connect new concepts to familiar ideas. Specifically, we generated analogies using large language models (LLMs), namely ChatGPT, and used them to help students make the necessary connections. In this poster, we present the results of our survey, in which students were provided with two analogies relating to different computing concepts, and were asked to describe the extent to which they were accurate, interesting, and useful. This data was used to determine how effective LLM-generated analogies can be for teaching computer science concepts, as well as how responsive students are to this approach.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {812},
numpages = {1},
keywords = {analogies, computer science education, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3641554.3701800,
author = {Shah, Anshul and Chernova, Anya and Tomson, Elena and Porter, Leo and Griswold, William G. and Soosai Raj, Adalbert Gerald},
title = {Students' Use of GitHub Copilot for Working with Large Code Bases},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701800},
doi = {10.1145/3641554.3701800},
abstract = {Large language models (LLMs) are already heavily used by professional software engineers. An important skill for new university graduates to possess will be the ability to use such LLMs to effectively navigate and modify a large code base. While much of the prior work related to LLMs in computing education focuses on novice programmers learning to code, less work has focused on how upper-division students use and trust these tools, especially while working with large code bases. In this study, we taught students about various GitHub Copilot features, including Copilot chat, in an upper-division software engineering course and asked students to add a feature to a large code base using Copilot. Our analysis revealed a novel interaction pattern that we call one-shot prompting, in which students ask Copilot to implement the entire feature at once and spend the next few prompts asking Copilot to debug the code or asking Copilot to regenerate its incorrect response. Finally, students reported significantly more trust in the code comprehension features than code generation features of Copilot, perhaps due to the presence of trust affordances in the Copilot chat that are absent in the code generation features. Our study takes the first steps in understanding how upper-division students use Github Copilot so that our instruction can adequately prepare students for a career in software engineering.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1050–1056},
numpages = {7},
keywords = {github copilot, large code bases, program comprehension, trust},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701810,
author = {Borela, Rodrigo and Liding, Zhixian and McDaniel, Melinda},
title = {Enhancing CS1 Education through Experiential Learning with Robotics Projects},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701810},
doi = {10.1145/3641554.3701810},
abstract = {To address the challenges of generative AI in CS1 education, especially its misuse by students to bypass coding exercises, which undermines their engagement with foundational learning, CS1 curricula are evolving to emphasize higher-level problem-solving and systems thinking. In response, a novel experiential learning initiative grounded in High-Impact Practices was introduced to a CS1 course over the course of 2 semesters, involving 132 students. This initiative utilized robotics lab assignments to enhance computational thinking across various levels of granularity, from individual functional components to overall system behaviors, bridging conceptual understanding with real-world applications. The approach emphasized project-based learning, extended engagement time, and reflective practices to deepen students' understanding of core computing concepts and scaffold knowledge integration. The curriculum featured both individual and team-based lab assignments to build foundational skills followed by collaborative problem-solving. The initiative's impact was assessed against a control group of 427 students who completed traditional web development lab assignments. Evaluation methods included thematic analyses of student reflections, instructor opinion surveys, and statistical analysis of exam performances across the semester. Results revealed a substantial positive effect on self-efficacy and learning outcomes. Students in the experiential learning group reported increased confidence in applying their computing skills to real-world scenarios, heightened engagement, and greater improvements in technical proficiency. Notably, their exam scores demonstrated a statistically significant improvement compared to the control group. These findings highlight the effectiveness of integrating practical, interactive elements into computer science education to meet the demands of a rapidly evolving technological landscape.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {144–150},
numpages = {7},
keywords = {artificial intelligence, collaborative learning, cs1, experiential learning, robotics},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3568812.3603453,
author = {Tran, Minh},
title = {Prompt Engineering for Large Language Models to Support K-8 Computer Science Teachers in Creating Culturally Responsive Projects},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603453},
doi = {10.1145/3568812.3603453},
abstract = {The power of large language models has opened up opportunities for educational use. In computing education, recent studies have demonstrated the potential of these models to improve learning and teaching experiences in university-level programming courses. However, research into leveraging them to aid computer science instructors in curriculum development and course material design is relatively sparse, especially at the K-12 level. This work aims to fill this gap by exploring the capability of large language models in ideating and designing culturally responsive projects for elementary and middle school programming classes. Our ultimate goal is to support K-8 teachers in effectively extracting suggestions from large language models by only using natural language modifications. Furthermore, we aim to develop a comprehensive assessment framework for culturally responsive AI-generated project ideas. We also hope to provide valuable insight into teachers’ perspectives on large language models and their integration into teaching practices.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {110–112},
numpages = {3},
keywords = {culturally responsive pedagogy, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3641555.3704754,
author = {Bhattacharya, Sambit and Uma, Ravanasamudram and Deb, Debzani},
title = {Integrating Data Science for Social Justice: A Tutorial on Developing Non-Traditional Pathways for Non-CS Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704754},
doi = {10.1145/3641555.3704754},
abstract = {In response to the growing need for socially responsible computer scientists and data scientists, our team is developing a comprehensive data science certificate program specifically tailored for non-computing majors, with a focus on data science for social justice. This program aims to broaden participation in data science and create non-traditional pathways for diverse student populations. Each course in the program is designed to be accessible to non-computing majors, equipping them with the skills to analyze and address social justice issues through data science. Process Oriented Guided Inquiry Learning (POGIL) is employed as an instructional strategy promoting active learning, and real datasets related to social justice are utilized for hands-on activities and assignments, enhancing practical learning experiences. The courses are taught in a synchronous hybrid format, across multiple universities, accommodating both live online and in-person students.This tutorial will equip educators with the tools to incorporate data science for social justice in their courses. Attendees will have access to materials developed for these courses, enabling them to integrate similar content into their own curricula. A key focus is on recent challenges and opportunities created by generative AI. The presenters will share their experiences, course materials, and strategies for introducing computer science through a social justice lens. Participants will share ideas and strategies, which will be collated and made available in a shared repository. This initiative aims to enable educators to train future generations in data science while addressing social justice issues.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1767},
numpages = {1},
keywords = {certificate program, data science, non-computing majors, social justice},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3632621.3671429,
author = {Potriasaeva, Anna and Dzialets, Katsiaryna and Golubev, Yaroslav and Birillo, Anastasiia},
title = {Using a Low-Code Environment to Teach Programming in the Era of LLMs},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671429},
doi = {10.1145/3632621.3671429},
abstract = {LLMs change the landscape of software engineering, and the question arises: “How can we combine LLMs with traditional teaching approaches in computer science?”. In this work, we propose to teach students in a low-code environment of code generation, developing not only their coding but also decomposition and prompting skills.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {542–543},
numpages = {2},
keywords = {Generative AI, LLMs, MOOC, Programming Education},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3641555.3705076,
author = {Chen, Matt},
title = {Early Adoption of Custom Generative AI Bots in Online Forums for CS Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705076},
doi = {10.1145/3641555.3705076},
abstract = {This lightning talk presents insights from a pilot program in an IT Faculty, where custom generative AI bots were integrated into online forums across 20 courses over two semesters in 2024. The AI bots were trained on specific course content and past student questions to provide tailored responses to student inquiries, with all responses reviewed by teaching staff before being released to students.This approach, distinct from the direct use of large language models (LLMs) like ChatGPT or Claude, offers targeted information aligned with course material and ensures accuracy while preventing the disclosure of assignment answers. The mechanism is designed to support large computer science courses, including first-year courses with over 1,000 students, where timely and comprehensive staff responses can be challenging.This talk will explore the benefits and drawbacks of using generative AI bots in the CS context. It will also examine the factors influencing staff acceptance and trust in chatbot responses and how AI impacts the types and quality of student questions in forums. Key lessons learned and challenges encountered during the program's implementation will also be shared.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1739},
numpages = {1},
keywords = {custom AI integration, generative AI bots},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3665464.3665480,
author = {Manley, Eric D.},
title = {Getting Started with Large Language Models for the CS Curriculum},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {With the introduction of ChatGPT in late 2022, popular interest in language-based Artificial Intelligence has exploded. Employers are looking to hire computer scientists who can leverage large language models (LLMs) [2], and student demand for learning about them at many higher education institutions has followed. This one-hour workshop will help computer science educators respond to this demand by introducing the Python transformers library and its associated LLM ecosystem [1]. We will discuss how LLMs can be integrated into college computer science curricula from CS 1 through advanced courses in Artificial Intelligence, Machine Learning, or Natural Language Processing. Specific topics include• Using the transformers library with pre-trained models for inference tasks like sentiment analysis, text classification, summarization, translation, and question answering in only a few lines of code• Searching for and using hundreds of thousands of different pre-trained language models hosted by Hugging Face along with datasets that they can be tested on• Utilizing conversational models to build chat bots},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {116–117},
numpages = {2}
}

@article{10.1145/3687038,
author = {Kumar, Harsh and Musabirov, Ilya and Reza, Mohi and Shi, Jiakai and Wang, Xinyuan and Williams, Joseph Jay and Kuzminykh, Anastasia and Liut, Michael},
title = {Guiding Students in Using LLMs in Supported Learning Environments: Effects on Interaction Dynamics, Learner Performance, Confidence, and Trust},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687038},
doi = {10.1145/3687038},
abstract = {Personalized chatbot-based teaching assistants can be crucial in addressing increasing classroom sizes, especially where direct teacher presence is limited. Large language models (LLMs) offer a promising avenue, with increasing research exploring their educational utility. However, the challenge lies not only in establishing the efficacy of LLMs but also in discerning the nuances of interaction between learners and these models, which impact learners' engagement and results. We conducted a formative study in an undergraduate computer science classroom (N=145) and a controlled experiment on Prolific (N=356) to explore the impact of four pedagogically informed guidance strategies on the learners' performance, confidence and trust in LLMs. Direct LLM answers marginally improved performance, while refining student solutions fostered trust. Structured guidance reduced random queries as well as instances of students copy-pasting assignment questions to the LLM. Our work highlights the role that teachers can play in shaping LLM-supported learning environments.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {499},
numpages = {30},
keywords = {artificial intelligence in education, collaborative learning with ai, human-ai collaboration, large language models, transparency, tutoring systems}
}

@inproceedings{10.1145/3657604.3664663,
author = {Wang, Tianjia and Ramanujan, Ramaraja and Lu, Yi and Mao, Chenyu and Chen, Yan and Brown, Chris},
title = {DevCoach: Supporting Students in Learning the Software Development Life Cycle at Scale with Generative Agents},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664663},
doi = {10.1145/3657604.3664663},
abstract = {Supporting novice computer science students in learning the software development life cycle (SDLC) at scale is vital for ensuring the quality of future software systems. However, this presents unique challenges, including the need for effective interactive collaboration and access to diverse skill sets of members in the software development team. To address these problems, we present ''DevCoach'', an online system designed to support students learning the SDLC at scale by interacting with generative agents powered by large language models simulating members with different roles in a software development team. Our preliminary user study results reveal that DevCoach improves the experiences and outcomes for students, with regard to learning concepts in SDLC's ''Plan and Design'' and ''Develop'' phases. We aim to use our findings to enhance DevCoach to support the entire SDLC workflow by incorporating additional simulated roles and enabling students to choose their project topics. Future studies will be conducted in an online Software Engineering class at our institution, aiming to explore and inspire the development of intelligent systems that provide comprehensive SDLC learning experiences to students at scale.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {351–355},
numpages = {5},
keywords = {computer science education, generative ai, software development life cycle, software engineering},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@book{10.1145/3708897,
author = {Giacaman, Nasser and Terragni, Valerio},
title = {Empowering Computing Students with Large Language Models by Developing an Escape Room Game},
year = {2025},
isbn = {9798400714450},
abstract = {In this project, computing students learn to integrate large language models (LLMs) into a software system. Students develop a Java application with a basic graphical user interface (GUI) using JavaFX, gain practical experience with prompt engineering, and learn about the impact of LLM parameters and conversational roles. Students are provided with a Javabased API that connects with OpenAI's GPT model. The project emphasizes teaching students to manage LLM API calls, enhance GUI responsiveness, and improve the user experience all in the context of an AI-powered application. This experience equips them with critical skills in software development and AI application. It prepares them for advanced software development by learning how to create effective LLM prompts to create intelligent and user-friendly applications. We share the experience of using this project and provide guidelines for assessing it in a second-year software engineering undergraduate course, where students' prior programming experience is limited to the prerequisite CS2 course on object-oriented programming. In the case study we present, the project involved developing a riddle-solving escape room, which we called EscAIpe Room.},
numpages = {6}
}

@inproceedings{10.1145/3626203.3670577,
author = {Nadel, Peter and Maloney, Delilah and Monahan, Kyle},
title = {Enabling access to large-language models (LLMs) at scale for higher education},
year = {2024},
isbn = {9798400704192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626203.3670577},
doi = {10.1145/3626203.3670577},
abstract = {The use of language models, particularly large-language models (LLMs), have been increasingly popular and can be transformative in higher education, by both enabling novel research approaches and providing instructional opportunities for skills needed in data science and engineering. However, running these LLMs traditionally requires access to advanced hardware resources and technical knowledge. To better provide a platform for experimenting with LLMs for users of all skill levels, we developed the Tufts Technology Services (TTS) LLM-Hub, a series of example Jupyter notebooks served through Tufts Open OnDemand (OOD) to setup, configure, and run LLMs automatically. The TTS LLM-Hub enabled quick access to running LLMs, while reducing barriers to compute and enabling users to chat with an LLM in just four clicks. We have used these platforms for support of advanced data science courses, and to enable research computing at Tufts.},
booktitle = {Practice and Experience in Advanced Research Computing 2024: Human Powered Computing},
articleno = {49},
numpages = {4},
keywords = {High-Performance Computing (HPC), Large-Language Models (LLMs), Open OnDemand (OOD)},
location = {Providence, RI, USA},
series = {PEARC '24}
}

@article{10.5555/3737313.3737340,
author = {Crocetti, Giancarlo and Bak, Seonwoo and Noory, Naqib A. and Vautor-Laplaceliere, Daena D.},
title = {Evaluating the Pedagogical Impact of Large Language Models on Programming Skills in Higher Education},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {This empirical study investigated the impact of Generative AI (GenAI) tools, particularly large language models (LLMs), on college students' Python programming skills in a graduate-level data science course. Using a pretest-posttest methodology and accounting for variables like prior programming experience, the research examined how guided LLM usage affected students' self-assessed programming abilities. The findings revealed that while LLMs positively influenced students' capacity to develop complex applications, work with Python libraries, and write quality code, they had no significant impact on students' grasp of fundamental Python concepts or their general comfort with the language. These results suggest that LLMs serve as effective tools for advancing practical programming skills but cannot substitute for the foundational programming knowledge that must be developed through traditional learning.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {163–177},
numpages = {15}
}

@inproceedings{10.1145/3641555.3705061,
author = {Liu, Rongxin and Xu, Benjamin and Perez, Christopher and Zhao, Julianna and Zhukovets, Yuliia and Malan, David J.},
title = {Assessment in CS50 with AI: Leveraging Generative Artificial Intelligence for Personalized Student Evaluation},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705061},
doi = {10.1145/3641555.3705061},
abstract = {The scalability challenges of code review and pair-programming assessments in large computer science courses, such as CS50 at Harvard University, have opened up opportunities for the application of Generative AI. Leveraging large language models (LLMs), CS50.ai offers a suite of AI-based tools that assist both students and instructors in mastering course material while overcoming the limitations posed by human resource constraints. This demo highlights how generative AI can be employed to conduct code reviews and pair-programming simulations, providing real-time feedback, code explanations, and collaborative programming insights. By integrating these AI tools into students' learning journeys, we aim to mimic the 1:1 interaction between instructor and student, improving both formative and summative assessments. We will showcase how these tools are implemented to scale personalized feedback, ensure academic integrity, and maintain pedagogical efficacy. Our presentation will also reflect on lessons learned from deploying these AI-driven tools in recent course offerings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1735},
numpages = {1},
keywords = {AI, LLMs, artificial intelligence, generative AI, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3660650.3660657,
author = {Roberts, Jordan and Mohamed, Abdallah},
title = {Generative AI in CS Education: Literature Review through a SWOT Lens},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660657},
doi = {10.1145/3660650.3660657},
abstract = {The rapid growth of generative artificial intelligence (AI) models introduced challenges for educators, students and administrators across the academic sphere related to how to manage and regulate these tools. While some oppose their use, many researchers have begun to approach the topic of educational AI use from a different perspective. Despite being in its early stages; this field of research has produced notable insights into the capabilities and limitations of models like ChatGPT. This paper utilizes a SWOT analysis framework to analyze and consolidate existing literature, with a specific focus on Computer Science education. Through the analysis of this literature, we have created a set of use cases and guidelines to aid in the future development of strategies and tools within this field. Our findings indicate that while some concerns are valid, such as AI's ability to generate plagiarized work, we identified several promising avenues and opportunities for careful integration of this technology into education.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {10},
numpages = {6},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3641554.3701872,
author = {McDanel, Bradley and Novak, Ed},
title = {Designing LLM-Resistant Programming Assignments: Insights and Strategies for CS Educators},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701872},
doi = {10.1145/3641554.3701872},
abstract = {The rapid advancement of Large Language Models (LLMs) like ChatGPT has raised concerns among computer science educators about how programming assignments should be adapted. This paper explores the capabilities of LLMs (GPT-3.5, GPT-4, and Claude Sonnet) in solving complete, multi-part CS homework assignments from the SIGCSE Nifty Assignments list. Through qualitative and quantitative analysis, we found that LLM performance varied significantly across different assignments and models, with Claude Sonnet consistently outperforming the others. The presence of starter code and test cases improved performance for advanced LLMs, while certain assignments, particularly those involving visual elements, proved challenging for all models. LLMs often disregarded assignment requirements, produced subtly incorrect code, and struggled with context-specific tasks. Based on these findings, we propose strategies for designing LLM-resistant assignments. Our work provides insights for instructors to evaluate and adapt their assignments in the age of AI, balancing the potential benefits of LLMs as learning tools with the need to ensure genuine student engagement and learning.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {756–762},
numpages = {7},
keywords = {ai-resistant assignments, assignment design, cs education, llm code generation, programming pedagogy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3585059.3611431,
author = {Zheng, Yong},
title = {ChatGPT for Teaching and Learning: An Experience from Data Science Education},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611431},
doi = {10.1145/3585059.3611431},
abstract = {ChatGPT, an implementation and application of large language models, has gained significant popularity since its initial release. Researchers have been exploring ways to harness the practical benefits of ChatGPT in real-world scenarios. Educational researchers have investigated its potential in various subjects, e.g., programming, mathematics, finance, clinical decision support, etc. However, there has been limited attention given to its application in data science education. This paper aims to bridge that gap by utilizing ChatGPT in a data science course, gathering perspectives from students, and presenting our experiences and feedback on using ChatGPT for teaching and learning in data science education. The findings not only distinguish data science education from other disciplines but also uncover new opportunities and challenges associated with incorporating ChatGPT into the data science curriculum.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {66–72},
numpages = {7},
keywords = {ChatGPT, data analytics, data science, large language model},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@inproceedings{10.1145/3641555.3705250,
author = {Akhmetov, Ildar and Prpa, Mirjana},
title = {Simulating Requirement Elicitation: Development and Evaluation of a Persona-Based Tool},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705250},
doi = {10.1145/3641555.3705250},
abstract = {We present the Requirement Elicitation Tool that leverages Large Language Model (LLM) (gpt-4o-mini) to enable simulated real-world interactions of requirements gathering from three synthetic personas. We demonstrate the use case of Computer Science (CS) students in Database Management Systems leveraging the tool to build a conceptual model and Entity-Relationship (ER) diagrams. Our preliminary findings show the potential of this tool to engage students in discovery process without providing predefined solutions and set the directions for future work.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1357–1358},
numpages = {2},
keywords = {AI persona, requirement elicitation, software engineering education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3657604.3664673,
author = {Fung, Sze Ching Evelyn and Wong, Man Fai and Tan, Chee Wei},
title = {Automatic Feedback Generation on K-12 Students' Data Science Education by Prompting Cloud-based Large Language Models},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664673},
doi = {10.1145/3657604.3664673},
abstract = {Since data science is traditionally an advanced field taught at the college or university level, introducing its concepts to K-12 students can present unique learning challenges. As educational environments increasingly adopt data science curricula for K-12 students, the need for scalable, personalized teaching tools becomes critical. While the integration of large language models (LLMs) in educational environments offers significant potential for scalability and automation, it is important to note that the generated language output may not always be highly suitable for K-12 students. In this paper, we introduce the DSRAG, a novel educational automatic feedback generation framework that leverages Retrieval-Augmented Generation (RAG) and cloud-based LLMs to provide automated and personalized feedback for K-12 students engaged in data science education. DSRAG employs Langchain question-answering and RAG systems to manage educational content and generate feedback on the top of GPT-4. We also demonstrate the framework's capability to simplify complex concepts and align its responses to be pedagogically appropriate and understandable for K-12 students.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {255–258},
numpages = {4},
keywords = {large language models, learning technologies, prompt engineering, retrieval-augmented generation},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3626252.3630937,
author = {Grover, Shuchi},
title = {Teaching AI to K-12 Learners: Lessons, Issues, and Guidance},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630937},
doi = {10.1145/3626252.3630937},
abstract = {There is growing recognition of the need to teach artificial intelli- gence (AI) and machine learning (ML) at the school level. This push acknowledges the meteoric growth in the range and diversity of ap- plications of ML in all industries and everyday consumer products, with Large Language Models (LLMs) being only the latest and most compelling example yet. Efforts to bring AI, especially ML educa- tion to school learners are being propelled by substantial industry interest, research efforts, as well as technological developments that make sophisticated ML tools readily available to learners of all ages. These early efforts span a variety of learning goals captured by the AI4K12 "big ideas" framework and employ a plurality of pedagogies.This paper provides a sense for the current state of the field, shares lessons learned from early K-12 AI education as well as CS education efforts that can be leveraged, highlights issues that must be addressed in designing for teaching AI in K-12, and provides guidance for future K-12 AI education efforts and tackle what to many feels like "the next new thing".},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {422–428},
numpages = {7},
keywords = {artificial intelligence, k-12 ai education, k-12 cs education, machine learning},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3657604.3664660,
author = {Nguyen, Ha and Stott, Nate and Allan, Vicki},
title = {Comparing Feedback from Large Language Models and Instructors: Teaching Computer Science at Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664660},
doi = {10.1145/3657604.3664660},
abstract = {Large language models (LLMs) can provide formative feedback in programming to help students improve the code they have written. We investigate the use of LLMs (GPT-4) to provide formative code feedback in a sophomore-level computer science (CS) course on data structures and algorithms. In three quizzes on recursion, half of the students randomly received GPT-4's feedback, while the other half received feedback from the course instructor. Students resubmitted their code based on the provided feedback. We found that students in the LLM-feedback condition scored higher in resubmissions than those receiving feedback from the instructor. Students perceived the two types of feedback as equally supportive of guiding resubmissions. We discuss the implications of using LLMs to provide formative feedback at scale in CS instruction.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {335–339},
numpages = {5},
keywords = {computer science education, feedback, large language models},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3641555.3705121,
author = {Harrington, Brian and Alnoor, Ahmad Zubair and Haqiqi, Pedram and Hoseininia, Zahra and Lin, Kai and Lodi, Maliha and Mirza, Asad and Wolfe, Leah and Zhang, Kevin},
title = {A Systematic Literature Mapping of Early Generative AI Research is CS Education},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705121},
doi = {10.1145/3641555.3705121},
abstract = {The widespread release of generative AI tools has led to a rapid rise in publications evaluating their impact on CS education. While there is no doubt that the area is new and rapidly evolving, it is important to begin to catalogue and map the literature at this early stage. In this work, we systematically search and map 82 papers evaluating the impact of generative AI tools on CS education. We then build a literature map of these papers using the axes of population, use of generative AI, and method of evaluation. This work will serve as both a snapshot of the first generation of generative AI papers in the field, and a road-map for further classification and literature review as the field develops.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1467–1468},
numpages = {2},
keywords = {gen ai, generative ai, large language models, literature map, llm},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3722229,
author = {AlOmar, Eman Abdullah},
title = {Nurturing Code Quality: Leveraging Static Analysis and Large Language Models for Software Quality in Education},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
url = {https://doi.org/10.1145/3722229},
doi = {10.1145/3722229},
abstract = {Large Language Models (LLMs), such as ChatGPT, have become widely popular for various software engineering tasks, including programming, testing, code review, and program comprehension. However, their impact on improving software quality in educational settings remains uncertain. This article explores our experience teaching the use of Programming Mistake Detector (PMD) to foster a culture of bug fixing and leverage LLM to improve software quality in the classroom. This article discusses the results of an experiment involving 155 submissions that carried out a code review activity of 1,658 rules. Our quantitative and qualitative analyses reveal that a set of PMD quality issues influences the acceptance or rejection of the issues, and design-related categories that take longer to resolve. Although students acknowledge the potential of using ChatGPT during code review, some skepticism persists. Further, constructing prompts for ChatGPT that possess clarity, complexity, and context nurtures vital learning outcomes, such as enhanced critical thinking, and among the 1,658 issues analyzed, 93% of students indicated that ChatGPT did not identify any additional issues beyond those detected by PMD. Conversations between students and ChatGPT encompass five categories, including ChatGPT’s use of affirmation phrases like “certainly” regarding bug fixing decisions, and apology phrases such as “apologize” when resolving challenges. Through this experiment, we demonstrate that code review can become an integral part of the educational computing curriculum. We envision our findings to enable educators to support students with effective code review strategies, increasing awareness of LLMs, and promoting software quality in education.},
journal = {ACM Trans. Comput. Educ.},
month = may,
articleno = {16},
numpages = {36},
keywords = {large language models, education, bugfix, static analysis, code quality}
}

@inproceedings{10.1145/3716640.3716651,
author = {Qiao, Shuying and Denny, Paul and Giacaman, Nasser},
title = {Oversight in Action: Experiences with Instructor-Moderated LLM Responses in an Online Discussion Forum},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716651},
doi = {10.1145/3716640.3716651},
abstract = {The integration of large language models (LLMs) into computing education offers many potential benefits to student learning, and several novel pedagogical approaches have been reported in the literature. However LLMs also present challenges, one of the most commonly cited being that of student over-reliance. This challenge is compounded by the fact that LLMs are always available to provide instant help and solutions to students, which can undermine their ability to independently solve problems and diagnose and resolve errors. Providing instructor oversight of LLM-generated content can mitigate this problem, however it is often not practical in real-time learning contexts. Online class discussion forums, which are widely used in computing education, present an opportunity for exploring instructor oversight because they operate asynchronously. Unlike real-time interactions, the discussion forum format aligns with the expectation that responses may take time, making oversight not only feasible but also pedagogically appropriate. In this practitioner paper, we present the design, deployment, and evaluation of a ‘bot’ module that is controlled by the instructor, and integrated into an online discussion forum. The bot assists the instructor by generating draft responses to student questions, which are reviewed, modified, and approved before release. Key features include the ability to leverage course materials, access archived discussions, and publish responses anonymously to encourage open participation. We report our experiences using this tool in a 12-week second-year software engineering course on object-oriented programming. Instructor feedback confirmed the tool successfully alleviated workload but highlighted a need for improvement in handling complex, context-dependent queries. We report the features that were viewed as most beneficial, and suggest avenues for future exploration.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {95–104},
numpages = {10},
keywords = {Large language models, LLMs, discussion forums, instructor-in-the-loop, software engineering education, chatbots, computing education},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3649409.3691086,
author = {Velez, Xavier},
title = {Understanding Algorithmic Problem Solving using LLMs},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691086},
doi = {10.1145/3649409.3691086},
abstract = {With the rapid advancement of Large Language Models (LLMs) many instructors for Computer Science courses have begun to opt to allow students to use them as an additional educational resource but often warn that the output may be unreliable. Recent research on LLMs has demonstrated their ability to interpret commands in natural language and produce code in a variety of programming languages. However, it is not clear how well LLMs fair in tackling more complex problem set ups, like those typically seen in Algorithms courses in which students are provided natural language descriptions of an ambiguous problem and use what they learn to map the problem to an algorithmic solution. In this paper, we explore use of LLMs, such as OpenAI's GPT-4o, as tools for assisting students with complex Computer Science curricula, such as algorithmic problem solving. We specifically aim to see if using prompt refinement techniques, LLMs are capable of taking a problem statement in plain English and performing the following tasks: providing both a natural language description and code solution in the Python programming language, producing an analytical argument for the solutions correctness, and finally providing runtime analysis for the produced solution. Our experiments show that GPT-4o is well suited to solving problems like LeetCode 75 that have been seen during training, and prompt-refinement helps with those that have not been seen.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {327–328},
numpages = {2},
keywords = {GPT-4o, algorithms, large language models},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@article{10.1145/3697009,
author = {Zhang, Ting and Irsan, Ivana Clairine and Thung, Ferdian and Lo, David},
title = {Revisiting Sentiment Analysis for Software Engineering in the Era of Large Language Models},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3697009},
doi = {10.1145/3697009},
abstract = {Software development involves collaborative interactions where stakeholders express opinions across various platforms. Recognizing the sentiments conveyed in these interactions is crucial for the effective development and ongoing maintenance of software systems. For software products, analyzing the sentiment of user feedback, e.g., reviews, comments, and forum posts can provide valuable insights into user satisfaction and areas for improvement. This can guide the development of future updates and features. However, accurately identifying sentiments in software engineering datasets remains challenging.This study investigates bigger large language models (bLLMs) in addressing the labeled data shortage that hampers fine-tuned smaller large language models (sLLMs) in software engineering tasks. We conduct a comprehensive empirical study using five established datasets to assess three open source bLLMs in zero-shot and few-shot scenarios. Additionally, we compare them with fine-tuned sLLMs, using sLLMs to learn contextual embeddings of text from software platforms.Our experimental findings demonstrate that bLLMs exhibit state-of-the-art performance on datasets marked by limited training data and imbalanced distributions. bLLMs can also achieve excellent performance under a zero-shot setting. However, when ample training data are available or the dataset exhibits a more balanced distribution, fine-tuned sLLMs can still achieve superior results.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
articleno = {60},
numpages = {30},
keywords = {Large Language Models, Sentiment Analysis, Software Engineering}
}

@inproceedings{10.1145/3672608.3707736,
author = {Speiser, Sebastian},
title = {Assessing the Real-World Impact of Disagreement Between Human Graders and LLMs},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707736},
doi = {10.1145/3672608.3707736},
abstract = {Applying artificial intelligence models to grade student answers is a popular application. Lately Large Language Models (LLMs) have shown promising results. However, the disagreement between human graders and LLMs is often considered too large for practical adoption. In this paper, we investigate the real-world impact of this disagreement on final grades. Instead of focusing on individual answers, we simulate the grading process of an entire exam. We use an unmodified LLM (OpenAI GPT-3.5 Turbo) with one-shot prompting for grading individual answers to short answer questions from computer science courses at a German university. Our main contributions are the evaluation of the real-world impact on examination grades in contrast to correctness of individual student answers, the simulation of grading strategies common in human grading practice, and the discussion of the results in the context of observed inter-rater variabilities among human graders. The findings confirm the natural expectation that the impact of the disagreement is lower for final grades than when looking at individual answers. We quantify this effect and compare it to a grading obtained by simulating a second human grader.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {48–53},
numpages = {6},
keywords = {LLMs, programming education, automated short answer grading},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3641525.3663617,
author = {Boufford, Nichole and Wonsil, Joseph and Pocock, Adam and Sullivan, Jack and Seltzer, Margo and Pasquier, Thomas},
title = {Computational Experiment Comprehension using Provenance Summarization},
year = {2024},
isbn = {9798400705304},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641525.3663617},
doi = {10.1145/3641525.3663617},
abstract = {Scientists use complex multistep workflows to analyze data. However, reproducing computational experiments is often difficult as scientists’ software engineering practices are geared towards the science, not the programming. In particular, reproducing a scientific workflow frequently requires information about its execution. This information includes the precise versions of packages and libraries used, the particular processor used to perform floating point computation, and the language runtime used. This can be extracted from data provenance, the formal record of what happened during an experiment. However, data provenance is inherently graph-structured and often large, which makes interpretation challenging. Rather than exposing data provenance through its graphical representation, we propose a textual one and use a large language model to generate it. We develop techniques for prompting large language models to automatically generate textual summaries of provenance data. We conduct a user study to compare the effectiveness of these summaries to the more common node-link diagram representation. Study participants are able to extract useful information from both the textual summaries and node-link diagrams. The textual summaries were particularly beneficial for scientists with low computational expertise. We discuss the qualitative results from our study to motivate future designs for reproducibility tools.},
booktitle = {Proceedings of the 2nd ACM Conference on Reproducibility and Replicability},
pages = {1–19},
numpages = {19},
keywords = {Provenance, Reproducibility, Text Generation, User Study},
location = {Rennes, France},
series = {ACM REP '24}
}

@inproceedings{10.1145/3641555.3705236,
author = {Chopra, Ryka C. and Chakraborty, Suparna},
title = {RAFIKI: Leveraging Large Language Models to Increase AP Computer Science A Enrollment among Disadvantaged High School Females},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705236},
doi = {10.1145/3641555.3705236},
abstract = {The gender gap in computing persists even after decades of investment in lowering the gap. Evidence suggests that stereotypical attitudes and bias perceptions play a critical role in limiting female participation in STEM, beginning in middle and high school. The gap is exacerbated in developing nations with limited academic counselor support. Therefore, the goal is to provide early targeted counseling. RAFIKI - "friend" in Swahili is a large language model-based web application designed to mimic an academic coach. Using user inputs, it provides customized academic counseling with curated information on STEM and computing pathways. Initial experimental evidence shows that RAFIKI use leads to a significant increase in AP Computer Science A course enrollment, considered a pathway to future computing career, particularly among female high school students.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1417–1418},
numpages = {2},
keywords = {AP CSA, ChatGPT, digital coach, female enrollment},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3696673.3723053,
author = {Vasudevan, Poonkuzhali and Reddivari, Sandeep},
title = {The Role of Generative AI Models in Requirements Engineering: A Systematic Literature Review},
year = {2025},
isbn = {9798400712777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696673.3723053},
doi = {10.1145/3696673.3723053},
abstract = {The software engineering field is experiencing rapid growth, driven by recent advancements in Artificial Intelligence (AI), particularly in Generative AI (GenAI) and Large Language Models (LLMs). Requirements Engineering (RE), a critical phase in software development, involves gathering and defining software requirements. However, research on the impact of GenAI and LLMs within RE remains limited. This paper examines the adoption of GenAI in RE, with the aim of exploring its practical implications, identifying current research trends, and highlighting areas for future development. To achieve this, a systematic literature review was conducted, addressing three research questions and analyzing 44 studies published over the past decade. The findings reveal that GenAI models, especially LLMs, are extensively employed in a variety of RE tasks, underscoring the versatility and potential of LLMs in enhancing the RE process.},
booktitle = {Proceedings of the 2025 ACM Southeast Conference},
pages = {188–194},
numpages = {7},
keywords = {requirements engineering, generative AI, large language models},
location = {Southeast Missouri State University, Cape Girardeau, MO, USA},
series = {ACMSE 2025}
}

@inproceedings{10.1145/3641554.3701785,
author = {Ramirez Osorio, Valeria and Zavaleta Bernuy, Angela and Simion, Bogdan and Liut, Michael},
title = {Understanding the Impact of Using Generative AI Tools in a Database Course},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701785},
doi = {10.1145/3641554.3701785},
abstract = {Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) have led to changes in educational practices by creating opportunities for personalized learning and immediate support. Computer science student perceptions and behaviors towards GenAI tools have been studied, but the effects of such tools on student learning have yet to be determined conclusively. We investigate the impact of GenAI tools on computing students' performance in a database course and aim to understand why students use GenAI tools in assignments. Our mixed-methods study (N=226) asked students to self-report whether they used a GenAI tool to complete a part of an assignment and why. Our results reveal that students utilizing GenAI tools performed better on the assignment part in which LLMs were permitted but did worse in other parts of the assignment and in the course overall. Also, those who did not use GenAI tools viewed more discussion board posts and participated more than those who used ChatGPT. This suggests that using GenAI tools may not lead to better skill development or mental models, at least not if the use of such tools is unsupervised, and that engagement with official course help supports may be affected. Further, our thematic analysis of reasons for using or not using GenAI tools, helps understand why students are drawn to these tools. Shedding light into such aspects empowers instructors to be proactive in how to encourage, supervise, and handle the use or integration of GenAI into courses, fostering good learning habits.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {959–965},
numpages = {7},
keywords = {computing education, databases, generative artificial intelligence, large language models, student behavior, student performance},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626253.3635511,
author = {Bhalerao, Rasika},
title = {My Learnings from Allowing Large Language Models in Introductory Computer Science Classes},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635511},
doi = {10.1145/3626253.3635511},
abstract = {Many instructors want to allow their students to use large language models (LLMs) in their introductory computer science courses, but they first want to see other instructors' results from doing so before taking on the risk in their own courses. Presented here are the results from allowing students to use LLMs in the second course in a sequence of intensive introductory courses designed to prepare students with a non-computational background for entry into a masters' degree program. We allowed students to use the internet and LLMs (such as ChatGPT or Github Copilot) to help with assignments, with guidelines to avoid plagiarism and encourage learning. We then surveyed students to ask about how they used LLMs, whether they saw others cheating, how they generally used internet-based resources on assignments and exams, and their feedback on the policies. We found that students are overwhelmingly using LLMs (and the internet generally) to learn and code "better" rather than cheat. These results are intended to be a starting point to spark discussion on the adoption of new technologies in introductory computer science courses. The authors themselves will continue teaching courses with the policy that students should interact with an LLM the way they interact with a person: students are encouraged to discuss and collaborate with it, but copying code from it is considered plagiarism.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1574–1575},
numpages = {2},
keywords = {AI, assignments, plagiarism, students},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3636243.3636257,
author = {Budhiraja, Ritvik and Joshi, Ishika and Challa, Jagat Sesh and Akolekar, Harshal D. and Kumar, Dhruv},
title = {“It's not like Jarvis, but it's pretty close!” - Examining ChatGPT's Usage among Undergraduate Students in Computer Science},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636257},
doi = {10.1145/3636243.3636257},
abstract = {Large language models (LLMs) such as ChatGPT and Google Bard have garnered significant attention in the academic community. Previous research has evaluated these LLMs for various applications such as generating programming exercises and solutions. However, these evaluations have predominantly been conducted by instructors and researchers, not considering the actual usage of LLMs by students. This study adopts a student-first approach to comprehensively understand how undergraduate computer science students utilize ChatGPT, a popular LLM, released by OpenAI. We employ a combination of student surveys and interviews to obtain valuable insights into the benefits, challenges, and suggested improvements related to ChatGPT. Our findings suggest that a majority of students (over 57%) have a convincingly positive outlook towards adopting ChatGPT as an aid in coursework-related tasks. However, our research also highlights various challenges that must be resolved for long-term acceptance of ChatGPT amongst students. The findings from this investigation have broader implications and may be applicable to other LLMs and their role in computing education.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {124–133},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, User Study},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3641554.3701946,
author = {Li, Nero and Broner, Shahar and Kim, Yubin and Mizuo, Katrina and Sauder, Elijah and To, Claire and Wang, Albert and Gila, Ofek and Shindler, Michael},
title = {Investigating the Capabilities of Generative AI in Solving Data Structures, Algorithms, and Computability Problems},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701946},
doi = {10.1145/3641554.3701946},
abstract = {There is both great hope and concern about the future of Computer Science practice and education concerning the recent advent of large language models (LLMs).We present the first study to extensively evaluate the ability of such a model to solve problems in Computer Science Theory. Specifically, we tested 165 exam-level problems across 16 specific topics related to computer science theory, ranging from preliminary data structures to algorithm design paradigms to theory of computation (automata and complexity). Our results use the recent popular models (GPT-4 and GPT-4o). This is a rapidly evolving field, with model performance continuously improving. We present our results primarily as an indication of what they can already achieve-equivalently how they can already be useful-today, fully expecting them to improve even further in the near future. Our results show that what was very recently a state-of-the-art model (GPT-4) can solve 77% of free-response problems in data structures and algorithms with little to no guidance. The latest model, GPT-4o, can solve around 46% of the Theory of Computation problems we posed, with predictable categories for which problems it could not solve. When broken down by topic, the model can solve 80% of problems in 4 out of the 15 topics and at least half in 8 other topics. Other problems, namely more visual problems, either require more substantial coaching or seem to still be beyond the capabilities of the language model--for now. By understanding the strengths and limitations of these models for solving theory problems, we can open the door to future work, ranging from human educational assessment on the topic to automated tutors for learners of the subject.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {659–665},
numpages = {7},
keywords = {algorithm design techniques, chatgpt, computational thinking, computer-assisted instruction, data structures, generative ai, gpt-4, gpt-4o, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3643795.3648375,
author = {Grandel, Skyler and Schmidt, Douglas C. and Leach, Kevin},
title = {Applying Large Language Models to Enhance the Assessment of Parallel Functional Programming Assignments},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648375},
doi = {10.1145/3643795.3648375},
abstract = {Courses in computer science (CS) often assess student programming assignments manually, with the intent of providing in-depth feedback to each student regarding correctness, style, efficiency, and other quality attributes. As class sizes increase, however, it is hard to provide detailed feedback consistently, especially when multiple assessors are required to handle a larger number of assignment submissions. Large language models (LLMs), such as ChatGPT, offer a promising alternative to help automate this process in a consistent, scalable, and minimally-biased manner.This paper explores ChatGPT-4's scalablility and accuracy in assessing programming assignments based on predefined rubrics in the context of a case study we conducted in an upper-level undergraduate and graduate CS course at Vanderbilt University. In this case study, we employed a method that compared assessments generated by ChatGPT-4 against human graders to measure the accuracy, precision, and recall associated with identifying programming mistakes. Our results show that when ChatGPT-4 is used properly (e.g., with appropriate prompt engineering and feature selection) it can improve objectivity and grading efficiency, thereby acting as a complementary tool to human graders for advanced computer science graduate and undergraduate students.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {102–110},
numpages = {9},
keywords = {ChatGPT, education, generative AI, large language models, prompt engineering, automated grading},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3641554.3701957,
author = {Basit, Nada and Floryan, Mark and Hott, John R. and Huo, Allen and Le, Jackson and Zheng, Ivan},
title = {ASCI: AI-Smart Classroom Initiative},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701957},
doi = {10.1145/3641554.3701957},
abstract = {The Artificial Intelligence Smart Classroom Initiative (ASCI) presents a re-imagined set of online course tools, designed primarily to support growing computer science classes. The system has four primary tools: an office hours queue, an automatic student grouping algorithm, a course-specific local large-language model (LLM), and administration tools for detecting students and TAs that need support. These tools interoperate to improve the quality of one another (e.g., LLM conversations support students directly in the office hours queue) and are enhanced by synchronizing data from multiple external sources such as Piazza, Gradescope, and Canvas. The system has been deployed in multiple courses over the past three semesters: initially as a FIFO queue, then supporting manual grouping and smart grouping of office hour attendees, and recently including LLM support. Preliminary results indicate that students who were grouped using the tool were more likely to return to the queue more than twice as often (on average) than those who were not. However, while grouping in office hours has the potential to decrease student wait times, teaching assistants and students tend to favor one-on-one meetings over group meetings. This might be improved in the future with updates to the software, TA training, and incorporation of other supporting tools (e.g., LLM technology). The other, newer, tools will be more thoroughly evaluated in future semesters.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {81–87},
numpages = {7},
keywords = {computer science education, cosine similarity, group formation, office hours},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3660767,
author = {Liang, Jenny T. and Badea, Carmen and Bird, Christian and DeLine, Robert and Ford, Denae and Forsgren, Nicole and Zimmermann, Thomas},
title = {Can GPT-4 Replicate Empirical Software Engineering Research?},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660767},
doi = {10.1145/3660767},
abstract = {Empirical software engineering research on production systems has brought forth a better understanding of the software engineering process for practitioners and researchers alike. However, only a small subset of production systems is studied, limiting the impact of this research. While software engineering practitioners could benefit from replicating research on their own data, this poses its own set of challenges, since performing replications requires a deep understanding of research methodologies and subtle nuances in software engineering data. Given that large language models (LLMs), such as GPT-4, show promise in tackling both software engineering- and science-related tasks, these models could help replicate and thus democratize empirical software engineering research.
 

 
In this paper, we examine GPT-4’s abilities to perform replications of empirical software engineering research on new data. We specifically study their ability to surface assumptions made in empirical software engineering research methodologies, as well as their ability to plan and generate code for analysis pipelines on seven empirical software engineering papers. We perform a user study with 14 participants with software engineering research expertise, who evaluate GPT-4-generated assumptions and analysis plans (i.e., a list of module specifications) from the papers. We find that GPT-4 is able to surface correct assumptions, but struggles to generate ones that apply common knowledge about software engineering data. In a manual analysis of the generated code, we find that the GPT-4-generated code contains correct high-level logic, given a subset of the methodology. However, the code contains many small implementation-level errors, reflecting a lack of software engineering knowledge. Our findings have implications for leveraging LLMs for software engineering research as well as practitioner data scientists in software teams.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {60},
numpages = {24},
keywords = {Large language models, empirical software engineering, study replication}
}

@inproceedings{10.1145/3723010.3723036,
author = {B\"{o}hm, Karsten},
title = {Towards a Semantic Representation of Framework Recommendations for Curricular Specifications in Higher Education},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723036},
doi = {10.1145/3723010.3723036},
abstract = {Curricular specifications play an important role in the Higher Education sector and the domain of Computer Science and Software Engineering is characterized by a wide range of education programs with a broad range of topic. Therefore, recommendation frameworks play an important role and their usage is beneficial for a unification of education profiles in a systematic way. This  research is contributing to this development by exploring how a recommendation for the domain of Business Informatics in German speaking countries can be improved by formalizing the recommendations in a semantic model that relies on sophisticated European ontologies in the domain like the European Learning Model (ELM) and related data models. It employs Generative Artificial Intelligence Systems to create semantic models in an experimental way and evaluates the resulting model quality. The results show that a formalization using GenAI has a high potential, but currently also shows deficits in the correctness of the resulting models, requiring human oversight during the model creation.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {154–160},
numpages = {7},
keywords = {Business Informatics, Competence Specification, European Learning Model, Higher Education, Learning Framework, Semantic Web},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3641555.3705235,
author = {Gonzalez, Elias and Chan, Joel and Weintrop, David},
title = {Quack! Configuring Large Language Models to Serve as Rubber Duck Coding Assistants},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705235},
doi = {10.1145/3641555.3705235},
abstract = {The emergence of Generative Artificial Intelligence (GenAI) tools broadly, and Large Language Models (LLMs) specifically, are equipping introductory programming instructors with a whole new class of pedagogical tools. While GenAI certainly poses threats to time-honored instructional techniques, it also provides opportunities for new forms of instructional support. In this work, we introduce our strategy for configuring an LLM to serve as a ''rubber duck debugging'' coding assistant to help novice programmers when they encounter difficulties in programming assignments. The key contribution of this work is not in the idea of using LLMs for debugging itself (which has already been demonstrated elsewhere, e.g., [3]) but to demonstrate the ease, flexibility, and pedagogical potential of the strategy. In particular, through carefully crafted prompts and easily accessible platforms, rubber duck LLMs can assist learners with specific questions while also situating those questions alongside larger computer science concepts and computational thinking practices. This work contributes an easily replicated and model-agnostic instructional strategy that productively and responsibly leverages the power of LLMs to assist novice programmers in developing foundational programming skills.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1463–1464},
numpages = {2},
keywords = {computer science education, generative ai, introductory programming, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3674805.3690744,
author = {Steinmacher, Igor and Penney, Jacob Mcauley and Felizardo, Katia Romero and Garcia, Alessandro F. and Gerosa, Marco A.},
title = {Can ChatGPT emulate humans in software engineering surveys?},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690744},
doi = {10.1145/3674805.3690744},
abstract = {Context: There is a growing belief in the literature that large language models (LLMs), such as ChatGPT, can mimic human behavior in surveys. Gap: While the literature has shown promising results in social sciences and market research, there is scant evidence of its effectiveness in technical fields like software engineering. Objective: Inspired by previous work, this paper explores ChatGPT’s ability to replicate findings from prior software engineering research. Given the frequent use of surveys in this field, if LLMs can accurately emulate human responses, this technique could address common methodological challenges like recruitment difficulties, representational shortcomings, and respondent fatigue. Method: We prompted ChatGPT to reflect the behavior of a ‘mega-persona’ representing the demographic distribution of interest. We replicated surveys from 2019 to 2023 from leading SE conferences, examining ChatGPT’s proficiency in mimicking responses from diverse demographics. Results: Our findings reveal that ChatGPT can successfully replicate the outcomes of some studies, but in others, the results were not significantly better than a random baseline. Conclusions: This paper reports our results so far and discusses the challenges and potential research opportunities in leveraging LLMs for representing humans in software engineering surveys.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {414–419},
numpages = {6},
keywords = {Generative AI, Mega-Personas, Replication Study, Survey},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3626253.3635356,
author = {AlOmar, Eman Abdullah and Mkaouer, Mohamed Wiem},
title = {How can We Leverage Static Analysis and Large Language Models to Engage Students in Software Quality Improvement},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635356},
doi = {10.1145/3626253.3635356},
abstract = {Static analysis tools are frequently used to scan the source code and detect deviations from the project coding guidelines. Yet, their adoption is challenged by their high false positive rate, which makes them not suitable for students and novice developers. However, Large Language Models (LLMs), such as ChatGPT, have gained widespread popularity and usage in various software engineering tasks, including testing, code review, and program comprehension. Such models represent an opportunity to reduce the ambiguity of static analysis tools and support their adoption. Yet, the effectiveness of using static analysis (i.e., PMD) to detect coding issues, and relying on LLMs (i.e., ChatGPT) to explain and recommend fix, has not yet been explored. In this talk, we aim to shed light on our experience in teaching the use of ChatGPT to cultivate a bugfix culture and leverage LLMs to improve software quality in educational settings. We share our findings to support educators in teaching students better code review strategies, and to increase students' awareness about LLM and promote software quality in education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1930},
numpages = {1},
keywords = {computing, education, large language models, quality},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3701625.3701687,
author = {Sampaio, Savio Sousa and Lima, M\'{a}rcia Sampaio and de Souza, Eriky Rodrigues and Meireles, Maria Alcimar and Pessoa, Marcela Savia and Conte, Tayana Uchoa},
title = {Exploring the Use of Large Language Models in Requirements Engineering Education: An Experience Report with ChatGPT 3.5},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701687},
doi = {10.1145/3701625.3701687},
abstract = {Large Language Models (LLMs) are becoming common in educational settings. This trend presents a challenge for teachers, who must focus on teaching the proper usage of LLMs. In the context of Software Engineering (SE), ChatGPT can support various software development tasks. This work reports an experience with students using ChatGPT 3.5 to support the Requirements Engineering (RE) phase. We conducted a two-phase study with 42 students. First, the students elicited requirements for systems using RE techniques. Then, the students used ChatGPT 3.5 to generate requirements for the same systems. Finally, they compared both sets of requirements based on equivalence, innovation, and relevance. On average, 65.26% of the requirements generated by ChatGPT were considered equivalents to the requirements the students had elicited. However, students reported that ChatGPT generates broad and non-specific requirements. Students also reported that ChatGPT 3.5 can foster the requirements elicitation, but it is necessary to establish well-defined prompts for generating requirements.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {624–634},
numpages = {11},
keywords = {Requirement Elicitation, ChatGPT 3.5, Software engineering education},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3641554.3701959,
author = {Wu, Ylesia and Zheng, Qirui and Lau, Sam},
title = {How Novices Use Program Visualizations to Understand Code that Manipulates Data Tables},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701959},
doi = {10.1145/3641554.3701959},
abstract = {As data science and artificial intelligence continue to impact society, more and more people are learning how to manipulate data with code. To support these learners, program visualization tools automatically generate diagrams to show how code transforms data, in contrast to tools based on large language models (LLMs) that primarily focus on textual explanations. Although program visualization tools are popular among instructors, do novices find these tools usable and useful for data science programs that often manipulate datasets with many rows? To address this, we evaluate a popular, publicly available tool that generates diagrams for Python pandas code through a randomized, in-lab usability study with 17 data science novices. Despite minimal instruction on how to use the tool, novices found that program visualizations increased their confidence in comprehending and debugging code. In addition, even though the tool sometimes produced diagrams with many visual elements, participant performance on the study tasks was not negatively impacted. These findings suggest design guidelines for program visualization tools to help manage cognitive load for data science novices. To our knowledge, this is the first empirical study that investigates how novices use program visualization tools to understand code that manipulates data tables, and suggests a future where novices can use automatically generated diagrams as a complement to LLM tools for effectively understanding unfamiliar programs in data science.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1267–1273},
numpages = {7},
keywords = {data science education, novice programmers, program visualization tools},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705183,
author = {Brockenbrough, Allan and Feild, Henry and Salinas, Dominic},
title = {Exploring LLMs Impact on Student-Created User Stories and Acceptance Testing in Software Development},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705183},
doi = {10.1145/3641555.3705183},
abstract = {In Agile software development methodology, a user story describes a new feature or functionality from an end user's perspective. The user story details may also incorporate acceptance testing criteria, which can be developed through negotiation with users. When creating stories from user feedback, the software engineer may maximize their usefulness by considering story attributes, including scope, independence, negotiability, and testability. This study investigates how LLMs (large language models), with guided instructions, affect undergraduate software engineering students' ability to transform user feedback into user stories. Students, working individually, were asked to analyze user feedback comments, appropriately group related items, and create user stories following the principles of INVEST, a framework for assessing user stories. We found that LLMs help students develop valuable stories with well-defined acceptance criteria. However, students tend to perform better without LLMs when creating user stories with an appropriate scope.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1401–1402},
numpages = {2},
keywords = {LLM, generative AI, large language model, user story},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3631504.3631518,
author = {Amer-Yahia, Sihem and Bonifati, Angela and Chen, Lei and Li, Guoliang and Shim, Kyuseok and Xu, Jianliang and Yang, Xiaochun},
title = {From Large Language Models to Databases and Back: A Discussion on Research and Education},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0163-5808},
url = {https://doi.org/10.1145/3631504.3631518},
doi = {10.1145/3631504.3631518},
abstract = {In recent years, large language models (LLMs) have garnered increasing attention from both academia and industry due to their potential to facilitate natural language processing (NLP) and generate highquality text. Despite their benefits, however, the use of LLMs is raising concerns about the reliability of knowledge extraction. The combination of DB research and data science has advanced the state of the art in solving real-world problems, such as merchandise recommendation and hazard prevention [30]. In this discussion, we explore the challenges and opportunities related to LLMs in DB and data science research and education.},
journal = {SIGMOD Rec.},
month = nov,
pages = {49–56},
numpages = {8}
}

@article{10.1145/3710795.3710797,
author = {Tran, Nicholas},
title = {The Book Review Column},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {4},
issn = {0163-5700},
url = {https://doi.org/10.1145/3710795.3710797},
doi = {10.1145/3710795.3710797},
abstract = {Foundation Mathematics for Computer Science: A Visual Approach, 4th edition (Springer, 2023) by John Vince (Bournemouth University, UK) is a comprehensive collection of discrete and continuous mathematical topics that are covered in most undergraduate programs in computer science. The subtitle refers to the author's use of colored graphs and tables to illustrate the concepts.Online Algorithms (Cambridge University Press, 2023) by Rahul Vaze (Tata Institute of Fundamental Research, India) is an accessible but rigorous introduction to the area aimed at advanced undergraduates and beginning graduate students. The book covers the basic as well as applied online problems with a preference of elegant analysis over performance.Privacy-preserving Computing for Big Data Analytics and AI (Cambridge University Press, 2023) by Kai Chen and Qiang Yang (Hong Kong University of Science and Technology) is a systematic examination of the history, theories, techniques, applications, and future of the field.Prize-winning neuroscientist Terrence Sejnowski (University of California at San Diego) explains the technology and mathematics behind large language models such as ChatGPT and explores the debate on their so-called comprehension of language in ChatGPT and the Future of AI: The Deep Language Revolution (The MIT Press, 2024).},
journal = {SIGACT News},
month = dec,
pages = {3–20},
numpages = {18}
}

@inproceedings{10.1145/3664476.3664497,
author = {Zhang, Xinyu and Muralee, Siddharth and Cherupattamoolayil, Sourag and Machiry, Aravind},
title = {On the Effectiveness of Large Language Models for GitHub Workflows},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3664497},
doi = {10.1145/3664476.3664497},
abstract = {GitHub workflows or GitHub CI is a popular continuous integration platform that enables developers to automate various software engineering tasks by specifying them as workflows,&nbsp;i.e., &nbsp;YAML files with a list of jobs. However, engineering valid workflows is tedious. They are also prone to severe security issues, which can result in supply chain vulnerabilities. Recent advancements in&nbsp;Large Language Models (LLMs) have demonstrated their effectiveness in various software development tasks. However,&nbsp;GitHub workflows differ from regular programs in both structure and semantics. We perform the first comprehensive study to understand the effectiveness of&nbsp;Large Language Models (LLMs) on five workflow-related tasks with different levels of prompts. We curated a set of ∼ 400K workflows and generated prompts with varying detail. We also fine-tuned&nbsp;LLMs on&nbsp;GitHub workflow tasks. Our evaluation of three state-of-the-art&nbsp;LLMs and their fine-tuned variants revealed various interesting findings on the current effectiveness and drawbacks of&nbsp;LLMs.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {32},
numpages = {14},
keywords = {GitHub Workflow, Large Language Model, Vulnerability Detection},
location = {Vienna, Austria},
series = {ARES '24}
}

@inproceedings{10.1145/3639478.3643060,
author = {H. Fard, Fatemeh},
title = {Technical Briefing on Parameter Efficient Fine-Tuning of (Large) Language Models for Code-Intelligence},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3643060},
doi = {10.1145/3639478.3643060},
abstract = {Large Language Models (LLMs) have gained much attention in the Software Engineering (SE) community, specifically for code-related tasks. Though a common approach is to fine-tune these models fully, it is a computationally heavy and time-consuming process that is not accessible to all. More importantly, with billions of parameters in the models, fully fine-tuning them for new tasks or domains is infeasible or inefficient. This technical briefing covers the alternative approach -Parameter Efficient Fine Tuning (PEFT), discussing the state-of-the-art techniques and reflecting on the few studies of using PEFT in Software Engineering and how changing the current PEFT architectures in natural language processing could enhance the performance for code-related tasks.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {434–435},
numpages = {2},
keywords = {parameter efficient fine tuning, code language models, large language models},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3626252.3630826,
author = {Hoq, Muntasir and Shi, Yang and Leinonen, Juho and Babalola, Damilola and Lynch, Collin and Price, Thomas and Akram, Bita},
title = {Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630826},
doi = {10.1145/3626252.3630826},
abstract = {The emergence of publicly accessible large language models (LLMs) such as ChatGPT poses unprecedented risks of new types of plagiarism and cheating where students use LLMs to solve exercises for them. Detecting this behavior will be a necessary component in introductory computer science (CS1) courses, and educators should be well-equipped with detection tools when the need arises. However, ChatGPT generates code non-deterministically, and thus, traditional similarity detectors might not suffice to detect AI-created code. In this work, we explore the affordances of Machine Learning (ML) models for the detection task. We used an openly available dataset of student programs for CS1 assignments and had ChatGPT generate code for the same assignments, and then evaluated the performance of both traditional machine learning models and Abstract Syntax Tree-based (AST-based) deep learning models in detecting ChatGPT code from student code submissions. Our results suggest that both traditional machine learning models and AST-based deep learning models are effective in identifying ChatGPT-generated code with accuracy above 90%. Since the deployment of such models requires ML knowledge and resources that are not always accessible to instructors, we also explore the patterns detected by deep learning models that indicate possible ChatGPT code signatures, which instructors could possibly use to detect LLM-based cheating manually. We also explore whether explicitly asking ChatGPT to impersonate a novice programmer affects the code produced. We further discuss the potential applications of our proposed models for enhancing introductory computer science instruction.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {526–532},
numpages = {7},
keywords = {artificial intelligence, chatgpt, cheat detection, cs1, introductory programming course, large language model, plagiarism detection},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630960,
author = {Nguyen, Ha and Allan, Vicki},
title = {Using GPT-4 to Provide Tiered, Formative Code Feedback},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630960},
doi = {10.1145/3626252.3630960},
abstract = {Large language models (LLMs) have shown promise in generating sensible code explanation and feedback in programming exercises. In this experience report, we discuss the process of using one of these models (OpenAI's GPT-4) to generate individualized feedback for students' Java code and pseudocode. We instructed GPT-4 to generate feedback for 113 submissions to four programming problems in an Algorithms and Data Structures class. We prompted the model with example feedback (few-shot learning) and instruction to (1) give feedback on conceptual understanding, syntax, and time complexity, and (2) suggest follow-up actions based on students' code or provide guiding questions. Overall, GPT-4 provided accurate feedback and successfully built on students' ideas in most submissions. Human evaluators (computer science instructors and tutors) rated GPT-4's hints as useful in guiding students' next steps. Model performance varied with programming problems but not submission quality. We reflect on where the model performed well and fell short, and discuss the potential of integrating LLM-generated, individualized feedback into computer science instruction.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {958–964},
numpages = {7},
keywords = {computer science education, feedback, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3708519,
author = {Lyu, Michael R. and Ray, Baishakhi and Roychoudhury, Abhik and Tan, Shin Hwei and Thongtanunam, Patanamon},
title = {Automatic Programming: Large Language Models and Beyond},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708519},
doi = {10.1145/3708519},
abstract = {Automatic programming has seen increasing popularity due to the emergence of tools like GitHub Copilot which rely on Large Language Models (LLMs). At the same time, automatically generated code faces challenges during deployment due to concerns around quality and trust. In this article, we study automated coding in a general sense and study the concerns around code quality, security, and related issues of programmer responsibility. These are key issues for organizations while deciding on the usage of automatically generated code. We discuss how advances in software engineering such as program repair and analysis can enable automatic programming. We conclude with a forward looking view, focusing on the programming environment of the near future, where programmers may need to switch to different roles to fully utilize the power of automatic programming. Automated repair of automatically generated programs from LLMs can help produce higher assurance code from LLMs, along with evidence of assurance.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {140},
numpages = {33},
keywords = {AI-based coding, Automated Program Repair, Trustworthy Software}
}

@inproceedings{10.1145/3649165.3690101,
author = {Hellas, Arto and Leinonen, Juho and Lepp\"{a}nen, Leo},
title = {Experiences from Integrating Large Language Model Chatbots into the Classroom},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690101},
doi = {10.1145/3649165.3690101},
abstract = {We provided students access to a state-of-the-art large language model (LLM) chatbot through the online materials of three university-level courses. One of the courses focused on software engineering with LLMs, while the two other courses were not directly related to LLMs. The chatbot used OpenAI GPT-4 without additional filters or system prompts.  Our results suggest that only a minority of students engage with the chatbot in the courses that do not relate to LLMs. At the same time, unsurprisingly, nearly all students in the LLM-focused course leveraged the chatbot. In all courses, the majority of the chatbot usage came from a few superusers, whereas the majority of the students did not heavily use the chatbot even though it effectively provided free access to OpenAI's GPT-4 model (which would have otherwise required a paid subscription at the time of the study). We observe that in addition to students using the chatbot for course-specific purposes, many use the chatbot for their own purposes.  Overall, our results suggest that the worst fears of educators -- all students overrelying on chatbots -- did not materialize. Finally, we discuss potential reasons for low usage, including the need for more tailored and scaffolded chatbot experiences targeted for specific types of use cases.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {46–52},
numpages = {7},
keywords = {chatbots, classroom experiences, experience report, generative ai, large language models, usage analysis},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1109/SCW63240.2024.00017,
author = {Herron, Emily and Yin, Junqi and Wang, Feiyi},
title = {SciTrust: Evaluating the Trustworthiness of Large Language Models for Science},
year = {2025},
isbn = {9798350355543},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SCW63240.2024.00017},
doi = {10.1109/SCW63240.2024.00017},
abstract = {This work presents SciTrust, a comprehensive framework for assessing the trustworthiness of large language models (LLMs) in scientific contexts, with a focus on truthfulness, accuracy, hallucination, and sycophancy. The framework introduces four novel open-ended benchmarks in Computer Science, Chemistry, Biology, and Physics, and employs a multi-faceted evaluation approach combining traditional metrics with LLM-based evaluation. SciTrust was applied to five LLMs, including one general-purpose and four scientific models, revealing nuanced strengths and weaknesses across different models and benchmarks. The study also evaluated SciTrust's performance and scalability on high-performance computing systems. Results showed varying performance across models, with Llama3-70B-Instruct performing strongly overall, while Galactica-120B and SciGLM-6B excelled among scientific models. SciTrust aims to advance the development of trustworthy AI in scientific applications and establish a foundation for future research on model robustness, safety, and ethics in scientific contexts. We have open-sourced our framework, including all associated scripts and datasets, at https://github.com/herronej/SciTrust.},
booktitle = {Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {72–78},
numpages = {7},
keywords = {High Performance Computing, Large Language Models for Science, Trustworthy AI},
location = {Atlanta, GA, USA},
series = {SC-W '24}
}

@inproceedings{10.1145/3626252.3630928,
author = {Poulsen, Seth and Sarsa, Sami and Prather, James and Leinonen, Juho and Becker, Brett A. and Hellas, Arto and Denny, Paul and Reeves, Brent N.},
title = {Solving Proof Block Problems Using Large Language Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630928},
doi = {10.1145/3626252.3630928},
abstract = {Large language models (LLMs) have recently taken many fields, including computer science, by storm. Most recent work on LLMs in computing education has shown that they are capable of solving most introductory programming (CS1) exercises, exam questions, Parsons problems, and several other types of exercises and questions. Some work has investigated the ability of LLMs to solve CS2 problems as well. However, it remains unclear how well LLMs fare against more advanced upper-division coursework, such as proofs in algorithms courses. After all, while known to be proficient in many programming tasks, LLMs have been shown to have more difficulties in forming mathematical proofs.In this paper, we investigate the ability of LLMs to solve mathematical proofs by using Proof Blocks, a tool previously shown to efficaciously teach proofs to students. Our results show that GPT-3.5 is almost completely unable to provide correct solutions (11.4%), while GPT-4 shows a significant increase in correctness (64.8%). However, even given this improvement, current models still struggle to correctly order lines in a proof. It remains an open question whether this is a temporary situation or if LLMs will continue to struggle to solve these types of exercises in the future.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1063–1069},
numpages = {7},
keywords = {ai, algorithms, artificial intelligence, chatgpt, code generation, generative ai, gpt-3, gpt-4, large language models, openai, proof blocks, proofs},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3690931.3690982,
author = {Zhang, Ye and Nie, Yiming},
title = {InternDrive: A Multimodal Large Language Model for Autonomous Driving Scenario Understanding},
year = {2024},
isbn = {9798400710049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690931.3690982},
doi = {10.1145/3690931.3690982},
abstract = {With the rapid development of autonomous driving technology, accurately understanding complex driving scenarios has become a critical challenge. Existing computer vision-based solutions exhibit limitations when dealing with dynamic driving environments. Therefore, this paper proposes a method for understanding autonomous driving scenarios using multimodal large language models. Firstly, we designed a set of questions to guide multimodal large language models in comprehensively understanding driving scenarios, and based on this, we constructed a multimodal driving scenario dataset. This dataset combines open-source nuScenes image data with natural language annotations automatically generated and manually reviewed via the OpenAI API. Subsequently, we conducted visual instruction tuning on the open-source multimodal large language model InternVL-1.5 and proposed the InternDrive model. Furthermore, this paper introduces an evaluation method based on a proprietary large model and conducts a comprehensive assessment of InternDrive's ability to understand driving scenarios. Experimental results demonstrate that InternDrive exhibits superior accuracy in multiple driving scenario understanding tasks. Our research provides new methods and perspectives for enhancing the scene understanding capabilities of autonomous driving systems and showcases the potential application of multimodal large language models in the field of autonomous driving.},
booktitle = {Proceedings of the 2024 4th International Conference on Artificial Intelligence, Automation and High Performance Computing},
pages = {294–305},
numpages = {12},
location = {Zhuhai, China},
series = {AIAHPC '24}
}

@article{10.1145/3705300,
author = {Xu, Xiaodan and Ni, Chao and Guo, Xinrong and Liu, Shaoxuan and Wang, Xiaoya and Liu, Kui and Yang, Xiaohu},
title = {Distinguishing LLM-Generated from Human-Written Code by Contrastive Learning},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3705300},
doi = {10.1145/3705300},
abstract = {Large language models (LLMs), such as ChatGPT released by OpenAI, have attracted significant attention from both industry and academia due to their demonstrated ability to generate high-quality content for various tasks. Despite the impressive capabilities of LLMs, there are growing concerns regarding their potential risks in various fields, such as news, education, and software engineering. Recently, several commercial and open source LLM-generated content detectors have been proposed, which, however, are primarily designed for detecting natural language content without considering the specific characteristics of program code. This article aims to fill this gap by proposing a novel ChatGPT-generated code detector, CodeGPTSensor, based on a contrastive learning framework and a semantic encoder built with UniXcoder. To assess the effectiveness of CodeGPTSensor on differentiating ChatGPT-generated code from human-written code, we first curate a large-scale Human and Machine comparison Corpus (HMCorp), which includes 550k pairs of human-written and ChatGPT-generated code (i.e., 288k Python code pairs and 222k Java code pairs). Based on the HMCorp dataset, our qualitative and quantitative analysis of the characteristics of ChatGPT-generated code reveals the challenge and opportunity of distinguishing ChatGPT-generated code from human-written code with their representative features. Our experimental results indicate that CodeGPTSensor can effectively identify ChatGPT-generated code, outperforming all selected baselines.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {91},
numpages = {31},
keywords = {Large Language Model, ChatGPT, AI-generated Code Detection, Contrastive Learning}
}

@article{10.1145/3708522,
author = {Zhou, Xin and Cao, Sicong and Sun, Xiaobing and Lo, David},
title = {Large Language Model for Vulnerability Detection and Repair: Literature Review and the Road Ahead},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708522},
doi = {10.1145/3708522},
abstract = {The significant advancements in Large Language Models (LLMs) have resulted in their widespread adoption across various tasks within Software Engineering (SE), including vulnerability detection and repair. Numerous studies have investigated the application of LLMs to enhance vulnerability detection and repair tasks. Despite the increasing research interest, there is currently no existing survey that focuses on the utilization of LLMs for vulnerability detection and repair. In this paper, we aim to bridge this gap by offering a systematic literature review of approaches aimed at improving vulnerability detection and repair through the utilization of LLMs. The review encompasses research work from leading SE, AI, and Security conferences and journals, encompassing 43 papers published across 25 distinct venues, along with 15 high-quality preprint papers, bringing the total to 58 papers. By answering three key research questions, we aim to (1) summarize the LLMs employed in the relevant literature, (2) categorize various LLM adaptation techniques in vulnerability detection, and (3) classify various LLM adaptation techniques in vulnerability repair. Based on our findings, we have identified a series of limitations of existing studies. Additionally, we have outlined a roadmap highlighting potential opportunities that we believe are pertinent and crucial for future research endeavors.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {145},
numpages = {31},
keywords = {Literature review, vulnerability detection, vulnerability repair, large language models}
}

@article{10.1145/3715112,
author = {Betz, Stefanie and Penzenstadler, Birgit},
title = {With Great Power Comes Great Responsibility: The Role of Software Engineers},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715112},
doi = {10.1145/3715112},
abstract = {The landscape of Software Engineering evolves rapidly amidst digital transformation and the ascendancy of AI, leading to profound shifts in the role and responsibilities of Software Engineers. This evolution encompasses both immediate changes, such as the adoption of Large Language Model-based approaches to coding, and deeper shifts driven by the profound societal and environmental impacts of technology. Despite the urgency, there persists a lag in adapting to these evolving roles. This roadmap article proposes 10 research challenges to develop a new generation of Software Engineers equipped to navigate the technical and social complexities as well as ethical considerations inherent in their evolving profession. Furthermore, the challenges target role definition, integration of AI, education transformation, standards evolution, and impact assessment to equip future Software Engineers to skillfully and responsibly handle the obstacles within their transforming discipline.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {136},
numpages = {21},
keywords = {Sustainability, Responsibility, Roles, Ethics}
}

@inproceedings{10.1145/3661167.3661222,
author = {Mbaka, Winnie Bahati},
title = {New experimental design to capture bias using LLM to validate security threats},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661222},
doi = {10.1145/3661167.3661222},
abstract = {The usage of Large Language Models is already well understood in software engineering and security and privacy. Yet, little is known about the effectiveness of LLMs in threat validation or the possibility of biased output when assessing security threats for correctness. To mitigate this research gap, we present a pilot study investigating the effectiveness of chatGPT in the validation of security threats. One main observation made from the results was that chatGPT assessed bogus threats as realistic regardless of the assumptions provided which negated the feasibility of certain threats occurring.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {458–459},
numpages = {2},
keywords = {ChatGPT, Large Language Models, Security Threat Validation},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3663529.3663818,
author = {Jaccheri, Letizia and Duc, Anh Nguyen},
title = {Software Engineering and Gender: A Tutorial},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663818},
doi = {10.1145/3663529.3663818},
abstract = {Software runs the world and should provide equal rights and opportunities to all genders. However, the gender gap exists in the software engineering workforce and many software products are still gender biased. Recently, AI systems, including modern large language models are shown to be related to gender bias issues. Many efforts have been devoted to understanding the problem and investigating solutions. The tutorial aims to present a set of scientific studies based on qualitative and quantitative research methods. The authors have a long record of research leadership in interdisciplinary projects with a focus on gender and software engineering. The issues with team diversity in software development and AI engineering will be presented to highlight the importance of fostering inclusive and diverse software development teams.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {704–706},
numpages = {3},
keywords = {Software engineering, bias, gender, research methods},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3680533.3697064,
author = {Feng, Tony Haoran and Denny, Paul and W\"{u}nsche, Burkhard C. and Luxton-Reilly, Andrew and Whalley, Jacqueline},
title = {An Eye for an AI: Evaluating GPT-4o's Visual Perception Skills and Geometric Reasoning Skills Using Computer Graphics Questions},
year = {2024},
isbn = {9798400711367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680533.3697064},
doi = {10.1145/3680533.3697064},
abstract = {CG (Computer Graphics) is a popular field of CS (Computer Science), but many students find this topic difficult due to it requiring a large number of skills, such as mathematics, programming, geometric reasoning, and creativity. Over the past few years, researchers have investigated ways to harness the power of GenAI (Generative Artificial Intelligence) to improve teaching. In CS, much of the research has focused on introductory computing. A recent study evaluating the performance of an LLM (Large Language Model), GPT-4 (text-only), on CG questions, indicated poor performance and reliance on detailed descriptions of image content, which often required considerable insight from the user to return reasonable results. So far, no studies have investigated the abilities of LMMs (Large Multimodal Models), or multimodal LLMs, to solve CG questions and how these abilities can be used to improve teaching.In this study, we construct two datasets of CG questions requiring varying degrees of visual perception skills and geometric reasoning skills, and evaluate the current state-of-the-art LMM, GPT-4o, on the two datasets. We find that although GPT-4o exhibits great potential in solving questions with visual information independently, major limitations still exist to the accuracy and quality of the generated results. We propose several novel approaches for CG educators to incorporate GenAI into CG teaching despite these limitations. We hope that our guidelines further encourage learning and engagement in CG classrooms.},
booktitle = {SIGGRAPH Asia 2024 Educator's Forum},
articleno = {5},
numpages = {8},
keywords = {Large Language Models, LLMs, Large Multimodal Models, LMMs, Visual Language Models, VLMs, Generative Artificial Intelligence, GenAI, GPT-4, GPT-4o, Visual Perception, Geometric Reasoning, Computer Graphics, Computing Education, Evaluation, Assessment},
location = {
},
series = {SA '24}
}

@article{10.5555/3636517.3636522,
author = {Crandall, Aaron S. and Sprint, Gina and Fischer, Bryan},
title = {Generative Pre-Trained Transformer (GPT) Models as a Code Review Feedback Tool in Computer Science Programs},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {1},
issn = {1937-4771},
abstract = {Undergraduate computer science and software engineering students benefit significantly from in-depth reviews of their code early and often in their courses. Performing these reviews is time-consuming for teaching assistants and professors to complete, consequently impacting the timeliness and consistency of the provided feedback. When code feedback is not delivered close to the time of authorship, the utility of the review for students is diminished. Prior work with Automatic Static Analysis Tools has shown promise at using artificial intelligence to automate code reviews, with some success integrating them into classroom environments. To leverage new advances in Generative Pre-Trained Transformer (GPT) models, this work reports on an Automatic Review Tool (ART) to provide timely, automatically generated code reviews. ART was evaluated in a second-semester computer science course by integrating ART into the course's Github-based assignment submission system. A cohort of student volunteers (N = 74) read the ART reviews and provided feedback using a survey spanning two of their course assignments. The results of this pilot study show that students perceived ART was successful at detecting defects and offering style-based suggestions, and students were receptive to receiving future automated reviews of their work.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {38–47},
numpages = {10}
}

@article{10.1145/3643758,
author = {Wang, Wei and Ning, Huilong and Zhang, Gaowei and Liu, Libo and Wang, Yi},
title = {Rocks Coding, Not Development: A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643758},
doi = {10.1145/3643758},
abstract = {Recently, large language models (LLM) based generative AI has been gaining momentum for their impressive high-quality performances in multiple domains, particularly after the release of the ChatGPT. Many believe that they have the potential to perform general-purpose problem-solving in software development and replace human software developers. Nevertheless, there are in a lack of serious investigation into the capability of these LLM techniques in fulfilling software development tasks. In a controlled 2 \texttimes{} 2 between-subject experiment with 109 participants, we examined whether and to what degree working with ChatGPT was helpful in the coding task and typical software development task and how people work with ChatGPT. We found that while ChatGPT performed well in solving simple coding problems, its performance in supporting typical software development tasks was not that good. We also observed the interactions between participants and ChatGPT and found the relations between the interactions and the outcomes. Our study thus provides first-hand insights into using ChatGPT to fulfill software engineering tasks with real-world developers and motivates the need for novel interaction mechanisms that help developers effectively work with large language models to achieve desired outcomes.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {32},
numpages = {23},
keywords = {controlled experiment, human-AI collaboration, large langauge models, software development task}
}

@article{10.1145/3672089.3672101,
author = {Arnedo-Moreno, Joan and Cooper, Kendra M. L. and Lin, Dayi},
title = {Emerging Advanced Technologies for Game Engineering},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/3672089.3672101},
doi = {10.1145/3672089.3672101},
abstract = {In this paper, the outcomes of the 8th International Workshop on Games and Software Engineering (GAS 2024)1 are reported. The one-day workshop has been held as part of the 46th International Conference on Software Engineering (ICSE 2024) in Lisbon, Portugal on April 14, 2024. The workshop programme includes two exciting keynotes discussing topics related to harnessing video game simulations to generate content and locate bugs, and the experience of maintaining a popular FOSS library, raylib. There are three research paper sessions. The first relates to automation in game engineering; the second explores testing and quality assurance; and the third discusses specification and quality of service. The conclusion of the workshop is anchored by a panel of four researchers, educators, and practitioners discussing the current strengths and limitations of large language models in game engineering.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jul,
pages = {37–41},
numpages = {5}
}

@inproceedings{10.1145/3691620.3695336,
author = {Cinkusz, Konrad and Chudziak, Jaroslaw A.},
title = {Towards LLM-augmented multiagent systems for agile software engineering},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695336},
doi = {10.1145/3691620.3695336},
abstract = {A cognitive multi-agent ecosystem designed for efficient software engineering using Agile methodologies can significantly improve software development processes. Key components include the integration of Multi-Agent Systems (MAS) and Large Language Models (LLMs), utilizing Dynamic Context techniques for agent profiling, and Theory of Mind to enhance collaboration. The CogniSim Ecosystem analyzes problems, proposes solutions, constructs and validates plans, and coordinates specialized agents playing roles such as developers, executors, quality checkers, and methodology reviewers. These agents produce documentation, models, and diagrams (e.g., UML) while adhering to predefined quality and performance measures. The ecosystem also simulates the impact of various team configurations on problem-solving effectiveness, helping organizations identify optimal team structures. Case studies and simulations demonstrate its practical applications.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2476–2477},
numpages = {2},
keywords = {multi-agent systems, large language models, software engineering, collaboration automation, methodologies, SAFe, cognisim},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@article{10.1145/3715007,
author = {Chen, Xiang and Gao, Chaoyang and Chen, Chunyang and Zhang, Guangbei and Liu, Yong},
title = {An Empirical Study on Challenges for LLM Application Developers},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715007},
doi = {10.1145/3715007},
abstract = {In recent years, large language models (LLMs) have seen rapid advancements, significantly impacting various fields such as computer vision, natural language processing, and software engineering. These LLMs, exemplified by OpenAI’s ChatGPT, have revolutionized the way we approach language understanding and generation tasks. However, in contrast to traditional software development practices, LLM development introduces new challenges for AI developers in design, implementation, and deployment. These challenges span different areas (such as prompts, APIs, and plugins), requiring developers to navigate unique methodologies and considerations specific to LLM application development.Despite the profound influence of LLMs, to the best of our knowledge, these challenges have not been thoroughly investigated in previous empirical studies. To fill this gap, we present the first comprehensive study on understanding the challenges faced by LLM developers. Specifically, we crawl and analyze 29,057 relevant questions from a popular OpenAI developer forum. We first examine their popularity and difficulty. After manually analyzing 2,364 sampled questions, we construct a taxonomy of challenges faced by LLM developers. Based on this taxonomy, we summarize a set of findings and actionable implications for LLM-related stakeholders, including developers and providers (especially the OpenAI organization).},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {Mining Software Repository, Empirical Study, LLM Developer, Development Challenges, Prompt Engineering}
}

@inproceedings{10.1145/3626252.3630817,
author = {Fernandez, Amanda S. and Cornell, Kimberly A.},
title = {CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630817},
doi = {10.1145/3626252.3630817},
abstract = {As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create "black box" code with significant security vulnerabilities. We outline methods for integrating basic AI knowledge and traditional software verification steps into CS1 along with LLMs, which will better prepare students for software development in professional settings.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {345–351},
numpages = {7},
keywords = {ai, artificial intelligence, code generation, copilot, cs1, gpt-4, introductory programming, large language model, llm, machine learning, novice programmers, programming, prompt engineering, secure code, software verification},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3636243.3636263,
author = {Feng, Tony Haoran and Denny, Paul and Wuensche, Burkhard and Luxton-Reilly, Andrew and Hooper, Steffan},
title = {More Than Meets the AI: Evaluating the performance of GPT-4 on Computer Graphics assessment questions},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636263},
doi = {10.1145/3636243.3636263},
abstract = {Recent studies have showcased the exceptional performance of LLMs (Large Language Models) on assessment questions across various discipline areas. This can be helpful if used to support the learning process, for example by enabling students to quickly generate and contrast alternative solution approaches. However, concerns about student over-reliance and inappropriate use of LLMs in education are common. Understanding the capabilities of LLMs is essential for instructors to make informed decisions on question choices for learning and assessment tasks. In CS (Computer Science), previous evaluations of LLMs have focused on CS1 and CS2 questions, and little is known about how well LLMs perform for assessment questions in upper-level CS courses such as CG (Computer Graphics), which covers a wide variety of concepts and question types. To address this gap, we compiled a dataset of past assessment questions used in a final-year undergraduate course about introductory CG, and evaluated the performance of GPT-4 on this dataset. We also classified assessment questions and evaluated the performance of GPT-4 for different types of questions. We found that the performance tended to be best for simple mathematical questions, and worst for questions requiring creative thinking, and those with complex descriptions and/or images. We share our benchmark dataset with the community and provide new insights into the capabilities of GPT-4 in the context of CG courses. We highlight opportunities for teaching staff to improve student learning by guiding the use of LLMs for CG questions, and inform decisions around question choices for assessment tasks.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {182–191},
numpages = {10},
keywords = {Artificial Intelligence, Assessment, Computer Graphics, Computing Education, Evaluation, GPT-4, Large Language Models},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@article{10.1145/3735636,
author = {Yang, Guang and Zhou, Yu and Cheng, Wei and Zhang, Xiangyu and Chen, Xiang and Zhuo, Terry Yue and Liu, Ke and Zhou, Xin and Lo, David and Chen, Taolue},
title = {Less is More: DocString Compression in Code Generation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3735636},
doi = {10.1145/3735636},
abstract = {The widespread use of Large Language Models (LLMs) in software engineering has intensified the need for improved model and resource efficiency. In particular, for neural code generation, LLMs are used to translate function/method signature and DocString to executable code. DocStrings, which capture user requirements for the code and are typically used as the prompt for LLMs, often contain redundant information. Recent advancements in prompt compression have shown promising results in Natural Language Processing (NLP), but their applicability to code generation remains uncertain. Our empirical study show that the state-of-the-art prompt compression methods achieve only about 10% reduction, as further reductions would cause significant performance degradation. In our study, we propose a novel compression method, ShortenDoc, dedicated to DocString compression for code generation. Our experiments on six code generation datasets, five open-source LLMs (1B to 10B parameters) and one closed-source LLM GPT-4o confirm that ShortenDoc achieves 25–40% compression while preserving the quality of generated code, outperforming other baseline methods at similar compression levels. The benefit of this method is to improve efficiency and reduce the token processing cost while maintaining the quality of the generated code, especially when calling third-party APIs.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {DocString Compression, Code Generation, Large Language Model}
}

@inproceedings{10.1145/3652037.3663956,
author = {Roy, Ayon and Karim, Enamul and Bin Farukee, Minhaz and Makedon, Fillia},
title = {ChatGPT as an Assistive Technology: Enhancing Human-Computer Interaction for People with Speech Impairments},
year = {2024},
isbn = {9798400717604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652037.3663956},
doi = {10.1145/3652037.3663956},
abstract = {Communication challenges faced by individuals with speech impairments present a unique set of difficulties, often hindering effective interaction. This research paper centers on addressing these challenges by employing ChatGPT, a sophisticated large language model (LLM) developed by OpenAI, within the framework of Human-Computer Interaction (HCI). The study investigates the intricate landscape of speech impairments, emphasizing the inherent complexities in vocal expression. Our work highlights the pivotal role of ChatGPT in offering a tailored and adaptable communication solution.The paper highlights the contributions to HCI principles and assistive technologies, showcasing the innovative integration of ChatGPT. Emphasizing interdisciplinary collaboration, the study positions itself at the forefront of leveraging large language models to provide a comprehensive theoretical framework tailored to the unique needs of individuals with speech impairments.},
booktitle = {Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {63–66},
numpages = {4},
keywords = {AI, Assistive Technologies, ChatGPT, HCI, Large Language Models, Speech Impairments},
location = {Crete, Greece},
series = {PETRA '24}
}

@inproceedings{10.1145/3626253.3635403,
author = {Li, Yi and Zhang, Riteng and Qu, Danni and Marques Samary, Ma\'{\i}ra},
title = {Mining Students' Mastery Levels from CS Placement Tests via LLMs},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635403},
doi = {10.1145/3626253.3635403},
abstract = {In higher education, introductory Computer Science (CS) programs offer a range of foundational courses. These encompass not only the standard CS1 and CS2 courses but may also include more specialized options like CS0 and CS1.5. In order to appropriately assign students to the suitable introductory courses, many institutions utilize placement tests, which assess students' pre-existing knowledge and skills. While most institutions rely on accuracy alone to make these determinations, there is often additional information concealed within the completed tests. This paper delves into the potential of Large Language Models (LLMs) to uncover this hidden information, particularly in gaining insights into how students perform in different concepts. Moreover, our framework has the flexibility to accommodate variations in curricula across different institutions, providing additional analytical perspectives. Initially, we built a concept inventory (CI) using the concepts covered in an institution's CS0, CS1, and CS2 curricula. Next, an LLM, specifically GPT 3.5, was applied to associate each question in the placement test with one or more concepts in the CI. Finally, the results of the placement tests were scrutinized, allowing the calculation of mastery levels in each concept for individual students. These mastery levels enable institutions to gauge a student's prior knowledge across various concepts simply by using a CS placement test. Additionally, we presented a case study demonstrating the application of this framework to 267 existing placement test results at Boston College.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1883},
numpages = {1},
keywords = {concept inventory, introductory computer science courses, large language models, placement test},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3632620.3671103,
author = {Logacheva, Evanfiya and Hellas, Arto and Prather, James and Sarsa, Sami and Leinonen, Juho},
title = {Evaluating Contextually Personalized Programming Exercises Created with Generative AI},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671103},
doi = {10.1145/3632620.3671103},
abstract = {Programming skills are typically developed through completing various hands-on exercises. Such programming problems can be contextualized to students’ interests and cultural backgrounds. Prior research in educational psychology has demonstrated that context personalization of exercises stimulates learners’ situational interests and positively affects their engagement. However, creating a varied and comprehensive set of programming exercises for students to practice on is a time-consuming and laborious task for computer science educators. Previous studies have shown that large language models can generate conceptually and contextually relevant programming exercises. Thus, they offer a possibility to automatically produce personalized programming problems to fit students’ interests and needs. This article reports on a user study conducted in an elective introductory programming course that included contextually personalized programming exercises created with GPT-4. The quality of the exercises was evaluated by both the students and the authors. Additionally, this work investigated student attitudes towards the created exercises and their engagement with the system. The results demonstrate that the quality of exercises generated with GPT-4 was generally high. What is more, the course participants found them engaging and useful. This suggests that AI-generated programming problems can be a worthwhile addition to introductory programming courses, as they provide students with a practically unlimited pool of practice material tailored to their personal interests and educational needs.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {95–113},
numpages = {19},
keywords = {automatic exercise generation, context personalization, generative AI, large language models},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3701716.3717819,
author = {Jia, Runsong and Zhang, Bowen and M\'{e}ndez, Sergio Jos\'{e} Rodr\'{\i}guez and Omran, Pouya G.},
title = {StructRAG: Structure-Aware RAG Framework with Scholarly Knowledge Graph for Diverse Question Answering},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717819},
doi = {10.1145/3701716.3717819},
abstract = {Recent advances in Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) have shown promise in academic question answering. However, existing approaches often fail to fully utilize document structural information and lack diversity in retrieved contexts. This paper presents StructRAG, a structure-aware RAG framework that leverages scholarly knowledge graphs for enhanced question answering. Our framework features three key innovations: (1) an automated knowledge graph construction pipeline based on Deep Document Model (DDM) that preserves document hierarchical structure, (2) a structure-aware retrieval mechanism that combines semantic relevance with source diversity, and (3) a context-enhanced generation approach that integrates structural metadata for improved answer synthesis. Experimental results on 329 computer science papers demonstrate that StructRAG significantly outperforms vanilla RAG baseline. While maintaining comparable semantic accuracy (91% vs 90%), our approach achieves substantially higher diversity in generated answers (Distinct-1: 62% vs 52%, Distinct-2: 89% vs 78%) and better answer quality across all metrics, with notable improvements in relevance (29%) and readability (36.5%). These results demonstrate that StructRAG effectively enhances both the diversity and quality of academic question answering.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2567–2573},
numpages = {7},
keywords = {deep document model, knowledge graph, knowledge graph construction, large language models, retrieval-augmented generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3545947.3573358,
author = {MacNeil, Stephen and Kim, Joanne and Leinonen, Juho and Denny, Paul and Bernstein, Seth and Becker, Brett A. and Wermelinger, Michel and Hellas, Arto and Tran, Andrew and Sarsa, Sami and Prather, James and Kumar, Viraj},
title = {The Implications of Large Language Models for CS Teachers and Students},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3573358},
doi = {10.1145/3545947.3573358},
abstract = {The introduction of Large Language Models (LLMs) has generated a significant amount of excitement both in industry and among researchers. Recently, tools that leverage LLMs have made their way into the classroom where they help students generate code and help instructors generate learning materials. There are likely many more uses of these tools -- both beneficial to learning and possibly detrimental to learning. To help ensure that these tools are used to enhance learning, educators need to not only be familiar with these tools, but with their use and potential misuse. The goal of this BoF is to raise awareness about LLMs and to build a learning community around their use in computing education. Aligned with this goal of building an inclusive learning community, our BoF is led by globally distributed discussion leaders, including undergraduate researchers, to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of LLMs in CS education.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1255},
numpages = {1},
keywords = {artificial intelligence, code explanations, code generation, computer science education, copilot, gpt-3, large language models},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3717383.3721236,
author = {Rathore, Santosh Singh and Tiwari, Saurabh and Farooq, Sheikh Umar},
title = {Seventh Workshop on Emerging Software Engineering Education(WESEE 2025)},
year = {2025},
isbn = {9798400714245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3717383.3721236},
doi = {10.1145/3717383.3721236},
abstract = {The seventh Workshop on Emerging Software Engineering Education (WESEE) aims to discuss and examine the development of learning environments that are influencing the pedagogical strategies for the education of software engineering courses in institutions, specifically through the adoption of Generative AI (GenAI) tools and techniques. Additionally, the workshop aims to examine how industries are utilizing GenAI tools and technologies for teaching software development methods and how the developers are utilizing the material for self-learning and skill acquisition. The report is an overview of the upcoming seventh edition of WESEE, which will be held on 20th February 2025 at NIT Kurukshetra. The workshop will be held alongside the 18th Innovations in Software Engineering Conference (ISEC 2025).},
booktitle = {Proceedings of the 18th Innovations in Software Engineering Conference},
articleno = {22},
numpages = {3},
location = {
},
series = {ISEC '25}
}

@inproceedings{10.1145/3632620.3671097,
author = {Ali, Murtaza and Rao, Prerna and Mai, Yifan and Xie, Benjamin},
title = {Using Benchmarking Infrastructure to Evaluate LLM Performance on CS Concept Inventories: Challenges, Opportunities, and Critiques},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671097},
doi = {10.1145/3632620.3671097},
abstract = {BACKGROUND AND CONTEXT. The pace of advancement of large language models (LLMs) motivates the use of existing infrastructure to automate the evaluation of LLM performance on computing education tasks. Concept inventories are well suited for evaluation because of their careful design and prior validity evidence. OBJECTIVES. Our research explores the feasibility of using an automated benchmarking framework to evaluate computer science (CS) concept inventories. We explore three primary objectives: evaluation of LLM performance on the SCS1 and BDSI concept inventories; informal expert panel review of items which had variations between LLM and expected student performance; and description of challenges with using benchmarking infrastructure as a methodological innovation. METHOD. We used the Holistic Evaluation of Language Models (HELM) framework to evaluate the SCS1 and BDSI against 10 LLMS with zero-shot and few-shot in-context learning: GPT (3.5, 4.0), Claude (1.3, 2.0, 2.1), Llama (7B, 13B, 70B), Mistral v0.1 7B, and Mixtral 8x7B. We used psychometric data from prior studies to measure knowledge levels for each LLM run. We then conducted an informal expert review to qualitatively explore how question design, CS content knowledge, and LLM design may explain differences between LLM and expected student performances. FINDINGS. Our quantitative analysis found that most LLM response patterns reflected a below average introductory computing student with the SCS1 and did not fit the psychometric 2PL model for the BDSI. Our qualitative analysis identified that LLMs performed well on code infill questions, but poorly on nested conditionals, runtime analysis, and longer questions. We also identified several methodological challenges related to item security, translation, the structure when using HELM. IMPLICATIONS. We consider the feasibility of using automated benchmarking as a methodology to support more reproducible, replicable, and rigorous investigations to understand the intersection of LLM capabilities, computing concepts, and assessment design. We also consider connections between psychometric approaches and LLM evaluations to inform the design of computing assessments that are more resilient to LLM advancements.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {452–468},
numpages = {17},
keywords = {benchmarking, computing education, concept inventories, large language models, psychometrics},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3686215.3688378,
author = {Molto, Joaquin and Fields, Jonathan and Visser, Ubbo and Lisetti, Christine},
title = {An LLM-powered Socially Interactive Agent with Adaptive Facial Expressions for Conversing about Health},
year = {2024},
isbn = {9798400704635},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686215.3688378},
doi = {10.1145/3686215.3688378},
abstract = {Virtual Socially Interactive Agents (SIA) have shown great promise for human interactions with computer applications in which not only domain-relevant content is needed, but also the way in which the content is delivered (e.g. socio-emotionally adaptive tutoring agents, socio-emotionally responsive health agents). While recent progress on Large Language Models (LLMs) has made rich verbal interactions possible, LLMs cannot communicate nonverbal social cues through a simple text-based interface. We propose an expressive conversational SIA system, powered by an OpenAI Large Language Model (LLM) for text generation, integrated with a 3D humanoid model with real-time behavior generation of FACS-based facial expressions that mirror the user’s to increase rapport and engagement using HumeAI’s Facial Expression Recognition and Empathic Voice Interface (EVI) models to drive the model’s animations. As a case study, we use prompt-engineering to focus the conversation on discussing health-related behaviors. We ground the generation of the LLM’s questions based on the World Health Organization’s (WHO) Alcohol Use Disorders Identification Test (AUDIT) 10-question inventory, a test that help identify whether someone is at risk of alcohol use disorder.},
booktitle = {Companion Proceedings of the 26th International Conference on Multimodal Interaction},
pages = {75–77},
numpages = {3},
keywords = {Adaptation, Health Information Technologies, LLMs, Virtual Agent},
location = {San Jose, Costa Rica},
series = {ICMI Companion '24}
}

@inproceedings{10.1145/3644815.3644981,
author = {Rahman, Md Tajmilur and Singh, Rahul and Sultan, Mir Yousuf},
title = {Automating Patch Set Generation from Code Reviews Using Large Language Models},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644981},
doi = {10.1145/3644815.3644981},
abstract = {The advent of Large Language Models (LLMs) has revolutionized various domains of artificial intelligence, including the realm of software engineering. In this research, we evaluate the efficacy of pre-trained LLMs in replicating the tasks traditionally performed by developers in response to code review comments. We provide code contexts to five popular LLMs and obtain the suggested code-changes (patch sets) derived from real-world code-review comments. The performance of each model is meticulously assessed by comparing their generated patch sets against the historical data of human-generated patch-sets from the same repositories. This comparative analysis aims to determine the accuracy, relevance, and depth of the LLMs' feedback, thereby evaluating their readiness to support developers in responding to code-review comments. Novelty: This particular research area is still immature requiring a substantial amount of studies yet to be done. No prior research has compared the performance of existing Large Language Models (LLMs) in code-review comments. This in-progress study assesses current LLMs in code review and paves the way for future advancements in automated code quality assurance, reducing context-switching overhead due to interruptions from code change requests.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {273–274},
numpages = {2},
keywords = {large language models, automated code review, software engineering, pull requests, code quality},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@article{10.1145/3735129,
author = {Yang, Boyang and Tian, Haoye and Ren, Jiadong and Zhang, Hongyu and Klein, Jacques and Bissyande, Tegawende and Le Goues, Claire and Jin, Shunfu},
title = {MORepair: Teaching LLMs to Repair Code via Multi-Objective Fine-Tuning},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3735129},
doi = {10.1145/3735129},
abstract = {Within the realm of software engineering, specialized tasks on code, such as program repair, present unique challenges, necessitating fine-tuning Large language models&nbsp;(LLMs) to unlock state-of-the-art performance. Fine-tuning approaches proposed in the literature for LLMs on program repair tasks generally overlook the need to reason about the logic behind code changes, beyond syntactic patterns in the data. High-performing fine-tuning experiments also usually come at very high computational costs. With MORepair, we propose a novel perspective on the learning focus of LLM fine-tuning for program repair: we not only adapt the LLM parameters to the syntactic nuances of the task of code transformation (objective ➊), but we also specifically fine-tune the LLM with respect to the logical reason behind the code change in the training data (objective ➋). Such a multi-objective fine-tuning will instruct LLMs to generate high-quality patches.We apply MORepair to fine-tune four open-source LLMs with different sizes and architectures. Experimental results on function-level and repository-level repair benchmarks show that the implemented fine-tuning effectively boosts LLM repair performance by 11.4% to 56.0%. We further show that our fine-tuning strategy yields superior performance compared to the state-of-the-art approaches, including standard fine-tuning, Fine-tune-CoT, and RepairLLaMA.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Program Repair, Fine-tuning, Large Language Model, Open Source}
}

@inproceedings{10.1145/3650212.3652115,
author = {Zeng, Zhengran and Wang, Yidong and Xie, Rui and Ye, Wei and Zhang, Shikun},
title = {CoderUJB: An Executable and Unified Java Benchmark for Practical Programming Scenarios},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3652115},
doi = {10.1145/3650212.3652115},
abstract = {In the evolving landscape of large language models (LLMs) tailored for software engineering, the need for benchmarks that accurately reflect real-world development scenarios is paramount. Current benchmarks are either too simplistic or fail to capture the multi-tasking nature of software development. To address this, we introduce CoderUJB, a new benchmark designed to evaluate LLMs across diverse Java programming tasks that are executable and reflective of actual development scenarios, acknowledging Java's prevalence in real-world software production. CoderUJB comprises 2,239 programming questions derived from 17 real open-source Java projects and spans five practical programming tasks. Our empirical study on this benchmark investigates the coding abilities of various open-source and closed-source LLMs, examining the effects of continued pre-training in specific programming languages code and instruction fine-tuning on their performance. The findings indicate that while LLMs exhibit strong potential, challenges remain, particularly in non-functional code generation (e.g., test generation and defect detection). Importantly, our results advise caution in the specific programming languages continued pre-training and instruction fine-tuning, as these techniques could hinder model performance on certain tasks, suggesting the need for more nuanced strategies. CoderUJB thus marks a significant step towards more realistic evaluations of programming capabilities in LLMs, and our study provides valuable insights for the future development of these models in software engineering.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {124–136},
numpages = {13},
keywords = {Benchmark, Code Generation, Large Language Models},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@article{10.1145/3660788,
author = {Khojah, Ranim and Mohamad, Mazen and Leitner, Philipp and de Oliveira Neto, Francisco Gomes},
title = {Beyond Code Generation: An Observational Study of ChatGPT Usage in Software Engineering Practice},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660788},
doi = {10.1145/3660788},
abstract = {Large Language Models (LLMs) are frequently discussed in academia and the general public as support tools for virtually any use case that relies on the production of text, including software engineering. Currently, there is much debate, but little empirical evidence, regarding the practical usefulness of LLM-based tools such as ChatGPT for engineers in industry. We conduct an observational study of 24 professional software engineers who have been using ChatGPT over a period of one week in their jobs, and qualitatively analyse their dialogues with the chatbot as well as their overall experience (as captured by an exit survey). We find that rather than expecting ChatGPT to generate ready-to-use software artifacts (e.g., code), practitioners more often use ChatGPT to receive guidance on how to solve their tasks or learn about a topic in more abstract terms. We also propose a theoretical framework for how the (i) purpose of the interaction, (ii) internal factors (e.g., the user's personality), and (iii) external factors (e.g., company policy) together shape the experience (in terms of perceived usefulness and trust). We envision that our framework can be used by future research to further the academic discussion on LLM usage by software engineering practitioners, and to serve as a reference point for the design of future empirical LLM research in this domain.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {81},
numpages = {22},
keywords = {Chatbots, Large Language Models (LLMs), Software Development Bots}
}

@inproceedings{10.1145/3650105.3652288,
author = {Venkatesh, Ashwin Prasad Shivarpatna and Sabu, Samkutty and Mir, Amir M. and Reis, Sofia and Bodden, Eric},
title = {The Emergence of Large Language Models in Static Analysis: A First Look through Micro-Benchmarks},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650105.3652288},
doi = {10.1145/3650105.3652288},
abstract = {The application of Large Language Models (LLMs) in software engineering, particularly in static analysis tasks, represents a paradigm shift in the field. In this paper, we investigate the role that current LLMs can play in improving callgraph analysis and type inference for Python programs. Using the PyCG, HeaderGen, and TypeEvalPy micro-benchmarks, we evaluate 26 LLMs, including OpenAI's GPT series and open-source models such as LLaMA. Our study reveals that LLMs show promising results in type inference, demonstrating higher accuracy than traditional methods, yet they exhibit limitations in callgraph analysis. This contrast emphasizes the need for specialized fine-tuning of LLMs to better suit specific static analysis tasks. Our findings provide a foundation for further research towards integrating LLMs for static analysis tasks.},
booktitle = {Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
pages = {35–39},
numpages = {5},
location = {Lisbon, Portugal},
series = {FORGE '24}
}

@inproceedings{10.1145/3691620.3695066,
author = {Li, Guochang and Zhi, Chen and Chen, Jialiang and Han, Junxiao and Deng, Shuiguang},
title = {Exploring Parameter-Efficient Fine-Tuning of Large Language Model on Automated Program Repair},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695066},
doi = {10.1145/3691620.3695066},
abstract = {Automated Program Repair (APR) aims to fix bugs by generating patches. And existing work has demonstrated that "pre-training and fine-tuning" paradigm enables Large Language Models (LLMs) improve fixing capabilities on APR. However, existing work mainly focuses on Full-Model Fine-Tuning (FMFT) for APR and limited research has been conducted on the execution-based evaluation of Parameter-Efficient Fine-Tuning (PEFT) for APR. Comparing to FMFT, PEFT can reduce computing resource consumption without compromising performance and has been widely adopted to other software engineering tasks.To fill this gap, we enhance the existing APR dataset by employing prompt engineering to create an instruction dataset, APR-Instruction, at first. Secondly, we fine-tune four pre-trained LLMs using four different PEFT methods with APR-Instruction. The best fine-tuned model fixes 58% more bugs than the state-of-the-art LLM-based APR techniques. The results also show that (IA)3 improves the creativity of LLMs more effectively through fine-tuning and achieves the highest fixing capability compared to the other three PEFT methods. Thirdly, we explore the optimal configuration of PEFT hyperparameters, and assess the impact of instruction dataset size, showing that a larger number of parameters and a larger training dataset do not necessarily result in better performance for PEFT. Lastly, we analyze peak memory usage and trainable parameters to show the efficiency of PEFT.This work provides a comprehensive exploration of PEFT on APR and suggests potentially promising directions for extension to other software engineering downstream tasks. APR-Instruction, PEFT weights, and the fine-tuning code are publicly available as open-source resources.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {719–731},
numpages = {13},
keywords = {automated program repair, parameter-effective fine-tuning, large language model, execution-based evaluation},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3643915.3644088,
author = {Li, Jialong and Zhang, Mingyue and Li, Nianyu and Weyns, Danny and Jin, Zhi and Tei, Kenji},
title = {Exploring the Potential of Large Language Models in Self-adaptive Systems},
year = {2024},
isbn = {9798400705854},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643915.3644088},
doi = {10.1145/3643915.3644088},
abstract = {Large Language Models (LLMs), with their abilities in knowledge acquisition and reasoning, can potentially enhance the various aspects of Self-adaptive Systems (SAS). Yet, the potential of LLMs in SAS remains largely unexplored and ambiguous, due to the lack of literature from flagship conferences or journals in the field, such as SEAMS and TAAS. The interdisciplinary nature of SAS suggests that drawing and integrating ideas from related fields, such as software engineering and autonomous agents, could unveil innovative research directions for LLMs within SAS. To this end, this paper reports the results of a literature review of studies in relevant fields, summarizes and classifies the studies relevant to SAS, and outlines their potential to specific aspects of SAS. Literature classification: www.github.com/545659928/LLM4SAS},
booktitle = {Proceedings of the 19th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {77–83},
numpages = {7},
keywords = {large language model, self-adaptive systems, survey},
location = {Lisbon, AA, Portugal},
series = {SEAMS '24}
}

@inproceedings{10.1145/3701625.3701657,
author = {de Almeida, \'{A}gatha and Collins, Eliane and Oran, Ana Carolina},
title = {AI in Service of Software Quality: How ChatGPT and Personas Are Transforming Exploratory Testing},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701657},
doi = {10.1145/3701625.3701657},
abstract = {Context: Exploratory testing is essential in the software validation process as a way to find unexpected and critical failures in a short time, complementing documented functional test cases. However, creating scenarios to explore the software (such as test charters) can be time-consuming, and depending on the team’s experience, it may lack adequate coverage of functionalities and scenarios that target specific user profiles of the application. Objective: This article investigates how AI, through LLMs (Large Language Models), can assist in creating exploratory test charters that reflect the characteristics and needs of different user personas. Method: To achieve this, an experimental study was conducted where personas were used as input in ChatGPT 3.5 to generate exploratory test charters. The effectiveness of the approach was evaluated by Software Engineering students, who analyzed the performance and usefulness of the generated charters through a questionnaire based on the TAM model, supplemented by qualitative and quantitative analyses. Results: Data analysis indicated positive acceptance of ChatGPT 3.5 by the participants, highlighting its ease of use and perceived usefulness. Conclusion: This study contributes to the field of Software Engineering by demonstrating a practical application of artificial intelligence in the automated generation of test charters. ChatGPT 3.5 has proven to be a promising tool to support the creation of personalized exploratory test charters, contributing to software quality improvement. The integration of artificial intelligence techniques with user-centered design methods can significantly optimize the software testing process.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {179–188},
numpages = {10},
keywords = {Exploratory Testing, ChatGPT, Personas, Software Quality, Artificial Intelligence},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3636243.3636249,
author = {Sheese, Brad and Liffiton, Mark and Savelka, Jaromir and Denny, Paul},
title = {Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636249},
doi = {10.1145/3636243.3636249},
abstract = {Providing personalized assistance at scale is a long-standing challenge for computing educators, but a new generation of tools powered by large language models (LLMs) offers immense promise. Such tools can, in theory, provide on-demand help in large class settings and be configured with appropriate guardrails to prevent misuse and mitigate common concerns around learner over-reliance. However, the deployment of LLM-powered tools in authentic classroom settings is still rare, and very little is currently known about how students will use them in practice and what type of help they will seek. To address this, we examine students’ use of an innovative LLM-powered tool that provides on-demand programming assistance without revealing solutions directly. We deployed the tool for 12 weeks in an introductory computer and data science course&nbsp;(n = 52), collecting more than 2,500 queries submitted by students throughout the term. We manually categorized all student queries based on the type of assistance sought, and we automatically analyzed several additional query characteristics. We found that most queries requested immediate help with programming assignments, whereas fewer requests asked for help on related concepts or for deepening conceptual understanding. Furthermore, students often provided minimal information to the tool, suggesting this is an area in which targeted instruction would be beneficial. We also found that students who achieved more success in the course tended to have used the tool more frequently overall. Lessons from this research can be leveraged by programming educators and institutions who plan to augment their teaching with emerging LLM-powered tools.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {49–57},
numpages = {9},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3658644.3670392,
author = {Liu, Zeyan and Yao, Zijun and Li, Fengjun and Luo, Bo},
title = {On the Detectability of ChatGPT Content: Benchmarking, Methodology, and Evaluation through the Lens of Academic Writing},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670392},
doi = {10.1145/3658644.3670392},
abstract = {With ChatGPT under the spotlight, utilizing large language models (LLMs) to assist academic writing has drawn a significant amount of debate in the community. In this paper, we aim to present a comprehensive study of the detectability of ChatGPT-generated content within the academic literature, particularly focusing on the abstracts of scientific papers, to offer holistic support for the future development of LLM applications and policies in academia. Specifically, we first present GPABench2, a benchmarking dataset of over 2.8 million comparative samples of human-written, GPT-written, GPT-completed, and GPT-polished abstracts of scientific writing in computer science, physics, and humanities and social sciences. Second, we explore the methodology for detecting ChatGPT content. We start by examining the unsatisfactory performance of existing ChatGPT detecting tools and the challenges faced by human evaluators (including more than 240 researchers or students). We then test the hand-crafted linguistic features models as a baseline and develop a deep neural framework named CheckGPT to better capture the subtle and deep semantic and linguistic patterns in ChatGPT written literature. Last, we conduct comprehensive experiments to validate the proposed CheckGPT framework in each benchmarking task over different disciplines. To evaluate the detectability of ChatGPT content, we conduct extensive experiments on the transferability, prompt engineering, and robustness of CheckGPT.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2236–2250},
numpages = {15},
keywords = {aigc detection, large language models, responsible ai},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3643795.3648389,
author = {Dingle, Adam and Krulis, Martin},
title = {Tackling Students' Coding Assignments with LLMs},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648389},
doi = {10.1145/3643795.3648389},
abstract = {State-of-the-art large language models (LLMs) have demonstrated an extraordinary ability to write computer code. This ability can be quite beneficial when integrated into an IDE to assist a programmer with basic coding. On the other hand, it may be misused by computer science students for cheating on coding tests or homework assignments. At present, knowledge about the exact capabilities and limitations of state-of-the-art LLMs is still inadequate. Furthermore, their capabilities have been changing quickly with each new release. In this paper, we present a dataset of 559 programming exercises in 10 programming languages collected from a system for evaluating coding assignments at our university. We have experimented with four well-known LLMs (GPT-3.5, GPT-4, Codey, Code Llama) and asked them to solve these assignments. The evaluation results are intriguing and provide insights into the strengths and weaknesses of the models. In particular, GPT-4 (which performed the best) is currently capable of solving 55% of all our exercises and achieved an average score of 86% on exercises from the introductory programming course (using the best of five generated solutions).},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {94–101},
numpages = {8},
keywords = {LLM, large language model, coding, programming, student assignment, teaching},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3650212.3680328,
author = {Yang, Boyang and Tian, Haoye and Pian, Weiguo and Yu, Haoran and Wang, Haitao and Klein, Jacques and Bissyand\'{e}, Tegawend\'{e} F. and Jin, Shunfu},
title = {CREF: An LLM-Based Conversational Software Repair Framework for Programming Tutors},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680328},
doi = {10.1145/3650212.3680328},
abstract = {With the proven effectiveness of Large Language Models (LLMs) in code-related tasks, researchers have explored their potential for program repair. However, existing repair benchmarks might have influenced LLM training data, potentially causing data leakage. To evaluate LLMs’ realistic repair capabilities, (i) we introduce an extensive, non-crawled benchmark TutorCode, comprising 1,239 C++ defect codes and associated information such as tutor guidance, solution description, failing test cases, and the corrected code. Our work assesses LLM’s repair performance on TutorCode, measuring repair correctness (TOP-5 and AVG-5) and patch precision (RPSR). (ii) We then provide a comprehensive investigation into which types of extra information can help LLMs improve their repair performance. Among these types, tutor guidance was the most effective information. To fully harness LLMs’ conversational capabilities and the benefits of augmented information, (iii) we introduce a novel conversational semi-automatic repair framework CREF assisting human programming tutors. It demonstrates a remarkable AVG-5 improvement of 17.2%-24.6% compared to the baseline, achieving an impressive AVG-5 of 76.6% when utilizing GPT-4. These results highlight the potential for enhancing LLMs’ repair capabilities through tutor interactions and historical conversations. The successful application of CREF in a real-world educational setting demonstrates its effectiveness in reducing tutors’ workload and improving students’ learning experience, showing promise for code review and other software engineering tasks.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {882–894},
numpages = {13},
keywords = {Large Language Model, Open Source, Program Repair},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3649217.3653584,
author = {Vadaparty, Annapurna and Zingaro, Daniel and Smith IV, David H. and Padala, Mounika and Alvarado, Christine and Gorson Benario, Jamie and Porter, Leo},
title = {CS1-LLM: Integrating LLMs into CS1 Instruction},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653584},
doi = {10.1145/3649217.3653584},
abstract = {The recent, widespread availability of Large Language Models (LLMs) like ChatGPT and GitHub Copilot may impact introductory programming courses (CS1) both in terms of what should be taught and how to teach it. Indeed, recent research has shown that LLMs are capable of solving the majority of the assignments and exams we previously used in CS1. In addition, professional software engineers are often using these tools, raising the question of whether we should be training our students in their use as well. This experience report describes a CS1 course at a large research-intensive university that fully embraces the use of LLMs from the beginning of the course. To incorporate the LLMs, the course was intentionally altered to reduce emphasis on syntax and writing code from scratch. Instead, the course now emphasizes skills needed to successfully produce software with an LLM. This includes explaining code, testing code, and decomposing large problems into small functions that are solvable by an LLM. In addition to frequent, formative assessments of these skills, students were given three large, open-ended projects in three separate domains (data science, image processing, and game design) that allowed them to showcase their creativity in topics of their choosing. In an end-of-term survey, students reported that they appreciated learning with the assistance of the LLM and that they interacted with the LLM in a variety of ways when writing code. We provide lessons learned for instructors who may wish to incorporate LLMs into their course.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {297–303},
numpages = {7},
keywords = {copilot, cs1, generative ai, introductory programming, llm},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3639474.3640076,
author = {Xue, Yuankai and Chen, Hanlin and Bai, Gina R. and Tairas, Robert and Huang, Yu},
title = {Does ChatGPT Help With Introductory Programming?An Experiment of Students Using ChatGPT in CS1},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640076},
doi = {10.1145/3639474.3640076},
abstract = {Generative AI, notably ChatGPT, has garnered attention in computer science education. This paper presents a controlled experiment that explores ChatGPT's role in CS1 in a classroom setting. Specifically, we aim to investigate the impact of ChatGPT on student learning outcomes and their behaviors when working on programming assignments. Participants were tasked with creating a UML diagram and subsequently implementing its design through programming, followed by a closed-book post-evaluation and a post-survey. All the participants were required to screen-record the whole process. In total, 56 participants were recruited, with 48 successful screen recordings. Participants in the Experimental Group can access ChatGPT 3.5 and other online resources, such as Google and Stack Overflow when creating the UML diagram and programming; however, participants in the Control Group can access all online resources except for ChatGPT (i.e., the only design variable is the access to ChatGPT). Finally, we measured and analyzed participants' learning outcomes through their UML diagram, programming, and post-evaluation scores. We also analyzed the time participants took to complete the tasks and their interactions with ChatGPT and other resources from the screen recordings. After finishing the tasks, student participants also provided their perceptions of using ChatGPT in CS1 through a post-survey.With rigorous quantitative and qualitative analysis, we found that (1) using ChatGPT does not present a significant impact on students' learning performance in the CS1 assignment-style tasks; (2) once using ChatGPT, students' tendency to explore other traditional educational resources is largely reduced (though available) and they tend to rely solely on ChatGPT, and this reliance on ChatGPT did not guarantee enhanced learning performance; (3) the majority of students hold neutral views on ChatGPT's role in CS1 programming but most of them raised concerns about its potential ethical issues and inconsistent performance across different tasks. We hope this study can help educators and students better understand the impact of ChatGPT in CS1 and inspire future work to provide proper guidelines for using ChatGPT in introductory programming classes.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {331–341},
numpages = {11},
keywords = {CS education, CS1, generative AI, ChatGPT, OOP},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3643795.3648393,
author = {Chusap, Krerkkiat and Liu, Chang},
title = {Gauging Tech Community Acceptance of Rapid Prototyping in Unfamiliar Programming Languages using LLM Chatbots},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648393},
doi = {10.1145/3643795.3648393},
abstract = {Large Language Model (LLM) chatbots such as ChatGPT possess information not only about human languages but also computer languages. It is now possible to perform programming and software design tasks with assistance from ChatGPT. We are particularly interested in how the software development community views the use of LLM chatbots in rapid prototyping using unfamiliar programming languages. In four different tech events, several example scenarios of how a tech-savvy engineer could use ChatGPT to prototype apps in unfamiliar programming languages were demonstrated, including a health education app. The four events include an IEEE chapter workshop, an IEEE WIE (Woman In Engineering) meeting, an IEEE joint chapter talk, and a university-level Computer Science class. The responses from the tech audience showed that the majority perceived value in the use of LLM chatbots in these contexts, even though there were subtle differences among different groups. This shows the need for further research on how to effectively incorporate LLM chatbots into traditional software design workflow to better serve the software development community.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {8–13},
numpages = {6},
keywords = {software engineering, software design, rapid prototyping, LLMs, ChatGPT},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3626252.3630842,
author = {Amoozadeh, Matin and Daniels, David and Nam, Daye and Kumar, Aayush and Chen, Stella and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Mohammad Amin},
title = {Trust in Generative AI among Students: An exploratory study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630842},
doi = {10.1145/3626252.3630842},
abstract = {Generative Artificial Intelligence (GenAI) systems have experienced exponential growth in the last couple of years. These systems offer exciting capabilities for CS Education (CSEd), such as generating programs, that students can well utilize for their learning. Among the many dimensions that might affect the effective adoption of GenAI for CSEd, in this paper, we investigate students' trust. Trust in GenAI influences the extent to which students adopt GenAI, in turn affecting their learning. In this paper, we present results from a survey of 253 students at two large universities to understand how much they trust GenAI tools and their feedback on how GenAI impacts their performance in CS courses. Our results show that students have different levels of trust in GenAI. We also observe different levels of confidence and motivation, highlighting the need for further understanding of factors impacting trust.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {67–73},
numpages = {7},
keywords = {generative ai, novice programmers, trust},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3657604.3664714,
author = {Arif, Taimoor and Asthana, Sumit and Collins-Thompson, Kevyn},
title = {Generation and Assessment of Multiple-Choice Questions from Video Transcripts using Large Language Models},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664714},
doi = {10.1145/3657604.3664714},
abstract = {We present an empirical study evaluating the quality of multiple-choice questions (MCQs) generated by Large Language Models (LLMs) from a corpus of video transcripts of course lectures in an online data science degree program. With our database of thousands of generated questions, we conducted both human and automated judging of question quality on a representative sample using a broad set of criteria, including well-established Item Writing Flaw (IWF) categories. We found the number of average IWFs per MCQ ranged from 1.6 (rule-based verification) to 2.18 (LLM-based). Among the most frequently identified MCQ flaws were lack of enough context (17%) or answer choices with at least one implausible distractor (57%). Both human and automated assessment identified implausible distractors as one of the most frequent flaw categories. Results from our human annotation study were generally more positive (51--65% good items) compared to our automated assessment study results, which tended toward greater flaw identification (15--25% good items), depending on evaluation method.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {530–534},
numpages = {5},
keywords = {educational video, large language models, question generation},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3716640.3716647,
author = {Leinonen, Juho and Denny, Paul and Kiljunen, Olli and MacNeil, Stephen and Sarsa, Sami and Hellas, Arto},
title = {LLM-itation is the Sincerest Form of Data: Generating Synthetic Buggy Code Submissions for Computing Education},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716647},
doi = {10.1145/3716640.3716647},
abstract = {There is a great need for data in computing education research. Data is needed to understand how students behave, to train models of student behavior to optimally support students, and to develop and validate new assessment tools and learning analytics techniques. However, relatively few computing education datasets are shared openly, often due to privacy regulations and issues in making sure the data is anonymous. Large language models (LLMs) offer a promising approach to create large-scale, privacy-preserving synthetic data, which can be used to explore various aspects of student learning, develop and test educational technologies, and support research in areas where collecting real student data may be challenging or impractical. This work explores generating synthetic buggy code submissions for introductory programming exercises using GPT-4o. We compare the distribution of test case failures between synthetic and real student data from two courses to analyze the accuracy of the synthetic data in mimicking real student data. Our findings suggest that LLMs can be used to generate synthetic incorrect submissions that are not significantly different from real student data with regard to test case failure distributions. Our research contributes to the development of reliable synthetic datasets for computing education research and teaching, potentially accelerating progress in the field while preserving student privacy.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {56–63},
numpages = {8},
keywords = {generative AI, genAI, large language models, LLMs, GPT-4o, prompt engineering, synthetic data, bugs, submissions, data generation},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641554.3701841,
author = {Aljedaani, Wajdi and Eler, Marcelo Medeiros and Parthasarathy, P D},
title = {Enhancing Accessibility in Software Engineering Projects with Large Language Models (LLMs)},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701841},
doi = {10.1145/3641554.3701841},
abstract = {Digital accessibility ensures that digital products and services are usable by a diverse range of users, regardless of their physical or cognitive abilities. While numerous standards and guidelines have been established to aid developers in creating accessible content, studies reveal a persistent lack of accessibility in many web and mobile applications. This gap is often attributed to barriers such as lack of awareness, insufficient knowledge, absence of specific requirements, time constraints, and lack of executive support. In this context, we aim to address the lack of awareness and knowledge challenges by proposing a hands-on approach that leverages the capabilities of Large Language Models (LLMs) like ChatGPT to enhance students' accessibility awareness, knowledge, and practical skills. We engaged software engineering students in tasks involving website development and accessibility evaluation using checker tools, and we utilized ChatGPT 3.5 to fix identified accessibility issues. Our findings suggest that practical assignments significantly enhance learning outcomes, as interactions with LLMs allow students to develop a deeper understanding of accessibility concepts. This approach not only reinforces theoretical knowledge but also highlights the real-world impact of their work. The results indicate that combining practical assignments with AI-driven support effectively improves students' proficiency in web accessibility.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {25–31},
numpages = {7},
keywords = {chatgpt 3.5, digital accessibility, large language models, llms, project based learning, software engineering, wcag},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3711000,
author = {Kapania, Shivani and Wang, Ruiyi and Li, Toby Jia-Jun and Li, Tianshi and Shen, Hong},
title = { 'I'm Categorizing LLM as a Productivity Tool': Examining Ethics of LLM Use in HCI Research Practices},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711000},
doi = {10.1145/3711000},
abstract = {Large language models are increasingly applied in real-world scenarios, including research and education. These models, however, come with well-known ethical issues, which may manifest in unexpected ways in human-computer interaction research due to the extensive engagement with human subjects. This paper reports on research practices related to LLM use, drawing on 16 semi-structured interviews and a survey with 50 HCI researchers. We discuss the ways in which LLMs are already being utilized throughout the entire HCI research pipeline, from ideation to system development and paper writing. While researchers described nuanced understandings of ethical issues, they were rarely or only partially able to identify and address those ethical concerns in their own projects. This lack of action and reliance on workarounds was explained through the perceived lack of control and distributed responsibility in the LLM supply chain, the conditional nature of engaging with ethics, and competing priorities. Finally, we reflect on the implications of our findings and present opportunities to shape emerging norms of engaging with large language models in HCI research.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW102},
numpages = {26},
keywords = {hci research, large language models, research ethics, research practices}
}

@article{10.1145/3695988,
author = {Hou, Xinyi and Zhao, Yanjie and Liu, Yue and Yang, Zhou and Wang, Kailong and Li, Li and Luo, Xiapu and Lo, David and Grundy, John and Wang, Haoyu},
title = {Large Language Models for Software Engineering: A Systematic Literature Review},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {8},
issn = {1049-331X},
url = {https://doi.org/10.1145/3695988},
doi = {10.1145/3695988},
abstract = {Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a Systematic Literature Review (SLR) on LLM4SE, with a particular focus on understanding how LLMs can be exploited to optimize processes and outcomes. We selected and analyzed 395 research articles from January 2017 to January 2024 to answer four key Research Questions (RQs). In RQ1, we categorize different LLMs that have been employed in SE tasks, characterizing their distinctive features and uses. In RQ2, we analyze the methods used in data collection, pre-processing, and application, highlighting the role of well-curated datasets for successful LLM for SE implementation. RQ3 investigates the strategies employed to optimize and evaluate the performance of LLMs in SE. Finally, RQ4 examines the specific SE tasks where LLMs have shown success to date, illustrating their practical contributions to the field. From the answers to these RQs, we discuss the current state-of-the-art and trends, identifying gaps in existing research, and highlighting promising areas for future study. Our artifacts are publicly available at .},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {220},
numpages = {79},
keywords = {Software Engineering, Large Language Model, Survey}
}

@inproceedings{10.1145/3616961.3616974,
author = {Rajala, Jaakko and Hukkanen, Jenni and Hartikainen, Maria and Niemel\"{a}, Pia},
title = {"\"Call me Kiran\" – ChatGPT as a Tutoring Chatbot in a Computer Science Course"},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616974},
doi = {10.1145/3616961.3616974},
abstract = {Natural language processing has taken enormous steps during the last few years. The development of large language models and generative AI has elevated natural language processing to the level that it can output coherent and contextually relevant text for a given natural language prompt. ChatGPT is one incarnation of these steps, and its use in education is a rather new phenomenon. In this paper, we study students’ perception on ChatGPT during a computer science course. On the course, we integrated ChatGPT into Teams private discussion groups. In addition, all the students had freedom to employ ChatGPT and related technologies to help them in their coursework. The results show that the majority of students had at least tested AI-powered chatbots, and that students are using AI-powered chatbots for multiple tasks, e.g., debugging code, tutoring, and enhancing comprehension. The amount of positive implications of using ChatGPT takes over the negative implications, when the implications were considered from an understanding, learning and creativity perspective. Relatively many students reported reliability issues with the outputs and that the iterations with prompts might be necessary for satisfactory outputs. It is important to try to steer the usage of ChatGPT so that it complements students’ learning processes, but does not replace it.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {83–94},
numpages = {12},
keywords = {tutoring, student perceptions, generative AI, education, discussion forum, chatbots, artificial intelligence, ChatGPT},
location = {Tampere, Finland},
series = {Mindtrek '23}
}

@article{10.1145/3714461,
author = {Weyssow, Martin and Zhou, Xin and Kim, Kisub and Lo, David and Sahraoui, Houari},
title = {Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3714461},
doi = {10.1145/3714461},
abstract = {Large language models (LLMs) demonstrate impressive capabilities to generate accurate code snippets given natural language intents in a zero-shot manner, i.e., without the need for specific fine-tuning. While prior studies have highlighted the advantages of fine-tuning LLMs, this process incurs high computational costs, making it impractical in resource-scarce environments, particularly for models with billions of parameters. To address these challenges, previous research explored in-context learning (ICL) and retrieval-augmented generation (RAG) as strategies to guide the LLM generative process with task-specific prompt examples. However, ICL and RAG introduce inconveniences, such as the need for designing contextually relevant prompts and the absence of learning task-specific parameters, thereby limiting downstream task performance. In this context, we foresee parameter-efficient fine-tuning (PEFT) as a promising approach to efficiently specialize LLMs to task-specific data while maintaining reasonable resource consumption. In this paper, we deliver a comprehensive study of PEFT techniques for LLMs in the context of automated code generation. Our comprehensive investigation of PEFT techniques for LLMs reveals their superiority and potential over ICL and RAG across a diverse set of LLMs and three representative Python code generation datasets: Conala, CodeAlpacaPy, and APPS. Furthermore, our study highlights the potential for tuning larger LLMs and significant reductions in memory usage by combining PEFT with quantization. Therefore, this study opens opportunities for broader applications of PEFT in software engineering scenarios.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {code generation, large language models, parameter-efficient fine-tuning, quantization, retrieval-augmented generation, empirical study}
}

@inproceedings{10.1145/3674805.3690743,
author = {Felizardo, Katia Romero and Steinmacher, Igor and Lima, M\'{a}rcia Sampaio and Deizepe, Anderson and Conte, Tayana Uch\^{o}a and Barcellos, Monalessa Perini},
title = {Data extraction for systematic mapping study using a large language model - a proof-of-concept study in software engineering},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690743},
doi = {10.1145/3674805.3690743},
abstract = {Context: Systematic mapping studies (SMS) are adopted in Software Engineering (SE) to select and synthesize relevant literature on a research topic and, thus, support evidence-based decision-making. Performing SMS is effort-demanding and time-consuming. Hence, using tools is beneficial. Large Language Models (LLMs) such as ChatGPT–4.o can potentially accelerate repetitive activities, such as data extraction in SMS, saving time and effort. Goal: We conducted this work to evaluate and provide preliminary evidence on how ChatGPT–4.o can support data extraction in SMS. Method: We performed a proof-of-concept study and assessed the results’ accuracy of using ChatGPT 4.0 to extract data in one SMS compared to the results produced manually. Results: The accuracy of ChatGPT–4.o was 87.83%. Conclusions: Our preliminary findings suggest that entirely replacing the manual data extraction with ChatGPT–4.o is not recommended. However, employing ChatGPT for semi-automated data extraction to aid in evidence synthesis in SMS is promising.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {407–413},
numpages = {7},
keywords = {ChatGPT, Data Extraction, LLM, Mapping Study},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3644815.3644945,
author = {Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
title = {Seven Failure Points When Engineering a Retrieval Augmented Generation System},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644945},
doi = {10.1145/3644815.3644945},
abstract = {Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {194–199},
numpages = {6},
keywords = {retrieval augmented generation, RAG, SE4AI, case study},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3657604.3662039,
author = {Smith, David H. and Denny, Paul and Fowler, Max},
title = {Prompting for Comprehension: Exploring the Intersection of Explain in Plain English Questions and Prompt Writing},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662039},
doi = {10.1145/3657604.3662039},
abstract = {Learning to program requires the development of a variety of skills including the ability to read, comprehend, and communicate the purpose of code. In the age of large language models (LLMs), where code can be generated automatically, developing these skills is more important than ever for novice programmers. The ability to write precise natural language descriptions of desired behavior is essential for eliciting code from an LLM, and the code that is generated must be understood in order to evaluate its correctness and suitability. In introductory computer science courses, a common question type used to develop and assess code comprehension skill is the 'Explain in Plain English' (EiPE) question. In these questions, students are shown a segment of code and asked to provide a natural language description of that code's purpose. The adoption of EiPE questions at scale has been hindered by: 1) the difficulty of automatically grading short answer responses and 2) the ability to provide effective and transparent feedback to students. To address these shortcomings, we explore and evaluate a grading approach where a student's EiPE response is used to generate code via an LLM, and that code is evaluated against test cases to determine if the description of the code was accurate. This provides a scalable approach to creating code comprehension questions and enables feedback both through the code generated from a student's description and the results of test cases run on that code. We evaluate students' success in completing these tasks, their use of the feedback provided by the system, and their perceptions of the activity.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {39–50},
numpages = {12},
keywords = {CS1, EIPE, LLMs, code comprehension, explain in plain English, introductory programming, large language models, prompting},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3699538.3699581,
author = {Vassar, Alexandra and Renzella, Jake and Ross, Emily and Taylor, Andrew},
title = {Fine-Tuning Large Language Models for Better Programming Error Explanations},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699581},
doi = {10.1145/3699538.3699581},
abstract = {This paper investigates supervised fine-tuning of large language models (LLMs) to improve their pedagogical alignment in computing education, addressing concerns that LLMs may hinder learning outcomes. The project utilised a proprietary dataset of 2,500 high quality question/answer pairs from programming course forums, and explores two research questions: the suitability of university course forums in contributing to fine-tuning datasets, and how supervised fine-tuning can improve LLMs’ alignment with educational principles such as constructivism. Initial findings suggest benefits in pedagogical alignment of LLMs, with deeper evaluations required.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {26},
numpages = {2},
keywords = {Programming Error Messages, CS1, AI in CS1, AI in Education, Generative AI, LLM},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3649217.3653600,
author = {Villegas Molina, Ismael and Montalvo, Audria and Zhong, Shera and Jordan, Mollie and Soosai Raj, Adalbert Gerald},
title = {Generation and Evaluation of a Culturally-Relevant CS1 Textbook for Latines using Large Language Models},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653600},
doi = {10.1145/3649217.3653600},
abstract = {In the United States, culturally relevant computing (CRC) is one of the most popular pedagogical implementations for Latin American (Latine) students. Culturally-relevant learning resources are a valuable tool for implementing CRC. However, the traditional method of creation and maintenance of textbooks takes a significant amount of time and effort. Given the duration required for textbook production, the development of culturally-relevant learning resources may become lengthened, as it requires close attention both on the material and the incorporation of cultural referents. In order to accelerate the process, we used the advancement of large language models (LLMs) to our advantage. Through prompt engineering, we created a series of prompts to produce a textbook for an introductory computer science course (CS1) that incorporates Latine culture. This textbook was evaluated on metrics regarding sensibility, correctness, readability, linguistic approachability, appropriateness of examples, and cultural relevance. Overall, the generated textbook was mainly sensible, correct, readable, and linguistically approachable. Code examples were not always appropriate due to the usage of libraries that are not typically used in a CS1 course. The cultural relevance was apparent, but it often included surface-level cultural referents. The main incorporation of culture was through geographical locations and people's names. This suggests that the use of LLMs to generate textbooks may serve as a valuable first step for writing culturally-relevant learning resources. Though this study focuses on Latines, our results and prompts may be applicable for generating culturally-relevant CS1 textbooks for other cultures.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {325–331},
numpages = {7},
keywords = {Latina, Latine, Latino, Latinx, computer science textbook, culturally relevant resources, large language models, resource generation},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3631802.3631830,
author = {Liffiton, Mark and Sheese, Brad E and Savelka, Jaromir and Denny, Paul},
title = {CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631830},
doi = {10.1145/3631802.3631830},
abstract = {Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students’ usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {8},
numpages = {11},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3610661.3616129,
author = {Brooks, Jeffrey A. and Tiruvadi, Vineet and Baird, Alice and Tzirakis, Panagiotis and Li, Haoqi and Gagne, Chris and Oh, Moses and Cowen, Alan},
title = {Emotion Expression Estimates to Measure and Improve Multimodal Social-Affective Interactions},
year = {2023},
isbn = {9798400703218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610661.3616129},
doi = {10.1145/3610661.3616129},
abstract = {Large language models (LLMs) are being adopted in a wide range of applications, but an understanding of other social-affective signals is needed to support effective human-computer-interaction (HCI) in multimodal interfaces. In particular, robust, accurate measurements of human emotional expression can be used to tailor responses to human values and preferences. In this paper, we present two models available from an API-based suite of emotional expression models that measure nuanced facial and vocal signals, providing rich, high-dimensional emotional expression estimates (EEEs). We demonstrate the ability of EEEs to provide insight into two established datasets and present methods for integrating EEEs into large language model (LLM) applications. We discuss how this approach is a step towards more reliable tools for clinical screening and scientific study, as well as empathic digital assistants that can be used in therapeutic settings.},
booktitle = {Companion Publication of the 25th International Conference on Multimodal Interaction},
pages = {353–358},
numpages = {6},
keywords = {Multimodal Sentiment Analysis, Mental Health, Emotion Science, Emotion Recognition, Affective Computing},
location = {Paris, France},
series = {ICMI '23 Companion}
}

@inproceedings{10.1145/3674805.3690741,
author = {De Bari, Daniele and Garaccione, Giacomo and Coppola, Riccardo and Torchiano, Marco and Ardito, Luca},
title = {Evaluating Large Language Models in Exercises of UML Class Diagram Modeling},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690741},
doi = {10.1145/3674805.3690741},
abstract = {Large Language Models (LLM) have rapidly affirmed in the latest years as a means to support or substitute human actors in a variety of tasks. LLM agents can generate valid software models, because of their inherent ability in evaluating textual requirements provided to them in the form of prompts. The goal of this work is to evaluate the capability of LLM agents to correctly generate UML class diagrams in activities of Requirements Modeling in the field of Software Engineering. Our aim is to evaluate LLMs in an educational setting, i.e., understanding how valuable are the results of LLMs when compared to results made by human actors, and how valuable can LLM be to generate sample solutions to provide to students. For that purpose, we collected 20 exercises from a diverse set of web sources and compared the models generated by a human and an LLM solver in terms of syntactic, semantic, pragmatic correctness, and distance from a provided reference solution. Our results show that the solutions generated by an LLM solver typically present a significantly higher number of errors in terms of semantic quality and textual difference against the provided reference solution, while no significant difference is found in syntactic and pragmatic quality. We can therefore conclude that, with a limited amount of errors mostly related to the textual content of the solution, UML diagrams generated by LLM agents have the same level of understandability as those generated by humans, and exhibit the same frequency in violating rules of UML Class Diagrams.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {393–399},
numpages = {7},
keywords = {Artificial Intelligence, Class Diagrams, Large Language Models, Software Modeling},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3708493.3712691,
author = {Cummins, Chris and Seeker, Volker and Grubisic, Dejan and Roziere, Baptiste and Gehring, Jonas and Synnaeve, Gabriel and Leather, Hugh},
title = {LLM Compiler: Foundation Language Models for Compiler Optimization},
year = {2025},
isbn = {9798400714078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708493.3712691},
doi = {10.1145/3708493.3712691},
abstract = {Large Language Models (LLMs) have demonstrated remarkable capabilities across a variety of software engineering and coding tasks. However, their application in the domain of code and compiler optimization remains underexplored. Training LLMs is resource-intensive, requiring substantial GPU hours and extensive data collection, which can be prohibitive. To address this gap, we introduce LLM&nbsp;Compiler, a suite of robust, openly available, pre-trained models specifically designed for compiler tasks. Built on the foundation of Code&nbsp;Llama, LLM&nbsp;Compiler enhances the understanding of compiler intermediate representations (IRs), assembly language, and optimization techniques. The models have been trained on a vast corpus of 546 billion tokens of LLVM-IR and assembly code and have undergone instruction fine-tuning to interpret compiler behavior.    To demonstrate the utility of these research tools, we also present fine-tuned versions of the models with enhanced capabilities in optimizing code size and disassembling from x86_64 and ARM assembly back into LLVM-IR. These achieve 77% of the optimising potential of an autotuning search, and 45% disassembly round trip (14% exact match).    LLM&nbsp;Compiler is released under a bespoke commercial license to allow wide reuse and is available in two sizes: 7 billion and 13 billion parameters. Our aim is to provide scalable, cost-effective foundational models for further research and development in compiler optimization by both academic researchers and industry practitioners. Since we released LLM&nbsp;Compiler the community has quantized, repackaged, and downloaded the models over 250k times.},
booktitle = {Proceedings of the 34th ACM SIGPLAN International Conference on Compiler Construction},
pages = {141–153},
numpages = {13},
keywords = {Code Optimization, Compiler Optimization, LLVM-IR, Large Language Models, Pre-trained Models},
location = {Las Vegas, NV, USA},
series = {CC '25}
}

@inproceedings{10.1145/3625549.3658689,
author = {Nichols, Daniel and Davis, Joshua H. and Xie, Zhaojun and Rajaram, Arjun and Bhatele, Abhinav},
title = {Can Large Language Models Write Parallel Code?},
year = {2024},
isbn = {9798400704130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625549.3658689},
doi = {10.1145/3625549.3658689},
abstract = {Large language models are increasingly becoming a popular tool for software development. Their ability to model and generate source code has been demonstrated in a variety of contexts, including code completion, summarization, translation, and lookup. However, they often struggle to generate code for complex programs. In this paper, we study the capabilities of state-of-the-art language models to generate parallel code. In order to evaluate language models,we create a benchmark, ParEval, consisting of prompts that represent 420 different coding tasks related to scientific and parallel computing. We use ParEval to evaluate the effectiveness of several state-of-the-art open- and closed-source language models on these tasks. We introduce novel metrics for evaluating the performance of generated code, and use them to explore how well each large language model performs for 12 different computational problem types and six different parallel programming models.},
booktitle = {Proceedings of the 33rd International Symposium on High-Performance Parallel and Distributed Computing},
pages = {281–294},
numpages = {14},
keywords = {large language models, parallel code generation, performance evaluation, benchmarking, HPC},
location = {Pisa, Italy},
series = {HPDC '24}
}

@inproceedings{10.1145/3657604.3662042,
author = {Kumar, Harsh and Xiao, Ruiwei and Lawson, Benjamin and Musabirov, Ilya and Shi, Jiakai and Wang, Xinyuan and Luo, Huayin and Williams, Joseph Jay and Rafferty, Anna N. and Stamper, John and Liut, Michael},
title = {Supporting Self-Reflection at Scale with Large Language Models: Insights from Randomized Field Experiments in Classrooms},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662042},
doi = {10.1145/3657604.3662042},
abstract = {Self-reflection on learning experiences constitutes a fundamental cognitive process, essential for consolidating knowledge and enhancing learning efficacy. However, traditional methods to facilitate reflection often face challenges in personalization, immediacy of feedback, engagement, and scalability. Integration of Large Language Models (LLMs) into the reflection process could mitigate these limitations. In this paper, we conducted two randomized field experiments in undergraduate computer science courses to investigate the potential of LLMs to help students engage in post-lesson reflection. In the first experiment (N=145), students completed a take-home assignment with the support of an LLM assistant; half of these students were then provided access to an LLM designed to facilitate self-reflection. The results indicated that the students assigned to LLM-guided reflection reported somewhat increased self-confidence compared to peers in a no-reflection control and a non-significant trend towards higher scores on a later assessment. Thematic analysis of students' interactions with the LLM showed that the LLM often affirmed the student's understanding, expanded on the student's reflection, and prompted additional reflection; these behaviors suggest ways LLM-interaction might facilitate reflection. In the second experiment (N=112), we evaluated the impact of LLM-guided self-reflection against other scalable reflection methods, such as questionnaire-based activities and review of key lecture slides, after assignment. Our findings suggest that the students in the questionnaire and LLM-based reflection groups performed equally well and better than those who were only exposed to lecture slides, according to their scores on a proctored exam two weeks later on the same subject matter. These results underscore the utility of LLM-guided reflection and questionnaire-based activities in improving learning outcomes. Our work highlights that focusing solely on the accuracy of LLMs can overlook their potential to enhance metacognitive skills through practices such as self-reflection. We discuss the implications of our research for the learning-at-scale community, highlighting the potential of LLMs to enhance learning experiences through personalized, engaging, and scalable reflection practices.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {86–97},
numpages = {12},
keywords = {field experiments, human-ai collaboration, large language models, learning engineering, self-reflection},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3687123.3698286,
author = {Gramacki, Piotr and Martins, Bruno and Szyma\'{n}ski, Piotr},
title = {Evaluation of Code LLMs on Geospatial Code Generation},
year = {2024},
isbn = {9798400711763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687123.3698286},
doi = {10.1145/3687123.3698286},
abstract = {Software development support tools have been studied for a long time, with recent approaches using Large Language Models (LLMs) for code generation. These models can generate Python code for data science and machine learning applications. LLMs are helpful for software engineers because they increase productivity in daily work. An LLM can also serve as a "mentor" for inexperienced software developers, and be a viable learning support. High-quality code generation with LLMs can also be beneficial in geospatial data science. However, this domain poses different challenges, and code generation LLMs are typically not evaluated on geospatial tasks. Here, we show how we constructed an evaluation benchmark for code generation models, based on a selection of geospatial tasks. We categorised geospatial tasks based on their complexity and required tools. Then, we created a dataset with tasks that test model capabilities in spatial reasoning, spatial data processing, and geospatial tools usage. The dataset consists of specific coding problems that were manually created for high quality. For every problem, we proposed a set of test scenarios that make it possible to automatically check the generated code for correctness. In addition, we tested a selection of existing code generation LLMs for code generation in the geospatial domain. We share our dataset and reproducible evaluation code on a public GitHub repository1, arguing that this can serve as an evaluation benchmark for new LLMs in the future. Our dataset will hopefully contribute to the development new models capable of solving geospatial coding tasks with high accuracy. These models will enable the creation of coding assistants tailored for geospatial applications.},
booktitle = {Proceedings of the 7th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {54–62},
numpages = {9},
keywords = {code generation, geospatial data science, large language models},
location = {Atlanta, GA, USA},
series = {GeoAI '24}
}

@inproceedings{10.1145/3626253.3635369,
author = {MacNeil, Stephen and Leinonen, Juho and Denny, Paul and Kiesler, Natalie and Hellas, Arto and Prather, James and Becker, Brett A. and Wermelinger, Michel and Reid, Karen},
title = {Discussing the Changing Landscape of Generative AI in Computing Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635369},
doi = {10.1145/3626253.3635369},
abstract = {In a previous Birds of a Feather discussion, we delved into the nascent applications of generative AI, contemplating its potential and speculating on future trajectories. Since then, the landscape has continued to evolve revealing the capabilities and limitations of these models. Despite this progress, the computing education research community still faces uncertainty around pivotal aspects such as (1) academic integrity and assessments, (2) curricular adaptations, (3) pedagogical strategies, and (4) the competencies students require to instill responsible use of these tools. The goal of this Birds of a Feather discussion is to unravel these pressing and persistent issues with computing educators and researchers, fostering a collaborative exploration of strategies to navigate the educational implications of advancing generative AI technologies. Aligned with this goal of building an inclusive learning community, our BoF is led by globally distributed leaders to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of LLMs in CS education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1916},
numpages = {1},
keywords = {academic integrity, assessment, computing education, curriculum, large language models, pedagogy},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3691621.3694934,
author = {Siddiq, Mohammed Latif and da Silva Santos, Joanna Cecilia and Devareddy, Sajith and Muller, Anna},
title = {SALLM: Security Assessment of Generated Code},
year = {2024},
isbn = {9798400712494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691621.3694934},
doi = {10.1145/3691621.3694934},
abstract = {With the growing popularity of Large Language Models (LLMs) in software engineers' daily practices, it is important to ensure that the code generated by these tools is not only functionally correct but also free of vulnerabilities. Although LLMs can help developers to be more productive, prior empirical studies have shown that LLMs can generate insecure code. There are two contributing factors to the insecure code generation. First, existing datasets used to evaluate LLMs do not adequately represent genuine software engineering tasks sensitive to security. Instead, they are often based on competitive programming challenges or classroom-type coding tasks. In real-world applications, the code produced is integrated into larger codebases, introducing potential security risks. Second, existing evaluation metrics primarily focus on the functional correctness of the generated code while ignoring security considerations. Therefore, in this paper, we described Sallm, a framework to benchmark LLMs' abilities to generate secure code systematically. This framework has three major components: a novel dataset of security-centric Python prompts, configurable assessment techniques to evaluate the generated code, and novel metrics to evaluate the models' performance from the perspective of secure code generation.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering Workshops},
pages = {54–65},
numpages = {12},
keywords = {security evaluation, large language models, pre-trained transformer model, metrics},
location = {Sacramento, CA, USA},
series = {ASEW '24}
}

@article{10.1145/3697010,
author = {Ouyang, Shuyin and Zhang, Jie M. and Harman, Mark and Wang, Meng},
title = {An Empirical Study of the Non-Determinism of ChatGPT in Code Generation},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3697010},
doi = {10.1145/3697010},
abstract = {There has been a recent explosion of research on Large Language Models (LLMs) for software engineering tasks, in particular code generation. However, results from LLMs can be highly unstable; non-deterministically returning very different code for the same prompt. Such non-determinism affects the correctness and consistency of the generated code, undermines developers’ trust in LLMs, and yields low reproducibility in LLM-based papers. Nevertheless, there is no work investigating how serious this non-determinism threat is.To fill this gap, this article conducts an empirical study on the non-determinism of ChatGPT in code generation. We chose to study ChatGPT because it is already highly prevalent in the code generation research literature. We report results from a study of 829 code generation problems across three code generation benchmarks (i.e., CodeContests, APPS and HumanEval) with three aspects of code similarities: semantic similarity, syntactic similarity, and structural similarity. Our results reveal that ChatGPT exhibits a high degree of non-determinism under the default setting: the ratio of coding tasks with zero equal test output across different requests is 75.76%, 51.00% and 47.56% for three different code generation datasets (i.e., CodeContests, APPS and HumanEval), respectively. In addition, we find that setting the temperature to 0 does not guarantee determinism in code generation, although it indeed brings less non-determinism than the default configuration (temperature  (=)  1). In order to put LLM-based research on firmer scientific foundations, researchers need to take into account non-determinism in drawing their conclusions.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
articleno = {42},
numpages = {28},
keywords = {code generation, non-determinism, large language model}
}

@inproceedings{10.1145/3671016.3674821,
author = {Liang, Wenjun and Xiao, Guanping},
title = {An Exploratory Evaluation of Large Language Models Using Empirical Software Engineering Tasks},
year = {2024},
isbn = {9798400707056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671016.3674821},
doi = {10.1145/3671016.3674821},
abstract = {In empirical software engineering (EMSE), various activities require human participation, such as data collection, processing, analysis, and comprehension. On one hand, these processes are time-consuming and labor-intensive. On the other hand, human participation may introduce bias. With the rise of large language models (LLMs) like ChatGPT, the potential for these models to enhance productivity has become apparent. However, the auxiliary capabilities and effectiveness of LLMs in EMSE tasks have rarely been explored. To fill this gap, in this paper, we evaluate the performance of LLMs by using scenarios of human participation in EMSE tasks, i.e., EMSEBench. We conduct replication experiments using four LLMs (ChatGPT4.0, ERNIE Bot4.0, Gemini3.0, and ChatGLM4.0), evaluating the difference in performance across seven scenarios collected from papers published in top SE venues. In the experiments, we perform three types of prompts, i.e., zero-shot, one-shot, and optimized one-shot. Besides, we leverage the concept of multi-agent workflow to explore the performance improvement and limitations of LLMs. Our study summarizes six findings, which facilitate the understanding of the auxiliary of LLMs in EMSE tasks.},
booktitle = {Proceedings of the 15th Asia-Pacific Symposium on Internetware},
pages = {31–40},
numpages = {10},
keywords = {empirical software engineering tasks, evaluation benchmark, large language models},
location = {Macau, China},
series = {Internetware '24}
}

@inproceedings{10.1145/3702163.3702188,
author = {Schefer-Wenzl, Sigrid and Vogl, Christoph and Peiris, Sahani and Miladinovic, Igor},
title = {Exploring the Adoption of Generative AI Tools in Computer Science Education: A Student Survey},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702188},
doi = {10.1145/3702163.3702188},
abstract = {The integration of generative AI tools into education has the potential to revolutionize learning experiences, particularly in computer science. This paper explores the adoption and utilization of generative AI tools among computer science students at the University of Applied Sciences Campus Vienna in Austria through a comprehensive survey. The study aims to understand the extent to which AI tools like ChatGPT are integrated into students' academic routines, their perceptions of these tools, and the challenges and opportunities they present. The survey results indicate a high level of acceptance and frequent use of AI tools for tasks such as programming, exam preparation, and generating simplified explanations. However, concerns about the accuracy of AI-generated content and the potential impact on critical thinking skills were also highlighted. The findings underscore the need for clear institutional guidelines and ethical considerations in the use of AI tools in education. This paper contributes to the growing body of literature on AI in education and provides insights for educators and policymakers to enhance the responsible integration of AI technologies in computer science curricula.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {173–178},
numpages = {6},
keywords = {Artificial Intelligence, Computer Science Education, Generative AI Tools, Higher Education},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3716640.3716652,
author = {Edwards, John and Hellas, Arto and Leinonen, Juho},
title = {On the Opportunities of Large Language Models for Programming Process Data},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716652},
doi = {10.1145/3716640.3716652},
abstract = {Computing educators and researchers have long used programming process data to understand how students construct programs and address challenges. Despite its potential, fully automated feedback systems remain underexplored. The emergence of Large Language Models (LLMs) offers new opportunities for analyzing programming data and providing formative feedback. This study explores using LLMs to summarize programming processes and deliver formative feedback. A case study analyzed keystroke-level data from an introductory programming course, processed into code snapshots. Three state-of-the-art LLMs – Claude 3 Opus, GPT-4 Turbo, and LLaMa2 70B Chat – were evaluated for their feedback capabilities. Results show LLMs effectively provide tailored feedback, emphasizing incremental development, algorithmic planning, and code readability. Our findings highlight the potential of combining keystroke data with LLMs to automate formative feedback, showing that the computing education research and practice community is again one step closer to automating formative programming process feedback.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {105–113},
numpages = {9},
keywords = {programming process data, large language models, generative AI, programming process feedback, programming process summarization, keystroke data},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3643991.3645069,
author = {Wu, Liangxuan and Zhao, Yanjie and Hou, Xinyi and Liu, Tianming and Wang, Haoyu},
title = {ChatGPT Chats Decoded: Uncovering Prompt Patterns for Superior Solutions in Software Development Lifecycle},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645069},
doi = {10.1145/3643991.3645069},
abstract = {The advent of Large Language Models (LLMs) like ChatGPT has markedly transformed software development, aiding tasks from code generation to issue resolution with their human-like text generation. Nevertheless, the effectiveness of these models greatly depends on the nature of the prompts given by developers. Therefore, this study delves into the DevGPT dataset, a rich collection of developer-ChatGPT dialogues, to unearth the patterns in prompts that lead to effective problem resolutions. The underlying motivation for this research is to enhance the collaboration between human developers and AI tools, thereby improving productivity and problem-solving efficacy in software development. Utilizing a combination of textual analysis and data-driven approaches, this paper seeks to identify the attributes of prompts that are associated with successful interactions, providing crucial insights for the strategic employment of ChatGPT in software engineering environments.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {142–146},
numpages = {5},
keywords = {data mining, large language model, LLM, ChatGPT},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3641554.3701827,
author = {Renzella, Jake and Vassar, Alexandra and Lee Solano, Lorenzo and Taylor, Andrew},
title = {Compiler-Integrated, Conversational AI for Debugging CS1 Programs},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701827},
doi = {10.1145/3641554.3701827},
abstract = {Large Language Models (LLMs) present a transformative opportunity to address longstanding challenges in computing education. This paper presents a conversational AI extension to an LLM-enhanced C/C++ compiler which generates pedagogically sound programming error explanations. Our new tool, DCC Sidekick, retains compiler integration, allowing students to see their code, error messages, and stack frames alongside a conversational AI interface. Compiler context improves error explanations, and provides a seamless development experience. We present quantitative analyses of Sidekick's usage and engagement patterns in a large CS1 course. In the first seven weeks of use, 959 students initiated 11,222 DCC Sidekick sessions, generating 17,982 error explanations. Over half of all conversations occur outside of business hours, highlighting the value of these always-available tools. Early results indicate strong adoption of conversational AI debugging tools, demonstrating scalability in supporting large CS1 courses. We share implementation details and lessons learned, offering guidance to educators considering integrating AI tools with pedagogical guardrails.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {994–1000},
numpages = {7},
keywords = {ai in education, cs1, generative ai, programming error messages},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626253.3635609,
author = {Mitra, Chancharik and Miroyan, Mihran and Jain, Rishi and Kumud, Vedant and Ranade, Gireeja and Norouzi, Narges},
title = {Elevating Learning Experiences: Leveraging Large Language Models as Student-Facing Assistants in Discussion Forums},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635609},
doi = {10.1145/3626253.3635609},
abstract = {Recent advancements in instruction-tuned large language models offer new potential for enhancing students' experiences in large-scale classes. Deploying LLMs as student-facing assistants, however, presents challenges. Key issues include integrating class-specific content into responses and applying effective pedagogical techniques. This study addresses these challenges through retrieval and prompting techniques, focusing on mitigating hallucinations in LLM-generated responses, a crucial concern in education. Furthermore, practical deployment brings further challenges related to student data privacy and computational constraints. This research strives to enhance the quality and relevance of LLM responses while addressing practical deployment issues, with an emphasis on creating a versatile system for diverse domains and teaching styles.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1752–1753},
numpages = {2},
keywords = {discussion forum, educational tools, natural language processing},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641555.3705195,
author = {Marwan, Samiha and Ibrahim, Mohamed and Morrison, Briana},
title = {How Good are Large Language Models at Generating Subgoal Labels?},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705195},
doi = {10.1145/3641555.3705195},
abstract = {The use of subgoal labels in introduction to programming classrooms has been shown to improve student performance, learning, retention, and reduce students' drop out rates. However, creating and adding subgoal labels to programming assignments is often hard to articulate and very time-intensive for instructors. In Computing Education Research, Large Language Models (LLMs) have been widely used to generate human-like outputs such as worked examples and source code. In this work, we explore whether ChatGPT could be used to generate high-quality and appropriate subgoal labels in two programming curricula. Our qualitative data analysis suggests that LLMs can assist instructors in creating subgoal labels in their classrooms, opening up directions to empower students' learning experience in programming classrooms.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1541–1542},
numpages = {2},
keywords = {large language models, subgoal labels, subgoals},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626252.3630784,
author = {Rogers, Michael P. and Hillberg, Hannah Miller and Groves, Christopher L.},
title = {Attitudes Towards the Use (and Misuse) of ChatGPT: A Preliminary Study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630784},
doi = {10.1145/3626252.3630784},
abstract = {ChatGPT is the front end to a powerful large language model that has garnered widespread attention in many fields of study, including computer science (CS), where it promises to be transformational. As educators, we are just starting to grapple with the ramifications of this new technology, including implications for what we teach, how we teach, and how we grade. The decisions educators make moving forward depend heavily on the prevalence of students' use (and misuse) of ChatGPT in the classroom. Further, predictors of nefarious use could aid educators as well. We conducted an online survey to capture CS student awareness of, experience with, and attitudes toward ChatGPT. Through quantitative and qualitative analysis, we found that awareness of ChatGPT is generally high, and it is more frequently being used as a study tool than to complete students' work for them. Most students are aware of the potential for abuse in academic pursuits, but a notable minority of students admit to using it unscrupulously and to the potential for it to interfere with their learning. We conclude with a discussion of factors to consider as educators modify their approaches and develop guidelines for ChatGPT usage in their classrooms.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1147–1153},
numpages = {7},
keywords = {academic misconduct, artificial intelligence, chatgpt, large language models, student survey},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3597503.3639585,
author = {Imran, Mia Mohammad and Chatterjee, Preetha and Damevski, Kostadin},
title = {Shedding Light on Software Engineering-specific Metaphors and Idioms},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639585},
doi = {10.1145/3597503.3639585},
abstract = {Use of figurative language, such as metaphors and idioms, is common in our daily-life communications, and it can also be found in Software Engineering (SE) channels, such as comments on GitHub. Automatically interpreting figurative language is a challenging task, even with modern Large Language Models (LLMs), as it often involves subtle nuances. This is particularly true in the SE domain, where figurative language is frequently used to convey technical concepts, often bearing developer affect (e.g., 'spaghetti code). Surprisingly, there is a lack of studies on how figurative language in SE communications impacts the performance of automatic tools that focus on understanding developer communications, e.g., bug prioritization, incivility detection. Furthermore, it is an open question to what extent state-of-the-art LLMs interpret figurative expressions in domain-specific communication such as software engineering. To address this gap, we study the prevalence and impact of figurative language in SE communication channels. This study contributes to understanding the role of figurative language in SE, the potential of LLMs in interpreting them, and its impact on automated SE communication analysis. Our results demonstrate the effectiveness of fine-tuning LLMs with figurative language in SE and its potential impact on automated tasks that involve affect. We found that, among three state-of-the-art LLMs, the best improved fine-tuned versions have an average improvement of 6.66% on a GitHub emotion classification dataset, 7.07% on a GitHub incivility classification dataset, and 3.71% on a Bugzilla bug report prioritization dataset.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {207},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3661167.3661183,
author = {Watanabe, Miku and Kashiwa, Yutaro and Lin, Bin and Hirao, Toshiki and Yamaguchi, Ken'Ichi and Iida, Hajimu},
title = {On the Use of ChatGPT for Code Review: Do Developers Like Reviews By ChatGPT?},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661183},
doi = {10.1145/3661167.3661183},
abstract = {Code review is a critical but time-consuming process for ensuring code quality in modern software engineering. To alleviate the effort of reviewing source code, recent studies have investigated the possibility of automating the review process. Moreover, tools based on large language models such as ChatGPT are playing an increasingly important role in this vision. Understanding how these tools are used during code review can provide valuable insights for code review automation. This study investigates for what purposes developers use ChatGPT during code review and how developers react to the information and suggestions provided by ChatGPT. We manually analyze 229 review comments in 205 pull requests from 179 projects. We find that developers often use ChatGPT for outsourcing their work as frequently as asking for references. Moreover, we observe that only 30.7% of responses to the answers provided by ChatGPT are negative. We further analyze the reasons behind the negative reactions. Our results provide valuable insights for improving the effectiveness of LLMs in code reviews.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {375–380},
numpages = {6},
keywords = {ChatGPT, Code Review, Empirical Study},
location = {Salerno, Italy},
series = {EASE '24}
}

@article{10.1145/3688089,
author = {Zhou, Kyrie Zhixuan and Kilhoffer, Zachary and Sanfilippo, Madelyn Rose and Underwood, Ted and Gumusel, Ece and Wei, Mengyi and Choudhry, Abhinav and Xiong, Jinjun},
title = {Ethics, Governance, and User Mental Models for Large Language Models in Computing Education},
year = {2024},
issue_date = {Fall 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1528-4972},
url = {https://doi.org/10.1145/3688089},
doi = {10.1145/3688089},
abstract = {Large language models like ChatGPT are disrupting many industries, including computing education. How should policy evolve to improve learning outcomes?},
journal = {XRDS},
month = oct,
pages = {46–51},
numpages = {6}
}

@inproceedings{10.1145/3641555.3705277,
author = {Tsang, Jedidiah and Li, Carol and Park, Su Min and Yan, Lisa},
title = {Using LLMs to Detect the Presence of Learning Outcomes in Submitted Work Within Computing Ethics Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705277},
doi = {10.1145/3641555.3705277},
abstract = {This study investigates how large language models (LLMs) can identify the presence of learning outcomes within student submitted work in a computing ethics course. To do so, we craft a codebook to spot key learning outcomes, such as the usage of critical reasoning and awareness of various social issues. We leverage the GPT-4o and GPT-3.5-turbo LLMs to apply codes onto 8,500 pieces of student submitted work. We then use Cohen's kappa to assess interrater reliability and compare human reviewers' coding to outputs from those models, finding that GPT-4o performed just as well as the agreement between human reviewers. We then use the model outputs to identify specific course readings that students engaged particularly deeply with to better inform our computing ethics instruction.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1641–1642},
numpages = {2},
keywords = {codebook, computing ethics, critical consciousness, large language models, positionality},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3643991.3648400,
author = {Xiao, Tao and Treude, Christoph and Hata, Hideaki and Matsumoto, Kenichi},
title = {DevGPT: Studying Developer-ChatGPT Conversations},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3648400},
doi = {10.1145/3643991.3648400},
abstract = {This paper introduces DevGPT, a dataset curated to explore how software developers interact with ChatGPT, a prominent large language model (LLM). The dataset encompasses 29,778 prompts and responses from ChatGPT, including 19,106 code snippets, and is linked to corresponding software development artifacts such as source code, commits, issues, pull requests, discussions, and Hacker News threads. This comprehensive dataset is derived from shared ChatGPT conversations collected from GitHub and Hacker News, providing a rich resource for understanding the dynamics of developer interactions with ChatGPT, the nature of their inquiries, and the impact of these interactions on their work. DevGPT enables the study of developer queries, the effectiveness of ChatGPT in code generation and problem solving, and the broader implications of AI-assisted programming. By providing this dataset, the paper paves the way for novel research avenues in software engineering, particularly in understanding and improving the use of LLMs like ChatGPT by developers.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {227–230},
numpages = {4},
keywords = {ChatGPT, LLM, generative AI, dataset},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@article{10.1145/3736407,
author = {Weyssow, Martin and Kamanda, Aton and Zhou, Xin and Sahraoui, Houari},
title = {CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3736407},
doi = {10.1145/3736407},
abstract = {Evaluating the alignment of large language models (LLMs) with user-defined coding preferences is a challenging endeavor that requires a deep assessment of LLMs’ outputs. Existing methods and benchmarks rely primarily on automated metrics and static analysis tools, which often fail to capture the nuances of user instructions and LLM outputs. To address this gap, we introduce the LLM-as-a-Judge evaluation framework and present CodeUltraFeedback, a comprehensive dataset for assessing and improving LLM alignment with coding preferences. CodeUltraFeedback consists of 10,000 coding instructions, each annotated with four responses generated from a diverse pool of 14 LLMs. These responses are annotated using GPT-3.5 as a judge, with both ranking-based scores and detailed textual feedback across five distinct coding preferences. Our analysis reveals that responses from GPT-3.5 and GPT-4 are consistently rated higher than those from open-weight models, underscoring substantial alignment gaps between closed- and open-weight LLMs. In turn, we explore the usage of CodeUltraFeedback as feedback data to fine-tune and align CodeLlama-7B-Instruct using supervised fine-tuning (SFT) and reinforcement learning from AI feedback (RLAIF) with direct preference optimization (DPO). The resulting aligned model achieves an average alignment improvement of 22.7% and 29.7% when evaluated with GPT-3.5 and GPT-4 judges, respectively. Notably, our aligned CodeLlama-7B-Instruct surpasses much larger models, such as CodeLlama-13B and 34B, in alignment with coding preferences. Despite not being explicitly trained for functional correctness, it also achieves a 10.5% and 26.6% relative improvement in Pass@ (1)  and Pass@ (10)  on the HumanEval+ benchmark. Our contributions demonstrate the practical value of preference tuning in code generation and set the stage for further progress in model alignment and RLAIF for automated software engineering.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Large language models, code generation, automated software engineering, reinforcement learning from AI feedback, direct preference optimization, LLM-as-a-Judge}
}

@inproceedings{10.1145/3641555.3704765,
author = {Liu, Rongxin and Malan, David J. and Zhukovets, Yuliia and Lloyd, Doug},
title = {Teaching with AI (GPT)},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704765},
doi = {10.1145/3641555.3704765},
abstract = {Teaching computer science at scale can be challenging. From our experience in CS50, Harvard University's introductory course, we've seen firsthand the impactful role that generative artificial intelligence can play in education. Recognizing its potential and stakes, we integrated OpenAI's GPT into our own teaching methodology. The goal was to emulate a 1:1 teacher-to-student ratio, incorporating "pedagogical guardrails" to maintain instructional integrity. The result was a personalized, AI-powered bot in the form of a friendly rubber duck aimed at delivering instructional responses and troubleshooting without giving outright solutions. In this tutorial, we share our journey and offer insights into responsibly harnessing AI in educational settings. Participants will gain hands-on experience working with GPT through OpenAI's latest APIs, understanding and crafting prompts, answering questions using embedding-based search, and finally, collaboratively building their own AI chatbot. Ultimately, we'll not only share lessons learned from our own approach but also equip educators hands-on with the knowledge and tools with which they, too, can implement these technologies in their unique teaching environments.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1773},
numpages = {1},
keywords = {AI, AI ethics, ChatGPT, GPT, generative AI, programming, prompt, prompt engineering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626253.3633418,
author = {Gunawardena, Ananda and Chaturvedi, Naina},
title = {AI Enhanced Learning: Powering Curated Videos with Generative Intelligence},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633418},
doi = {10.1145/3626253.3633418},
abstract = {Instructional videos are becoming increasingly popular among computer science students. Over 78% of students frequently visit YouTube to find videos as supplement to their textbook or classroom instruction[1]. Recent surveys show that on average, 73% of students prefer having their instructors curate a supplemental video library to aid in their learning. Now, the emergence of generative AI is revolutionizing supplemental video instruction, enabling instructors to generate slides, recording scripts, and produce high-quality videos with deep search and embedded interactive activities.Generative AI also takes the student video learning to a new level by providing AI-generated video summaries, on-demand questions, and exploration of topics in greater depth. Integrating AI into standard videos greatly expands the possibilities of video-based learning. This workshop demonstrates how educators can enhance their existing video playlists by incorporating AI to increase student engagement and establish safety measures for AI use in education. By using dynamic dashboards, scheduled content, and gamified questions, instructors can maintain student focus.Drawing on insights from computer science courses taught at Princeton and Rutgers Universities, we will highlight the transformative potential of AI-enhanced videos in promoting active learning, particularly in large classes. We will discuss engagement strategies and real-time data visualizations applicable to any video platform. We will utilize the cubits.ai[2] platform, a Princeton University initiative that enhances the impact of computer science courses. The platform is free, and participants are encouraged to bring their own video playlists to curate them into AI-enabled collections by enhancing the student experience through integrated generative AI.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1898},
numpages = {1},
keywords = {ai generated content, contextualized generative ai, cost-effective videos, customized videos, data-driven insights, instructional videos, video summarization},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@proceedings{10.1145/3580305,
title = {KDD '23: Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining KDD 2023. This year's conference continues its tradition of being the premier forum for presentation of research results and experience reports on leading edge issues of knowledge discovery, data science, and machine learning. The mission of the conference is to provide the premier forum for advancement, education, and adoption of the "science" of knowledge discovery and machine learning from all types of data; to share novel methodologies that fulfill the needs of heterogeneous applications and environments and identify new directions for future research and development. These ideas have the potential to shape and impact our society and environment, and are becoming particularly important with the emergence of AI in all fields. KDD provides researchers and practitioners a unique opportunity to share their perspectives with others interested in various aspects of data science and machine learning.KDD '23 has a program of three keynotes, 313 research track papers, 184 ADS (Applied Data Science) track papers, 34 workshops, 33 tutorials, nine special days, three panels, and eight ADS invited talks. For the first time, we switched to OpenReview with the mission to further improve the review quality and facilitate the interaction between reviewers and authors. We have introduced several new special days, such as Large Language Model (LLM) Day, Finance Day, AI for Open Society Day, Entertainment, Sports, and Media (ESM) Day, Southern California Data Science; and several new panels, such as AI for Science and LLMs for education &amp; research. The rise of LLMs has been historic and the nature of creativity itself may change. With this in mind, we have emphasized LLMs in our keynotes, special days, and panels. Only time will tell whether we went too far or not far enough!},
location = {Long Beach, CA, USA}
}

@inproceedings{10.1145/3649217.3653624,
author = {Grande, Virginia and Kiesler, Natalie and Francisco R., Mar\'{\i}a Andre\'{\i}na},
title = {Student Perspectives on Using a Large Language Model (LLM) for an Assignment on Professional Ethics},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653624},
doi = {10.1145/3649217.3653624},
abstract = {The advent of Large Language Models (LLMs) started a serious discussion among educators on how LLMs would affect, e.g., curricula, assessments, and students' competencies. Generative AI and LLMs also raised ethical questions and concerns for computing educators and professionals.This experience report presents an assignment within a course on professional competencies, including some related to ethics, that computing master's students need in their careers. For the assignment, student groups discussed the ethical process by Lennerfors et al. by analyzing a case: a fictional researcher considers whether to attend the real CHI 2024 conference in Hawaii. The tasks were (1) to participate in in-class discussions on the case, (2) to use an LLM of their choice as a discussion partner for said case, and (3) to document both discussions, reflecting on their use of the LLM.Students reported positive experiences with the LLM as a way to increase their knowledge and understanding, although some identified limitations. The LLM provided a wider set of options for action in the studied case, including unfeasible ones. The LLM would not select a course of action, so students had to choose themselves, which they saw as coherent.From the educators' perspective, there is a need for more instruction for students using LLMs: some students did not perceive the tools as such but rather as an authoritative knowledge base. Therefore, this work has implications for educators considering the use of LLMs as discussion partners or tools to practice critical thinking, especially in computing ethics education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {478–484},
numpages = {7},
keywords = {chatgpt, ethics, experience report, large language models, llms, student perspective},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3657604.3664699,
author = {Hutt, Stephen and Hieb, Grayson},
title = {Scaling Up Mastery Learning with Generative AI: Exploring How Generative AI Can Assist in the Generation and Evaluation of Mastery Quiz Questions},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664699},
doi = {10.1145/3657604.3664699},
abstract = {Generative AI has the potential to scale a number of educational practices, previously limited by resources. One such instructional approach is mastery learning, a pedagogy emphasizing proficiency before progression that is highly resource (teacher time, materials) intensive. The rise of computer-based instruction offered partial solutions, tailoring student progression and automating some facets of the mastery learning process. This work in progress considers the application of large language models for content generation tailored to mastery learning. We present a paired framework for analyzing and evaluating the generated content relative to rubrics designed by the teacher. Recognizing the potential of large language models, we critically assess the potential of improving mastery-based instruction. We close our discussion by considering the applications and limitations of this approach.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {310–314},
numpages = {5},
keywords = {content evaluation, content generation, generative ai, large language models, mastery learning},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3644815.3644946,
author = {Li, Ziyu and Shin, Donghwan},
title = {Mutation-based Consistency Testing for Evaluating the Code Understanding Capability of LLMs},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644946},
doi = {10.1145/3644815.3644946},
abstract = {Large Language Models (LLMs) have shown remarkable capabilities in processing both natural and programming languages, which have enabled various applications in software engineering, such as requirement engineering, code generation, and software testing. However, existing code generation benchmarks do not necessarily assess the code understanding performance of LLMs, especially for the subtle inconsistencies that may arise between code and its semantics described in natural language.In this paper, we propose a novel method, called Mutation-based Consistency Testing (MCT), to systematically assess the code understanding performance of LLMs, particularly focusing on subtle differences between code and its descriptions, by introducing code mutations to existing code generation datasets. Code mutations are small changes that alter the semantics of the original code, creating a mismatch with the natural language description. MCT uses different types of code mutations, such as operator replacement and statement deletion, to generate inconsistent code-description pairs. MCT then uses these pairs to test the ability of LLMs to detect the inconsistencies correctly.We conduct a case study on the two popular LLMs, GPT-3.5 and GPT-4, using the state-of-the-art code generation benchmark, HumanEval-X, which consists of 164 programming problems written in six programming languages (Python, C++, Java, Go, JavaScript, and Rust). The results show that the LLMs have significant variations in their code understanding performance and that they have different strengths and weaknesses depending on the mutation type and language. We further explain conditions under which the LLMs result in correct answers using input characteristics (e.g., number of tokens) and investigate to what extent the test results can be improved using one-shot prompts (i.e., providing an additional example). Our MCT method and the case study results provide valuable implications for future research and development of LLM-based software engineering.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {150–159},
numpages = {10},
keywords = {large language models, software engineering, mutation analysis},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3626253.3635380,
author = {Veilleux, Nanette and Bates, Rebecca and Goldsmith, Judy and Summet, Valerie},
title = {Mentoring, AI, and the End of Affirmative Action: Connecting with SIGCSE Reads},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635380},
doi = {10.1145/3626253.3635380},
abstract = {This Birds of a Feather will begin with a high-level overview of the SIGCSE Reads 2024 books and then quickly move to discussion about mentoring students in the era of large language models and ChatGPT, including how students may value the curriculum differently, how learning outcomes may change, and how we can support students and alumni/ae as they work with rapidly changing job and learning expectations. We expect that many of the sessions at SIGCSE will address the radical shifts in learning outcomes and curricular changes due to LLMs. We will not focus on the particulars of these changes, but rather on mentoring in this time with Sister Resisters: Mentoring Black Women on Campus by Janie Victoria Ward and Tracy L. Robinson-Wood as a resource. How do we guide our students through the curriculum upheaval triggered by shifting learning outcomes? How do we help them prepare for the new instantiation of computer science?  This BOF is the primary session for SIGCSE Reads. We encourage discussion of this year's fiction works The Lifecycle of Software Objects by Ted Chiang and "Dolly" by Elizabeth Bear, as well as past Reads, throughout the conference.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1922},
numpages = {1},
keywords = {computing education, diversity in computing, mentoring, science fiction},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3643991.3645081,
author = {AlOmar, Eman Abdullah and Venkatakrishnan, Anushkrishna and Mkaouer, Mohamed Wiem and Newman, Christian and Ouni, Ali},
title = {How to refactor this code? An exploratory study on developer-ChatGPT refactoring conversations},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645081},
doi = {10.1145/3643991.3645081},
abstract = {Large Language Models (LLMs), like ChatGPT, have gained widespread popularity and usage in various software engineering tasks, including refactoring, testing, code review, and program comprehension. Despite recent studies delving into refactoring documentation in commit messages, issues, and code review, little is known about how developers articulate their refactoring needs when interacting with ChatGPT. In this paper, our goal is to explore conversations between developers and ChatGPT related to refactoring to better understand how developers identify areas for improvement in code and how ChatGPT addresses developers' needs. Our approach relies on text mining refactoring-related conversations from 17,913 ChatGPT prompts and responses, and investigating developers' explicit refactoring intention. Our results reveal that (1) developer-ChatGPT conversations commonly involve generic and specific terms/phrases; (2) developers often make generic refactoring requests, while ChatGPT typically includes the refactoring intention; and (3) various learning settings when prompting ChatGPT in the context of refactoring. We envision that our findings contribute to a broader understanding of the collaboration between developers and AI models.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {202–206},
numpages = {5},
keywords = {refactoring documentation, ChatGPT, mining software repositories},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3700410.3702126,
author = {Wang, Zhaode and Yang, Jingbang and Qian, Xinyu and Xing, Shiwen and Jiang, Xiaotang and Lv, Chengfei and Zhang, Shengyu},
title = {MNN-LLM: A Generic Inference Engine for Fast Large Language Model Deployment on Mobile Devices},
year = {2024},
isbn = {9798400713149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700410.3702126},
doi = {10.1145/3700410.3702126},
abstract = {Large language models (LLMs) have demonstrated exceptional performance across a variety of tasks. However, their substantial scale leads to significant computational resource consumption during inference, resulting in high costs. Consequently, edge device inference presents a promising solution. The primary challenges of edge inference include memory usage and inference speed. This paper introduces MNN-LLM, a framework specifically designed to accelerate the deployment of large language models on mobile devices. MNN-LLM addresses the runtime characteristics of LLMs through model quantization and DRAM-Flash hybrid storage, effectively reducing memory usage. It rearranges weights and inputs based on mobile CPU instruction sets and GPU characteristics while employing strategies such as multicore load balancing, mixed-precision floating-point operations, and geometric computations to enhance performance. Notably, MNN-LLM achieves up to a 8.6x speed increase compared to current mainstream LLM-specific frameworks.},
booktitle = {Proceedings of the 6th ACM International Conference on Multimedia in Asia Workshops},
articleno = {11},
numpages = {7},
location = {
},
series = {MMAsia '24 Workshops}
}

@inproceedings{10.1145/3674805.3690746,
author = {Almeida, Aylton and Xavier, Laerte and Valente, Marco Tulio},
title = {Automatic Library Migration Using Large Language Models: First Results},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690746},
doi = {10.1145/3674805.3690746},
abstract = {Despite being introduced only a few years ago, Large Language Models (LLMs) are already widely used by developers for code generation. However, their application in automating other Software Engineering activities remains largely unexplored. Thus, in this paper, we report the first results of a study in which we are exploring the use of ChatGPT to support API migration tasks, an important problem that demands manual effort and attention from developers. Specifically, in the paper, we share our initial results involving the use of ChatGPT to migrate a client application to use a newer version of SQLAlchemy, an ORM (Object Relational Mapping) library widely used in Python. We evaluate the use of three types of prompts (Zero-Shot, One-Shot, and Chain Of Thoughts) and show that the best results are achieved by the One-Shot prompt, followed by the Chain Of Thoughts. Particularly, with the One-Shot prompt we were able to successfully migrate all columns of our target application and upgrade its code to use new functionalities enabled by SQLAlchemy’s latest version, such as Python’s asyncio and typing modules, while preserving the original code behavior.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {427–433},
numpages = {7},
keywords = {API Migration, ChatGPT, Large Language Models, Python, SQLAlchemy},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3661167.3661207,
author = {S\'{a}godi, Zolt\'{a}n and Antal, G\'{a}bor and Bogenf\"{u}rst, Bence and Isztin, Martin and Hegedundefineds, P\'{e}ter and Ferenc, Rudolf},
title = {Reality Check: Assessing GPT-4 in Fixing Real-World Software Vulnerabilities},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661207},
doi = {10.1145/3661167.3661207},
abstract = {Discovering and mitigating software vulnerabilities is a challenging task. These vulnerabilities are often caused by simple, otherwise (and in other contexts) harmless code snippets (e.g., unchecked path traversal). Large Language Models (LLMs) promise to revolutionize not just human-machine interactions but various software engineering tasks as well, including the automatic repair of vulnerabilities. However, currently, it is hard to assess the performance, robustness, and reliability of these models as most of their evaluation has been done on small, synthetic examples. In our work, we systematically evaluate the automatic vulnerability fixing capabilities of GPT-4, a popular LLM, using a database of real-world Java vulnerabilities, Vul4J. We expect the model to provide fixes for vulnerable methods, which we evaluate manually and based on unit test results included in the Vul4J database. GPT-4 provided perfect fixes consistently for at least 12 out of the total 46 examined vulnerabilities, which could be applied as is. In an additional 5 cases, the provided textual instructions would help to fix the vulnerabilities in a practical scenario (despite the provided code being incorrect). Our findings, similar to others, also show that prompting has a significant effect.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {252–261},
numpages = {10},
keywords = {Automated program repair, GPT, Machine learning, Vulnerability fixing},
location = {Salerno, Italy},
series = {EASE '24}
}

@article{10.1145/3717512.3717515,
author = {Anwar, Mubashir and Caesar, Matthew},
title = {Understanding Misunderstandings: Evaluating LLMs on Networking Questions},
year = {2025},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/3717512.3717515},
doi = {10.1145/3717512.3717515},
abstract = {Large Language Models (LLMs) have demonstrated impressive abilities in tackling tasks across numerous domains. The capabilities of LLMs could potentially be applied to various computer networking tasks, including network synthesis, management, debugging, security, and education. However, LLMs can be unreliable: they are prone to reasoning errors and may hallucinate incorrect information. Their effectiveness and limitations in computer networking tasks remain unclear. In this paper, we attempt to understand the capabilities and limitations of LLMs in network applications. We evaluate misunderstandings regarding networking related concepts across 3 LLMs over 500 questions. We assess the reliability, explain-ability, and stability of LLM responses to networking questions. Furthermore, we investigate errors made, analyzing their cause, detectability, effects, and potential mitigation strategies.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = feb,
pages = {14–24},
numpages = {11},
keywords = {characterization study, computer networking, large language models}
}

@article{10.1145/3707453,
author = {Li, Ding and Zhang, Ziqi and Yao, Mengyu and Cai, Yifeng and Guo, Yao and Chen, Xiangqun},
title = {TEESlice: Protecting Sensitive Neural Network Models in Trusted Execution Environments When Attackers have Pre-Trained Models},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3707453},
doi = {10.1145/3707453},
abstract = {Trusted Execution Environments (TEE) are used to safeguard on-device models. However, directly employing TEEs to secure the entire DNN model is challenging due to the limited computational speed. Utilizing GPU can accelerate DNN's computation speed but commercial widely-available GPUs usually lack security protection. To this end, scholars introduce TEE-shielded DNN partition (TSDP), a method that protects privacy-sensitive weights within TEEs and offloads insensitive weights to GPUs. Nevertheless, current methods do not consider the presence of a knowledgeable adversary who can access abundant publicly available pre-trained models and datasets. This paper investigates the security of existing methods against such a knowledgeable adversary and reveals their inability to fulfill their security promises. Consequently, we introduce a novel partition before training strategy, which effectively separates privacy-sensitive weights from other components of the model. Our evaluation demonstrates that our approach can offer full model protection with a computational cost reduced by a factor of 10. In addition to traditional CNN models, we also demonstrate the scalability to large language models. Our approach can compress the private functionalities of the large language model to lightweight slices and achieve the same level of protection as the shielding-whole-model baseline.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {LLM, TEE, Model Slicing, Model Stealing, Membership Inference Attack}
}

@inproceedings{10.1145/3587102.3588815,
author = {Daun, Marian and Brings, Jennifer},
title = {How ChatGPT Will Change Software Engineering Education},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588815},
doi = {10.1145/3587102.3588815},
abstract = {This position paper discusses the potential for using generative AIs like ChatGPT in software engineering education. Currently, discussions center around potential threats emerging from student's use of ChatGPT. For instance, generative AI will limit the usefulness of graded homework dramatically. However, there exist potential opportunities as well. For example, ChatGPT's ability to understand and generate human language allows providing personalized feedback to students, and can thus accompany current software engineering education approaches. This paper highlights the potential for enhancing software engineering education. The availability of generative AI will improve the individualization of education approaches. In addition, we discuss the need to adapt software engineering curricula to the changed profiles of software engineers. Moreover, we point out why it is important to provide guidance for using generative AI and, thus, integrate it in courses rather than accepting the unsupervised use by students, which can negatively impact the students' learning.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {110–116},
numpages = {7},
keywords = {ChatGPT, generative AI, software engineering education},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3641555.3705187,
author = {O'Neill, Abby and Smith, Samantha and Durai, Aneesh and DeNero, John and Zamfirescu-Pereira, J.D. and Norouzi, Narges},
title = {From Code to Concepts: Textbook-Driven Knowledge Tracing with LLMs in CS1},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705187},
doi = {10.1145/3641555.3705187},
abstract = {Gauging a student's understanding of course concepts, at an arbitrary point during a course, can be challenging. Standardized exams offer only a snapshot of performance rather than a deep understanding of progress. However, with Large Language Models (LLMs) now deployed at scale in CS1 courses, we can track multiple attempts from each student for every homework problem. This data provides insights into how students learn and deploy concepts over time, presenting a unique opportunity to rethink how we track changes in individual student knowledge. Traditional Knowledge Tracing (KT) methods often lack explainability and are computationally expensive. In contrast, our framework leverages an LLM to identify student progress on labeled, problem-level concepts from a student homework code submission. Our initial results show that the student's knowledge state can be dynamically updated. This knowledge state can then be used to provide more targeted, effective feedback and create tailored study materials.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1565–1566},
numpages = {2},
keywords = {artificial intelligence/machine learning, cs1/cs2, instructional technologies, programming, tools and tool use},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3674149,
author = {Mendon\c{c}a, Nabor C.},
title = {Evaluating ChatGPT-4 Vision on Brazil's National Undergraduate Computer Science Exam},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
url = {https://doi.org/10.1145/3674149},
doi = {10.1145/3674149},
abstract = {The recent integration of visual capabilities into Large Language Models (LLMs) has the potential to play a pivotal role in science and technology education, where visual elements such as diagrams, charts, and tables are commonly used to improve the learning experience. This study investigates the performance of ChatGPT-4 Vision, OpenAI’s most advanced visual model at the time the study was conducted, on the Bachelor in Computer Science section of Brazil’s 2021 National Undergraduate Exam (ENADE). By presenting the model with the exam’s open and multiple-choice questions in their original image format and allowing for reassessment in response to differing answer keys, we were able to evaluate the model’s reasoning and self-reflecting capabilities in a large-scale academic assessment involving textual and visual content. ChatGPT-4 Vision significantly outperformed the average exam participant, positioning itself within the top 10 best score percentile. While it excelled in questions that incorporated visual elements, it also encountered challenges with question interpretation, logical reasoning, and visual acuity. A positive correlation between the model’s performance in multiple-choice questions and the performance distribution of the human participants suggests multimodal LLMs can provide a useful tool for question testing and refinement. However, the involvement of an independent expert panel to review cases of disagreement between the model and the answer key revealed some poorly constructed questions containing vague or ambiguous statements, calling attention to the critical need for improved question design in future exams. Our findings suggest that while ChatGPT-4 Vision shows promise in multimodal academic evaluations, human oversight remains crucial for verifying the model’s accuracy and ensuring the fairness of high-stakes educational exams. The paper’s research materials are publicly available at .},
journal = {ACM Trans. Comput. Educ.},
month = aug,
articleno = {37},
numpages = {56},
keywords = {Multimodal generative AI, ChatGPT-4 vision, educational assessment, computer science education}
}

@inproceedings{10.1145/3641554.3701844,
author = {Yu, Zezhu and Liu, Suqing and Denny, Paul and Bergen, Andreas and Liut, Michael},
title = {Integrating Small Language Models with Retrieval-Augmented Generation in Computing Education: Key Takeaways, Setup, and Practical Insights},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701844},
doi = {10.1145/3641554.3701844},
abstract = {Leveraging a Large Language Model (LLM) for personalized learning in computing education is promising, yet cloud-based LLMs pose risks around data security and privacy. To address these concerns, we developed and deployed a locally stored Small Language Model (SLM) utilizing Retrieval-Augmented Generation (RAG) methods to support computing students' learning. Previous work has demonstrated that SLMs can match or surpass popular LLMs (gpt-3.5-turbo and gpt-4-32k) in handling conversational data from a CS1 course. We deployed SLMs with RAG (SLM + RAG) in a large course with more than 250 active students, fielding nearly 2,000 student questions, while evaluating data privacy, scalability, and feasibility of local deployments. This paper provides a comprehensive guide for deploying SLM + RAG systems, detailing model selection, vector database choice, embedding methods, and pipeline frameworks. We share practical insights from our deployment, including scalability concerns, accuracy versus context length trade-offs, guardrails and hallucination reduction, as well as data privacy maintenance. We address the "Impossible Triangle" in RAG systems, which states that achieving high accuracy, short context length, and low time consumption simultaneously is not feasible. Furthermore, our novel RAG framework, Intelligence Concentration (IC), categorizes information into multiple layers of abstraction within Milvus collections mitigating trade-offs and enabling educational assistants to deliver more relevant and personalized responses to students quickly.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1302–1308},
numpages = {7},
keywords = {computer science education, computing education, conversational agent, intelligence concentration, intelligent tutoring system, large language models, milvus, personalized ai agent, retrieval-augmented generation, small language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706599.3719287,
author = {Oh, Sunggyeol and Zhao, Jiacheng and Russo, Carson and Bolmer, Michael},
title = {Boosting Diary Study Outcomes with a Fine-Tuned Large Language Model},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719287},
doi = {10.1145/3706599.3719287},
abstract = {This study explores fine-tuned Large Language Models (LLMs) integration into diary studies within the Human-Computer Interaction (HCI) field to enhance data collection and analysis. Leveraging a Mistral 7B model fine-tuned with a curated dataset of over 1,000 diary entries, this research addresses challenges such as participant engagement and data richness. The fine-tuned model offers personalized feedback, facilitating deeper reflection and structured recording while reducing the cognitive load on participants. The DiaryQuest educational platform, enhanced with advanced visualization tools and semantic search capabilities, enables educators to efficiently analyze diary data, extract thematic insights, and provide targeted guidance. Results from user evaluations reveal that the optimized platform improves learning outcomes, teaching efficiency, and overall user experience. By bridging traditional diary methodologies with state-of-the-art LLMs, this study advances HCI education and establishes a scalable framework for applying AI in broader educational and research contexts.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {896},
numpages = {7},
keywords = {Diary Study, Large Language Model},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3638247,
author = {Cheng, Yu and Chen, Jieshan and Huang, Qing and Xing, Zhenchang and Xu, Xiwei and Lu, Qinghua},
title = {Prompt Sapper: A LLM-Empowered Production Tool for Building AI Chains},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3638247},
doi = {10.1145/3638247},
abstract = {The emergence of foundation models, such as large language models (LLMs) GPT-4 and text-to-image models DALL-E, has opened up numerous possibilities across various domains. People can now use natural language (i.e., prompts) to communicate with AI to perform tasks. While people can use foundation models through chatbots (e.g., ChatGPT), chat, regardless of the capabilities of the underlying models, is not a production tool for building reusable AI services. APIs like LangChain allow for LLM-based application development but require substantial programming knowledge, thus posing a barrier. To mitigate this, we systematically review, summarise, refine and extend the concept of AI chain by incorporating the best principles and practices that have been accumulated in software engineering for decades into AI chain engineering, to systematize AI chain engineering methodology. We also develop a no-code integrated development environment, , which embodies these AI chain engineering principles and patterns naturally in the process of building AI chains, thereby improving the performance and quality of AI chains. With Prompt Sapper, AI chain engineers can compose prompt-based AI services on top of foundation models through chat-based requirement analysis and visual programming. Our user study evaluated and demonstrated the efficiency and correctness of Prompt Sapper.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {124},
numpages = {24},
keywords = {AI chain engineering, visual programming, large language models, No/Low code, SE for AI}
}

@inproceedings{10.1145/3649165.3690100,
author = {MacNeil, Stephen and Rogalska, Magdalena and Leinonen, Juho and Denny, Paul and Hellas, Arto and Crosland, Xandria},
title = {Synthetic Students: A Comparative Study of Bug Distribution Between Large Language Models and Computing Students},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690100},
doi = {10.1145/3649165.3690100},
abstract = {Large language models (LLMs) present an exciting opportunity for generating synthetic classroom data. Such data could include code containing a typical distribution of errors, simulated student behavior to address the cold start problem when developing education tools, and synthetic user data when access to authentic data is restricted due to privacy reasons. In this research paper, we conduct a comparative study examining the distribution of bugs generated by LLMs in contrast to those produced by computing students. Leveraging data from two previous large-scale analyses of student-generated bugs, we investigate whether LLMs can be coaxed to exhibit bug patterns that are similar to authentic student bugs when prompted to inject errors into code. The results suggest that unguided, LLMs do not generate plausible error distributions, and many of the generated errors are unlikely to be generated by real students. However, with guidance including descriptions of common errors and typical frequencies, LLMs can be shepherded to generate realistic distributions of errors in synthetic code.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {137–143},
numpages = {7},
keywords = {buggy code, generative ai, gpt-4, llms, synthetic data},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3639477.3639719,
author = {Di, Peng and Li, Jianguo and Yu, Hang and Jiang, Wei and Cai, Wenting and Cao, Yang and Chen, Chaoyu and Chen, Dajun and Chen, Hongwei and Chen, Liang and Fan, Gang and Gong, Jie and Gong, Zi and Hu, Wen and Guo, Tingting and Lei, Zhichao and Li, Ting and Li, Zheng and Liang, Ming and Liao, Cong and Liu, Bingchang and Liu, Jiachen and Liu, Zhiwei and Lu, Shaojun and Shen, Min and Wang, Guangpei and Wang, Huan and Wang, Zhi and Xu, Zhaogui and Yang, Jiawei and Ye, Qing and Zhang, Gehao and Zhang, Yu and Zhao, Zelin and Zheng, Xunjin and Zhou, Hailian and Zhu, Lifu and Zhu, Xianying},
title = {CodeFuse-13B: A Pretrained Multi-lingual Code Large Language Model},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639719},
doi = {10.1145/3639477.3639719},
abstract = {Code Large Language Models (Code LLMs) have gained significant attention in the industry due to their wide applications in the full lifecycle of software engineering. However, the effectiveness of existing models in understanding non-English inputs for multi-lingual code-related tasks is still far from well studied. This paper introduces CodeFuse-13B, an open-sourced pre-trained code LLM 2. It is specifically designed for code-related tasks with both English and Chinese prompts and supports over 40 programming languages. CodeFuse achieves its effectiveness by utilizing a high-quality pre-training dataset that is carefully filtered by program analyzers and optimized during the training process. Extensive experiments are conducted using real-world usage scenarios, the industry-standard benchmark HumanEval-x, and the specially designed CodefuseEval for Chinese prompts. To assess the effectiveness of CodeFuse, we actively collected valuable human feedback from the AntGroup's software development process where CodeFuse has been successfully deployed. The results demonstrate that CodeFuse-13B achieves a HumanEval pass@1 score of 37.10%, positioning it as one of the top multi-lingual code LLMs with similar parameter sizes. In practical scenarios, such as code generation, code translation, code comments, and testcase generation, CodeFuse performs better than other models when confronted with Chinese prompts.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {418–429},
numpages = {12},
keywords = {code large language models, multi-lingual, chinese prompts},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@inproceedings{10.1145/3649409.3691076,
author = {Wiese, Eliane S. and Finnie-Ansley, James and Duran, Rodrigo and Cunningham, Kathryn and Demirtas, Mehmet Arif},
title = {Challenges and Solutions for Teaching Decomposition and Planning Skills in CS1},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691076},
doi = {10.1145/3649409.3691076},
abstract = {The task of decomposing a problem into sub-problems to build a solution, also formalized as planning in prior work, is a key skill for programming expertise. Improving the decomposition and planning skills of novices is shown to be a challenging goal for educators. Moreover, decomposing complex projects into smaller subtasks is an increasingly relevant skill with rapid developments in tools like large language models (LLMs). While there are many aspects of planning, one skill consistently observed in studies with experts is the ability to identify subtasks that can be solved via common code patterns. To support students in acquiring these skills, many researchers have explored explicit instruction about a set of common patterns in programs (i.e. programming plans). However, recent work implies that students may need additional support to fully benefit from such interventions. This panel aims to bring computing education researchers together to discuss the main challenges around teaching decomposition and planning using common patterns, the crucial factors for designing instruction for teaching these concepts, and the impact evolving technology like LLMs can have on these developments.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {291–292},
numpages = {2},
keywords = {cs1, decomposition, large language models, programming plans},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@article{10.1145/3722107,
author = {Zou, Wentao and Shen, Zongwen and Li, Qi and Ge, Jidong and Li, Chuanyi and Chen, Xiang and Shen, Xiaoyu and Huang, LiGuo and Luo, Bin},
title = {Experimental Evaluation of Parameter-Efficient Fine-Tuning for Software Engineering Tasks},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3722107},
doi = {10.1145/3722107},
abstract = {Pre-trained models (PTMs) have succeeded in various software engineering (SE) tasks following the “pre-train then fine-tune” paradigm. As fully fine-tuning all parameters of PTMs can be computationally expensive, a potential solution is parameter-efficient fine-tuning (PEFT), which freezes PTMs while introducing extra parameters. Although PEFT methods have been applied to SE tasks, researchers often focus on specific scenarios and lack a comprehensive comparison of PTMs from different aspects such as field, size, and architecture. To fill this gap, we have conducted an empirical study on six PEFT methods, eight PTMs, and four SE tasks. The experimental results reveal several noteworthy findings. For example, model architecture has little impact on PTM performance when using PEFT methods. Additionally, we provide a comprehensive discussion of PEFT methods from three perspectives. First, we analyze the effectiveness and efficiency of PEFT methods. Second, we explore the impact of the scaling factor hyperparameter. Finally, we investigate the application of PEFT methods on the latest open-source large language model, Llama 3.2. These findings provide valuable insights to guide future researchers in effectively applying PEFT methods to SE tasks.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
keywords = {parameter-efficient fine-tuning, pre-trained model, software engineering task, empirical study, effectiveness and efficiency}
}

@inproceedings{10.1145/3643916.3645030,
author = {Khajezade, Mohamad and Wu, Jie JW and Fard, Fatemeh Hendijani and Rodriguez-Perez, Gema and Shehata, Mohamed Sami},
title = {Investigating the Efficacy of Large Language Models for Code Clone Detection},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3645030},
doi = {10.1145/3643916.3645030},
abstract = {Large Language Models (LLMs) have demonstrated remarkable success in various natural language processing and software engineering tasks, such as code generation. The LLMs are mainly utilized in the prompt-based zero/few-shot paradigm to guide the model in accomplishing the task. GPT-based models are one of the popular ones studied for tasks such as code comment generation or test generation. These tasks are 'generative' tasks. However, there is limited research on the usage of LLMs for 'non-generative' tasks such as classification using the prompt-based paradigm. In this preliminary exploratory study, we investigated the applicability of LLMs for Code Clone Detection (CCD), a non-generative task. By building a mono-lingual and cross-lingual CCD dataset derived from CodeNet, we first investigated two different prompts using ChatGPT to detect Type-4 code clones in Java-Java and Java-Ruby pairs in a zero-shot setting. We then conducted an analysis to understand the strengths and weaknesses of ChatGPT in CCD. ChatGPT surpasses the baselines in cross-language CCD attaining an F1-score of 0.877 and achieves comparable performance to fully fine-tuned models for mono-lingual CCD, with an F1-score of 0.878. Also, the prompt and the difficulty level of the problems has an impact on the performance of ChatGPT. Finally, we provide insights and future directions based on our initial analysis1.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {161–165},
numpages = {5},
keywords = {large language models, code clone detection, zero-shot learning, few-shot learning},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3641554.3701906,
author = {Hassan, Mohammed and Chen, Yuxuan and Denny, Paul and Zilles, Craig},
title = {On Teaching Novices Computational Thinking by Utilizing Large Language Models Within Assessments},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701906},
doi = {10.1145/3641554.3701906},
abstract = {Novice programmers often struggle to develop computational thinking (CT) skills in introductory programming courses. This study investigates the use of Large Language Models (LLMs) to provide scalable, strategy-driven feedback to teach CT. Through think-aloud interviews with 17 students solving code comprehension and writing tasks, we found that LLMs effectively guided decomposition and program development tool usage. Challenges included students seeking direct answers or pasting feedback without considering suggested strategies. We discuss how instructors should integrate LLMs into assessments to support students' learning of CT.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {471–477},
numpages = {7},
keywords = {code comprehension, debuggers, execution, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626253.3633436,
author = {Leinonen, Juho and MacNeil, Stephen and Denny, Paul and Hellas, Arto},
title = {Using Large Language Models for Teaching Computing},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633436},
doi = {10.1145/3626253.3633436},
abstract = {In the past year, large language models (LLMs) have taken the world by storm, demonstrating their potential as a transformative force in many domains including computing education. Computing education researchers have found that LLMs can solve most assessments in introductory programming courses, including both traditional code writing tasks and other popular tasks such as Parsons problems. As more and more students start to make use of LLMs, the question instructors might ask themselves is "what can I do?". We propose that one promising way forward is to integrate LLMs into teaching practice, providing all students with an equal opportunity to learn how to interact productively with LLMs as well as encounter and understand their limitations. In this workshop, we first present state-of-the-art research results on how to utilize LLMs in computing education practice, after which participants will take part in hands-on activities using LLMs. We end the workshop by brainstorming ideas with participants around adapting their classrooms to most effectively integrate LLMs while avoiding some common pitfalls.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1901},
numpages = {1},
keywords = {generative ai, large language models, teaching practice},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3731753,
author = {Yang, Zhou and Shi, Jieke and Devanbu, Prem and Lo, David},
title = {Ecosystem of Large Language Models for Code},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3731753},
doi = {10.1145/3731753},
abstract = {The extensive availability of publicly accessible source code and the advances in language models, coupled with increasing computational resources, have led to a remarkable rise of large language models for code (LLM4Code). These models do not exist in isolation but rather depend on and interact with each other, forming a complex ecosystem that is worth studying. It motivates us to introduce a pioneering analysis of the LLM4Code ecosystem. Utilizing Hugging Face —the premier hub for transformer-based models—as our primary source, we manually curate a list of datasets and models focused on software engineering tasks. We first identify key datasets, models, and users in the ecosystem and quantify their contributions and importance. We then examine each model's documentation to trace its base model and understand the process for deriving new models. We categorize LLM4Code model reuse into nine categories, with the top three being fine-tuning, architecture sharing, and quantization. Additionally, we examine documentation and licensing practices, revealing that LLM4Code documentation is less detailed than that of general AI repositories on GitHub. The license usage pattern is also different from other software repositories, and we further analyze potential license incompatibility issues. To analyze the rapidly growing LLM4Code, we explore the potential of using LLMs to assist in constructing and analyzing the ecosystem. Advanced LLMs from OpenAI identify LLM4Code with 98% accuracy, infer base models with 87% accuracy, and predict reuse types with 89% accuracy. We employ LLMs to expand the ecosystem and find that conclusions from the manually curated dataset align with those from the automatically created one. Based on our findings, we discuss the implications and suggestions to facilitate the healthy growth of LLM4Code.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr
}

@inproceedings{10.1145/3641555.3705178,
author = {Eikmeier, Nicole and Perlmutter, Leah},
title = {Experiences Teaching A Course On Algorithms, Ethics, and Society},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705178},
doi = {10.1145/3641555.3705178},
abstract = {It is essential for CS students to graduate with competence about ethics and societal impacts of technology. We designed and taught a new reading discussion course, at Grinnell College, Algorithms, Ethics, and Society, for advanced undergraduate students who have completed CS1 and CS2. Course topics included Identity in Computing, Tech Ethics, Algorithms Informing Policies, Large Language Models, Networks and Social Media, Health Applications, and Robotics. We encountered some challenges with the discussion format, which we addressed by upholding class norms, employing discussion techniques learned from humanities and social science colleagues, and being open to learn from our mistakes.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1449–1450},
numpages = {2},
keywords = {computer science education, computing and society, technology ethics},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inbook{10.1145/3718491.3718578,
author = {Ji, Shubo and Zhang, Long and Niu, Liyue and Zheng, Qiusheng},
title = {Evaluation of Chinese Sentiment Analysis for Lightweight LLM},
year = {2025},
isbn = {9798400710865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3718491.3718578},
abstract = {Large language models have demonstrated impressive performance in natural language processing tasks. However, their extensive parameter scale necessitates substantial computational resources and presents various challenges regarding portability and application scenarios, thereby hindering the widespread adoption and utilization of this technology. This study examines domestic large language models characterized by high portability and a smaller parameter scale, particularly focusing on their performance in sentiment analysis tasks. Accordingly, we designed five Chinese sentiment analysis tasks based on seven public datasets, evaluated the tasks using popular lightweight domestic large language models, and compared their capabilities with deep learning models and ChatGPT. The results indicate that the performance of lightweight domestic large language models on Chinese sentiment analysis tasks surpasses that of deep learning models and approaches the performance of ChatGPT. Furthermore, we assessed enhancement techniques such as prompt word engineering and large model fine-tuning, revealing that the enhanced model's parameter count is merely 3.45% of ChatGPT's, while achieving 95.2% of ChatGPT's performance.},
booktitle = {Proceedings of the 4th Asia-Pacific Artificial Intelligence and Big Data Forum},
pages = {528–534},
numpages = {7}
}

@article{10.14778/3611540.3611634,
author = {Halevy, Alon and Choi, Yejin and Floratou, Avrilia and Franklin, Michael J. and Noy, Natasha and Wang, Haixun},
title = {Will LLMs Reshape, Supercharge, or Kill Data Science? (VLDB 2023 Panel)},
year = {2023},
issue_date = {August 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3611540.3611634},
doi = {10.14778/3611540.3611634},
abstract = {Large language models (LLMs) have recently taken the world by storm, promising potentially game changing opportunities in multiple fields. Naturally, there is significant promise in applying LLMs to the management of structured data, or more generally, to the processes involved in data science. At the very least, LLMs have the potential to provide substantial advancements in long-standing challenges that our community has been tackling for decades. On the other hand, they may introduce completely new capabilities that we have only dreamed of thus far. This panel will bring together a few leading experts who have been thinking about these opportunities from various perspectives and fielding them in research prototypes and even in commercial applications.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4114–4115},
numpages = {2}
}

@article{10.1145/3660809,
author = {Oueslati, Khouloud and Laberge, Gabriel and Lamothe, Maxime and Khomh, Foutse},
title = {Mining Action Rules for Defect Reduction Planning},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660809},
doi = {10.1145/3660809},
abstract = {Defect reduction planning plays a vital role in enhancing software quality and minimizing software maintenance costs. By training a black box machine learning model and “explaining” its predictions, explainable AI for software engineering aims to identify the code characteristics that impact maintenance risks. However, post-hoc explanations do not always faithfully reflect what the original model computes. In this paper, we introduce CounterACT, a Counterfactual ACTion rule mining approach that can generate defect reduction plans without black-box models. By leveraging action rules, CounterACT provides a course of action that can be considered as a counterfactual explanation for the class (e.g., buggy or not buggy) assigned to a piece of code. We compare the effectiveness of CounterACT with the original action rule mining algorithm and six established defect reduction approaches on 9 software projects. Our evaluation is based on (a) overlap scores between proposed code changes and actual developer modifications; (b) improvement scores in future releases; and (c) the precision, recall, and F1-score of the plans. Our results show that, compared to competing approaches, CounterACT’s explainable plans achieve higher overlap scores at the release level (median 95%) and commit level (median 85.97%), and they offer better trade-off between precision and recall (median F1-score 88.12%). Finally, we venture beyond planning and explore leveraging Large Language models (LLM) for generating code edits from our generated plans. Our results show that suggested LLM code edits supported by our plans are actionable and are more likely to pass relevant test cases than vanilla LLM code recommendations.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {102},
numpages = {23},
keywords = {Action rule mining, Counterfactual explanations, Defect reduction planning, Explainability, Software analytics}
}

@article{10.1145/3721127,
author = {Alami, Adam and Jensen, Victor Vadmand and Ernst, Neil A.},
title = {Accountability in Code Review: The Role of Intrinsic Drivers and the Impact of LLMs},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3721127},
doi = {10.1145/3721127},
abstract = {Accountability is an innate part of social systems. It maintains stability and ensures positive pressure on individuals’ decision-making. As actors in a social system, software developers are accountable to their team and organization for their decisions. However, the drivers of accountability and how it changes behavior in software development are less understood. In this study, we look at how the social aspects of code review affect software engineers’ sense of accountability for code quality. Since software engineering (SE) is increasingly involving Large Language Models (LLM) assistance, we also evaluate the impact on accountability when introducing LLM-assisted code reviews. We carried out a two-phased sequential qualitative study ( (textbf{interviews}rightarrowtextbf{focus groups}) ). In Phase I (16 interviews), we sought to investigate the intrinsic drivers of software engineers influencing their sense of accountability for code quality, relying on self-reported claims. In Phase II, we tested these traits in a more natural setting by simulating traditional peer-led reviews with focus groups and then LLM-assisted review sessions. We found that there are four key intrinsic drivers of accountability for code quality: personal standards, professional integrity, pride in code quality, and maintaining one’s reputation. In a traditional peer-led review, we observed a transition from individual to collective accountability when code reviews are initiated. We also found that the introduction of LLM-assisted reviews disrupts this accountability process, challenging the reciprocity of accountability taking place in peer-led evaluations, i.e., one cannot be accountable to an LLM. Our findings imply that the introduction of AI into SE must preserve social integrity and collective accountability mechanisms.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {Code quality, Accountability, Artificial Intelligence, Large Language Models, LLM, Code Review, Human and Social Aspects of Software Engineering}
}

@article{10.1613/jair.1.17028,
author = {Karev, Alexey and Xu, Dong},
title = {ConSCompF: Consistency-focused Similarity Comparison Framework for Generative Large Language Models},
year = {2025},
issue_date = {May 2025},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {82},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.17028},
doi = {10.1613/jair.1.17028},
abstract = {Large Language Models (LLM) are one of the most important discoveries in machine learning in recent years. LLM-based artificial intelligence (AI) assistants, such as ChatGPT, have consistently attracted attention from researchers, investors, and the general public, driving the rapid growth of this industry. With dozens of new LLMs released every month, it becomes quite challenging to differentiate between them, thereby creating a demand for new LLM comparison methods.
In this research, the Consistency-focused Similarity Comparison Framework (ConSCompF) for generative large language models is proposed. It compares texts generated by two LLMs and produces a similarity score, indicating the overall degree of similarity between their responses. The main advantage of this framework is that it can operate on a small number of unlabeled data, such as chatbot instruction prompts, and does not require LLM developers to disclose any information about their product.
To evaluate the efficacy of ConSCompF, two experiments aimed at identifying similarities between multiple LLMs are conducted. Additionally, these experiments examine the correlation between the similarity scores generated by ConSCompF and the differences in outputs produced by other benchmarking techniques, such as ROUGE-L. Finally, a series of few-shot LLM comparison experiments is conducted to evaluate the performance of ConSCompF in a few-shot LLM comparison scenario.
The proposed framework can be used for calculating similarity matrices of multiple LLMs, which can be effectively visualized using principal component analysis (PCA). The outputs of ConSCompF may provide useful insights into data that might have been used during LLM training and help detect potential investment fraud attempts.},
journal = {J. Artif. Int. Res.},
month = apr,
numpages = {23},
keywords = {electronic health records, Medical Information, NLP, EHR, document level, deep learning, machine learning}
}

@inproceedings{10.1145/3652620.3687807,
author = {Yang, Yujing and Chen, Boqi and Chen, Kua and Mussbacher, Gunter and Varr\'{o}, D\'{a}niel},
title = {Multi-step Iterative Automated Domain Modeling with  Large Language Models},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687807},
doi = {10.1145/3652620.3687807},
abstract = {Domain modeling, which represents the concepts and relationships in a problem domain, is an essential part of software engineering. As large language models (LLMs) have recently exhibited remarkable ability in language understanding and generation, many approaches are designed to automate domain modeling with LLMs. However, these approaches usually formulate all input information to the LLM in a single step. Our previous single-step approach resulted in many missing modeling elements and advanced patterns. This paper introduces a novel framework designed to enhance fully automated domain model generation. The proposed multi-step automated domain modeling approach extracts model elements (e.g., classes, attributes, and relationships) from problem descriptions. The approach includes instructions and human knowledge in each step and uses an iterative process to identify complex patterns, repeatedly extracting the pattern from various instances and then synthesizing these extractions into a summarized overview. Furthermore, the framework incorporates a self-reflection mechanism. This mechanism assesses each generated model element, offering self-feedback for necessary modifications or removals, and integrates the domain model with the generated self-feedback. The proposed approach is assessed in experiments, comparing it with a baseline single-step approach from our earlier work. Experiments demonstrate a significant improvement over our earlier work, with a 22.71% increase in the F1-score for identifying classes, 75.18% for relationships, and a 10.39% improvement for identifying the player-role pattern, with comparable performance for attributes. Our approach, dataset, and evaluation provide valuable insight for future research in automated LLM-based domain modeling.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {587–595},
numpages = {9},
keywords = {domain modeling, large language models, few-shot learning, prompt engineering},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3644032.3644443,
author = {El Haji, Khalid and Brandt, Carolin and Zaidman, Andy},
title = {Using GitHub Copilot for Test Generation in Python: An Empirical Study},
year = {2024},
isbn = {9798400705885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644032.3644443},
doi = {10.1145/3644032.3644443},
abstract = {Writing unit tests is a crucial task in software development, but it is also recognized as a time-consuming and tedious task. As such, numerous test generation approaches have been proposed and investigated. However, most of these test generation tools produce tests that are typically difficult to understand. Recently, Large Language Models (LLMs) have shown promising results in generating source code and supporting software engineering tasks. As such, we investigate the usability of tests generated by GitHub Copilot, a proprietary closed-source code generation tool that uses an LLM. We evaluate GitHub Copilot's test generation abilities both within and without an existing test suite, and we study the impact of different code commenting strategies on test generations.Our investigation evaluates the usability of 290 tests generated by GitHub Copilot for 53 sampled tests from open source projects. Our findings highlight that within an existing test suite, approximately 45.28% of the tests generated by Copilot are passing tests; 54.72% of generated tests are failing, broken, or empty tests. Furthermore, if we generate tests using Copilot without an existing test suite in place, we observe that 92.45% of the tests are failing, broken, or empty tests. Additionally, we study how test method comments influence the usability of test generations.},
booktitle = {Proceedings of the 5th ACM/IEEE International Conference on Automation of Software Test (AST 2024)},
pages = {45–55},
numpages = {11},
location = {Lisbon, Portugal},
series = {AST '24}
}

@inproceedings{10.1145/3643661.3643952,
author = {Astekin, Merve and Hort, Max and Moonen, Leon},
title = {An Exploratory Study on How Non-Determinism in Large Language Models Affects Log Parsing},
year = {2024},
isbn = {9798400705649},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643661.3643952},
doi = {10.1145/3643661.3643952},
abstract = {Most software systems used in production generate system logs that provide a rich source of information about the status and execution behavior of the system. These logs are commonly used to ensure the reliability and maintainability of software systems. The first step toward automated log analysis is generally log parsing, which aims to transform unstructured log messages into structured log templates and extract the corresponding parameters.Recently, Large Language Models (LLMs) such as ChatGPT have shown promising results on a wide range of software engineering tasks, including log parsing. However, the extent to which non-determinism influences log parsing using LLMs remains unclear. In particular, it is important to investigate whether LLMs behave consistently when faced with the same log message multiple times.In this study, we investigate the impact of non-determinism in state-of-the-art LLMs while performing log parsing. Specifically, we select six LLMs, including both paid proprietary and free-to-use models, and evaluate their non-determinism on 16 system logs obtained from a selection of mature open-source projects. The results of our study reveal varying degrees of non-determinism among models. Moreover, they show that there is no guarantee for deterministic results even with a temperature of zero.},
booktitle = {Proceedings of the ACM/IEEE 2nd International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering},
pages = {13–18},
numpages = {6},
keywords = {log parsing, large language model, robustness, non-determinism, consistency},
location = {Lisbon, Portugal},
series = {InteNSE '24}
}

@inproceedings{10.1145/3649409.3691074,
author = {Zarb, Mark and Brown, John N.A. and Goodfellow, Martin and Liaskos, Konstantinos and Young, Tiffany},
title = {Ethical Implications of Gen-AI and LLMs in Computing Education},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691074},
doi = {10.1145/3649409.3691074},
abstract = {The panel convenes five educators to discuss the ethical implications of utilising Generative AI (Gen-AI) and Large Language Models (LLMs) in computing education. Their expertise spans various domains, including organising national workshops on the implications of generative AI tools, conducting surveys on their use within curricula, implementing institutional policies related to technology use, and engaging with students directly in the classroom. They reflect on the evolution of Gen-AI and LLMs from challenging-to-use technologies to indispensable tools for users of all levels. Furthermore, they examine the ethical dilemmas arising from the widespread adoption of these technologies in educational contexts, particularly regarding issues of originality, integrity, and responsible use. In addition, they explore practical strategies for integrating ethics education into computing curriculum design and classroom practices. This includes discussions on the role of educators in guiding students towards ethical technology usage, addressing uncertainties surrounding Gen-AI tools, and fostering a culture of responsible innovation within educational institutions. Through their collective insights and experiences, the panel aims to provide recommendations for navigating the ethical complexities inherent in the integration of Gen-AI technologies into computing education curricula.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {293–294},
numpages = {2},
keywords = {ChatGPT, curriculum design, ethics, generative AI, large language models, responsibility},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3587102.3588814,
author = {Cipriano, Bruno Pereira and Alves, Pedro},
title = {GPT-3 vs Object Oriented Programming Assignments: An Experience Report},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588814},
doi = {10.1145/3587102.3588814},
abstract = {Recent studies show that AI-driven code generation tools, such as Large Language Models, are able to solve most of the problems usually presented in introductory programming classes. However, it is still unknown how they cope with Object Oriented Programming assignments, where the students are asked to design and implement several interrelated classes (either by composition or inheritance) that follow a set of best-practices. Since the majority of the exercises in these tools' training dataset are written in English, it is also unclear how well they function with exercises published in other languages.In this paper, we report our experience using GPT-3 to solve 6 real-world tasks used in an Object Oriented Programming course at a Portuguese University and written in Portuguese. Our observations, based on an objective evaluation of the code, performed by an open-source Automatic Assessment Tool, show that GPT-3 is able to interpret and handle direct functional requirements, however it tends not to give the best solution in terms of object oriented design. We perform a qualitative analysis of GPT-3's output, and gather a set of recommendations for computer science educators, since we expect students to use and abuse this tool in their academic work.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {61–67},
numpages = {7},
keywords = {GPT-3, large language models, object oriented programming, programming assignments, teaching},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@article{10.1145/3593230,
author = {Brie, Paul and Burny, Nicolas and Slu\"{y}ters, Arthur and Vanderdonckt, Jean},
title = {Evaluating a Large Language Model on Searching for GUI Layouts},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {EICS},
url = {https://doi.org/10.1145/3593230},
doi = {10.1145/3593230},
abstract = {The field of generative artificial intelligence has seen significant advancements in recent years with the advent of large language models, which have shown impressive results in software engineering tasks but not yet in engineering user interfaces. Thus, we raise a specific research question: would an LLM-based system be able to search for relevant GUI layouts? To address this question, we conducted a controlled study evaluating how Instigator, an LLM-based system for searching GUI layouts of web pages by generative pre-trained training, would return GUI layouts that are relevant to a given instruction and what would be the user experience of (N =34) practitioners interacting with Instigator. Our results identify a very high similarity and a moderate correlation between the rankings of the GUI layouts generated by Instigator and the rankings of the practitioners with respect to their relevance to a given design instruction. We highlight the results obtained through thirteen UEQ+ scales that characterize the user experience of the practitioner with Instigator, which we use to discuss perspectives for improving such future tools.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {178},
numpages = {37},
keywords = {web pages, large language model, gui layout, gui design, generative pre-training}
}

@inproceedings{10.1145/3626253.3635624,
author = {Fan, Aysa X. and Hendrawan, Rully A. and Shi, Yang and Ma, Qianou},
title = {Enhancing Code Tracing Question Generation with Refined Prompts in Large Language Models},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635624},
doi = {10.1145/3626253.3635624},
abstract = {This study refines Large Language Models (LLMs) prompts to enhance the generation of code tracing questions, where the new expert-guided prompts consider features identified from prior research. Expert evaluations compared new LLM-generated questions against previously preferred ones, revealing improved quality in aspects like complexity and concept coverage. While providing insights into effective question generation and affirming LLMs' potential in educational content creation, the study also contributes an expert-evaluated question dataset to the computing education community. However, generating high-quality reverse tracing questions remains a nuanced challenge, indicating a need for further LLM prompting refinement.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1640–1641},
numpages = {2},
keywords = {computer science education, large language model, programming education, tracing question},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641554.3701791,
author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Ashraf, Syed and Denny, Paul},
title = {Evaluating Language Models for Generating and Judging Programming Feedback},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701791},
doi = {10.1145/3641554.3701791},
abstract = {The emergence of large language models (LLMs) has transformed research and practice across a wide range of domains. Within the computing education research (CER) domain, LLMs have garnered significant attention, particularly in the context of learning programming. Much of the work on LLMs in CER, however, has focused on applying and evaluating proprietary models. In this article, we evaluate the efficiency of open-source LLMs in generating high-quality feedback for programming assignments and judging the quality of programming feedback, contrasting the results with proprietary models. Our evaluations on a dataset of students' submissions to introductory Python programming exercises suggest that state-of-the-art open-source LLMs are nearly on par with proprietary models in both generating and assessing programming feedback. Additionally, we demonstrate the efficiency of smaller LLMs in these tasks and highlight the wide range of LLMs accessible, even for free, to educators and practitioners.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {624–630},
numpages = {7},
keywords = {automatic evaluation, automatic feedback, generative ai, large language models, llm-as-a-judge, open source, programming feedback},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3623762.3633499,
author = {Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir},
title = {The Robots Are Here: Navigating the Generative AI Revolution in Computing Education},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633499},
doi = {10.1145/3623762.3633499},
abstract = {Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {108–159},
numpages = {52},
keywords = {ai, artificial intelligence, chatgpt, code generation, codex, computer programming, copilot, cs1, curriculum, generative ai, github, gpt, gpt-3, gpt-4, large language models, llm, llms, novice programming, openai, pedagogical practices, programming},
location = {Turku, Finland},
series = {ITiCSE-WGR '23}
}

@article{10.1145/3705734,
author = {George, Amrita and Storey, Veda Catherine and Hong, Shuguang},
title = {Unraveling the Impact of ChatGPT as a Knowledge Anchor in Business Education},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3705734},
doi = {10.1145/3705734},
abstract = {The emergence of Large Language Models (LLM), such as ChatGPT, is considered a productivity revolution in many areas of business and society. For a classroom setting, especially, it would be useful to understand whether, and how, to incorporate ChatGPT, similar to any other productivity revolution technology, such as calculators or a Google search engine. Although there are concerns regarding the use of LLMs in business education, the positive or negative impact of LLM use is not well-understood. In this research, we examine the substitution and complementarity effects of using ChatGPT in business curricula on learning outcomes and well-being in a socially supportive learning environment. Specifically, we examine whether technology anchors impact students’ goal orientation, learning outcomes, and well-being by conducting an empirical study with students majoring in Information Systems. Our analysis reveals that a technology anchor (computer playfulness) can complement the effects of social support on learning outcomes, while enhancing well-being for simple tasks. Students’ well-being and learning outcomes are hindered by LLM use (specifically, the computer anxiety anchor), substituting social support for simple and difficult tasks. These findings have implications for educational institutions that are assessing how to incorporate LLMs into business curricula.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {4},
numpages = {30},
keywords = {ChatGPT, Large language model (LLM), technology self-efficacy, computer anxiety, goal orientation, computer playfulness, social support, technology anchors, generative AI, knowledge anchor, OpenAI, technology anchors, artificial intelligence (AI), achievement theory}
}

@inproceedings{10.1145/3678610.3678631,
author = {Robledo-Rella, V\'{\i}ctor and Toh, Bee-Yen},
title = {Artificial Intelligence in Physics Courses to Support Active Learning},
year = {2024},
isbn = {9798400716799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678610.3678631},
doi = {10.1145/3678610.3678631},
abstract = {The integration of generative artificial intelligence (AI), particularly Large Language Models (LLMs) like OpenAI's ChatGPT and Microsoft's Copilot, is transforming educational methodologies, including undergraduate physics courses for engineering students. Despite their potential, these LLMs typically rely on statistical learning methods and often exhibit algebraic inaccuracies in solving standard university-level physics problems. This study explores the use of LLMs in physics courses for N = 91 freshman engineering students over two academic terms (Spring and Fall 2023). Students engaged in AI-assisted activities to solve physics problems and were asked to identify and correct the errors made by the chatbot. The outcomes were compared with those from traditional teaching methods without AI involvement, and no significant difference in student learning gains was found. To assess the impact of AI tools in education, a more detailed approach using pre-test and post-test instruments&nbsp;with control and experimental groups is necessary. Survey results revealed, however, that AI-assisted sessions enhanced student engagement, problem-solving skills, and understanding of physics concepts. Students also indicated a strong preference for AI-assisted activities, citing increased motivation and a firm belief in the educational benefits of using these tools. Our findings suggest that well-designed AI interventions can effectively complement traditional instructional methods, especially when the LLMs are integrated with symbolic computational tools like WolframAlpha to improve their accuracy.},
booktitle = {Proceedings of the 2024 10th International Conference on E-Society, e-Learning and e-Technologies (ICSLT)},
pages = {68–75},
numpages = {8},
keywords = {ChatGPT, Copilot, Educational Innovation, Generative AI, Higher Education, Interactive Learning, Physics Education Research},
location = {
},
series = {ICSLT '24}
}

@inproceedings{10.1145/3663649.3664371,
author = {Prakash, Kishore and Rao, Shashwat and Hamza, Rayan and Lukich, Jack and Chaudhari, Vatsal and Nandi, Arnab},
title = {Integrating LLMs into Database Systems Education},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664371},
doi = {10.1145/3663649.3664371},
abstract = {Large Language Models (LLMs) have sparked a drastic improvement in the ways computers can understand, process, and generate language. As LLM-based offerings become mainstream, we explore the incorporation of such LLMs into introductory or undergraduate database systems education. Students and instructors are both faced with the calculator dilemma: while the use of LLM-based tools may “solve” tasks such as assignments and exams, do they impede or accelerate the learning itself? We review deficiencies of using existing off-the-shelf tools for learning, and further articulate the differentiated needs of database systems students as opposed to trained data practitioners. Building on our exploration, we outline a vision that integrates LLMs into database education in a principled manner, keeping pedagogical best practices in mind. If implemented correctly, we posit that LLMs can drastically amplify the impact of existing instruction, minimizing costs and barriers towards learning database systems fundamentals.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {33–39},
numpages = {7},
keywords = {ChatGPT, database systems education, foundation models, intro to db, large language models, llm, undergrad databases},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{10.1109/ASE56229.2023.00206,
author = {Le, Van-Hoang and Zhang, Hongyu},
title = {Log Parsing: How Far Can ChatGPT Go?},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00206},
doi = {10.1109/ASE56229.2023.00206},
abstract = {Software logs play an essential role in ensuring the reliability and maintainability of large-scale software systems, as they are often the sole source of runtime information. Log parsing, which converts raw log messages into structured data, is an important initial step towards downstream log analytics. In recent studies, ChatGPT, the current cutting-edge large language model (LLM), has been widely applied to a wide range of software engineering tasks. However, its performance in automated log parsing remains unclear. In this paper, we evaluate ChatGPT's ability to undertake log parsing by addressing two research questions. (1) Can ChatGPT effectively parse logs? (2) How does ChatGPT perform with different prompting methods? Our results show that ChatGPT can achieve promising results for log parsing with appropriate prompts, especially with few-shot prompting. Based on our findings, we outline several challenges and opportunities for ChatGPT-based log parsing.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1699–1704},
numpages = {6},
keywords = {log analytics, log parsing, large language model, ChatGPT},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3593434.3593468,
author = {Ahmad, Aakash and Waseem, Muhammad and Liang, Peng and Fahmideh, Mahdi and Aktar, Mst Shamima and Mikkonen, Tommi},
title = {Towards Human-Bot Collaborative Software Architecting with ChatGPT},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593434.3593468},
doi = {10.1145/3593434.3593468},
abstract = {Architecting software-intensive systems can be a complex process. It deals with the daunting tasks of unifying stakeholders’ perspectives, designers’ intellect, tool-based automation, pattern-driven reuse, and so on, to sketch a blueprint that guides software implementation and evaluation. Despite its benefits, architecture-centric software engineering (ACSE) suffers from a multitude of challenges. ACSE challenges could stem from a lack of standardized processes, socio-technical limitations, and scarcity of human expertise etc. that can impede the development of existing and emergent classes of software. Software Development Bots (DevBots) trained on large language models can help synergise architects’ knowledge with artificially intelligent decision support to enable rapid architecting in a human-bot collaborative ACSE. An emerging solution to enable this collaboration is ChatGPT, a disruptive technology not primarily introduced for software engineering, but is capable of articulating and refining architectural artifacts based on natural language processing. We detail a case study that involves collaboration between a novice software architect and ChatGPT to architect a service-based software. Future research focuses on harnessing empirical evidence about architects’ productivity and explores socio-technical aspects of architecting with ChatGPT to tackle challenges of ACSE.},
booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
pages = {279–285},
numpages = {7},
keywords = {Software Architecture, Large Language Models, DevBots, ChatGPT},
location = {Oulu, Finland},
series = {EASE '23}
}

@inproceedings{10.1145/3611643.3613093,
author = {Cabra-Acela, Laura and Mojica-Hanke, Anamaria and Linares-V\'{a}squez, Mario and Herbold, Steffen},
title = {On Using Information Retrieval to Recommend Machine Learning Good Practices for Software Engineers},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613093},
doi = {10.1145/3611643.3613093},
abstract = {Machine learning (ML) is nowadays widely used for different purposes and with several disciplines. From self-driving cars to automated medical diagnosis, machine learning models extensively support users’ daily activities, and software engineering tasks are no exception. Not embracing good ML practices may lead to pitfalls that hinder the performance of an ML system and potentially lead to unexpected results. Despite the existence of documentation and literature about ML best practices, many non-ML experts turn towards gray literature like blogs and Q&amp;A systems when looking for help and guidance when implementing ML systems. To better aid users in distilling relevant knowledge from such sources, we propose a recommender system that recommends ML practices based on the user’s context. As a first step in creating a recommender system for machine learning practices, we implemented Idaka. A tool that provides two different approaches for retrieving/generating ML best practices: i) an information retrieval (IR) engine and ii) a large language model. The IR-engine uses BM25 as the algorithm for retrieving the practices, and a large language model, in our case Alpaca. The platform has been designed to allow comparative studies of best practices retrieval tools. Idaka is publicly available at  GitHub: https://bit.ly/idaka. Video: https://youtu.be/cEb-AhIPxnM},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {2142–2146},
numpages = {5},
keywords = {Good practices, Information retrieval, Large language models, Machine learning},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inbook{10.1145/3724504.3724622,
author = {Liang, Bohan},
title = {Artificial Intelligence in Language Education: CiteSpace-based Visualisation and Analysis},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724622},
abstract = {Over the past five years, the rapid development of generative artificial intelligence (AI) has led to a significant increase in research on AI in language education. This article uses CiteSpace software to conduct a visual analysis of research related to AI in language education from the SCI and SSCI databases over the past five years. The research results indicate that from 2020 to 2024, the number of papers related to AI in language education has been increasing steadily with the improvement of AI technologies. What's more, China, the United States, South Korea, England, and Saudi Arabia are the leading countries in terms of publication volume. Institutions such as the Chinese University of Hong Kong, Education University of Hong Kong, and Indiana University System (including Indiana University Bloomington), etc. have a significant number of publications, and collaborative publications among institutions are the mainstream. Moreover, the keyword co-occurrence graph shows that students’ English learning, large language models, natural language processing technology and deep learning are the foci of scholars' research. Keyword clustering graph and top terms in each cluster indicate that research in this field primarily focuses on English learning, particularly on speech and writing skills, and the psychological factors, learning effect, and learning strategies in the process of AI-assisted language education have also attracted the attention of scholars. Lastly, computational modeling technologies and mobile-assisted language learning are also topics that scholars have discussed extensively. The application of AI in non-English languages education, emotional factors of students and mobile-assisted language education driven by large language models may become hotspots in the future.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {721–725},
numpages = {5}
}

@inproceedings{10.1145/3636243.3636256,
author = {Doughty, Jacob and Wan, Zipiao and Bompelli, Anishka and Qayum, Jubahed and Wang, Taozhi and Zhang, Juran and Zheng, Yujia and Doyle, Aidan and Sridhar, Pragnya and Agarwal, Arav and Bogart, Christopher and Keylor, Eric and Kultur, Can and Savelka, Jaromir and Sakr, Majd},
title = {A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636256},
doi = {10.1145/3636243.3636256},
abstract = {There is a constant need for educators to develop and maintain effective up-to-date assessments. While there is a growing body of research in computing education on utilizing large language models&nbsp;(LLMs) in generation and engagement with coding exercises, the use of LLMs for generating programming MCQs has not been extensively explored. We analyzed the capability of GPT-4 to produce multiple-choice questions (MCQs) aligned with specific learning objectives (LOs) from Python programming classes in higher education. Specifically, we developed an LLM-powered (GPT-4) system for generation of MCQs from high-level course context and module-level LOs. We evaluated 651 LLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python courses. We found that GPT-4 was capable of producing MCQs with clear language, a single correct choice, and high-quality distractors. We also observed that the generated MCQs appeared to be well-aligned with the LOs. Our findings can be leveraged by educators wishing to take advantage of the state-of-the-art generative models to support MCQ authoring efforts.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {114–123},
numpages = {10},
keywords = {Assessments, Automated Content Generation, Automatic Generation, GPT-4, LLMs, LOs, Large Language Models, Learning Objectives, MCQs, Multiple-choice Questions},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3649165.3690116,
author = {Golesteanu, Matei A. and Vowinkel, Garrett B. and Dougherty, Ryan E.},
title = {Can ChatGPT pass a Theory of Computing Course?},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690116},
doi = {10.1145/3649165.3690116},
abstract = {Large Language Models (LLMs) have had considerable difficulty when prompted with mathematical and formal questions, especially those within theory of computing (ToC) courses. In this paper, we detail two experiments regarding our own ToC course and the ChatGPT LLM. For the first, we evaluated ChatGPT's ability to pass our own ToC course's exams. For the second, we created a database of sample ToC questions and responses to accommodate other ToC offerings' choices for topics and structure. We scored each of ChatGPT's outputs on these questions. Overall, we determined that ChatGPT can pass our ToC course, and is adequate at understanding common formal definitions and answering "simple''-style questions, e.g., true/false and multiple choice. However, ChatGPT often makes nonsensical claims in open-ended responses, such as proofs.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {33–38},
numpages = {6},
keywords = {automata theory, chatgpt, computer science education, formal languages, large language model, theoretical computer science},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3631802.3631845,
author = {Pirttinen, Nea and Leinonen, Juho},
title = {Could ChatGPT Be Used for Reviewing Learnersourced Exercises?},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631845},
doi = {10.1145/3631802.3631845},
abstract = {Large language models and tools based on large language models such as ChatGPT have received intense attention in the past year in computing education. In this work, we explore whether ChatGPT could be used to review learnersourced exercises. One of the major downsides of learnersourcing is the dubious quality of the created content, leading to many systems using peer review for curating the content. Our results suggest that ChatGPT is not yet ready for this task.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {42},
numpages = {2},
keywords = {ChatGPT, LLMs, crowdsourcing, generative AI, large language models, learnersourcing, reviews},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3650105.3652301,
author = {Macedo, Marcos and Tian, Yuan and Cogo, Filipe and Adams, Bram},
title = {Exploring the Impact of the Output Format on the Evaluation of Large Language Models for Code Translation},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650105.3652301},
doi = {10.1145/3650105.3652301},
abstract = {Code translation between programming languages is a long-existing and critical task in software engineering, facilitating the modernization of legacy systems, ensuring cross-platform compatibility, and enhancing software performance. With the recent advances in large language models (LLMs) and their applications to code translation, there is an increasing need for comprehensive evaluation of these models. In this study, we empirically analyze the generated outputs of eleven popular instruct-tuned LLMs with parameters ranging from 1B up to 46.7B on 3,820 translation pairs across five languages, including C, C++, Go, Java, and Python. Our analysis found that between 26.4% and 73.7% of code translations produced by our evaluated LLMs necessitate post-processing, as these translations often include a mix of code, quotes, and text rather than being purely source code. Overlooking the output format of these models can inadvertently lead to underestimation of their actual performance. This is particularly evident when evaluating them with execution-based metrics such as Computational Accuracy (CA). Our results demonstrate that a strategic combination of prompt engineering and regular expression can effectively extract the source code from the model generation output. In particular, our method can help eleven selected models achieve an average Code Extraction Success Rate (CSR) of 92.73%. Our findings shed light on and motivate future research to conduct more reliable benchmarks of LLMs for code translation.},
booktitle = {Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
pages = {57–68},
numpages = {12},
keywords = {code translation, output format, large language model, LLM, software engineering, benchmarking, evaluation, empirical study, case study},
location = {Lisbon, Portugal},
series = {FORGE '24}
}

@inproceedings{10.1145/3691620.3695277,
author = {Sahoo, Priyam and Pujar, Saurabh and Nalawade, Ganesh and Genhardt, Richard and Mandel, Louis and Buratti, Luca},
title = {Ansible Lightspeed: A Code Generation Service for IT Automation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695277},
doi = {10.1145/3691620.3695277},
abstract = {The availability of Large Language Models (LLMs) which can generate code, has made it possible to create tools that improve developer productivity. Integrated development environments or IDEs which developers use to write software are often used as an interface to interact with LLMs. Although many such tools have been released, almost all of them focus on general-purpose programming languages. Domain-specific languages, such as those crucial for Information Technology (IT) automation, have not received much attention. Ansible is one such YAML-based IT automation-specific language. Ansible Lightspeed is an LLM-based service designed explicitly to generate Ansible YAML, given natural language prompt.In this paper, we present the design and implementation of the Ansible Lightspeed service. We then evaluate its utility to developers using diverse indicators, including extended utilization, analysis of user edited suggestions, as well as user sentiments analysis. The evaluation is based on data collected for 10,696 real users including 3,910 returning users. The code for Ansible Lightspeed service and the analysis framework is made available for others to use.To our knowledge, our study is the first to involve thousands of users of code assistants for domain-specific languages. We are also the first code completion tool to present N-Day user retention figures, which is 13.66% on Day 30. We propose an improved version of user acceptance rate, called Strong Acceptance rate, where a suggestion is considered accepted only if less than 50% of it is edited and these edits do not change critical parts of the suggestion. By focusing on Ansible, Lightspeed is able to achieve a strong acceptance rate of 49.08% for multi-line Ansible task suggestions. With our findings we provide insights into the effectiveness of small, dedicated models in a domain-specific context. We hope this work serves as a reference for software engineering and machine learning researchers exploring code completion.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2148–2158},
numpages = {11},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3643787.3648032,
author = {Shome, Arumoy and Cruz, Luis and Van Deursen, Arie},
title = {Towards Automatic Translation of Machine Learning Visual Insights to Analytical Assertions},
year = {2024},
isbn = {9798400705762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643787.3648032},
doi = {10.1145/3643787.3648032},
abstract = {We present our vision for developing an automated tool capable of translating visual properties observed in Machine Learning (ML) visualisations into Python assertions. The tool aims to streamline the process of manually verifying these visualisations in the ML development cycle, which is critical as real-world data and assumptions often change post-deployment. In a prior study, we mined 54, 070 Jupyter notebooks from Github and created a catalogue of 269 semantically related visualisation-assertion (VA) pairs. Building on this catalogue, we propose to build a taxonomy that organises the VA pairs based on ML verification tasks. The input feature space comprises of a rich source of information mined from the Jupyter notebooks---visualisations, Python source code, and associated markdown text. The effectiveness of various AI models, including traditional NLP4Code models and modern Large Language Models, will be compared using established machine translation metrics and evaluated through a qualitative study with human participants. The paper also plans to address the challenge of extending the existing VA pair dataset with additional pairs from Kaggle and to compare the tool's effectiveness with commercial generative AI models like ChatGPT. This research not only contributes to the field of ML system validation but also explores novel ways to leverage AI for automating and enhancing software engineering practices in ML.},
booktitle = {Proceedings of the Third ACM/IEEE International Workshop on NL-Based Software Engineering},
pages = {29–32},
numpages = {4},
keywords = {SE4AI, NLP4Code, ML testing, visualisations, assertions, computational notebooks, automated tool},
location = {Lisbon, Portugal},
series = {NLBSE '24}
}

@inproceedings{10.1145/3626253.3633433,
author = {Liu, Rongxin and Zenke, Carter and Lloyd, Doug and Malan, David J.},
title = {Teaching with AI (GPT)},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633433},
doi = {10.1145/3626253.3633433},
abstract = {Teaching computer science at scale can be challenging. From our experience in CS50, Harvard University's introductory course, we've seen firsthand the impactful role that generative artificial intelligence can play in education. Recognizing its potential and stakes, we integrated OpenAI's GPT into our own teaching methodology. The goal was to emulate a 1:1 teacher-to-student ratio, incorporating "pedagogical guardrails" to maintain instructional integrity. The result was a personalized, AI-powered bot in the form of a friendly rubber duck aimed at delivering instructional responses and troubleshooting without giving outright solutions. We plan to share our journey and offer insights into responsibly harnessing AI in educational settings. Participants will gain hands-on experience working with GPT through OpenAI's APIs, understanding and crafting prompts, answering questions using embedding-based search, and finally, building their own AI chatbot. Ultimately, we'll not only share lessons learned from our own approach but also equip educators hands-on with the knowledge and tools with which they, too, can implement these technologies in their unique teaching environments.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1902},
numpages = {1},
keywords = {ai, artificial intelligence, chatgpt, ethics, generative ai, gpt, programming, prompt, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1109/ASE56229.2023.00157,
author = {Zhou, Xin and Kim, Kisub and Xu, Bowen and Liu, Jiakun and Han, DongGyun and Lo, David},
title = {The Devil is in the Tails: How Long-Tailed Code Distributions Impact Large Language Models},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00157},
doi = {10.1109/ASE56229.2023.00157},
abstract = {Learning-based techniques, especially advanced Large Language Models (LLMs) for code, have gained considerable popularity in various software engineering (SE) tasks. However, most existing works focus on designing better learning-based models and pay less attention to the properties of datasets. Learning-based models, including popular LLMs for code, heavily rely on data, and the data's properties (e.g., data distribution) could significantly affect their behavior. We conducted an exploratory study on the distribution of SE data and found that such data usually follows a skewed distribution (i.e., long-tailed distribution) where a small number of classes have an extensive collection of samples, while a large number of classes have very few samples. We investigate three distinct SE tasks and analyze the impacts of long-tailed distribution on the performance of LLMs for code. Our experimental results reveal that the long-tailed distribution has a substantial impact on the effectiveness of LLMs for code. Specifically, LLMs for code perform between 30.0% and 254.0% worse on data samples associated with infrequent labels compared to data samples of frequent labels. Our study provides a better understanding of the effects of long-tailed distributions on popular LLMs for code and insights for the future development of SE automation.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {40–52},
numpages = {13},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3677182.3677282,
author = {Huang, Haitao and Liang, Zijing and Fang, Zirui and Wang, Zhiyuan and Chen, Mingxiu and Hong, Yifan and Liu, Ke and Shang, Penghui},
title = {A Concise Review of Long Context in Large Language Models},
year = {2024},
isbn = {9798400709784},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677182.3677282},
doi = {10.1145/3677182.3677282},
abstract = {Sincerely in part to the rise of high-performance computer systems and transformer models, natural language processing has advanced. Also, a multitude of applications built on large language models continually improve people's cognitive abilities. Large language models continue to face difficulties when dealing with long context input. Many studies have suggested various specific strategies to address the challenge of extended context, however as of yet, no thorough summary of these studies exists. In this paper, we discuss the issues raised and the developments that have occurred in the long context application of large language models, and we attempt to suggest future directions for research and development.},
booktitle = {Proceedings of the International Conference on Algorithms, Software Engineering, and Network Security},
pages = {563–566},
numpages = {4},
location = {Nanchang, China},
series = {ASENS '24}
}

@inproceedings{10.1145/3716640.3716658,
author = {Feng, Tony Haoran and Luxton-Reilly, Andrew and W\"{u}nsche, Burkhard C and Denny, Paul},
title = {From Automation to Cognition: Redefining the Roles of Educators and Generative AI in Computing Education},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716658},
doi = {10.1145/3716640.3716658},
abstract = {Generative Artificial Intelligence (GenAI) offers numerous opportunities to revolutionise teaching and learning in Computing Education (CE). However, educators have expressed concerns that students may over-rely on GenAI and use these tools to generate solutions without engaging in the learning process. While substantial research has explored GenAI use in CE, and many Computer Science (CS) educators have expressed their opinions and suggestions on the subject, there remains little consensus on implementing curricula and assessment changes.In this paper, we describe our experiences with using GenAI in CS-focused educational settings and the changes we have implemented accordingly in our teaching in recent years since the popularisation of GenAI. From our experiences, we propose two primary actions for the CE community: 1) redesign take-home assignments to incorporate GenAI use and assess students on their process of using GenAI to solve a task rather than simply on the final product; 2) redefine the role of educators to emphasise metacognitive aspects of learning, such as critical thinking and self-evaluation. This paper presents and discusses these stances and outlines several practical methods to implement these strategies in CS classrooms. Then, we advocate for more research addressing the concrete impacts of GenAI on CE, especially those evaluating the validity and effectiveness of new teaching practices.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {164–171},
numpages = {8},
keywords = {Generative Artificial Intelligence, GenAI, Strategy, Assignments, Metacognition, Assessments},
location = {
},
series = {ACE '25}
}

@article{10.5555/3729857.3729874,
author = {Bandi, Ajay and Blackford, Benjamin and Fellah, Aziz and Linville, Diana and Meyer, Trevor C. and Voss, Robert J.},
title = {Prompting Collaboration: Development of an Multidisciplinary Applied AI Minor Program},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {6},
issn = {1937-4771},
abstract = {Artificial Intelligence (AI) has rapidly transformed industries and research, becoming a driving force for technological innovation and development [1]. As AI continues to grow and change, it is reshaping the way we approach problem-solving, decision-making, and creative processes across various sectors. Northwest Missouri State University is developing a new multidisciplinary AI minor open to all undergraduate students on campus. The program is tailored for students from any discipline who want to explore how AI can be utilized and integrated into their fields such as computer science, humanities, business, sciences, healthcare, agriculture, and education, among others. The curriculum integrates topics such as foundational AI concepts, prompt engineering and writing processes, ethical considerations in AI, AI in the workplace, and a capstone project. This program also promotes interdisciplinary collaboration and emphasizes the ethical use of AI.By the end of the program, students will be able to use AI to enhance efficiency and accuracy in tasks, develop and evaluate effective prompts, apply generative AI tools across various input formats, and assess the ethical considerations of AI in real-world applications. The panel members are experts from diverse fields, including management, humanities, technical writing, and computer science. The panel discusses the development of the AI minor curriculum and explores opportunities to extend the AI curriculum by offering AI certificates for undergraduate and graduate online professional students. By attending this panel, the audience will gain valuable insights into developing comprehensive AI programs, fostering cross-disciplinary innovation, and preparing students to use AI ethically and effectively across diverse fields.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {129–132},
numpages = {4}
}

@inproceedings{10.1145/3649217.3653612,
author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Denny, Paul},
title = {Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653612},
doi = {10.1145/3649217.3653612},
abstract = {Large language models (LLMs) have shown great potential for the automatic generation of feedback in a wide range of computing contexts. However, concerns have been voiced around the privacy and ethical implications of sending student work to proprietary models. This has sparked considerable interest in the use of open source LLMs in education, but the quality of the feedback that such open models can produce remains understudied. This is a concern as providing flawed or misleading generated feedback could be detrimental to student learning. Inspired by recent work that has utilised very powerful LLMs, such as GPT-4, to evaluate the outputs produced by less powerful models, we conduct an automated analysis of the quality of the feedback produced by several open source models using a dataset from an introductory programming course. First, we investigate the viability of employing GPT-4 as an automated evaluator by comparing its evaluations with those of a human expert. We observe that GPT-4 demonstrates a bias toward positively rating feedback while exhibiting moderate agreement with human raters, showcasing its potential as a feedback evaluator. Second, we explore the quality of feedback generated by several leading open-source LLMs by using GPT-4 to evaluate the feedback. We find that some models offer competitive performance with popular proprietary LLMs, such as ChatGPT, indicating opportunities for their responsible use in educational settings.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {52–58},
numpages = {7},
keywords = {automatic evaluation, automatic feedback, code llama, generative ai, gpt-4, large language models, llm-as-a-judge, llms, open source, programming feedback, zephyr},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3661167.3661172,
author = {Huotala, Aleksi and Kuutila, Miikka and Ralph, Paul and M\"{a}ntyl\"{a}, Mika},
title = {The Promise and Challenges of Using LLMs to Accelerate the Screening Process of Systematic Reviews},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661172},
doi = {10.1145/3661167.3661172},
abstract = {Context: Systematic review (SR) is a popular research method in software engineering (SE). However, conducting an SR takes an average of 67 weeks. Thus, automating any step of the SR process could reduce the effort associated with SRs. Objective: Our objective is to investigate the extent to which Large Language Models (LLMs) can accelerate title-abstract screening by (1) simplifying abstracts for human screeners, and (2) automating title-abstract screening entirely. Method: We performed an experiment where human screeners performed title-abstract screening for 20 papers with both original and simplified abstracts from a prior SR. The experiment with human screeners was reproduced by instructing GPT-3.5 and GPT-4 LLMs to perform the same screening tasks. We also studied whether different prompting techniques (Zero-shot (ZS), One-shot (OS), Few-shot (FS), and Few-shot with Chain-of-Thought (FS-CoT) prompting) improve the screening performance of LLMs. Lastly, we studied if redesigning the prompt used in the LLM reproduction of title-abstract screening leads to improved screening performance. Results: Text simplification did not increase the screeners’ screening performance, but reduced the time used in screening. Screeners’ scientific literacy skills and researcher status predict screening performance. Some LLM and prompt combinations perform as well as human screeners in the screening tasks. Our results indicate that a more recent LLM (GPT-4) is better than its predecessor LLM (GPT-3.5). Additionally, Few-shot and One-shot prompting outperforms Zero-shot prompting. Conclusion: Using LLMs for text simplification in the screening process does not significantly improve human performance. Using LLMs to automate title-abstract screening seems promising, but current LLMs are not significantly more accurate than human screeners. To recommend the use of LLMs in the screening process of SRs, more research is needed. We recommend future SR studies to publish replication packages with screening data to enable more conclusive experimenting with LLM screening.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {262–271},
numpages = {10},
keywords = {ChatGPT, GPT-3.5, GPT-4, LLMs, Screening Process of Systematic Reviews, Text Simplification},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1109/ASE56229.2023.00010,
author = {Das, Debeshee and Mathews, Noble Saji and Mathai, Alex and Tamilselvam, Srikanth and Sedamaki, Kranthi and Chimalakonda, Sridhar and Kumar, Atul},
title = {COMEX: A Tool for Generating Customized Source Code Representations},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00010},
doi = {10.1109/ASE56229.2023.00010},
abstract = {Learning effective representations of source code is critical for any Machine Learning for Software Engineering (ML4SE) system. Inspired by natural language processing, large language models (LLMs) like Codex and CodeGen treat code as generic sequences of text and are trained on huge corpora of code data, achieving state of the art performance on several software engineering (SE) tasks. However, valid source code, unlike natural language, follows a strict structure and pattern governed by the underlying grammar of the programming language. Current LLMs do not exploit this property of the source code as they treat code like a sequence of tokens and overlook key structural and semantic properties of code that can be extracted from code-views like the Control Flow Graph (CFG), Data Flow Graph (DFG), Abstract Syntax Tree (AST), etc. Unfortunately, the process of generating and integrating code-views for every programming language is cumbersome and time consuming. To overcome this barrier, we propose our tool COMEX - a framework that allows researchers and developers to create and combine multiple code-views which can be used by machine learning (ML) models for various SE tasks. Some salient features of our tool are: (i) it works directly on source code (which need not be compilable), (ii) it currently supports Java and C#, (iii) it can analyze both method-level snippets and program-level snippets by using both intra-procedural and inter-procedural analysis, and (iv) it is easily extendable to other languages as it is built on tree-sitter - a widely used incremental parser that supports over 40 languages. We believe this easy-to-use code-view generation and customization tool will give impetus to research in source code representation learning methods and ML4SE. The source code and demonstration of our tool can be found at https://github.com/IBM/tree-sitter-codeviews and https://youtu.be/GER6U87FVbU, respectively.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2054–2057},
numpages = {4},
keywords = {representation learning, static analysis},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3641555.3705281,
author = {Li, Carol and Park, Su Min and Tsang, Jedidiah and Yan, Lisa},
title = {What Gets Them Talking? Identifying Catalysts for Student Engagement Within a Computing Ethics Course},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705281},
doi = {10.1145/3641555.3705281},
abstract = {The expansion of undergraduate CS programs brings different forms of student identity, sociotechnical perspectives, and intersectionality into the classroom. These background factors affect student understanding of the world, and, consequently, their work in computing ethic classes. Instructors of computing ethics courses therefore must facilitate topics that are not only pertinent to modern technologies but that are also interesting for students from a range of backgrounds. In this work, we introduce a low-overhead, natural language processing tool that can assist instructors in extracting student talking points from over 600 discussion forum posts in a large-scale undergraduate computing ethics course. When compared to large language model approaches, this n-gram-based scripting tool is more effective in selecting popular quotes and summarizing course discussion. This tool is simple in implementation and can be easily adapted by instructors to prepare for classroom discussion.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1521–1522},
numpages = {2},
keywords = {computing ethics, llm-based tool, n-gram-based tool, open pedagogy, student engagement},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3568813.3600139,
author = {Hellas, Arto and Leinonen, Juho and Sarsa, Sami and Koutcheme, Charles and Kujanp\"{a}\"{a}, Lilja and Sorva, Juha},
title = {Exploring the Responses of Large Language Models to Beginner Programmers’ Help Requests},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600139},
doi = {10.1145/3568813.3600139},
abstract = {Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence. Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers’ help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on. Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students’ code and assessed the LLM-generated answers both quantitatively and qualitatively. Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 57% of the time). False positives are common (40% chance for GPT-3.5). The advice that the LLMs provide on the issues is often sensible. The LLMs perform better on issues involving program logic rather than on output formatting. Model solutions are frequently provided even when the LLM is prompted not to. LLM responses to prompts in a non-English language are only slightly worse than responses to English prompts. Implications: Our results continue to highlight the utility of LLMs in programming education. At the same time, the results highlight the unreliability of LLMs: LLMs make some of the same mistakes that students do, perhaps especially when formatting output as required by automated assessment systems. Our study informs teachers interested in using LLMs as well as future efforts to customize LLMs for the needs of programming education.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {93–105},
numpages = {13},
keywords = {CS1, GPT, OpenAI Codex, automatic feedback, help seeking, introductory programming education, large language models, student questions},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3649217.3653554,
author = {Liu, Suqing and Yu, Zezhu and Huang, Feiran and Bulbulia, Yousef and Bergen, Andreas and Liut, Michael},
title = {Can Small Language Models With Retrieval-Augmented Generation Replace Large Language Models When Learning Computer Science?},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653554},
doi = {10.1145/3649217.3653554},
abstract = {Leveraging Large Language Models (LLMs) for personalized learning and support is becoming a promising tool in computing education. AI Assistants can help students with programming, problem-solving, converse with them to clarify course content, explain error messages to help with debugging, and much more. However, using cloud-based LLMs poses risks around data security, privacy, but also control of the overarching system.To address these concerns, we created a locally-stored Small Language Model (SLM) that leverages different Retrieval-Augmented Generation (RAG) methods to support computing students' learning. We compare one SLM (neural-chat-7b-v3 - fine-tuned version of Mistral-7B-v0.1) against two popular LLMs (gpt-3.5-turbo and gpt-4-32k) to see the viability for computing educators to use in their course(s).We use conversations from a CS1 course (N = 1,260), providing students with an AI Assistant (using gpt-3.5-turbo) to help them learn content and support problem-solving while completing their Python programming assignment. In total, we had 269 students use the AI Assistant, with a total of 1,988 questions asked. Using this real conversational data, we re-ran student questions using our novel SLM (neural-chat-7b-v3 testing nine different RAG methods) and gpt-4-32k, then compared those results against the original gpt-3.5-turbo responses. Our findings indicate that using an SLM with RAG can perform similarly, if not better, than LLMs. This shows that it is possible for computing educators to use SLMs (with RAG) in their course(s) as a tool for scalable learning, supporting content understanding and problem-solving needs, while employing their own policies on data privacy and security.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {388–393},
numpages = {6},
keywords = {computing education, conversational agent, cs1, intelligence concentration, intelligent teaching assistant, intelligent tutoring system, large language models, locally deployable ai, personalized ai agent, retrieval augmented generation, small language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3716640.3716657,
author = {Arora, Utkarsh and Garg, Anupam and Gupta, Aryan and Jain, Samyak and Mehta, Ronit and Oberoi, Rupin and Prachi and Raina, Aryaman and Saini, Manav and Sharma, Sachin and Singh, Jaskaran and Tyagi, Sarthak and Kumar, Dhruv},
title = {Analyzing LLM Usage in an Advanced Computing Class in India},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716657},
doi = {10.1145/3716640.3716657},
abstract = {This study examines the use of large language models (LLMs) by undergraduate and graduate students for programming assignments in advanced computing classes. Unlike existing research, which primarily focuses on introductory classes and lacks in-depth analysis of actual student-LLM interactions, our work fills this gap. We conducted a comprehensive analysis involving 411 students from a Distributed Systems class at an Indian university, where they completed three programming assignments and shared their experiences through Google Form surveys and interviews.Our findings reveal that students leveraged LLMs for a variety of tasks, including code generation, debugging, conceptual inquiries, and test case creation. They employed a spectrum of prompting strategies, ranging from basic contextual prompts to advanced techniques like chain-of-thought prompting and iterative refinement. While students generally viewed LLMs as beneficial for enhancing productivity and learning, we noted a concerning trend of over-reliance, with many students submitting entire assignment descriptions to obtain complete solutions. Given the increasing use of LLMs in the software industry, our study highlights the need to update undergraduate curricula to include training on effective prompting strategies and to raise awareness about the benefits and potential drawbacks of LLM usage in academic settings.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {154–163},
numpages = {10},
keywords = {Large Language Models, Computing Education, User Study},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3649217.3653527,
author = {Martini, Simone},
title = {Teaching Programming in the Age of Generative AI},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653527},
doi = {10.1145/3649217.3653527},
abstract = {Programming has been considered the "essence of informatics" since the beginning of computing as a discipline. But programming in the fifties was very different from what we know today, and one of the goals (or dreams) throughout the history of programming language technology, has been "automatic programming''---the ability to automatically generate computer code starting from a high(er)-level description of the specification of that code. What this meant changed over the years, from punching paper tape, to compiling high-level programming languages, to program synthesis.Today, however, the availability of machine learning artefacts that produce high-level code from natural language specifications has completely changed the traditional meaning. To the extent that some computer scientists have begun to question the received wisdom that the core of their discipline is deeply rooted in programming.If programming and programming languages are no longer the essence of computer science, this changes the epistemology of the discipline itself. Moreover, if we are at the end of programming, we should also change the curriculum, where programming, algorithms and programming languages play a major role. Several recent papers reviewed the performance of code generators based on large language models on typical CS1 problems (e.g., from the many possible citations and how machine learning impacts K-12 teaching.Starting from this data, I will argue for the role of programming in the curriculum, distinguishing between programming taught as part of a holistic curriculum (as in some non-technical high schools) or as a vocational tool. I will use Simondon's notion of (closed and open) technical object as an interpretive lens, together with Calvino's reflections on the availability of writing machines capable of replacing the poet and the author.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {1–2},
numpages = {2},
keywords = {epistemology, large language models, programming},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@article{10.1145/3585060.3585063,
author = {Lopez, Patty},
title = {Reflections on the Design of Systems that Impact Computers and Society},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0095-2737},
url = {https://doi.org/10.1145/3585060.3585063},
doi = {10.1145/3585060.3585063},
abstract = {Having spent the past year post-retirement working with my alma mater, New Mexico State University's (NMSU) Computer Science department to broaden computing, increase student engagement, and to improve graduation completion, as well as reflecting on the state of computing in society at large, I thought I'd share some observations. In March of this year, I had the opportunity to participate in the SIGCSE 2022 Technical Symposium. I was struck by Dr. Shaundra Daily's plenary keynote, entitled "Diversifying Computing: Real Change Must Come from Within", and her use of the phrase "navigating systems that were not designed for me" as she described her exploration of STEM as a first-generation college student, as both a dance and an engineering student, and as a graduate student preparing for motherhood lacking flexibility during her pregnancy, no maternity leave, no livable stipend, and a lack of affordable childcare, as well as the coping strategies she needed to develop to deal with academic culture. In my work with NMSU this past spring, co-teaching a problem solving course, my work this fall advising CS students, and my board roles serving on the National Academy of Science, Engineering, and Medicine's Roundtable for Systemic Change in Undergraduate STEM Education co-chairing the "Culture of STEM" workgroup, on the Computing Alliance of Hispanic Serving Institution's (CAHSI) Advisory Board, and on the Computing Research Association for Widening Participation (CRA-WP), co-editing the "Expanding the Pipeline" column, it's clear that system design adversely impacts society in terms of determining not only who gets to participate in the design of computer hardware and software, but also who gets to advance in social and economic mobility. Academic institutions are complex systems in need of an overhaul, by the University of California's academic workers strike for better pay and benefits. The design and commercialization of AI without fully understanding the implications of bias and ethics is inherently a system design problem. The application to everything from AI generated art and images (and how to spot deep fakes), the ability of large language models (LLMs) to create volumes of text generated articles that appear legitimate with the capacity to spread hate and misinformation globally are but just a few examples of the potentially horrific impact to society, because humans cannot work at the pace and scale to validate and/or authenticate them, with few if any meaningful domestic and international laws or policies in place to safeguard us.},
journal = {SIGCAS Comput. Soc.},
month = feb,
pages = {9},
numpages = {1},
keywords = {system design, ethics, diversity, bias}
}

@inproceedings{10.1145/3706599.3716299,
author = {Hwang, Angel Hsing-Chi and Bernstein, Michael S. and Sundar, S. Shyam and Zhang, Renwen and Horta Ribeiro, Manoel and Lu, Yingdan and Chang, Serina and Wu, Tongshuang and Yang, Aimei and Williams, Dmitri and Park, Joon Sung and Ognyanova, Katherine and Xiao, Ziang and Shaw, Aaron and Shamma, David A.},
title = {Human Subjects Research in the Age of Generative AI: Opportunities and Challenges of Applying LLM-Simulated Data to HCI Studies},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3716299},
doi = {10.1145/3706599.3716299},
abstract = {Rapid advances in generative artificial intelligence suggest new possibilities for how human subjects research can be conducted in HCI studies. The panel invites both computer and social scientists to discuss future directions for applying simulated responses from large language models (LLM) for human subjects research. We discuss current challenges and opportunities in LLM simulations and brainstorm how insights across different disciplines might inform breakthroughs. We pay close attention to when and how applications of LLM simulations might augment human subjects research instead of steering it toward unintended directions. Discussions from the panel will provide preliminary ideas for when and how HCI researchers can apply LLM simulations to human subjects research pipelines. Through this engagement, we also aim to build a research community with shared interests.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {761},
numpages = {7},
keywords = {LLM simulation, synthetic data, human subject research, social science in HCI},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3626252.3630828,
author = {Prasad, Prajish and Sane, Aamod},
title = {A Self-Regulated Learning Framework using Generative AI and its Application in CS Educational Intervention Design},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630828},
doi = {10.1145/3626252.3630828},
abstract = {Self-regulation refers to the ability to plan, monitor, control and reflect on one's problem-solving process. Prior research has shown that self-regulated learning (SRL) strategies help improve novice performance in solving programming problems. However, with the advent of LLM tools like ChatGPT, novices can generate fairly accurate code by just providing the problem prompt, and hence may forego applying essential self-regulation strategies such as planning and reflection to solve the problem. In this position paper, we discuss challenges and opportunities that generative AI technologies pose for novices' self-regulation strategies in the context of programming problem solving. We believe that the key challenge facing educators is that such technologies may hamper novices' ability to regulate their programming problem solving process.On the other hand, these technologies also open up the possibility to design new interventions that promote better SRL strategies in learners. We draw on generic and domain-specific self-regulated learning theories as the basis of our work, and propose an SRL framework that incorporates use of generative AI tools in programming problem solving. We illustrate how the proposed framework guides exploration of the design space of interventions that integrate generative AI in CS education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1070–1076},
numpages = {7},
keywords = {chatgpt, generative ai, llm, metacognition, pair programming, pair thinking, self-regulated learning, self-regulation, srl},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3737882,
author = {Salvi, Rohan Charudatt and Bosch, Nigel},
title = {Investigating Perception of Gender Stereotypes in Large Language Models: A Computational Grounded Theory Approach},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3737882},
doi = {10.1145/3737882},
abstract = {Artificial Intelligence has expanded its influence far beyond traditional boundaries in our society. One prominent application of artificial intelligence is the use of large language models, which have transcended their initial roles in high-tech industries and academic research and are now actively utilized by individual users. These models have continually improved over the years in their generative capabilities and performance across numerous tasks. However, they still pose a persistent risk of reproducing biases and stereotypes. Previous research has predominantly focused on quantitatively measuring biases in these large language models. In this study, we seek to assess not just the presence of bias itself, but the perception of stereotypes by these models via in-depth exploration of their responses. We demonstrate how the computational grounded theory framework, which integrates qualitative and quantitative approaches, can be applied in this context to assess the conceptualization of stereotypes. Furthermore, we contrast language model results with a survey of 400 human participants who also completed similar prompts as the model in order to understand people’s perception of gender stereotypes. The results indicate substantial similarities between language model and human perceptions of stereotypes, highlighting that a model’s perception stems from societal perception of stereotypes.},
note = {Just Accepted},
journal = {ACM J. Responsib. Comput.},
month = jun,
keywords = {Large language models, mixed methods, grounded theory, computational social science, LLM bias}
}

@article{10.1145/3680471,
author = {Russo, Daniel},
title = {Navigating the Complexity of Generative AI Adoption in Software Engineering—RCR Report},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {8},
issn = {1049-331X},
url = {https://doi.org/10.1145/3680471},
doi = {10.1145/3680471},
abstract = {This Replicated Computational Results (RCR) report complements the study “Navigating the Complexity of Generative AI Adoption in Software Engineering,” which examines the factors influencing the integration of AI tools in software engineering practices. Employing a mixed-methods approach grounded in the Technology Acceptance Model, Diffusion of Innovation Theory, and Social Cognitive Theory, the study introduces the Human-AI Collaboration and Adaptation Framework (HACAF), validated through PLS-SEM analysis. The replication package detailed herein includes survey instruments, raw data, and analysis scripts essential for reproducing the study's findings. By providing these artifacts, the RCR report aims to support transparency, enable replication, and encourage further research on effective AI tool adoption strategies in software engineering.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {221},
numpages = {5},
keywords = {Generative AI, Large Language Models, Technology Adaption, Empirical Software Engineering}
}

@inproceedings{10.1145/3626252.3630909,
author = {Denny, Paul and Leinonen, Juho and Prather, James and Luxton-Reilly, Andrew and Amarouche, Thezyrie and Becker, Brett A. and Reeves, Brent N.},
title = {Prompt Problems: A New Programming Exercise for the Generative AI Era},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630909},
doi = {10.1145/3626252.3630909},
abstract = {Large language models (LLMs) are revolutionizing the field of computing education with their powerful code-generating capabilities. Traditional pedagogical practices have focused on code writing tasks, but there is now a shift in importance towards reading, comprehending and evaluating LLM-generated code. Alongside this shift, an important new skill is emerging -- the ability to solve programming tasks by constructing good prompts for code-generating models. In this work we introduce a new type of programming exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are designed to help students learn how to write effective prompts for AI code generators. A student solves a Prompt Problem by crafting a natural language prompt which, when provided as input to an LLM, outputs code that successfully solves a specified programming task. We also present a new web-based tool called Promptly which hosts a repository of Prompt Problems and supports the automated evaluation of prompt-generated code. We deploy Promptly in one CS1 and one CS2 course and describe our experiences, which include student perceptions of this new type of activity and their interactions with the tool. We find that students are enthusiastic about Prompt Problems, and appreciate how the problems engage their computational thinking skills and expose them to new programming constructs. We discuss ideas for the future development of new variations of Prompt Problems, and the need to carefully study their integration into classroom practice.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {296–302},
numpages = {7},
keywords = {ai code generation, artificial intelligence, generative ai, large language models, llms, prompt engineering, prompt problems},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3597503.3639219,
author = {Du, Xueying and Liu, Mingwei and Wang, Kaixin and Wang, Hanlin and Liu, Junwei and Chen, Yixuan and Feng, Jiayi and Sha, Chaofeng and Peng, Xin and Lou, Yiling},
title = {Evaluating Large Language Models in Class-Level Code Generation},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639219},
doi = {10.1145/3597503.3639219},
abstract = {Recently, many large language models (LLMs) have been proposed, showing advanced proficiency in code generation. Meanwhile, many efforts have been dedicated to evaluating LLMs on code generation benchmarks such as HumanEval. Although being very helpful for comparing different LLMs, existing evaluation focuses on a simple code generation scenario (i.e., function-level or statement-level code generation), which mainly asks LLMs to generate one single code unit (e.g., a function or a statement) for the given natural language description. Such evaluation focuses on generating independent and often small-scale code units, thus leaving it unclear how LLMs perform in real-world software development scenarios.To fill this knowledge gap, we make the first attempt to evaluate LLMs in a more challenging code generation scenario, i.e., class-level code generation. Compared with existing code generation benchmarks, it better reflects real-world software development scenarios due to it comprising broader contextual dependencies and multiple, interdependent units of code. We first manually construct the first class-level code generation benchmark ClassEval of 100 class-level Python code generation tasks with approximately 500 person-hours. Based on the new benchmark ClassEval, we then perform the first study of 11 state-of-the-art LLMs on class-level code generation. Based on our results, we find that all LLMs perform much worse on class-level code generation compared to the method-level. While GPT models still dominate other LLMs on class-level code generation, the performance rankings of other models on method-level code generation no longer holds for class-level code generation. Besides, most models (except GPT models) perform better when generating the class method by method; and they have the limited ability of generating dependent code. Based on our findings, we call for software engineering (SE) researchers' expertise to build more LLM benchmarks based on practical and complicated software development scenarios.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {81},
numpages = {13},
keywords = {class-level code generation, large language model, benchmark},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1109/ASE56229.2023.00096,
author = {Yan, Dapeng and Gao, Zhipeng and Liu, Zhiming},
title = {A Closer Look at Different Difficulty Levels Code Generation Abilities of ChatGPT},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00096},
doi = {10.1109/ASE56229.2023.00096},
abstract = {Code generation aims to generate source code implementing human requirements illustrated with natural language specifications. With the rapid development of intelligent software engineering, automated code generation has become a hot research topic in both artificial intelligence and software engineering, and researchers have made significant achievements on code generation. More recently, large language models (LLMs) have demonstrated outstanding performance on code generation tasks, such as ChatGPT released by OpenAI presents the fantastic potential on automated code generation. However, the existing studies are limited to exploring LLMs' ability for generating code snippets to solve simple programming problems, the task of competition-level code generation has never been investigated. The specifications of the programming competition are always complicated and require the specific input/output format as well as the high-level algorithmic reasoning ability. In this study, we conduct the first large empirical study to investigate the zero-shot learning ability of ChatGPT for solving competition programming problems. Specifically, we warm up the design of prompts by using the Human-Eval dataset. Then, we apply the well-designed prompt to the competition-level code generation dataset, namely APPS, to further explore the effectiveness of using ChatGPT for solving competition problems. We collect ChatGPT's outputs on 5,000 code competition problems, the evaluation results show that it can successfully pass 25.4% test cases. By further feeding extra information (e.g, test failed information) to ChatGPT, we observe that ChatGPT has the potential to fix partial pass into a fully pass program. Moreover, we investigate the solutions generated by LLMs and the existing solutions, we find that it prefers to directly copy the code instead of re-write when facing more difficult problems. Finally, we evaluate the code quality generated by ChatGPT in terms of "code cleanness", we observe that the generated codes are with small functions and file sizes, which are in line with the standard of clean code.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1887–1898},
numpages = {12},
keywords = {code generation, program competition, Chat-GPT, large language model, clean code},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3703187.3703290,
author = {Ma, Xiangfei and Li, Lin},
title = {Geological Disaster Named Entity Recognition with Small Samples Based on Data Augmentation and Prompt Engineering},
year = {2024},
isbn = {9798400707254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703187.3703290},
doi = {10.1145/3703187.3703290},
abstract = {This paper uses a large language model to perform generative data enhancement on the original small sample data by performing random synonym replacement and random mask filling operations. In accordance with the reasoning logic of the large language model, three prompt templates are designed and the reasons are explored. Experiments show that when the parameters remain unchanged, the data enhanced by this method has been greatly improved under the three prompt templates, alleviating the difficulty of low resources of geological disaster data. And by comparing the performance of different instructions under different learning rates, the fine-tuning learning rate range suitable for the field of geological disasters is summarized. The limitation is that it is constrained by local computing resources, which reduces the parameter scale of LLM, and the recognition performance is low for extremely long or complex texts.},
booktitle = {Proceedings of the 2024 7th International Conference on Computer Information Science and Artificial Intelligence},
pages = {613–617},
numpages = {5},
keywords = {Data Augmentation, Geological Disasters, LLMs, Named Entity Recognition, Prompt Engineering},
location = {
},
series = {CISAI '24}
}

@inproceedings{10.1145/3641554.3701859,
author = {Gorson Benario, Jamie and Marroquin, Jenn and Chan, Monica M. and Holmes, Ernest D.V. and Mejia, Daniel},
title = {Unlocking Potential with Generative AI Instruction: Investigating Mid-level Software Development Student Perceptions, Behavior, and Adoption},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701859},
doi = {10.1145/3641554.3701859},
abstract = {Generative AI tools are rapidly evolving and impacting many domains, including programming. Computer Science (CS) instructors must address student access to these tools. While some advocate to ban the tools entirely, others suggest embracing them so that students develop the skills for utilizing the tools safely and responsibly. Studies indicate positive impacts, as well as cautions, on student outcomes when these tools are integrated into courses. We studied the impact of incorporating instruction on industry-standard generative AI tools into a mid-level software development course with students from 16 Minority Serving Institutions. 89% of student participants used generative AI tools prior to the course without any formal instruction. After formal instruction, students most frequently used generative AI tools for explaining concepts and learning new things. Students generally reported positive viewpoints on their ability to learn to program and learn problem-solving skills while using generative AI tools. Finally, we found that students: reported to understand their code when they work with generative AI tools, are critical about the outputs that generative AI tools provide, and check outputs of generative AI tools to ensure accuracy.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {395–401},
numpages = {7},
keywords = {cs education, generative ai, llms in cs education, minority serving institutions},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3686852.3687073,
author = {Servin, Christian and Karichev, Nadia V. and Pagel, Myshie},
title = {Unfolding Programming: How to Use AI Tools in Introductory Computing Courses},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3687073},
doi = {10.1145/3686852.3687073},
abstract = {Artificial Intelligence (AI) generative tools, commonly referred to as AI-based tools, have become integral in various computing domains, including education. The widespread adoption of these tools has raised concerns among educators, spanning from issues related to plagiarism and comprehension gaps to potential threats to student identity. Consequently, educators are grappling with how to adapt their courses and incorporate AI technologies into their curriculum and pedagogical approaches. In addition to navigating challenges associated with AI regulations, educators face the compounded difficulty of addressing post-pandemic issues, such as students displaying diminished effort and professionalism in the classroom. The convergence of these two challenges creates a complex scenario that intertwines technical and professional considerations. Within the Computer Science Fundamentals course, commonly referred to as CS 1, the learning process revolves around comprehending programming through a sequential understanding of steps, as each concept builds upon the preceding one. This investigation centers on the CS 1 curriculum within an American two-year program, commonly known as a community college. The objective is to address a problem by leveraging an AI tool within team settings. The study assesses both problem-solving capabilities and the effectiveness of teamwork, providing recommendations to guide students in the proper utilization of AI tools. The emphasis is on fostering contextual relevance and collaborative work within the generative learning process.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {49–55},
numpages = {7},
keywords = {ai-tools, community colleges, prompt programming, two-year},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3689535.3689554,
author = {Santos, Eddie Antonio and Becker, Brett A.},
title = {Not the Silver Bullet: LLM-enhanced Programming Error Messages are Ineffective in Practice},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689554},
doi = {10.1145/3689535.3689554},
abstract = {The sudden emergence of large language models (LLMs) such as ChatGPT has had a disruptive impact throughout the computing education community. LLMs have been shown to excel at producing correct code to CS1 and CS2 problems, and can even act as friendly assistants to students learning how to code. Recent work shows that LLMs demonstrate unequivocally superior results in being able to explain and resolve compiler error messages—for decades, one of the most frustrating parts of learning how to code. However, LLM-generated error message explanations have only been assessed by expert programmers in artificial conditions. This work sought to understand how novice programmers resolve programming error messages (PEMs) in a more realistic scenario. We ran a within-subjects study with n = 106 participants in which students were tasked to fix six buggy C programs. For each program, participants were randomly assigned to fix the problem using either a stock compiler error message, an expert-handwritten error message, or an error message explanation generated by GPT-4. Despite promising evidence on synthetic benchmarks, we found that GPT-4 generated error messages outperformed conventional compiler error messages in only 1 of the 6 tasks, measured by students’ time-to-fix each problem. Handwritten explanations still outperform LLM and conventional error messages, both on objective and subjective measures.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {5},
numpages = {7},
keywords = {AI, C, CS1, GPT-4, GenAI, Generative AI, LLMs, PEM, compiler error messages, computing education, debugging, feedback, large language models, novice programmers, programming error messages},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3587102.3588785,
author = {Leinonen, Juho and Denny, Paul and MacNeil, Stephen and Sarsa, Sami and Bernstein, Seth and Kim, Joanne and Tran, Andrew and Hellas, Arto},
title = {Comparing Code Explanations Created by Students and Large Language Models},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588785},
doi = {10.1145/3587102.3588785},
abstract = {Reasoning about code and explaining its purpose are fundamental skills for computer scientists. There has been extensive research in the field of computing education on the relationship between a student's ability to explain code and other skills such as writing and tracing code. In particular, the ability to describe at a high-level of abstraction how code will behave over all possible inputs correlates strongly with code writing skills. However, developing the expertise to comprehend and explain code accurately and succinctly is a challenge for many students. Existing pedagogical approaches that scaffold the ability to explain code, such as producing exemplar code explanations on demand, do not currently scale well to large classrooms. The recent emergence of powerful large language models (LLMs) may offer a solution. In this paper, we explore the potential of LLMs in generating explanations that can serve as examples to scaffold students' ability to understand and explain code. To evaluate LLM-created explanations, we compare them with explanations created by students in a large course (n ≈ 1000) with respect to accuracy, understandability and length. We find that LLM-created explanations, which can be produced automatically on demand, are rated as being significantly easier to understand and more accurate summaries of code than student-created explanations. We discuss the significance of this finding, and suggest how such models can be incorporated into introductory programming education.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {124–130},
numpages = {7},
keywords = {CS1, ChatGPT, GPT-3, GPT-4, code comprehension, code explanations, foundation models, large language models, natural language generation, resource generation},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3649217.3653575,
author = {Smith, C. Estelle and Shiekh, Kylee and Cooreman, Hayden and Rahman, Sharfi and Zhu, Yifei and Siam, Md Kamrul and Ivanitskiy, Michael and Ahmed, Ahmed M. and Hallinan, Michael and Grisak, Alexander and Fierro, Gabe},
title = {Early Adoption of Generative Artificial Intelligence in Computing Education: Emergent Student Use Cases and Perspectives in 2023},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653575},
doi = {10.1145/3649217.3653575},
abstract = {Because of the rapid development and increasing public availability of Generative Artificial Intelligence (GenAI) models and tools, educational institutions and educators must immediately reckon with the impact of students using GenAI. There is limited prior research on computing students' use and perceptions of GenAI. In anticipation of future advances and evolutions of GenAI, we capture a snapshot of student attitudes towards and uses of yet emerging GenAI, in a period of time before university policies had reacted to these technologies. We surveyed all computer science majors in a small engineering-focused R1 university in order to: (1) capture a baseline assessment of how GenAI has been immediately adopted by aspiring computer scientists; (2) describe computing students' GenAI-related needs and concerns for their education and careers; and (3) discuss GenAI influences on CS pedagogy, curriculum, culture, and policy. We present an exploratory qualitative analysis of this data and discuss the impact of our findings on the emerging conversation around GenAI and education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {3–9},
numpages = {7},
keywords = {ai literacy, code generator, education, generative artificial intelligence, image generator, interactive tutoring, large language model, policy, student experience, survey},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3631802.3631816,
author = {Malaise, Yoshi and Signer, Beat},
title = {Explorotron: An IDE Extension for Guided and Independent Code Exploration and Learning (Discussion Paper)},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631816},
doi = {10.1145/3631802.3631816},
abstract = {We introduce the Explorotron Visual Studio Code extension for guided and independent code exploration and learning. Explorotron is a continuation of earlier work to explore how we can enable small organisations with limited resources to provide pedagogically sound learning experiences in programming. We situate Explorotron in the field of Computing Education Research&nbsp;(CER) and envision it to initiate a discussion around different topics, including how to balance the optimisation between the researcher-student-teacher trifecta that is inherent in CER, how to ethically and responsibly use large language models&nbsp;(LLMs) in the independent learning and exploration by students, and how to define better learning sessions over coding content that students obtained on their own. We further reflect on the question raised by Begel and Ko whether technology should “structure learning for learners” or whether learners should “be taught how to structure their own independent learning” outside of the classroom.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {24},
numpages = {8},
keywords = {PRIMM, Programming Education, Study Lenses},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3626203.3670628,
author = {Oelgoetz, Megan and Walker, Tony},
title = {Improving an NSF ACCESS Program AI Chatbot: Response Data Logistic Regression},
year = {2024},
isbn = {9798400704192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626203.3670628},
doi = {10.1145/3626203.3670628},
abstract = {The NSF ACCESS program has implemented a vendor-supplied AI chatbot using the OpenAI GPT-4 large language model. ACCESS provides high performance computing (HPC) resources to researchers by allocating time at computing centers at diverse institutions of higher education across the United States. Effectively implementing a large language model on a limited knowledge base for the diversity of the resources and technical nature of HPC in general has raised questions in optimal knowledge base construction. The following analysis takes a limited test case to investigate the driving factors contributing to the accuracy of the chatbot’s response to predetermined prompts, specifically regarding the clusters on which specific software applications are currently available. It additionally tests the necessity of providing documentation of synonymous terms in the form of a synonym dictionary in the knowledge base. While ongoing, this initial research utilizing logistic regression suggests the knowledge base is yet insufficient for the prompts given and that the synonym dictionary has no statistically significant effect on the response.},
booktitle = {Practice and Experience in Advanced Research Computing 2024: Human Powered Computing},
articleno = {101},
numpages = {3},
keywords = {Artificial Intelligence, HPC Facilitation, Logistic Regression, Natural Language Processing},
location = {Providence, RI, USA},
series = {PEARC '24}
}

@inproceedings{10.1145/3706598.3713447,
author = {Falk, Jeanette and Chen, Yiyi and Rafner, Janet and Zhang, Mike and Bjerva, Johannes and Nolte, Alexander},
title = {How Do Hackathons Foster Creativity? Towards Automated Evaluation of Creativity at Scale},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713447},
doi = {10.1145/3706598.3713447},
abstract = {Hackathons have become popular collaborative events for accelerating the development of creative ideas and prototypes. There are several case studies showcasing creative outcomes across domains such as industry, education, and research. However, there are no large-scale studies on creativity in hackathons which can advance theory on how hackathon formats lead to creative outcomes. We conducted a computational analysis of 193,353 hackathon projects. By operationalizing creativity through usefulness and novelty, we refined our dataset to 10,363 projects, allowing us to analyze how participant characteristics, collaboration patterns, and hackathon setups influence the development of creative projects. The contribution of our paper is twofold: We identified means for organizers to foster creativity in hackathons. We also explore the use of large language models (LLMs) to augment the evaluation of creative outcomes and discuss challenges and opportunities of doing this, which has implications for creativity research at large.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {198},
numpages = {23},
keywords = {Hackathons, creativity, human-centered AI, large language models, quantitative methods},
location = {
},
series = {CHI '25}
}

@article{10.1145/3660773,
author = {Hossain, Soneya Binta and Jiang, Nan and Zhou, Qiang and Li, Xiaopeng and Chiang, Wen-Hao and Lyu, Yingjun and Nguyen, Hoan and Tripp, Omer},
title = {A Deep Dive into Large Language Models for Automated Bug Localization and Repair},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660773},
doi = {10.1145/3660773},
abstract = {Large language models (LLMs) have shown impressive effectiveness in various software engineering tasks,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
including automated program repair (APR). In this study, we take a deep dive into automated bug localization
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
and repair utilizing LLMs. In contrast to many deep learning-based APR methods that assume known bug
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
locations, rely on line-level localization tools, or address bug prediction and fixing in one step, our approach
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
uniquely employs LLMs to predict bug location at the token level and subsequently utilizes them for bug
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
fixing. This methodological separation of bug localization and fixing using different LLMs enables effective
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
integration of diverse contextual information and improved incorporation of inductive biases. We introduce
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Toggle: Token-Granulated Bug Localization and Repair, a comprehensive program repair framework
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
that integrates a bug localization model, an adjustment model to address tokenizer inconsistencies, and a
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
bug-fixing model. Toggle takes a buggy function as input and generates a complete corrected function. We
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
investigate various styles of prompting to the bug fixing model to identify the most effective prompts that
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
better utilize the inductive bias and significantly outperform others. Toggle achieves the new state-of-the-art
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(SOTA) performance on the CodeXGLUE code refinement benchmark, and exhibits better and comparable
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
performance on several other widely-used APR datasets, including Defects4J. In the Defects4J benchmark, our
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
approach consistently ranks above other methods, achieving superior results in the Top-10, Top-30, Top-50,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
and Top-100 metrics. Besides examining Toggle’s generalizability to unseen data, evaluating the effectiveness
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
of various prompts, we also investigate the impact of additional contextual information such as buggy lines
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
and code comments on bug localization, and explore the importance of the adjustment model. Our extensive
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
experiments offer valuable insights and answers to critical research questions.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {66},
numpages = {23},
keywords = {Automated Bug Localization and Reapir, Large Language Models}
}

@inproceedings{10.1145/3626253.3635604,
author = {Weber, Jason Lee and Martinez Neda, Barbara and Carbajal Juarez, Kitana and Wong-Ma, Jennifer and Gago-Masague, Sergio and Ziv, Hadar},
title = {Measuring CS Student Attitudes Toward Large Language Models},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635604},
doi = {10.1145/3626253.3635604},
abstract = {With the mainstream adoption of Large Language Models (LLMs), members of both academia and the media have raised concerns around their impact on student learning and pedagogy. Many students and educators wonder about the pedagogical fit of this emerging technology. We aim to measure the adoption of and attitudes toward LLMs among the CS student population at an R1 University to determine how students are using these new tools. To this end, we conducted a large survey study targeting two populations participating in computing courses at the university: intro-sequence students (ISS) and experienced students (ES).In our preliminary results from Spring 2023, we've found several significant differences among the views of over 700 respondents across the two groups. Most students reported LLMs' unparalleled potential for quick information access, yet many harbor concerns about the reliability of the LLM responses, and the impact on academic integrity. Additionally, while ES have rapidly integrated LLMs into their learning, ISS remain cautious of the tools, highlighting a stark contrast in adoption rates between the groups.LLMs are clearly going to reshape pedagogical approaches and student engagement. Our study hopes to provide insight on the nuanced student attitudes toward LLMs. For example, the notable reservations expressed by ISS illustrate an imperative for careful, informed, and ethical integration to ensure these tools enhance rather than compromise the educational experience. In the future, we plan to continue tracking student attitudes in order to gain further understanding of the changing perceptions of LLMs and their impact.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1846–1847},
numpages = {2},
keywords = {academic integrity, ai tools, chatgpt, faculty perception, generative ai, large language models (llms), student perception},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3663529.3663846,
author = {Zhang, Xuchao and Ghosh, Supriyo and Bansal, Chetan and Wang, Rujia and Ma, Minghua and Kang, Yu and Rajmohan, Saravan},
title = {Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663846},
doi = {10.1145/3663529.3663846},
abstract = {Root Cause Analysis (RCA) plays a pivotal role in the incident diagnosis process for cloud services, requiring on-call engineers to identify the primary issues and implement corrective actions to prevent future recurrences. Improving the incident RCA process is vital for minimizing service downtime, customer impact and manual toil. Recent advances in artificial intelligence have introduced state-of-the-art Large Language Models (LLMs) like GPT-4, which have proven effective in tackling various AIOps problems, ranging from code authoring to incident management. Nonetheless, the GPT-4 model’s immense size presents challenges when trying to fine-tune it on user data because of the significant GPU resource demand and the necessity for continuous model fine-tuning with the emergence of new data. To address the high cost of fine-tuning LLM, we propose an in-context learning approach for automated root causing, which eliminates the need for fine-tuning. We conduct extensive study over 100,000 production incidents from Microsoft, comparing several large language models using multiple metrics. The results reveal that our in-context learning approach outperforms the previous fine-tuned large language models such as GPT-3 by an average of 24.8% across all metrics, with an impressive 49.7% improvement over the zero-shot model. Moreover, human evaluation involving actual incident owners demonstrates its superiority over the fine-tuned model, achieving a 43.5% improvement in correctness and an 8.7% enhancement in readability. The impressive results demonstrate the viability of utilizing a vanilla GPT model for the RCA task, thereby avoiding the high computational and maintenance costs associated with a fine-tuned model.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {266–277},
numpages = {12},
keywords = {In-context Learning, Incident Diagnosis, Large Language Model, Root Cause Analysis},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3613904.3642377,
author = {Chen, John and Lu, Xi and Du, Yuzhou and Rejtig, Michael and Bagley, Ruth and Horn, Mike and Wilensky, Uri},
title = {Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT &amp; NetLogo Chat},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642377},
doi = {10.1145/3613904.3642377},
abstract = {Large Language Models (LLMs) have the potential to fundamentally change the way people engage in computer programming. Agent-based modeling (ABM) has become ubiquitous in natural and social sciences and education, yet no prior studies have explored the potential of LLMs to assist it. We designed NetLogo Chat to support the learning and practice of NetLogo, a programming language for ABM. To understand how users perceive, use, and need LLM-based interfaces, we interviewed 30 participants from global academia, industry, and graduate schools. Experts reported more perceived benefits than novices and were more inclined to adopt LLMs in their workflow. We found significant differences between experts and novices in their perceptions, behaviors, and needs for human-AI collaboration. We surfaced a knowledge gap between experts and novices as a possible reason for the benefit gap. We identified guidance, personalization, and integration as major needs for LLM-based interfaces to support the programming of ABM.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {141},
numpages = {18},
keywords = {Agent-based Modeling, ChatGPT, LLM Companion, Learning with LLMs, NetLogo Chat, Programming Assistant},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3711403.3711428,
author = {Guo, Peirong and Zhang, Qi and Tian, Chunwei and Xue, Wanli and Feng, Xiaocheng},
title = {Digital Human Techniques for Education Reform},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711428},
doi = {10.1145/3711403.3711428},
abstract = {The rapid evolution of artificial intelligence, big data, and generative AI models has ushered in significant transformations across various sectors, including education. Digital Human Technique, an innovative technology grounded in advanced computer science and artificial intelligence, is reshaping educational paradigms by enabling virtual humans to simulate human behavior, express emotions, and interact with users. This paper explores the application of Digital Human Technique in education reform, focusing on creating immersive, intelligent classroom experiences that foster meaningful interactions between teachers and students. We define Digital Human Technique and delve into its key technical components such as character modeling and rendering, natural language processing, computer vision, and augmented reality technologies. Our methodology involves analyzing the role of educational digital humans created through these technologies, assessing their impact on educational processes, and examining various application scenarios in educational reform. Results indicate that Digital Human Technique significantly enhances the learning experience by enabling personalized teaching, increasing engagement, and fostering emotional connections. Educational digital humans serve as virtual teachers, interactive learning aids, and facilitators of emotional interaction, effectively addressing the challenges of traditional educational methods. They also promote a deeper understanding of complex concepts through simulated environments and interactive digital content.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {173–178},
numpages = {6},
keywords = {Digital Human Techniques, Education Reform},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3593663.3593695,
author = {Dobslaw, Felix and Bergh, Peter},
title = {Experiences with Remote Examination Formats in Light of GPT-4},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593663.3593695},
doi = {10.1145/3593663.3593695},
abstract = {Sudden access to the rapidly improving large language model GPT by OpenAI forces educational institutions worldwide to revisit their exam procedures. In the pre-GPT era, we successfully applied oral and open-book home exams for two courses in the third year of our predominantly remote Software Engineering BSc program. We ask in this paper whether our current open-book exams are still viable or whether a move back to a legally compliant but less scalable oral exam is the only workable alternative. We further compare work-effort estimates between oral and open-book exams and report on differences in throughput and grade distribution over eight years to better understand the impact of examination format on the outcome. Examining GPT-4 on the most recent open-book exams showed that our current Artificial Intelligence and Reactive Programming exams are not GPT v4 proof. Three potential weaknesses of GPT are outlined. We also found that grade distributions have largely been unaffected by the examination format, opening up for a move to oral examinations only if needed. Throughput was higher for open-book exam course instances (73% vs 64%), while fail rates were too (12% vs 7%), with teacher workload increasing even for smaller classes. We also report on our experience regarding effort. Oral examinations are efficient for smaller groups but come with caveats regarding intensity and stress.},
booktitle = {Proceedings of the 5th European Conference on Software Engineering Education},
pages = {220–225},
numpages = {6},
keywords = {Software Engineering Education, Oral Examinations, Examination Formats, ChatGPT},
location = {Seeon/Bavaria, Germany},
series = {ECSEE '23}
}

@inproceedings{10.1145/3696673.3723069,
author = {Meda, Kavya Nikhita and Nara, Pavan Subhash Chandrabose and Bozenka, Svoboda and Zormati, Tarek and Turner, Seth and Worley, Wayne and Mitra, Reshmi},
title = {Integrating Prompt Structures Using LLM Embeddings for Cybersecurity Threats},
year = {2025},
isbn = {9798400712777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696673.3723069},
doi = {10.1145/3696673.3723069},
abstract = {This paper aims to develop a specialized Large Language Model (LLM) for cybersecurity training, designed to educate users on fundamental cybersecurity concepts. This paper focuses on creating an interactive system where users can ask questions about computer security and receive accurate, informative responses. By addressing cybersecurity as a critical national issue, the LLM empowers individuals and organizations to defend against malicious cyber threats. Our system was developed using Python, utilizing Google Sheets as a database, Gradio for the user interface, and Google Gemini's API for advanced language processing. The implementation followed a test-driven development approach, iterating between coding and testing to ensure functionality and reliability. Key technologies include Mistral's Large 2 model and embedding models for clustering related data. The Retrieval-Augmented Generation (RAG) framework was employed to integrate information retrieval with the LLM, enhancing its accuracy and relevance. Tools such as Google Suite, Colab, and Gradio contributed to creating a robust and user-friendly system. This paper highlights the potential of domain-specific LLMs, offering a practical solution to the growing need for accessible cybersecurity education and fostering awareness to mitigate the risks posed by malicious hackers.},
booktitle = {Proceedings of the 2025 ACM Southeast Conference},
pages = {180–187},
numpages = {8},
keywords = {large language model (LLM), embedding models, retrieval-augmented generation (RAG), information retrieval, cybersecurity education},
location = {Southeast Missouri State University, Cape Girardeau, MO, USA},
series = {ACMSE 2025}
}

@inproceedings{10.1145/3675812.3675837,
author = {Yan, ZhenTing and Zhang, Rui and Jia, Fei},
title = {Exploring the Potential of Large Language Models as a Grading Tool for Conceptual Short-Answer Questions in Introductory Physics},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675837},
doi = {10.1145/3675812.3675837},
abstract = {Large language models (LLMs) have shown remarkable capabilities in various natural language tasks, raising the question of their potential as grading tools in physics education. This study explores the potential of LLMs as grading tools in physics education, focusing on their efficacy in assessing conceptual short-answer questions. These questions, pivotal in physics learning, require understanding rather than computation, aligning well with LLMs' text-processing strengths. In this work, we employed GPT-4 to grade a set of conceptual questions from Introductory Physics, encompassing different cognitive domains. Our approach involved comparing LLM grading with human evaluations, using correlation and classification methodologies. Additionally, we investigated the impact of reference answers with varying levels of detail and explanation on LLMs' grading performance and discriminative ability. The results show that LLMs can grade lower cognitive level questions reliably and accurately, regardless of the reference answers. However, LLMs face a trade-off when grading higher cognitive level questions: more detailed reference answers help them align with human standards, but these answers may also limit their recognition of diverse valid responses. The research provides novel insights into the potential and challenges of using LLMs as grading tools in physics education.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {308–314},
numpages = {7},
keywords = {Automated Grading, Cognitive Abilities, Conceptual Physics Questions, Generative Pre-trained Transformer (GPT), Large Language Models (LLMs)},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3656019.3676949,
author = {Park, Daon and Egger, Bernhard},
title = {Improving Throughput-oriented LLM Inference with CPU Computations},
year = {2024},
isbn = {9798400706318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656019.3676949},
doi = {10.1145/3656019.3676949},
abstract = {Large language models (LLMs) have recently captured the attention of a broad audience. To a large part, their exceptional performance in text generation was made possible by an exponential growth of the model parameters. This growth, however, comes at the expense of significantly higher operational costs and a decreased processing speed. Recent research has focused on running LLMs on commodity hardware, for example, by employing the memory hierarchy to augment throughput by increasing the number of batches. These studies, however, tend to overlook or inefficiently utilize the additional computational resources provided by the CPU. In this paper, we introduce a technique capable of efficiently harnessing all available computational resources through a finely tuned and dynamic workload allocation approach. This technique applies to decoder-based models on standard general-purpose hardware, effectively minimizing idle periods for both the CPU and the GPU. We conducted experiments involving various large language models, each representing distinct decoder-based architectures. Compared to the state-of-the-art, the results demonstrate a potential for an increase of up to 105% in throughput with the OPT-30B model.},
booktitle = {Proceedings of the 2024 International Conference on Parallel Architectures and Compilation Techniques},
pages = {233–245},
numpages = {13},
keywords = {CPU offloading, large language model generation, throughput-latency tradeoff},
location = {Long Beach, CA, USA},
series = {PACT '24}
}

@inproceedings{10.1145/3649409.3691089,
author = {Gupta, Anisha and Monahan, Robert and Vandenberg, Jessica and Smith, Andy and Elsayed, Rasha and Fox, Kimkinyona and Minogue, James and Oliver, Kevin and Hubbard Cheuoua, Aleata and Ringstaff, Cathy and Mott, Bradford},
title = {Leveraging Large Language Models for Automated Assessment of Elementary Students' Block-Based Narrative Programs},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691089},
doi = {10.1145/3649409.3691089},
abstract = {Recent years have seen increasing awareness of the need to engage young learners in computational thinking (CT). Integrating digital storytelling, where students create short narratives, and CT offers significant potential for promoting interdisciplinary learning for students; however, it is critical to provide both teachers and students with automated support. A promising approach for enabling support is to leverage advances in Large Language Models (LLMs), which have demonstrated considerable potential for assessing both programming and natural language artifacts. In this work, we investigate the capabilities of LLMs to automatically assess student-created block-based programs developed using a narrative-centered learning environment that engages upper elementary students (ages 9 to 11) in learning CT and physical science through the creation of interactive science narratives. Using the narrative programs created by 28 students, we explore the efficacy of LLMs to assess the programs across two dimensions.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {318–319},
numpages = {2},
keywords = {k-12 education, natural language processing},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3722237.3722245,
author = {Fan, Sun and Peng, Lu and Wu, Shaofeng and Yu, Xingmu},
title = {ChatGPT Empowers Higher Education: —Research Topics Hotspots and Quantitative Visual Analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722245},
doi = {10.1145/3722237.3722245},
abstract = {In order to deeply explore the current research hotspots and development trends of ChatGPT generative artificial intelligence in empowering higher education applications, this study conducted a detailed analysis of 178 articles related to ChatGPT+higher education in the knowledge Resource Database. By using software tools such as Power BI, SPSS, and Excel, this study conducted a visual analysis of core authors, research funding, research topics, author institutions, discipline areas, and related indicators in the literature. The aim of the study is to analyze the current status of ChatGPT research in higher education applications and to explore the hot issues surrounding ChatGPT empowerment in higher education.The study points out that current research in higher education in the era of artificial intelligence mainly focuses on introducing ChatGPT, the characteristics and connotations of large language models, and discussing the opportunities, challenges, coping strategies, and digital transformation research they bring. However, there is still a lack of in-depth exploration of the application of ChatGPT and other technologies in education, especially in areas such as personalized learning and precision teaching, the integration of virtual and actual teaching spaces, intelligent teaching facilities and resources, human-computer collaborative teaching methods, and interdisciplinary innovative research methods.We should actively respond to the opportunities and challenges brought by intelligent tools such as ChatGPT to higher education, and comprehensively and deeply explore how to integrate ChatGPT into key areas of digital education, including teaching design, teaching resource development, teaching organization and implementation, teaching evaluation and reflection, learning and personal knowledge management, innovation team building, and enhancing the digital literacy and professional capabilities of teachers and students. In addition, the impact of the application of ChatGPT and other technologies in education on educational equity, and how to ensure that all students can benefit from it through reasonable design and use, should also be of concern. The goal of this study is to further promote and drive the digital transformation of higher education by building a brand new higher education ecosystem based on ChatGPT.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {38–45},
numpages = {8},
keywords = {ChatGPT, Digital transformation, Empowers, higher education, hot topics, human-machine collaborative intelligence, trends, visualization},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3545945.3569770,
author = {Leinonen, Juho and Hellas, Arto and Sarsa, Sami and Reeves, Brent and Denny, Paul and Prather, James and Becker, Brett A.},
title = {Using Large Language Models to Enhance Programming Error Messages},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569770},
doi = {10.1145/3545945.3569770},
abstract = {A key part of learning to program is learning to understand programming error messages. They can be hard to interpret and identifying the cause of errors can be time-consuming. One factor in this challenge is that the messages are typically intended for an audience that already knows how to program, or even for programming environments that then use the information to highlight areas in code. Researchers have been working on making these errors more novice friendly since the 1960s, however progress has been slow. The present work contributes to this stream of research by using large language models to enhance programming error messages with explanations of the errors and suggestions on how to fix them. Large language models can be used to create useful and novice-friendly enhancements to programming error messages that sometimes surpass the original programming error messages in interpretability and actionability. These results provide further evidence of the benefits of large language models for computing educators, highlighting their use in areas known to be challenging for students. We further discuss the benefits and downsides of large language models and highlight future streams of research for enhancing programming error messages.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {563–569},
numpages = {7},
keywords = {ai, codex, compiler error messages, large language models, programming error messages, syntax error messages},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3676536.3699507,
author = {Liao, Yuchao and Adegbija, Tosiron and Lysecky, Roman},
title = {Are LLMs Any Good for High-Level Synthesis?},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3699507},
doi = {10.1145/3676536.3699507},
abstract = {The increasing complexity and demand for faster, energy-efficient hardware designs necessitate innovative High-Level Synthesis (HLS) methodologies. This paper explores the potential of Large Language Models (LLMs) to streamline or replace the HLS process, leveraging their ability to understand natural language specifications and refactor code. We survey the current research and conduct experiments comparing Verilog designs generated by a standard HLS tool (Vitis HLS) with those produced by LLMs translating C code or natural language specifications. Our evaluation focuses on quantifying the impact on performance, power, and resource utilization, providing an assessment of the efficiency of LLM-based approaches. This study aims to illuminate the role of LLMs in HLS, identifying promising directions for optimized hardware design in applications such as AI acceleration, embedded systems, and high-performance computing.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {29},
numpages = {8},
keywords = {high-level synthesis, hardware accelerator design, electronic design automation, large language models},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@article{10.1145/3736721,
author = {Qin, Ruiyang and Liu, Dancheng and Xu, Chenhui and Yan, Zheyu and Tan, Zhaoxuan and Jia, Zhenge and Nassereldine, Amir and Li, Jiajie and Jiang, Meng and Abbasi, Ahmed and xiong, jinjun and Shi, Yiyu},
title = {Empirical Guidelines for Deploying LLMs onto Resource-constrained Edge Devices},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3736721},
doi = {10.1145/3736721},
abstract = {The scaling laws have become the de facto guidelines for designing large language models (LLMs), but they were studied under the assumption of unlimited computing resources for both training and inference. As LLMs are increasingly used as personalized intelligent assistants, their customization (i.e., learning through fine-tuning) and deployment onto resource-constrained edge devices will become more and more prevalent. An urgent but open question is how a resource-constrained computing environment would affect the design choices for a personalized LLM. We study this problem empirically in this work. In particular, we consider the tradeoffs among a number of key design factors and their intertwined impacts on learning efficiency and accuracy. The factors include the learning methods for LLM customization, the amount of personalized data used for learning customization, the types and sizes of LLMs, the compression methods of LLMs, the amount of time afforded to learn, and the difficulty levels of the target use cases. Through extensive experimentation and benchmarking, we draw a number of surprisingly insightful guidelines for deploying LLMs onto resource-constrained devices. For example, an optimal choice between parameter learning and RAG may vary depending on the difficulty of the downstream task, the longer fine-tuning time does not necessarily help the model, and a compressed LLM may be a better choice than an uncompressed LLM to learn from limited personalized data.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = may,
keywords = {Do, Not, Us, This, Code, Put, the, Correct, Terms, for, Your, Paper}
}

@inproceedings{10.1145/3706598.3713698,
author = {Yarmand, Matin and Reed, Courtney N. and Tandon, Udayan and Hekler, Eric B. and Weibel, Nadir and Wang, April Yi},
title = {Towards Dialogic and On-Demand Metaphors for Interdisciplinary Reading},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713698},
doi = {10.1145/3706598.3713698},
abstract = {The interdisciplinary field of Human-Computer Interaction (HCI) thrives on productive engagement with different domains, yet this engagement often breaks due to idiosyncratic writing styles and unfamiliar concepts. Inspired by the dialogic model of abstract metaphors, as well as the potential of Large Language Models (LLMs) to produce on-demand support, we investigate the use of metaphors to facilitate engagement between Science and Technology Studies (STS) and System HCI. Our reflective-style survey with early-career HCI researchers (N=48) reported that limited prior exposure to STS research can hinder perceived openness of the work, and ultimately interest in reading. The survey also revealed that metaphors enhance likelihood to continue reading STS papers, and alternative perspectives can build critical thinking skills to mitigate potential risks of LLM-generated metaphors. We lastly offer a specified model of metaphor exchange (within this generative context) that incorporates alternative perspectives to construct shared understanding in interdisciplinary engagement.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1069},
numpages = {19},
keywords = {Metaphor Exchange, Large Language Models, Reflective Survey},
location = {
},
series = {CHI '25}
}

@article{10.5555/3715602.3715609,
author = {Weiss, Richard and Mache, Jens},
title = {Cybersecurity Exercises in the Age of LLMs},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {In this tutorial, we will introduce a cybersecurity education framework for developing polymorphic hands-on exercises. Many faculty readily acknowledge the importance of cybersecurity in the Computer Science curriculum, but there are still barriers to integrating it into existing courses. One of those barriers is the fact that in most courses, the current content fills the entire term. Another issues is that faculty don't have time and expertise to create new content that would fit well with their current content and style. The third problem is that exercises created should be resistant to solution by LLMs. We have developed cybersecurity exercises that combine two principles: environment specificity and polymorphism. Environment specificity means that the solutions to the exercise should depend on the local environment (LLMs don't have access to that information). In this context, polymorphism means that they can be easily modified each time that the class is taught.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {25–27},
numpages = {3}
}

@article{10.1145/3643757,
author = {Bairi, Ramakrishna and Sonwane, Atharv and Kanade, Aditya and C., Vageesh D. and Iyer, Arun and Parthasarathy, Suresh and Rajamani, Sriram and Ashok, B. and Shet, Shashank},
title = {CodePlan: Repository-Level Coding using LLMs and Planning},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643757},
doi = {10.1145/3643757},
abstract = {Software engineering activities such as package migration, fixing error reports from static analysis or testing, and adding type annotations or other specifications to a codebase, involve pervasively editing the entire repository of code.     We formulate these activities as repository-level coding tasks.         Recent tools like GitHub Copilot, which are powered by Large Language Models (LLMs), have succeeded in offering high-quality solutions to localized coding problems.     Repository-level coding tasks are more involved and cannot be solved directly using LLMs, since code within a repository is inter-dependent and the entire repository may be too large to fit into the prompt.     We frame repository-level coding as a planning problem and present a task-agnostic, neuro-symbolic framework called CodePlan to solve it.     CodePlan synthesizes a multi-step chain-of-edits (plan), where each step results in a call to an LLM on a code location with context derived from the entire repository, previous code changes and task-specific instructions.     CodePlan is based on a novel combination of an incremental dependency analysis, a change may-impact analysis and an adaptive planning algorithm (symbolic components) with the neural LLMs.         We evaluate the effectiveness of CodePlan on two repository-level tasks: package migration (C#) and temporal code edits (Python). Each task is evaluated on multiple code repositories, each of which requires inter-dependent changes to many files (between 2–97 files).     Coding tasks of this level of complexity have not been automated using LLMs before. Our results show that CodePlan has better match with the ground truth compared to baselines.     CodePlan is able to get 5/7 repositories to pass the validity checks (i.e., to build without errors and make correct code edits) whereas the baselines (without planning but with the same type of contextual information as CodePlan) cannot get any of the repositories to pass them.     We provide our (non-proprietary) data, evaluation scripts and supplementary material at https://github.com/microsoft/codeplan.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {31},
numpages = {24},
keywords = {Automated coding, LLMs, chain of edits, neuro-symbolic AI, plan, repositories, static analysis}
}

@inproceedings{10.1145/3568812.3603476,
author = {Phung, Tung and P\u{a}durean, Victor-Alexandru and Cambronero, Jos\'{e} and Gulwani, Sumit and Kohn, Tobias and Majumdar, Rupak and Singla, Adish and Soares, Gustavo},
title = {Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603476},
doi = {10.1145/3568812.3603476},
abstract = {Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies. State-of-the-art models like OpenAI’s ChatGPT&nbsp;[8] and GPT-4&nbsp;[9] could enhance programming education in various roles, e.g., by acting as a personalized digital tutor for a student, a digital assistant for an educator, and a digital peer for collaborative learning&nbsp;[1, 2, 7]. In our work, we seek to comprehensively evaluate and benchmark state-of-the-art large language models for various scenarios in programming education. Recent works have evaluated several large language models in the context of programming education&nbsp;[4, 6, 10, 11, 12]. However, these works are limited for several reasons: they have typically focused on evaluating a specific model for a specific education scenario (e.g., generating explanations), or have considered models that are already outdated (e.g., OpenAI’s Codex&nbsp;[3] is no longer publicly available since March 2023). Consequently, there is a lack of systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios in programming education. These scenarios are designed to capture distinct roles these models could play, namely digital tutors, assistants, and peers, as discussed above. More concretely, we consider the following six scenarios: (1) program repair, i.e., fixing a student’s buggy program; (2) hint generation, i.e., providing a natural language hint to the student to help resolve current issues; (3) grading feedback, i.e., grading a student’s program w.r.t. a given rubric; (4) peer programming, i.e., completing a partially written program or generating a sketch for the solution program; (5) task creation, i.e., generating new tasks that exercise specific types of concepts or bugs; (6) contextualized explanation, i.e., explaining specific concepts or functions in the context of a given program. Our study uses a mix of quantitative and qualitative evaluation to compare the performance of these models with the performance of human tutors. We conduct our evaluation based on 5 introductory Python programming problems with a diverse set of input/output specifications. For each of these problems, we consider 5 buggy programs based on publicly accessible submissions from geeksforgeeks.org &nbsp;[5] (see Figure&nbsp;1); these buggy programs are picked to capture different types of bugs for each problem. We will provide a detailed analysis of the data and results in a longer version of this poster. Our preliminary results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors’ performance for several scenarios.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {41–42},
numpages = {2},
keywords = {ChatGPT, generative AI, introductory programming education, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3700794.3700817,
author = {Monteiro Santos, Mateus and Barros, Aristoteles and Rodrigues, Luiz and Dermeval, Diego and Primo, Tiago and Ibert, Ig and Isotani, Seiji},
title = {Near Feasibility, Distant Practicality: Empirical Analysis of Deploying and Using LLMs on Resource-Constrained Smartphones},
year = {2025},
isbn = {9798400710414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700794.3700817},
doi = {10.1145/3700794.3700817},
abstract = {Artificial Intelligence (AI) systems, such as Large Language Models (LLMs), have the transformative potential to empower education. However, utilizing such systems often requires technological infrastructure, including computers and internet access, which are unavailable in many underserved regions, particularly in the Global South. Despite these limitations, research indicates that smartphones are increasingly accessible even in these areas, presenting an opportunity to deliver advanced systems like LLMs through resource-constrained devices. Nevertheless, the technical feasibility of deploying and using LLMs on disconnected smartphones remains unexplored to the best of our knowledge. This paper presents an empirical study that developed an LLM-powered mobile application, deployed it on a smartphone, and evaluated its performance in terms of response time, memory usage, and storage utilization based on three lightweight LLMs (Tinyllama, Redpajama, and Qwen2). The results show that the overall response time ranged from one to two minutes, and memory usage varied between three and nearly five GB. While these findings demonstrate the technical feasibility of deploying LLMs on disconnected smartphones, the significant waiting time and memory consumption highlight the challenges of this approach. Therefore, although LLMs can be deployed on resource-constrained devices to provide equitable access to advanced educational technology, there is an urgent need to develop optimized alternatives suitable for underserved educational settings so that exploring LLMs in such context becomes practically feasible.},
booktitle = {Proceedings of the 13th International Conference on Information &amp; Communication Technologies and Development},
pages = {224–235},
numpages = {12},
location = {
},
series = {ICTD '24}
}

@inproceedings{10.1145/3626252.3630897,
author = {Jordan, Mollie and Ly, Kevin and Soosai Raj, Adalbert Gerald},
title = {Need a Programming Exercise Generated in Your Native Language? ChatGPT's Got Your Back: Automatic Generation of Non-English Programming Exercises Using OpenAI GPT-3.5},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630897},
doi = {10.1145/3626252.3630897},
abstract = {Large language models (LLMs) like ChatGPT are changing computing education and may create additional barriers to those already faced by non-native English speakers (NNES) learning computing. We investigate an opportunity for a positive impact of LLMs on NNES through multilingual programming exercise generation. Following previous work with LLM exercise generation in English, we prompt OpenAI GPT-3.5 in 4 natural languages (English, Tamil, Spanish, and Vietnamese) to create introductory programming problems, sample solutions, and test cases. We evaluate these problems on their sensibility, readability, translation, sample solution accuracy, topicality, and cultural relevance. We find that problems generated in English, Spanish, and Vietnamese are largely sensible, easily understood, and accurate in their sample solutions. However, Tamil problems are mostly non-sensible and have a much lower passing test rate, indicating that the abilities of LLMs for problem generation are not generalizable across languages. Our analysis suggests that these problems could not be given verbatim to students, but with minimal effort, most errors can be fixed. We further discuss the benefits of these problems despite their flaws, and their opportunities to provide personalized and culturally relevant resources for students in their native languages.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {618–624},
numpages = {7},
keywords = {introductory programming, large language models, non-native english speakers, problem generation},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3605390.3610821,
author = {Di Caro, Luigi and Rapp, Amon and Torrielli, Federico},
title = {GENERAL: GENerative, Explainable and Reasonable Artificial Learning},
year = {2023},
isbn = {9798400708060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605390.3610821},
doi = {10.1145/3605390.3610821},
abstract = {The GENERAL (GENerative, Explainable and Reasonable Artificial Learning) workshop, held at CHITALY 2023, delves into the advancements in General and Generative Artificial Intelligence (GGAI), with a focus on breakthroughs in natural language processing (NLP) and computer vision (CV). The workshop highlights the capabilities of Large Language Models (LLMs) and Latent Diffusion Models (LDMs) in generating human-like content across text and images. It emphasizes the importance of AI explainability, aiming to understand, explain, and control the complexities of these AI systems in terms of fairness, accountability, and transparency. The workshop encourages interdisciplinary collaboration across fields like HCI, psychology, social studies, and the arts to better understand AI’s societal and cultural impacts. Topics of interest include user perceptions of generative AIs, machine psychology, AI assistants, ethical issues in Generative AI, and safety and control mechanisms for large language models.},
booktitle = {Proceedings of the 15th Biannual Conference of the Italian SIGCHI Chapter},
articleno = {35},
numpages = {2},
keywords = {Large Language Models, Interdisciplinary Collaboration, Generative Artificial Intelligence, Ethical Issues in AI, AI Explainability},
location = {Torino, Italy},
series = {CHItaly '23}
}

@inproceedings{10.1145/3658644.3690306,
author = {Wen, Rui and Li, Zheng and Backes, Michael and Zhang, Yang},
title = {Membership Inference Attacks Against In-Context Learning},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690306},
doi = {10.1145/3658644.3690306},
abstract = {Adapting Large Language Models (LLMs) to specific tasks introduces concerns about computational efficiency, prompting an exploration of efficient methods such as In-Context Learning (ICL). However, the vulnerability of ICL to privacy attacks under realistic assumptions remains largely unexplored. In this work, we present the first membership inference attack tailored for ICL, relying solely on generated texts without their associated probabilities. We propose four attack strategies tailored to various constrained scenarios and conduct extensive experiments on four popular large language models. Empirical results show that our attacks can accurately determine membership status in most cases, e.g., 95% accuracy advantage against LLaMA, indicating that the associated risks are much higher than those shown by existing probability-based attacks. Additionally, we propose a hybrid attack that synthesizes the strengths of the aforementioned strategies, achieving an accuracy advantage of over 95% in most cases. Furthermore, we investigate three potential defenses targeting data, instruction, and output. Results demonstrate combining defenses from orthogonal dimensions significantly reduces privacy leakage and offers enhanced privacy assurances.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {3481–3495},
numpages = {15},
keywords = {in-context learning, large language models, membership inference attacks},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3617553.3617887,
author = {Fulcini, Tommaso and Torchiano, Marco},
title = {Is ChatGPT Capable of Crafting Gamification Strategies for Software Engineering Tasks?},
year = {2023},
isbn = {9798400703737},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617553.3617887},
doi = {10.1145/3617553.3617887},
abstract = {Gamification has gained significant attention in the last decade for its potential to enhance engagement and motivation in various domains. During the last year ChatGPT, a state-of-the-art large language model has received even more attention both in the field of scientific research and in common use by individuals or companies.  
In this study, we investigate the possibility of adopting ChatGPT as a tool for designing gamification platforms in the Software Engineering domain. Leveraging the capabilities of ChatGPT, we assess how good is it at generating effective suggestions and ideas for designers or developers.  
To evaluate ChatGPT's potential as a gamification platform creator we narrowed the context to one particular Software Engineering activity, asking for possible aspects of the activity to be gamified. Each proposed aspect was subsequently unraveled by ChatGPT both asking in a shared and separate context, first following the conversational nature of the model, then applying a validated design framework. The study assesses ChatGPT's ability to select and integrate game elements to build a thriving gamification environment by framing the design of the platform to a state-of-the-art conceptual framework. To evaluate the goodness of the design choices made we relied both on the Octalysis framework and on personal experience.  
The findings of the papers show that ChatGPT can only create simple playful experiences not very effective. Although, by instructing the model with more specific desired mechanics and dynamics, it is possible to guide it toward the application of the ideas suggested. We argue that ChatGPT is not capable of building a gamified environment on its own, but it could still be used to build the foundation of a gamification platform as long as the designers refine and rough out the advice gained from a user-centered solution.},
booktitle = {Proceedings of the 2nd International Workshop on Gamification in Software Development, Verification, and Validation},
pages = {22–28},
numpages = {7},
keywords = {Software Lifecycle, Software Engineering, Large Language Model, Gamification, Artificial Intelligence},
location = {San Francisco, CA, USA},
series = {Gamify 2023}
}

@inproceedings{10.1145/3597503.3639177,
author = {Wei, Moshi and Harzevili, Nima Shiri and Huang, Yuekai and Yang, Jinqiu and Wang, Junjie and Wang, Song},
title = {Demystifying and Detecting Misuses of Deep Learning APIs},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639177},
doi = {10.1145/3597503.3639177},
abstract = {Deep Learning (DL) libraries have significantly impacted various domains in computer science over the last decade. However, developers often face challenges when using the DL APIs, as the development paradigm of DL applications differs greatly from traditional software development. Existing studies on API misuse mainly focus on traditional software, leaving a gap in understanding API misuse within DL APIs. To address this gap, we present the first comprehensive study of DL API misuse in TensorFlow and PyTorch. Specifically, we first collected a dataset of 4,224 commits from the top 200 most-starred projects using these two libraries and manually identified 891 API misuses. We then investigated the characteristics of these misuses from three perspectives, i.e., types, root causes, and symptoms. We have also conducted an evaluation to assess the effectiveness of the current state-of-the-art API misuse detector on our 891 confirmed API misuses. Our results confirmed that the state-of-the-art API misuse detector is ineffective in detecting DL API misuses. To address the limitations of existing API misuse detection for DL APIs, we propose LLMAPIDet, which leverages Large Language Models (LLMs) for DL API misuse detection and repair. We build LLMAPIDet by prompt-tuning a chain of ChatGPT prompts on 600 out of 891 confirmed API misuses and reserve the rest 291 API misuses as the testing dataset. Our evaluation shows that LLMAPIDet can detect 48 out of the 291 DL API misuses while none of them can be detected by the existing API misuse detector. We further evaluate LLMAPIDet on the latest versions of 10 GitHub projects. The evaluation shows that LLMAPIDet can identify 119 previously unknown API misuses and successfully fix 46 of them.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {201},
numpages = {12},
keywords = {API misuse, deep learning APIs, empirical study, detection},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3701716.3715591,
author = {Qi, Weihong and Lyu, Hanjia and Luo, Jiebo},
title = {Representation Bias in Political Sample Simulations with Large Language Models},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715591},
doi = {10.1145/3701716.3715591},
abstract = {This study explores representation biases in simulating political samples using Large Language Models (LLMs), focusing on vote choice and public opinion. We evaluate seven LLMs from diverse cultural backgrounds with data from the American National Election Studies, German Longitudinal Election Study, and Zuobiao Dataset. The study identifies three dimensions of bias: societal and cultural contexts, demographic groups, and political institutions. Results show higher simulation accuracy for vote choice than public opinion, particularly in English-speaking and democratic countries with bipartisan systems. The cultural backgrounds of development teams significantly influence simulation performance. The findings offer insights into addressing biases in AI-driven computational social science.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1264–1267},
numpages = {4},
keywords = {large language model, political science, representation bias},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3742939.3742941,
author = {Vardanega, T.},
title = {It Is Time to Care for Ada!},
year = {2025},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {1094-3641},
url = {https://doi.org/10.1145/3742939.3742941},
doi = {10.1145/3742939.3742941},
abstract = {1 A rather strange introductionI confess, I am a voracious book reader, and being (luckily) versed in quite a few tongues, I enjoy reading books frequently (but not always) without needing translation. In fact, I find languages fascinating, for all they say about people's culture, history, and traits.As a student in Computer Science in the late 1980s, I was imbued with Noam Chomsky's linguistic ''generative grammar'' theory. That theory sees specific languages as second-order derivatives of a single universal grammar, innate in the human mind. That theory, with its hierarchy of formal grammars, has laid the foundation for the theory and practice of language compilers. The principal tenet of Chomsky's theory is that grammar precedes language.},
journal = {Ada Lett.},
month = jun,
pages = {27–28},
numpages = {2}
}

@inproceedings{10.1145/3611643.3613892,
author = {Jin, Matthew and Shahriar, Syed and Tufano, Michele and Shi, Xin and Lu, Shuai and Sundaresan, Neel and Svyatkovskiy, Alexey},
title = {InferFix: End-to-End Program Repair with LLMs},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613892},
doi = {10.1145/3611643.3613892},
abstract = {Software development life cycle is profoundly influenced by bugs; their introduction, identification, and eventual resolution account for a significant portion of software development cost. This has motivated software engineering researchers and practitioners to propose different approaches for automating the identification and repair of software defects. Large Language Models (LLMs) have been adapted to the program repair task through few-shot demonstration learning and instruction prompting, treating this as an infilling task. However, these models have only focused on learning general bug-fixing patterns for uncategorized bugs mined from public repositories. In this paper, we propose : a transformer-based program repair framework paired with a state-of-the-art static analyzer to fix critical security and performance bugs.  combines a Retriever – transformer encoder model pretrained via contrastive learning objective, which aims at searching for semantically equivalent bugs and corresponding fixes; and a Generator – an LLM (12 billion parameter Codex Cushman model) finetuned on supervised bug-fix data with prompts augmented via adding bug type annotations and semantically similar fixes retrieved from an external non-parametric memory. To train and evaluate our approach, we curated , a novel, metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories. Our evaluation demonstrates that  outperforms strong LLM baselines, with a top-1 accuracy of 65.6% for generating fixes in C# and 76.8% in Java. We discuss the deployment of  alongside Infer at Microsoft which offers an end-to-end solution for detection, classification, and localization of bugs, as well as fixing and validation of candidate patches, integrated in the continuous integration (CI) pipeline to automate the software development workflow.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1646–1656},
numpages = {11},
keywords = {Program repair, finetuning, prompt augmentation, static analyses},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3723498.3723702,
author = {Poglitsch, Christian and Szak\'{a}cs, Fabian and Pirker, Johanna},
title = {Evaluating Large Language Models through Communication Games: An Agent-Based Framework Using Werewolf in Unity},
year = {2025},
isbn = {9798400718564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723498.3723702},
doi = {10.1145/3723498.3723702},
abstract = {In this study, we explore the reasoning capabilities of Large Language Models (LLMs) within the context of the social communication game Werewolf, aiming to evaluate their performance in managing complex system states commonly found in computer games. Our agent architecture gathers data, refines them into detailed information, and plans actions based on this knowledge. To demonstrate the feasibility of using LLM based agents in computer games, we developed a simulation and evaluation tool using the Unity game engine. This software enables users to experiment with various LLMs and agent architectures and to measure model performance within the application.For evaluation, we tested three models: GPT-3.5 Turbo, Mistral-7B-OpenOrca, and Nous-Hermes-Llama2-13B. The results show that even smaller models can perform reasonably well in Werewolf. However, their error rate is significantly higher, highlighting the need for additional software modules or fine-tuning to improve their accuracy.},
booktitle = {Proceedings of the 20th International Conference on the Foundations of Digital Games},
articleno = {25},
numpages = {10},
keywords = {Large Language Models, Werewolf, Social deduction, Evaluation Framework},
location = {
},
series = {FDG '25}
}

@article{10.1145/3704739,
author = {Le, Linh and Tran, Dung},
title = {A Metric-Based Detection System for Large Language Model Texts},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3704739},
doi = {10.1145/3704739},
abstract = {More efforts are being put into improving the capabilities of Large Language Models (LLM) than into dealing with their implications. Current LLMs are able to generate high-quality texts seemingly indistinguishable from those written by human experts. While offering great potential, such breakthroughs also pose new challenges for safe and ethical uses of LLMs in education, science, and a multitude of other areas. Thus, majority of current approaches in LLM text detection are either computationally expensive or need access to the LLMs’ internal computations, both of which hinder their public accessibility. With such motivation, this article presents a novel metric learning paradigm for detection of LLM-generated texts that is able to balance computational costs, accessibility, and performances. Specifically, the detection is based on learning a similarity function between a given text and an equivalent example generated by LLMs that outputs high values for LLM-LLM text pairs and low values for LLM-human text pairs. In terms of architecture, the detection framework includes a pre-trained language model for the text embedding task and a newly designed deep metric model. The metric component can be trained on triplets or pairs of same-context instances to signify the distances between human and LLM texts while reducing that among LLM texts. Next, we develop five datasets totaling more than 95,000 contexts and triplets of responses in which one is from humans and two are from GPT-3.5 TURBO or GPT-4 TURBO for benchmarking. Experiment studies show that our best architectures maintain F1 scores between 0.87 and 0.95 across the tested corpora in multiple experiment settings. The metric framework also demands significantly less time in training and inference compared to RoBERTa, LLaMA 3, Mistral v0.3, and Ghostbuster, while keeping 90% to 150% performance of the best benchmark.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {8},
numpages = {19},
keywords = {LLM text detection, contrastive learning, triplet learning, metric learning}
}

@inproceedings{10.1145/3706598.3713271,
author = {Pickering, Madison and Williams, Helena and Gan, Alison and He, Weijia and Park, Hyojae and Piedrahita Velez, Francisco and Littman, Michael L. and Ur, Blase},
title = {How Humans Communicate Programming Tasks in Natural Language and Implications For End-User Programming with LLMs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713271},
doi = {10.1145/3706598.3713271},
abstract = {Large language models (LLMs) like GPT-4 can convert natural-language descriptions of a task into computer code, making them a promising interface for end-user programming. We undertake a systematic analysis of how people with and without programming experience describe information-processing tasks (IPTs) in natural language, focusing on the characteristics of successful communication. Across two online between-subjects studies, we paired crowdworkers either with one another or with an LLM, asking senders (always humans) to communicate IPTs in natural language to their receiver (either a human or LLM). Both senders and receivers tried to answer test cases, the latter based on their sender’s description. While participants with programming experience tended to communicate IPTs more successfully than non-programmers, this advantage was not overwhelming. Furthermore, a user interface that solicited example test cases from senders often, but not always, improved IPT communication. Allowing receivers to request clarification, though, was less successful at improving communication.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {875},
numpages = {34},
keywords = {Large Language Models, LLMs, End-User Programming},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3702250.3702263,
author = {Totade, Sanjot Sagar and Babu, Nithin C and Rao, Shika and Soundararajan, Rajiv},
title = {Internal Embeddings of Multi-modal LLMs as Generalizable Representations for Image Quality Assessment},
year = {2025},
isbn = {9798400710759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702250.3702263},
doi = {10.1145/3702250.3702263},
abstract = {One of the major challenges in no-reference (NR) image quality assessment (IQA) is the ability to generalize to diverse quality assessment applications. Recently, multi-modal vision-language models are found to be very promising in this direction. They are beginning to form a part of several state of the art NR IQA methods. On the other hand, multi-modal large language models (LLMs) are increasingly being studied for various computer vision applications including IQA. In this work, we perform a thorough study of the ability of multi-modal LLMs for NR IQA by training some of its components and testing for its generalizability. In particular, we keep the LLM frozen and learn parameters corresponding to the querying transformer, LLM prompt and some layers that process the embedding output by the LLM. We observe that some of these components offer a generalization performance far superior to any existing NR IQA algorithm.},
booktitle = {Proceedings of the Fifteenth Indian Conference on Computer Vision Graphics and Image Processing},
articleno = {13},
numpages = {9},
keywords = {Image quality assessment, large language models},
location = {
},
series = {ICVGIP '24}
}

@inproceedings{10.5555/3709347.3743537,
author = {Banna, Tahsin Tariq and Rahman, Sejuti and Tareq, Mohammad},
title = {Beyond Words: Integrating Personality Traits and Context-Driven Gestures in Human-Robot Interactions},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {As robots become increasingly integrated into human life, personalizing human-robot interactions (HRI) is crucial for improving user acceptance, engagement, and interaction quality. However, personalizing HRI poses a unique challenge due to the diversity of human personality traits. This paper proposes a method that leverages large language models (LLMs) to dynamically tailor robot conversations according to the Big Five (OCEAN) personality traits. Our novelty lies in using user personality traits to shape robots' verbal responses and implementing contextual action generation for gestures. This study addresses two primary research questions: (1) Does adapting robots' verbal responses based on user personality traits improve communication satisfaction? (2) How does the addition of context-appropriate gestures further enhance user satisfaction? We used Goldberg's personality trait measurement scale (1992) to assess 26 participants who engaged in conversations with an LLM-powered Pepper robot on various topics. The quality of these interactions was self-reported using a revised version of Hecht's (1978) conversation satisfaction scale. Three experimental conditions were conducted: (i) Baseline: Standard LLM conversation, (ii) Personality-congruent: LLM-adjusted dialogue based on personality of participants, and (iii) Enhanced interaction: Personality adaptation plus dynamic gestures. For the third condition, we implemented contextually appropriate pre-defined animations and generated novel gestures by computing joint angle values in real time. Statistical analysis using ANOVA revealed significant differences in communication satisfaction across the three conditions (F=13.41, p&lt;.001). Post-hoc analyses using \v{S}id\'{a}k's multiple comparison test showed significant pairwise differences: Condition 2 vs. 1: Δ Δmean 4.42 , p = 0.02; Condition 3 vs. 1: Δ Δmean 8.23, p &lt; 0.01; Condition 3 vs. 2: Δ Δmean 3.80, p = 0.05. These results demonstrate that both personality-congruent interactions and non-verbal gestures significantly enhance communication satisfaction, with the combined approach yielding the highest satisfaction. This approach opens new possibilities for developing socially intelligent robots with applications in healthcare, education, and customer service.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {242–251},
numpages = {10},
keywords = {HRI, LLM, generative actions, personality traits, robotics},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3696348.3696868,
author = {He, Zhiyuan and Gottipati, Aashish and Qiu, Lili and Luo, Xufang and Xu, Kenuo and Yang, Yuqing and Yan, Francis Y.},
title = {Designing Network Algorithms via Large Language Models},
year = {2024},
isbn = {9798400712722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696348.3696868},
doi = {10.1145/3696348.3696868},
abstract = {We introduce Nada, the first framework to autonomously design network algorithms by leveraging the generative capabilities of large language models (LLMs). Starting with an existing algorithm implementation, Nada enables LLMs to create a wide variety of alternative designs in the form of code blocks. It then efficiently identifies the top-performing designs through a series of filtering techniques, minimizing the need for full-scale evaluations and significantly reducing computational costs. Using adaptive bitrate (ABR) streaming as a case study, we demonstrate that Nada produces novel ABR algorithms---previously unknown to human developers---that consistently outperform the original algorithm in diverse network environments, including broadband, satellite, 4G, and 5G.},
booktitle = {Proceedings of the 23rd ACM Workshop on Hot Topics in Networks},
pages = {205–212},
numpages = {8},
keywords = {Large Language Models, Network Algorithms},
location = {Irvine, CA, USA},
series = {HotNets '24}
}

@inproceedings{10.1145/3639474.3640058,
author = {Lehtinen, Teemu and Koutcheme, Charles and Hellas, Arto},
title = {Let's Ask AI About Their Programs: Exploring ChatGPT's Answers To Program Comprehension Questions},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640058},
doi = {10.1145/3639474.3640058},
abstract = {Recent research has explored the creation of questions from code submitted by students. These Questions about Learners' Code (QLCs) are created through program analysis, exploring execution paths, and then creating code comprehension questions from these paths and the broader code structure. Responding to the questions requires reading and tracing the code, which is known to support students' learning. At the same time, computing education researchers have witnessed the emergence of Large Language Models (LLMs) that have taken the community by storm. Researchers have demonstrated the applicability of these models especially in the introductory programming context, outlining their performance in solving introductory programming problems and their utility in creating new learning resources. In this work, we explore the capability of the state-of-the-art LLMs (GPT-3.5 and GPT-4) in answering QLCs that are generated from code that the LLMs have created. Our results show that although the state-of-the-art LLMs can create programs and trace program execution when prompted, they easily succumb to similar errors that have previously been recorded for novice programmers. These results demonstrate the fallibility of these models and perhaps dampen the expectations fueled by the recent LLM hype. At the same time, we also highlight future research possibilities such as using LLMs to mimic students as their behavior can indeed be similar for some specific tasks.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {221–232},
numpages = {12},
keywords = {QLCs, large language models, artificial intelligence, introductory programming, program comprehension},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3626253.3633407,
author = {Westerlund, Jill and Czajka, Sandra and Kuemmel, Andrew},
title = {Innovative Strategies for genAI in CS Courses},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633407},
doi = {10.1145/3626253.3633407},
abstract = {Students are using generative artificial intelligence (genAI), organizations are embracing AI and machine learning, tools are emerging almost daily, and addressing these evolving technologies can be overwhelming. Rather than choosing to ignore genAI, instructors of computer science (CS) can find ways to teach with and guide students in the use of genAI in their courses. Teaching about genAI can be incorporated with instruction about effective and appropriate uses of the ever-growing tools.This special session brings together three experienced CS educators who integrate genAI in their work with high school students, college students, and in-service teachers. The session environment allows for participant involvement in three model activities that showcase genAI tools with learner-focused practices. Participants will be provided supporting teaching resources for each guided activity and encouraged to discuss with peers and presenters.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1875–1876},
numpages = {2},
keywords = {ai, assessment, genai, instruction},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3722237.3722266,
author = {Yang, Ye and Wen, Xiong and Maidin, Siti Sarah},
title = {Generative AI Tools in Higher Education Emerging Research: A Bibliometric analysis of co-citation and co-word analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722266},
doi = {10.1145/3722237.3722266},
abstract = {Artificial Intelligence (AI) is positively grasped as promising to disrupt the higher education system but it also poses a number of challenges. Although so many studies attempt to explore the matching of the possibility of this growing technology with the higher education system, ample research needs to be conducted to solve the challenges facing the renovation of higher education. With this in mind, our aim of bibliometric studies is to conduct a deep investigation into the increasingly developing scenario of Generative AI tools in higher education. We extracted data from the Web of Science database that is up-to-date till July 2024, comprising 934 relevant articles. Co-citation and co-word analyses revealed three main research clusters: advanced computationable methods, AI application in higher education, and user technology and adoption. The findings illustrated rapid diffusion of generative AI technologies with prominent emphasis on large-language models in pedagogical practices. Other critical themes center around developing AI-facilitated learning interventions, ethical challenges, and usage impact on learning outcomes. The results show that the field is inherently interdisciplinary, using ideas from educational technology, cognitive science, and AI. In addition, a rising trend is noted for the focus on academic honesty and users' involvement with AI devices. The results indicate the important implications of this study for teachers and policymakers alongside contributions to teaching and research that offer a guide to sustainable improvement across education. Future research would benefit from longitudinal studies drawing on an interdisciplinary approach to realize the long-term implications and address complex issues surrounding the integration of AI within universities.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {166–174},
numpages = {9},
keywords = {Generative AI, artificial intelligence, bibliometric, educational technology, higher education},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3636243.3636245,
author = {Macneil, Stephen and Denny, Paul and Tran, Andrew and Leinonen, Juho and Bernstein, Seth and Hellas, Arto and Sarsa, Sami and Kim, Joanne},
title = {Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636245},
doi = {10.1145/3636243.3636245},
abstract = {Identifying and resolving logic errors can be one of the most frustrating challenges for novices programmers. Unlike syntax errors, for which a compiler or interpreter can issue a message, logic errors can be subtle. In certain conditions, buggy code may even exhibit correct behavior – in other cases, the issue might be about how a problem statement has been interpreted. Such errors can be hard to spot when reading the code, and they can also at times be missed by automated tests. There is great educational potential in automatically detecting logic errors, especially when paired with suitable feedback for novices. Large language models (LLMs) have recently demonstrated surprising performance for a range of computing tasks, including generating and explaining code. These capabilities are closely linked to code syntax, which aligns with the next token prediction behavior of LLMs. On the other hand, logic errors relate to the runtime performance of code and thus may not be as well suited to analysis by LLMs. To explore this, we investigate the performance of two popular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly explanation of logic errors. We compare LLM performance with a large cohort of introductory computing students (n = 964) solving the same error detection task. Through a mixed-methods analysis of student and model responses, we observe significant improvement in logic error identification between the previous and current generation of LLMs, and find that both LLM generations significantly outperform students. We outline how such models could be integrated into computing education tools, and discuss their potential for supporting students when learning programming.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {11–18},
numpages = {8},
keywords = {bug detection, computing education, generative AI, large language models, programming errors},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3675094.3678991,
author = {Li, Yunjia and Liu, Haiming and Wald, Mike},
title = {DeepVision: Heads-up Computing and AI in Education},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3678991},
doi = {10.1145/3675094.3678991},
abstract = {Heads-up computing together with AI can enhance in-class learning experiences. In this position paper, we propose the development of a multimodal AI system called DeepVision that integrates Automatic Speech Recognition (ASR), Large Language Models (LLM), Large Vision Models (LVM), Information Retrieval (IR) and Inclusive User Experience Design (IUX) to convert real-time lectures into multiple knowledge representations. These will be visualized on heads-up communication devices such as Augmented Reality (AR) and Mixed Reality (MR) devices. The initiative is a collaboration between Habitat Learn Limited (HLL) and the University of Southampton, leveraging HLL's existing software and extensive data repository to address the challenges of traditional and digital learning environments, especially for students with disabilities or language differences.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {627–630},
numpages = {4},
keywords = {ai, ar, heads-up computing, inclusive user experience design, large language model, multimodal information access and retrieval},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3605770.3625214,
author = {Singla, Tanmay and Anandayuvaraj, Dharun and Kalu, Kelechi G. and Schorlemmer, Taylor R. and Davis, James C.},
title = {An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures},
year = {2023},
isbn = {9798400702631},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605770.3625214},
doi = {10.1145/3605770.3625214},
abstract = {As we increasingly depend on software systems, the consequences of breaches in the software supply chain become more severe. High-profile cyber attacks like SolarWinds and ShadowHammer have resulted in significant financial and data losses, underlining the need for stronger cybersecurity. One way to prevent future breaches is by studying past failures. However, traditional methods of analyzing past failures require manually reading and summarizing reports about them. Automated support could reduce costs and allow analysis of more failures. Natural Language Processing (NLP) techniques such as Large Language Models (LLMs) could be leveraged to assist the analysis of failures. In this study, we assessed the ability of Large Language Models (LLMs) to analyze historical software supply chain breaches. We used LLMs to replicate the manual analysis of 69 software supply chain security failures performed by members of the Cloud Native Computing Foundation (CNCF). We developed prompts for LLMs to categorize these by four dimensions: type of compromise, intent, nature, and impact. GPT 3.5's categorizations had an average accuracy of 68% and Bard's had an accuracy of 58% over these dimensions. We report that LLMs effectively characterize software supply chain failures when the source articles are detailed enough for consensus among manual analysts, but cannot yet replace human analysts. Future work can improve LLM performance in this context, and study a broader range of articles and failures.},
booktitle = {Proceedings of the 2023 Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses},
pages = {5–15},
numpages = {11},
keywords = {cybersecurity, empirical software engineering, failure analysis, large language models, software security, software supply chain},
location = {Copenhagen, Denmark},
series = {SCORED '23}
}

@inbook{10.1145/3724504.3724635,
author = {He, Hao and Gao, Chaobang},
title = {Research on the Application of Artificial Intelligence in Basic Education: A Global Trend Analysis Based on Bibliometrics},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724635},
abstract = {Based on the bibliometric method, this study visually analyzed the application research literature of artificial intelligence (AI) in the domain of basic education in the Web of Science Core Collection from January 1, 2014 to November 1, 2024 with the help of VOSviewer and CiteSpace. A total of 344 valid articles were selected from 588 institutions and 1090 authors in 60 countries. They were published in 126 journals and cited 13855 references from 6922 journals. The study found that the number of papers published in China is the largest, and the quality recognition of papers in the United States is high. The journals with the greatest number of articles were mostly related to educational technology and computational intelligence, and Computers &amp; Education had the greatest number of citations per article. Keyword co-occurrence analysis shows that the study focuses on deep learning and the application of large language models (LLMs) has increased. The timeline analysis shows that the domain research has moved from the stage of data driven and educational technology application exploration to the stage of AI empowerment and personalized education. The co-citation analysis reveals that the interdisciplinary characteristics of educational technology research are obvious, and the literature co-citation network reflects the multi-dimensional application research type of AI in basic education. All in all, the popularity of AI application research in basic education is increasing, the research focus has changed, and generative AI is developing rapidly.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {799–806},
numpages = {8}
}

@inproceedings{10.1145/3689187.3709607,
author = {Clear, Tony and Cajander, \r{A}sa and Clear, Alison and McDermott, Roger and Daniels, Mats and Divitini, Monica and Forshaw, Matthew and Humble, Niklas and Kasinidou, Maria and Kleanthous, Styliani and Kultur, Can and Parvini, Ghazaleh and Polash, Mohammad and Zhu, Tingting},
title = {AI Integration in the IT Professional Workplace: A Scoping Review and Interview Study with Implications for Education and Professional Competencies},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709607},
doi = {10.1145/3689187.3709607},
abstract = {As Artificial Intelligence (AI) continues transforming workplaces globally, particularly within the Information Technology (IT) industry, understanding its impact on IT professionals and computing curricula is crucial. This research builds on joint work from two countries, addressing concerns about AI's increasing influence in IT sector workplaces and its implications for tertiary education. The study focuses on AI technologies such as generative AI (GenAI) and large language models (LLMs). It examines how they are perceived and adopted and their effects on workplace dynamics, task allocation, and human-system interaction.IT professionals, noted as early adopters of AI, offer valuable insights into the interplay between AI and work engagement, highlighting the significant competencies required for digital workplaces. This study employs a dual-method approach, combining a systematic and multi-vocal literature review and qualitative research methods. These included a thematic analysis of a set of 47 interviews conducted between March and May of 2024 with IT professionals in two countries (New Zealand and Sweden). The research aimed to understand the implications for computing students, education curricula, and the assessment of emerging professional competencies.The literature review found insufficient evidence addressing comprehensive AI practice methodologies, highlighting the need to both develop and regulate professional competencies for effective AI integration. Key interview findings revealed diverse levels of GenAI adoption, ranging from individual experimentation to institutional integration. Participants generally expressed positive attitudes toward the technology and were actively pursuing self-learning despite some concerns. The themes emerging from the interviews included AI's role in augmenting human tasks, privacy and security concerns, productivity enhancements, legal and ethical challenges, and the evolving need for new competencies in the workplace.The study underscores the critical role of competency frameworks in guiding professional development and ensuring preparedness for an AI-driven environment. Additionally, it highlights the need for educational institutions to adapt curricula to address these emerging demands effectively},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {34–67},
numpages = {34},
keywords = {artificial intelligence, computing competencies, computing curricula, generative ai, it profession, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3652620.3687776,
author = {Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta and Scalera, Michele},
title = {Enhancing Software Modeling Learning with AI-Powered Scaffolding},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687776},
doi = {10.1145/3652620.3687776},
abstract = {This study introduces an innovative AI-powered scaffolding approach aimed at enhancing software modeling learning through UML diagrams. The focus of this research is on defining the principles and functions comprising the scaffolding. Leveraging recent advancements in generative AI, our approach provides a structured educational framework to improve comprehension and proficiency in modeling concepts. We present the initial implementation of the scaffolding, specifically highlighting the feedback function. By integrating theoretical insights with practical applications, this study seeks to advance Model-Driven Software Engineering education and underscores the potential of AI in enhancing instructional methodologies.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {103–106},
numpages = {4},
keywords = {generative AI, education, software modelling, model-driven software engineering, UML, scaffolding},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3649217.3653533,
author = {Bernstein, Seth and Denny, Paul and Leinonen, Juho and Kan, Lauren and Hellas, Arto and Littlefield, Matt and Sarsa, Sami and Macneil, Stephen},
title = {"Like a Nesting Doll": Analyzing Recursion Analogies Generated by CS Students Using Large Language Models},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653533},
doi = {10.1145/3649217.3653533},
abstract = {Grasping complex computing concepts often poses a challenge for students who struggle to anchor these new ideas to familiar experiences and understandings. To help with this, a good analogy can bridge the gap between unfamiliar concepts and familiar ones, providing an engaging way to aid understanding. However, creating effective educational analogies is difficult even for experienced instructors. We investigate to what extent large language models (LLMs), specifically ChatGPT, can provide access to personally relevant analogies on demand. Focusing on recursion, a challenging threshold concept, we conducted an investigation analyzing the analogies generated by more than 350 first-year computing students. They were provided with a code snippet and tasked to generate their own recursion-based analogies using ChatGPT, optionally including personally relevant topics in their prompts. We observed a great deal of diversity in the analogies produced with student-prescribed topics, in contrast to the otherwise generic analogies, highlighting the value of student creativity when working with LLMs. Not only did students enjoy the activity and report an improved understanding of recursion, but they described more easily remembering analogies that were personally and culturally relevant.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {122–128},
numpages = {7},
keywords = {analogies, computing education, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@article{10.1145/3735635,
author = {Zhao, Zixiao and Fard, Fatemeh},
title = {Do Current Language Models Support Code Intelligence for R Programming Language?},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3735635},
doi = {10.1145/3735635},
abstract = {Recent advancements in developing Pre-trained Language Models for Code (Code-PLMs) have urged many areas of Software Engineering (SE) and brought breakthrough results for many SE tasks. Though these models have achieved the state-of-the-art performance for SE tasks for many popular programming languages, such as Java and Python, the Scientific Software and its related languages like R programming language have rarely benefited or even been evaluated with the Code-PLMs. Research has shown that R has many differences with other programming languages and requires specific techniques. In this study, we provide the first insights for code intelligence for R. For this purpose, we collect and open source an R dataset, and evaluate Code-PLMs for the two tasks of code summarization and method name prediction using several settings and strategies, including the differences in two R styles, Tidy-verse and Base R. Our results demonstrate that the studied models have experienced varying degrees of performance degradation when processing R programming language code, which is supported by human evaluation. Additionally, not all models show performance improvement in R-specific tasks even after multi-language fine-tuning. The dual syntax paradigms in R significantly impact the models’ performance, particularly in code summarization tasks. Furthermore, the project-specific context inherent in R codebases significantly impacts the performance when attempting cross-project training. Interestingly, even when Large Language Models like CodeLlama and StarCoder2 are used for code generation, the Pass@K ( (K=1,5,10) ) results lags signigicantly behind Python scores. Our research shows that R as a low resource language requires different techniques to collect a high quality data. Specifically separating the two R styles has a great impact on the results and the separate dataset could increase the performance of the models. Our research sheds light on the capabilities of Code-PLMs and opens new research directions for researchers and practitioners for developing code intelligence tools and techniques for R. With R's widespread use and popularity, the results of our study can potentially benefit a large community of R developers, both in research and industry.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Empirical Studies, Code Summarization, Method Name Prediction, R Programming Language, Code Generation in R, R programming Styles (Tidy-verse and Base)}
}

@inproceedings{10.1145/3726010.3726041,
author = {Ding, Yuxuan and Yu, Hongzhi and Wan, Fucheng},
title = {Optimization Research on Reasoning Capabilities of Large Models Based on Chain of Thought},
year = {2025},
isbn = {9798400712845},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726010.3726041},
doi = {10.1145/3726010.3726041},
abstract = {The aim of this study is to explore a chain-of-thought-based approach to improving the reasoning ability of large language models, using the LLaMA3-8B model as a base and combining LoRA fine-tuning techniques to optimize it. The LLaMA3 model shows strong basic ability in natural language processing tasks, but when dealing with complex reasoning tasks, the model's inference steps tend not to be clear enough, this paper introduces the chain-of-thought approach, which significantly improves the model's performance in multi-step reasoning tasks by gradually unfolding the reasoning process. At the same time, this study adopts the LoRA fine-tuning technique to ensure the computational efficiency of the model, while further improving its adaptability and accuracy on specific tasks. Through experimental evaluations on several standard datasets, the results show that the LLaMA3 model combining LoRA fine-tuning and CoT methods significantly improves both reasoning accuracy and efficiency, providing new ideas and practical basis for efficient reasoning and fine-tuning of large language models.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence, Digital Media Technology and Interaction Design},
pages = {209–213},
numpages = {5},
keywords = {LLaMA3 model, LoRA fine-tuning, chain-of-thought, efficient reasoning},
location = {
},
series = {ICADI '24}
}

@inproceedings{10.1145/3613904.3642024,
author = {Rajashekar, Niroop Channa and Shin, Yeo Eun and Pu, Yuan and Chung, Sunny and You, Kisung and Giuffre, Mauro and Chan, Colleen E and Saarinen, Theo and Hsiao, Allen and Sekhon, Jasjeet and Wong, Ambrose H and Evans, Leigh V and Kizilcec, Rene F. and Laine, Loren and Mccall, Terika and Shung, Dennis},
title = {Human-Algorithmic Interaction Using a Large Language Model-Augmented Artificial Intelligence Clinical Decision Support System},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642024},
doi = {10.1145/3613904.3642024},
abstract = {Integration of artificial intelligence (AI) into clinical decision support systems (CDSS) poses a socio-technological challenge that is impacted by usability, trust, and human-computer interaction (HCI). AI-CDSS interventions have shown limited benefit in clinical outcomes, which may be due to insufficient understanding of how health-care providers interact with AI systems. Large language models (LLMs) have the potential to enhance AI-CDSS, but haven’t been studied in either simulated or real-world clinical scenarios. We present findings from a randomized controlled trial deploying AI-CDSS for the management of upper gastrointestinal bleeding (UGIB) with and without an LLM interface within realistic clinical simulations for physician and medical student participants. We find evidence that LLM augmentation improves ease-of-use, that LLM-generated responses with citations improve trust, and HCI varies based on clinical expertise. Qualitative themes from interviews suggest the perception of LLM-augmented AI-CDSS as a team-member used to confirm initial clinical intuitions and help evaluate borderline decisions.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {442},
numpages = {20},
keywords = {Artificial Intelligence, Clinical Decision Support Systems, Electronic Health Record, Health-Clinical, Machine Learning, Medical: Nursing Homes/Hospitals, Qualitative Methods, Quantitative Methods, Workflows},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3708557.3716162,
author = {Gadiraju, Ujwal and Yadav, Kuldeep},
title = {DECI: The 3rd Tutorial on Designing Effective Conversational Interfaces},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716162},
doi = {10.1145/3708557.3716162},
abstract = {Advances in generative AI and the widespread proliferation of LLM-based applications have created a number of opportunities for designing effective and intelligent human-AI interfaces. Conversational User Interfaces (CUIs) have enabled humans to interact with machines more naturally across several domains and applications. People are increasingly familiar with conversational interactions mediated by technology due to the widespread use of mobile technologies, social networks, pervasive computing, and the rapid adoption of large language models that power conversational agents. Based on the recent advances in conversational AI, due to the proliferation of LLMs, there are clear signs that the future of human-computer interaction will have a significant conversational component. In the context of ever-lowering barriers to accessibility to technologies, digital applications, and generative AI, this tutorial will showcase the benefits of employing conversational interfaces for human-AI decision making, health and well-being, and crowd computing. We will discuss the potential of conversational interfaces in facilitating and mediating people’s interactions with AI systems and the opportunities and challenges that lie at this intersection from the broad standpoint of intelligent user interfaces. This third incarnation of this tutorial will include interactive elements and discussions, providing participants with practical insights to inform the design of effective conversational interfaces.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {195–198},
numpages = {4},
keywords = {conversational user interfaces, conversational crowdsourcing, human-AI interaction, human-AI decision making, conversational AI},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3669940.3707224,
author = {Tan, Yifan and Tan, Cheng and Mi, Zeyu and Chen, Haibo},
title = {PipeLLM: Fast and Confidential Large Language Model Services with Speculative Pipelined Encryption},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669940.3707224},
doi = {10.1145/3669940.3707224},
abstract = {Confidential computing on GPUs, like NVIDIA H100, mitigates the security risks of outsourced Large Language Models (LLMs) by implementing strong isolation and data encryption. Nonetheless, this encryption incurs a significant performance overhead, reaching up to 52.8% and 88.2% throughput drop when serving OPT-30B and OPT-66B, respectively. To address this challenge, we introduce PipeLLM, a user-transparent runtime system. PipeLLM removes the overhead by overlapping the encryption and GPU computation through pipelining-an idea inspired by the CPU instruction pipelining-thereby effectively concealing the latency increase caused by encryption. The primary technical challenge is that, unlike CPUs, the encryption module lacks prior knowledge of the specific data needing encryption until it is requested by the GPUs. To this end, we propose speculative pipelined encryption to predict the data requiring encryption by analyzing the serving patterns of LLMs. Further, we have developed an efficient, low-cost pipeline relinquishing approach for instances of incorrect predictions. Our experiments show that compared with vanilla systems without confidential computing (e.g., vLLM, PEFT, and FlexGen), PipeLLM incurs modest overhead ( &lt; 19.6% in throughput) across various LLM sizes, from 13B to 175B. PipeLLM's source code is available at https://github.com/SJTU-IPADS/PipeLLM.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
pages = {843–857},
numpages = {15},
keywords = {confidential virtual machine, large language model, nvidia confidential computing},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3702212.3702214,
author = {Clift, Lee and Petrovska, Olga},
title = {Learning without Limits: Analysing the Usage of Generative AI in a Summative Assessment},
year = {2025},
isbn = {9798400711725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702212.3702214},
doi = {10.1145/3702212.3702214},
abstract = {This paper explores how Generative AI (GenAI) can be introduced within summative assessment components in software engineering education. We present an example of an assessment which allows learners to use GenAI in a freeform, constructionist manner, as part of a large, software development project. This work is inspired by previously executed AI-focused assessments and surveys, which explicitly indicate that learners on an Applied Software Engineering Degree Apprenticeship Programme want to formally learn how to use GenAI tools when programming and their employers want to see these skills from graduates. The learning outcome of the assignment was for learners to explore a typical developmental pipeline as a solo developer, moving from design to development to finished product. Learners were marked exclusively on their end product and understanding of application components, not the written code itself, resulting in an assessment where the end product and project were prioritised over foundational code (which was adequately assessed in other components). The results show that all learners used GenAI to some extent during their project, and in all cases, they found it beneficial for large programming tasks. Learners were generally able to produce a larger, more comprehensive and more ambitious project, compared to previous years. It is proposed that removing the barrier to GenAI - and demystifying it - can encourage a constructionist approach to its use, and normalise it as a potential tool for programming.},
booktitle = {Proceedings of the 9th Conference on Computing Education Practice},
pages = {5–8},
numpages = {4},
keywords = {GenAI, software engineering, education, apprenticeship},
location = {
},
series = {CEP '25}
}

@inproceedings{10.1145/3706599.3720022,
author = {Yin, Yue},
title = {Too Much Information? Investigating Information Disclosure in Auction Systems with LLM Simulations},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720022},
doi = {10.1145/3706599.3720022},
abstract = {Online advertising relies on auction systems to allocate advertisement impressions efficiently and maximize revenue. A defining characteristic of these systems is information asymmetry: publishers (auctioneers) have access to detailed data, while bidders rely on limited signals. Understanding how information disclosure strategies shape bidder behavior and auction outcomes is essential for designing adaptive, user-centered advertising systems.This paper introduces InfoBid, a simulation framework powered by large language models (LLMs) to study the impact of information signaling in auction environments. This simulation framework enables researchers to analyze how information disclosure affects decision-making and system performance. By offering a flexible and extensible testbed, InfoBid advances Human-Computer Interaction (HCI) methodologies for studying multi-agent interactions, adaptive decision-making, and information sharing in complex digital marketplaces.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {532},
numpages = {8},
keywords = {Multi-Agent Simulation, Information Asymmetry, Strategic Information Disclosure, Large Language Models (LLMs), Mechanism Design, Digital Advertising System},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3649217.3653557,
author = {Farinetti, Laura and Canale, Lorenzo},
title = {Chatbot Development Using LangChain: A Case Study to Foster Critical Thinking and Creativity},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653557},
doi = {10.1145/3649217.3653557},
abstract = {Critical thinking and creativity are fundamental skills for engineers and computer scientists. The emergence of Large Language Models (LLMs) able to create chatbots that use natural language is an opportunity for educators to foster these skills. The well-known risk of generative AI for potential misinformation offers fertile ground to practice critical thinking.This paper describes a hands-on experience within a database course, where students had to develop a chatbot using the LangChain framework, and to evaluate it from different points of view. The students were free to choose the domain of their chatbot. The learning goal was twofold: on the one hand, to make them practice with state-of-the-art technologies, and on the other hand to stimulate critical analysis on their output. The paper discusses the students' evaluation of the chatbots under several metrics, including document retrieval, syntax and grammar accuracy, semantic relevance and information reliability. Students' assessments were also compared to the teachers' ones, to gain an insight on the critical attitude of the students and to offer a ground for discussion.The experience was stimulating and appreciated by the students. The final results highlight that the majority of students successfully produced chatbot responses that were grammatically and syntactically correct, and that consistently extracted pertinent sections from documents, yielding semantically relevant outputs. Despite these achievements, a significant portion of students expressed reservations about the reliability of the chatbot's responses to prompts, gaining awareness of LLMs' capability to generate responses that make sense to humans but may be potentially misleading.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {401–407},
numpages = {7},
keywords = {chatbot development, creativity and critical thinking, database education, information retrieval, langchain framework, large language models, natural language interfaces},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@article{10.5555/3722479.3722482,
author = {Reno, Michael J. and Russell, Victoria and Nutter, Taylor J. and Rao, P. Anand and Polack, Jennifer},
title = {AI Intersections: Ethics, Education, and Technological Philopsophy},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {This panel explores the multifaceted intersections of artificial intelligence with ethics, education, and philosophical perspectives on technology. As AI continues to reshape our world, it becomes increasingly crucial to examine its implications across various disciplines. Our panelists will present diverse viewpoints, ranging from innovative pedagogical approaches using AI to philosophical inquiries into the nature of intelligence and technology. The panel will address critical questions surrounding AI explainability, the integration of AI in education, the historical context of AI research, and the ethical considerations that arise from these technological advancements. By bringing together experts from computer science, philosophy, religious studies, and digital humanities, this panel aims to foster a rich, interdisciplinary dialogue on the present and future of AI in academia and society. In the spirit of the panel topic, this abstract was created using Anthropic's Generative AI platform, Claude.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {21–23},
numpages = {3}
}

@inproceedings{10.1145/3626253.3635483,
author = {Lee Solano, Lorenzo and Renzella, Jake and Vassar, Alexandra},
title = {DCC Sidekick: Helping Novices Solve Programming Errors Through a Conversational Explanation Interface},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635483},
doi = {10.1145/3626253.3635483},
abstract = {Students in introductory computing courses often lack the experience required to effectively identify and resolve errors in their code. For such students, Programming Error Messages (PEMs) are often the first indication of an error, and could provide valuable debugging guidance. However, in many cases, such as with standard C compiler implementations, PEMs are largely unsuitable for novices. Confusing, misleading, and filled with terse language and jargon, these messages instead act as an additional source of difficulty.In this paper, we present DCC Sidekick, which integrates the Debugging C Compiler (DCC) with a Large Language Model (LLM) in a web-based dashboard to produce contextual, accurate guidance conducive to student learning. This dashboard is directly accessible from the output of the compiler, and provides a bird's-eye-view of the program source, compiler output, and a conversational AI interface to help unravel cryptic error messages. We aim to deploy DCC Sidekick to a C-based CS1 cohort at a large higher education institution to investigate how novice students utilise the conversational explanation interface during debugging activities. In this work, we present our experience designing and building DCC Sidekick.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1714–1715},
numpages = {2},
keywords = {ai in education, compiler error messages, cs1, error message enhancement, generative ai},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3701716.3716842,
author = {Naseem, Usman and Rashid, Junaid and Kim, Junguen and Beheshti, Amin and Yang, Jian and Dras, Mark},
title = {LLMs as Historical Actors: How AI Systems Influence the Web's Evolution},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3716842},
doi = {10.1145/3701716.3716842},
abstract = {The history of the web has been defined by a series of revolutionary developments, from the advent of HTML and web browsers to the explosion of social media and cloud computing. Throughout this evolution, human actors have played pivotal roles, serving as developers, technologists, and innovators who have guided the trajectory of the Internet. However, the emergence of Large Language Models (LLMs), such as OpenAI's GPT series, represents a paradigm shift. These AI systems are not merely tools for humans but are increasingly becoming autonomous agents that shape the flow of information on the web. In this paper, we argue that LLMs can be framed as historical actors, meaning they are not only facilitators of human endeavors but also independent forces that influence the web's evolution. We explore how these AI systems direct the flow of information, shape public discourse, and may influence future interpretations of web-based history.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {841–844},
numpages = {4},
keywords = {actors, distributors, echo chambers, llms, public discourse, web},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3636243.3636252,
author = {Jury, Breanna and Lorusso, Angela and Leinonen, Juho and Denny, Paul and Luxton-Reilly, Andrew},
title = {Evaluating LLM-generated Worked Examples in an Introductory Programming Course},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636252},
doi = {10.1145/3636243.3636252},
abstract = {Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, ‘WorkedGen’, which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for optimising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen’s value in a range of programming languages, and with more complex questions suitable for more advanced courses.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {77–86},
numpages = {10},
keywords = {CS1, GPT-3.5, LLM, chat-GPT, computing education, large language models, worked examples},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@article{10.1145/3718096,
author = {Jo, Ashly Ann and Raj, Ebin Deni and Sahoo, Jayakrushna},
title = {Efficiency and Performance Optimization in Large Language Models through IB Fine-Tuning},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/3718096},
doi = {10.1145/3718096},
abstract = {In the rapidly evolving field of Natural Language Processing (NLP), optimizing methods for fine-tuning Large Language Models (LLMs) is increasingly critical for improving generalization and performance. Fine-tuning LLMs is challenging due to high costs, overfitting, and difficulty adapting to diverse tasks. These challenges grow as LLMs scale, making traditional fine-tuning methods inefficient and expensive. To address these issues, a novel Information Bottleneck (IB) method for fine-tuning LLMs is proposed, focusing on retaining only the most critical and relevant information in the model’s internal representations. By striking a balance between information compression and predictive relevance, the IB method aims to reduce overfitting and enhance generalization. This approach also integrates reinforcement learning and continual learning to enhance LLM performance further. The proposed framework considers two key metrics: (1) compression effectiveness, which reduces redundancy and improves generalization, and (2) predictive relevance, which ensures high task-specific performance. The proposed scheme achieves scalable fine-tuning across diverse NLP tasks using a lightweight proxy model to enhance computational efficiency. The proposed framework empirical evaluations and ablation studies show that the IB method improves accuracy while significantly reducing computational costs, enabling efficient, interpretable, and adaptable LLM optimization and increasing convergence.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = apr,
articleno = {56},
numpages = {23},
keywords = {Transformer models, BERT, Attention}
}

@inproceedings{10.1145/3649329.3663517,
author = {Huang, Yingbing and Wan, Lily Jiaxin and Ye, Hanchen and Jha, Manvi and Wang, Jinghua and Li, Yuhong and Zhang, Xiaofan and Chen, Deming},
title = {Invited: New Solutions on LLM Acceleration, Optimization, and Application},
year = {2024},
isbn = {9798400706011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649329.3663517},
doi = {10.1145/3649329.3663517},
abstract = {Large Language Models (LLMs) have revolutionized a wide range of applications with their strong human-like understanding and creativity. Due to the continuously growing model size and complexity, LLM training and deployment have shown significant challenges, which often results in extremely high computational and storage costs and energy consumption. In this paper, we discuss the recent advancements and research directions on (1) LLM algorithm-level acceleration, (2) LLM-hardware co-design for improved system efficiency, (3) LLM-to-accelerator compilation for customized LLM accelerators, and (4) LLM-aided design for HLS (High-Level Synthesis) functional verification. For each aspect, we present the background study, our proposed solutions, and future directions. An extended version of this work can be found at: https://arxiv.org/abs/2406.10903.},
booktitle = {Proceedings of the 61st ACM/IEEE Design Automation Conference},
articleno = {369},
numpages = {4},
keywords = {large language models (LLMs), high-level synthesis (HLS), acceleration, functional verification, hardware design},
location = {San Francisco, CA, USA},
series = {DAC '24}
}

@inproceedings{10.1145/3641554.3701960,
author = {Sanchez, Edwin Antonio and Zheng, Muwei and Bishop, Matt and Zou, Xukai},
title = {Case Study 2: Mapping between an E-Voting Curriculum and the DHS/NSA CAE Knowledge Units},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701960},
doi = {10.1145/3641554.3701960},
abstract = {To become a DHS/NSA Center of Academic Excellence in Cyber Defense (CAE-CD), academic institutions must satisfy several specific Knowledge Units (KUs). How they achieve this is up to the institutions. In this case study, we follow the methodology of an earlier work to demonstrate how key parts of an electronic voting (E-voting)-oriented cybersecurity curriculum, proposed by Hostler et al. [4] in 2021, maps into the DHS/NSA KUs supporting the CAE-CD designation, from two aspects: E-voting principle based topics, i.e., from theory and a plug-and-play e-voting system's composing components, i.e., from practice. We grouped CAE-CD KUs into those required as prerequisites, closely related, related/supported, and not covered by the E-voting curriculum. Teachers can then choose which KUs they will use and teach using only the parts of the E-voting-oriented curriculum they deem relevant, and in a depth they find appropriate to their educational objectives, while meeting the requirements of the selected KUs. We conclude with a discussion of how LLMs (Large Language Models) and quantum computing might be added to the E-voting-oriented curriculum.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1022–1028},
numpages = {7},
keywords = {cae-cd, cybersecurity curriculum, cybersecurity education, electronic voting system},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inbook{10.1145/3715014.3724375,
author = {Harris, George S. and Lok, Aidan and Nirjon, Shahriar},
title = {Demo Abstract: Human Strategy Meets AI Execution: An LLM-Driven Gaming Agent},
year = {2025},
isbn = {9798400714795},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715014.3724375},
abstract = {We introduce an intelligent mobile agent that leverages large language models (LLMs) and computer vision to interpret user commands and autonomously interact with smartphone applications. This agent continuously captures and analyzes screen content, executes actions such as taps, swipes, and text inputs, and intelligently handles ambiguous situations by prompting users for clarification. To advance this vision, we first develop a prototype focused on automating interactions in low-frame-rate mobile games like 2048 and tic-tac-toe. By taking user-defined strategies as input, the agent automates game interactions, effectively separating strategic decision-making from physical touch-based inputs. This enhances accessibility for users who cannot physically interact with a phone and for those who prefer focusing on strategy rather than execution.},
booktitle = {Proceedings of the 23rd ACM Conference on Embedded Networked Sensor Systems},
pages = {718–719},
numpages = {2}
}

@inproceedings{10.1145/3587103.3594206,
author = {Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Caspersen, Michael E. and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir},
title = {Transformed by Transformers: Navigating the AI Coding Revolution for Computing Education: An ITiCSE Working Group Conducted by Humans},
year = {2023},
isbn = {9798400701399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587103.3594206},
doi = {10.1145/3587103.3594206},
abstract = {The recent advent of highly accurate and scalable large language models (LLMs) has taken the world by storm. From art to essays to computer code, LLMs are producing novel content that until recently was thought only humans could produce. Recent work in computing education has sought to understand the capabilities of LLMs for solving tasks such as writing code, explaining code, creating novel coding assignments, interpreting programming error messages, and more. However, these technologies continue to evolve at an astonishing rate leaving educators little time to adapt. This working group seeks to document the state-of-the-art for code generation LLMs, detail current opportunities and challenges related to their use, and present actionable approaches to integrating them into computing curricula.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2},
pages = {561–562},
numpages = {2},
keywords = {AI, CS1, GPT, GitHub, LLM, artificial intelligence, code generation, codex, computer programming, copilot, large language models, novice programming, openAI, pedagogical practices},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.5555/3709347.3744043,
author = {Zhao, Yunfan and Boehmer, Niclas and Taneja, Aparna and Tambe, Milind},
title = {Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {AI for social impact (AI4SI) offers significant potential for addressing complex societal challenges in areas such as public health, agriculture, education, conservation, and public safety. However, existing AI4SI research is often labor-intensive and resource-demanding, limiting its accessibility and scalability; the standard approach is to design a (base-level) system tailored to a specific AI4SI problem. We propose the development of a novel meta-level multi-agent system designed to accelerate the development of such base-level systems, thereby reducing the computational cost and the burden on social impact domain experts and AI researchers. Leveraging advancements in foundation models and large language models, our proposed approach focuses on resource allocation problems providing help across the full AI4SI pipeline from problem formulation over solution design to impact evaluation. We highlight the ethical considerations and challenges inherent in deploying such systems and emphasize the importance of a human-in-the-loop approach to ensure the responsible and effective application of AI systems.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {2901–2907},
numpages = {7},
keywords = {foundation models, multiagent systems, social impact},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3701625.3701700,
author = {de Lima, Vitor Mesaque Alves and Marcacini, Ricardo Marcondes},
title = {Opinion Mining for App Reviews: Identifying and Prioritizing Emerging Issues for Software Maintenance and Evolution},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701700},
doi = {10.1145/3701625.3701700},
abstract = {Opinion mining for app reviews aims to analyze user comments on app stores to support software engineering activities, primarily software maintenance and evolution. One of the main challenges in maintaining software quality is promptly identifying emerging issues, such as bugs. However, manually analyzing these comments is challenging due to the large amount of textual data. Methods based on machine learning have been employed to automate opinion mining and address this issue. Gap. While recent methods have achieved promising results in extracting and categorizing issues from users’ opinions, existing studies mainly focus on assisting software engineers in exploring users’ historical behavior regarding app functionalities and do not explore mechanisms for trend detection and risk classification of emerging issues. Furthermore, these studies do not cover the entire issue analysis process through an unsupervised approach. Contribution. This work advances state of the art in opinion mining for app reviews by proposing an entire automated issue analysis approach to identify, prioritize, and monitor the risk of emerging issues. Our proposal introduces a two-fold approach that (i) identifies possible defective software requirements and trains predictive models for anticipating requirements with a higher probability of negative evaluation and (ii) detect issues in reviews, classifies them in a risk matrix with prioritization levels, and monitors their evolution over time. Additionally, we present a risk matrix construction approach from app reviews using the recent Large Language Models (LLMs). We introduce an analytical data exploration tool that allows engineers to browse the risk matrix, time series, heat map, issue tree, alerts, and notifications. Our goal is to minimize the time between the occurrence of an issue and its correction, enabling the quick identification of problems. Results. We processed over 6.6 million reviews across 20 domains to evaluate our proposal, identifying and ranking the risks associated with nearly 270,000 issues. The results demonstrate the competitiveness of our unsupervised approach compared to existing supervised models. Conclusions. We have proven that opinions extracted from user reviews provide crucial insights into app issues and risks and can be identified early to mitigate their impact. Our opinion mining process implements an entire automated issue analysis with risk-based prioritization and temporal monitoring.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {687–696},
numpages = {10},
keywords = {opinion mining, app reviews, issue detection, issue prioritization, software maintenance and evolution},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3632621.3671424,
author = {Mozgovoy, Maxim and Suero Montero, Calkin},
title = {Exploring Students Solutions to Concurrent and Parallel Programming Exercises – Impact of Generative AI},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671424},
doi = {10.1145/3632621.3671424},
abstract = {Background. Concurrent and parallel programming is difficult to teach and learn as the understanding of complex and abstract concepts such as nondeterminism, semaphore, and rare conditions, among others, is required [1, 2, 9], having as a core issue the synchronisation of processes to achieve a common goal [4]. It is well-acknowledged that concurrent and parallel programming skills are fundamental since, nowadays, computing is increasingly handled in a parallel manner [7].Problem and Motivation. Therefore, identifying students’ pitfalls and successes when solving practical concurrent and parallel programming exercises could shed light on the best approaches and strategies that they use [3]. In addition, the advent of large language models, and generative AI applications such as ChatGPT, has prompted intensive research on their use in several areas including programming teaching and learning [8]. Yet, the studies in the literature have focused on issues related to learning to program by novice students in introductory courses (e.g., CS1, CS2) [6]. Less work, however, has been presented on the impact of generative AI tools in advanced programming practices such as concurrent and parallel programming.Methodology. To investigate whether generative AI has had an impact on the submitted concurrent and parallel programming exercises solutions at the University of Aizu, Japan, we performed a comparison analysis of the students’ submissions over 2020–2023. The analysis included five different exercises covering the basis of concurrency through various tasks and scenarios where the implementation of parallel processes is needed as solution. For instance, exercises 2.3 and 2.4 required to create parallel processes and perform independent computations; exercises 3.2 and 3.3, required synchronisation of the parallel processes; and in exercise 3.5 a code template was given for modification. We analysed the submissions of 72 undergraduate 3rd year students (avg. 18 students/year) and labelled the solutions using the following nomenclature: OK, indicating a good solution; OKFeat, a good solution but with unusual features; AdvLib, use of unnecessary advanced library or functionality; BadTool, use of an inappropriate tool when the task definition explicitly required a different tool; CodeErr, general coding error; SyncErr, concurrent programming specific error; N/A, solution not submitted or incomplete.Results and Analysis. Results show a substantial increase in the incidence of use of advance libraries (AdvLib) and the wrong tools (BadTool) among students in 2023 for three out of the five analysed exercises. At the same time the concurrency programming-specific errors (SyncErr) also see a reduction in all the exercises. (Figure 1). This coincides with the availability of generative AI tools such as ChatGPT [5], which warrants further investigations to understand how students, teachers and instructors could harness the affordances of large language models in their concurrent programming learning, teaching, and practice.Contribution and Impact. This paper presents an initial step towards investigating the impact of generative AI on advanced programming topics. This research will continue to uncover strategies for the lecturers and instructors to identify the affordances and use of generative AI and to design exercises that harness these affordances to support students learning of difficult programming concepts.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {533–534},
numpages = {2},
keywords = {Evaluation of students’ exercises, Large language models in advanced programming},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3597503.3639111,
author = {Dolata, Mateusz and Lange, Norbert and Schwabe, Gerhard},
title = {Development in times of hype: How freelancers explore Generative AI?},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639111},
doi = {10.1145/3597503.3639111},
abstract = {The rise of generative AI has led many companies to hire freelancers to harness its potential. However, this technology presents unique challenges to developers who have not previously engaged with it. Freelancers may find these challenges daunting due to the absence of organizational support and their reliance on positive client feedback. In a study involving 52 freelance developers, we identified multiple challenges associated with developing solutions based on generative AI. Freelancers often struggle with aspects they perceive as unique to generative AI such as unpredictability of its output, the occurrence of hallucinations, and the inconsistent effort required due to trial-and-error prompting cycles. Further, the limitations of specific frameworks, such as token limits and long response times, add to the complexity. Hype-related issues, such as inflated client expectations and a rapidly evolving technological ecosystem, further exacerbate the difficulties. To address these issues, we propose Software Engineering for Generative AI (SE4GenAI) and Hype-Induced Software Engineering (HypeSE) as areas where the software engineering community can provide effective guidance. This support is essential for freelancers working with generative AI and other emerging technologies.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {183},
numpages = {13},
keywords = {generative AI, AI-based systems, challenges, freelancers, hype, SE for generative AI, SE4GenAI, hype-induced SE, hype-SE, fashion, product, paradigm, novelty, qualitative research},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3709026.3709050,
author = {Li, Bingli and Vargas, Danilo Vasconcellos},
title = {Extending Token Computation for LLM Reasoning},
year = {2025},
isbn = {9798400718182},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709026.3709050},
doi = {10.1145/3709026.3709050},
abstract = {Large Language Models (LLMs) are pivotal in advancing natural language processing but often struggle with complex reasoning tasks due to inefficient attention distributions. In this paper, we explore the effect of increased computed tokens on LLM performance and introduce a novel method for extending computed tokens in the Chain-of-Thought (CoT) process, utilizing attention mechanism optimization. By fine-tuning an LLM on a domain-specific, highly structured dataset, we analyze attention patterns across layers, identifying inefficiencies caused by non-semantic tokens with outlier high attention scores. To address this, we propose an algorithm that emulates early layer attention patterns across downstream layers to re-balance skewed attention distributions and enhance knowledge abstraction. Our findings demonstrate that our approach not only facilitates a deeper understanding of the internal dynamics of LLMs but also significantly improves their reasoning capabilities, particularly in non-STEM domains. Our study lays the groundwork for further innovations in LLM design, aiming to create more powerful, versatile, and responsible models capable of tackling a broad range of real-world applications.},
booktitle = {Proceedings of the 2024 8th International Conference on Computer Science and Artificial Intelligence},
pages = {367–373},
numpages = {7},
keywords = {neural networks, attention mechanisms, reasoning},
location = {
},
series = {CSAI '24}
}

@article{10.5555/3737313.3737323,
author = {Barnard, Jakob and Braught, Grant and Davis, Janet and Holland-Minkley, Amanda and Schmitt, Karl and Tartaro, Andrea},
title = {Reviewing and Revising your Undergraduate CS Major: A Structured Design Process for Creating Distinctive Curricula},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {Computer science (CS) programs have a variety of reasons for regularly reviewing and revising the curriculum for their undergraduate major. Some of these stem from the rapid pace of change in the discipline and corresponding changes in industry expectations for CS graduates. This has been most recently seen as departments consider how to adjust to advances in generative AI and respond to new international curricular guidelines in the form of CS2023 [1]. Programs also revise their CS major in response to contextual shifts at their institution, such as changes in the size and makeup of the student body, the resources and staffing of a program, assessment results, or new institutional priorities [6]. A shifting student body may come with changes in prior experience with computing and in the professional goals of the students. For smaller programs, staffing changes often affect the balance of expertise within subareas of CS. New institutional priorities such as enabling more study abroad experiences or embedding internship/service-learning into the curriculum can require majors to adjust to both accommodate and support these priorities.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {32–34},
numpages = {3}
}

@inproceedings{10.1145/3669940.3707215,
author = {Mei, Yixuan and Zhuang, Yonghao and Miao, Xupeng and Yang, Juncheng and Jia, Zhihao and Vinayak, Rashmi},
title = {Helix: Serving Large Language Models over Heterogeneous GPUs and Network via Max-Flow},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669940.3707215},
doi = {10.1145/3669940.3707215},
abstract = {This paper introduces Helix, a distributed system for high-throughput, low-latency large language model (LLM) serving in heterogeneous GPU clusters. The key idea behind Helix is to formulate inference computation of LLMs over heterogeneous GPUs and network connections as a max-flow problem on directed, weighted graphs, whose nodes represent GPU instances and edges capture both GPU and network heterogeneity through their capacities. Helix then uses a mixed integer linear programming (MILP) algorithm to discover highly optimized strategies to serve LLMs on heterogeneous GPUs. This approach allows Helix to jointly optimize model placement and request scheduling, two highly entangled tasks in heterogeneous LLM serving. Our evaluation on several heterogeneous clusters ranging from 24 to 42 GPU nodes shows that Helix improves serving throughput by up to 3.3x and reduces prompting and decoding latency by up to 66% and 24%, respectively, compared to existing approaches. Helix is available at https://github.com/Thesys-lab/Helix-ASPLOS25.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
pages = {586–602},
numpages = {17},
keywords = {cloud computing, distributed systems, large language model serving, system for ml},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3568812.3603482,
author = {Tran, Andrew and Li, Linxuan and Rama, Egi and Angelikas, Kenneth and Macneil, Stephen},
title = {Using Large Language Models to Automatically Identify Programming Concepts in Code Snippets},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603482},
doi = {10.1145/3568812.3603482},
abstract = {Curating course material that aligns with students’ learning goals is a challenging and time-consuming task that instructors undergo when preparing their curricula. For instance, it is a challenge to find multiple-choice questions or example codes that demonstrate recursion in an unlabeled question bank or repository. Recently, Large Language Models (LLMs) have demonstrated the capability to generate high-quality learning materials at scale. In this poster, we use LLMs to identify programming concepts found within code snippets, allowing instructors to quickly curate their course materials. We compare programming concepts generated by LLMs with concepts generated by experts to see the extent to which they agree. The agreement was calculated using Cohen’s Kappa.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {22–23},
numpages = {2},
keywords = {computer science education, explanations, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3613904.3642139,
author = {Gero, Katy Ilonka and Swoopes, Chelse and Gu, Ziwei and Kummerfeld, Jonathan K. and Glassman, Elena L.},
title = {Supporting Sensemaking of Large Language Model Outputs at Scale},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642139},
doi = {10.1145/3613904.3642139},
abstract = {Large language models (LLMs) are capable of generating multiple responses to a single prompt, yet little effort has been expended to help end-users or system designers make use of this capability. In this paper, we explore how to present many LLM responses at once. We design five features, which include both pre-existing and novel methods for computing similarities and differences across textual documents, as well as how to render their outputs. We report on a controlled user study (n=24) and eight case studies evaluating these features and how they support users in different tasks. We find that the features support a wide variety of sensemaking tasks and even make tasks tractable that our participants previously considered to be too difficult to attempt. Finally, we present design guidelines to inform future explorations of new LLM interfaces.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {838},
numpages = {21},
keywords = {analogical learning theory, foundation models, language models, large language models, reading, sensemaking, skimming, variation theory},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3636243.3636247,
author = {Hou, Irene and Man, Owen and Mettille, Sophia and Gutierrez, Sebastian and Angelikas, Kenneth and MacNeil, Stephen},
title = {More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636247},
doi = {10.1145/3636243.3636247},
abstract = {Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {29–38},
numpages = {10},
keywords = {Bard, ChatGPT, GPT-4V, Generative AI, LLMs, Parsons Problems, computing education, visual programming problems},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3597503.3639183,
author = {Ahmed, Toufique and Pai, Kunal Suresh and Devanbu, Premkumar and Barr, Earl},
title = {Automatic Semantic Augmentation of Language Model Prompts (for Code Summarization)},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639183},
doi = {10.1145/3597503.3639183},
abstract = {Large Language Models (LLM) are a new class of computation engines, "programmed" via prompt engineering. Researchers are still learning how to best "program" these LLMs to help developers. We start with the intuition that developers tend to consciously and unconsciously collect semantics facts, from the code, while working. Mostly these are shallow, simple facts arising from a quick read. For a function, such facts might include parameter and local variable names, return expressions, simple pre- and post-conditions, and basic control and data flow, etc.One might assume that the powerful multi-layer architecture of transformer-style LLMs makes them implicitly capable of doing this simple level of "code analysis" and extracting such information, while processing code: but are they, really? If they aren't, could explicitly adding this information help? Our goal here is to investigate this question, using the code summarization task and evaluate whether automatically augmenting an LLM's prompt with semantic facts explicitly, actually helps.Prior work shows that LLM performance on code summarization benefits from embedding a few code &amp; summary exemplars in the prompt, before the code to be summarized. While summarization performance has steadily progressed since the early days, there is still room for improvement: LLM performance on code summarization still lags its performance on natural-language tasks like translation and text summarization.We find that adding semantic facts to the code in the prompt actually does help! This approach improves performance in several different settings suggested by prior work, including for three different Large Language Models. In most cases, we see improvements, as measured by a range of commonly-used metrics; for the PHP language in the challenging CodeSearchNet dataset, this augmentation actually yields performance surpassing 30 BLEU1. In addition, we have also found that including semantic facts yields a substantial enhancement in LLMs' line completion performance.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {220},
numpages = {13},
keywords = {LLM, code summarization, program analysis, prompt engineering},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3586182.3615817,
author = {Du, Ruofei and Li, Na and Jin, Jing and Carney, Michelle and Yuan, Xiuxiu and Wright, Kristen and Sherwood, Mark and Mayes, Jason and Chen, Lin and Jiang, Jun and Zhou, Jingtao and Zhou, Zhongyi and Yu, Ping and Kowdle, Adarsh and Iyengar, Ram and Olwal, Alex},
title = {Experiencing Visual Blocks for ML: Visual Prototyping of AI Pipelines},
year = {2023},
isbn = {9798400700965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586182.3615817},
doi = {10.1145/3586182.3615817},
abstract = {We demonstrate Visual Blocks for ML, a visual programming platform that facilitates rapid prototyping of ML-based multimedia applications. As the public version of Rapsai&nbsp;[3], we further integrated large language models and custom APIs into the platform. In this demonstration, we will showcase how to build interactive AI pipelines in a few drag-and-drops, how to perform interactive data augmentation, and how to integrate pipelines into Colabs. In addition, we demonstrate a wide range of community-contributed pipelines in Visual Blocks for ML, covering various aspects including interactive graphics, chains of large language models, computer vision, and multi-modal applications. Finally, we encourage students, designers, and ML practitioners to contribute ML pipelines through https://github.com/google/visualblocks/tree/main/pipelines to inspire creative use cases. Visual Blocks for ML is available at http://visualblocks.withgoogle.com.},
booktitle = {Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {76},
numpages = {3},
keywords = {data augmentation, deep learning, deep neural networks, large language models, multi-modal models, node-graph editor, visual analytics, visual programming, visual prototyping},
location = {San Francisco, CA, USA},
series = {UIST '23 Adjunct}
}

@inproceedings{10.1145/3641555.3705025,
author = {Diaz, Marc and Karp, Dustin and Tuli, Prayuj and Kapoor, Amanpreet},
title = {Edugator: An AI-enabled Tool for Creating and Delivering Interactive Computing Content},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705025},
doi = {10.1145/3641555.3705025},
abstract = {Edugator is a browser-based, AI-enabled tool designed to help instructors of introductory computing courses create and deliver interactive educational content. It streamlines the content authoring process by incorporating generative AI models into both the creation and delivery stages. Instructors can create bespoke interactive computing lessons and programming problems by providing a prompt and a few clicks. They can also author templates and test cases in programming languages such as C++, Java, C, and Python. Additionally, instructors can validate programming problems by running them against an auto-generated solution, allowing them to refine the problems before releasing it to students, preventing misinformation or ambiguity. Students can complete lessons and solve programming problems in a browser-based text editor receiving immediate feedback. They can also interact with a large language model-powered AI chatbot that scaffolds a student on how to approach the problem without giving out solutions. Edugator is built using modern web frameworks and the goal of the tool is to accelerate the adoption of automated assessment tools by minimizing the challenges instructors face with such tools. It also supports Learning Tools Interoperability (LTI), allowing seamless integration with learning management systems (LMS). The demo will provide an overview of Edugator's features, including authoring programming problems and lessons using AI or remixing existing problems obtained from test banks, LTI integration, and AI-chatbot. More information about the tool can be found at https://edugator.app/ and https://github.com/edugatorlabs/resources},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1732},
numpages = {1},
keywords = {ai tutor, automated assessment tool, generative ai, introductory programming, learning by doing},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3662006.3662059,
author = {Li, Xiang and Lu, Zhenyan and Cai, Dongqi and Ma, Xiao and Xu, Mengwei},
title = {Large Language Models on Mobile Devices: Measurements, Analysis, and Insights},
year = {2024},
isbn = {9798400706639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662006.3662059},
doi = {10.1145/3662006.3662059},
abstract = {Deploying large language models (LLMs) inference into mobile devices is cost-efficient for companies, and well addresses the privacy concern of users. However, the limited computation capacity and memory constraints of mobile devices hinder their practical deployment. Prior work strives to expand model size for better accuracy performance, while there is a lack of systematic understanding of "small" sub-10 billion LLMs that are already feasible for current commodity devices. To better reveal the current landscape of LLMs on mobile devices, we conducted a comprehensive measurement study, deploying 22 models across 4 mobile devices. Our measurements focus on accuracy, inference latency, and memory footprint across various input lengths, devices, and execution engines. The observations from the measurements point us toward promising directions for efficient LLM deployment on mobile devices.},
booktitle = {Proceedings of the Workshop on Edge and Mobile Foundation Models},
pages = {1–6},
numpages = {6},
keywords = {Large Language Model, Measurement Study, Mobile Devices},
location = {Minato-ku, Tokyo, Japan},
series = {EdgeFM '24}
}

@inproceedings{10.1145/3672539.3686351,
author = {Lu, Qiuyu and Fang, Jiawei and Yao, Zhihao and Yang, Yue and Lyu, Shiqing and Mi, Haipeng and Yao, Lining},
title = {Large Language Model Agents Enabled Generative Design of Fluidic Computation Interfaces},
year = {2024},
isbn = {9798400707186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672539.3686351},
doi = {10.1145/3672539.3686351},
abstract = {The creation of interactive devices is a major area of interest. However, traditional design tools in this field often require a significant learning curve and may not effectively support creative ideation. This study explores the use of fluidic computation interfaces as a case study to examine the potential of enhancing design tools for physical devices with Large Language Model (LLM) agents. With LLM agents, the Generative Design Tool (GDT) can understand the capabilities and limitations of new devices, suggest diverse, insightful, and practical application scenarios, and recommend designs that are technically and contextually appropriate. Additionally, it generates the necessary design parameters for the traditional components of the design tool to visualize results and create files for fabrication.},
booktitle = {Adjunct Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {76},
numpages = {3},
keywords = {Generative Design, Large Language Model, Novel Devices},
location = {Pittsburgh, PA, USA},
series = {UIST Adjunct '24}
}

@inproceedings{10.1145/3589335.3641296,
author = {Todorov, Konstantin and Fafalios, Pavlos and Dietze, Stefan and Dimitrov, Dimitar},
title = {Beyond Facts: 4th International Workshop on Computational Methods for Online Discourse Analysis},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641296},
doi = {10.1145/3589335.3641296},
abstract = {Expressing opinions and interacting with others on the Web has led to the production of an abundance of online discourse data, such as claims and viewpoints on controversial topics, their sources and contexts (events, entities). This data constitutes a valuable source of insights for studies into misinformation spread, bias reinforcement, echo chambers or political agenda setting. Computational methods, mostly from the field of NLP, have emerged that tackle a wide range of tasks in this context, including argument and opinion mining, claim detection, checkworthiness detection, stance detection or fact verification. However, computational models require robust definitions of classes and concepts under investigation. Thus, these computational tasks require a strong interdisciplinary and epistemological foundation, specifically with respect to the underlying definitions of key concepts such as claims, arguments, stances, check-worthiness or veracity. This requires a highly interdisciplinary approach combining expertise from fields such as communication studies, computational linguistics and computer science. As opposed to facts, claims are inherently more complex. Their interpretation strongly depends on the context and a variety of intentional or unintended meanings, where terminology and conceptual understandings strongly diverge across communities. From a computational perspective, in order to address this complexity, the synergy of multiple approaches, coming both from symbolic (knowledge representation) and statistical AI seem to be promising to tackle such challenges. This workshop aims at strengthening the relations between these communities, providing a forum for shared works on the modeling, extraction and analysis of discourse on the Web. It will address the need for a shared understanding and structured knowledge about discourse data in order to enable machine-interpretation, discoverability and reuse, in support of scientific or journalistic studies into the analysis of societal debates on the Web. Beyond research into information and knowledge extraction, data consolidation and modeling for knowledge graphs building, the workshop targets communities focusing on the analysis of online discourse, relying on methods from machine learning, natural language processing, large language models and Web data mining.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1418–1421},
numpages = {4},
keywords = {computational fact-checking, computational journalism, intent detection, knowledge graphs, language models, mis- and dis-information, online discourse analysis, social web mining, stance and viewpoint discovery},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3664646.3676276,
author = {Cai, Jiahao},
title = {Agents for Data Science: From Raw Data to AI-Generated Notebooks using LLMs and Code Execution (Invited Talk)},
year = {2024},
isbn = {9798400706851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664646.3676276},
doi = {10.1145/3664646.3676276},
abstract = {Data science tasks involve a complex interplay of datasets, code and code outputs for answering questions, deriving insights, or building models from data. Tasks and chosen methods may require specialized data domain or scientific domain knowledge. Queries range from high-level (low-code) or highly technical (high-code). Code execution results, such as plots and tables are artifacts used by data scientists to interpret and reason about the current and future states of a solution towards completing the task. This presents unique challenges in designing, deploying and evaluating LLM-based agents for automating data science workflows. In this talk we will introduce an end-to-end, autonomous Data Science Agent (DSA) built around Gemini and available as an experiment at labs.google/code. DSA leverages agentic flows, planning and orchestration to tackle open-ended data science explorations. It uses LLMs for planning, task decomposition, code generation, reasoning and error-correction through code execution. DSA is designed to streamline the entire data science process, enabling users to query data in natural language, and get from a dataset and prompt to a fully AI-generated, populated notebook. We’ll discuss design choices (prompting, SFT, orchestration), iterative development cycles, evaluation, lessons learned and future challenges. Where applicable, we will showcase real-world case studies demonstrating how DSA can assist with bootstrapping the analysis of data from complex scientific domains.},
booktitle = {Proceedings of the 1st ACM International Conference on AI-Powered Software},
pages = {181},
numpages = {1},
location = {Porto de Galinhas, Brazil},
series = {AIware 2024}
}

@inproceedings{10.1145/3706598.3714154,
author = {Zamfirescu-Pereira, J.D. and Jun, Eunice and Terry, Michael and Yang, Qian and Hartmann, Bjoern},
title = {Beyond Code Generation: LLM-supported Exploration of the Program Design Space},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714154},
doi = {10.1145/3706598.3714154},
abstract = {In this work, we explore explicit Large Language Model (LLM)-powered support for the iterative design of computer programs. Program design, like other design activity, is characterized by navigating a space of alternative problem formulations and associated solutions in an iterative fashion. LLMs are potentially powerful tools in helping this exploration; however, by default, code-generation LLMs deliver code that represents a particular point solution. This obscures the larger space of possible alternatives, many of which might be preferable to the LLM’s default interpretation and its generated code. We contribute an IDE that supports program design through generating and showing new ways to frame problems alongside alternative solutions, tracking design decisions, and identifying implicit decisions made by either the programmer or the LLM. In a user study, we find that with our IDE, users combine and parallelize design phases to explore a broader design space—but also struggle to keep up with LLM-originated changes to code and other information overload. These findings suggest a core challenge for future IDEs that support program design through higher-level instructions given to LLM-based agents: carefully managing attention and deciding what information agents should surface to program designers and when.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {153},
numpages = {17},
keywords = {Program design, Code generation, Design space exploration, Generative AI, LLMs},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3670474.3685964,
author = {Nakkab, Andre and Zhang, Sai Qian and Karri, Ramesh and Garg, Siddharth},
title = {Rome was Not Built in a Single Step: Hierarchical Prompting for LLM-based Chip Design},
year = {2024},
isbn = {9798400706998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670474.3685964},
doi = {10.1145/3670474.3685964},
abstract = {Large Language Models (LLMs) are effective in computer hardware synthesis via hardware description language (HDL) generation. However, LLM-assisted approaches for HDL generation struggle when handling complex tasks. We introduce a suite of hierarchical prompting techniques which facilitate efficient stepwise design methods, and develop a generalizable automation pipeline for the process. To evaluate these techniques, we present a benchmark set of hardware designs which have solutions with or without architectural hierarchy. Using these benchmarks, we compare various open-source and proprietary LLMs, including our own fine-tuned Code Llama-Verilog model. Our hierarchical methods automatically produce successful designs for complex hardware modules that standard flat prompting methods cannot achieve, allowing smaller open-source LLMs to compete with large proprietary models. Hierarchical prompting reduces HDL generation time and yields savings on LLM costs. Our experiments detail which LLMs are capable of which applications, and how to apply hierarchical methods in various modes. We explore case studies of generating complex cores using automatic scripted hierarchical prompts, including the first-ever LLM-designed processor with no human feedback.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD},
articleno = {26},
numpages = {11},
keywords = {Automation, Hardware design, Hierarchy, LLM},
location = {Salt Lake City, UT, USA},
series = {MLCAD '24}
}

@inproceedings{10.1145/3626253.3633431,
author = {Shaffer, Cliff and Brusilovsky, Peter and Koedinger, Ken and Price, Thomas and Barnes, Tiffany and Mostafavi, Behrooz},
title = {Ninth SPLICE Workshop on Technology and Data Infrastructure for CS Education Research},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633431},
doi = {10.1145/3626253.3633431},
abstract = {Many SIGCSE attendees are either developing or using online educational tools, and all will benefit from better interoperability among these tools and better analysis of the clickstream data coming from those tools. New tools for analyzing big data leveraged by AI (e.g., deep learning for assessment) in turn improve both content and pedagogy, thus setting up a virtuous cycle fueling learning discoveries and leveraging innovation in AI: Online technologies → big data analysis → better online technologies. This NSF-supported workshop is the latest in a series of SPLICE workshops, and is a continuation of our event at SIGCSE 2023, where the SPLICE-Portal, a dedicated socio-technical research infrastructure for Computing Education Research, was presented. This year, we continue the work with several new SPLICE community working groups, including those on Dashboards, Large Language Models, Parsons Problems, and Smart Learning Content Protocols. We continue to build upon our existing collaborations developed over the course of the project to engage more members of the community in tasks that will advance the project agenda.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1904},
numpages = {1},
keywords = {collaborative tools, computing education research, online technologies},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3702038.3702046,
author = {Borges, Jonathan Martins and Ara\'{u}jo, Rafael Dias},
title = {Experiences and challenges of a redesign process with the support of an AI assistant on an educational platform},
year = {2024},
isbn = {9798400712241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702038.3702046},
doi = {10.1145/3702038.3702046},
abstract = {Artificial Intelligence (AI) has contributed to the advancement of many knowledge areas. In particular, Large Language Models (LLMs) has become a trending topic and its application has been studied in different contexts, including human-computer interaction (HCI) and interface design research. Interaction design (IxD) and interface design (UI) benefit from these technologies, in which some tasks can be automated with new tools for creating more efficient interfaces. This experience report explores the integration of AI in the redesign process of the educational platform Classroom eXperience (CX), utilizing models such as GPT-4 and Gemini 1.5. The study shows that AI can complement the work of designers, providing precise analyses and suggestions to improve usability and user experience, although human supervision remains essential to validate and implement these improvements.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {8},
numpages = {12},
keywords = {User Interface, Interface Design, LLM, Online Learning Environment},
location = {
},
series = {IHC '24}
}

@inproceedings{10.1145/3701716.3715453,
author = {Shi, Haonan and Ouyang, Tu and Wang, An},
title = {Navigating the Designs of Privacy-Preserving Fine-tuning for Large Language Models},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715453},
doi = {10.1145/3701716.3715453},
abstract = {Instruction tuning has proven effective in enhancing Large Language Models' (LLMs) performance on downstream tasks. However, real-world fine-tuning faces inherent conflicts between model providers' intellectual property protection, clients' data privacy requirements, and tuning costs. While recent approaches like split learning and offsite tuning demonstrate promising architectures for privacy-preserving fine-tuning, there is a gap in systematically addressing the multidimensional trade-offs required for diverse real-world deployments. We propose several indicative evaluation metrics to guide design trade-offs for privacy-preserving fine-tuning and a series of example designs, collectively named GuardedTuning; they result from novel combinations of system architectures with adapted privacy-enhancement methods and emerging computation techniques. Each design represents distinct trade-offs across model utility, privacy guarantees, and costs. Experimental results demonstrate that these designs protect against data reconstruction attacks while maintaining competitive fine-tuning performance.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1298–1302},
numpages = {5},
keywords = {data reconstruction attack, large language models, split learning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3676536.3676753,
author = {Chen, Lvcheng and Wu, Ying and Wen, Chenyi and Wang, Shizhang and Zhang, Li and Yu, Bei and Sun, Qi and Zhuo, Cheng},
title = {An Agile Framework for Efficient LLM Accelerator Development and Model Inference},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676753},
doi = {10.1145/3676536.3676753},
abstract = {Large Language Models (LLMs) have revolutionized many domains with exceptional performance while their large sizes hinder their broad applicability, especially in the edge computation scenarios. Designing large-scale LLM-specific accelerators is also challenging, suffering from the complicated, cumbersome, and time-consuming design, simulation, and optimization process. This paper meticulously proposes an agile framework for accelerator development, supporting efficient LLM inference. Firstly, we investigate the architecture of LLMs, uncover performance bottlenecks, and design an optimized binarized accelerator and a configurable RISC-V-based SoC to boost the inference of binary LLMs. Further, a novel fidelity-driven method is proposed to learn the multi-fidelity representation, solving the modeling and accuracy issues due to the lack of accurate later-stage data in the EDA flow, by capturing complex relationships among simulation metrics in and across different fidelities. Tailored strategies across model preparation, backend kernel implementations, agile accelerator and SoC design, and inference simulation are incorporated into our framework to refine the development workflow. Our method significantly accelerates the hardware design, simulation, and optimization processes. Experimental results illustrate the impressive speed and effectiveness of our framework in designing edge LLM accelerators and optimizing LLM inference.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {200},
numpages = {9},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3613904.3642229,
author = {Chen, Liuqing and Xiao, Shuhong and Chen, Yunnong and Song, Yaxuan and Wu, Ruoyu and Sun, Lingyun},
title = {ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642229},
doi = {10.1145/3613904.3642229},
abstract = {As Computational Thinking (CT) continues to permeate younger age groups in K-12 education, established CT platforms such as Scratch face challenges in catering to these younger learners, particularly those in the elementary school (ages 6-12). Through formative investigation with Scratch experts, we uncover three key obstacles to children’s autonomous Scratch learning: artist’s block in project planning, bounded creativity in asset creation, and inadequate coding guidance during implementation. To address these barriers, we introduce ChatScratch, an AI-augmented system to facilitate autonomous programming learning for young children. ChatScratch employs structured interactive storyboards and visual cues to overcome artist’s block, integrates digital drawing and advanced image generation technologies to elevate creativity, and leverages Scratch-specialized Large Language Models (LLMs) for professional coding guidance. Our study shows that, compared to Scratch, ChatScratch efficiently fosters autonomous programming learning, and contributes to the creation of high-quality, personally meaningful Scratch projects for children.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {649},
numpages = {19},
keywords = {Children Aged 6-12, Computational Thinking, Large Language Model, Scratch},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3702634.3702950,
author = {Wang, Li and Jiang, Yankai and Mi, Ningfang},
title = {Advancing Serverless Computing for Scalable AI Model Inference: Challenges and Opportunities},
year = {2024},
isbn = {9798400713361},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702634.3702950},
doi = {10.1145/3702634.3702950},
abstract = {Artificial Intelligence (AI) model inference has emerged as a crucial component across numerous applications. Serverless computing, known for its scalability, flexibility, and cost-efficiency, is an ideal paradigm for executing AI model inference tasks. This survey provides a comprehensive review of recent research on AI model inference systems in serverless environments, focusing on studies published since 2019. We investigate system-level advancements aimed at optimizing performance and cost-efficiency through a range of innovative techniques. By analyzing high-impact papers from leading venues in AI model inference and serverless computing, we highlight key breakthroughs and solutions. This survey serves as a valuable resource for both practitioners and academic researchers, offering critical insights into the current state and future trends in integrating AI model inference with serverless architectures. To the best of our knowledge, this is the first survey that includes Large Language Models (LLMs) inference in the context of serverless computing.},
booktitle = {Proceedings of the 10th International Workshop on Serverless Computing},
pages = {1–6},
numpages = {6},
keywords = {serverless computing, LLMs inference, DL inference, ML inference},
location = {Hong Kong, Hong Kong},
series = {WoSC10 '24}
}

@inproceedings{10.1145/3626252.3630880,
author = {Sheard, Judy and Denny, Paul and Hellas, Arto and Leinonen, Juho and Malmi, Lauri and Simon},
title = {Instructor Perceptions of AI Code Generation Tools - A Multi-Institutional Interview Study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630880},
doi = {10.1145/3626252.3630880},
abstract = {Much of the recent work investigating large language models and AI Code Generation tools in computing education has focused on assessing their capabilities for solving typical programming problems and for generating resources such as code explanations and exercises. If progress is to be made toward the inevitable lasting pedagogical change, there is a need for research that explores the instructor voice, seeking to understand how instructors with a range of experiences plan to adapt. In this paper, we report the results of an interview study involving 12 instructors from Australia, Finland and New Zealand, in which we investigate educators' current practices, concerns, and planned adaptations relating to these tools. Through this empirical study, our goal is to prompt dialogue between researchers and educators to inform new pedagogical strategies in response to the rapidly evolving landscape of AI code generation tools.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1223–1229},
numpages = {7},
keywords = {ai code generation, generative ai, instructor perceptions, interview study, large language models, llms, programming education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3613905.3650764,
author = {Englhardt, Zachary and Li, Richard and Nissanka, Dilini and Zhang, Zhihan and Narayanswamy, Girish and Breda, Joseph and Liu, Xin and Patel, Shwetak and Iyer, Vikram},
title = {Exploring and Characterizing Large Language Models for Embedded System Development and Debugging},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650764},
doi = {10.1145/3613905.3650764},
abstract = {Large language models (LLMs) have shown remarkable abilities to generate code. However, their ability to develop software for physical computing and embedded systems, which requires cross-domain hardware and software knowledge, has not been thoroughly studied. We observe through our experiments and a 15-user pilot study that even when LLMs fail to produce working code, they can generate helpful reasoning about embedded design tasks, as well as specific debugging suggestions for both novice and expert developers. These results highlight the potential to develop AI assistants to dramatically lower the barrier to entry for working with hardware. To evaluate the capabilities and limitations of LLMs, we develop an automated testbench to quantify LLM performance on embedded programming tasks and perform 450 trials. We leverage these findings to analyze how programmers interact with these tools including their productivity and sense of fulfillment and outline a human-AI collaborative workflow for developing and debugging embedded systems.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {150},
numpages = {9},
keywords = {Embedded Systems Development, GPT, Large Language Models},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3702163.3702432,
author = {Zhang, Mengchen and Feng, Xiang},
title = {Automated Annotation of Academic Emotion Intensity in Online Learning Comment Texts: A BWS Method Based on LLMs},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702432},
doi = {10.1145/3702163.3702432},
abstract = {Academic emotions significantly impact learning processes and student performance, with a recent trend towards automated measurement for their types and intensity. However, manual annotation methods for large-scale training data required by modeling face issues of time consumption and high cost. The Best Worst Scaling (BWS) methodology enhances the reliability of intensity annotation, while Large Language Models (LLMs) offer advantages in understanding academic emotions across diverse contexts. Combining the BWS and LLMs in academic emotion intensity annotation, this study aims to address the challenge of data annotation in measuring academic emotion intensity in online learning. We choose three widely recognized LLMs to complete the BWS annotation tasks separately, then calculate the consistency and conduct statistical analysis. Results indicate that the consistency of the three LLMS in identifying emotion intensity in nine academic emotions was above 0.750, with a total of 0.865 in 4569 comment texts. The perception of emotion intensity by the LLMs closely resembles that of human cognition and responds to the context of online learning, enabling them to effectively substitute for humans in performing large-scale annotation tasks.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {317–323},
numpages = {7},
keywords = {Academic Emotion Intensity, Automated Annotation, Best Worst Scaling (BWS), Online Learning},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3613904.3641965,
author = {Calle, Paul and Shao, Ruosi and Liu, Yunlong and H\'{e}bert, Emily T and Kendzor, Darla and Neil, Jordan and Businelle, Michael and Pan, Chongle},
title = {Towards AI-Driven Healthcare: Systematic Optimization, Linguistic Analysis, and Clinicians’ Evaluation of Large Language Models for Smoking Cessation Interventions},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641965},
doi = {10.1145/3613904.3641965},
abstract = {Creating intervention messages for smoking cessation is a labor-intensive process. Advances in Large Language Models (LLMs) offer a promising alternative for automated message generation. Two critical questions remain: 1) How to optimize LLMs to mimic human expert writing, and 2) Do LLM-generated messages meet clinical standards? We systematically examined the message generation and evaluation processes through three studies investigating prompt engineering (Study 1), decoding optimization (Study 2), and expert review (Study 3). We employed computational linguistic analysis in LLM assessment and established a comprehensive evaluation framework, incorporating automated metrics, linguistic attributes, and expert evaluations. Certified tobacco treatment specialists assessed the quality, accuracy, credibility, and persuasiveness of LLM-generated messages, using expert-written messages as the benchmark. Results indicate that larger LLMs, including ChatGPT, OPT-13B, and OPT-30B, can effectively emulate expert writing to generate well-written, accurate, and persuasive messages, thereby demonstrating the capability of LLMs in augmenting clinical practices of smoking cessation interventions.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {436},
numpages = {16},
keywords = {Computational Linguistic Analysis, Expert Review, Large Language Model, Message Generation, Smoking Cessation Intervention},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3691620.3695503,
author = {Huang, Junjie and Guo, Daya and Wang, Chenglong and Gu, Jiazhen and Lu, Shuai and Inala, Jeevana Priya and Yan, Cong and Gao, Jianfeng and Duan, Nan and Lyu, Michael R.},
title = {Contextualized Data-Wrangling Code Generation in Computational Notebooks},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695503},
doi = {10.1145/3691620.3695503},
abstract = {Data wrangling, the process of preparing raw data for further analysis in computational notebooks, is a crucial yet time-consuming step in data science. Code generation has the potential to automate the data wrangling process to reduce analysts' overhead by translating user intents into executable code. Precisely generating data wrangling code necessitates a comprehensive consideration of the rich context present in notebooks, including textual context, code context and data context. However, notebooks often interleave multiple non-linear analysis tasks into linear sequence of code blocks, where the contextual dependencies are not clearly reflected. Directly training models with source code blocks fails to fully exploit the contexts for accurate wrangling code generation.To bridge the gap, we aim to construct a high quality datasets with clear and rich contexts to help training models for data wrangling code generation tasks. In this work, we first propose an automated approach, CoCoMine to mine data-wrangling code generation examples with clear multi-modal contextual dependency. It first adopts data flow analysis to identify the code blocks containing data wrangling codes. Then, CoCoMine extracts the contextualized data-wrangling code examples through tracing and replaying notebooks. With CoCoMine, we construct CoCoNote, a dataset containing 58,221 examples for Contextualized Data-wrangling Code generation in Notebooks. To demonstrate the effectiveness of our dataset, we finetune a range of pretrained code models and prompt various large language models on our task. Furthermore, we also propose Data-Coder, which encodes data context and code&amp;textual contexts separately to enhance code generation. Experiment results demonstrate the significance of incorporating data context in data-wrangling code generation and the effectiveness of our model. We release code and data at https://github.com/Jun-jie-Huang/CoCoNote.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1282–1294},
numpages = {13},
keywords = {code generation, data wrangling, computational notebooks, large language models},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@article{10.1145/3709154,
author = {Tariq, Amara and Trivedi, Shubham and Urooj, Aisha and Ramasamy, Gokul and Fathizadeh, Sam and Stib, Matthew and Tan, Nelly and Patel, Bhavik and Banerjee, Imon},
title = {Patient-centric Summarization of Radiology Findings Using Two-step Training of Large Language Models},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
url = {https://doi.org/10.1145/3709154},
doi = {10.1145/3709154},
abstract = {Education-level or socioeconomic background of patients may dictate their ability to understand medical jargon. Inability to understand primary findings from a radiology report may lead to unnecessary anxiety among patients or missed follow up. We aim to meet this challenge by developing a patient-sensitive summarization model for radiology reports. We selected computed tomography (CT) exams of chest as a use-case and collected 7,000 studies from Mayo Clinic. Summarization model was built on top of the T5 large language model (LLM) as our experiments indicated that its text-to-text transfer architecture was suited for abstractive text summarization, resulting in a model with 0.77B trainable parameters. Noisy ground truth for model training was collected by prompting LLaMA-13B model. We recruited experts (board-certified radiologists) and laymen to manually evaluate model-generated summaries generated by model. Our model rarely missed information as marked by majority opinion of radiologists. Laymen indicated 63% improvement in their understanding by reading model-generated layman summaries. Comparison with zero-shot performance of ChatGPT indicated that the proposed model reduced the rate of hallucination by half and rate of missing important information by fivefold. The proposed model can generate reliable summaries for radiology reports understandable by patients with vastly different levels of medical knowledge.},
journal = {ACM Trans. Comput. Healthcare},
month = apr,
articleno = {21},
numpages = {15},
keywords = {large language models, domain-specific training, chest computed tomography}
}

@inproceedings{10.1145/3708635.3708655,
author = {Yu, Hong Qing and Sutton, Jack and O'Neill, Sam and Reiff-Marganiec, Stephan},
title = {Case Studies on LLM Centric and Services Oriented Data Analytics Agent Development},
year = {2025},
isbn = {9798400717765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708635.3708655},
doi = {10.1145/3708635.3708655},
abstract = {This paper presents a novel service orchestration framework for a chatbot application focused on data analytics questions. The framework integrates Large Language Models (LLMs) with service-oriented computing to transform data analytics into a dynamic, conversational experience. The approach leverages advancements in LLM technology to enable real-time, automated data insights via chatbot interfaces, making complex data analytics accessible across various industries. In addition, the data will be processed and analysis at edge-machine rather than post all the data directly to the LLMs on the cloud. Therefore, the Central to the framework is the local Micro Analytics Service (MAS) and a dynamic service-data coordination framework, which together facilitate the decoupling of data from business logic, allowing for intuitive engagement with analytics processes. Through two case studies, retail data analysis and regional healthcare planning, the ability of the framework to provide actionable insights through natural language prompts is demonstrated, showcasing its potential to significantly reduce barriers to sophisticated data analytics. The evaluation reveals strong performance in data connection and code generation, with identified areas for improvement in visualizations and handling complex data scenarios.},
booktitle = {Proceedings of the 2024 13th International Conference on Software and Information Engineering},
pages = {69–76},
numpages = {8},
keywords = {LLM-driven service orchestration, Dynamic data analytics services, Services Computing},
location = {
},
series = {ICSIE '24}
}

@inproceedings{10.1145/3674399.3674426,
author = {Dong, Dong and Liang, Yue},
title = {Grading Programming Assignments by Summarization},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674399.3674426},
doi = {10.1145/3674399.3674426},
abstract = {Grading programming assignments manually is a big burden for instructors who teach programming languages for university students due to complexity and subjectivity. The black test approach adopted by online judge systems can only outputs either an answer is correct or incorrect. This study proposes a Large Language Model (LLM) approach to automatically grade answers from students for programming assignments. A LLM mode formed by coder-decoder architecture is utilized to generate summarization from source code, then the summarization is compared to the textual assignment description by semantic similarity. Finally, the output is converted to five-score rating. CodeBERT and a Transformer model serve as coder and decoder respectively. The semantic similarity is computed by MiniLM-L6. The validation test shows that the accuracy of the suggested approach reaches 0.92.},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2024},
pages = {53–58},
numpages = {6},
keywords = {CodeBERT, automatic grading, programming assignment assessment, source code summarization},
location = {Changsha, China},
series = {ACM-TURC '24}
}

@inproceedings{10.1145/3600100.3626262,
author = {Berger, Markus and Ploennigs, Joern},
title = {ArchiGuesser – Teaching Architecture Styles using Generative AI},
year = {2023},
isbn = {9798400702303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600100.3626262},
doi = {10.1145/3600100.3626262},
abstract = {Generative AIs are opening new possibilities to create content from text, speech, and images based on simple input prompts. Users use this to improve their productivity when summarizing knowledge, templating communication, and inspiring their creativity. But, can it also be used to teach, e.g. about our architectural history? With this demo we are exploring this question. We created an educational game that combines various AI technologies from large language models and image generation to computer vision, in order to serve a single purpose: Teach users about architecture in an entertaining way. We wanted to enable students to explore and learn the diversity of our architectural history in a playful and exploratory way and at the same time experience and understand what current AI technologies can achieve.},
booktitle = {Proceedings of the 10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {284–285},
numpages = {2},
location = {Istanbul, Turkey},
series = {BuildSys '23}
}

@inproceedings{10.1145/3706599.3719821,
author = {Liu, Jiaying "Lizzy" and Su, Yiheng and Seth, Praneel},
title = {Can Large Language Models Grasp Abstract Visual Concepts in Videos? A Case Study on YouTube Shorts about Depression},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719821},
doi = {10.1145/3706599.3719821},
abstract = {Large language models (LLMs) are increasingly used to assist computational social science research. While prior efforts have focused on text, the potential of leveraging multimodal LLMs (MLLMs) for online video studies remains underexplored. We conduct one of the first case studies on MLLM-assisted video content analysis, comparing AI’s interpretations to human understanding of abstract concepts. We leverage LLaVA-1.6 Mistral 7B to interpret four abstract concepts regarding video-mediated self-disclosure, analyzing 725 keyframes from 142 depression-related YouTube short videos. We perform a qualitative analysis of MLLM’s self-generated explanations and found that the degree of operationalization can influence MLLM’s interpretations. Interestingly, greater detail does not necessarily increase human-AI alignment. We also identify other factors affecting AI alignment with human understanding, such as concept complexity and versatility of video genres. Our exploratory study highlights the need to customize prompts for specific concepts and calls for researchers to incorporate more human-centered evaluations when working with AI systems in a multimodal context.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {127},
numpages = {11},
keywords = {Computational Social Science, Video-Mediated Communication, Multimodal Information, Human-AI Alignment, User-Generated Content, Large Language-and-Vision Assistant (LLaVA), Content Analysis, Mental Health},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.5555/3709347.3743565,
author = {Chopra, Ayush and Kumar, Shashank and Kuru, Nurullah Giray and Raskar, Ramesh and Quera-Bofarull, Arnau},
title = {On the Limits of Agency in Agent-based Models},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Agent-based modeling (ABM) offers powerful insights into complex systems, but its practical utility has been limited by computational constraints and simplistic agent behaviors, especially when simulating large populations. Recent advancements in large language models (LLMs) could enhance ABMs with adaptive agents, but their integration into large-scale simulations remains challenging. This work introduces a novel methodology that bridges this gap by efficiently integrating LLMs into ABMs, enabling the simulation of millions of adaptive agents. We present LLM archetypes, a technique that balances behavioral complexity with computational efficiency, allowing for nuanced agent behavior in large-scale simulations. Our analysis explores the crucial trade-off between simulation scale and individual agent expressiveness, comparing different agent architectures ranging from simple heuristic-based agents to fully adaptive LLM-powered agents. We demonstrate the real-world applicability of our approach through a case study of the COVID-19 pandemic, simulating 8.4 million agents representing New York City and capturing the intricate interplay between health behaviors and economic outcomes. Our method significantly enhances ABM capabilities for predictive and counterfactual analyses, addressing limitations of historical data in policy design. By implementing these advances in an open-source framework, we facilitate the adoption of LLM archetypes across diverse ABM applications. Our results show that LLM archetypes can markedly improve the realism and utility of large-scale ABMs while maintaining computational feasibility, opening new avenues for modeling complex societal challenges and informing data-driven policy decisions.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {500–509},
numpages = {10},
keywords = {agent-based simulations, differentiable abms, generative agents, llm as abm agents},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3670865.3673513,
author = {Filippas, Apostolos and Horton, John J. and Manning, Benjamin S.},
title = {Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?},
year = {2024},
isbn = {9798400707049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670865.3673513},
doi = {10.1145/3670865.3673513},
abstract = {Large language models---because of how they are trained and designed---are implicit computational models of humans---a homo silicus. Social scientists can use LLMs like economists use homo economicus: LLMs can be given endowments, information, preferences, and so on, and then their behavior can be explored in scenarios via simulation. We replicate four experiments using this approach and find qualitatively similar results to the original. Benefits of this approach include trying new variations for fresh insights, piloting studies via simulation, and searching for novel social science insights to test in the real world. The full version of the paper can be accessed at https://apostolos-filippas.com/papers/hs.pdf.},
booktitle = {Proceedings of the 25th ACM Conference on Economics and Computation},
pages = {614–615},
numpages = {2},
keywords = {artificial intelligence, experimentation, simulation and modelling},
location = {New Haven, CT, USA},
series = {EC '24}
}

@proceedings{10.1145/3637528,
title = {KDD '24: Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our pleasure to welcome you to the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining---KDD'2024 in Barcelona, Catalonia. This year's conference continues its tradition of being the premier forum for presentation of research results and experience reports on knowledge discovery, data science, and machine learning. The mission of the conference is to provide the best venue for advancement, education, and adoption of the "science" of knowledge discovery and machine learning from all types of data; to share novel methodologies that fulfill the needs of heterogeneous applications and environments and identify new directions for future research and development. These ideas have the potential to shape and impact our society and environment, becoming particularly important with the emergence of AI in all fields. So, KDD provides researchers and practitioners a unique opportunity to share their perspectives with others interested in various aspects of data science and machine learning.KDD'24 has a program of three keynotes (Sanjeev Arora, Tanya Berger-Wolf and Xihong Lin), one panel on generative AI, 411 research track papers, 151 applied data science (ADS) track papers and eight invited talks, 30 workshops, 34 tutorials (nine of them hands-on), nine special days (one online for India), and three KDD cups. We have introduced two new special days, one in Responsible AI and another in European Data Science given the location of the conference. We also added one extra poster session to have more time for posters presentations. For second time we used Openreview for the research and ADS tracks with the goal to further improve the review quality and facilitate the interaction between reviewers and authors. We hope that you will find this program interesting and thought-provoking and that the conference will provide you with a valuable opportunity to share ideas with other researchers and practitioners from institutions around the world.},
location = {Barcelona, Spain}
}

@inproceedings{10.1145/3633083.3633099,
author = {Stone, Irene},
title = {Exploring the Research Gap: Generative AI and Learning of Python Programming among Post-Primary Students},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633099},
doi = {10.1145/3633083.3633099},
abstract = {The introduction of Leaving Certificate Computer Science (LCCS) in Ireland in 2018 signifies a notable advancement in post-primary education. Moreover, developments in generative Artificial Intelligence (GAI) in education, are gaining prominence, yet we do not understand its value or how best to implement it in post-primary educational settings. Despite a growing international body of research in this area, my scoping review highlights that many aspects of these topics have yet to be explored, particularly in the context of post-primary students in Ireland. My study will begin to bridge this gap by exploring how a purposeful sample of LCCS post-primary students in Ireland engage with GAI tools, such as ChatGPT, during their initial experiences learning Python programming. These findings, when approached through the lens of Human-Centred Artificial Intelligence (HCAI), can help enhance pedagogical strategies and lead to improved learning experiences for students.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {51},
numpages = {1},
location = {Dublin, Ireland},
series = {HCAIep '23}
}

@inproceedings{10.1145/3704289.3704293,
author = {Duah, James Ewert and Lu, Xin and McGivern, Paul and Jing, Yanguo},
title = {Interdisciplinary Perspectives on Generative Artificial Intelligence Adoption in Higher Education: A Theoretical Framework Review},
year = {2025},
isbn = {9798400716980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704289.3704293},
doi = {10.1145/3704289.3704293},
abstract = {The ongoing integration of Generative Artificial Intelligence (GenAI) within higher education (HE) signifies a pivotal shift in pedagogical paradigms, demanding comprehensive theoretical and practical considerations. This paper critically examines the multifaceted adoption of GenAI in HE by reviewing interdisciplinary theoretical frameworks from psychology, computer science, and pedagogy. It highlights the insufficiency of traditional technology acceptance models, which predominantly address cognitive and rational decision-making processes, and advocates for the inclusion of emotional and ethical dimensions often overlooked in existing frameworks. By synthesizing research across various disciplines, this review identifies significant gaps and proposes an integrated theoretical model to effectively understand and guide GenAI adoption. The proposed framework emphasizes the need for robust, empirically supported methodologies that accommodate the complex, dynamic nature of GenAI applications. This paper not only contributes to academic discourse by providing a comprehensive review of existing literature but also sets a foundation for future empirical studies aimed at refining GenAI integration strategies in HE, ensuring they are ethically aligned and educationally effective.},
booktitle = {Proceedings of the 2024 7th International Conference on Big Data and Education},
pages = {1–9},
numpages = {9},
keywords = {GenAI, Higher Education, Psychology, Theoretical Frameworks},
location = {
},
series = {ICBDE '24}
}

@inproceedings{10.5555/3721488.3721724,
author = {Rosenberg-Kima, Rinat B. and Buchem, Ilona},
title = {Understanding Technology Acceptance of Social Robots as Conversational Interfaces for LLMs},
year = {2025},
publisher = {IEEE Press},
abstract = {Advancements in large language models (LLMs) have transformed human-computer interaction, enhancing engagement with conversational agents like chatbots, virtual agents, and social robots. This study explored how different conversational interfaces (computer, Furhat, NAO, and Pepper) impact perception and acceptance using the Human-Robot Interaction Evaluation Scale (HRIES) and the Technology Acceptance Model (TAM). One hundred participants rated interfaces through a video-based survey, revealing significant differences: computers scored highest in Perceived Usefulness (PU) and Ease of Use (PEU), while social robots, particularly Pepper and NAO, excelled in Sociability. A Structural Equation Model (SEM) indicated that HRIES dimensions of Sociability and Agency positively influenced Perceived Enjoyment (PENJ) and PEU, whereas Disturbance negatively affected both. These findings highlight the nuanced interplay between interface design and user acceptance, suggesting that while factors like Sociability and Agency are pivotal for enhancing enjoyment and ease of use, they alone are insufficient to account for overall acceptance.},
booktitle = {Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1583–1587},
numpages = {5},
keywords = {conversational robots in education, genai, human-robot interaction, technology acceptance model},
location = {Melbourne, Australia},
series = {HRI '25}
}

@inproceedings{10.1145/3706598.3713274,
author = {Zheng, Chanjin and Yu, Zengyi and Jiang, Yilin and Zhang, Mingzi and Lu, Xunuo and Jin, Jing and Gao, Liteng},
title = {ArtMentor: AI-Assisted Evaluation of Artworks to Explore Multimodal Large Language Models Capabilities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713274},
doi = {10.1145/3706598.3713274},
abstract = {Can Multimodal Large Language Models (MLLMs), with capabilities in perception, recognition, understanding, and reasoning, act as independent assistants in art evaluation dialogues? Current MLLM evaluation methods, reliant on subjective human scoring or costly interviews, lack comprehensive scenario coverage. This paper proposes a process-oriented Human-Computer Interaction (HCI) space design for more accurate MLLM assessment and development. This approach aids teachers in efficient art evaluation and records interactions for MLLM capability assessment. We introduce ArtMentor, a comprehensive space integrating a dataset and three systems for optimized MLLM evaluation. It includes 380 sessions from five art teachers across nine critical dimensions. The modular system features entity recognition, review generation, and suggestion generation agents, enabling iterative upgrades. Machine learning and natural language processing ensure reliable evaluations. Results confirm GPT-4o’s effectiveness in assisting teachers in art evaluation dialogues. Our contributions are available at https://artmentor.github.io/.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {659},
numpages = {18},
keywords = {AI-Assisted Artwork Evaluation, GPT-4o, Multimodal Large Language Models, Human-Computer Interaction Dataset Design, Entity Recognition, Multi-Agent for Iterative Upgrades.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3701571.3701582,
author = {de Jong, Sander and Wester, Joel and Schrills, Tim and S. Secher, Kristina and F. Griggio, Carla and van Berkel, Niels},
title = {Assessing Cognitive and Social Awareness among Group Members in AI-assisted Collaboration},
year = {2024},
isbn = {9798400712838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701571.3701582},
doi = {10.1145/3701571.3701582},
abstract = {Successful collaboration in computer-mediated teams requires awareness among group members of each other’s knowledge, skills, and goals. Large Language Models (LLMs) can play a mediating role in establishing and maintaining this awareness among group members. In an in-situ study, we explored the impact of an LLM-based chatbot on cognitive and social group awareness through a distributed text-based group task. We instructed participants (N = 48) to complete a travel-planning task in sixteen groups of three, with each member given conflicting goals. Each chat was complemented by a chatbot that could be asked for assistance. Through a survey and semi-structured interview, we gained insight into participants’ deliberations on the task and the chatbot’s role. We found that the chatbot’s presence helped increase group awareness as users are forced to clearly and transparently formulate their intentions when prompting the chatbot. The chatbot’s ability to provide suggestions that compromise between user goals based on the chat history helped participants reach a consensus. We present implications for the design of chatbots for collaborative settings.},
booktitle = {Proceedings of the International Conference on Mobile and Ubiquitous Multimedia},
pages = {338–350},
numpages = {13},
keywords = {human-AI teams, artificial intelligence, Large Language Models, collaboration, group awareness},
location = {
},
series = {MUM '24}
}

@article{10.1145/3726831.3726833,
author = {Ognyanova, Katherine and Weber, Matthew},
title = {ACM Web Science Conference: Reflecting the Web, AI, and Society},
year = {2025},
issue_date = {Winter 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2025},
number = {Winter},
issn = {1931-1745},
url = {https://doi.org/10.1145/3726831.3726833},
doi = {10.1145/3726831.3726833},
abstract = {The ACM Web Science conference (WebSci) is an annual interdisciplinary event exploring the complex relationships between the Web and our society. Through quantitative, qualitative, and computational approaches, Web Science examines research questions at the intersection of social science and computer science. The conference features research that develops and employs cutting-edge methods to study online behavior. WebSci'25 will take place May 21--25 in New Brunswick, NJ, USA hosted by Rutgers University's School of Communication &amp; Information. The main theme of the conference is "Maintaining a Human-Centric Web in the Era of Generative AI". Proceedings will be published by ACM.},
journal = {SIGWEB Newsl.},
month = apr,
articleno = {2},
numpages = {2}
}

@inproceedings{10.1145/3701625.3701681,
author = {Menolli, Andr\'{e} and Strik, Bruno and Rodrigues, Luiz},
title = {Teaching Refactoring to Improve Code Quality with ChatGPT: An Experience Report in Undergraduate Lessons},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701681},
doi = {10.1145/3701625.3701681},
abstract = {Refactoring presents a complex computational challenge, and its learning is intricate, requiring a solid foundation in computational thinking, programming and object-oriented concepts. Moreover, making students realize the importance and benefits of refactoring is also challenging. To address this complexity, we introduce a refactoring teaching method based on Generative Artificial Intelligence (GAI), incorporating single-loop and double-loop learning principles, focusing on fostering deeper and critical learning. We used ChatGPT, a GAI-based tool, and conducted an eight-week mixed-methods study involving 23 computer science undergraduate students. The study involved applying four distinct projects extracted from GitHub, where participants were tasked with identifying code smells and performing the necessary refactoring to improve code quality. The primary focus was on identifying both the positive and negative aspects of the method, as well as delineating the computational thinking characteristics developed during the process. The results indicate that the use of ChatGPT facilitated the learning of refactoring, contributing to the development of numerous computational thinking skills, especially problem formulation, decomposition, and abstraction. Thus, this paper contributes a GAI-based teaching method along with evidence on how it helps students develop refactoring skills.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {563–574},
numpages = {12},
keywords = {Generative Artificial Intelligence, ChatGPT, Refactory, Higher Education, Teaching, Computational Thinking},
location = {
},
series = {SBQS '24}
}

@article{10.1145/3728636,
author = {Kim, Gun Il and Hwang, Sunga and Jang, Beakcheol},
title = {Efficient Compressing and Tuning Methods for Large Language Models: A Systematic Literature Review},
year = {2025},
issue_date = {October 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {10},
issn = {0360-0300},
url = {https://doi.org/10.1145/3728636},
doi = {10.1145/3728636},
abstract = {Efficient compression and tuning techniques have become indispensable in addressing the increasing computational and memory demands of large language models (LLMs). While these models have demonstrated exceptional performance across a wide range of natural language processing tasks, their growing size and resource requirements pose significant challenges to accessibility and sustainability. This survey systematically reviews state-of-the-art methods in model compression, including compression techniques such as knowledge distillation, low-rank approximation, parameter pruning, and quantization, as well as tuning techniques such as parameter-efficient fine-tuning and inference optimization. Compression techniques, though well-established in traditional deep learning, require updated methodologies tailored to the scale and dynamics of LLMs. Simultaneously, parameter-efficient fine-tuning, exemplified by techniques like Low-Rank Adaptation (LoRA) and query tuning, emerges as a promising solution for adapting models with minimal resource overhead. This study provides a detailed taxonomy of these methods, examining their practical applications, strengths, and limitations. Critical gaps are identified in scalability, and the integration of compression and tuning strategies, signaling the need for unified frameworks and hybrid approaches to maximize efficiency and performance. By addressing these challenges, this survey aims at guiding researchers toward sustainable, efficient, and accessible LLM development, ensuring their broader applicability across diverse domains while mitigating resource constraints.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {253},
numpages = {39},
keywords = {Large language models, knowledge distillation, low-rank strategy, quantization, parameter pruning, LoRA, PEFT, inference tuning}
}

@inproceedings{10.1145/3627673.3679885,
author = {Li, Peiyu and Huang, Xiaobao and Tian, Yijun and Chawla, Nitesh V.},
title = {ChefFusion: Multimodal Foundation Model Integrating Recipe and Food Image Generation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679885},
doi = {10.1145/3627673.3679885},
abstract = {Significant work has been conducted in the domain of food computing, yet these studies typically focus on single tasks such as t2t (instruction generation from food titles and ingredients), i2t (recipe generation from food images), or t2i (food image generation from recipes). None of these approaches integrate all modalities simultaneously. To address this gap, we introduce a novel food computing foundation model that achieves true multimodality, encompassing tasks such as t2t, t2i, i2t, it2t, and t2ti. By leveraging large language models (LLMs) and pre-trained image encoder and decoder models, our model can perform a diverse array of food computing-related tasks, including food understanding, food recognition, recipe generation, and food image generation. Compared to previous models, our foundation model demonstrates a significantly broader range of capabilities and exhibits superior performance, particularly in food image generation and recipe generation tasks. We open-sourced ChefFusion at https://github.com/Peiyu-Georgia-Li/ChefFusion-Multimodal-Foundation-Model-Integrating-Recipe-and-Food-Image-Generation.git.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3872–3876},
numpages = {5},
keywords = {food image generation, llms, multimodal, recipe generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3696443.3708944,
author = {Lee, Yoon Noh and Yu, Yongseung and Park, Yongjun},
title = {CUrator: An Efficient LLM Execution Engine with Optimized Integration of CUDA Libraries},
year = {2025},
isbn = {9798400712753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696443.3708944},
doi = {10.1145/3696443.3708944},
abstract = {Large Language Models (LLMs) have recently emerged as a state-of-the-art learning model with a wide range of applications in diverse computing environments. Among the various computational operations that comprise the LLM, the GEneral Matrix Multiplication (GEMM) operation is the most frequently utilized operation within the LLM. GEMM libraries such as cuBLAS and CUTLASS provide a variety of optimization techniques to achieve optimal GEMM performance in GPU-enabled computing environments. In particular, the CUTLASS open-source library for GPUs within the CUDA programming environment provides users with the capability to optimize templates for high performance. Previous research has demonstrated the effectiveness of CUTLASS-based GEMMs in improving the performance of real-world deep neural networks on various deep learning platforms. However, these studies have not considered different model parameters for modern LLMs nor have they explored the impact of diverse GPU computing environments.                                                                                                                                                                                                This paper presents CUrator, an efficient LLM execution engine that can achieve optimal end-to-end LLM performance using both cuBLAS and CUTLASS libraries on different GPUs for modern LLMs such as BERT, GPT, and Llama. CUrator first generates CUTLASS-/cuBLAS-friendly graph IRs of various LLMs on the TVM framework to maximize mapping coverage. On the CUTLASS mapping path, it performs a comprehensive search for programmable tuning parameters in the CUTLASS library with the objective of deriving optimal kernels for all GEMMs within each LLM. CUrator further introduces two optimization techniques: 1) build-time reduction key initialization support for CUTLASS Split-K GEMMs, and 2) Split-K support for CUTLASS Batch GEMMs. Finally, CUrator selects the best performing mapping path between cuBLAS and CUTLASS paths. The experimental results show that CUrator achieves inference speedups of 1.50\texttimes{} and 4.99\texttimes{}, respectively, for representative LLMs on the A100 GPU in the single and half precision, compared to the baseline. We strongly believe that the CUrator framework can provide the best direction for next-generation tuning frameworks by showing the maximum end-to-end performance of various LLMs on various GPUs.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {209–224},
numpages = {16},
keywords = {Compiler, GEMM, GPU, Large Language Model},
location = {Las Vegas, NV, USA},
series = {CGO '25}
}

@inproceedings{10.1145/3649409.3691093,
author = {Garcia, Yuan and Ngo, Jenny and Lin, Florence Rui},
title = {Code Metrics, Rules of Thumb for Introductory CS},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691093},
doi = {10.1145/3649409.3691093},
abstract = {In response to the recent surge in easily accessible generative AI, Harvey Mudd College has integrated AI-assisted coding into the introductory Computer Science course. In this context, a question arises: How do we measure the quality of students' code when AI-generated code is present?Allowing generative AI to write coding assignments comes with the expectation of improved efficiency and accuracy. While generative AI is a useful tool, it merely supplements fundamental computing skills. This technological step towards being fully syntax-free allows for emphasis on the already important skill of developing problem-solving and critical thinking skills in more abstract contexts. In past years, metrics were designed to measure quantitative aspects of code, but these metrics alone are insufficient when evaluating how code written with the assistance of AI will perform in broader applications. When students submit code written with the assistance of generative AI, they are still expected to meet standards given by past metrics, such as Correctness and Complexity. To establish foundational computing skills, students will also be held to new standards and evaluated by new metrics such as Individuality and Ambition.While the model does give objective measures of the metrics, due to the fast-evolving nature of programming, predefined rules-of-thumb for these metrics are not provided. As users of our system, we recognize that evaluating the measurements will require our judgment, which will evolve over time. This work offers the foundation for that evolution.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {314–315},
numpages = {2},
keywords = {computing as a general education requirement, computing as a shared literacy, generative AI, undergraduate-universal computing},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1109/SC41406.2024.00010,
author = {Singh, Siddharth and Singhania, Prajwal and Ranjan, Aditya and Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Jain, Neel and Hans, Abhimanyu and Shu, Manli and Tomar, Aditya and Goldstein, Tom and Bhatele, Abhinav},
title = {Democratizing AI: Open-source Scalable LLM Training on GPU-based Supercomputers},
year = {2024},
isbn = {9798350352917},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC41406.2024.00010},
doi = {10.1109/SC41406.2024.00010},
abstract = {Training and fine-tuning large language models (LLMs) with hundreds of billions to trillions of parameters requires tens of thousands of GPUs, and a highly scalable software stack. In this work, we present a novel four-dimensional hybrid parallel algorithm implemented in a highly scalable, portable, open-source framework called AxoNN. We describe several performance optimizations in AxoNN to improve matrix multiply kernel performance, overlap non-blocking collectives with computation, and performance modeling to choose performance optimal configurations. These have resulted in unprecedented scaling and peak flop/s (bf16) for training of GPT-style transformer models on Perlmutter (620.1 Petaflop/s), Frontier (1.381 Exaflop/s) and Alps (1.423 Exaflop/s).While the abilities of LLMs improve with the number of trainable parameters, so do privacy and copyright risks caused by memorization of training data, which can cause disclosure of sensitive or private information at inference time. We highlight this side effect of scale through experiments that explore "catastrophic memorization," where models are sufficiently large to memorize training data in a single pass, and present an approach to prevent it. As part of this study, we demonstrate fine-tuning of a 405-billion parameter LLM using AxoNN on Frontier.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {4},
numpages = {14},
keywords = {GPGPUs, asynchrony, collective communication, large language models, parallel training},
location = {Atlanta, GA, USA},
series = {SC '24}
}

@article{10.1145/3733719,
author = {Kreikemeyer, Justin Noah and Jankowski, Mi\l{}osz and Wilsdorf, Pia and Uhrmacher, Adelinde M.},
title = {Using (Not-so) Large Language Models to Generate Simulation Models in a Formal DSL: A Study on Reaction Networks},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-3301},
url = {https://doi.org/10.1145/3733719},
doi = {10.1145/3733719},
abstract = {Formal languages are an integral part of modeling and simulation. They allow the distillation of knowledge into concise simulation models amenable to automatic execution, interpretation, and analysis. However, the arguably most humanly accessible means of expressing models is through natural language, which is not easily interpretable by computers. Here, we evaluate how a Large Language Model (LLM) might be used for formalizing natural language into simulation models. Existing studies only explored using very large LLMs, like the commercial GPT models, without fine-tuning model weights. To close this gap, we show how an open-weights, 7B-parameter Mistral model can be fine-tuned to translate natural language descriptions to reaction network models in a domain-specific language, offering a self-hostable, compute-, and memory efficient alternative. To this end, we develop a synthetic data generator to serve as the basis for fine-tuning and evaluation. Our quantitative evaluation shows that our fine-tuned Mistral model can recover the ground truth simulation model in up to  (84.5% )  of cases. In addition, our small-scale user study demonstrates the model’s practical potential for one-time generation as well as interactive modeling in various domains. While promising, in its current form, the fine-tuned small LLM cannot catch up with large LLMs. We conclude that higher-quality training data are required, and expect future small and open-source LLMs to offer new opportunities.},
note = {Just Accepted},
journal = {ACM Trans. Model. Comput. Simul.},
month = may,
keywords = {simulation model generation, natural language processing, language model, constrained decoding, knowledge extraction}
}

@inproceedings{10.1145/3696410.3714620,
author = {Liu, Zheng and Li, Chaofan and Xiao, Shitao and Li, Chaozhuo and Zhang, Chen Jason and Liao, Hao and Lian, Defu and Shao, Yingxia},
title = {Fitting Into Any Shape: A Flexible LLM-Based Re-Ranker With Configurable Depth and Width},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714620},
doi = {10.1145/3696410.3714620},
abstract = {Large language models (LLMs) provide powerful foundations to perform fine-grained text re-ranking. However, they are often prohibitive in reality due to constraints on computation bandwidth. In this work, we propose a flexible architecture called Matroyshka Re-Ranker, which is designed to facilitate runtime customization of model layers and sequence lengths at each layer based on users' configurations. Consequently, the LLM-based re-rankers can be made applicable across various real-world situations. The increased flexibility may come at the cost of precision loss. To address this problem, we introduce a suite of techniques to optimize the performance. First, we propose cascaded self-distillation, where each sub-architecture learns to preserve a precise re-ranking performance from its super components, whose predictions can be exploited as smooth and informative teacher signals. Second, we design a factorized compensation mechanism, where two collaborative LoRA modules, vertical and horizontal, are jointly employed to compensate for the precision loss resulted from arbitrary combinations of layer and sequence compression. We perform comprehensive experiments using passage and document retrieval datasets from MSMARCO, along with all public datasets from BEIR. In our experiments, Matryoshka Re-Ranker substantially outperforms existing methods, while effectively preserving its superior performance across various compression forms and application scenarios. We have publicly released our method at this https://github.com/FlagOpen/FlagEmbedding repo.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {3942–3951},
numpages = {10},
keywords = {flexibility, lightweighting, llm-based re-rankers, text retrieval},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.5555/3737313.3737332,
author = {Chamberlain, Devin and Levine, David B. and Pitcairn, Abigail and Snow, Nicholas and Sweeney, Benjamin},
title = {Large Language Models and Introductory Lab Exercises: Susceptibility, Resistance, and Potential},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {Three student personas were created, each representing a way in which current students interact with AI tools such as ChatGPT when completing introductory computer science assignments. Four undergraduate students assumed the role of each of the personas in turn and two semesters worth of current assignments were completed in each persona. The results and experiences were then analyzed to determine aspects of the assignments that made it more (or less) difficult to complete them using the AI tools, with an eye towards whether small changes in phrasing or requirements might result in significant changes in this metric.Three of the main takeaways were that LLMs are more difficult for students to use when assignments 1) consist of many small steps, 2) make use of external code libraries, or 3) involve spatial reasoning.Finally, the student/persona experiences helped to generate a list of opportunities for instructors to proactively include the use of AI tools in current assignments without sacrificing any of the current learning objectives.The initial phase involved labs from one institution and used only one AI tool, but follow-up work involving the use of other tools and labs from other institutions validated those core conclusions. A student survey (as well as other published literature) also validated the choice of personas.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {49–63},
numpages = {15}
}

@article{10.1145/3732938,
author = {Le, Huong and Luu, Ngoc and Nguyen, Thanh and Dao, Tuan and Dinh, Sang},
title = {Optimizing Answer Generator in Vietnamese Legal Question Answering Systems Using Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3732938},
doi = {10.1145/3732938},
abstract = {The development of large language models (LLMs) such as ChatGPT and Gemini has led to impressive advancements in question answering (QA) systems. However, they often rely on generic knowledge from the internet, resulting in hallucinated answers when applied to domain-specific QA tasks. Furthermore, their operational dependence on powerful GPUs poses challenges for practical software deployment. Building a QA systems for low-resource languages like Vietnamese is even more challenging due to the scarcity of labeled data and limited pre-trained language models. In this study, we aim to construct a Vietnamese legal QA system using a retrieval-augmented generation approach to reduce incorrect outputs. Our focus is on improving answer generation accuracy by training small-scale LLMs suitable for real-world deployment. Our contributions are: (i) constructing Vietnamese legal provisions and QA datasets for training the system; and (ii) proposing methods to fine-tune language models with QA capabilities in the legal domain. Experimental results demonstrate that it is possible to train an LLM with fewer computational resources and a smaller dataset while maintaining effectiveness. Our findings highlight that designing an efficient training and fine-tuning strategy is crucial for overcoming these challenges, particularly in the context of Vietnamese legal question-answering tasks.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = apr,
keywords = {Vietnamese, Legal, Question Answering, answer generator, BartPho, VinaLlama}
}

@inproceedings{10.1145/3676536.3676761,
author = {Zhao, Tiandong and Lu, Shaoqiang and Wu, Chen and He, Lei},
title = {ChatOPU: An FPGA-based Overlay Processor for Large Language Models with Unstructured Sparsity},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676761},
doi = {10.1145/3676536.3676761},
abstract = {Large language models (LLMs) have achieved notable success on many applications with increasingly tremendous parameters and computations. While hardware accelerators on Transformer-based models have been extensively studied, recent work mainly assumes structured model pruning and does not work well for unstructured sparsity that could lead to more parameter and computation reduction. The reason behind is that it is difficult to exploit data reuse from the unstructured sparsity, leaving hardware underutilized. This paper proposes ChatOPU, an FPGA-based overlay processor for LLMs, to support unstructured model pruning with better data reuse. First, we propose a new diagonal dataflow on a systolic array to obtain efficient data reuse for both sparse and dense matrix multiplication. Second, we develop efficient encoding and decoding for the sparse parameters to save off-chip memory traffic. Moreover, we boost the off-chip bandwidth utilization with pinned on-chip KV cache allocation and coalesced access throughout the LLM inference. Experimental results show that ChatOPU on Xilinx U200 FPGA outperforms GPU and other FPGA-based accelerators on token/s by 2.29\texttimes{} and 1.63\texttimes{} on LLMs with unstructured sparsity across different input and output sequence lengths.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {203},
numpages = {9},
keywords = {large language model, hardware accelerator, FPGA, sparsity},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3652988.3673918,
author = {Zhang, Taiyu and Zhang, Xuesong and Cools, Robbe and Simeone, Adalberto},
title = {Focus Agent: LLM-Powered Virtual Focus Group},
year = {2024},
isbn = {9798400706257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652988.3673918},
doi = {10.1145/3652988.3673918},
abstract = {In the domain of Human-Computer Interaction, focus groups represent a widely utilised yet resource-intensive methodology, often demanding the expertise of skilled moderators and meticulous preparatory efforts. This study introduces the “Focus Agent,” a Large Language Model (LLM) powered framework that simulates both the focus group (for data collection) and acts as a moderator in a focus group setting with human participants. To assess the data quality derived from the Focus Agent, we ran five focus group sessions with a total of 23 human participants as well as deploying the Focus Agent to simulate these discussions with AI participants. Quantitative analysis indicates that Focus Agent can generate opinions similar to those of human participants. Furthermore, the research exposes some improvements associated with LLMs acting as moderators in focus group discussions that include human participants.},
booktitle = {Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents},
articleno = {10},
numpages = {10},
keywords = {Human-computer Interaction, Intelligent Virtual Agent, Multi Agent Simulation, Virtual Focus Group},
location = {GLASGOW, United Kingdom},
series = {IVA '24}
}

@inproceedings{10.1145/3711708.3723442,
author = {Huang, Xiaowen and Zhang, Xu and Tao, Lvfang and Mao, Renjie and Zhou, Nan and Zhu, Wenxi and Deng, Minwen and Meng, Jintao and Wei, Yanjie and Zhou, Amelie Chi and Wang, Bingqiang and Feng, Shengzhong},
title = {ParaCoder: Parallel Code Generation with Large Language Model},
year = {2025},
isbn = {9798400714467},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711708.3723442},
doi = {10.1145/3711708.3723442},
abstract = {High-performance parallel code generation is a complex and fascinating area in computer science that focuses on producing code that executes as quickly and efficiently as possible. In our paper, we designed a new architecture for parallel code generation agent with 4 inter-connected components of LLM---Memory, Planning, Tools and Action. It also incooperated with two techniques: data augmentation, prompting and retrieval-augmented editing to improve the performance of the parallel codes. Data augmentation is implemented by extracting and processing PIE dataset, and also synthesis dataset generated by LLM models with ParEval benchmark. Finally planning-oriented prompting, code verification and retrieval augmented editing are used to promote the actual performance of the LLM generated code. The evaluation results confirm that a rough speedup of 6.06X and 5.13X are achieved using Qwen2.5-Coder-7B-Instruct, Qwen2.5-Coder-14B-Instruct LLM models.},
booktitle = {Proceedings of the 1st FastCode Programming Challenge},
pages = {1–7},
numpages = {7},
keywords = {LLM, code generation, parallelization},
location = {The Westin Las Vegas Hotel &amp; Spa, Las Vegas, NV, USA},
series = {FCPC '25}
}

@article{10.1145/3660807,
author = {Kou, Bonan and Chen, Shengmai and Wang, Zhijie and Ma, Lei and Zhang, Tianyi},
title = {Do Large Language Models Pay Similar Attention Like Human Programmers When Generating Code?},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660807},
doi = {10.1145/3660807},
abstract = {Large Language Models (LLMs) have recently been widely used for code generation. Due to the complexity and opacity of LLMs, little is known about how these models generate code. We made the first attempt to bridge this knowledge gap by investigating whether LLMs attend to the same parts of a task description as human programmers during code generation. An analysis of six LLMs, including GPT-4, on two popular code generation benchmarks revealed a consistent misalignment between LLMs' and programmers' attention. We manually analyzed 211 incorrect code snippets and found five attention patterns that can be used to explain many code generation errors. Finally, a user study showed that model attention computed by a perturbation-based method is often favored by human programmers. Our findings highlight the need for human-aligned LLMs for better interpretability and programmer trust.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {100},
numpages = {24},
keywords = {Attention, Code Generation, Large Language Models}
}

@inproceedings{10.1109/ASE56229.2023.00089,
author = {Li, Tsz-On and Zong, Wenxi and Wang, Yibo and Tian, Haoye and Wang, Ying and Cheung, Shing-Chi and Kramer, Jeff},
title = {Nuances Are the Key: Unlocking ChatGPT to Find Failure-Inducing Tests with Differential Prompting},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00089},
doi = {10.1109/ASE56229.2023.00089},
abstract = {Automated detection of software failures is an important but challenging software engineering task. It involves finding in a vast search space the failure-inducing test cases that contain an input triggering the software fault and an oracle asserting the incorrect execution. We are motivated to study how far this outstanding challenge can be solved by recent advances in large language models (LLMs) such as ChatGPT. However, our study reveals that ChatGPT has a relatively low success rate (28.8%) in finding correct failure-inducing test cases for buggy programs. A possible conjecture is that finding failure-inducing test cases requires analyzing the subtle differences (nuances) between the tokens of a program's correct version and those for its buggy version. When these two versions have similar sets of tokens and attentions, ChatGPT is weak in distinguishing their differences.We find that ChatGPT can successfully generate failure-inducing test cases when it is guided to focus on the nuances. Our solution is inspired by an interesting observation that ChatGPT could infer the intended functionality of buggy code if it is similar to the correct version. Driven by the inspiration, we develop a novel technique, called Differential Prompting, to effectively find failure-inducing test cases with the help of the compilable code synthesized by the inferred intention. Prompts are constructed based on the nuances between the given version and the synthesized code. We evaluate Differential Prompting on Quixbugs (a popular benchmark of buggy programs) and recent programs published at Codeforces (a popular programming contest portal, which is also an official benchmark of ChatGPT). We compare Differential Prompting with two baselines constructed using conventional ChatGPT prompting and Pynguin (the state-of-the-art unit test generation tool for Python programs). Our evaluation results show that for programs of Quixbugs, Differential Prompting can achieve a success rate of 75.0% in finding failure-inducing test cases, outperforming the best baseline by 2.6X. For programs of Codeforces, Differential Prompting's success rate is 66.7%, outperforming the best baseline by 4.0X.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {14–26},
numpages = {13},
keywords = {failure-inducing test cases, large language models, program intention inference, program generation},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3689092.3689402,
author = {Zhang, Zixing and Dong, Zhongren and Gao, Zhiqiang and Gao, Shihao and Wang, Donghao and Chen, Ciqiang and Nie, Yuhan and Zhao, Huan},
title = {Open Vocabulary Emotion Prediction Based on Large Multimodal Models},
year = {2024},
isbn = {9798400712036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689092.3689402},
doi = {10.1145/3689092.3689402},
abstract = {The Multimodal Emotion Recognition (MER 2024) Challenge focuses on recognizing emotions through the integration of audio, language, and visual signals, driving advancements in the field of affective computing. This study presents our approach for the MER-OV sub-challenge, concentrating on open-vocabulary emotion recognition. We innovatively employ Optical Character Recognition (OCR) technology to optimize video subtitles, thereby enhancing the accuracy of textual descriptions. Additionally, we utilize in-context learning techniques with large language models (LLMs) for open-vocabulary emotion prediction. By incorporating video content analysis, we leverage large multimodal models (LMMs) to further improve the accuracy of emotion prediction. Our proposed text-only modality-based open-vocabulary emotion prediction method achieves an average score of 51.0% on the training set, and the multimodal open-vocabulary emotion prediction method achieves an average score of 59.1%. This surpasses the best model in the baseline, GPT-4V, which has a score of 56.0%, achieving a state-of-the-art (SOTA) result.},
booktitle = {Proceedings of the 2nd International Workshop on Multimodal and Responsible Affective Computing},
pages = {99–103},
numpages = {5},
keywords = {large language models, large multimodal models, multimodal emotion recognition},
location = {Melbourne VIC, Australia},
series = {MRAC '24}
}

@inproceedings{10.1145/3627673.3680048,
author = {Qiu, Zexuan and Zhu, Jieming and Chen, Yankai and Cai, Guohao and Liu, Weiwen and Dong, Zhenhua and King, Irwin},
title = {EASE: Learning Lightweight Semantic Feature Adapters from Large Language Models for CTR Prediction},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680048},
doi = {10.1145/3627673.3680048},
abstract = {Recent studies highlight the potential of large language models (LLMs) to enhance content integration in recommender systems by leveraging their semantic understanding capabilities. However, directly incorporating LLMs into an online inference pipeline significantly increases computation costs for large-scale deployment, posing a practical challenge in balancing their benefits and costs. In this work, we propose the EASE framework, which enriches and aligns semantic feature embeddings using LLMs during the training phase while establishing a lightweight inference pipeline that does not directly involve LLMs. Specifically, we train a semantic adapter to align item features with LLMs and simultaneously enrich semantic embeddings through reconstruction tasks from LLMs. During inference, we retain only the item feature encoder and lightweight semantic adapter, thereby eliminating the computation overhead of resource-intensive LLMs. Our EASE framework is flexible, supporting not only text and visual features but also other pre-processed embedding features. Extensive experiments on both public and industrial datasets demonstrate that enriching semantic feature embeddings with our EASE framework yields consistent improvements in downstream click-through rate prediction tasks.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4819–4827},
numpages = {9},
keywords = {ctr prediction, large language models, multimodal embedding, recommender systems, semantic embedding},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3644116.3644294,
author = {Zhu, Jinyang and Gong, Qingyue and Zhou, Chunfang and Luan, Huidan},
title = {ZhongJing: A Locally Deployed Large Language Model for Traditional Chinese Medicine and Corresponding Evaluation Methodology: A Large Language Model for data fine-tuning in the field of Traditional Chinese Medicine, and a new evaluation method called TCMEval are proposed},
year = {2024},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644116.3644294},
doi = {10.1145/3644116.3644294},
abstract = {The success of ChatGPT has showcased the potential applications of Large Language Models (LLMs) in the field of Traditional Chinese Medicine (TCM), encompassing areas such as medical diagnosis, adjunctive therapy, and TCM talent cultivation. However, the current challenges, including hardware constraints, insufficient model domain knowledge, and difficulties in domain-specific evaluation, have constrained the fusion of LLMs with TCM. In an attempt to address these issues, this paper introduces ZhongJing, a domain-specific LLM fine-tuned within the domain of TCM, capable of generating responses at a rate of 8 tokens per second, smoothly operating on local personal computers. To assess the model's domain expertise, this paper introduces the TCMEval evaluation method, designed concerning medical students' exams. Experimental results demonstrate that ZhongJing achieves a 6.49 TCMEval Score improvement over Chinese-LLaMA2 in the field of TCM, indicating the model's ability to generate more specialized responses compared to baseline models.},
booktitle = {Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
pages = {1036–1042},
numpages = {7},
location = {Chengdu, China},
series = {ISAIMS '23}
}

@inproceedings{10.1145/3695794.3695809,
author = {Wu, Jianbo and Liu, Jie and Kestor, Gokcen and Gioiosa, Roberto and Li, Dong and Marquez, Andres},
title = {Performance Study of CXL Memory Topology},
year = {2024},
isbn = {9798400710919},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3695794.3695809},
doi = {10.1145/3695794.3695809},
abstract = {This paper presents a comprehensive evaluation of the performance impact of various Compute Express Link (CXL) memory topologies, with a particular emphasis on CXL switches, in the context of High-Performance Computing (HPC) and Large Language Model (LLM) inference workloads. Our study unveils significant performance variations across different topologies, demonstrating that certain configurations yield superior performance for specific workloads. These findings underscore the critical importance of tailored topology selection in optimizing system performance. Additionally, we address the inherent challenges associated with integrating CXL switches, including overhead considerations and routing complexities. Our research highlights the necessity for thorough evaluation methodologies to fully leverage CXL technology’s potential in contemporary computing environments. These insights provide valuable guidance for system architects and data center operators in designing and optimizing CXL-based infrastructures for diverse workload requirements.},
booktitle = {Proceedings of the International Symposium on Memory Systems},
pages = {172–177},
numpages = {6},
keywords = {CXL.mem and CXL switch, CXL.mem topologies, CXL.mem Emulation},
location = {
},
series = {MEMSYS '24}
}

@inproceedings{10.1145/3676536.3697135,
author = {Firouzi, Farshad and Nakkilla, Sri Sai Rakesh and Fu, Chenghao and Banerjee, Sanmitra and Talukdar, Jonti and Chakrabarty, Krishnendu},
title = {LLM-AID: Leveraging Large Language Models for Rapid Domain-Specific Accelerator Development},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3697135},
doi = {10.1145/3676536.3697135},
abstract = {The challenges posed by the Dark Silicon era, combined with the escalating computational demands of emerging applications, such as Deep Learning (DL), have strained the capabilities of traditional CPUs and GPUs, necessitating the development of Domain-Specific Accelerators (DSAs). Despite offering substantial enhancements in Power, Performance, and Area (PPA), DSAs encounter significant challenges, including the rapid evolution of applications that necessitate the frequent development of new architectures. This, coupled with the expertise-intensive nature of the design process, often leads to reduced flexibility and extended development cycles, ultimately hindering the broader adoption and efficient deployment of DSAs. To address these challenges, this paper introduces LLM-AID, an agile framework that streamlines the DSA design flow by transforming high-level abstract specifications into Hardware Description Language (HDL) code and facilitating backend Computer-Aided Design (CAD) tool operations. By synergistically combining Large Language Models (LLMs), High-Level Synthesis (HLS) tools, design exploration techniques, and symbolic AI, LLM-AID dramatically accelerates design iterations, optimizes hardware performance, and significantly reduces time-to-market. This innovative approach democratizes DSA development, empowering designers to achieve unprecedented productivity while delivering high-quality DSA solutions.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {25},
numpages = {9},
keywords = {domain-specific accelerators (DSAs), high-level synthesis (HLS), computer-aided design (CAD), large language models (LLMs), design exploration},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3638530.3664163,
author = {Custode, Leonardo Lucio and Caraffini, Fabio and Yaman, Anil and Iacca, Giovanni},
title = {An investigation on the use of Large Language Models for hyperparameter tuning in Evolutionary Algorithms},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3664163},
doi = {10.1145/3638530.3664163},
abstract = {Hyperparameter optimization is a crucial problem in Evolutionary Computation. In fact, the values of the hyperparameters directly impact the trajectory taken by the optimization process, and their choice requires extensive reasoning by human operators. Although a variety of self-adaptive Evolutionary Algorithms have been proposed in the literature, no definitive solution has been found. In this work, we perform a preliminary investigation to automate the reasoning process that leads to the choice of hyperparameter values. We employ two open-source Large Language Models (LLMs), namely Llama2-70b and Mixtral, to analyze the optimization logs online and provide novel real-time hyperparameter recommendations. We study our approach in the context of step-size adaptation for (1 + 1)-ES. The results suggest that LLMs can be an effective method for optimizing hyperparameters in Evolution Strategies, encouraging further research in this direction.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1838–1845},
numpages = {8},
keywords = {evolutionary algorithms, large language models, landscape analysis, parameter tuning},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{10.1145/3613905.3647967,
author = {Kimmel, Bailey and Geisert, Austin Lee and Yaro, Lily and Gipson, Brendan and Hotchkiss, Ronald Taylor and Osae-Asante, Sidney Kwame and Vaught, Hunter and Wininger, Grant and Yamaguchi, Chase},
title = {Enhancing Programming Error Messages in Real Time with Generative AI},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3647967},
doi = {10.1145/3613905.3647967},
abstract = {Generative AI is changing the way that many disciplines are taught, including computer science. Researchers have shown that generative AI tools are capable of solving programming problems, writing extensive blocks of code, and explaining complex code in simple terms. Particular promise has been shown in using generative AI to enhance programming error messages. Both students and instructors have complained for decades that these messages are often cryptic and difficult to understand. Yet recent work has shown that students make fewer repeated errors when enhanced via GPT-4. We extend this work by implementing feedback from ChatGPT for all programs submitted to our automated assessment tool, Athene, providing help for compiler, run-time, and logic errors. Our results indicate that adding generative AI to an automated assessment tool does not necessarily make it better and that design of the interface matters greatly to the usability of the feedback that GPT-4 provided.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {608},
numpages = {7},
keywords = {AI, Artificial Intelligence, Automatic Code Generation, CS1, ChatGPT, Codex, Copilot, GPT-4, GitHub, HCI, Introductory Programming, LLM, Large Language Models, Novice Programming, OpenAI},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3706599.3721205,
author = {Kl\"{u}wer, Nils and Nalis, Irina and Neidhardt, Julia},
title = {Context over Categories: Implementing the Theory of Constructed Emotion with LLM-Guided User Analysis},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3721205},
doi = {10.1145/3706599.3721205},
abstract = {Emotion analysis is a critical research area with applications in content moderation and personalized systems. Many existing approaches rely on Ekman’s universal emotions theory, which reduces emotions to static categories, neglecting their complexity and contextual variability. This work introduces a novel, context-aware approach based on Lisa Feldman Barrett’s Theory of Constructed Emotion. A key contribution is the development of the “context sphere,” a personalized construct derived from user behavior data. To our knowledge, this is the first operationalization for computational methods. A context-aware emotion analysis pipeline was developed, incorporating advanced Large Language Model (LLM) prompting strategies like role-play and controlled generation. A case study in content moderation demonstrates how the “context sphere” enables contextually aware emotion analyses. Future directions include refining the framework, advancing LLM methodologies, and conducting user studies. This research lays the foundation for more human-centered, ethical, and effective emotion analysis systems.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {151},
numpages = {7},
keywords = {Human-Computer Interaction, Emotion Analysis, Large Language Models (LLMs), Context Aware Computing, Online Content Moderation},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3696443.3708929,
author = {Taneja, Jubi and Laird, Avery and Yan, Cong and Musuvathi, Madan and Lahiri, Shuvendu K.},
title = {LLM-Vectorizer: LLM-Based Verified Loop Vectorizer},
year = {2025},
isbn = {9798400712753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696443.3708929},
doi = {10.1145/3696443.3708929},
abstract = {Vectorization is a powerful optimization technique that significantly boosts the performance of high performance computing applications operating on large data arrays. Despite decades of research on auto-vectorization, compilers frequently miss opportunities to vectorize code. On the other hand, writing vectorized code manually using compiler intrinsics is still a complex, error-prone task that demands deep knowledge of specific architecture and compilers.  In this paper, we evaluate the potential of large-language models (LLMs) to generate vectorized (Single Instruction Multiple Data) code from scalar programs that process individual array elements.   We propose a novel finite-state-machine multi-agents based approach that harnesses LLMs and test-based feedback to generate vectorized code.  Our findings indicate that LLMs are capable of producing high-performance vectorized code with run-time speedup ranging from 1.1x to 9.4x as compared to the state-of-the-art compilers such as Intel Compiler, GCC, and Clang.  To verify the correctness of vectorized code, we use Alive2, a leading bounded translation validation tool for LLVM IR. We describe a few domain-specific techniques to improve the scalability of Alive2 on our benchmark dataset. Overall, our approach is able to verify 38.2% of vectorizations as correct on the TSVC benchmark dataset.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {137–149},
numpages = {13},
keywords = {AI Agents, Large language model, Loop Vectorization, Translation Validation},
location = {Las Vegas, NV, USA},
series = {CGO '25}
}

@inproceedings{10.1145/3672539.3686776,
author = {Fang, Cathy Mengying and Chwalek, Patrick and Kuang, Quincy and Maes, Pattie},
title = {WatchThis: A Wearable Point-and-Ask Interface powered by Vision-Language Models for Contextual Queries},
year = {2024},
isbn = {9798400707186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672539.3686776},
doi = {10.1145/3672539.3686776},
abstract = {This paper introduces WatchThis, a novel wearable device that enables natural language interactions with real-world objects and environments through pointing gestures. Building upon previous work in gesture-based computing interfaces, WatchThis leverages recent advancements in Large Language Models (LLM) and Vision Language Models (VLM) to create a hands-free, contextual querying system. The prototype consists of a wearable watch with a rotating, flip-up camera that captures the area of interest when pointing, allowing users to ask questions about their surroundings in natural language. This design addresses limitations of existing systems that require specific commands or occupy the hands, while also maintaining a non-discrete form factor for social awareness. The paper explores various applications of this point-and-ask interaction, including object identification, translation, and instruction queries. By utilizing off-the-shelf components and open-sourcing the design, this work aims to facilitate further research and development in wearable, AI-enabled interaction paradigms.},
booktitle = {Adjunct Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {54},
numpages = {4},
keywords = {camera, pointing, vision language model, watch, wearable},
location = {Pittsburgh, PA, USA},
series = {UIST Adjunct '24}
}

@inproceedings{10.1145/3722405.3722445,
author = {Zhou, Shengpeng and Li, Haojie},
title = {A Personality Detection Model Based on Language Style and Contrastive Learning},
year = {2025},
isbn = {9798400713880},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722405.3722445},
doi = {10.1145/3722405.3722445},
abstract = {Launched based on data up to October 2024, personality detection has become a significant area of recent research in psychology, human-computer interaction, and social media analysis. Yet existing computational psychology frameworks ignore the role of writing style in behavioral prediction tasks. Further, a single pre-trained model is still used in many studies to extract semantic information from texts. To overcome these limitations, we propose a novel personality detection approach, styleSem, which jointly leverages writing style and deep semantics. We first apply large language models (LLMs) to extract 11 different writing style features, then incorporate a number of pre-trained models with contrastive learning to enhance semantic aspects. We perform experiments on two common benchmark datasets, Essays and MyPersonality. On the Essays dataset, the new method showed an improvement of 1.74% on average compared to the current state of art algorithm. On MyPersonality dataset, it obtains average accuracy 2.42% higher than top-performing method.},
booktitle = {Proceedings of the 2024 International Conference on Image Processing, Multimedia Technology and Maching Learning},
pages = {247–252},
numpages = {6},
keywords = {Attention, Contrastive Learning, Personality Detection, Pre-trained Model, Writing Style},
location = {
},
series = {IPMML '24}
}

@inproceedings{10.1145/3660650.3660673,
author = {Rajabi, Parsa and Kerslake, Chris},
title = {Can You Spot the AI? Incorporating GenAI into Technical Writing Assignments},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660673},
doi = {10.1145/3660650.3660673},
abstract = {In an effort to foster critical reflection on the usage of generative AI (genAI) during computer science writing assignments, this three-part assignment challenges students to predict whether their peers can detect which essays are generated using AI. Implemented as part of a third-year professional responsibility and technical writing course for N=200 students during Spring 2024, students individually generated two short persuasive essays, one using genAI and the other without. They then combined the two essays into a single document and submitted it for peer-review. Additionally, they formulated a guess on whether their peers would be able to detect which essay was generated as well as a rationale for their guess. Following the peer-review process, students reflected on their own experience trying to detect which essays were generated as well as the outcome of their guess about their peers abilities as well. Feedback indicates its effectiveness in engaging students in their understanding of the potentials and limitations of genAI. Recommended prerequisites include a clear course AI-usage policy and a brief overview of genAI prompt engineering.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {23},
numpages = {2},
keywords = {AI Literacy, AI in Education, AI-usage Policy, ChatGPT, Generative AI, Technical Writing},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3701716.3715222,
author = {Zhao, Gang and Zhang, Ximing and Lu, Chenji and Zhao, Hui and Wu, Tianshu and Wang, Pengjie and Xu, Jian and Zheng, Bo},
title = {Explainable LLM-driven Multi-dimensional Distillation for E-Commerce Relevance Learning},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715222},
doi = {10.1145/3701716.3715222},
abstract = {Effective query-item relevance modeling is pivotal for enhancing user experience and safeguarding user satisfaction in e-commerce search systems. Recently, benefiting from the vast inherent knowledge, Large Language Model (LLM) approach demonstrates strong performance and long-tail generalization ability compared with previous neural-based specialized relevance learning methods. Though promising, current LLM-based method encounters the following inadequacies in practice: Firstly, the relevance modeling process is a black box, making it difficult to clearly understand why LLM can provide the significant improvement or to analyze its relevance judgment errors. This opacity also hinders the reuse of the LLM's rich intrinsic knowledge. Secondly, the massive parameters and computational demands make it challenging to be deployed online. To improve the interpretability of LLM and boost the performance of online relevance models, we propose an Explainable LLM-driven Multi-dimensional Distillation framework for e-commerce relevance learning, which comprises two core components: (1) An Explainable LLM for relevance modeling (ELLM-rele), which decomposes the relevance learning into intermediate steps and models relevance learning as a Chain-of-Thought (CoT) reasoning, thereby enhancing both interpretability and performance of LLM. (2) A Multi-dimensional Knowledge Distillation (MKD) architecture that transfers the knowledge of ELLM-rele to current interaction-based and representation-based student models from both the relevance score distribution and CoT reasoning aspects. Through distilling the probabilistic and CoT reasoning knowledge, MKD improves both the semantic interaction and long-tail generalization abilities of student models. Extensive offline evaluations and online experiments conducted on Taobao search ad scene demonstrate that our proposed ELLM-MD framework significantly enhances e-commerce relevance learning performance and consumer experience.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {631–640},
numpages = {10},
keywords = {e-commerce, knowledge distillation, large language model, semantic matching},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3696410.3714595,
author = {Qiao, Tingrui and Walker, Caroline and Cunningham, Chris and Koh, Yun Sing},
title = {Thematic-LM: A LLM-based Multi-agent System for Large-scale Thematic Analysis},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714595},
doi = {10.1145/3696410.3714595},
abstract = {Thematic analysis (TA) is a widely used qualitative method for identifying underlying meanings within unstructured text. However, TA requires manual processes, which become increasingly labour-intensive and time-consuming as datasets grow. While large language models (LLMs) have been introduced to assist with TA on small-scale datasets, three key limitations hinder their effectiveness. First, current approaches often depend on interactions between an LLM agent and a human coder, a process that becomes challenging with larger datasets. Second, with feedback from the human coder, the LLM tends to mirror the human coder, which provides a narrower viewpoint of the data. Third, existing methods follow a sequential process, where codes are generated for individual samples without recalling previous codes and associated data, reducing the ability to analyse data holistically. To address these limitations, we propose Thematic-LM, an LLM-based multi-agent system for large-scale computational thematic analysis. Thematic-LM assigns specialised tasks to each agent, such as coding, aggregating codes, and maintaining and updating the codebook. We assign coder agents different identity perspectives to simulate the subjective nature of TA, fostering a more diverse interpretation of the data. We applied Thematic-LM to the Dreaddit dataset and the Reddit climate change dataset to analyse themes related to social media stress and online opinions on climate change. We evaluate the resulting themes based on trustworthiness principles in qualitative research. Our study reveals insights such as assigning different identities to coder agents promotes divergence in codes and themes.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {649–658},
numpages = {10},
keywords = {computational social science, large language model, multi-agent system, thematic analysis},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3701716.3717808,
author = {Mondal, Chayan and Pham, Duc-Son and Gupta, Ashu and Tan, Tele and Gedeon, Tom},
title = {Leveraging Prompt Engineering with Lightweight Large Language Models to Label and Extract Clinical Information from Radiology Reports},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717808},
doi = {10.1145/3701716.3717808},
abstract = {Chest X-ray imaging plays a critical role in diagnosing chest diseases, making it a cornerstone in clinical and research domains. Automating disease diagnosis and extracting relevant clinical information from chest X-ray reports have become essential for developing AI-driven healthcare systems. While effective, deep learning models require extensive labelled datasets, making the labelling of diseases from radiology reports crucial. Traditionally, rule-based labelling approaches have been employed, but the emergence of large language models (LLMs) has introduced new possibilities through instruction-based prompt engineering. In this study, we explore various prompt engineering techniques, including in-context learning and prompt chaining, to label multilabel disease reports and extract key clinical findings from radiology reports. We conducted ablation studies on both proprietary LLMs (e.g., GPT-4 Turbo, GPT-3.5 Turbo) and publicly available LLMs (e.g., Llama2-7B, Llama2-13B, Llama3-8B, Llama2-70B), comparing their performance in terms of clinical accuracy, privacy, and computational cost. Our findings demonstrate that well-crafted prompts on publicly available and lightweight LLMs can achieve competitive results compared to larger and/or proprietary models, offering a cost-effective and privacy-preserving solution for clinical applications. These results highlight the potential of leveraging advanced prompt engineering to streamline disease labelling and enhance the quality of automated report generation in radiology.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1616–1625},
numpages = {10},
keywords = {chest x-ray report., generative ai, in-context learning, llm, prompt engineering},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3723005,
author = {Zhang, Xinjie and Zhang, Tenggan and Sun, Lei and Zhao, Jinming and Jin, Qin},
title = {Exploring Interpretability in Deep Learning for Affective Computing: A Comprehensive Review},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3723005},
doi = {10.1145/3723005},
abstract = {Deep learning has shown impressive performance in affective computing, but its black-box characteristic limits the model’s interpretability, posing a challenge to further development and application. Compared with objective recognition tasks such as image recognition, emotion perception as a high-level cognition is more subjective, making it particularly important to enhance the interpretability of deep learning in affective computing. In recent years, some interpretability-related works have emerged, but there are few reviews on this topic yet. This paper summarizes the explainable deep learning methods in affective computing from two aspects: first, the application of general explainable deep learning methods in affective computing from the perspectives of model-agnostic and model-specific is introduced; second, emotion-specific interpretability research that combines emotional psychology theories, physiological studies, and human cognition, covering task design, model design, and result analysis methods, is systematically reviewed. There are new explainable deep learning methods for multimodal and large language models in the context of emotion. Finally, we discuss five specific challenges and propose corresponding future directions to provide insights and references for subsequent research on affective computing interpretability.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = mar,
keywords = {Affective computing, Explainable methods, Deep learning, Multimodal}
}

@inproceedings{10.1145/3636555.3636889,
author = {Sonkar, Shashank and Chen, Xinghe and Le, Myco and Liu, Naiming and Basu Mallick, Debshila and Baraniuk, Richard},
title = {Code Soliloquies for Accurate Calculations in Large Language Models},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636889},
doi = {10.1145/3636555.3636889},
abstract = {High-quality conversational datasets are crucial for the successful development of Intelligent Tutoring Systems (ITS) that utilize a Large Language Model (LLM) backend. Synthetic student-teacher dialogues, generated using advanced GPT-4 models, are a common strategy for creating these datasets. However, subjects like physics that entail complex calculations pose a challenge. While GPT-4 presents impressive language processing capabilities, its limitations in fundamental mathematical reasoning curtail its efficacy for such subjects. To tackle this limitation, we introduce in this paper an innovative stateful prompt design. Our design orchestrates a mock conversation where both student and tutorbot roles are simulated by GPT-4. Each student response triggers an internal monologue, or ‘code soliloquy’ in the GPT-tutorbot, which assesses whether its subsequent response would necessitate calculations. If a calculation is deemed necessary, it scripts the relevant Python code and uses the Python output to construct a response to the student. Our approach notably enhances the quality of synthetic conversation datasets, especially for subjects that are calculation-intensive. The preliminary Subject Matter Expert evaluations reveal that our Higgs model, a fine-tuned LLaMA model, effectively uses Python for computations, which significantly enhances the accuracy and computational reliability of Higgs’ responses.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {828–835},
numpages = {8},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3638530.3654426,
author = {Vella Zarb, David and Parks, Geoff and Kipouros, Timoleon},
title = {Synergistic Utilization of LLMs for Program Synthesis},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3654426},
doi = {10.1145/3638530.3654426},
abstract = {Advances in Large Language Models (LLMs) have led them to be used as black boxes in several evolutionary algorithms for program synthesis. While these methods tend to be agnostic about which model is used, they only allow for using one. This paper suggests that using a combination of LLMs to seed population-based algorithms introduces more variation and leads to a wider variety of problems that can be solved, due to leveraging the strengths of component LLMs. We test this on the PSB2 suite, using the Search, Execute, Instruct, Debug and Rank (SEIDR) algorithm. In all cases examined, we find that using a combination of LLMs leads to more problems solved and better test pass rates compared to using the best individual model. We also find that the computational cost, as measured in terms of excess programs generated, is lowered.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {539–542},
numpages = {4},
keywords = {program synthesis, large language models, evolutionary algorithms},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{10.1145/3653081.3653102,
author = {Yang, Shanglin and Zhu, Jialin and Wang, Jialin and Xu, Xiaohan and Shao, Zihang and Yao, Liwei and Zheng, Benchang and Huang, Hu},
title = {Retrieval-Augmented Generation with Quantized Large Language Models: A Comparative Analysis},
year = {2024},
isbn = {9798400716485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653081.3653102},
doi = {10.1145/3653081.3653102},
abstract = {Large language models have demonstrated emergent intelligence and ability to handle a wide array of tasks. However, the reliability of these models in terms of factual accuracy and timely knowledge acquisition remains a challenge. Researchers explore the implementation of retrieval-augmented generation methods, aiming to enhance the authenticity and specificity in knowledge-intensive tasks. This paper discusses the practical application in industrial settings, particularly in assisting design personnel with navigating complex standards and quality manuals. Utilizing an open-source model with 6 billion parameters, the study employs quantization technology for local deployment, addressing computational challenges. The retrieval-augmented generation framework is analyzed, emphasizing the integration of document parsing, vector databases, and text embedding models. Experimental results compare models at different quantization levels, revealing trade-offs between response time, model size, and performance metrics. The findings suggest that 4-bit integer quantization is optimal for standard document retrieval and question-answering tasks, highlighting practical considerations for CPU inference. The paper concludes with insights into hyper-parameter tuning, model comparisons, and future optimizations for enhanced performance in edge device deployments of large language models.},
booktitle = {Proceedings of the 2023 5th International Conference on Internet of Things, Automation and Artificial Intelligence},
pages = {120–124},
numpages = {5},
location = {Nanchang, China},
series = {IoTAAI '23}
}

@inproceedings{10.1145/3568812.3603474,
author = {Singla, Adish},
title = {Evaluating ChatGPT and GPT-4 for Visual Programming},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603474},
doi = {10.1145/3568812.3603474},
abstract = {Generative AI has the potential to drastically improve the landscape of computing education by automatically generating personalized feedback and content. In particular, this potential lies in the advanced capabilities of state-of-the-art deep generative and large language models such as OpenAI’s Codex&nbsp;[7], ChatGPT&nbsp;[11], and GPT-4&nbsp;[12]. In our work, we seek to investigate the capabilities of these models in visual programming domains popularly used for K-8 programming education, including domains like Scratch&nbsp;[17], Hour of Code: Maze Challenge by Code.org&nbsp;[4, 5], and Karel&nbsp;[13]. Recent works have shown us sparks of advanced capabilities of such models for various education scenarios in introductory Python programming&nbsp;[2, 14, 18, 20]. In fact, a study in 2022 had ranked Codex in the top quartile w.r.t students in a large Python programming course&nbsp;[8]. However, all these works consider only text-based Python programming and leave open the question of how well these models would perform for visual programming. The main research question is: Do state-of-the-art neural generative models show advanced capabilities for visual programming on par with their capabilities on text-based Python programming?In our work, we evaluate these models for visual programming based on the following three settings designed to capture various generative and problem-solving capabilities: We conduct our evaluation based on 10 representative tasks from two visual programming domains: Hour of Code: Maze Challenge by Code.org&nbsp;[4, 5] and Intro to Programming with Karel course by CodeHS.com&nbsp;[3, 13]. As illustrative examples, Figures&nbsp;1,&nbsp;2,&nbsp;and&nbsp;3 show the output of GPT-4 in three settings for Maze18 task. We will provide the detailed analysis and prompts used in a longer version of this poster. Our preliminary results for ChatGPT (based on GPT-3.5) and GPT-4 show that these models perform poorly and produce incorrect output the majority of the time. These results highlight that state-of-the-art neural generative models like GPT-4 still struggle to combine spatial, logical, and programming skills crucial for visual programming. As the next step, it would be important to curate novel benchmarks that the research community can use to evaluate improvements in future versions of these models for visual programming.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {14–15},
numpages = {2},
keywords = {ChatGPT, block-based visual programming, generative AI, introductory programming education, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3706599.3720175,
author = {Wang, Yishu and Zhou, Fangyu and Han, Xiaokang and Yao, Kecheng and Li, Zhuying},
title = {FoodSage: Addressing Recognition Uncertainty in Automated Dietary Monitoring through Human-Robot Dialogue},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720175},
doi = {10.1145/3706599.3720175},
abstract = {This paper presents FoodSage, a robotic dietary monitoring system that addresses meal tracking challenges through human-robot dialogue. Unlike conventional approaches reliant on manual logging or fully automated recognition, FoodSage employs a human-in-the-loop methodology combining computer vision with natural conversation. A mobile robot autonomously navigates to dining locations and captures meal images using an onboard camera for automated food recognition. Recognition uncertainty is resolved by conversational verification, facilitated by a large language model (LLM). Through incremental learning, FoodSage incorporates user feedback to improve recognition and adapt to diverse eating scenarios. A pilot study with four participants demonstrates that FoodSage communicates effectively while achieving accurate food tracking. By functioning as both a food monitor and an eating companion, it reduces the burden of manual input, maintains high accuracy, and enriches the dining experience. This work contributes to dining monitoring by offering a human-in-the loop approach, ultimately supporting healthier eating habits.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {282},
numpages = {7},
keywords = {Human-in-the-loop, Incremental learning, Diet monitoring, LLM},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1109/ASP-DAC58780.2024.10473893,
author = {Wan, Lily Jiaxin and Huang, Yingbing and Li, Yuhong and Ye, Hanchen and Wang, Jinghua and Zhang, Xiaofan and Chen, Deming},
title = {Software/Hardware Co-Design for LLM and Its Application for Design Verification},
year = {2024},
isbn = {9798350393545},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASP-DAC58780.2024.10473893},
doi = {10.1109/ASP-DAC58780.2024.10473893},
abstract = {The widespread adoption of Large Language Models (LLMs) is impeded by their demanding compute and memory resources. The first task of this paper is to explore optimization strategies to expedite LLMs, including quantization, pruning, and operation-level optimizations. One unique direction is to optimize LLM inference through novel software/hardware co-design methods. Given the accelerated LLMs, the second task of this paper is to study LLMs' performance in the usage scenario of circuit design and verification. Specifically, we place a particular emphasis on functional verification. Through automated prompt engineering, we harness the capabilities of the established LLM, GPT-4, to generate High-Level Synthesis (HLS) designs with predefined errors based on 11 open-source synthesizable HLS benchmark suites. This dataset is a comprehensive collection of over 1000 function-level designs, and each of which is afflicted with up to 45 distinct combinations of defects injected into the source code. This dataset, named Chrysalis, expands upon what's available in current HLS error models, offering a rich resource for training to improve how LLMs debug code. The dataset can be accessed at: https://github.com/UIUC-ChenLab/Chrysalis-HLS.},
booktitle = {Proceedings of the 29th Asia and South Pacific Design Automation Conference},
pages = {435–441},
numpages = {7},
keywords = {large language models, software/hardware co-design, functional verification},
location = {Incheon, Republic of Korea},
series = {ASPDAC '24}
}

@inproceedings{10.1145/3691620.3695286,
author = {Adejumo, Elijah Kayode and Johnson, Brittany},
title = {Towards Leveraging LLMs for Reducing Open Source Onboarding Information Overload},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695286},
doi = {10.1145/3691620.3695286},
abstract = {Consistent, diverse, and quality contributions are essential to the sustainability of the open source community. Therefore, it is important that there is infrastructure for effectively onboarding and retaining diverse newcomers to open source software projects. Most often, open source projects rely on onboarding documentation to support newcomers in making their first contributions. Unfortunately, prior studies suggest that information overload from available documentation, along with the predominantly monolingual nature of repositories, can have negative effects on the newcomer experiences and onboarding process. This, coupled with the effort involved in creating and maintaining onboarding documentation, suggest a need for support in creating more accessible documentation. Large language models (LLMs) have shown great potential in providing text transformation support in other domains, and even shown promise in simplifying or generating other kinds of computing artifacts, such as source code and technical documentation. We contend that LLMs can also help make software onboarding documentation more accessible, thereby reducing the potential for information overload. Using ChatGPT (GPT-3.5 Turbo) and Gemini Pro as case studies, we assessed the effectiveness of LLMs for simplifying software onboarding documentation, one method for reducing information overload. We discuss a broader vision for using LLMs to support the creation of more accessible documentation and outline future research directions toward this vision.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2210–2214},
numpages = {5},
keywords = {open-source, software, on-boarding, generative AI, documentation, ChatGPT, LLMs},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3677052.3698614,
author = {Han, Shijie and Kang, Haoqiang and Jin, Bo and Liu, Xiao-Yang and Yang, Steve Y},
title = {XBRL Agent: Leveraging Large Language Models for Financial Report Analysis},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698614},
doi = {10.1145/3677052.3698614},
abstract = {eXtensible Business Reporting Language (XBRL) has attained the status of the global de facto standard for business reporting. However, its complexity poses significant barriers to interpretation and accessibility. In this paper, we present the first evaluation of large language models’ (LLMs) performance in analyzing XBRL reports. Our study identifies LLMs’ limitations in the comprehension of financial domain knowledge and mathematical calculation in the context of XBRL reports. To address these issues, we propose enhancement methods using external tools under the agent framework, referred to as XBRL-Agent, which invokes retrievers and calculators. Extensive experiments on two tasks - the Domain Query Task (which involved testing 500 XBRL term explanations and 50 domain questions) and the Numeric Type Query Task (tested 1,000 financial math tests and 50 numeric queries) - demonstrate substantial performance improvements, with accuracy increasing by up to 17% for the domain task and 42% for the numeric type task. This work not only explores the potential of LLMs for analyzing XBRL reports but also augments the reliability and robustness of such analysis, although there is still much room for improvement in mathematical calculations.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {856–864},
numpages = {9},
keywords = {Large language models (LLM), Semantic-augmented generation, XBRL reports},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@inproceedings{10.1145/3664647.3680750,
author = {Zhang, Jinxu and Yu, Yongqi and Zhang, Yu},
title = {CREAM: Coarse-to-Fine Retrieval and Multi-modal Efficient Tuning for Document VQA},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680750},
doi = {10.1145/3664647.3680750},
abstract = {Document Visual Question Answering (DVQA) involves responding to queries based on the contents of document images. Existing works are confined to locating information within a single page and lack support for cross-page question-and-answer interactions. Furthermore, the token length limitation on model inputs can lead to the truncation of answer-relevant segments. In this study, we present CREAM, an innovative methodology that focuses on high-performance retrieval and integrates relevant multimodal document information to effectively address this critical issue. To overcome the limitations of current text embedding similarity methods, we first employ a coarse-to-fine retrieval and ranking approach. The coarse phase calculates the similarity between the query and text chunk embeddings, while the fine phase involves multiple rounds of grouping and ordering with a large language model to identify the text chunks most relevant to the query. Subsequently, integrating an attention pooling mechanism for multi-page document images into the vision encoder allows us to effectively merge the visual information of multi-page documents, enabling the multimodal large language model (MLLM) to simultaneously process both single-page and multi-page documents. Finally, we apply various parameter-efficient tuning methods to enhance document visual question-answering performance. Experiments demonstrate that our approach secures state-of-the-art results across various document datasets.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {925–934},
numpages = {10},
keywords = {document vqa, large language model ranking, multi-page document representation, retrieval augmented generation},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3540250.3569444,
author = {Gulwani, Sumit},
title = {AI-assisted programming: applications, user experiences, and neuro-symbolic techniques (keynote)},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3569444},
doi = {10.1145/3540250.3569444},
abstract = {AI can enhance programming experiences for a diverse set of programmers: from professional developers and data scientists (proficient programmers) who need help in software engineering and data wrangling, all the way to spreadsheet users (low-code programmers) who need help in authoring formulas, and students (novice programmers) who seek hints when stuck with their programming homework. To communicate their need to AI, users can express their intent explicitly—as input-output examples or natural-language specification—or implicitly—where they encounter a bug (and expect AI to suggest a fix), or simply allow AI to observe their last few lines of code or edits (to have it suggest the next steps).  

The task of synthesizing an intended program snippet from the user’s intent is both a search and a ranking problem. Search is required to discover candidate programs that correspond to the (often ambiguous) intent, and ranking is required to pick the best program from multiple plausible alternatives. This creates a fertile playground for combining symbolic-reasoning techniques, which model the semantics of programming operators, and machine-learning techniques, which can model human preferences in programming. Recent advances in large language models like Codex offer further promise to advance such neuro-symbolic techniques.  

Finally, a few critical requirements in AI-assisted programming are usability, precision, and trust; and they create opportunities for innovative user experiences and interactivity paradigms. In this talk, I will explain these concepts using some existing successes, including the Flash Fill feature in Excel, Data Connectors in PowerQuery, and IntelliCode/CoPilot in Visual Studio. I will also describe several new opportunities in AI-assisted programming, which can drive the next set of foundational neuro-symbolic advances.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1},
numpages = {1},
keywords = {Symbolic Reasoning, Program Synthesis, Machine Learning, Interactive Programming},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@article{10.1145/3652154,
author = {Russo, Daniel},
title = {Navigating the Complexity of Generative AI Adoption in Software Engineering},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3652154},
doi = {10.1145/3652154},
abstract = {This article explores the adoption of Generative Artificial Intelligence (AI) tools within the domain of software engineering, focusing on the influencing factors at the individual, technological, and social levels. We applied a convergent mixed-methods approach to offer a comprehensive understanding of AI adoption dynamics. We initially conducted a questionnaire survey with 100 software engineers, drawing upon the Technology Acceptance Model, the Diffusion of Innovation Theory, and the Social Cognitive Theory as guiding theoretical frameworks. Employing the Gioia methodology, we derived a theoretical model of AI adoption in software engineering: the Human-AI Collaboration and Adaptation Framework. This model was then validated using Partial Least Squares–Structural Equation Modeling based on data from 183 software engineers. Findings indicate that at this early stage of AI integration, the compatibility of AI tools within existing development workflows predominantly drives their adoption, challenging conventional technology acceptance theories. The impact of perceived usefulness, social factors, and personal innovativeness seems less pronounced than expected. The study provides crucial insights for future AI tool design and offers a framework for developing effective organizational implementation strategies.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {135},
numpages = {50},
keywords = {Generative AI, large language models, technology adaption, empirical software engineering}
}

@inproceedings{10.1145/3626253.3635400,
author = {Hurley, Ethan and Okyere-Badoo, Joel},
title = {A Comparative Study of Few-Shot vs. Zero-Shot Prompting to Generate Quick and Useful Responses to Students' Periodic Reflections},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635400},
doi = {10.1145/3626253.3635400},
abstract = {Our study investigates the effectiveness of leveraging Large Language Models (LLMs), such as GPT-3.5, to generate responses to student reflections. Acknowledging the intensive nature of manually handling reflections, our investigation centers on crafting prompts to automate reflection response generation. Driven by fast and meaningful response generation to student reflections, we explored both Zero-Shot learning (ZSL) and Few-Shot learning (FSL) methodologies. Our research meticulously examined the facets of each approach, highlighting the significance of consistent and meaningful responses.The Few-Shot prompting approach involves creating a fundamental prompt based on reflection questions and desired responses, striving for consistency while facing challenges such as GPT-3.5 computational time and issues related to content "hallucinations." In contrast, Zero-Shot prompting utilizes the base prompt and response without the assistance of examples. The evaluation process entails a meticulous examination of the quality of GPT-3.5 responses compared to the original student reflections.In the future, our study foresees integrating our devised prompting techniques as a resource for educators to promptly grasp students' learning concerns and issues. Despite challenges, Few-Shot prompting stands out as the more reliable and relevant approach, particularly in the context of email-based formats. As Machine Learning and AI continue to advance, overcoming challenges and adjusting to fluctuations in student emotions and content remains a pivotal factor in fully harnessing the capabilities of LLMs for automating the generation of responses to student reflections.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1881},
numpages = {1},
keywords = {artificial intelligence (ai), few-shot learning (fsl), large language models (llms), student reflections, zero-shot learning (zsl)},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1177/26339137241305117,
author = {Heyman, Jennifer L and Rick, Steven R and Giacomelli, Gianni and Wen, Haoran and Laubacher, Robert J and Taubenslag, Nancy and Ragupathy, Pranav and Curhan, Jared and Malone, Thomas W and Knicker, Max Sina and Jeddi, Younes},
title = {Supermind Ideator: How scaffolding Human-AI collaboration can increase creativity},
year = {2024},
issue_date = {October-December 2024},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {3},
number = {4},
url = {https://doi.org/10.1177/26339137241305117},
doi = {10.1177/26339137241305117},
abstract = {Previous efforts to support creative problem-solving have included (a) techniques such as brainstorming and design thinking to stimulate creative ideas, and (b) software tools to record and share these ideas. Now, generative AI technologies can suggest new ideas that might never have occurred to the users, and users can then select from these ideas or use them to stimulate even more ideas. To explore these possibilities, we developed a system called Supermind Ideator that uses a large language model (LLM) and adds prompts, fine tuning, and a specialized user interface in order to help users reformulate their problem statements and generate possible solutions. This provides scaffolding to guide users through a set of creative problem-solving techniques, including some techniques specifically intended to help generate innovative ideas about designing groups of people and/or computers (“superminds”). In an experimental study, we found that people using Supermind Ideator generated significantly more innovative ideas than those generated by people using ChatGPT or people working alone. Thus our results suggest that the benefits of using LLMs for creative problem-solving can be substantially enhanced by scaffolding designed specifically for this purpose.},
journal = {Collective Intelligence},
month = dec,
numpages = {17},
keywords = {Creativity, innovation, collective intelligence, generative AI, scaffolding, large language models}
}

@inproceedings{10.1145/3715669.3726786,
author = {Mardanbegi, Diako and Hylands, Nicholas and Sarkar, Neil and Zahirovic, Nino},
title = {GazeLog: Optimizing Eye-Tracking with Fixation Keyframes &amp; LLM Insights},
year = {2025},
isbn = {9798400714870},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715669.3726786},
doi = {10.1145/3715669.3726786},
abstract = {Advancements in eye-tracking technology have greatly expanded our ability to study human visual and cognitive processes in naturalistic settings. This paper introduces a new pipeline for optimizing eye-tracking video data, aimed at enhancing computational efficiency and enabling deeper contextual analysis through the integration of Large Language Models (LLMs). We propose a method that selectively captures keyframes during moments of sustained attention, significantly reducing data volume while preserving essential information. This optimization is complemented by the use of LLMs for object identification and contextual interpretation of the visual data within these keyframes. Our approach addresses significant challenges such as the high storage demands and computational overhead associated with processing large video recordings. We demonstrate the feasibility of our method through a software prototype and preliminary testing on two 60-minute recordings. Our results suggest that meaningful information about a user’s gaze can be extracted and inferred by selectively capturing video based on fixation events, resulting in a data reduction equivalent to approximately 4-8 frames per minute on average. We argue that this approach has the potential to enable more effective and scalable gaze-tracking applications in real-world settings. Finally, we outline potential improvements to enhance reliability in dynamic scenes with moving objects.},
booktitle = {Proceedings of the 2025 Symposium on Eye Tracking Research and Applications},
articleno = {108},
numpages = {8},
keywords = {Gaze Tracking, Mobile Eye Tracking, Large Language Models, Video Summarization, Fixations, Context-Aware Computing, Object Recognition, Real-World Applications},
location = {
},
series = {ETRA '25}
}

@proceedings{10.1145/3664647,
title = {MM '24: Proceedings of the 32nd ACM International Conference on Multimedia},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to welcome you to Melbourne, Australia for ACM Multimedia 2024, the 32nd ACM International Conference on Multimedia. ACM Multimedia is the premier international conference series in the area of multimedia within the field of computer science. Since 1993, ACM Multimedia has been bringing together worldwide researchers and practitioners from academia and industry to present their innovative research and to discuss recent advancements in multimedia.For the first time since the end of the COVID-19 pandemic, this year's conference returns to the Asia-Pacific region and resumes as a full-fledged, inperson event. With no travel restrictions or significant visa challenges, we are excited to once again experience the warmth of face-to-face gatherings, where we can reconnect with colleagues and friends.The enthusiasm and support from the community have been incredible. ACM Multimedia 2024 received over 4,300 main conference submissions, accepting more than 1,100 papers (please refer to the TPC Chairs' message for details). In addition, 10 Grand Challenges were selected from 22 submissions, 18 workshops from 30 submissions, and 8 tutorials from 13 proposals. We've prepared an exciting five-day program: workshops, grand challenges, and tutorials will be held on the 1st and 5th days, with the main conference occupying the middle three days. All accepted papers will be accessible online prior to the conference, and we are working to ensure proceedings are available through the ACM Digital Library around the conference period.This year's conference features three distinguished academic keynote speeches, several prestigious SIGMM award talks, a panel discussion on Generative AI in Multimedia, a refreshed Brave New Idea (BNI) session, and our inaugural industry program.The opening keynote will be delivered by Prof. Pascale Fung from HKUST, a Fellow of AAAI, ACL, and IEEE. Her talk will explore the pressing topic of Agents in the Large Language Model (LLM) Era. Prof. Judy Kay from the University of Sydney, a renowned expert in HCI, user modeling, and ubiquitous computing, will give the second keynote on how to empower individuals to harness and control their multimodal data. The final academic keynote will be presented by Prof. Jiebo Luo from the University of Rochester, a Fellow of ACM, AAAI, IEEE, SPIE, and IAPR, as well as a member of Academia Europaea and the US National Academy of Inventors. He will discuss leveraging LLMs as social multimedia analysis engines.This year, we continue using OpenReview to ensure an open and transparent review process. Thanks to the exceptional efforts of the technical program committee, every paper received at least three reviews before the review announcement. The BNI track has also revamped its review process to align with the main conference, promoting visionary papers. Additionally, we are excited to introduce the industry program to ACM Multimedia for the first time, featuring industry keynote speeches, expert talks, and demonstrations (please refer to the industry chairs' message for further details).We are also committed to making the conference inclusive and accessible. To support students with financial constraints, we have awarded travel grants to at least 25 students from the ACM Multimedia 2024 budget, with an additional 20+ students receiving SIGMM travel grants. Over 20 local students have also been recruited as volunteers, benefiting from complimentary registration. Furthermore, we have arranged childcare facilities to accommodate attendees with young children. A welcome reception will take place on the 2nd day of the conference, followed by a gala dinner on the 3rd day, featuring exciting cultural performances.We hope you find this year's program engaging and thought-provoking and that it offers valuable opportunities to exchange ideas with fellow researchers and practitioners from around the globe. We also encourage you to take time to explore the beautiful city of Melbourne and its surrounding regions.},
location = {Melbourne VIC, Australia}
}

@inproceedings{10.1145/3636534.3690668,
author = {Laskaridis, Stefanos and Katevas, Kleomenis and Minto, Lorenzo and Haddadi, Hamed},
title = {MELTing Point: Mobile Evaluation of Language Transformers},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690668},
doi = {10.1145/3636534.3690668},
abstract = {Transformers have recently revolutionized the machine learning (ML) landscape, gradually making their way into everyday tasks and equipping our computers with "sparks of intelligence". However, their runtime requirements have prevented them from being broadly deployed on mobile. As personal devices become increasingly powerful at the consumer edge and prompt privacy becomes an ever more pressing issue, we explore the current state of mobile execution of Large Language Models (LLMs). To achieve this, we have created our own automation infrastructure, MELT, which supports the headless execution and benchmarking of LLMs on device, supporting different models, devices and frameworks, including Android, iOS and Nvidia Jetson devices. We evaluate popular instruction fine-tuned LLMs and leverage different frameworks to measure their end-to-end and granular performance, tracing their memory and energy requirements along the way.Our analysis is the first systematic study of on-device LLM execution, quantifying performance, energy efficiency and accuracy across various state-of-the-art models and showcases the state of on-device intelligence in the era of hyperscale models. Results highlight the performance heterogeneity across targets and corroborates that LLM inference is largely memory-bound. Quantization drastically reduces memory requirements and renders execution viable, but at a non-negligible accuracy cost. Drawing from its energy footprint and thermal behavior, the continuous execution of LLMs remains elusive, as both factors negatively affect user experience. Last, our experience shows that the ecosystem is still in its infancy, and algorithmic as well as hardware break-throughs can significantly shift the execution cost. We expect NPU acceleration, and framework-hardware co-design to be the biggest bet towards efficient standalone execution, with the alternative of offloading tailored towards edge deployments.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {890–907},
numpages = {18},
keywords = {machine learning, mobile systems, large language models},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@inproceedings{10.1145/3613905.3650868,
author = {Cai, Zhenyao and Park, Seehee and Nixon, Nia and Doroudi, Shayan},
title = {Advancing Knowledge Together: Integrating Large Language Model-based Conversational AI in Small Group Collaborative Learning},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650868},
doi = {10.1145/3613905.3650868},
abstract = {In today’s educational landscape, students learn collaboratively, where students benefit from both peer interactions and facilitator guidance. Prior research in Human-Computer Interaction (HCI) and Computer-Supported Collaborative Learning (CSCL) has explored chatbots and AI techniques to aid such collaboration. However, these methods often depend on predefined dialogues (which limits adaptability), are not based on collaborative learning theories, and do not fully recognize the learning context. In this paper, we introduce an Large Language Model (LLM)-powered conversational AI, designed to enhance small group learning through its advanced language understanding and generation capabilities. We detail the iterative design process, final design, and implementation. Our preliminary evaluation indicates that the bot performs as designed but points to considerations in the timing of interventions and bot’s role in discussions. The evaluation also reveals that learners perceive the bot’s tone and behavior as important for engagement. We discuss design implications for chatbot integration in collaborative learning and future research directions.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {37},
numpages = {9},
keywords = {AI facilitator, Collaborative Learning, Human-AI Collaboration},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@article{10.1145/3736654,
author = {Basnet, Animesh Singh and Ghanem, Mohamed Chahine and Dunsin, Dipo and Kheddar, Hamza and Sowinski-Mydlarz, Wiktor},
title = {Advanced Persistent Threats (APT) Attribution Using Deep Reinforcement Learning},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3736654},
doi = {10.1145/3736654},
abstract = {This paper investigates the application of Deep Reinforcement Learning (DRL) for attributing malware to specific Advanced Persistent Threat (APT) groups through detailed behavioural analysis. By analysing over 3,500 malware samples from 12 distinct APT groups, the study utilises sophisticated tools like Cuckoo Sandbox to extract behavioural data, providing a deep insight into the operational patterns of malware. The research demonstrates that the DRL model significantly outperforms traditional machine learning approaches such as SGD, SVC, KNN, MLP, and Decision Tree Classifiers, achieving an impressive test accuracy of 94.12%. It highlights the model's capability to adeptly manage complex, variable, and elusive malware attributes. Furthermore, the paper discusses the considerable computational resources and extensive data dependencies required for deploying these advanced AI models in cybersecurity frameworks. Future research is directed towards enhancing the efficiency of DRL models, expanding the diversity of the datasets, addressing ethical concerns, and leveraging Large Language Models (LLMs) to refine reward mechanisms and optimise the DRL framework. By showcasing the transformative potential of DRL in malware attribution, this research advocates for a responsible and balanced approach to AI integration, with the goal of advancing cybersecurity through more adaptable, accurate, and robust systems.},
note = {Just Accepted},
journal = {Digital Threats},
month = may,
keywords = {Advanced Persistent Threat (APT), Malware Attribution, AI, MDP, Deep Reinforcement Learning (DRL)}
}

@inproceedings{10.1145/3593342.3593360,
author = {Rajabi, Parsa and Taghipour, Parnian and Cukierman, Diana and Doleck, Tenzin},
title = {Exploring ChatGPT’s impact on post-secondary education: A qualitative study},
year = {2023},
isbn = {9798400707896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593342.3593360},
doi = {10.1145/3593342.3593360},
abstract = {As Chat Generative Pre-trained Transformer (ChatGPT) gains traction, its impact on post-secondary education is increasingly being debated. This qualitative study explores the perception of students and faculty members at a research university in Canada regarding ChatGPT’s use in a post-secondary setting, focusing on how it could be incorporated and what ways instructors can respond to this technology. We present the summary of a discussion that took place in a two-hour focus group session with 40 participants from the computer science and engineering departments, and highlight issues surrounding plagiarism, assessment methods, and the appropriate use of ChatGPT. Findings suggest that students are likely to use ChatGPT, but there is a need for specific guidelines, more classroom assessments, and mandatory reporting of ChatGPT use. The study contributes to the emergent research on ChatGPT in higher education and emphasizes the importance of proactively addressing challenges and opportunities associated with ChatGPT adoption and use.},
booktitle = {Proceedings of the 25th Western Canadian Conference on Computing Education},
articleno = {9},
numpages = {6},
keywords = {post-secondary, higher education, education, conversational AI, assessment, ChatGPT, Artificial Intelligence in education},
location = {Vancouver, BC, Canada},
series = {WCCCE '23}
}

@inproceedings{10.1145/3715014.3724368,
author = {Xuan, Ziyi and Wu, Yiwen and Yang, Yu},
title = {Demo Abstract: GIDEA: Generative AI-Powered Interactive Design and Evaluation Platform for Assistant Agent Research},
year = {2025},
isbn = {9798400714795},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715014.3724368},
doi = {10.1145/3715014.3724368},
abstract = {Conducting human-computer interaction (HCI) experiments often requires extensive manual effort, including configuring environments, recruiting participants, and recording interactions. We introduce GIDEA, a generative AI-powered interactive design and evaluation platform for assistant agents to streamline and accelerate HCI research. Our platform employs a three-role interaction pipeline, where researchers define experiments, large language model-driven avatars simulated participants, and a smart assistant agent moderates interactions. This pipeline dynamically generates interaction scenarios, avatar profiles, and adaptive responses based on researcher input. By integrating with Unity, GIDEA enables real-time monitoring and control over simulated experiments, providing researchers with an interactive and adaptable evaluation environment. Through the replication of real-world case studies, we demonstrate that GIDEA reduces the time and effort required for HCI experiments while producing results that align with real studies. This capability has the potential to revolutionize HCI research by transforming traditionally lengthy and labor-intensive processes into a highly efficient, scalable, and adaptive methodology, accelerating innovation and broadening experimental possibilities.},
booktitle = {Proceedings of the 23rd ACM Conference on Embedded Networked Sensor Systems},
pages = {704–705},
numpages = {2},
keywords = {assistant agent, user simulation, simulation-based experimentation, large language models, human-computer interaction},
location = {UC Irvine Student Center., Irvine, CA, USA},
series = {SenSys '25}
}

@inproceedings{10.1145/3581754.3584111,
author = {Cao, Chen},
title = {Scaffolding CS1 Courses with a Large Language Model-Powered Intelligent Tutoring System},
year = {2023},
isbn = {9798400701078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581754.3584111},
doi = {10.1145/3581754.3584111},
abstract = {Programming skills are rapidly becoming essential for many educational paths and career opportunities. Yet, for many international students, the traditional approach to teaching introductory programming courses can be a significant challenge due to the complexities of the language, the lack of prior programming knowledge, and the language and cultural barriers. This study explores how large language models and gamification can scaffold coding learning and increase Chinese students’ sense of belonging in introductory programming courses. In this project, a gamification intelligent tutoring system was developed to adapt to Chinese international students’ learning needs and provides scaffolding to support their success in introductory computer programming courses. My research includes three studies: a formative study, a user study of an initial prototype, and a computer simulation study with a user study in progress. Both qualitative and quantitative data were collected through surveys, observations, focus group discussions and computer simulation. The preliminary findings suggest that GPT-3-enhanced gamification has great potential in scaffolding introductory programming learning by providing adaptive and personalised feedback, increasing students’ sense of belonging, and reducing their anxiety about learning programming.},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {229–232},
numpages = {4},
location = {Sydney, NSW, Australia},
series = {IUI '23 Companion}
}

@inproceedings{10.1145/3672758.3672766,
author = {Zeng, Juntao and Chen, Bo and Deng, Yuandan and Chen, Weiqin and Mao, Yanlin and Li, Jiawei},
title = {Fine-tuning of financial Large Language Model and application at edge device},
year = {2024},
isbn = {9798400716942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672758.3672766},
doi = {10.1145/3672758.3672766},
abstract = {Large Language Model (LLM), particularly conversational models, have garnered significant attention in recent years, owing to their novel approaches to human-computer interaction and natural language processing tasks for individuals or organizations. Against the backdrop of private computing becoming a prevailing trend, the training, fine-tuning, and application of private large models have become exceptionally challenging. This study aims to delve into how fine-tuning LLM for vertical domain applications, in conjunction with edge device, facilitates innovative applications of LLMs in private and vertical domains. We fine-tuned the BaiChuan-2-7b-chat model, specifically enhancing its reasoning capabilities in the financial domain. Through comparative analysis of benchmark datasets, the fine-tuned model exhibited a 2% increase in average response accuracy across various financial domains. Furthermore, we implemented the fine-tuned model on both central computing infrastructure and edge devices, undertaking a comprehensive investigation into the model's inference efficiency and nuanced power consumption across diverse hardware platforms. Comparative analyses unveiled that the deployment of personalized Language Model Machines (LLMs) on edge devices yields superior cost-effectiveness.},
booktitle = {Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering},
pages = {42–47},
numpages = {6},
location = {Xi' an, China},
series = {CAICE '24}
}

@inproceedings{10.1145/3658617.3697645,
author = {Xu, Jiaming and Li, Jinhao and Liu, Jun and Zhou, Hao and Dai, Guohao},
title = {Accelerator for LLM-Enhanced GNN with Product Quantization and Unified Indexing},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697645},
doi = {10.1145/3658617.3697645},
abstract = {To alleviate the vulnerability of graph neural networks (GNNs) on unseen graphs, many works propose to integrate large language models (LLMs) into GNNs, called graph foundation models (GFMs). The LLM-enhanced GNN, a typical integration method of GFMs, has achieved state-of-the-art performance in most graph-related tasks. However, intensive general matrix multiplications (GEMMs) overhead of LLMs poses a significant challenge to end-to-end inference latency. The introduction of LLMs brings 100\texttimes{} more workload than original GNNs, with GEMMs accounting for more than 99%, becoming the bottleneck of end-to-end inference.To tackle the above challenge, we present GFMEngine, an algorithm and hardware co-design accelerator supporting LLM-enhanced GNNs at multiple levels. (1) At the algorithm level, we point out that the computational precision of LLMs has little impact on the end-to-end accuracy, and propose a product-quantization-based (PQ-based) matrix multiplication for LLMs to alleviate the intensive GEMMs in LLMs, reducing more than 70% computation with negligible accuracy loss. (2) At the hardware level, we point out that the implementation of PQ-based matrix multiplication effectively alleviates the intensive GEMMs but results in a substantial increase in dynamic memory access. Coupled with the dynamic memory access inherent in GNNs, we design a unified indexing unit as the hardware support, reducing ~ 30% memory access in end-to-end inference. (3) At the compilation level, we further design an extensible instruction set architecture as the software support, GFM-ISA, for various real-world GFM tasks. We implement GFMEngine with TSMC 28nm process, and extensive experiments show that GFMEngine achieves up to 3.93\texttimes{}, 38.66\texttimes{}, 22.32\texttimes{}, 2.96\texttimes{} speedup and up to 102.52\texttimes{}, 37.82\texttimes{}, 28.37\texttimes{}, 2.56\texttimes{} energy efficiency improvement compared with NVIDIA Tesla A100 and the domain-specific accelerators, SGCN, MEGA, FACT, respectively.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {534–540},
numpages = {7},
location = {Tokyo, Japan},
series = {ASPDAC '25}
}

@inproceedings{10.1145/3633053.3633057,
author = {Petrovska, Olga and Clift, Lee and Moller, Faron and Pearsall, Rebecca},
title = {Incorporating Generative AI into Software Development Education},
year = {2024},
isbn = {9798400709326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633053.3633057},
doi = {10.1145/3633053.3633057},
abstract = {This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools “doing the homework”.},
booktitle = {Proceedings of the 8th Conference on Computing Education Practice},
pages = {37–40},
numpages = {4},
keywords = {apprenticeship, assessment, education, generative AI, software engineering},
location = {Durham, United Kingdom},
series = {CEP '24}
}

@inproceedings{10.1145/3663548.3675605,
author = {Kodandaram, Satwik Ram and Uckun, Utku and Bi, Xiaojun and Ramakrishnan, IV and Ashok, Vikas},
title = {Enabling Uniform Computer Interaction Experience for Blind Users through Large Language Models},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3675605},
doi = {10.1145/3663548.3675605},
abstract = {Blind individuals, who by necessity depend on screen readers to interact with computers, face considerable challenges in navigating the diverse and complex graphical user interfaces of different computer applications. The heterogeneity of various application interfaces often requires blind users to remember different keyboard combinations and navigation methods to use each application effectively. To alleviate this significant interaction burden imposed by heterogeneous application interfaces, we present&nbsp;Savant, a novel assistive technology powered by large language models (LLMs) that allows blind screen reader users to interact uniformly with any application interface through natural language. Novelly, Savant can automate a series of tedious screen reader actions on the control elements of the application when prompted by a natural language command from the user. These commands can be flexible in the sense that the user is not strictly required to specify the exact names of the control elements in the command. A user study evaluation of&nbsp;Savant with 11 blind participants demonstrated significant improvements in interaction efficiency and usability compared to current practices.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {73},
numpages = {14},
keywords = {Accessibility, Assistive technology, Blind users, Computer Interaction, Large language models (LLMs), Uniform interaction},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@inproceedings{10.1145/3637528.3671573,
author = {Kuang, Weirui and Qian, Bingchen and Li, Zitao and Chen, Daoyuan and Gao, Dawei and Pan, Xuchen and Xie, Yuexiang and Li, Yaliang and Ding, Bolin and Zhou, Jingren},
title = {FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671573},
doi = {10.1145/3637528.3671573},
abstract = {Large language models (LLMs) have demonstrated great capabilities in various natural language understanding and generation tasks. These pre-trained LLMs can be further improved for specific downstream tasks by fine-tuning. However, the adoption of LLM in real-world applications can be hindered by privacy concerns and the resource-intensive nature of model training and fine-tuning. When multiple entities have similar interested tasks but cannot directly share their local data due to privacy regulations, federated learning (FL) is a mainstream solution to leverage the data of different entities. Besides avoiding direct data sharing, FL can also achieve rigorous data privacy protection, model intelligent property protection, and model customization via composition with different techniques. Despite the aforementioned advantages of FL, fine-tuning LLMs in FL settings still lacks adequate support from the existing frameworks and, therefore, faces challenges in optimizing the consumption of significant communication and computational resources, preparing various data for different tasks, and satisfying diverse information protection demands. In this paper, we discuss these challenges and introduce our package FederatedScope-LLM (FS-LLM) as a main contribution, which consists: (1) We build a complete end-to-end benchmarking pipeline under real-world scenarios, automizing the processes of dataset preprocessing, federated fine-tuning execution or simulation, and performance evaluation; (2) We provide comprehensive and off-the-shelf federated parameter-efficient fine-tuning (PEFT) algorithm implementations and versatile programming interfaces for future extension, enhancing the capabilities of LLMs in FL scenarios with low communication and computation costs, even without accessing the full model; (3) We adopt several accelerating and resource-efficient operators, and provide flexible pluggable sub-routines for interdisciplinary study. We conduct extensive and reproducible experiments to show the effectiveness of FS-LLM and benchmark advanced LLMs with PEFT algorithms in FL. We release FS-LLM at https://github.com/alibaba/FederatedScope/tree/llm.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5260–5271},
numpages = {12},
keywords = {benchmark, federated learning, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3627673.3679821,
author = {Wang, Haoran and Shu, Kai},
title = {Trojan Activation Attack: Red-Teaming Large Language Models using Steering Vectors for Safety-Alignment},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679821},
doi = {10.1145/3627673.3679821},
abstract = {To ensure AI safety, instruction-tuned Large Language Models (LLMs) are specifically trained to ensure alignment, which refers to making models behave in accordance with human intentions. While these models have demonstrated commendable results on various safety benchmarks, the vulnerability of their safety alignment has not been extensively studied. This is particularly troubling given the potential harm that LLMs can inflict. Existing attack methods on LLMs often rely on poisoned training data or the injection of malicious prompts. These approaches compromise the stealthiness and generalizability of the attacks, making them susceptible to detection. Additionally, these models often demand substantial computational resources for implementation, making them less practical for real-world applications. In this work, we study a different attack scenario, called Trojan Activation Attack (TA2), which injects trojan steering vectors into the activation layers of LLMs. These malicious steering vectors can be triggered at inference time to steer the models toward attacker-desired behaviors by manipulating their activations. Our experiment results on four primary alignment tasks show that TA2 is highly effective and adds little or no overhead to attack efficiency. Additionally, we discuss potential countermeasures against such activation attacks.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2347–2357},
numpages = {11},
keywords = {activation steering, large language model, trojan attack},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3679659,
author = {Huang, Yubo and Zeng, Guosun},
title = {RD-P: A Trustworthy Retrieval-Augmented Prompter with Knowledge Graphs for LLMs},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679659},
doi = {10.1145/3627673.3679659},
abstract = {Large Language Models (LLMs) face challenges due to hallucination issues. Current solutions use retrieval-augmented generation (RAG), integrating LLMs with external knowledge to enhance answer accuracy. However, the misuse of irrelevant external knowledge can be misleading. In this paper, we propose a novel method called Retrieve-and-Discriminate Prompter (RD-P), which leverages knowledge graphs (KGs) for trustworthy RAG by synchronizing knowledge retrieval and discrimination in a unified model. Specifically, we train a prompter based on a pre-trained language model with shared parameters. It has two key modules: the retriever and the discriminator. The retriever identifies relevant reasoning paths in the KG, while the discriminator evaluates their credibility through "logical coverage calculation" and in turn instructs the retrieval process. Prompts are then constructed to guide LLMs in reasoning and answering questions using both retrieved and implicit knowledge. Experiments on knowledge-intensive question answering (QA) tasks demonstrate that our method significantly improves answer coverage rate while reducing the retrieval scale, achieving superior performance in complex KGQA tasks compared with state-of-the-art RAG methods at a low cost.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {942–952},
numpages = {11},
keywords = {kgqa, large language models, prompter, retrieval-augmented generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3636555.3636853,
author = {Singh, Anjali and Brooks, Christopher and Wang, Xu and Li, Warren and Kim, Juho and Wilson, Deepti},
title = {Bridging Learnersourcing and AI: Exploring the Dynamics of Student-AI Collaborative Feedback Generation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636853},
doi = {10.1145/3636555.3636853},
abstract = {This paper explores the space of optimizing feedback mechanisms in complex domains such as data science, by combining two prevailing approaches: Artificial Intelligence (AI) and learnersourcing. Towards addressing the challenges posed by each approach, this work compares traditional learnersourcing with an AI-supported approach. We report on the results of a randomized controlled experiment conducted with 72 Master’s level students in a data visualization course, comparing two conditions: students writing hints independently versus revising hints generated by GPT-4. The study aimed to evaluate the quality of learnersourced hints, examine the impact of student performance on hint quality, gauge learner preference for writing hints with versus without AI support, and explore the potential of the student-AI collaborative exercise in fostering critical thinking about LLMs. Based on our findings, we provide insights for designing learnersourcing activities leveraging AI support and optimizing students’ learning as they interact with LLMs.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {742–748},
numpages = {7},
keywords = {Data Visualization, Feedback Generation, GPT-4, Learnersourcing},
location = {Kyoto, Japan},
series = {LAK '24}
}

@article{10.1145/3712709,
author = {Ataguba, Grace and Orji, Rita},
title = {Exploring Large Language Models for Personalized Recipe Generation and Weight-Loss Management},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
url = {https://doi.org/10.1145/3712709},
doi = {10.1145/3712709},
abstract = {The emergence of large language models (LLMs) is transforming various health-related domains, including approaches to obesity management. Obesity remains one of the world’s leading health issues, prompting the research community to develop various weight-loss applications focused on physical activity, dietary planning, and related interventions. In this study, we explore the capability of the LLM ChatGPT for personalized dietary planning. We conducted two case studies: Case Study 1 examined self-supervised recipe generation using ChatGPT alone, while Case Study 2 investigated a self-supervised approach combining National Institute of Health standards with ChatGPT recipe recommendations. We also performed a user study to evaluate recipe recommendations from ChatGPT. Our results show that ChatGPT recommends appropriate recipes based on comparisons with the United States Department of Agriculture’s (USDA) recipe calculator. We found no significant difference between ChatGPT-generated recipe recommendation calories and USDA standards for either Case Study 1 (p = 0.8530) or Case Study 2 (p = 0.0687). In addition, we found significant weight loss in participants following these recipes in both Case Study 1 (p &lt; 0.00001) and Case Study 2 (p = 0.0014). Furthermore, the user study with potential weight-loss participants revealed varying levels of satisfaction (p = 0.001) and identified themes related to meal preferences, effective prompt generation, and mixed concerns regarding privacy, trust, user consent, and data storage. We conclude by discussing additional findings from our case and user studies, and present opportunities, challenges, and design and ethical considerations for the research community.},
journal = {ACM Trans. Comput. Healthcare},
month = apr,
articleno = {22},
numpages = {57},
keywords = {large language model, obesity, weight loss, ChatGPT, recipes, diet plan}
}

@inproceedings{10.1145/3651890.3672265,
author = {Qian, Kun and Xi, Yongqing and Cao, Jiamin and Gao, Jiaqi and Xu, Yichi and Guan, Yu and Fu, Binzhang and Shi, Xuemei and Zhu, Fangbo and Miao, Rui and Wang, Chao and Wang, Peng and Zhang, Pengcheng and Zeng, Xianlong and Ruan, Eddie and Yao, Zhiping and Zhai, Ennan and Cai, Dennis},
title = {Alibaba HPN: A Data Center Network for Large Language Model Training},
year = {2024},
isbn = {9798400706141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651890.3672265},
doi = {10.1145/3651890.3672265},
abstract = {This paper presents HPN, Alibaba Cloud's data center network for large language model (LLM) training. Due to the differences between LLMs and general cloud computing (e.g., in terms of traffic patterns and fault tolerance), traditional data center networks are not well-suited for LLM training. LLM training produces a small number of periodic, bursty flows (e.g., 400Gbps) on each host. This characteristic of LLM training predisposes Equal-Cost Multi-Path (ECMP) to hash polarization, causing issues such as uneven traffic distribution. HPN introduces a 2-tier, dual-plane architecture capable of interconnecting 15K GPUs within one Pod, typically accommodated by the traditional 3-tier Clos architecture. Such a new architecture design not only avoids hash polarization but also greatly reduces the search space for path selection. Another challenge in LLM training is that its requirement for GPUs to complete iterations in synchronization makes it more sensitive to singlepoint failure (typically occurring on ToR). HPN proposes a new dual-ToR design to replace the single-ToR in traditional data center networks. HPN has been deployed in our production for more than eight months. We share our experience in designing, and building HPN, as well as the operational lessons of HPN in production.},
booktitle = {Proceedings of the ACM SIGCOMM 2024 Conference},
pages = {691–706},
numpages = {16},
keywords = {network architecture, AI infrastructure, large language model, model training, data center networks},
location = {Sydney, NSW, Australia},
series = {ACM SIGCOMM '24}
}

@inproceedings{10.1145/3643991.3644895,
author = {Storey, Margaret Anne D},
title = {Questioning the questions we ask about the impact of AI on software engineering},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644895},
doi = {10.1145/3643991.3644895},
abstract = {The recent advent and wide diffusion of generative AI has initiated a fundamental change in how software is developed. This technology is just one innovation along a long arc of disruptions in software engineering that include the internet, high-level programming languages, integrated development environments, open source, agile development, and social coding environments. Disruptive technologies such as these show the potential to augment and accelerate development activities along many socio-technical dimensions, while altering fundamental business processes and paradigms. Yet paradoxically, these innovations have the potential to eventually undermine the very advancements they seek to promote, rendering technologies and methods obsolete [1].When any new disruptive technology emerges, successful software companies that traditionally respond well to incremental innovations often fail when they suffer from inertia to change or don't anticipate how people will interact with the new technology. Similarly, researchers constrained by rigid research discipline can be slow to react, and may fail to recognize important and urgent societal and industrial needs. Researchers and companies alike may struggle in knowing which metrics to use and even how to measure the impact of change, further misleading their efforts to adapt.In this talk, I question the way we select research questions in software engineering and how we study them, particularly in the face of innovations such as generative AI. To provoke a change in our research, I introduce a disruptive playbook to steer us towards broader and more novel research directions. This step-by-step playbook is first illustrated by applying it to a prior disruptive technology, Stack Overflow. I will discuss how the playbook provides a new lens for reflecting on this body of research and how doing so reveals new insights. I then use the playbook, assisted with a customized research playbook GPT, to brainstorm and frame new research directions about the emerging disruptive innovations in software engineering that are being built on top of generative AI.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {530},
numpages = {1},
keywords = {software engineering, disruptive innovations, playbook, research questions},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3685767.3685777,
author = {Abdalla, Hemn Barzan and Awlla, Ardalan Hussein and Kumar, Yulia and Cheraghy, Maryam},
title = {Big Data: Past, Present, and Future Insights},
year = {2024},
isbn = {9798400709609},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3685767.3685777},
doi = {10.1145/3685767.3685777},
abstract = {This paper presents a comprehensive analysis of the historical progression, current trends, and prospects of Big Data. It explores the technological advancements that have established Big Data as a critical element of contemporary analytics, its extensive impact across various sectors, and the ethical challenges it poses. Beginning with the early recognition of Big Data's potential in the 2000s, the paper traces the development of foundational technologies such as Hadoop and the subsequent diversification of tools and methods. It delves into the integration of advanced analytics and machine learning, the rise of cloud-based Big Data services, and the transformative effects on sectors including healthcare, finance, agriculture, and education. The study also examines ethical considerations such as privacy, bias, transparency, and regulatory compliance, emphasizing the need for robust governance frameworks. It investigates the potential of emerging technologies like AI, IoT, and quantum computing to enhance Big Data capabilities further. It highlights future directions, including decentralized data ecosystems, advanced analytical techniques, and enhanced data privacy measures. By providing a panoramic view of Big Data's development, this paper aims to showcase its potential to revolutionize decision-making processes, improve operational efficiency, and drive innovation across industries; it underscores the importance of balancing technological innovation with ethical responsibility to ensure positive societal advancement and global progress. To add a novelty to the discussion, an AI agent Big D was created to provide a relevant analysis of trends in Big Data. The agent uses a multimodal ChatGPT-4o Large Language Model (LLM) from OpenAI and provides its review based on uploaded files and LLM knowledge.},
booktitle = {Proceedings of the 2024 Asia Pacific Conference on Computing Technologies, Communications and Networking},
pages = {60–70},
numpages = {11},
location = {Chengdu, China},
series = {CTCNet '24}
}

@inproceedings{10.1145/3689031.3696098,
author = {Yao, Jiayi and Li, Hanchen and Liu, Yuhan and Ray, Siddhant and Cheng, Yihua and Zhang, Qizheng and Du, Kuntai and Lu, Shan and Jiang, Junchen},
title = {CacheBlend: Fast Large Language Model Serving for RAG with Cached Knowledge Fusion},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689031.3696098},
doi = {10.1145/3689031.3696098},
abstract = {Large language models (LLMs) often incorporate multiple text chunks in their inputs to provide the necessary contexts. To speed up the prefill of the long LLM inputs, one can pre-compute the KV cache of a text and re-use the KV cache when the context is reused as the prefix of another LLM input. However, the reused text chunks are not always the input prefix, which makes precomputed KV caches not directly usable since they ignore the text's cross-attention with the preceding texts. Thus, the benefits of reusing KV caches remain largely unrealized.This paper tackles just one challenge: when an LLM input contains multiple text chunks, how to quickly combine their precomputed KV caches in order to achieve the same generation quality as the expensive full prefill (i.e., without reusing KV cache)? This challenge naturally arises in retrieval-augmented generation (RAG) where the input is supplemented with multiple retrieved texts as the context. We present CacheBlend, a scheme that reuses the precomputed KV caches, regardless prefix or not, and selectively recomputes the KV values of a small subset of tokens to partially update each reused KV cache. In the meantime, the small extra delay for recomputing some tokens can be pipelined with the retrieval of KV caches within the same job, allowing CacheBlend to store KV caches in slower devices with more storage capacity while retrieving them without increasing the inference delay. By comparing CacheBlend with the state-of-the-art KV cache reusing schemes on three open-source LLMs of various sizes and four popular benchmark datasets of different tasks, we show that CacheBlend reduces time-to-first-token (TTFT) by 2.2-3.3\texttimes{} and increases the inference throughput by 2.8-5\texttimes{} from full KV recompute without compromising generation quality. The code is available at https://github.com/LMCache/LMCache.},
booktitle = {Proceedings of the Twentieth European Conference on Computer Systems},
pages = {94–109},
numpages = {16},
keywords = {KV Cache, Large Language Models, Retrieval-Augmented-Generation},
location = {Rotterdam, Netherlands},
series = {EuroSys '25}
}

@inproceedings{10.1145/3643562.3672611,
author = {Heyman, Jennifer L and Rick, Steven R and Giacomelli, Gianni and Wen, Haoran and Laubacher, Robert and Taubenslag, Nancy and Knicker, Max and Jeddi, Younes and Ragupathy, Pranav and Curhan, Jared and Malone, Thomas},
title = {Supermind Ideator: How Scaffolding Human-AI Collaboration Can Increase Creativity},
year = {2024},
isbn = {9798400705540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643562.3672611},
doi = {10.1145/3643562.3672611},
abstract = {Previous efforts to support creative problem-solving have included (a) techniques such as brainstorming and design thinking to stimulate creative ideas, and (b) software tools to record and share these ideas. Now, generative AI technologies can suggest new ideas that might never have occurred to the users, and users can then select from these ideas or use them to stimulate even more ideas. To explore these possibilities, we developed a system called Supermind Ideator that uses a large language model (LLM) and adds prompts, fine tuning, and a specialized user interface in order to help users reformulate their problem statements and generate possible solutions. This provides scaffolding to guide users through a set of creative problem-solving techniques, including some techniques specifically intended to help generate innovative ideas about designing groups of people and/or computers (“superminds”). In an experimental study, we found that people using Supermind Ideator generated significantly more innovative ideas than those generated by people using ChatGPT or people working alone. Thus our results suggest that the benefits of using LLMs for creative problem-solving can be substantially enhanced by scaffolding designed specifically for this purpose.},
booktitle = {Proceedings of the ACM Collective Intelligence Conference},
pages = {18–28},
numpages = {11},
keywords = {Collective Intelligence, Creativity, Generative AI, Innovation, Large Language Models, Scaffolding},
location = {Boston, MA, USA},
series = {CI '24}
}

@inproceedings{10.1145/3701268.3701273,
author = {Conway, Brian and Nolan, Keith and Quille, Keith},
title = {HCAI Block Model: A competence model for Human Centred Artificial Intelligence at K-12},
year = {2024},
isbn = {9798400711596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701268.3701273},
doi = {10.1145/3701268.3701273},
abstract = {Artificial Intelligence (AI) is becoming a common topic within the computing K-12 curricula worldwide. While much of the focus of research is on the use of Generative AI in and for education, AI as a core subject area is still gaining popularity, with much of this research focusing on content and tools that effectively support the teaching of AI. However, as we grow as a field, there is a need currently unmet to provide foundations (in the form of a block model as there exists for programming) to allow researchers to build strong pedagogies and methodologies from, and even a base to design activities and content. Compounding this, as ethics and its relationship to AI in the K-12 classroom grows stronger, there is a further need to provide scaffolding to educators and researchers not only on traditional AI concepts, but also on how they link with ethical knowledge, skills and dispositions. In this paper, the Human Centered Artificial Intelligence (HCAI) Block Model is developed and introduced. This is a competence-based model to guide effective teaching and learning of Human Centered Artificial Intelligence, as well as research in the K-12 space. The HCAI Block model’s foundation is developed/adapted from the programming Block model and has been adapted and developed using two lenses. The first was through the data science lens through interaction with Computational Thinking 2.0 and competency-based learning. The second lens was through a human-centred lens. The outcome was a ground-up K-12 model where traditional and technical AI concepts have been developed from the start, integrating ethical considerations and human-centred approaches.},
booktitle = {Proceedings of the 2024 Conference on Human Centred Artificial Intelligence - Education and Practice},
pages = {22–28},
numpages = {7},
keywords = {Computing Education, Machine Learning, Human-Centered AI, Block Model, Ethics, Computational Thinking 2.0},
location = {
},
series = {HCAIep '24}
}

@inproceedings{10.1109/SC41406.2024.00076,
author = {Giordani, Jeremiah and Xu, Ziyang and Colby, Ella and Ning, August and Godala, Bhargav Reddy and Chaturvedi, Ishita and Zhu, Shaowei and Chon, Yebin and Chan, Greg and Tan, Zujun and Collier, Galen and Halverson, Jonathan D. and Deiana, Enrico Armenio and Liang, Jasper and Sossai, Federico and Su, Yian and Patel, Atmn and Pham, Bangyen and Greiner, Nathan and Campanoni, Simone and August, David I.},
title = {Revisiting Computation for Research: Practices and Trends},
year = {2024},
isbn = {9798350352917},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC41406.2024.00076},
doi = {10.1109/SC41406.2024.00076},
abstract = {In the field of computational science, effectively supporting researchers necessitates a deep understanding of how they utilize computational resources. Building upon a decade-old survey that explored the practices and challenges of research computation, this study aims to bridge the understanding gap between providers of computational resources and researchers who rely on them. This study revisits key survey questions and gathers feedback on open-ended topics from over a hundred interviews. Quantitative analyses of present and past results illuminate the landscape of research computation. Qualitative analyses, including careful use of large language models, highlight trends and challenges with concrete evidence. Given the rapid evolution of computational science, this paper offers a toolkit with methodologies and insights to simplify future research and ensure ongoing examination of the landscape. This study, with its findings and toolkit, guides enhancements to computational systems, deepens understanding of user needs, and streamlines reassessment of the computational landscape.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {70},
numpages = {14},
location = {Atlanta, GA, USA},
series = {SC '24}
}

@inproceedings{10.1145/3651890.3672239,
author = {Cao, Jiamin and Guan, Yu and Qian, Kun and Gao, Jiaqi and Xiao, Wencong and Dong, Jianbo and Fu, Binzhang and Cai, Dennis and Zhai, Ennan},
title = {Crux: GPU-Efficient Communication Scheduling for Deep Learning Training},
year = {2024},
isbn = {9798400706141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651890.3672239},
doi = {10.1145/3651890.3672239},
abstract = {Deep learning training (DLT), e.g., large language model (LLM) training, has become one of the most important services in multitenant cloud computing. By deeply studying in-production DLT jobs, we observed that communication contention among different DLT jobs seriously influences the overall GPU computation utilization, resulting in the low efficiency of the training cluster. In this paper, we present Crux, a communication scheduler that aims to maximize GPU computation utilization by mitigating the communication contention among DLT jobs. Maximizing GPU computation utilization for DLT, nevertheless, is NP-Complete; thus, we formulate and prove a novel theorem to approach this goal by GPU intensity-aware communication scheduling. Then, we propose an approach that prioritizes the DLT flows with high GPU computation intensity, reducing potential communication contention. Our 96-GPU testbed experiments show that Crux improves 8.3% to 14.8% GPU computation utilization. The large-scale production trace-based simulation further shows that Crux increases GPU computation utilization by up to 23% compared with alternatives including Sincronia, TACCL, and CASSINI.},
booktitle = {Proceedings of the ACM SIGCOMM 2024 Conference},
pages = {1–15},
numpages = {15},
keywords = {communication scheduling, data center network, deep learning},
location = {Sydney, NSW, Australia},
series = {ACM SIGCOMM '24}
}

@inproceedings{10.1145/3597503.3639223,
author = {Imran, Mia Mohammad and Chatterjee, Preetha and Damevski, Kostadin},
title = {Uncovering the Causes of Emotions in Software Developer Communication Using Zero-shot LLMs},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639223},
doi = {10.1145/3597503.3639223},
abstract = {Understanding and identifying the causes behind developers' emotions (e.g., Frustration caused by 'delays in merging pull requests') can be crucial towards finding solutions to problems and fostering collaboration in open-source communities. Effectively identifying such information in the high volume of communications across the different project channels, such as chats, emails, and issue comments, requires automated recognition of emotions and their causes. To enable this automation, large-scale software engineering-specific datasets that can be used to train accurate machine learning models are required. However, such datasets are expensive to create with the variety and informal nature of software projects' communication channels.In this paper, we explore zero-shot LLMs that are pre-trained on massive datasets but without being fine-tuned specifically for the task of detecting emotion causes in software engineering: ChatGPT, GPT-4, and flan-alpaca. Our evaluation indicates that these recently available models can identify emotion categories when given detailed emotions, although they perform worse than the top-rated models. For emotion cause identification, our results indicate that zero-shot LLMs are effective at recognizing the correct emotion cause with a BLEU-2 score of 0.598. To highlight the potential use of these techniques, we conduct a case study of the causes of Frustration in the last year of development of a popular open-source project, revealing several interesting insights.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {182},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3640471.3680460,
author = {Munteanu, Cosmin and Sarcar, Sayan and Sin, Jaisie and Wei, Christina Ziying and Sayago, Sergio and Zhao, Wei and Waycott, Jenny},
title = {Designing Age-Inclusive Interfaces: Emerging Mobile, Conversational, and Generative AI to Support Interactions across the Life Span},
year = {2024},
isbn = {9798400705069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640471.3680460},
doi = {10.1145/3640471.3680460},
abstract = {We are concurrently witnessing two significant shifts: voice and chat-based conversational user interfaces (CUIs) are becoming ubiquitous (especially more recently due to advances in generative AI and LLMs - large language models), and older people are becoming a very large demographic group (and increasingly adopting of mobile technology on which such interfaces are present). However, despite the recent increase in research activity, age-relevant and inter/cross-generational aspects continue to be underrepresented in both research and commercial product design. Therefore, the overarching aim of this workshop is to increase the momentum for research within the space of hands-free, mobile, and conversational interfaces that centers on age-relevant and inter- and cross-generational interaction. For this, we plan to create an interdisciplinary space that brings together researchers, designers, practitioners, and users, to discuss and share challenges, principles, and strategies for designing such interfaces across the life span. We thus welcome contributions of empirical studies, theories, design, and evaluation of hands-free, mobile, and conversational interfaces designed with aging in mind (e.g. older adults or inter/cross-generational). We particularly encourage contributions focused on leveraging recent advances in generative AI or LLMs. Through this, we aim to grow the community of CUI researchers across disciplinary boundaries (human-computer interaction, voice and language technologies, geronto-technologies, information studies, etc.) that are engaged in the shared goal of ensuring that the aging dimension is appropriately incorporated in mobile / conversational interaction design research.},
booktitle = {Adjunct Proceedings of the 26th International Conference on Mobile Human-Computer Interaction},
articleno = {32},
numpages = {5},
location = {Melbourne, VIC, Australia},
series = {MobileHCI '24 Adjunct}
}

@inproceedings{10.1109/SCW63240.2024.00015,
author = {Pandey, Dhroov and Ghebremichael, Jonah and Qi, Zongqing and Shu, Tong},
title = {A Comparative Survey: Reusing Small Pre-Trained Models for Efficient Large Model Training},
year = {2025},
isbn = {9798350355543},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SCW63240.2024.00015},
doi = {10.1109/SCW63240.2024.00015},
abstract = {Training large language models is becoming increasingly complex due to the rapid expansion in their size, resulting in significant computational costs. To address this challenge, various model growth methodologies have been proposed to leverage smaller pre-trained models to incrementally build larger models and reduce computational requirements. These methods typically involve mapping parameters from small models to large ones using either static functions or learned mappings. Although these approaches have demonstrated effectiveness, there is a lack of comprehensive comparative evaluations in the literature. Additionally, combining different methodologies could potentially yield superior performance. This study provides a uniform evaluation of multiple state-of-the-art model growth techniques and their combinations, revealing that efficient combination techniques can reduce the training cost (in TFLOPs) of individual methods by up to 80%.},
booktitle = {Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {56–63},
numpages = {8},
location = {Atlanta, GA, USA},
series = {SC-W '24}
}

@inproceedings{10.1145/3674805.3686671,
author = {Liu, Yueyue and Zhang, Hongyu and Li, Zhiqiang and Miao, Yuantian},
title = {Optimizing the Utilization of Large Language Models via Schedule Optimization: An Exploratory Study},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3686671},
doi = {10.1145/3674805.3686671},
abstract = {Background: Large Language Models (LLMs) have gained significant attention in machine-learning-as-a-service (MLaaS) offerings. In-context learning (ICL) is a technique that guides LLMs towards accurate query processing by providing additional information. However, longer prompts lead to higher costs of LLM service, creating a performance-cost trade-off. Aims: We aim to investigate the potential of combining schedule optimization with ICL to optimize LLM utilization. Method: We conduct an exploratory study. First, we consider the performance-cost trade-off in LLM utilization as a multi-objective optimization problem, aiming to select the most suitable prompt template for each LLM job to maximize accuracy (the percentage of correctly processed jobs) and minimize invocation cost. Next, we investigate three methods for prompt performance prediction to address the challenge of evaluating the accuracy objective in the fitness function, as the result can only be determined after submitting the job to the LLM. Finally, we apply widely used search-based techniques and evaluate their effectiveness. Results: The results indicate that the machine learning-based technique is an effective approach for prompt performance prediction and fitness function calculation. Schedule optimization can achieve higher accuracy or lower cost by selecting a suitable prompt template for each job, compared to simply submitting all jobs using a single prompt template, e.g., saving costs from 21.33% to 86.92% in our experiments on LLM-based log parsing. However, the performance of the evaluated search-based techniques varies across different instances and metrics, with no single technique consistently outperforming the others. Conclusions: This study demonstrates the potential of combining schedule optimization with ICL to improve the utilization of LLMs. However, there is still ample room for improving the searched-based techniques and prompt performance prediction techniques for more cost-effective LLM utilization.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {84–95},
numpages = {12},
keywords = {Large Language Models, Multi-objective Optimization, Schedule Optimization, Search-based Techniques},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3654522.3654596,
author = {Jeong, Hong-Ju and Boo, Hacksung and Bae, Jiseung and Jeon, Mincheol and Huh, Eui-Nam},
title = {An Energy-Efficient Parallelism Scheme for Deep Neural Network Training And Inferencing on Heterogeneous Cloud Resources},
year = {2024},
isbn = {9798400716713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654522.3654596},
doi = {10.1145/3654522.3654596},
abstract = {The emergence of Large Language Models(LLM) and generative AI has led to an explosive increase in computational demands across cloud computing data centers. The growing number of parameters in deep learning models results in significant power consumption problem, leading to the need for cost-effective and eco-friendly data centers. Furthermore, with the advent of multi-cloud environments, deep learning computations, not only for training but also for inference, no longer occur on a single hardware unit but are distributed across various heterogeneous hardware nodes forming clusters. In this paper, we present solutions to these challenges from a parallelism perspective. Considering the characteristics of the models, we implement data parallelism and model parallelism, partitioning models and data across heterogeneous hardware nodes for power-efficient learning and inferencing. To quantify the impact, we measured the power consumption of CPUs, GPUs, and RAM during the experiments, providing insights into the energy efficiency of the proposed partitioning strategies. Furthermore, we conducted a carbon footprint analysis, converting the measured power consumption into equivalent carbon emissions. The study highlights the necessity of partitioning research for energy-efficient learning and inferencing, addressing the identified issues.},
booktitle = {Proceedings of the 2024 9th International Conference on Intelligent Information Technology},
pages = {493–498},
numpages = {6},
keywords = {Carbon footprint, Deep learning, Heterogeneous, Parallelism, Power consumption},
location = {Ho Chi Minh City, Vietnam},
series = {ICIIT '24}
}

@article{10.1145/3656177,
author = {Chen, Hongzheng and Zhang, Jiahao and Du, Yixiao and Xiang, Shaojie and Yue, Zichao and Zhang, Niansong and Cai, Yaohui and Zhang, Zhiru},
title = {Understanding the Potential of FPGA-based Spatial Acceleration for Large Language Model Inference},
year = {2024},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
issn = {1936-7406},
url = {https://doi.org/10.1145/3656177},
doi = {10.1145/3656177},
abstract = {Recent advancements in large language models (LLMs) boasting billions of parameters have generated a significant demand for efficient deployment in inference workloads. While hardware accelerators for Transformer-based models have been extensively studied, the majority of existing approaches rely on temporal architectures that reuse hardware units for different network layers and operators. However, these methods often encounter challenges in achieving low latency due to considerable memory access overhead.This article investigates the feasibility and potential of model-specific spatial acceleration for LLM inference on field-programmable gate arrays (FPGAs). Our approach involves the specialization of distinct hardware units for specific operators or layers, facilitating direct communication between them through a dataflow architecture while minimizing off-chip memory accesses. We introduce a comprehensive analytical model for estimating the performance of a spatial LLM accelerator, taking into account the on-chip compute and memory resources available on an FPGA. This model can be extended to multi-FPGA settings for distributed inference. Through our analysis, we can identify the most effective parallelization and buffering schemes for the accelerator and, crucially, determine the scenarios in which FPGA-based spatial acceleration can outperform its GPU-based counterpart.To enable more productive implementations of an LLM model on FPGAs, we further provide a library of high-level synthesis (HLS) kernels that are composable and reusable. This library will be made available as open-source. To validate the effectiveness of both our analytical model and HLS library, we have implemented Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-trained Transformers (GPT2) on an AMD Xilinx Alveo U280 FPGA device. Experimental results demonstrate our approach can achieve up to 13.4\texttimes{} speedup when compared to previous FPGA-based accelerators for the BERT model. For GPT generative inference, we attain a 2.2\texttimes{} speedup compared to Design for Excellence, an FPGA overlay, in the prefill stage, while achieving a 1.9\texttimes{} speedup and a 5.7\texttimes{} improvement in energy efficiency compared to the NVIDIA A100 GPU in the decode stage.},
journal = {ACM Trans. Reconfigurable Technol. Syst.},
month = dec,
articleno = {5},
numpages = {29},
keywords = {FPGA, high-level synthesis, large language models, hardware acceleration}
}

@inproceedings{10.1145/3691555.3696825,
author = {Tang, Zuoyin and He, Jianhua and Pe, Dashuai and Liu, Kezhong and Gao, Tao and Zheng, Jiawei},
title = {Test Large Language Models on Driving Theory Knowledge and Skills for Connected Autonomous Vehicles},
year = {2024},
isbn = {9798400712470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691555.3696825},
doi = {10.1145/3691555.3696825},
abstract = {Handling long tail corner cases is a major challenge faced by autonomous vehicles (AVs). While large language models (LLMs) hold great potentials to handle the corner cases with excellent generalization and explanation capabilities and received increasing research interest on application to autonomous driving, there are still technical barriers to be tackled, such as strict model performance and huge computing resource requirements of LLMs, which are difficult to be met locally at AVs. In this paper, we investigate a new approach of applying remote or edge LLMs to support autonomous driving. With this approach connected autonomous vehicles (CAVs) send driving assistance requests to the LLMs. LLMs deployed at the edge of the networks or remote clouds process the requests and generate driving assistance instructions for the CAVs. A key issue for such LLM assisted driving system is the assessment of LLMs on their understanding of driving theory and skills, ensuring they are qualified to undertake safety critical driving assistance tasks for CAVs. As there is no published work on assessing LLM of driving theory and skills, we design and run driving theory tests for several proprietary LLM models (OpenAI GPT models, Baidu Ernie and Ali QWen) and open-source LLM models (Tsinghua MiniCPM-2B and MiniCPM-Llama3-V2.5) with more than 500 multiple-choices theory test questions. These questions are close to the official UK driving theory test ones. Model accuracy, cost and processing latency are measured from the experiments. Experiment results show that while model GPT-4 passes the test with improved domain knowledge and Ernie has an accuracy of 85% (just below the 86% passing threshold), other LLM models including GPT-3.5 fail the test. For the test questions with images, the multimodal model GPT4-o has an excellent accuracy result of 96%, and the MiniCPM-Llama3-V2.5 achieves an accuracy of 76%. While GPT-4 holds stronger potential for CAV driving assistance applications, the cost of using model GPT4 is much higher, almost 50 times of that of using GPT3.5. The results can help make decision on the use of the existing LLMs for CAV applications and balancing on the model performance and cost.},
booktitle = {Proceedings of the 19th Workshop on Mobility in the Evolving Internet Architecture},
pages = {1–6},
numpages = {6},
keywords = {Connected autonomous vehicles, driving theory test, large language model, mobile cloud computing, mobile edge computing, remote driving},
location = {Washington D.C., DC, USA},
series = {MobiArch '24}
}

@inproceedings{10.1145/3672539.3686755,
author = {Xue, Cheng and Guo, Yijie and Wang, Ziyi and Shimizu, Mona and Jeung, Jihong and Mi, Haipeng},
title = {DishAgent: Enhancing Dining Experiences through LLM-Based Smart Dishes},
year = {2024},
isbn = {9798400707186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672539.3686755},
doi = {10.1145/3672539.3686755},
abstract = {With the rapid advancement of smart technologies, there is an increasing demand to enhance everyday experiences, including dining. Recent Human-Computer Interaction (HCI) research has begun to emphasize the aesthetic, affective, sensual, and sociocultural qualities of directly interacting with food. However, these technologies are often constrained by the material properties of food, limiting their everyday applicability. This research introduces DishAgent, an innovative device equipped with a Large Language Model (LLM)-based smart dish and a swarm robotics system. DishAgent adapts to various dining scenarios by generating appropriate conversational contexts and coordinating the action commands of swarm robots, thereby enhancing the dining experience through real-time interaction. This paper explores the applications of DishAgent in intelligent dining guidance, dietary behavior intervention, food information query and social companionship, aiming to fill the critical gap in current technologies for simply and intuitively enhancing dining experiences.},
booktitle = {Adjunct Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {46},
numpages = {4},
keywords = {Human Food Interaction, Large Language Model, Smart Dish},
location = {Pittsburgh, PA, USA},
series = {UIST Adjunct '24}
}

@inproceedings{10.1145/3650212.3680371,
author = {Li, Dong and Yan, Meng and Zhang, Yaosheng and Liu, Zhongxin and Liu, Chao and Zhang, Xiaohong and Chen, Ting and Lo, David},
title = {CoSec: On-the-Fly Security Hardening of Code LLMs via Supervised Co-decoding},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680371},
doi = {10.1145/3650212.3680371},
abstract = {Large Language Models (LLMs) specialized in code have shown exceptional proficiency across various programming-related tasks, particularly code generation. Nonetheless, due to its nature of pretraining on massive uncritically filtered data, prior studies have shown that code LLMs are prone to generate code with potential vulnerabilities. Existing approaches to mitigate this risk involve crafting data without vulnerability and subsequently retraining or fine-tuning the model. As the number of parameters exceeds a billion, the computation and data demands of the above approaches will be enormous. Moreover, an increasing number of code LLMs tend to be distributed as services, where the internal representation is not accessible, and the API is the only way to reach the LLM, making the prior mitigation strategies non-applicable.    To cope with this, we propose CoSec, an on-the-fly Security hardening method of code LLMs based on security model-guided Co-decoding, to reduce the likelihood of code LLMs to generate code containing vulnerabilities. Our key idea is to train a separate but much smaller security model to co-decode with a target code LLM. Since the trained secure model has higher confidence for secure tokens, it guides the generation of the target base model towards more secure code generation. By adjusting the probability distributions of tokens during each step of the decoding process, our approach effectively influences the tendencies of generation without accessing the internal parameters of the target code LLM. We have conducted extensive experiments across various parameters in multiple code LLMs (i.e., CodeGen, StarCoder, and DeepSeek-Coder), and the results show that our approach is effective in security hardening. Specifically, our approach improves the average security ratio of six base models by 5.02%-37.14%, while maintaining the functional correctness of the target model.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1428–1439},
numpages = {12},
keywords = {AI Safety, Code Generation, Large Language Models, Software Security},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3626202.3637562,
author = {Zeng, Shulin and Liu, Jun and Dai, Guohao and Yang, Xinhao and Fu, Tianyu and Wang, Hongyi and Ma, Wenheng and Sun, Hanbo and Li, Shiyao and Huang, Zixiao and Dai, Yadong and Li, Jintao and Wang, Zehao and Zhang, Ruoyu and Wen, Kairui and Ning, Xuefei and Wang, Yu},
title = {FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs},
year = {2024},
isbn = {9798400704185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626202.3637562},
doi = {10.1145/3626202.3637562},
abstract = {Transformer-based Large Language Models (LLMs) have made a significant impact on various domains. However, LLMs' efficiency suffers from both heavy computation and memory overheads. Compression techniques like sparsification and quantization are commonly used to mitigate the gap between LLM's computation/memory overheads and hardware capacity. However, existing GPU and transformer-based accelerators cannot efficiently process compressed LLMs, due to the following unresolved challenges: low computational efficiency, underutilized memory bandwidth, and large compilation overheads. This paper proposes FlightLLM, enabling efficient LLMs inference with a complete mapping flow on FPGAs. In FlightLLM, we highlight an innovative solution that the computation and memory overhead of LLMs can be solved by utilizing FPGA-specific resources (e.g., DSP48 and heterogeneous memory hierarchy). We propose a configurable sparse DSP chain to support different sparsity patterns with high computation efficiency. Second, we propose an always-on-chip decode scheme to boost memory bandwidth with mixed-precision support. Finally, to make FlightLLM available for real-world LLMs, we propose a length adaptive compilation method to reduce the compilation overhead. Implemented on the Xilinx Alveo U280 FPGA, FlightLLM achieves 6.0\texttimes{} higher energy efficiency and 1.8\texttimes{} better cost efficiency against commercial GPUs (e.g., NVIDIA V100S) on modern LLMs (e.g., LLaMA2-7B) using vLLM and SmoothQuant under the batch size of one. FlightLLM beats NVIDIA A100 GPU with 1.2\texttimes{} higher throughput using the latest Versal VHK158 FPGA.},
booktitle = {Proceedings of the 2024 ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
pages = {223–234},
numpages = {12},
keywords = {complete mapping flow, fpga, large language model},
location = {Monterey, CA, USA},
series = {FPGA '24}
}

@inproceedings{10.1145/3613905.3636287,
author = {Desai, Smit and Wei, Christina Ziying and Sin, Jaisie and Dubiel, Mateusz and Zargham, Nima and Ahire, Shashank and Porcheron, Martin and Kuzminykh, Anastasia and Lee, Minha and Candello, Heloisa and Fischer, Joel E and Munteanu, Cosmin and Cowan, Benjamin R.},
title = {CUI@CHI 2024: Building Trust in CUIs—From Design to Deployment},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636287},
doi = {10.1145/3613905.3636287},
abstract = {Conversational user interfaces (CUIs) have become an everyday technology for people the world over, as well as a booming area of research. Advances in voice synthesis and the emergence of chatbots powered by large language models (LLMs), notably ChatGPT, have pushed CUIs to the forefront of human-computer interaction (HCI) research and practice. Now that these technologies enable an elemental level of usability and user experience (UX), we must turn our attention to higher-order human factors: trust and reliance. In this workshop, we aim to bring together a multidisciplinary group of researchers and practitioners invested in the next phase of CUI design. Through keynotes, presentations, and breakout sessions, we will share our knowledge, identify cutting-edge resources, and fortify an international network of CUI scholars. In particular, we will engage with the complexity of trust and reliance as attitudes and behaviours that emerge when people interact with conversational agents.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {460},
numpages = {7},
keywords = {chatbots, conversational AI, conversational agents, conversational user interfaces, reliance, trust, voice assistants},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inbook{10.1145/3658617.3697618,
author = {Huang, Shan and Li, Jinhao and Yu, Zhen and Ye, Jiancai and Xu, Jiaming and Xu, Ningyi and Dai, Guohao},
title = {LLSM: LLM-enhanced Logic Synthesis Model with EDA-guided CoT Prompting, Hybrid Embedding and AIG-tailored Acceleration},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697618},
abstract = {Machine learning-based methods have shown promising results in the field of Electronic Design Automation (EDA) like logic synthesis result prediction, enabling a shift-left in the overall EDA flow. Designers should fully optimize their Register Transfer Level (RTL) designs early because remedying low-quality RTL in downstream synthesis stages is extremely challenging. However, previous works mainly start modeling from the netlist level or layout level and apply Graph Neural Networks (GNNs) to make predictions.RTL captures the logic and scale information of circuits with uniform representation, making it suitable for a unified embedding approach. Since Large Language Models (LLMs) possess the ability to understand text modality, making them a potential method for understanding RTL and performing various EDA tasks. Therefore, we propose LLSM, the first LLM-enhanced logic synthesis model to extract information directly from RTL code. We also propose three novel approaches for LLSM in this paper. (1) EDA-guided Chain-of-Thought (CoT) prompting. We apply LLMs guided by circuit knowledge to summarize, analyze RTL code, and generate text with circuit information. (2) Text-circuit hybrid embedding. We train a small Language Model (LM) to encode the generated circuit information from LLM and fuse the embeddings of text and circuit modalities with weighted summation. (3) AIG-tailored acceleration library. We utilize an ELL2 format with zero padding tailored for And-Inverter-Graph (AIG) circuit representation and fuse the computation and format conversion. We also design a cacheable state strategy to avoid redundant computation for LM. We are the first to work with both LLM and GNN for the prediction of logic synthesis results and conduct extensive experiments on the OpenABC-D dataset. LLSM achieve up to 21.53% and 19.27% loss reduction in delay and area prediction respectively. It also achieves 1.34\texttimes{} and 6296.77\texttimes{} speedup on average compared to PyG implementation and Synopsis Design Compiler, respectively.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {974–980},
numpages = {7}
}

@article{10.1145/3709138,
author = {Yuan, Wei and Yang, Chaoqun and Ye, Guanhua and Chen, Tong and Hung, Nguyen Quoc Viet and Yin, Hongzhi},
title = {FELLAS: Enhancing Federated Sequential Recommendation with LLM as External Services},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3709138},
doi = {10.1145/3709138},
abstract = {Sequential recommendation has been widely studied in the recommendation domain since it can capture users’ temporal preferences and provide more accurate and timely recommendations. To address user privacy concerns, the combination of federated learning and sequential recommender systems (FedSeqRec) has gained growing attention. Unfortunately, the performance of FedSeqRec is still unsatisfactory because the models used in FedSeqRec have to be lightweight to accommodate communication bandwidth and clients’ on-device computational resource constraints. Recently, large language models (LLMs) have exhibited strong transferable and generalized language understanding abilities and therefore, in the NLP area, many downstream tasks now utilize LLMs as a service to achieve superior performance without constructing complex models. Inspired by this successful practice, we propose a generic FedSeqRec framework, FELLAS, which aims to enhance FedSeqRec by utilizing LLMs as an external service.Specifically, FELLAS employs an LLM server to provide both item-level and sequence-level representation assistance. The item-level representation service is queried by the central server to enrich the original ID-based item embedding with textual information, while the sequence-level representation service is accessed by each client. However, invoking the sequence-level representation service requires clients to send sequences to the external LLM server. To safeguard privacy, we implement  (d_{mathcal{X}}) -privacy satisfied sequence perturbation, which protects clients’ sensitive data with guarantees. Additionally, a contrastive learning-based method is designed to transfer knowledge from the noisy sequence representation to clients’ sequential recommendation models. Furthermore, to empirically validate the privacy protection capability of FELLAS, we propose two interacted item inference attacks, considering the threats posed by the LLM server and the central server acting as curious-but-honest adversaries in cooperation. Extensive experiments conducted on three datasets with two widely used sequential recommendation models demonstrate the effectiveness and privacy-preserving capability of FELLAS.},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = dec,
keywords = {Recommender System, Federated Learning, Privacy Protection}
}

@inproceedings{10.1145/3638530.3664174,
author = {Bin Murtaza, Sardar and Mccoy, Aidan and Ren, Zhiyuan and Murphy, Aidan and Banzhaf, Wolfgang},
title = {LLM Fault Localisation within Evolutionary Computation Based Automated Program Repair},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3664174},
doi = {10.1145/3638530.3664174},
abstract = {Repairing bugs can be a daunting task for even a human experienced in debugging, so naturally, attempting to automatically repair programs with a computer system is quite challenging. The existing methods of automated program repair leave a lot of room for improvement. Fault localization, which aims to find lines of code that are potentially buggy, minimises the search space of an automated program repair system. Recent work has shown improvement in these fault localization methods, with the use of Large Language Models. Here, we propose a system where a LLM-based fault localization tool, which we call SemiAutoFL, is used within a fully automatic program repair program, ARJA-e. We show that utilising LLM-based fault localization with ARJA-e can significantly improve its performance on real world bugs. ARJA-e with SemiAutoFL can repair 10 bugs that ARJA-e was previously unable to so do. This finding adds to our understanding of how to improve fault localization and automated program repair, highlighting the potential for more efficient and accurate fault localisation methods being applied to automated program repair.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1824–1829},
numpages = {6},
keywords = {genetic improvement, fault localisation, large language models},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{10.1145/3658644.3670334,
author = {Sun, Haochen and Li, Jason and Zhang, Hongyang},
title = {zkLLM: Zero Knowledge Proofs for Large Language Models},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670334},
doi = {10.1145/3658644.3670334},
abstract = {The recent surge in artificial intelligence (AI), characterized by the prominence of large language models (LLMs), has ushered in fundamental transformations across the globe. However, alongside these advancements, concerns surrounding the legitimacy of LLMs have grown, posing legal challenges to their extensive applications. Compounding these concerns, the parameters of LLMs are often treated as intellectual property, restricting direct investigations.In this study, we address a fundamental challenge within the realm of AI legislation: the need to establish the authenticity of outputs generated by LLMs. To tackle this issue, we present zkLLM, which stands as the inaugural specialized zero-knowledge proof tailored for LLMs to the best of our knowledge. Addressing the persistent challenge of non-arithmetic operations in deep learning, we introduce tlookup, a parallelized lookup argument designed for non-arithmetic tensor operations in deep learning, offering a solution with no asymptotic overhead. Furthermore, leveraging the foundation of tlookup, we introduce zkAttn, a specialized zero-knowledge proof crafted for the attention mechanism, carefully balancing considerations of running time, memory usage, and accuracy.Empowered by our fully parallelized CUDA implementation, zkLLM emerges as a significant stride towards achieving efficient zero-knowledge verifiable computations over LLMs. Remarkably, for LLMs boasting 13 billion parameters, our approach enables the generation of a correctness proof for the entire inference process in under 15 minutes. The resulting proof, compactly sized at less than 200 kB, is designed to uphold the privacy of the model parameters, ensuring no inadvertent information leakage.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4405–4419},
numpages = {15},
keywords = {large language models, zero-knowledge proofs},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.5555/3716662.3716801,
author = {Wolfe, Robert and Mitra, Tanushree},
title = {The Implications of Open Generative Models in Human-Centered Data Science Work: A Case Study with Fact-Checking Organizations},
year = {2025},
publisher = {AAAI Press},
abstract = {Calls to use open generative language models in academic research have highlighted the need for reproducibility and transparency in scientific research. However, the impact of generative AI extends well beyond academia, as corporations and public interest organizations have begun integrating these models into their data science pipelines. We expand this lens to include the impact of open models on organizations, focusing specifically on fact-checking organizations, which use AI to observe and analyze large volumes of circulating misinformation, yet must also ensure the reproducibility and impartiality of their work. We wanted to understand where fact-checking organizations use open models in their data science pipelines; what motivates their use of open models or proprietary models; and how their use of open or proprietary models can inform research on the societal impact of generative AI. To answer these questions, we conducted an interview study with N=24 professionals at 20 fact-checking organizations on six continents. Based on these interviews, we offer a five-component conceptual model of where fact-checking organizations employ generative AI to support or automate parts of their data science pipeline, including Data Ingestion, Data Analysis, Data Retrieval, Data Delivery, and Data Sharing. We then provide taxonomies of fact-checking organizations' motivations for using open models and the limitations that prevent them for further adopting open models, finding that they prefer open models for Organizational Autonomy, Data Privacy and Ownership, Application Specificity, and Capability Transparency. However, they nonetheless use proprietary models due to perceived advantages in Performance, Usability, and Safety, as well as Opportunity Costs related to participation in emerging generative AI ecosystems. Finally, we propose a research agenda to address limitations of both open and proprietary models. Our research provides novel perspective on open models in data-driven organizations.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {1595–1607},
numpages = {13},
location = {San Jose, California, USA},
series = {AIES '24}
}

@article{10.1145/3696461,
author = {Hota, Aritra and Chatterjee, Soumyajit and Chakraborty, Sandip},
title = {Evaluating Large Language Models as Virtual Annotators for Time-series Physical Sensing Data},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3696461},
doi = {10.1145/3696461},
abstract = {Traditional human-in-the-loop-based annotation for time-series data like inertial data often requires access to alternate modalities like video or audio from the environment. These alternate sources provide the necessary information to the human annotator, as the raw numeric data is often too obfuscated even for an expert. However, this traditional approach has many concerns surrounding overall cost, efficiency, storage of additional modalities, time, scalability, and privacy. Interestingly, recent large language models (LLMs) are also trained with vast amounts of publicly available alphanumeric data, which allows them to comprehend and perform well on tasks beyond natural language processing. Naturally, this opens up a potential avenue to explore the opportunities in using these LLMs as virtual annotators where the LLMs will be directly provided the raw sensor data for annotation instead of relying on any alternate modality. Naturally, this could mitigate the problems of the traditional human-in-the-loop approach. Motivated by this observation, we perform a detailed study in this paper to assess whether the state-of-the-art (SOTA) LLMs can be used as virtual annotators for labeling time-series physical sensing data. To perform this in a principled manner, we segregate the study into two major phases. In the first phase, we investigate the challenges an LLM like GPT-4 faces in comprehending raw sensor data. Considering the observations from phase 1, in the next phase, we investigate the possibility of encoding the raw sensor data using SOTA SSL approaches and utilizing the projected time-series data to get annotations from the LLM. Detailed evaluation with four benchmark HAR datasets shows that SSL-based encoding and metric-based guidance allow the LLM to make more reasonable decisions and provide accurate annotations without requiring computationally expensive fine-tuning or sophisticated prompt engineering.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = sep,
keywords = {Large Language Models, Human-in-the-Loop, Time-series Data}
}

@article{10.14778/3685800.3685868,
author = {Wang, Mengzhao and Wu, Haotian and Ke, Xiangyu and Gao, Yunjun and Xu, Xiaoliang and Chen, Lu},
title = {An Interactive Multi-Modal Query Answering System with Retrieval-Augmented Large Language Models},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685868},
doi = {10.14778/3685800.3685868},
abstract = {Retrieval-augmented Large Language Models (LLMs) have reshaped traditional query-answering systems, offering unparalleled user experiences. However, existing retrieval techniques often struggle to handle multi-modal query contexts. In this paper, we present an interactive Multi-modal Query Answering (MQA) system, empowered by our newly developed multi-modal retrieval framework and navigation graph index, integrated with cutting-edge LLMs. It comprises five core components: Data Preprocessing, Vector Representation, Index Construction, Query Execution, and Answer Generation, all orchestrated by a dedicated coordinator to ensure smooth data flow from input to answer generation. One notable aspect of MQA is its utilization of contrastive learning to assess the significance of different modalities, facilitating precise measurement of multimodal information similarity. Furthermore, the system achieves efficient retrieval through our advanced navigation graph index, refined using computational pruning techniques. Another highlight of our system is its pluggable processing framework, allowing seamless integration of embedding models, graph indexes, and LLMs. This flexibility provides users diverse options for gaining insights from their multi-modal knowledge base. A preliminary video introduction of MQA is available at https://youtu.be/xvUuo2ZIqWk.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4333–4336},
numpages = {4}
}

@inproceedings{10.1145/3664647.3681695,
author = {Huang, Rongjie and Wang, Yongqi and Hu, Ruofan and Xu, Xiaoshan and Hong, Zhiqing and Yang, Dongchao and Cheng, Xize and Wang, Zehan and Jiang, Ziyue and Ye, Zhenhui and Liu, Luping and Zheng, Siqi and Zhao, Zhou},
title = {VoiceTuner: Self-Supervised Pre-training and Efficient Fine-tuning For Voice Generation},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681695},
doi = {10.1145/3664647.3681695},
abstract = {Voice large language models (LLMs) cast voice synthesis as a language modeling task in a discrete space, and have demonstrated significant progress to date. Despite the recent success, the current development of voice LLMs in low-resource applications is hampered by data scarcity and high computational cost. In this work, we propose VoiceTuner, with a self-supervised pre-training and efficient fine-tuning approach for low-resource voice generation. Specifically, 1) to mitigate data scarcity, we leverage large-scale unlabeled dataset and pre-train VoiceTuner-SSL without pre-defined applications, which can be fine-tuned in downstream tasks; 2) to further reduce the high training cost in complete fine-tuning, we introduce a multiscale transformer adapter to effectively update only around 1% parameters as a plug-and-play module. Experimental results demonstrate that VoiceTuner-SSL presents strong acoustic continuations, and VoiceTuner achieves state-of-the-art results in rich-resource TTS evaluation compared with competitive baseline models. Low-resource (1h, 10h, 30h) downstream applications including zero-shot TTS, instruction TTS, and singing voice synthesis present VoiceTuner's superior audio quality and style similarity with reduced data requirement and computational cost. Audio samples are available at https://VoiceTuner.github.io},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {10630–10639},
numpages = {10},
keywords = {efficient fine-tuning, large language models, speech synthesis},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3650212.3680334,
author = {Ran, Dezhi and Wang, Hao and Song, Zihe and Wu, Mengzhou and Cao, Yuan and Zhang, Ying and Yang, Wei and Xie, Tao},
title = {Guardian: A Runtime Framework for LLM-Based UI Exploration},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680334},
doi = {10.1145/3650212.3680334},
abstract = {Tests for feature-based UI testing have been indispensable for ensuring the quality of mobile applications (apps for short).        The high manual labor costs to create such tests have led to a strong interest in automated feature-based UI testing, where an approach automatically explores the App under Test (AUT) to find correct sequences of UI events achieving the target test objective, given only a high-level test objective description.        Given that the task of automated feature-based UI testing resembles conventional AI planning problems, large language models (LLMs), known for their effectiveness in AI planning, could be ideal for this task.        However, our study reveals that LLMs struggle with following specific instructions for UI testing and replanning based on new information. This limitation results in reduced effectiveness of LLM-driven solutions for automated feature-based UI testing, despite the use of advanced prompting techniques.                Toward addressing the preceding limitation, we propose Guardian, a runtime system framework to improve the effectiveness of automated feature-based UI testing by offloading computational tasks from LLMs with two major strategies.        First, Guardian refines UI action space that the LLM can plan over, enforcing the instruction following of the LLM by construction.        Second, Guardian deliberately checks whether the gradually enriched information invalidates previous planning by the LLM.        Guardian removes the invalidated UI actions from the UI action space that the LLM can plan over, restores the state of the AUT to the state before the execution of the invalidated UI actions, and prompts the LLM to re-plan with the new UI action space.        We instantiate Guardian with ChatGPT and construct a benchmark named FestiVal with 58 tasks from 23 highly popular apps.        Evaluation results on FestiVal show that Guardian achieves 48.3},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {958–970},
numpages = {13},
keywords = {Android Testing, Large Language Models, Mobile Testing, Runtime System, Sequential Planning, UI Testing},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3637528.3672010,
author = {Chen, Nuo and Li, Yuhan and Tang, Jianheng and Li, Jia},
title = {GraphWiz: An Instruction-Following Language Model for Graph Computational Problems},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672010},
doi = {10.1145/3637528.3672010},
abstract = {Large language models (LLMs) have achieved impressive success across various domains, but their capability in understanding and resolving complex graph problems is less explored. To bridge this gap, we introduce GraphInstruct, a novel instruction-tuning dataset aimed at enabling language models to tackle a broad spectrum of graph problems through explicit reasoning paths. Utilizing GraphInstruct, we build GraphWiz, an open-source language model capable of solving various graph computational problems while generating clear reasoning processes. To further enhance the model's performance and reliability, we integrate the Direct Preference Optimization (DPO) framework within the graph problem-solving context. The improved model, GraphWiz-DPO, achieves an average accuracy of 65% across nine tasks with different complexity levels, surpassing GPT-4 which has an average accuracy of 43.8%. Our study also investigates the relationship between training data volume and model performance, emphasizing the risk of overfitting as data volume increases. Additionally, we explore the transferability of the proposed model across different tasks and datasets, demonstrating its robust zero-shot generalization capability. GraphWiz offers a new blueprint and valuable insights for developing LLMs specialized in graph reasoning and problem-solving.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {353–364},
numpages = {12},
keywords = {graph algorithms, instruction tuning, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1613/jair.1.16653,
author = {Omotayo, Abdul-Hakeem and Mbilinyi, Ashery and Ismaila, Lukman and Turki, Houcemeddine and Abdien, Mahmoud and Gamal, Karim and Tondji, Idriss and Pimi, Yvan and Etori, Naome A. and Matar, Marwa M. and Broni-Bediako, Clifford and Oppong, Abigail and Gamal, Mai and Ehab, Eman and Dovonon, Gbetondji and Akinjobi, Zainab and Ajisafe, Daniel and Adegboro, Oluwabukola G. and Siam, Mennatullah},
title = {The State of Computer Vision Research in Africa},
year = {2025},
issue_date = {Jan 2025},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {81},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.16653},
doi = {10.1613/jair.1.16653},
abstract = {Despite significant efforts to democratize artificial intelligence (AI), computer vision which is a sub-field of AI, still lags in Africa. A significant factor to this, is the limited access to computing resources, datasets, and collaborations. As a result, Africa’s contribution to top-tier publications in this field has only been 0.06% over the past decade. Towards improving the computer vision field and making it more accessible and inclusive, this study analyzes 63,000 Scopus-indexed computer vision publications from Africa. We utilize large language models to automatically parse their abstracts, to identify and categorize topics and datasets. This resulted in listing more than 100 African datasets. Our objective is to provide a comprehensive taxonomy of dataset categories to facilitate better understanding and utilization of these resources. We also analyze collaboration trends of researchers within and outside the continent. Additionally, we conduct a large-scale questionnaire among African computer vision researchers to identify the structural barriers they believe require urgent attention. In conclusion, our study offers a comprehensive overview of the current state of computer vision research in Africa, to empower marginalized communities to participate in the design and development of computer vision systems.},
journal = {J. Artif. Int. Res.},
month = jan,
numpages = {27}
}

@inproceedings{10.1145/3690624.3709424,
author = {Yu, Pengfei and Gu, Jingjing and Shen, Dazhong and Dong, Xin and Liu, Yang and Xiong, Hui},
title = {Instruction Semantics Enhanced Dual-Flow Graph Model for GPU Error Resilience Prediction},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709424},
doi = {10.1145/3690624.3709424},
abstract = {As GPUs are widely deployed in High Performance Computing systems, it is critical to ensure that these systems can perform reliably. To improve system reliability, researchers estimate the error resilience of GPU programs by understanding resilience characteristics or modeling error propagation. However, features indicative of resilience rely on manual extraction from simulations of numerous faults, and error propagation analysis cannot target fine-grained bit-level faults. To address those problems, this paper introduces a novel paradigm, namely InstrDGM, for efficiently predicting GPU error resilience. Specifically, InstrDGM first fine-tunes a large language model using extensive sequences of GPU assembly instructions for extracting the semantic representation of instructions automatically. Meanwhile, we consider the propagation of bit-level faults during instruction execution and data transfer processes, and leverage graph neural networks to capture their distinct error propagation patterns. Then, the fault embeddings extracted from these error propagation patterns are integrated for error resilience prediction. Additionally, this paper releases a new dataset for GPU error resilience assessment, containing 1.2 million fault samples. Finally, extensive experiments show that InstrDGM significantly outperforms existing methods.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {2803–2814},
numpages = {12},
keywords = {error resilience, failure prediction, gpu, graph neural network, large language model},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3640794.3669998,
author = {Sacar, Sayan and Munteanu, Cosmin and Sin, Jaisie and Wei, Christina and Sayago, Sergio and Zhao, Wei and Waycott, Jenny},
title = {Designing Age-Inclusive Interfaces: Emerging Mobile, Conversational, and Generative AI to Support Interactions across the Life Span},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640794.3669998},
doi = {10.1145/3640794.3669998},
abstract = {We are concurrently witnessing two significant shifts: voice and chat-based conversational user interfaces (CUIs) are becoming ubiquitous (especially more recently due to advances in generative AI and LLMs - large language models), and older people are becoming a very large demographic group (and increasingly adopting of mobile technology on which such interfaces are present). However, despite the recent increase in research activity, age-relevant and inter/cross-generational aspects continue to be underrepresented in both research and commercial product design. Therefore, the overarching aim of this workshop is to increase the momentum for research within the space of hands-free, mobile, and conversational interfaces that centers on age-relevant and inter- and cross-generational interaction. For this, we plan to create an interdisciplinary space that brings together researchers, designers, practitioners, and users, to discuss and share challenges, principles, and strategies for designing such interfaces across the life span. We thus welcome contributions of empirical studies, theories, design, and evaluation of hands-free, mobile, and conversational interfaces designed with aging in mind (e.g. older adults or inter/cross-generational). We particularly encourage contributions focused on leveraging recent advances in generative AI or LLMs. Through this, we aim to grow the community of CUI researchers across disciplinary boundaries (human-computer interaction, voice and language technologies, geronto-technologies, information studies, etc.) that are engaged in the shared goal of ensuring that the aging dimension is appropriately incorporated in mobile / conversational interaction design research.},
booktitle = {Proceedings of the 6th ACM Conference on Conversational User Interfaces},
articleno = {64},
numpages = {5},
location = {Luxembourg, Luxembourg},
series = {CUI '24}
}

@inproceedings{10.1145/3587102.3588805,
author = {Reeves, Brent and Sarsa, Sami and Prather, James and Denny, Paul and Becker, Brett A. and Hellas, Arto and Kimmel, Bailey and Powell, Garrett and Leinonen, Juho},
title = {Evaluating the Performance of Code Generation Models for Solving Parsons Problems With Small Prompt Variations},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588805},
doi = {10.1145/3587102.3588805},
abstract = {The recent emergence of code generation tools powered by large language models has attracted wide attention. Models such as OpenAI Codex can take natural language problem descriptions as input and generate highly accurate source code solutions, with potentially significant implications for computing education. Given the many complexities that students face when learning to write code, they may quickly become reliant on such tools without properly understanding the underlying concepts. One popular approach for scaffolding the code writing process is to use Parsons problems, which present solution lines of code in a scrambled order. These remove the complexities of low-level syntax, and allow students to focus on algorithmic and design-level problem solving. It is unclear how well code generation models can be applied to solve Parsons problems, given the mechanics of these models and prior evidence that they underperform when problems include specific restrictions. In this paper, we explore the performance of the Codex model for solving Parsons problems over various prompt variations. Using a corpus of Parsons problems we sourced from the computing education literature, we find that Codex successfully reorders the problem blocks about half of the time, a much lower rate of success when compared to prior work on more free-form programming tasks. Regarding prompts, we find that small variations in prompting have a noticeable effect on model performance, although the effect is not as pronounced as between different problems.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {299–305},
numpages = {7},
keywords = {CS1, GPT-3, GitHub, ML, academic integrity, ai, artificial intelligence, chatgpt, code generation, code writing, codex, computer programming, copilot, deep learning, generative ai, introductory programming, large language models, machine learning, natural language processing, neural networks, novice programming, openAI},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3660605.3660941,
author = {Rao, Kunal and Coviello, Giuseppe and Benedetti, Priscilla and Giuseppe De Vita, Ciro and Mellone, Gennaro and Chakradhar, Srimat},
title = {ECO-LLM: LLM-based Edge Cloud Optimization},
year = {2024},
isbn = {9798400706523},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660605.3660941},
doi = {10.1145/3660605.3660941},
abstract = {AI/ML techniques have been used to solve systems problems, but their applicability to customize solutions on-the-fly has been limited. Traditionally, any customization required manually changing the AI/ML model or modifying the code, configuration parameters, application settings, etc. This incurs too much time and effort, and is very painful. In this paper, we propose a novel technique using Generative Artificial Intelligence (GenAI) technology, wherein instructions can be provided in natural language and actual code to handle any customization is automatically generated, integrated and applied on-the-fly. Such capability is extremely powerful since it makes customization of application settings or solution techniques super easy. Specifically, we propose ECO-LLM (LLM-based Edge Cloud Optimization), which leverages Large Language Models (LLM) to dynamically adjust placement of application tasks across edge and cloud computing tiers, in response to changes in application workload, such that insights are delivered quickly with low cost of operation (systems problem). Our experiments with real-world video analytics applications i.e. face recognition, human attributes detection and license plate recognition show that ECO-LLM is able to automatically generate code on-the-fly and adapt placement of application tasks across edge and cloud computing tiers. We note that the trigger workload (to switch between edge and cloud) for ECO-LLM is exactly the same as the baseline (manual) and actual placement performed by ECO-LLM is only slightly different i.e. on average (across 2 days) only 1.45% difference in human attributes detection and face recognition, and 1.11% difference in license plate recognition. Although we tackle this specific systems problem in this paper, our proposed GenAI-based technique is applicable to solve other systems problems too.},
booktitle = {Proceedings of the 2024 Workshop on AI For Systems},
pages = {7–12},
numpages = {6},
keywords = {large language models (LLM), generative artificial intelligence (GenAI), machine learning (ML), customization, optimization, edge computing, cloud computing, video analytics},
location = {Pisa, Italy},
series = {AI4Sys '24}
}

@inproceedings{10.1145/3613904.3642196,
author = {Lee, Yoonjoo and Kang, Hyeonsu B and Latzke, Matt and Kim, Juho and Bragg, Jonathan and Chang, Joseph Chee and Siangliulue, Pao},
title = {PaperWeaver: Enriching Topical Paper Alerts by Contextualizing Recommended Papers with User-collected Papers},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642196},
doi = {10.1145/3613904.3642196},
abstract = {With the rapid growth of scholarly archives, researchers subscribe to “paper alert’’ systems that periodically provide them with recommendations of recently published papers that are similar to previously collected papers. However, researchers sometimes struggle to make sense of nuanced connections between recommended papers and their own research context, as existing systems only present paper titles and abstracts. To help researchers spot these connections, we present PaperWeaver, an enriched paper alerts system that provides contextualized text descriptions of recommended papers based on user-collected papers. PaperWeaver employs a computational method based on Large Language Models (LLMs) to infer users’ research interests from their collected papers, extract context-specific aspects of papers, and compare recommended and collected papers on these aspects. Our user study (N=15) showed that participants using PaperWeaver were able to better understand the relevance of recommended papers and triage them more confidently when compared to a baseline that presented the related work sections from recommended papers.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {19},
numpages = {19},
keywords = {Contextualized Descriptions, Large Language Models, Scientific Paper},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3644815.3644948,
author = {Rasool, Zafaryab and Barnett, Scott and Willie, David and Kurniawan, Stefanus and Balugo, Sherwin and Thudumu, Srikanth and Abdelrazek, Mohamed},
title = {LLMs for Test Input Generation for Semantic Applications},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644948},
doi = {10.1145/3644815.3644948},
abstract = {Large language models (LLMs) enable state-of-the-art semantic capabilities to be added to software systems such as semantic search of unstructured documents and text generation. However, these models are computationally expensive. At scale, the cost of serving thousands of users increases massively affecting also user experience. To address this problem, semantic caches are used to check for answers to similar queries (that may have been phrased differently) without hitting the LLM service. Due to the nature of these semantic cache techniques that rely on query embeddings, there is a high chance of errors impacting user confidence in the system. Adopting semantic cache techniques usually requires testing the effectiveness of a semantic cache (accurate cache hits and misses) which requires a labelled test set of similar queries and responses which is often unavailable. In this paper, we present VaryGen, an approach for using LLMs for test input generation that produces similar questions from unstructured text documents. Our novel approach uses the reasoning capabilities of LLMs to 1) adapt queries to the domain, 2) synthesise subtle variations to queries, and 3) evaluate the synthesised test dataset. We evaluated our approach in the domain of a student question and answer system by qualitatively analysing 100 generated queries and result pairs, and conducting an empirical case study with an open source semantic cache. Our results show that query pairs satisfy human expectations of similarity and our generated data demonstrates failure cases of a semantic cache. Additionally, we also evaluate our approach on Qasper dataset. This work is an important first step into test input generation for semantic applications and presents considerations for practitioners when calibrating a semantic cache.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {160–165},
numpages = {6},
keywords = {large language model, query evaluation, question answering, semantic cache, test input generation},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3706890.3706951,
author = {Zhang, Tao and Zhao, Likun},
title = {MMR: Math Multi-step Reasoning in Medical Dialogue Generation},
year = {2025},
isbn = {9798400717826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706890.3706951},
doi = {10.1145/3706890.3706951},
abstract = {With the advancements of large language models in text and visual tasks, researchers are increasingly exploring their applications in medical scenarios. While existing studies have successfully applied these models to medical dialogue systems, challenges remain in accurately calculating medication dosages and handling multi-turn reasoning due to the low tolerance for error in medical contexts. To address this, we propose Math Multi-step Reasoning in Medical Dialogue Generation (MMR), which enhances reasoning by iteratively breaking down complex problems into simpler questions using a “Least to Most Prompting” (LMP)strategy. MMR integrates Chain of Thought, React mechanisms, and Retrieval-Augmented Generation (RAG) with a domain-specific knowledge base to improve reasoning accuracy. Supported by the MedDGQA dataset, MMR outperforms state-of-the-art methods in both objective and subjective evaluations.},
booktitle = {Proceedings of the 2024 5th International Symposium on Artificial Intelligence for Medicine Science},
pages = {348–351},
numpages = {4},
keywords = {Large Language Models, Medical Dialogue Generation, Multi-step Reasoning},
location = {
},
series = {ISAIMS '24}
}

@inproceedings{10.1145/3636555.3636912,
author = {Snyder, Caitlin and Hutchins, Nicole M and Cohn, Clayton and Fonteles, Joyce Horn and Biswas, Gautam},
title = {Analyzing Students Collaborative Problem-Solving Behaviors in Synergistic STEM+C Learning},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636912},
doi = {10.1145/3636555.3636912},
abstract = {This study introduces a methodology to investigate students’ collaborative behaviors as they work in pairs to build computational models of scientific processes. We expand the Self-Regulated Learning (SRL) framework—specifically, Planning, Enacting, and Reflection—proposed in the literature, applying it to examine students’ collaborative problem-solving (CPS) behaviors in a computational modeling task. We analyze these behaviors by employing a Markov Chain (MC) modeling approach that scrutinizes students’ model construction and model debugging behaviors during CPS. This involves interpreting their actions in the system collected through computer logs and analyzing their conversations using a Large Language Model (LLM) as they progress through their modeling task in segments. Our analytical framework assesses the behaviors of high- and low-performing students by evaluating their proficiency in completing the specified computational model for a kinematics problem. We employ a mixed-methods approach, combining Markov Chain analysis of student problem-solving transitions with qualitative interpretations of their conversation segments. The results highlight distinct differences in behaviors between high- and low-performing groups, suggesting potential for developing adaptive scaffolds in future work to enhance support for students in collaborative problem-solving.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {540–550},
numpages = {11},
keywords = {SRL, STEM, collaboration, learning analytics},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3641237.3691693,
author = {Kasierski, Benjamin and Fagnano, Emma},
title = {Optimizing the Grant Writing Process: A Framework for Creating a Grant Writing Assistant Using ChatGPT 4},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691693},
doi = {10.1145/3641237.3691693},
abstract = {This extended abstract explores prompt engineering strategies and usability testing that can be applied to create a grant writing assistant using ChatGPT 4. Utilizing scholarly literature from the past 3 years concerning LLM development, AI integration, and prompt engineering, along with White et al's experimental prompt pattern catalog [13] for software engineering, and previously accepted grants from a given institution, ChatGPT 4 can be applied to create a transferable template that streamlines the grant writing process. By following the frameworks outlined in the literature and guidelines for potential applications, we propose that grant writers can integrate a more efficient grant writing process that reduces confusion in understanding NSF's guidelines and criteria, helps to articulate clear and achievable objectives, and improves proposal alignment with NSF's strategic priorities.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {286–291},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, NSF, National Science Foundation, grant writing, large language models},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@inproceedings{10.1145/3663533.3676565,
author = {Kula, Raula Gaikovina},
title = {The Ever-Evolving Promises of Data in Software Ecosystems: Models, AI, and Analytics (Keynote)},
year = {2024},
isbn = {9798400706752},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663533.3676565},
doi = {10.1145/3663533.3676565},
abstract = {The year 2024 has sparked extensive discussions about the future of software engineering research, particularly for library dependencies and the software ecosystems they create. In this talk, I will take you on an experiential journey spanning the last decade, beginning in 2013 when I first embarked on my journey, and finally landing in the era of generative AI and augmented reality. We will explore how the landscape of collecting datasets through mining, user studies, and expanding from 3 systems to 3 million systems has evolved, examine what elements have remained constant, and discuss how we can advance with software ecosystems research in the face of these innovations.},
booktitle = {Proceedings of the 20th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {1},
numpages = {1},
location = {Porto de Galinhas, Brazil},
series = {PROMISE 2024}
}

@inproceedings{10.1145/3637528.3671865,
author = {Ling, Zhenqing and Chen, Daoyuan and Yao, Liuyi and Li, Yaliang and Shen, Ying},
title = {On the Convergence of Zeroth-Order Federated Tuning for Large Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671865},
doi = {10.1145/3637528.3671865},
abstract = {The confluence of Federated Learning (FL) and Large Language Models (LLMs) is ushering in a new era in privacy-preserving natural language processing. However, the intensive memory requirements for fine-tuning LLMs pose significant challenges, especially when deploying on clients with limited computational resources. To circumvent this, we explore the novel integration of Memory-efficient Zeroth-Order Optimization within a federated setting, a synergy we term as FedMeZO. Our study is the first to examine the theoretical underpinnings of FedMeZO in the context of LLMs, tackling key questions regarding the influence of large parameter spaces on optimization behavior, the establishment of convergence properties, and the identification of critical parameters for convergence to inform personalized federated strategies. Our extensive empirical evidence supports the theory, showing that FedMeZO not only converges faster than traditional first-order methods such as FedAvg but also significantly reduces GPU memory usage during training to levels comparable to those during inference. Moreover, the proposed personalized FL strategy that is built upon the theoretical insights to customize the client-wise learning rate can effectively accelerate loss reduction. We hope our work can help to bridge theoretical and practical aspects of federated fine-tuning for LLMs, thereby stimulating further advancements and research in this area.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1827–1838},
numpages = {12},
keywords = {convergence analysis, federated learning, large language models, zeroth-order optimization},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3627673.3679743,
author = {Wang, Yuhao and Wang, Yichao and Fu, Zichuan and Li, Xiangyang and Wang, Wanyu and Ye, Yuyang and Zhao, Xiangyu and Guo, Huifeng and Tang, Ruiming},
title = {LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679743},
doi = {10.1145/3627673.3679743},
abstract = {As the demand for more personalized recommendation grows and a dramatic boom in commercial scenarios arises, the study on multi-scenario recommendation (MSR) has attracted much attention, which uses the data from all scenarios to simultaneously improve their recommendation performance. However, existing methods tend to integrate insufficient scenario knowledge and neglect learning personalized cross-scenario preferences, thus leading to sub-optimal performance. Meanwhile, though large language model (LLM) has shown great capability of reasoning and capturing semantic information, the high inference latency and high computation cost of tuning hinder its implementation in industrial recommender systems. To fill these gaps, we propose an LLM-enhanced paradigm LLM4MSR in this work. Specifically, we first leverage LLM to uncover multi-level knowledge from the designed scenario- and user-level prompt without fine-tuning the LLM, then adopt hierarchical meta networks to generate multi-level meta layers to explicitly improve the scenario-aware and personalized recommendation capability. Our experiments on KuaiSAR-small, KuaiSAR, and Amazon datasets validate significant advantages of LLM4MSR: (i) the effectiveness and compatibility with different multi-scenario backbone models, (ii) high efficiency and deployability on industrial recommender systems, and (iii) improved interpretability. The implemented code and data is available to ease reproduction.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2472–2481},
numpages = {10},
keywords = {click-through rate prediction, large language model, multi-domain, multi-scenario recommendation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@proceedings{10.1145/3689094,
title = {SUMAC '24: Proceedings of the 6th workshop on the analySis, Understanding and proMotion of heritAge Contents},
year = {2024},
isbn = {9798400712050},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to SUMAC 2024, the 6th edition of the ACM workshop on analySis, Understanding and proMotion of heritAge Contents. The workshop focuses on analyzing, processing and valorizing all types of data related to cultural heritage, including tangible and intangible heritage. As stated by UNESCO, cultural heritage provides societies with a wealth of resources inherited from the past, created in the present for the benefit of future generations. The massive digitization of historical analogue resources and production of born-digital documents provide us with large volumes of varied multimedia heritage data (images, maps, text, video, 3D objects, multi-sensor data, etc.), which represent a rich heritage that can be exploited in a wide variety of fields, from research in social sciences and computational humanities to land use and territorial policies, including urban modeling, digital simulation, archaeology, tourism, education, culture preservation, creative media and entertainment. In terms of research in computer science, artificial intelligence and digital humanities, they address challenging problems related to the diversity, specificity or volume of the media, the veracity of the data, and different user needs with respect to engaging with this rich material and the extraction of value out of the data. These challenges are reflected in the corresponding sub-fields of machine learning, signal processing, multi-modal techniques and human-machine interaction, with special focus on:Analysis of historical data,Content understanding and pattern recognition,Linking and recommendation of multi-modal digital heritage,Human-machine interaction for big data analysis and visualization,Generative modeling of cultural heritage.},
location = {Melbourne VIC, Australia}
}

@inproceedings{10.1145/3610661.3617514,
author = {A, Rajagopal and V, Nirmala and Jebadurai, Immanuel Johnraja and Vedamanickam, Arun Muthuraj and Kumar, Prajakta Uthaya},
title = {Design of Generative Multimodal AI Agents to Enable Persons with Learning Disability},
year = {2023},
isbn = {9798400703218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610661.3617514},
doi = {10.1145/3610661.3617514},
abstract = {The recent advances in Multimodal AI &amp; Generative AI open doors to the possibilities of solving key challenges for Persons with Learning Disability. To assist individuals facing difficulty in visual or auditory perception, this paper designs &amp; develops a multimodal AI agent using recent advances in the field. We aim to solve the challenge of enabling persons with Visual or Auditory Processing Disorders to learn &amp; communicate. We do this by exploring a design that allows the transformation of information across visual and language modalities. This design can be realized with the recent advances in Generative Multimodal AI. Based on each individual's needs, the AI agent dynamically adapts the Human Computer interaction model. For instance, for a child with Visual Processing Disorder (VPD), given the child's hindered ability to make sense of information taken in through the eyes, the Multimodal AI agent transforms any visual information into auditory user interaction. In another instance, for a person with Central Auditory Processing Disorder (CAPD), given the hindrance in the individual's ability to analyze information taken in through the ears, the AI dynamically translates any speech modality into visual cues. Thus the AI agent adapts dynamically to the strengths and abilities of the individual. To enable students with VPD to learn, the design allows the student to ask questions about an image. This design is realized as a Visual Question Answering task in Vision Language Transformer models. We explore interactive multimodal conversations with Few shot Learning and In-Context Instruction Tuning of Multimodal Large Language Models to address difficulty in visual reasoning. To enable persons with CAPD to learn, the design translates audio lectures into visual cues. This visual cue consists of a combination of words using speech recognition and Large Language Models based re-phrasing to simpler words, cross-modal retrieval of images to address auditory memory challenges, and AI-generated images. To identify the strengths of each child, we also explore Multimodal embedding based Multimodal latent space arithmetic to link AI across senses. To effectively integrate the proposed design into the mainstream, we explore a universal design based inclusive approach to extend the use case to create AI assistants for assisting children with different learning styles such as visual learners or auditory learners. To enable future research on the proposed design, we explore an architecture to compose a pipeline of AI models, and to connect with external systems via plugin connectors. We implement lab scale prototypes of this design and present a demo on the project webpage at https://sites.google.com/view/multimodallearningdisability.},
booktitle = {Companion Publication of the 25th International Conference on Multimodal Interaction},
pages = {259–271},
numpages = {13},
keywords = {Visual Processing Disorder, Vision Language Models, Person with Disability, Multimodal latent space, Multimodal Large Language Transformers, Multimodal In-context Tuning, Multimodal Few shot Learning, Multimodal AI, Learning disability, Human Computer Interaction, Generative AI, Central Auditory Processing Disorder, Assistive Technology},
location = {Paris, France},
series = {ICMI '23 Companion}
}

@inproceedings{10.1145/3626772.3657657,
author = {Braga, Marco},
title = {Personalized Large Language Models through Parameter Efficient Fine-Tuning Techniques},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657657},
doi = {10.1145/3626772.3657657},
abstract = {Personalization of the search experience according to the users and their context is an important topic in Information Retrieval (IR), studied by the research community for a long time. The IR field has witnessed a transformation with the recent availability of pre-trained Large Language Models. Typically, personalization requires the model to incorporate user-specific information, through the definition of an appropriate prompting or injecting user knowledge into the model and then fine-tuning it. However, using prompting, we do not know where and how much the model is personalizing the output. Furthermore, fine-tuning such systems is computationally expensive: since they are characterized by billions of parameters, the fine-tuning process has introduced profound computational challenges. For these reasons, we propose a novel approach that combines personalization and Parameter Efficient Fine-Tuning methods.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3076},
numpages = {1},
keywords = {large language models, parameter efficient tuning, personalization},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3660395.3660411,
author = {Wang, Shuyue and Cao, Peng and Yan, Xiaotong and Mu, Shanwei and Yu, Xuelian and Wang, Xuan},
title = {A Preliminary Attempt of Deploying AIGC in Autodriving Scenario Generation: Via LLM},
year = {2024},
isbn = {9798400716362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660395.3660411},
doi = {10.1145/3660395.3660411},
abstract = {With huge progress in Large Language Model (LLM) by Artificial-Intelligence-Generated-Content (AIGC), a technical demand from the industry of autodriving with respect to scenario generation needs sees a new possible solution. Thus a new powerful tools of computational modeling, and simulation is now at hand. In this paper, we explore the use of prompt engineering and the fine-tuning applied to open-source model. This paper studies the use about OpenSCENARIO. The theoretical descriptions comes with practical experiment in comparisons of prompt feedbacks and performance estimation of long conceptual Q&amp;A and code snippet generation.},
booktitle = {Proceedings of the 2023 3rd Guangdong-Hong Kong-Macao Greater Bay Area Artificial Intelligence and Big Data Forum},
pages = {86–91},
numpages = {6},
keywords = {AIGC, Autodriving, ChatGPT, LLM, Llama-2, OpenSCENARIO, code generation},
location = {Guangzhou, China},
series = {AIBDF '23}
}

@article{10.1145/3735653,
author = {Ignacio, Marvin John and Kim, Yong-Guk and Jin, Hulin and Yu, Seunghee},
title = {U-Net Encapsulated Transformer for Reducing Dimensionality in Training Large Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3735653},
doi = {10.1145/3735653},
abstract = {Training language models from scratch presents a critical challenge in Natural Language Processing (NLP), primarily due to the computational demands of pre-trained Large Language Models, which are predominantly trained on English corpora using extensive resources. While offering viable solutions, existing alternatives still rely heavily on high-performance hardware. This work introduces a different approach to reducing the algorithmic complexity of Transformer-based architectures through the U-Net Encapsulated Transformer (UET), which applies dimensionality reduction to token embeddings. The UET architecture enables the development of language models with significantly reduced parameter sizes for a given set of hyperparameters. Alternatively, it allows researchers to design models of comparable size but with a substantially greater number of Transformer blocks, enhancing model depth and potential capacity. This study also outlines practical methodologies for training language models in resource-constrained environments. Experimental results illustrate the potential of the UET architecture in achieving reasonable performance under resource-constrained conditions, highlighting its promise as an accessible alternative for language model development. This work could broaden the accessibility of NLP research, empowering researchers with hardware constraints to contribute to language model development.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
keywords = {Language modeling, dimensionality reduction, training optimization}
}

@inproceedings{10.1145/3581784.3613215,
author = {Yin, Junqi and Dash, Sajal and Wang, Feiyi and Shankar, Mallikarjun},
title = {FORGE: Pre-Training Open Foundation Models for Science},
year = {2023},
isbn = {9798400701092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581784.3613215},
doi = {10.1145/3581784.3613215},
abstract = {Large language models (LLMs) are poised to revolutionize the way we conduct scientific research. However, both model complexity and pre-training cost are impeding effective adoption for the wider science community. Identifying suitable scientific use cases, finding the optimal balance between model and data sizes, and scaling up model training are among the most pressing issues that need to be addressed. In this study, we provide practical solutions for building and using LLM-based foundation models targeting scientific research use cases. We present an end-to-end examination of the effectiveness of LLMs in scientific research, including their scaling behavior and computational requirements on Frontier, the first Exascale supercomputer. We have also developed for release to the scientific community a suite of open foundation models called FORGE with up to 26B parameters using 257B tokens from over 200M scientific articles, with performance either on par or superior to other state-of-the-art comparable models. We have demonstrated the use and effectiveness of FORGE on scientific downstream tasks. Our research establishes best practices that can be applied across various fields to take advantage of LLMs for scientific discovery.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {81},
numpages = {13},
location = {Denver, CO, USA},
series = {SC '23}
}

@article{10.1145/3660811,
author = {Mai, Yubo and Gao, Zhipeng and Hu, Xing and Bao, Lingfeng and Liu, Yu and Sun, JianLing},
title = {Are Human Rules Necessary? Generating Reusable APIs with CoT Reasoning and In-Context Learning},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660811},
doi = {10.1145/3660811},
abstract = {Inspired by the great potential of Large Language Models (LLMs) for solving complex coding tasks, in this paper, we propose a novel approach, named Code2API, to automatically perform APIzation for Stack Overflow code snippets. Code2API does not require additional model training or any manual crafting rules and can be easily deployed on personal computers without relying on other external tools. Specifically, Code2API guides the LLMs through well-designed prompts to generate well-formed APIs for given code snippets. To elicit knowledge and logical reasoning from LLMs, we used chain-of-thought (CoT) reasoning and few-shot in-context learning, which can help the LLMs fully understand the APIzation task and solve it step by step in a manner similar to a developer. Our evaluations show that Code2API achieves a remarkable accuracy in identifying method parameters (65%) and return statements (66%) equivalent to human-generated ones, surpassing the current state-of-the-art approach, APIzator, by 15.0% and 16.5% respectively. Moreover, compared with APIzator, our user study demonstrates that Code2API exhibits superior performance in generating meaningful method names, even surpassing the human-level performance, and developers are more willing to use APIs generated by our approach, highlighting the applicability of our tool in practice. Finally, we successfully extend our framework to the Python dataset, achieving a comparable performance with Java, which verifies the generalizability of our tool.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {104},
numpages = {23},
keywords = {APIs, Chain-of-thought, In-context learning, Large language models, Stack Overflow}
}

@article{10.1145/3633287,
author = {Richards, Mike and Waugh, Kevin and Slaymaker, Mark and Petre, Marian and Woodthorpe, John and Gooch, Daniel},
title = {Bob or Bot: Exploring ChatGPT's Answers to University Computer Science Assessment},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
url = {https://doi.org/10.1145/3633287},
doi = {10.1145/3633287},
abstract = {Cheating has been a long-standing issue in university assessments. However, the release of ChatGPT and other free-to-use generative AI tools has provided a new and distinct method for cheating. Students can run many assessment questions through the tool and generate a superficially compelling answer, which may or may not be accurate.&nbsp;We ran a dual-anonymous “quality assurance” marking exercise across four end-of-module assessments across a distance university computer science (CS) curriculum. Each marker received five ChatGPT-generated scripts alongside 10 student scripts. A total of 90 scripts were marked; every ChatGPT-generated script for the undergraduate modules received at least a passing grade (&gt;40%), with all of the introductory module CS1 scripts receiving a distinction (&gt;85%). None of the ChatGPT-taught postgraduate scripts received a passing grade (&gt;50%). We also present the results of interviewing the markers and of running our sample scripts through a GPT-2 detector and the TurnItIn AI detector, which both identified every ChatGPT-generated script but differed in the number of false positives. As such, we contribute a baseline understanding of how the public release of generative AI is likely to significantly impact quality assurance processes. Our analysis demonstrates that in most cases, across a range of question formats, topics, and study levels, ChatGPT is at least capable of producing adequate answers for undergraduate assessment.},
journal = {ACM Trans. Comput. Educ.},
month = jan,
articleno = {5},
numpages = {32},
keywords = {ChatGPT, generative AI, cheating, quality assurance, university assessment’}
}

@inproceedings{10.1145/3597503.3639201,
author = {Choudhuri, Rudrajit and Liu, Dylan and Steinmacher, Igor and Gerosa, Marco and Sarma, Anita},
title = {How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639201},
doi = {10.1145/3597503.3639201},
abstract = {Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {184},
numpages = {13},
keywords = {empirical study, software engineering, generative AI, ChatGPT},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3706598.3714213,
author = {Park, Seokhyeon and Song, Yumin and Lee, Soohyun and Kim, Jaeyoung and Seo, Jinwook},
title = {Leveraging Multimodal LLM for Inspirational User Interface Search},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714213},
doi = {10.1145/3706598.3714213},
abstract = {Inspirational search, the process of exploring designs to inform and inspire new creative work, is pivotal in mobile user interface (UI) design. However, exploring the vast space of UI references remains a challenge. Existing AI-based UI search methods often miss crucial semantics like target users or the mood of apps. Additionally, these models typically require metadata like view hierarchies, limiting their practical use. We used a multimodal large language model (MLLM) to extract and interpret semantics from mobile UI images. We identified key UI semantics through a formative study and developed a semantic-based UI search system. Through computational and human evaluations, we demonstrate that our approach significantly outperforms existing UI retrieval methods, offering UI designers a more enriched and contextually relevant search experience. We enhance the understanding of mobile UI design semantics and highlight MLLMs’ potential in inspirational search, providing a rich dataset of UI semantics for future studies.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {579},
numpages = {22},
keywords = {Interface Design, UI Design, UI Retrieval, UI Search, Semantic Search, Multimodal LLM},
location = {
},
series = {CHI '25}
}

@article{10.1145/3705725,
author = {Yang, Yutao and Zhou, Jie and Ding, Xuanwen and Huai, Tianyu and Liu, Shunyu and Chen, Qin and Xie, Yuan and He, Liang},
title = {Recent Advances of Foundation Language Models-based Continual Learning: A Survey},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3705725},
doi = {10.1145/3705725},
abstract = {Recently, foundation language models (LMs) have marked significant achievements in the domains of natural language processing and computer vision. Unlike traditional neural network models, foundation LMs obtain a great ability for transfer learning by acquiring rich common sense knowledge through pre-training on extensive unsupervised datasets with a vast number of parameters. Despite these capabilities, LMs still struggle with catastrophic forgetting, hindering their ability to learn continuously like humans. To address this, continual learning (CL) methodologies have been introduced, allowing LMs to adapt to new tasks while retaining learned knowledge. However, a systematic taxonomy of existing approaches and a comparison of their performance are still lacking. In this article, we delve into a comprehensive review, summarization, and classification of the existing literature on CL-based approaches applied to foundation language models, such as pre-trained language models, large language models, and vision-language models. We divide these studies into offline and online CL, which consist of traditional methods, parameter-efficient-based methods, instruction tuning-based methods and continual pre-training methods. Additionally, we outline the typical datasets and metrics employed in CL research and provide a detailed analysis of the challenges and future work for LMs-based continual learning.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {112},
numpages = {38},
keywords = {Continual learning, foundation language models, pre-trained language models, large language models, vision-language models, survey}
}

@inproceedings{10.1145/3689217.3690614,
author = {Cong, Tianshuo and Ran, Delong and Liu, Zesen and He, Xinlei and Liu, Jinyuan and Gong, Yichen and Li, Qi and Wang, Anyu and Wang, Xiaoyun},
title = {Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging},
year = {2024},
isbn = {9798400712098},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689217.3690614},
doi = {10.1145/3689217.3690614},
abstract = {Model merging is a promising lightweight model empowerment technique that does not rely on expensive computing devices (e.g., GPUs) or require the collection of specific training data. Instead, it involves editing different upstream model parameters to absorb their downstream task capabilities. However, uncertified model merging can infringe upon the Intellectual Property (IP) rights of the original upstream models. In this paper, we conduct the first study on the robustness of IP protection methods under model merging scenarios. Specifically, we investigate two state-of-the-art IP protection techniques: Quantization Watermarking and Instructional Fingerprint, along with various advanced model merging technologies, such as Task Arithmetic, TIES-MERGING, and so on. Experimental results indicate that current Large Language Model (LLM) watermarking techniques cannot survive in the merged models, whereas model fingerprinting techniques can. Our research aims to highlight that model merging should be an indispensable consideration in the robustness assessment of model IP protection techniques, thereby promoting the healthy development of the open-source LLM community.},
booktitle = {Proceedings of the 1st ACM Workshop on Large AI Systems and Models with Privacy and Safety Analysis},
pages = {69–76},
numpages = {8},
keywords = {intellectual property, large language models, model merging},
location = {Salt Lake City, UT, USA},
series = {LAMPS '24}
}

@inproceedings{10.1145/3583780.3615047,
author = {Hoq, Muntasir and Chilla, Sushanth Reddy and Ahmadi Ranjbar, Melika and Brusilovsky, Peter and Akram, Bita},
title = {SANN: Programming Code Representation Using Attention Neural Network with Optimized Subtree Extraction},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615047},
doi = {10.1145/3583780.3615047},
abstract = {Automated analysis of programming data using code representation methods offers valuable services for programmers, from code completion to clone detection to bug detection. Recent studies show the effectiveness of Abstract Syntax Trees (AST), pre-trained Transformer-based models, and graph-based embeddings in programming code representation. However, pre-trained large language models lack interpretability, while other embedding-based approaches struggle with extracting important information from large ASTs. This study proposes a novel Subtree-based Attention Neural Network (SANN) to address these gaps by integrating different components: an optimized sequential subtree extraction process using Genetic algorithm optimization, a two-way embedding approach, and an attention network. We investigate the effectiveness of SANN by applying it to two different tasks: program correctness prediction and algorithm detection on two educational datasets containing both small and large-scale code snippets written in Java and C, respectively. The experimental results show SANN's competitive performance against baseline models from the literature, including code2vec, ASTNN, TBCNN, CodeBERT, GPT-2, and MVG, regarding accurate predictive power. Finally, a case study is presented to show the interpretability of our model prediction and its application for an important human-centered computing application, student modeling. Our results indicate the effectiveness of the SANN model in capturing important syntactic and semantic information from students' code, allowing the construction of accurate student models, which serve as the foundation for generating adaptive instructional support such as individualized hints and feedback.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {783–792},
numpages = {10},
keywords = {static analysis, program correctness prediction, program analysis, code representation, algorithm detection},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3605764.3623985,
author = {Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario},
title = {Not What You've Signed Up For: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection},
year = {2023},
isbn = {9798400702600},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605764.3623985},
doi = {10.1145/3605764.3623985},
abstract = {Large Language Models (LLMs) are increasingly being integrated into applications, with versatile functionalities that can be easily modulated via natural language prompts. So far, it was assumed that the user is directly prompting the LLM. But, what if it is not the user prompting? We show that LLM-Integrated Applications blur the line between data and instructions and reveal several new attack vectors, using Indirect Prompt Injection, that enable adversaries to remotely (i.e., without a direct interface) exploit LLM-integrated applications by strategically injecting prompts into data likely to be retrieved at inference time. We derive a comprehensive taxonomy from a computer security perspective to broadly investigate impacts and vulnerabilities, including data theft, worming, information ecosystem contamination, and other novel security risks. We then demonstrate the practical viability of our attacks against both real-world systems, such as Bing Chat and code-completion engines, and GPT-4 synthetic applications. We show how processing retrieved prompts can act as arbitrary code execution, manipulate the application's functionality, and control how and if other APIs are called. Despite the increasing reliance on LLMs, effective mitigations of these emerging threats are lacking. By raising awareness of these vulnerabilities, we aim to promote the safe and responsible deployment of these powerful models and the development of robust defenses that protect users from potential attacks.},
booktitle = {Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security},
pages = {79–90},
numpages = {12},
keywords = {indirect prompt injection, large language models},
location = {Copenhagen, Denmark},
series = {AISec '23}
}

@inproceedings{10.1145/3691620.3695513,
author = {Jiang, Zongze and Wen, Ming and Cao, Jialun and Shi, Xuanhua and Jin, Hai},
title = {Towards Understanding the Effectiveness of Large Language Models on Directed Test Input Generation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695513},
doi = {10.1145/3691620.3695513},
abstract = {Automatic testing has garnered significant attention and success over the past few decades. Techniques such as unit testing and coverage-guided fuzzing have revealed numerous critical software bugs and vulnerabilities. However, a long-standing, formidable challenge for existing techniques is how to achieve higher testing coverage. Constraint-based techniques, such as symbolic execution and concolic testing, have been well-explored and integrated into the existing approaches. With the popularity of Large Language Models (LLMs), recent research efforts to design tailored prompts to generate inputs that can reach more uncovered target branches. However, the effectiveness of using LLMs for generating such directed inputs and the comparison with the proven constraint-based solutions has not been systematically explored.To bridge this gap, we conduct the first systematic study on the mainstream LLMs and constraint-based tools for directed input generation with a comparative perspective. We find that LLMs such as ChatGPT are comparable to or even better than the constraint-based tools, succeeding in 43.40%-58.57% samples in our dataset. Meanwhile, there are also limitations for LLMs in specific scenarios such as sequential calculation, where constraint-based tools are in a position of strength. Based on these findings, we propose a simple yet effective method to combine these two types of tools and implement a prototype based on ChatGPT and constraint-based tools. Our evaluation shows that our approach can outperform the baselines by 1.4x to 2.3x relatively. We believe our study can provide novel insights into directed input generation using LLMs, and our findings are essential for future testing research.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1408–1420},
numpages = {13},
keywords = {LLM, symbolic execution, directed input generation},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3641825.3687742,
author = {Liu, Chao and Cheung, Chi San (Clarence) and Xu, Mingqing and Zhang, Zhongyue and Su, Mingyang and Fan, Mingming},
title = {Toward Facilitating Search in VR With the Assistance of Vision Large Language Models},
year = {2024},
isbn = {9798400705359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641825.3687742},
doi = {10.1145/3641825.3687742},
abstract = {While search is a common need in Virtual Reality (VR) applications, current approaches are cumbersome, often requiring users to type on a mid-air keyboard using controllers in VR or remove VR equipment to search on a computer. We first conducted a literature review and a formative study, identifying six common search needs: knowing about one object, knowing about the object’s partial details, knowing objects with environmental context, knowing about interactions with objects, and finding objects within field of view (FOV) and out of FOV in the VR scene. Informed by these needs, we designed technology probes that leveraged recent advances in Vision Large Language Models and conducted a probe-based study with users to elicit feedback. Based on the findings, we derived design principles for VR designers and developers to consider when designing a user-friendly search interface in VR. While prior work about VR search tended to address specific aspects of search, our work contributes design considerations aimed at enhancing the ease of search in VR and potential future directions.},
booktitle = {Proceedings of the 30th ACM Symposium on Virtual Reality Software and Technology},
articleno = {35},
numpages = {14},
keywords = {VR search, Virtual reality, participatory design, vision large language model},
location = {Trier, Germany},
series = {VRST '24}
}

@inproceedings{10.1145/3706598.3713791,
author = {Pan, Ziqi and Zhang, Xiucheng and Li, Zisu and Peng, Zhenhui and Fan, Mingming and Ma, Xiaojuan},
title = {ACKnowledge: A Computational Framework for Human Compatible Affordance-based Interaction Planning in Real-world Contexts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713791},
doi = {10.1145/3706598.3713791},
abstract = {Intelligent agents coexisting with humans often need to interact with human-shared objects in environments. Thus, agents should plan their interactions based on objects’ affordances and the current situation to achieve acceptable outcomes. How to support intelligent agents’ planning of affordance-based interactions compatible with human perception and values in real-world contexts remains under-explored. We conducted a formative study identifying the physical, intrapersonal, and interpersonal contexts that count to household human-agent interaction. We then proposed ACKnowledge, a computational framework integrating a dynamic knowledge graph, a large language model, and a vision language model for affordance-based interaction planning in dynamic human environments. In evaluations, ACKnowledge generated acceptable planning results with an understandable process. In real-world simulation tasks, ACKnowledge achieved a high execution success rate and overall acceptability, significantly enhancing usage-rights respectfulness and social appropriateness over baselines. The case study’s feedback demonstrated ACKnowledge’s negotiation and personalization capabilities toward an understandable planning process.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {892},
numpages = {20},
keywords = {Affordance-based Interaction Planning, Real-world Context, Human Compatible},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3642970.3655837,
author = {Neague, Petru and Gregoriadis, Marcel and Pouwelse, Johan},
title = {De-DSI: Decentralised Differentiable Search Index},
year = {2024},
isbn = {9798400705410},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3642970.3655837},
doi = {10.1145/3642970.3655837},
abstract = {This study introduces De-DSI, a novel framework that fuses large language models (LLMs) with genuine decentralization for information retrieval, particularly employing the differentiable search index (DSI) concept in a decentralized setting. Focused on efficiently connecting novel user queries with document identifiers without direct document access, De-DSI operates solely on query-docid pairs. To enhance scalability, an ensemble of DSI models is introduced, where the dataset is partitioned into smaller shards for individual model training. This approach not only maintains accuracy by reducing the number of data each model needs to handle but also facilitates scalability by aggregating outcomes from multiple models. This aggregation uses a beam search to identify top docids and applies a softmax function for score normalization, selecting documents with the highest scores for retrieval. The decentralized implementation demonstrates that retrieval success is comparable to centralized methods, with the added benefit of the possibility of distributing computational complexity across the network. This setup also allows for the retrieval of multimedia items through magnet links, eliminating the need for platforms or intermediaries.},
booktitle = {Proceedings of the 4th Workshop on Machine Learning and Systems},
pages = {134–143},
numpages = {10},
keywords = {Distributed Systems, Information Retrieval, Large Language Models (LLMs)},
location = {Athens, Greece},
series = {EuroMLSys '24}
}

@inproceedings{10.1145/3689031.3696075,
author = {Sheng, Guangming and Zhang, Chi and Ye, Zilingfeng and Wu, Xibin and Zhang, Wang and Zhang, Ru and Peng, Yanghua and Lin, Haibin and Wu, Chuan},
title = {HybridFlow: A Flexible and Efficient RLHF Framework},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689031.3696075},
doi = {10.1145/3689031.3696075},
abstract = {Reinforcement Learning from Human Feedback (RLHF) is widely used in Large Language Model (LLM) alignment. Traditional RL can be modeled as a dataflow, where each node represents computation of a neural network (NN) and each edge denotes data dependencies between the NNs. RLHF complicates the dataflow by expanding each node into a distributed LLM training or generation program, and each edge into a many-to-many multicast. Traditional RL frameworks execute the dataflow using a single controller to instruct both intra-node computation and inter-node communication, which can be inefficient in RLHF due to large control dispatch overhead for distributed intra-node computation. Existing RLHF systems adopt a multi-controller paradigm, which can be inflexible due to nesting distributed computation and data communication. We propose HybridFlow, which combines single-controller and multi-controller paradigms in a hybrid manner to enable flexible representation and efficient execution of the RLHF data flow. We carefully design a set of hierarchical APIs that decouple and encapsulate computation and data dependencies in the complex RLHF dataflow, allowing efficient operation orchestration to implement RLHF algorithms and flexible mapping of the computation onto various devices. We further design a 3D-HybridEngine for efficient actor model resharding between training and generation phases, with zero memory redundancy and significantly reduced communication overhead. Our experimental results demonstrate 1.53x~20.57\texttimes{} throughput improvement when running various RLHF algorithms using HybridFlow, as compared with state-of-the-art baselines. HybridFlow source code is available at https://github.com/volcengine/verl},
booktitle = {Proceedings of the Twentieth European Conference on Computer Systems},
pages = {1279–1297},
numpages = {19},
keywords = {Distributed systems, Reinforcement Learning from Human Feedback},
location = {Rotterdam, Netherlands},
series = {EuroSys '25}
}

@inproceedings{10.1145/3539618.3592067,
author = {Ferraretto, Fernando and Laitz, Thiago and Lotufo, Roberto and Nogueira, Rodrigo},
title = {ExaRanker: Synthetic Explanations Improve Neural Rankers},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3592067},
doi = {10.1145/3539618.3592067},
abstract = {Recent work has shown that incorporating explanations into the output generated by large language models (LLMs) can significantly enhance performance on a broad spectrum of reasoning tasks. Our study extends these findings by demonstrating the benefits of explanations for neural rankers. By utilizing LLMs such as GPT-3.5 to enrich retrieval datasets with explanations, we trained a sequence-to-sequence ranking model, dubbed ExaRanker, to generate relevance labels and explanations for query-document pairs. The ExaRanker model, finetuned on a limited number of examples and synthetic explanations, exhibits performance comparable to models finetuned on three times more examples, but without explanations. Moreover, incorporating explanations imposes no additional computational overhead into the reranking step and allows for on-demand explanation generation. The codebase and datasets used in this study will be available at https://github.com/unicamp-dl/ExaRanker},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2409–2414},
numpages = {6},
keywords = {explanations, few-shot models, generative models, large language models, multi-stage ranking, synthetic datasets},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3605507.3610629,
author = {Gehringer, Edward F. and Wang, Jianxun George and Jilla, Sharan Kumar},
title = {Dual-Submission Homework in Parallel Computer Architecture: An Exploratory Study in the Age of LLMs},
year = {2024},
isbn = {9798400702532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605507.3610629},
doi = {10.1145/3605507.3610629},
abstract = {The traditional model of assigning textbook problems for homework is endangered by the ability of students to find answers to almost any published problem on the web. An alternative is a dual-submission approach, where students submit their work, then receive the solutions, and submit a second metacognitive reflection, explaining any errors they made. Students’ scores can depend on the quality of their second submissions alone or the combined quality of their first and second submissions. We tried this approach in a class on parallel computer architecture. We report students’ personal experience based on their questionnaires responses. In addition, we quantitatively compare students’ performance on test questions related to dual-submission homework against their performance on other questions and previous semesters’ student performance on similar questions. Students overwhelmingly preferred this approach and thought they learned more from it, but evidence about whether it improved their learning was inconclusive. We also analyze the continued viability of this approach in the era of large language models.},
booktitle = {Proceedings of the Workshop on Computer Architecture Education},
pages = {41–47},
numpages = {7},
location = {Orlando, FL, USA},
series = {WCAE '23}
}

@inproceedings{10.1145/3653804.3654608,
author = {Qiu, Hongjie and Li, Jinqiang and Gan, Junhao and Zheng, Shuwen and Yan, Liqi},
title = {DroneGPT: Zero-shot Video Question Answering For Drones},
year = {2024},
isbn = {9798400718199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653804.3654608},
doi = {10.1145/3653804.3654608},
abstract = {With the continuous development and popularization of drone technology, drones are widely used in various fields, especially in drone video applications. We propose DroneGPT, a neural-symbolic method that learns VISPROG, which does not require any task-specific training. It leverages the contextual learning ability of large language models to generate and execute modular programs, solving complex and compositional drone vision tasks given natural language instructions. The modules in the program can call several ready-made computer vision models to achieve object detection, or write image processing programs by themselves, and finally connect them to achieve drone video question answering. We believe that DroneGPT can expand the task scope of drones in the video field and further enrich the functions of contemporary drones.},
booktitle = {Proceedings of the International Conference on Computer Vision and Deep Learning},
articleno = {49},
numpages = {6},
keywords = {Grounding DINO, computer vision, drone, question answering, video analysis, visual programing},
location = {Changsha, China},
series = {CVDL '24}
}

@inproceedings{10.1145/3690624.3709277,
author = {He, Yufei and Sui, Yuan and He, Xiaoxin and Hooi, Bryan},
title = {UniGraph: Learning a Unified Cross-Domain Foundation Model for Text-Attributed Graphs},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709277},
doi = {10.1145/3690624.3709277},
abstract = {Foundation models like ChatGPT and GPT-4 have revolutionized artificial intelligence, exhibiting remarkable abilities to generalize across a wide array of tasks and applications beyond their initial training objectives. However, graph learning has predominantly focused on single-graph models, tailored to specific tasks or datasets, lacking the ability to transfer learned knowledge to different domains. This limitation stems from the inherent complexity and diversity of graph structures, along with the different feature and label spaces specific to graph data. In this paper, we recognize text as an effective unifying medium and employ Text-Attributed Graphs (TAGs) to leverage this potential. We present our UniGraph framework, designed to learn a foundation model for TAGs, which is capable of generalizing to unseen graphs and tasks across diverse domains. Unlike single-graph models that use pre-computed node features of varying dimensions as input, our approach leverages textual features for unifying node representations, even for graphs such as molecular graphs that do not naturally have textual features. We propose a novel cascaded architecture of Language Models (LMs) and Graph Neural Networks (GNNs) as backbone networks. Additionally, we propose the first pre-training algorithm specifically designed for large-scale self-supervised learning on TAGs, based on Masked Graph Modeling. We introduce graph instruction tuning using Large Language Models (LLMs) to enable zero-shot prediction ability. Our comprehensive experiments across various graph learning tasks and domains demonstrate the model's effectiveness in self-supervised representation learning on unseen graphs, few-shot in-context transfer, and zero-shot transfer, even surpassing or matching the performance of GNNs that have undergone supervised training on target datasets.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {448–459},
numpages = {12},
keywords = {graph neural networks, graph pre-training, self-supervised learning},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3649158.3657032,
author = {Rubio-Medrano, Carlos E. and Kotak, Akash and Wang, Wenlu and Sohr, Karsten},
title = {Pairing Human and Artificial Intelligence: Enforcing Access Control Policies with LLMs and Formal Specifications},
year = {2024},
isbn = {9798400704918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649158.3657032},
doi = {10.1145/3649158.3657032},
abstract = {Large Language Models (LLMs), such as ChatGPT and Google Bard, have performed interestingly well when assisting developers on computer programming tasks, a.k.a., coding, thus potentially resulting in convenient and faster software constructions. This new approach significantly enhances efficiency but also presents challenges in unsupervised code construction with limited security guarantees. LLMs excel in producing code with accurate grammar, yet they are not specifically trained to guarantee the security of the code. In this paper, we provide an initial exploration into using formal software specifications as a starting point for software construction, allowing developers to translate descriptions of security-related behavior into natural language instructions for LLMs, a.k.a., prompts. In addition, we leveraged automated verification tools to evaluate the code produced against the aforementioned specifications , following a modular, step-by-step software construction process. For our study, we leveraged Role-based Access Control (RBAC), a mature security model, and the Java Modeling Language (JML), a behavioral specification language for Java. We test our approach on different publicly-available LLMs, namely, OpenAI ChatGPT 4.0, Google Bard, and Microsoft CoPilot. We provide a description of two applications-a security-sensitive Banking application employing RBAC and an RBAC API module itself-, the corresponding JML specifications, as well as a description of the prompts, the generated code, the verification results, as well as a series of interesting insights for practitioners interested in further exploring the use of LLMs for securely constructing applications.},
booktitle = {Proceedings of the 29th ACM Symposium on Access Control Models and Technologies},
pages = {105–116},
numpages = {12},
keywords = {chatgpt, formal specifications, large language models, prompt engineering, software construction. java modeling language},
location = {San Antonio, TX, USA},
series = {SACMAT 2024}
}

@article{10.1145/3660790,
author = {Hassan, Md Mahadi and Salvador, John and Santu, Shubhra Kanti Karmaker and Rahman, Akond},
title = {State Reconciliation Defects in Infrastructure as Code},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660790},
doi = {10.1145/3660790},
abstract = {In infrastructure as code (IaC), state reconciliation is the process of querying and comparing the infrastructure state prior to changing the infrastructure. As state reconciliation is pivotal to manage IaC-based computing infrastructure at scale, defects related to state reconciliation can create large-scale consequences. A categorization of state reconciliation defects, i.e., defects related to state reconciliation, can aid in understanding the nature of state reconciliation defects. We conduct an empirical study with 5,110 state reconciliation defects where we apply qualitative analysis to categorize state reconciliation defects. From the identified defect categories, we derive heuristics to design prompts for a large language model (LLM), which in turn are used for validation of state reconciliation. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
From our empirical study, we identify 8 categories of state reconciliation defects, amongst which 3 have not been reported for previously-studied software systems. The most frequently occurring defect category is inventory, i.e., the category of defects that occur when managing infrastructure inventory. Using an LLM with heuristics-based paragraph style prompts, we identify 9 previously unknown state reconciliation defects of which 7 have been accepted as valid defects, and 4 have already been fixed. Based on our findings, we conclude the paper by providing a set of recommendations for researchers and practitioners.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {83},
numpages = {24},
keywords = {defect, devops, empirical study, infrastructure as code, state reconciliation}
}

@inproceedings{10.1145/3613905.3650927,
author = {Su, Xia and Koh, Eunyee and Xiao, Chang},
title = {SonifyAR: Context-Aware Sound Effect Generation in Augmented Reality},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650927},
doi = {10.1145/3613905.3650927},
abstract = {Sound plays crucial roles in enhancing user experience and immersiveness in Augmented Reality (AR). However, current AR authoring platforms lack support for creating sound effects that harmonize with both the virtual and the real-world contexts. In this work, we present SonifyAR, a novel system for generating context-aware sound effects in AR experiences. SonifyAR implements a Programming by Demonstration (PbD) AR authoring pipeline. We utilize computer vision models and a large language model (LLM) to generate text descriptions that incorporate context information of user, virtual object and real world environment. This context information is then used to acquire sound effects with recommendation, generation, and retrieval methods. The acquired sound effects can be tested and assigned to AR events. Our user interface also provides the flexibility to allow users to iteratively explore and fine-tune the sound effects. We conducted a preliminary user study to demonstrate the effectiveness and usability of our system.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {297},
numpages = {7},
keywords = {Augmented Reality, Authoring Tool, Mixed Reality, Sound},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3635059.3635104,
author = {Karanikolas, Nikitas and Manga, Eirini and Samaridi, Nikoletta and Tousidou, Eleni and Vassilakopoulos, Michael},
title = {Large Language Models versus Natural Language Understanding and Generation},
year = {2024},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635059.3635104},
doi = {10.1145/3635059.3635104},
abstract = {In recent years, the process humans adopt to learn a foreign language has moved from the strict "Grammar –Translation" method, which is based mainly on grammar and syntax rules, to more innovative processes, resulting to the more modern "Communicative approach". As its name states, this approach focuses on the coherent communication with native speakers and the cultivation of oral skills, without taking into consideration, at least at the first stages, the rules that govern the language. The same trend seems to have been applied to the way machinery can be "educated" to comprehend and reproduce the unfamiliar, human language. The "rule based" Natural Language Generation (NLG) and Natural Language Understanding (NLU) algorithms, on one hand, and the "text based" Large Language Models (LLMs), on the other, are two, analogous to the two human foreign language learning processes, subareas of Natural Language Processing (NLP). This paper presents these two alternative approaches, LLMs (a technology having surfaced as an influential catalyst of NLP, during last years) on the one hand and NLG/NLU on the other, highlighting their applications, their technologies, their capabilities, their differences, their strengths and weaknesses and the challenges they present, contributing to a deeper comprehension of the evolving landscape of Artificial Intelligence and human-computer communication.},
booktitle = {Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {278–290},
numpages = {13},
keywords = {Large Language Models, Natural Language Generation, Natural Language Processing, Natural Language Understanding},
location = {Lamia, Greece},
series = {PCI '23}
}

@inproceedings{10.1145/3630106.3658993,
author = {Mirowski, Piotr and Love, Juliette and Mathewson, Kory and Mohamed, Shakir},
title = {A Robot Walks into a Bar: Can Language Models Serve as Creativity SupportTools for Comedy? An Evaluation of LLMs’ Humour Alignment with Comedians},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658993},
doi = {10.1145/3630106.3658993},
abstract = {We interviewed twenty professional comedians who perform live shows in front of audiences and who use artificial intelligence in their artistic process as part of 3-hour workshops on “AI x Comedy” conducted at the Edinburgh Festival Fringe in August 2023 and online. The workshop consisted of a comedy writing session with large language models (LLMs), a human-computer interaction questionnaire to assess the Creativity Support Index of AI as a writing tool, and a focus group interrogating the comedians’ motivations for and processes of using AI, as well as their ethical concerns about bias, censorship and copyright. Participants noted that existing moderation strategies used in safety filtering and instruction-tuned LLMs reinforced hegemonic viewpoints by erasing minority groups and their perspectives, and qualified this as a form of censorship. At the same time, most participants felt the LLMs did not succeed as a creativity support tool, by producing bland and biased comedy tropes, akin to “cruise ship comedy material from the 1950s, but a bit less racist”. Our work extends scholarship about the subtle difference between, one the one hand, harmful speech, and on the other hand, “offensive” language as a practice of resistance, satire and “punching up”. We also interrogate the global value alignment behind such language models, and discuss the importance of community-based value alignment and data ownership to build AI tools that better suit artists’ needs. Warning: this study may contain offensive language and discusses self-harm.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1622–1636},
numpages = {15},
keywords = {Censorship, Comedy, Creativity, Large Language Models, Offensive speech, Value Alignment},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@article{10.1145/3643753,
author = {Wang, Yan and Li, Xiaoning and Nguyen, Tien N. and Wang, Shaohua and Ni, Chao and Ding, Ling},
title = {Natural Is the Best: Model-Agnostic Code Simplification for Pre-trained Large Language Models},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643753},
doi = {10.1145/3643753},
abstract = {Pre-trained Large Language Models (LLM) have achieved remarkable successes in several domains. However, code-oriented LLMs are often heavy in computational complexity, and quadratically with the length of the input code sequence. Toward simplifying the input program of an LLM, the state-of-the-art approach has the strategies to filter the input code tokens based on the attention scores given by the LLM. The decision to simplify the input program should not rely on the attention patterns of an LLM, as these patterns are influenced by both the model architecture and the pre-training dataset. Since the model and dataset are part of the solution domain, not the problem domain where the input program belongs, the outcome may differ when the model is pre-trained on a different dataset. We propose SlimCode, a model-agnostic code simplification solution for LLMs that depends on the nature of input code tokens. As an empirical study on the LLMs including CodeBERT, CodeT5, and GPT-4 for two main tasks: code search and summarization, we reported that 1) the removal ratio of code has a linear-like relation with the saving ratio on training time, 2) the impact of categorized tokens on code simplification can vary significantly, 3) the impact of categorized tokens on code simplification is task-specific but model-agnostic, and 4) the above findings hold for the paradigm–prompt engineering and interactive in-context learning. The empirical results showed that SlimCode can improve the state-of-the-art technique by 9.46% and 5.15% in terms of MRR and BLEU score on code search and summarization, respectively. More importantly, SlimCode is 133 times faster than the state-of-the-art approach. Additionally, SlimCode can reduce the cost of invoking GPT-4 by up to 24% per API query, while still producing comparable results to those with the original code. With this result, we call for a new direction on code-based, model-agnostic code simplification solutions to further empower LLMs.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {27},
numpages = {23},
keywords = {AI4SE, Code Simplification, Machine Learning, Neural Networks, Pre-trained Large Language Models}
}

@inproceedings{10.1145/3673038.3673043,
author = {Ouyang, Bei and Ye, Shengyuan and Zeng, Liekang and Qian, Tianyi and Li, Jingyi and Chen, Xu},
title = {Pluto and Charon: A Time and Memory Efficient Collaborative Edge AI Framework for Personal LLMs Fine-tuning},
year = {2024},
isbn = {9798400717932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673038.3673043},
doi = {10.1145/3673038.3673043},
abstract = {Large language models (LLMs) have unlocked a plethora of powerful applications at the network edge, such as intelligent personal assistants. Data privacy and security concerns have prompted a shift towards edge-based fine-tuning of personal LLMs, away from cloud reliance. However, this raises issues of computational intensity and resource scarcity, hindering training efficiency and feasibility. While current studies investigate parameter-efficient fine-tuning (PEFT) techniques to mitigate resource constraints, our analysis indicates that these techniques are not sufficiently resource-efficient for edge devices. Other studies focus on exploiting the potential of edge devices through resource management optimization, yet are ultimately bottlenecked by the resource wall of individual devices. To tackle these challenges, we propose Pluto and Charon (PAC), a time and memory efficient collaborative edge AI framework for personal LLMs fine-tuning. PAC breaks the resource wall of personal LLMs fine-tuning with a sophisticated algorithm-system co-design. (1) Algorithmically, PAC implements a personal LLMs fine-tuning technique that is efficient in terms of parameters, time, and memory. It utilizes Parallel Adapters to circumvent the need for a full backward pass through the LLM backbone. Additionally, an activation cache mechanism further streamlining the process by negating the necessity for repeated forward passes across multiple epochs. (2) Systematically, PAC leverages edge devices in close proximity, pooling them as a collective resource for in-situ personal LLMs fine-tuning, utilizing a hybrid data and pipeline parallelism to orchestrate distributed training. The use of the activation cache eliminates the need for forward pass through the LLM backbone, enabling exclusive fine-tuning of the Parallel Adapters using data parallelism. Extensive evaluation based on prototype implementation demonstrates that PAC remarkably outperforms state-of-the-art approaches, achieving up to 8.64 \texttimes{} end-to-end speedup and up to &lt;Formula format="inline"&gt;&lt;TexMath&gt;&lt;?TeX $88.16%$?&gt;&lt;/TexMath&gt;&lt;AltText&gt;Math 1&lt;/AltText&gt;&lt;File name="icpp24-5-inline1" type="svg"/&gt;&lt;/Formula&gt; reduction in memory footprint.},
booktitle = {Proceedings of the 53rd International Conference on Parallel Processing},
pages = {762–771},
numpages = {10},
keywords = {Edge intelligence, data parallelism, large language model, parallel processing, parameter-efficient fine-tuning, pipeline parallelism},
location = {Gotland, Sweden},
series = {ICPP '24}
}

@inproceedings{10.1145/3649476.3660378,
author = {Miftah, Samit Shahnawaz and Srivastava, Amisha and Kim, Hyunmin and Basu, Kanad},
title = {Assert-O: Context-based Assertion Optimization using LLMs},
year = {2024},
isbn = {9798400706059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649476.3660378},
doi = {10.1145/3649476.3660378},
abstract = {Modern computing relies on System-on-Chips (SoCs), integrating IP cores for complex functions. However, this integration introduces vulnerabilities, necessitating rigorous hardware security validation. The effectiveness of this validation depends on the security properties embedded in the SoC. Recent studies explore large language models (LLMs) for generating security properties, but these may not be directly optimized for validation. Manual intervention remains necessary to reduce their number. Security validation methods that rely on human expertise are not scalable as they are time-intensive and prone to human error. In order to address these issues, we introduce Assert-O, an automated framework designed to derive security properties from SoC documentation and optimize the generated properties. It also ranks the properties based on the security vulnerabilities they are associated with, thereby streamlining the validation process. Our method leverages hardware documentation to initially create security properties, which are subsequently consolidated and prioritized based on their level of criticality. This approach serves to expedite the validation procedure. Assert-O is trained on documentation of six IPs from OpenTitan. To evaluate our proposed method, Assert-O was assessed on five other modules from OpenTitan. Assert-O was able to generate 183 properties, which was further optimized to reduce them to 138 properties. Subsequently, these properties were ranked based on their impact on the security of the overall system.},
booktitle = {Proceedings of the Great Lakes Symposium on VLSI 2024},
pages = {233–239},
numpages = {7},
keywords = {Hardware Security, Hardware Verification, Large Language Models},
location = {Clearwater, FL, USA},
series = {GLSVLSI '24}
}

@inproceedings{10.1145/3582269.3615596,
author = {Cai, Alice and Rick, Steven R and Heyman, Jennifer L and Zhang, Yanxia and Filipowicz, Alexandre and Hong, Matthew and Klenk, Matt and Malone, Thomas},
title = {DesignAID: Using Generative AI and Semantic Diversity for Design Inspiration},
year = {2023},
isbn = {9798400701139},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582269.3615596},
doi = {10.1145/3582269.3615596},
abstract = {Designers often struggle to sufficiently explore large design spaces, which can lead to design fixation and suboptimal outcomes. Here we introduce DesignAID, a generative AI tool that supports broader design space exploration by first using large language models to produce a range of diverse ideas expressed in words, and then using image generation software to create images from these words. This innovative combination of AI-based capabilities allows human-computer pairs to rapidly create a diverse set of visual concepts without time-consuming drawing. In a study with 87 crowd-sourced designers, we found that designers rated the automatic generation of images from words as significantly more inspirational, enjoyable, and useful than a conventional baseline condition of image search using Pinterest. Surprisingly, however, we found that automatically generating highly diverse ideas had less value. For image generation, the high diversity condition was somewhat better in inspiration but no better in the other dimensions, and for image search it was significantly worse in all dimensions.},
booktitle = {Proceedings of The ACM Collective Intelligence Conference},
pages = {1–11},
numpages = {11},
keywords = {AI assistance, creativity support, generative AI, human AI collaboration, human-computer collaboration, machine learning},
location = {Delft, Netherlands},
series = {CI '23}
}

@inproceedings{10.1145/3626252.3630854,
author = {Neyem, Andres and Sandoval Alcocer, Juan Pablo and Mendoza, Marcelo and Centellas-Claros, Leonardo and Gonzalez, Luis A. and Paredes-Robles, Carlos},
title = {Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630854},
doi = {10.1145/3626252.3630854},
abstract = {StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {951–957},
numpages = {7},
keywords = {capstone courses, chatgpt, generative ai, large language models, software engineering education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3637528.3672194,
author = {Lin, Xihong},
title = {Empower an End-to-end Scalable and Interpretable Data Science Ecosystem using Statistics, AI and Domain Science},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672194},
doi = {10.1145/3637528.3672194},
abstract = {The data science ecosystem encompasses data fairness, statistical, ML and AI methods and tools, interpretable data analysis and results, and trustworthy decision-making. Rapid advancements in AI have revolutionized data utilization and enabled machines to learn from data more effectively. Statistics, as the science of learning from data while accounting for uncertainty, plays a pivotal role in addressing complex real-world problems and facilitating trustworthy decision-making. In this talk, I will discuss the challenges and opportunities involved in building an end-to-end scalable and interpretable data science ecosystem using the analysis of whole genome sequencing studies and biobanks that integrates statistics, ML/AI, and genomic and health science as an example. Biobanks collect whole genome data, electronic health records and epidemiological data. I will illustrate key points using the analysis of multi-ancestry whole genome sequencing studies and biobanks by discussing a few scalable and interpretable statistical and ML/AI methods, tools and data science resources.Specifically, first, data fairness and diversity is a critical pillar of a trustworthy data science ecosystem. About 85+% of genome wide association study samples in the last 15 years are European, resulting in disparity in genetic research. I will discuss the community effort on improving diversity in genetic studies in the last 10 years. I will present trans-ancestry polygenic risk scores (PRS) using millions of common genetic variants across the genome by leveraging large GWAS sample sizes of European and smaller sample sizes of under-represented populations for predicting disease risk using transfer learning and genetic association summary statistics. The performance of deep learning methods for PRS will also be discussed. Second, scalability in cloud platforms is critical for large scale affordable analysis for multi-ancestry biobanks and whole genome studies. I will discuss improving scalability in cloud-computing using interpretable sparsity via FastSparseGRM.To build an interpretable and powerful end-to-end ecosystem of rare variant analysis of large scale whole genome sequencing studies and biobanks, I will first introduce FAVOR, a multi-faceted variant functional annotation database and portal of all possible 9 billions of variants across the whole genome. I will discuss FAVOR-GPT, a LLM interface of the FAVOR functional annotation database to improve user experience for navigating FAVOR and performing variant functional annotation query and variant functional summary statistics calculations. I will also discuss FAVORannotator which can be used to functionally annotate any whole genome sequencing studies. I will also discuss STAAR and STAAR and STAARpipeline, the WGS rare variant analysis pipeline that boosts the power of WGS rare variant association analysis by dynamically incorporating multi-faceted variant functional annotations. Extension of incorporating single-cell data in WGS analysis will also be discussed. I will also discuss ensemble methods that improve the power of rare variant association tests.Cloud-deployment of these resources and tools in several ecosystems will be presented, such as RAP for the UK biobank, AnVIL for the NHGRI Genome Sequencing Program and All of Us, and BioData Catalyst for the NHLBI Trans-omics Precision Medine Program (TOPMed). This talk aims to ignite proactive and thought-provoking discussions, foster collaboration, and cultivate open-minded approaches to advance scientific discovery.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3–4},
numpages = {2},
keywords = {ai, annotation, biobanks, electronic health records, ensemble methods, gpt, integrative analysis, interpretability, machine learning, scalability, sparsity, statistics, summary statistics, whole genome sequencing studies},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3654777.3676379,
author = {Dogan, Mustafa Doga and Gonzalez, Eric J and Ahuja, Karan and Du, Ruofei and Cola\c{c}o, Andrea and Lee, Johnny and Gonzalez-Franco, Mar and Kim, David},
title = {Augmented Object Intelligence with XR-Objects},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676379},
doi = {10.1145/3654777.3676379},
abstract = {Seamless integration of physical objects as interactive digital entities remains a challenge for spatial computing. This paper explores Augmented Object Intelligence&nbsp; (AOI) in the context of XR, an interaction paradigm that aims to blur the lines between digital and physical by equipping real-world objects with the ability to interact as if they were digital, where every object has the potential to serve as a portal to digital functionalities. Our approach utilizes real-time object segmentation and classification, combined with the power of Multimodal Large Language Models (MLLMs), to facilitate these interactions without the need for object pre-registration. We implement the AOI concept in the form of XR-Objects, an open-source prototype system that provides a platform for users to engage with their physical environment in contextually relevant ways using object-based context menus. This system enables analog objects to not only convey information but also to initiate digital actions, such as querying for details or executing tasks. Our contributions are threefold: (1) we define the AOI concept and detail its advantages over traditional AI assistants, (2) detail the XR-Objects&nbsp; system’s open-source design and implementation, and (3) show its versatility through various use cases and a user study.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {19},
numpages = {15},
keywords = {augmented objects, augmented reality, context menus, extended reality, mixed reality, spatial computing, user interfaces},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3662158.3662806,
author = {Jacobs, Sam Ade and Tanaka, Masahiro and Zhang, Chengming and Zhang, Minjia and Aminadabi, Reza Yazdani and Song, Shuaiwen Leon and Rajbhandari, Samyam and He, Yuxiong},
title = {System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models},
year = {2024},
isbn = {9798400706684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662158.3662806},
doi = {10.1145/3662158.3662806},
abstract = {Computation in a typical Transformer-based large language model (LLM) can be characterized by batch size, hidden dimension, number of layers, and sequence length. Until now, system works for accelerating LLM training have focused on the first three dimensions: data parallelism for batch size, tensor parallelism for hidden size, and pipeline parallelism for model depth or layers. These widely studied forms of parallelism are not targeted or optimized for long sequence Transformer models. Given practical application needs for long sequence LLM, renewed attentions are being drawn to sequence parallelism. However, existing works in sequence parallelism are constrained by memory-communication inefficiency, limiting their scalability to long sequence large models. In this work, we introduce Ulysses, a novel, portable, and effective methodology for enabling highly efficient and scalable LLM training with extremely long sequence length. Ulysses at its core partitions input data along the sequence dimension and employs an efficient all-to-all collective communication for attention computation. Theoretical communication analysis shows that, whereas other methods incur communication overhead as sequence length increases, Ulysses maintains constant communication volume when sequence length and compute devices are increased proportionally. Furthermore, experimental evaluations show that Ulysses scales to more than 1 million context length and trains 2.5x faster with 4x longer sequence length than the existing method SOTA baseline.},
booktitle = {Proceedings of the 43rd ACM Symposium on Principles of Distributed Computing},
pages = {121–130},
numpages = {10},
keywords = {AI/ML, long context LLM, HPC, distributed training},
location = {Nantes, France},
series = {PODC '24}
}

@inproceedings{10.1145/3610978.3640671,
author = {Macdonald, Jacob P. and Mallick, Rohit and Wollaber, Allan B. and Pe\~{n}a, Jaime D. and McNeese, Nathan and Siu, Ho Chit},
title = {Language, Camera, Autonomy! Prompt-engineered Robot Control for Rapidly Evolving Deployment},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3640671},
doi = {10.1145/3610978.3640671},
abstract = {The Context-observant LLM-Enabled Autonomous Robots (CLEAR) platform offers a general solution for large language model (LLM)-enabled robot autonomy. CLEAR-controlled robots use natural language to perceive and interact with their environment: contextual description deriving from computer vision and optional human commands prompt intelligent LLM responses that map to robotic actions. By emphasizing prompting, system behavior is programmed without manipulating code, and unlike other LLM-based robot control methods, we do not perform any model fine-tuning. CLEAR employs off-the-shelf pre-trained machine learning models for controlling robots ranging from simulated quadcopters to terrestrial quadrupeds. We provide the open-source CLEAR platform, along with sample implementations for a Unity-based quadcopter and Boston Dynamics Spot® robot. Each LLM used, GPT-3.5, GPT-4, and LLaMA2, exhibited behavioral differences when embodied by CLEAR, contrasting in actuation preference, ability to apply new knowledge, and receptivity to human instruction. GPT-4 demonstrates best performance compared to GPT-3.5 and LLaMA2, showing successful task execution 97% of the time. The CLEAR platform contributes to HRI by increasing the usability of robotics for natural human interaction.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {717–721},
numpages = {5},
keywords = {computer vision, large language models, robotics, software},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3624918.3625339,
author = {Hua, Wenyue and Xu, Shuyuan and Ge, Yingqiang and Zhang, Yongfeng},
title = {How to Index Item IDs for Recommendation Foundation Models},
year = {2023},
isbn = {9798400704086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624918.3625339},
doi = {10.1145/3624918.3625339},
abstract = {Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item as in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text and hallucinated recommendations when deciding which item(s) to recommend, creating LLM-compatible item IDs to uniquely identify each item is essential for recommendation foundation models. In this study, we systematically examine the item ID creation and indexing problem for recommendation foundation models, using P5 as an example of the backbone LLM. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as random indexing, title indexing, and independent indexing. We then propose four simple yet effective solutions, including sequential indexing, collaborative indexing, semantic (content-based) indexing, and hybrid indexing. Our study highlights the significant influence of item indexing methods on the performance of LLM-based recommendation, and our results on real-world datasets validate the effectiveness of our proposed solutions. The research also demonstrates how recent advances on language modeling and traditional IR principles such as indexing can help each other for better learning and inference. Source code and data are available at https://github.com/Wenyueh/LLM-RecSys-ID.},
booktitle = {Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {195–204},
numpages = {10},
keywords = {Item ID and Indexing, Large Language Model, Recommendation},
location = {Beijing, China},
series = {SIGIR-AP '23}
}

@inproceedings{10.1145/3706370.3731641,
author = {Coronado, Angelo and Carvalho, Sergio T and Berretta, Luciana},
title = {See Through My Eyes: Using Multimodal Large Language Model for Describing Rendered Environments to Blind People},
year = {2025},
isbn = {9798400713910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706370.3731641},
doi = {10.1145/3706370.3731641},
abstract = {Extended Reality (XR) is quickly expanding “as the next major technology wave in personal computing”. Nevertheless, this expansion and adoption could also exclude certain disabled users, particularly people with visual impairment (VIP). According to the World Health Organization (WHO) in their 2019 publication, there were at least 2.2 billion people with visual impairment, a number that is also estimated to have increased in recent years. Therefore, it is important to include disabled users, especially visually impaired people, in the design of Head-Mounted Displays and Extended Reality environments. Indeed, this objective can be pursued by incorporating Multimodal Large Language Model (MLLM) technology, which can assist visually impaired people. As a case study, this study employs different prompts that result in environment descriptions from an MLLM integrated into a virtual reality (VR) escape room. Therefore, six potential prompts were engineered to generate valuable outputs for visually impaired users inside a VR environment. These outputs were evaluated using the G-Eval, and VIEScore metrics. Even though, the results show that the prompt patterns provided a description that aligns with the user’s point of view, it is highly recommended to evaluate these outputs through “expected outputs” from Orientation and Mobility Specialists, and Sighted Guides. Furthermore, the subsequent step in the process is to evaluate these outputs by visually impaired people themselves to identify the most effective prompt pattern.},
booktitle = {Proceedings of the 2025 ACM International Conference on Interactive Media Experiences},
pages = {451–457},
numpages = {7},
keywords = {accessibility, blind, visual impairment, LLM, spatial cognition, rendered environments, virtual reality},
location = {
},
series = {IMX '25}
}

@inproceedings{10.1145/3690624.3709421,
author = {Jiang, Yanru and Liang, Siyu and Choi, Junwon},
title = {Synthetic Survey Data Generation and Evaluation},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709421},
doi = {10.1145/3690624.3709421},
abstract = {Survey data are common and invaluable in social science research for understanding population processes and supporting policymaking and planning. Depending on the nature and scale, survey data sharing comes with privacy risks, and data collectors and agencies are constrained by disclosure permissions, limiting usage across research groups and institutes. Previous methods for synthetic data generation and deidentification may not entirely prevent information disclosures, or they may sacrifice data quality and granularity.Using a large-scale national voter file at both national and state levels, this paper introduces an end-to-end pipeline to streamline synthetic data generation and evaluation for survey researchers. This study selects four generative approaches based on different statistical assumptions: the regression-based Synthpop, the generative deep learning-based CTGAN and TVAE, and the large language model-based REaLDTabFormer, and compares them to the baseline synthetic minority oversampling technique (SMOTE). We consider three key dimensions of evaluation (utility, fidelity, and privacy) to highlight the strengths and weaknesses of each approach, and systematically evaluate across various datasets and training sizes. The results reveal that Synthpop is optimized for general utility (i.e., fidelity), while TVAE excels in downstream applications (i.e., target-specific utility) but compromises on general utility and potentially risks data overfitting. REaLDTabFormer demonstrates a balanced performance in both general and target-specific utility, whereas CTGAN offers the best privacy protection. We recommend that future researchers select a generative method by considering the trade-offs between performance across various evaluation dimensions, training size, data type, and computational infrastructure.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {2292–2302},
numpages = {11},
keywords = {generative data science, generative modeling, machine learning, survey data, synthetic data},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3641822.3641870,
author = {Sera, Rie and Washizaki, Hironori and Chen, Junyan and Fukazawa, Yoshiaki and Taga, Masahiro and Nakagawa, Kazuyuki and Sakai, Yusuke and Honda, Kiyoshi},
title = {Development of Data-driven Persona Including User Behavior and Pain Point through Clustering with User Log of B2B Software},
year = {2024},
isbn = {9798400705335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641822.3641870},
doi = {10.1145/3641822.3641870},
abstract = {Persona --- fictional user profiles --- are used to identify user requirements in software engineering. However, methods targeting revisions, especially for existing B2B services, remain sparse. This paper proposes a method that integrates several models, including k-means clustering, term frequency-inverse document frequency (TF-IDF), and generative AI. Users' behavior tendencies, pain points, and other attributes are output solely from clickstream log data, bypassing the traditional survey-based approaches of previous studies. Clickstreams are vectorized and categorized, whereas users are further analyzed on the basis of time and content of their clickstreams. A case study was conducted with evaluations carried out both quantitatively and qualitatively. The results suggest that, although some parameters still need improvement, fairly rated persona outcomes were attained.},
booktitle = {Proceedings of the 2024 IEEE/ACM 17th International Conference on Cooperative and Human Aspects of Software Engineering},
pages = {85–90},
numpages = {6},
keywords = {persona, data-driven design, pain point, clustering, user experience, user behavior, user analytics, machine learning, data science},
location = {Lisbon, Portugal},
series = {CHASE '24}
}

@article{10.1145/3707639,
author = {Quinn, Michael J. and Riley, Jeff},
title = {Companion Robots: A Debate},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2024},
number = {December},
url = {https://doi.org/10.1145/3707639},
doi = {10.1145/3707639},
abstract = {Is it good or bad for humans to form intimate relationships with machines? This question has vexed machine designers for many years. One of its early appearances in computing was Joe Weizenbaum's Eliza program in 1966. Eliza mimicked a conversation one might have with a Rogerian psychotherapist. Weizenbaum was astounded when some of his friends, including his secretary, started divulging personal secrets to the machine and having warm feeling for the machine. He tried to dissuade them by showing them the inner workings of Eliza: a short program with no intelligence, just a short algorithm substituting keywords into user-typed strings. He was unsuccessful. They did not want to be dissuaded. This question has come back into public view with the arrival of large language models, which engage in competent, fluid conversations. It is now possible for robots to have natural language conversations with people. One of the areas where this is happening is companion robots, which have been introduced into long term care homes to provide companionship with residents and alert caretakers when someone has an emergency.Ubiquity is pleased to present a debate on companion robots. Computer scientist and author Michael Quinn argues their use may bring harmful consequences. Ubiquity's Jeff Riley, a semi-retired technologist and casual researcher in theoretical astrophysics, argues they have proved beneficial in research studies. Following their position papers are short rebuttals by Quinn and Riley on each other's positions.---Peter J. Denning, Editor in Chief, Ubiquity},
journal = {Ubiquity},
month = dec,
articleno = {1},
numpages = {24}
}

@inproceedings{10.1145/3584371.3612956,
author = {Shi, Wenqi and Zhuang, Yuchen and Zhu, Yuanda and Iwinski, Henry and Wattenbarger, Michael and Wang, May Dongmei},
title = {Retrieval-Augmented Large Language Models for Adolescent Idiopathic Scoliosis Patients in Shared Decision-Making},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3612956},
doi = {10.1145/3584371.3612956},
abstract = {As health-related decision-making evolves, patients increasingly seek help from additional online resources such as "Dr. Google" and ChatGPT. Despite their potential, these tools encounter limitations, including the risk of potentially inaccurate information, a lack of specialized medical knowledge, the risk of generating unrealistic outputs (hallucinations), and significant computational demands. In this study, we develop and validate an innovative shared decisionmaking (SDM) tool, Chat-Orthopedist, for adolescent idiopathic scoliosis (AIS) patients and families to prepare a meaningful discussion with clinicians based on retrieval-augmented large language models. Firstly, we establish an external knowledge base with information on AIS disease and treatment options Secondly, we develop a retrieval-augmented ChatGPT to feed LLMs with AIS domain knowledge, providing accurate and comprehensible responses to patient inquiries. In addition, we perform a cyclical process of human-in-the-loop evaluations for system validation and improvement. ment. Chat-Orthopedist may optimize SDM workflow by enabling better interactive learning experiences, more effective clinical visits, and better-informed treatment decision-making.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {14},
numpages = {10},
keywords = {adolescent idiopathic scoliosis, shared decision-making, pediatric healthcare, information retrieval, large language models},
location = {Houston, TX, USA},
series = {BCB '23}
}

@inproceedings{10.1145/3635636.3656195,
author = {Manesh, Daniel and Bowman Jr., Douglas and Lee, Sang Won},
title = {SHARP: Exploring Version Control Systems in Live Coding Music},
year = {2024},
isbn = {9798400704857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635636.3656195},
doi = {10.1145/3635636.3656195},
abstract = {Version control systems, which have proven essential for software engineering, can also provide value to creative and artistic practices. In this paper, we explore version control in the creative domain of live coding music, a generative performance practice where programmers edit and run code live to generate audiovisual artifacts. To that end, we developed SHARP, a lightweight version control system that live coders can use during performances as well as in preparation or practice sessions. We conducted a user study where live coders used SHARP for several weeks, wrote diary entries reflecting on their sessions, recorded a performance using SHARP, and participated in exit interviews. We found that SHARP enabled participants to engage with musical form on the fly in novel ways. In addition, the study revealed multifaceted perspectives on how and when versioning can be useful in the context of live coding. Our results inform the design of versioning systems for live coding and more generally for performance and generative arts practices.},
booktitle = {Proceedings of the 16th Conference on Creativity &amp; Cognition},
pages = {426–437},
numpages = {12},
keywords = {creativity support tools, exploratory programming, live coding, versioning},
location = {Chicago, IL, USA},
series = {C&amp;C '24}
}

@inproceedings{10.1145/3676641.3716006,
author = {Cai, Weilin and Qin, Le and Huang, Jiayi},
title = {MoC-System: Efficient Fault Tolerance for Sparse Mixture-of-Experts Model Training},
year = {2025},
isbn = {9798400710797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676641.3716006},
doi = {10.1145/3676641.3716006},
abstract = {As large language models continue to scale up, distributed training systems have expanded beyond 10k nodes, intensifying the importance of fault tolerance. Checkpoint has emerged as the predominant fault tolerance strategy, with extensive studies dedicated to optimizing its efficiency. However, the advent of the sparse Mixture-of-Experts (MoE) model presents new challenges due to the substantial increase in model size, despite comparable computational demands to dense models.In this work, we propose the Mixture-of-Checkpoint System (MoC-System) to orchestrate the vast array of checkpoint shards produced in distributed training systems. MoC-System features a novel Partial Experts Checkpointing (PEC) mechanism, an algorithm-system co-design that strategically saves a selected subset of experts, effectively reducing the MoE checkpoint size to levels comparable with dense models. Incorporating hybrid parallel strategies, MoC-System involves fully sharded checkpointing strategies to evenly distribute the workload across distributed ranks. Furthermore, MoC-System introduces a two-level checkpointing management method that asynchronously handles in-memory snapshots and persistence processes.We build MoC-System upon the Megatron-DeepSpeed framework, achieving up to a 98.9% reduction in overhead for each checkpointing process compared to the original method, during MoE model training with ZeRO-2 data parallelism and expert parallelism. Additionally, extensive empirical analyses substantiate that our methods enhance efficiency while maintaining comparable model accuracy, even achieving an average accuracy increase of 1.08% on downstream tasks.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {655–671},
numpages = {17},
keywords = {checkpoint, fault tolerance, large language models, mixture of experts, training},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3627217.3627234,
author = {Pawagi, Mrigank and Kumar, Viraj},
title = {GuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627234},
doi = {10.1145/3627217.3627234},
abstract = {Before implementing a function, programmers are encouraged to write a purpose statement i.e., a short, natural-language explanation of what the function computes. A purpose statement may be ambiguous i.e., it may fail to specify the intended behaviour when two or more inequivalent computations are plausible on certain inputs. Our paper makes four contributions. First, we propose a novel heuristic that suggests such inputs using Large Language Models (LLMs). Using these suggestions, the programmer may choose to clarify the purpose statement (e.g., by providing a functional example that specifies the intended behaviour on such an input). Second, to assess the quality of inputs suggested by our heuristic, and to facilitate future research, we create an open dataset of purpose statements with known ambiguities. Third, we compare our heuristic against GitHub Copilot’s Chat feature, which can suggest similar inputs when prompted to generate unit tests. Fourth, we provide an open-source implementation of our heuristic as an extension to Visual Studio Code for the Python programming language, where purpose statements and functional examples are specified as docstrings and doctests respectively. We believe that this tool will be particularly helpful to novice programmers and instructors.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {55–60},
numpages = {6},
keywords = {CS1, function design, purpose statement},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@inproceedings{10.1145/3643991.3645079,
author = {Zhang, Yue and Meredith, Rachel and Reeves, Wilson and Coriolano, J\'{u}lia and Babar, Muhammad Ali and Rahman, Akond},
title = {Does Generative AI Generate Smells Related to Container Orchestration?: An Exploratory Study with Kubernetes Manifests},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645079},
doi = {10.1145/3643991.3645079},
abstract = {Generative artificial intelligence (AI) technologies, such as ChatGPT have shown promise in solving software engineering problems. However, these technologies have also shown to be susceptible to generating software artifacts that contain quality issues. A systematic characterization of quality issues, such as smells in ChatGPT-generated artifacts can help in providing recommendations for practitioners who use generative AI for container orchestration.We conduct an empirical study with 98 Kubernetes manifests to quantify smells in manifests generated by ChatGPT. Our empirical study shows: (i) 35.8% of the 98 Kubernetes manifests generated include at least one instance of smell; (ii) two types of objects Kubernetes namely, Deployment and Service are impacted by identified smells; and (iii) the most frequently occurring smell is unset CPU and memory requirements. Based on our findings, we recommend practitioners to apply quality assurance activities for ChatGPT-generated Kubernetes manifests prior to using these manifests for container orchestration.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {192–196},
numpages = {5},
keywords = {container orchestration, empirical study, kubernetes, quality, smell},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3631700.3658531,
author = {Gadiraju, Ujwal and Yadav, Kuldeep},
title = {DECI: The 2nd Tutorial on Designing Effective Conversational Interfaces},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3658531},
doi = {10.1145/3631700.3658531},
abstract = {Conversational User Interfaces (CUIs) have been argued to have advantages over traditional GUIs due to having a more human-like interaction. The growing popularity of conversational agents has enabled humans to interact with machines more naturally. People are increasingly familiar with conversational interactions mediated by technology due to the widespread use of mobile devices and messaging services and a hungry market for conversational agents. Based on the recent advances in conversational AI, due to the proliferation of large language models, there are clear signs that the future of human-computer interaction will have a significant conversational component. Today, over two-thirds of the population on our planet has access to the Internet, with ever-lowering barriers to accessibility. This tutorial will showcase the benefits of employing novel conversational interfaces for crowd computing, human-AI decision making, health and well-being, and information retrieval. Given the widespread adoption of AI systems across several domains, we will discuss the potential of conversational interfaces in facilitating and mediating people’s interactions with AI systems and the opportunities and challenges that lie at this intersection from the user modeling and personalization standpoint. The tutorial will include interactive elements and discussions and provide participants with practical insights to inform the design of effective conversational interfaces.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {5–8},
numpages = {4},
keywords = {conversational AI, conversational crowdsourcing, conversational user interfaces, human-AI decision making, human-AI interaction},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@article{10.1145/3689736,
author = {Yang, Chenyuan and Deng, Yinlin and Lu, Runyu and Yao, Jiayi and Liu, Jiawei and Jabbarvand, Reyhaneh and Zhang, Lingming},
title = {WhiteFox: White-Box Compiler Fuzzing Empowered by Large Language Models},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3689736},
doi = {10.1145/3689736},
abstract = {Compiler correctness is crucial, as miscompilation can falsify program behaviors, leading to serious consequences over the software supply chain. In the literature, fuzzing has been extensively studied to uncover compiler defects. However, compiler fuzzing remains challenging: Existing arts focus on black- and grey-box fuzzing, which generates test programs without sufficient understanding of internal compiler behaviors. As such, they often fail to construct test programs to exercise intricate optimizations. Meanwhile, traditional white-box techniques, such as symbolic execution, are computationally inapplicable to the giant codebase of compiler systems. Recent advances demonstrate that Large Language Models (LLMs) excel in code generation/understanding tasks and even have achieved state-of-the-art performance in black-box fuzzing. Nonetheless, guiding LLMs with compiler source-code information remains a missing piece of research in compiler testing.
 
 
 
 
 
 
 

 
 
 
 
 
 
 
To this end, we propose WhiteFox, the first white-box compiler fuzzer using LLMs with source-code information to test compiler optimization, with a spotlight on detecting deep logic bugs in the emerging deep learning (DL) compilers. WhiteFox adopts a multi-agent framework: (i) an LLM-based analysis agent examines the low-level optimization source code and produces requirements on the high-level test programs that can trigger the optimization; (ii) an LLM-based generation agent produces test programs based on the summarized requirements. Additionally, optimization-triggering tests are also used as feedback to further enhance the test generation prompt on the fly. Our evaluation on the three most popular DL compilers (i.e., PyTorch Inductor, TensorFlow-XLA, and TensorFlow Lite) shows that WhiteFox can generate high-quality test programs to exercise deep optimizations requiring intricate conditions, practicing up to 8 times more optimizations than state-of-the-art fuzzers. To date, WhiteFox has found in total 101 bugs for the compilers under test, with 92 confirmed as previously unknown and 70 already fixed. Notably, WhiteFox has been recently acknowledged by the PyTorch team, and is in the process of being incorporated into its development workflow. Finally, beyond DL compilers, WhiteFox can also be adapted for compilers in different domains, such as LLVM, where WhiteFox has already found multiple bugs.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {296},
numpages = {27},
keywords = {Code Analysis, Fuzzing, Large Language Models, White-box Testing}
}

@article{10.1109/TASLP.2024.3490373,
author = {Li, Ren and Xiao, Qiao and Yang, Jianxi and Zhang, Luyi and Chen, Yu},
title = {MRC-PASCL: A Few-Shot Machine Reading Comprehension Approach via Post-Training and Answer Span-Oriented Contrastive Learning},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3490373},
doi = {10.1109/TASLP.2024.3490373},
abstract = {The rapid development of pre-trained language models (PLMs) has significantly enhanced the performance of machine reading comprehension (MRC). Nevertheless, the traditional fine-tuning approaches necessitate extensive labeled data. MRC remains a challenging task in the few-shot settings or low-resource scenarios. This study proposes a novel few-shot MRC approach via post-training and answer span-oriented contrastive learning, termed MRC-PASCL. Specifically, in the post-training module, a novel noun-entity-aware data selection and generation strategy is proposed according to characteristics of MRC task and data, focusing on masking nouns and named entities in the context. In terms of fine-tuning, the proposed answer span-oriented contrastive learning manner selects spans around the golden answers as negative examples, and performs multi-task learning together with the standard MRC answer prediction task. Experimental results show that MRC-PASCL outperforms the PLMs-based baseline models and the 7B and 13B large language models (LLMs) cross most MRQA 2019 datasets. Further analyses show that our approach achieves better inference efficiency with lower computational resource requirement. The analysis results also indicate that the proposed method can better adapt to the domain-specific scenarios.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {4838–4849},
numpages = {12}
}

@inproceedings{10.1145/3708359.3712087,
author = {Lukianova, Elizaveta and Jeong, Jae-Yeop and Jeong, Jin-Woo},
title = {A picture is worth a thousand words? Investigating the Impact of Image Aids in AR on Memory Recall for Everyday Tasks},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712087},
doi = {10.1145/3708359.3712087},
abstract = {Memory augmentation has long been a central field in Human-Computer Interaction (HCI) research. Recently, emerging multimodal large language models (MLLMs) have extended research on memory augmentation by enabling the retrieval of information stored in multiple formats (e.g., text and image) through free-form queries. However, literature has focused on text-based memory aids, there has been surprisingly limited research on image-based assistance, despite humans’ superior efficiency in processing visual information. Therefore, in this work, we explore the effect of image aids on memory augmentation. To this end, we first design and implement an augmented reality (AR) memory augmentation system, informed by human evaluation of MLLM performance (GPT-4o, LLaVA, and Mini-Gemini) and insights from user interface (UI) design workshops. As a result, we found that GPT-4o is most suitable for our system, images complemented with text (i.e., Image+text) are the most preferred format of memory aids. We also identified optimal UI design parameters for AR-based memory augmentation. With a finalized version of the system prototype, we conduct a user study (N=20) consisting of two tasks that simulate real-life memory-related challenges. We found that Image+text significantly enhanced both recall performance and memory vividness. Additionally, from a user experience perspective, Image+text was considered the most helpful and easiest to use for memory augmentation. Our findings showed that images are a powerful modality for enhancing memory recall, extending beyond traditional text-based approaches. We expect that insights gained from this work will contribute to the development of practical, everyday memory augmentation systems.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {106–126},
numpages = {21},
keywords = {Memory Augmentation, Cognitive Offloading, Visualization in AR},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3708359.3712148,
author = {Andrews, Peter and Borch, Nj\r{a}l and Fjeld, Morten},
title = {AiModerator: A Co-Pilot for Hyper-Contextualization in Political Debate Video},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712148},
doi = {10.1145/3708359.3712148},
abstract = {Political debates are essential in political discourse for democratic societies. Advancements in technology have significantly transformed the structure of political debates, the ways in which politicians communicate, and the platforms through which audiences engage with them. Originally a forum for improving understanding, political debates have increasingly favored theatrics over substance, risking young adult disengagement. To bring substance back to this medium we developed AiModerator, a political debate co-pilot acting as a Multimodal Conversational Agent (MCA). AiModerator aims to promote engagement while improving understanding by analyzing video content to provide contextually relevant information. This consolidated information facilitates understanding while keeping users synchronized with the debate viewing experience. Our system builds upon multimodal techniques, integrating computer vision and large language models to demonstrate ways of improving content delivery and engagement. AiModerator’s backend system extracts events from identified speech data, allowing the user to interact with these events through a touch interface on an iPad application. We address three key topics: evaluating young adults’ engagement, satisfaction, and preference compared to traditional second screening, and determining whether AiModerator can improve subjective understanding. To evaluate these measures we conducted a mixed-method evaluation (n=20) within-group design A-B study. Our analysis found AiModerator excelled in promoting engagement and satisfaction while delivering clear, contextually relevant information to the user which improved their understanding of debate topics more than the second screening mode. Our qualitative analysis offers broader insights, particularly in terms of a trade-off between automation and information consolidation versus autonomy and control.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {137–156},
numpages = {20},
keywords = {Multimodal Conversational Agents, Hyper-contextualization, User Experience, Natural Language Processing, Information Accessibility, Political Engagement, Interactive Video, Political Discourse},
location = {
},
series = {IUI '25}
}

@article{10.5555/3648699.3649076,
author = {Roberts, Adam and Chung, Hyung Won and Mishra, Gaurav and Levskaya, Anselm and Bradbury, James and Andor, Daniel and Narang, Sharan and Lester, Brian and Gaffney, Colin and Mohiuddin, Afroz and Hawthorne, Curtis and Lewkowycz, Aitor and Salcianu, Alex and Hu, Haitang and Tsvyashchenko, Sasha and Chowdhery, Aakanksha and Bastings, Jasmijn and Bulian, Jannis and Garcia, Xavier and Ni, Jianmo and Chen, Andrew and Kenealy, Kathleen and Han, Kehang and Casbon, Michelle and Clark, Jonathan H. and Lee, Stephan and Garrette, Dan and Lee-Thorp, James and Raffel, Colin and Shazeer, Noam and Ritter, Marvin and Bosma, Maarten and Passos, Alexandre and Maitin-Shepard, Jeremy and Fiedel, Noah and Omernick, Mark and Saeta, Brennan and Sepassi, Ryan and Spiridonov, Alexander and Newlan, Joshua and Gesmundo, Andrea and Van Zee, Marc and Austin, Jacob and Goodman, Sebastian and Soares, Livio Baldini},
title = {Scaling up models and data with t5x and seqio},
year = {2023},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {Scaling up training datasets and model parameters have benefited neural network-based language models, but also present challenges like distributed compute, input data bottlenecks and reproducibility of results. We introduce two simple and scalable software libraries that simplify these issues: t5x enables training large language models at scale, while seqio enables reproducible input and evaluation pipelines. These open-source libraries have been used to train models with hundreds of billions of parameters on multiterabyte datasets. Configurations and instructions for T5-like and GPT-like models are also provided. The libraries can be found at https://github.com/google-research/t5x and https://github.com/google/seqio.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {377},
numpages = {8},
keywords = {large language models, data parallelism, model parallelism, data processing}
}

@article{10.1145/3680543,
author = {Rutherford, Attapol and Akarajaradwong, Pawitsapak},
title = {Exploring the Correlation between Emojis and Mood Expression in Thai Twitter Discourse},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {11},
issn = {2375-4699},
url = {https://doi.org/10.1145/3680543},
doi = {10.1145/3680543},
abstract = {Mood, a long-lasting affective state detached from specific stimuli, plays an important role in behavior. Although sentiment analysis and emotion classification have garnered attention, research on mood classification remains in its early stages. This study adopts a two-dimensional structure of affect, comprising “pleasantness” and “activation,” to classify mood patterns. Emojis, graphic symbols representing emotions and concepts, are widely used in computer-mediated communication. Unlike previous studies that consider emojis as direct labels for emotion or sentiment, this work uses a pre-trained large language model which integrates both text and emojis to develop a mood classification model. Our contributions are three-fold. First, we annotate 10,000 Thai tweets with mood to train the models and release the dataset to the public. Second, we show that emojis contribute to determining mood to a lesser extent than text, far from mapping directly to mood. Third, through the application of the trained model, we observe the correlation of moods during the Thai political turmoil of 2019–2020 on Thai X (formerly known as Twitter) and find a significant correlation. These moods closely reflect the news events and reveal one side of Thai public opinion during the turmoil.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = nov,
articleno = {150},
numpages = {14},
keywords = {Mood, emoji, classifier, pretrained language model}
}

@inproceedings{10.1145/3662004.3663555,
author = {Choi, Pyeongjun and Kim, Jeongsoo and Kwak, Jeongho},
title = {Impact of Joint Heat and Memory Constraints of Mobile Device in Edge-Assisted On-Device Artificial Intelligence},
year = {2024},
isbn = {9798400706615},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662004.3663555},
doi = {10.1145/3662004.3663555},
abstract = {Recently, consumer demand for artificial intelligence (AI) applications using deep neural network (DNN) model such as large language model (LLM), miXed Reality (XR), and AI assistants has been steadily increasing. Hitherto, on-device AI and offloaded analytics with the help of mobile edge computing (MEC) have been extensively studied to realize AI services on top of mobile devices. However, both technologies suffer from the limited resources of mobile devices, such as thermal resilience, battery capacity, and memory size. To tackle this problem, we first extensively examine the impact of heat and memory constraints of a mobile device when networking and processing resources and multi-dimensional DNN model sizes are dynamically managed for AI applications via motivating measurement. From the experimental results, we conjecture that the threshold-based approach for joint consideration of heat and memory constraints would increase the performance of AI applications in terms of energy, frames per second (FPS), and inference accuracy. Hence, we propose a threshold-based H&amp;M algorithm that jointly adjusts offloading, Dynamic Voltage and Frequency Scaling (DVFS), and DNN model size, aiming to maximize inference accuracy while keeping target FPS with memory and heat constraints in various environments. Finally, we implement the proposed scheme on a mobile device and an MEC server and evaluate its performance and adaptability via extensive experiments.},
booktitle = {Proceedings of the 2nd International Workshop on Networked AI Systems},
pages = {31–36},
numpages = {6},
keywords = {DVFS, Offloaded analytics, On-device AI, Thermal and memory aware control},
location = {Minato-ku, Tokyo, Japan},
series = {NetAISys '24}
}

@article{10.1109/TASLP.2024.3485485,
author = {Xue, Jinlong and Deng, Yayue and Gao, Yingming and Li, Ya},
title = {Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3485485},
doi = {10.1109/TASLP.2024.3485485},
abstract = {Recent advancements in diffusion models and large language models (LLMs) have significantly propelled the field of generation tasks. Text-to-Audio (TTA), a burgeoning generation application designed to generate audio from natural language prompts, is attracting increasing attention. However, existing TTA studies often struggle with generation quality and text-audio alignment, especially for complex textual inputs. Drawing inspiration from state-of-the-art Text-to-Image (T2I) diffusion models, we introduce Auffusion, a TTA system adapting T2I model frameworks to TTA task, by effectively leveraging their inherent generative strengths and precise cross-modal alignment. Our objective and subjective evaluations demonstrate that Auffusion surpasses previous TTA approaches using limited data and computational resources. Furthermore, the text encoder serves as a critical bridge between text and audio, since it acts as an instruction for the diffusion model to generate coherent content. Previous studies in T2I recognize the significant impact of encoder choice on cross-modal alignment, like fine-grained details and object bindings, while similar evaluation is lacking in prior TTA works. Through comprehensive ablation studies and innovative cross-attention map visualizations, we provide insightful assessments, being the first to reveal the internal mechanisms in the TTA field and intuitively explain how different text encoders influence the diffusion process. Our findings reveal Auffusion's superior capability in generating audios that accurately match textual descriptions, which is further demonstrated in several related tasks, such as audio style transfer, inpainting, and other manipulations.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {4700–4712},
numpages = {13}
}

@inproceedings{10.1145/3628797.3628837,
author = {Nguyen, Duc-Vu and Nguyen, Quoc-Nam},
title = {Evaluating the Symbol Binding Ability of Large Language Models for Multiple-Choice Questions in Vietnamese General Education},
year = {2023},
isbn = {9798400708916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628797.3628837},
doi = {10.1145/3628797.3628837},
abstract = {In this paper, we evaluate the ability of large language models (LLMs) to perform multiple choice symbol binding (MCSB) for multiple choice question answering (MCQA) tasks in zero-shot, one-shot, and few-shot settings. We focus on Vietnamese, with fewer challenging MCQA datasets than in English. The two existing datasets, ViMMRC 1.0 and ViMMRC 2.0, focus on literature. Recent research in Vietnamese natural language processing (NLP) has focused on the Vietnamese National High School Graduation Examination (VNHSGE) from 2019 to 2023 to evaluate ChatGPT. However, these studies have mainly focused on how ChatGPT solves the VNHSGE step by step. We aim to create a novel and high-quality dataset by providing structured guidelines for typing LaTeX formulas for mathematics, physics, chemistry, and biology. This dataset can be used to evaluate the MCSB ability of LLMs and smaller language models (LMs) because it is typed in a strict LaTeX style. We determine the most probable character answer (A, B, C, or D) based on context, instead of finding the answer step by step as in previous Vietnamese works. This reduces computational costs and accelerates the evaluation of LLMs. Our evaluation of six well-known LLMs, namely BLOOMZ-7.1B-MT, LLaMA-2-7B, LLaMA-2-70B, GPT-3, GPT-3.5, and GPT-4.0, on the ViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promising results on the MCSB ability of LLMs for Vietnamese. The dataset is available1 for research purposes only.},
booktitle = {Proceedings of the 12th International Symposium on Information and Communication Technology},
pages = {379–386},
numpages = {8},
keywords = {Analysis of Language Models, Language Modeling, Multiple Choice Question Answering, Multiple Choice Symbol Binding},
location = {Ho Chi Minh, Vietnam},
series = {SOICT '23}
}

@inproceedings{10.1145/3613904.3642517,
author = {Yang, Jackie (Junrui) and Shi, Yingtian and Zhang, Yuhan and Li, Karina and Rosli, Daniel Wan and Jain, Anisha and Zhang, Shuning and Li, Tianshi and Landay, James A. and Lam, Monica S.},
title = {ReactGenie: A Development Framework for Complex Multimodal Interactions Using Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642517},
doi = {10.1145/3613904.3642517},
abstract = {By combining voice and touch interactions, multimodal interfaces can surpass the efficiency of either modality alone. Traditional multimodal frameworks require laborious developer work to support rich multimodal commands where the user’s multimodal command involves possibly exponential combinations of actions/function invocations. This paper presents ReactGenie, a programming framework that better separates multimodal input from the computational model to enable developers to create efficient and capable multimodal interfaces with ease. ReactGenie translates multimodal user commands into NLPL (Natural Language Programming Language), a programming language we created, using a neural semantic parser based on large-language models. The ReactGenie runtime interprets the parsed NLPL and composes primitives in the computational model to implement complex user commands. As a result, ReactGenie allows easy implementation and unprecedented richness in commands for end-users of multimodal apps. Our evaluation showed that 12 developers can learn and build a non-trivial ReactGenie application in under 2.5 hours on average. In addition, compared with a traditional GUI, end-users can complete tasks faster and with less task load using ReactGenie apps.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {483},
numpages = {23},
keywords = {development frameworks, large-language model, multimodal interactions, natural language processing, programming framework},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3689932.3694758,
author = {Roa, Camila and Mahbub, Maria and Srinivasan, Sudarshan and Begoli, Edmon and Sadovnik, Amir},
title = {Semantic Stealth: Crafting Covert Adversarial Patches for Sentiment Classifiers Using Large Language Models},
year = {2024},
isbn = {9798400712289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689932.3694758},
doi = {10.1145/3689932.3694758},
abstract = {Deep learning models have been shown to be vulnerable to adversarial attacks, in which perturbations to their inputs cause the model to produce incorrect predictions. As opposed to adversarial attacks in computer vision, where small changes introduced to pixel values can drastically alter a model's output while remaining imperceptible to humans, text-based attacks are difficult to conceal due to the discrete nature of tokens. Consequently, unconstrained gradient-based attacks often produce adversarial examples that lack semantic meaning, rendering them detectable through visual inspection or perplexity filters. In contrast to methods that rely on gradient-based optimization in the embedding space, we propose an approach that leverages a Large Language Model's ability to generate grammatically correct and semantically meaningful text to craft adversarial patches that seamlessly blend in with the original input text. These patches can be used to alter the behavior of a target model, such as a text classifier. Since our approach does not rely on gradient backpropagation, it only requires access to the target model's confidence scores, making it a grey-box attack. We demonstrate the feasibility of our approach using open-source LLMs, including Intel's Neural Chat, Llama2, and Mistral-Instruct, to generate adversarial patches capable of altering the predictions of a distilBERT model fine-tuned on the IMDB reviews dataset for sentiment classification.},
booktitle = {Proceedings of the 2024 Workshop on Artificial Intelligence and Security},
pages = {42–52},
numpages = {11},
keywords = {adversarial attack, adversarial patches, large language model, sentiment classification, transformer-based model},
location = {Salt Lake City, UT, USA},
series = {AISec '24}
}

@inproceedings{10.1145/3706598.3714135,
author = {Chen, Wei-Hao and Tong, Weixi and Case, Amanda and Zhang, Tianyi},
title = {Dango: A Mixed-Initiative Data Wrangling System using Large Language Model},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714135},
doi = {10.1145/3706598.3714135},
abstract = {Data wrangling is a time-consuming and challenging task in a data science pipeline. While many tools have been proposed to automate or facilitate data wrangling, they often misinterpret user intent, especially in complex tasks. We propose Dango, a mixed-initiative multi-agent system for data wrangling. Compared to existing tools, Dango enhances user communication of intent by: (1) allowing users to demonstrate on multiple tables and use natural language prompts in a conversation interface, (2) enabling users to clarify their intent by answering LLM-posed multiple-choice clarification questions, and (3) providing multiple forms of feedback such as step-by-step NL explanations and data provenance to help users evaluate the data wrangling scripts. We conducted a within-subjects user study (n=38) and demonstrated that Dango’s features can significantly improve intent clarification, accuracy, and efficiency in data wrangling. Furthermore, we demonstrated the generalizability of Dango by applying it to a broader set of data wrangling tasks.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {389},
numpages = {28},
keywords = {Data Wrangling, Data Science, Large Language Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3676536.3676796,
author = {Li, Jinhao and Xu, Jiaming and Li, Shiyao and Huang, Shan and Liu, Jun and Lian, Yaoxiu and Dai, Guohao},
title = {Fast and Efficient 2-bit LLM Inference on GPU: 2/4/16-bit in a Weight Matrix with Asynchronous Dequantization},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676796},
doi = {10.1145/3676536.3676796},
abstract = {Large language models (LLMs) have demonstrated impressive abilities in various domains while the inference cost is expensive. Many previous studies exploit quantization methods to reduce LLM inference cost by reducing latency and memory consumption. Applying 2-bit single-precision weight quantization brings &gt;3% accuracy loss, so the state-of-the-art methods use mixed-precision methods for LLMs (e.g. Llama2-7b, etc.) to improve the accuracy. However, challenges still exist: (1) Uneven distribution in weight matrix. Weights are quantized by groups, while some groups contain weights with large range. Previous methods apply inter-weight mixed-precision quantization and neglect the range difference inside each weight matrix, resulting in &gt;2.7% accuracy loss (e.g. LLM-MQ and APTQ). (2) Large speed degradation by adding sparse outliers. Reserving sparse outliers improves accuracy but slows down the speed affected by the outlier ratio (e.g. 1.5% outliers resulting in &gt;30% speed degradation in SpQR). (3) Time-consuming dequantization operations on GPUs. Mainstream methods require a dequantization operation to perform computation on the quantized weights, and the 2-order dequantization operation is applied because scales of groups are also quantized. These dequantization operations lead to &gt;50% execution time.To tackle these challenges and enable fast and efficient LLM inference on GPUs, we propose the following techniques in this paper. (1) Intra-weight mixed-precision quantization. We only quantize a small fraction of groups with higher sensitivity (larger Hessian value and range variation) using 4-bit. Meanwhile, we also take the memory alignment into consideration on GPUs. (2) Exclusive 2-bit sparse outlier with minimum speed degradation. We only reserve a small fraction of large weights in 2-bit groups as sparse outliers using 16-bit, which leads to a lower average bit increment and speed degradation. (3) Asynchronous dequantization. We point out that calculating the scales of each group in 2-order de-quantization is independent of the loading weights of each group in 1-order dequantization. Thus, we design the asynchronous dequantization on GPUs. We conduct extensive experiments on different model families (e.g. Llama3, etc.) and model sizes. We achieve 2.91-bit for each weight considering all scales/zeros for different models with negligible loss. As a result, with our 2/4/16 mixed-precision quantization for each weight matrix and asynchronous dequantization during inference, our design achieves an end-to-end speedup for Llama2-7b is 1.74\texttimes{} over the original model, and we reduce both runtime cost and total cost by up to 2.53\texttimes{} and 2.29\texttimes{} with less GPU requirements.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {150},
numpages = {9},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3584931.3606965,
author = {Zhu, Qingxiaoyang and Wang, Hao-Chuan},
title = {Leveraging Large Language Model as Support for Human Problem Solving: An Exploration of Its Appropriation and Impact},
year = {2023},
isbn = {9798400701290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584931.3606965},
doi = {10.1145/3584931.3606965},
abstract = {The emergence of pre-trained Large Language Model (LLM) has opened up new possibilities for people to access language resources at their fingertips. Previously, patterns of language could be difficult to derive from large-scale documents, which impeded people from processing and extracting information contained within. Observations from common users’ practices and experiences suggest that LLM may appear to possess certain capacities for processing, handling and working with not just human language, but also the associated knowledge. However, the original construction of LLM is essentially language-centric, which is not more than a probabilistic model representing and summarizing language patterns from large language corpora, without deliberately incorporating other types of data or information (e.g., user behaviors, domain concepts) into the model construction. Consequently, when using LLM in the real-world, it’s not uncommon to appropriate and re-purpose an LLM for handling tasks that don’t necessarily match what it’s built for. In this poster, we present an exploratory study aimed at understanding how people interact with an LLM, chatGPT, to obtain instructions to work on a problem-solving task, installing Python on a remote computer. The results reveal that users’ literacy and expectations concerning LLM can influence how they perceive and utilize it. Surprisingly, low-literacy participants with limited understanding of LLM appear to benefit more, producing implications for designing user-centric AI/ML tools.},
booktitle = {Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {333–337},
numpages = {5},
keywords = {LLM, appropriation, conversation, end-users, literacy, problem solving, prompt analysis, transparency},
location = {Minneapolis, MN, USA},
series = {CSCW '23 Companion}
}

@inproceedings{10.1145/3597503.3639194,
author = {Tanzil, Minaoar Hossain and Khan, Junaed Younus and Uddin, Gias},
title = {ChatGPT Incorrectness Detection in Software Reviews},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639194},
doi = {10.1145/3597503.3639194},
abstract = {We conducted a survey of 135 software engineering (SE) practitioners to understand how they use Generative AI-based chatbots like ChatGPT for SE tasks. We find that they want to use ChatGPT for SE tasks like software library selection but often worry about the truthfulness of ChatGPT responses. We developed a suite of techniques and a tool called CID (ChatGPT Incorrectness Detector) to automatically test and detect the incorrectness in ChatGPT responses. CID is based on the iterative prompting to ChatGPT by asking it contextually similar but textually divergent questions (using an approach that utilizes metamorphic relationships in texts). The underlying principle in CID is that for a given question, a response that is different from other responses (across multiple incarnations of the question) is likely an incorrect response. In a benchmark study of library selection, we show that CID can detect incorrect responses from ChatGPT with an F1-score of 0.74 -- 0.75.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {180},
numpages = {12},
keywords = {large language model, chatGPT, hallucination, testing},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inbook{10.5555/3716662.3716797,
author = {Wen-Yi, Andrea W and Adamson, Kathryn and Greenfield, Nathalie and Goldberg, Rachel and Babcock, Sandra and Mimno, David and Koenecke, Allison},
title = {Automate or Assist? The Role of Computational Models in Identifying Gendered Discourse in US Capital Trial Transcripts},
year = {2025},
publisher = {AAAI Press},
abstract = {The language used by US courtroom actors in criminal trials has long been studied for biases. However, systematic studies for bias in high-stakes court trials have been difficult, due to the nuanced nature of bias and the legal expertise required. Large language models offer the possibility to automate annotation. But validating the computational approach requires both an understanding of how automated methods fit in existing annotation workflows and what they really offer. We present a case study of adding a computational model to a complex and high-stakes problem: identifying gender-biased language in US capital trials for women defendants. Our team of experienced death-penalty lawyers and NLP technologists pursue a three-phase study: first annotating manually, then training and evaluating computational models, and finally comparing expert annotations to model predictions. Unlike many typical NLP tasks, annotating for gender bias in months-long capital trials is complicated, with many individual judgment calls. Contrary to standard arguments for automation that are based on efficiency and scalability, legal experts find the computational models most useful in providing opportunities to reflect on their own bias in annotation and to build consensus on annotation rules. This experience suggests that seeking to replace experts with computational models for complex annotation is both unrealistic and undesirable. Rather, computational models offer valuable opportunities to assist the legal experts in annotation-based studies.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {1556–1566},
numpages = {11}
}

@inproceedings{10.1145/3632775.3661939,
author = {Zhang, Xiaoyang and Yang, Yijie and Wang, Dan},
title = {Spatial-Temporal Embodied Carbon Models for the Embodied Carbon Accounting of Computer Systems},
year = {2024},
isbn = {9798400704802},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632775.3661939},
doi = {10.1145/3632775.3661939},
abstract = {Embodied carbon is the total amount of carbon released from the processes associated with a product from cradle to gate. In many industry sectors, embodied carbon dominates the overall carbon footprint. Embodied carbon accounting, i.e., to estimate the embodied carbon of a product, has become an important research topic. Existing studies derive the embodied carbon through life cycle analysis (LCA) reports. Current LCA reports only provide the carbon emission of a product class, e.g., 28nm CPU, yet a product instance can be manufactured from diverse regions and in diverse time periods, e.g., in the winter in Ireland (Intel). It is known that carbon emissions depend on the electricity generation process, which has spatial and temporal dynamics. Therefore, the embodied carbon of a specific product instance can largely differ from its product class. In this paper, we present new Spatial-Temporal Embodied Carbon (STEC) models for embodied carbon accounting. We observe significant differences between current embodied carbon models and STEC models, e.g., for 7nm CPU the difference can be 13.69%. We further examine the impact of STEC models on existing embodied carbon accounting schemes on key computer applications, such as Large Language Model (LLM) inference and LLM training. We observe that using STEC models leads to much greater differences in the embodied accounting of certain applications as compared to others (e.g., 32.26% vs. 6.35%). This is because the hardware requirements of certain applications allow for a wider range of hardware choices, while others have greater restrictions.},
booktitle = {Proceedings of the 15th ACM International Conference on Future and Sustainable Energy Systems},
pages = {464–471},
numpages = {8},
keywords = {Carbon accounting, Computer architecture, Sustainable computing},
location = {Singapore, Singapore},
series = {e-Energy '24}
}

@inproceedings{10.1145/3674805.3686664,
author = {Hu, Gang and Zeng, Xiaoqin and Yu, Wanlong and Peng, Min and Yuan, Mengting and Duan, Liang},
title = {Unsupervised and Supervised Co-learning for Comment-based Codebase Refining and its Application in Code Search},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3686664},
doi = {10.1145/3674805.3686664},
abstract = {&nbsp;Background: Code pre-training and large language models are heavily dependent on data quality. These models require a vast, high-quality corpus matching text descriptions with codes to establish semantic correlations between natural and programming languages. Unlike NLP tasks, code comment heavily relies on specialized programming knowledge and is often limited in quantity and variety. Thus, most widely available open-source datasets are established with compromise and noise from platforms, such as StackOverflow, where code snippets are often incomplete. This may lead to significant errors when deploying the trained models in real-world applications. &nbsp;Aims: Comments as a substitute for queries are used to build code search datasets from GitHub. While comments describe code functionality and details, they often contain noise and differ from queries. Thus, our research focuses on improving the syntactic and semantic quality of code comments. &nbsp;Method: We propose a comment-based data refinement framework CoCoRF 1 via an unsupervised and supervised co-learning technique. It applies manually defined rules for syntax filtering and constructs a bootstrap query corpus via the WTFF algorithm for training the TVAE model for further semantic filtering. &nbsp;Results: Our study shows that CoCoRF achieves high efficiency with less computational resource, and outperforms comparison models in DeepCS code search task. &nbsp;Conclusions: Our findings indicate that the CoCoRF framework significantly improves the performance of code search tasks by enhancing the quality of code datasets.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {1–12},
numpages = {12},
keywords = {Code Search, CodeSearchNet Cleaning, Comment-Code dataset, Self-attention Mechanism},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3641554.3701853,
author = {Filcik, Daniel and Sobiesk, Edward and Matthews, Suzanne J.},
title = {Fostering Creativity: Student-Generative AI Teaming in an Open-Ended CS0 Assignment},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701853},
doi = {10.1145/3641554.3701853},
abstract = {The increasing ubiquity of web-based generative artificial intelligence technologies necessitates that all students experience teaming with such technologies -- exploring their strengths and limitations and learning how to create synergy with them. To aid in this effort, we designed an open-ended generative AI project for the freshmen taking our general-education introduction to computing course. Students were required to team with generative AI to create something beyond what they alone (or the AI alone) could accomplish. Upon completion, students submitted a short written critical analysis documenting their experiences and presented a three-minute demonstration of their project in class. Despite limited course coverage of AI and generative AI prior to this project, we were impressed by the creativity and sophistication of the submitted final products as well as the breadth of generative AI tools explored. Student reflections on the experience illustrated numerous insights into the strengths and limitations of the tools they employed. Our results underscore that students can learn about the benefits and limitations of generative AI in as little as a single assignment and that covering such topics need not require extensive amounts of course time and resources.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {339–345},
numpages = {7},
keywords = {computing education, cs0, final project, freshmen, generative artificial intelligence, human-ai teaming},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3624062.3624257,
author = {Zhang, Chengming and Sun, Baixi and Yu, Xiaodong and Xie, Zhen and Zheng, Weijian and Iskra, Kamil A. and Beckman, Pete and Tao, Dingwen},
title = {Benchmarking and In-depth Performance Study of Large Language Models on Habana Gaudi Processors},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3624257},
doi = {10.1145/3624062.3624257},
abstract = {Transformer models have achieved remarkable success in various machine learning tasks but suffer from high computational complexity and resource requirements. The quadratic complexity of the self-attention mechanism further exacerbates these challenges when dealing with long sequences and large datasets. Specialized AI hardware accelerators, such as the Habana GAUDI architecture, offer a promising solution to tackle these issues. GAUDI features a Matrix Multiplication Engine (MME) and a cluster of fully programmable Tensor Processing Cores (TPC). This paper explores the untapped potential of using GAUDI processors to accelerate Transformer-based models, addressing key challenges in the process. Firstly, we provide a comprehensive performance comparison between the MME and TPC components, illuminating their relative strengths and weaknesses. Secondly, we explore strategies to optimize MME and TPC utilization, offering practical insights to enhance computational efficiency. Thirdly, we evaluate the performance of Transformers on GAUDI, particularly in handling long sequences and uncovering performance bottlenecks. Lastly, we evaluate the end-to-end performance of two Transformer-based large language models (LLM) on GAUDI. The contributions of this work encompass practical insights for practitioners and researchers alike. We delve into GAUDI’s capabilities for Transformers through systematic profiling, analysis, and optimization exploration. Our study bridges a research gap and offers a roadmap for optimizing Transformer-based model training on the GAUDI architecture.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {1759–1766},
numpages = {8},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@inproceedings{10.1145/3716640.3716656,
author = {Vadaparty, Annapurna and Geng, Francis and Smith, David H and Benario, Jamie Gorson and Zingaro, Daniel and Porter, Leo},
title = {Achievement Goals in CS1-LLM},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716656},
doi = {10.1145/3716640.3716656},
abstract = {Introduction: The emergence and widespread adoption of generative AI (GenAI) chatbots such as ChatGPT, and programming assistants such as GitHub Copilot, have radically redefined the landscape of programming education. This calls for replication of studies and reexamination of findings from pre-GenAI CS contexts to understand the impact on students. Objectives: Achievement Goals are well studied in computing education and can be predictive of student interest and exam performance. The objective in this study is to compare findings from prior achievement goal studies in CS1 courses with new CS1 courses that emphasize the use of human-GenAI collaborative coding. Methods: In a CS1 course that integrates GenAI, we use linear regression to explore the relationship between achievement goals and prior experience on student interest, exam performance, and perceptions of GenAI. Results: As with prior findings in traditional CS1 classes, Mastery goals are correlated with interest in computing. Contradicting prior CS1 findings, normative goals are correlated with exam scores. Normative and mastery goals correlate with students’ perceptions of learning with GenAI. Mastery goals weakly correlate with reading and testing code output from GenAI.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {144–153},
numpages = {10},
keywords = {CS1, CS1-LLM, Copilot, Achievement Goals, Large Language Models},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3597926.3598067,
author = {Deng, Yinlin and Xia, Chunqiu Steven and Peng, Haoran and Yang, Chenyuan and Zhang, Lingming},
title = {Large Language Models Are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598067},
doi = {10.1145/3597926.3598067},
abstract = {Deep Learning (DL) systems have received exponential growth in popularity and have become ubiquitous in our everyday life. Such systems are built on top of popular DL libraries, e.g., TensorFlow and PyTorch which provide APIs as building blocks for DL systems. Detecting bugs in these DL libraries is critical for almost all downstream DL systems in ensuring effectiveness/safety for end users. Meanwhile, traditional fuzzing techniques can be hardly effective for such a challenging domain since the input DL programs need to satisfy both the input language (e.g., Python) syntax/semantics and the DL API input/shape constraints for tensor computations.  
To address these limitations, we propose TitanFuzz – the first approach to directly leveraging Large Language Models (LLMs) to generate input programs for fuzzing DL libraries. LLMs are titanic models trained on billions of code snippets and can autoregressively generate human-like code snippets. Our key insight is that modern LLMs can also include numerous code snippets invoking DL library APIs in their training corpora, and thus can implicitly learn both language syntax/semantics and intricate DL API constraints for valid DL program generation. More specifically, we use both generative and infilling LLMs (e.g., Codex/InCoder) to generate and mutate valid/diverse input DL programs for fuzzing. Our experimental results demonstrate that TitanFuzz can achieve 30.38%/50.84% higher code coverage than state-of-the-art fuzzers on TensorFlow/PyTorch. Furthermore, TitanFuzz is able to detect 65 bugs, with 44 already confirmed as previously unknown bugs.  
This paper demonstrates that modern titanic LLMs can be leveraged to directly perform both generation-based and mutation-based fuzzing studied for decades, while being fully automated, generalizable, and applicable to domains challenging for traditional approaches (such as DL systems). We hope TitanFuzz can stimulate more work in this promising direction of LLMs for fuzzing.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {423–435},
numpages = {13},
keywords = {Test Generation, Large Language Model, Fuzz Testing},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.5555/3523760.3523920,
author = {Pittman, Daniel E. and Haring, Kerstin S. and Kim, Pilyoung and Dossett, Benjamin and Ehman, Gillian and Gutierrez-Gutierrez, Elizabeth and Patil, Sneha and Sanchez, Ashley},
title = {A Novel Online Robot Design Research Platform to Determine Robot Mind Perception},
year = {2022},
publisher = {IEEE Press},
abstract = {A common issue in Human-Robot Interaction is a gap in understanding how robot designs are perceived by the user. A common issue encountered by practitioners of Machine Learning (ML) is a lack of salient data to use in training. The "Build-A-Bot" project is developing a novel research platform implemented as a web-accessible 3D game that affords data collection of many user-provided robot designs. The designs are used to train ML models to better evaluate robot designs, predict how a design will be perceived using Convolutional Neural Networks (CNNs), and create new robot designs using Generative Adversarial Networks (GANs). This paper outlines the current and future work accomplished by an interdisciplinary undergraduate student team at the University of Denver across Computer Science, Music, Psychology, and other related STEM fields that have created Build-A-Bot.},
booktitle = {Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {986–990},
numpages = {5},
keywords = {machine learning, fnirs, robot design},
location = {Sapporo, Hokkaido, Japan},
series = {HRI '22}
}

@inproceedings{10.1145/3620666.3651380,
author = {Heo, Guseul and Lee, Sangyeop and Cho, Jaehong and Choi, Hyunmin and Lee, Sanghyeon and Ham, Hyungkyu and Kim, Gwangsun and Mahajan, Divya and Park, Jongse},
title = {NeuPIMs: NPU-PIM Heterogeneous Acceleration for Batched LLM Inferencing},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620666.3651380},
doi = {10.1145/3620666.3651380},
abstract = {Modern transformer-based Large Language Models (LLMs) are constructed with a series of decoder blocks. Each block comprises three key components: (1) QKV generation, (2) multi-head attention, and (3) feed-forward networks. In batched processing, QKV generation and feed-forward networks involve compute-intensive matrix-matrix multiplications (GEMM), while multi-head attention requires bandwidth-heavy matrix-vector multiplications (GEMV). Machine learning accelerators like TPUs or NPUs are proficient in handling GEMM but are less efficient for GEMV computations. Conversely, Processing-in-Memory (PIM) technology is tailored for efficient GEMV computation, while it lacks the computational power to handle GEMM effectively.Inspired by this insight, we propose NeuPIMs, a heterogeneous acceleration system that jointly exploits a conventional GEMM-focused NPU and GEMV-optimized PIM devices. The main challenge in efficiently integrating NPU and PIM lies in enabling concurrent operations on both platforms, each addressing a specific kernel type. First, existing PIMs typically operate in a "blocked" mode, allowing only either NPU or PIM to be active at any given time. Second, the inherent dependencies between GEMM and GEMV in LLMs restrict their parallel processing. To tackle these challenges, NeuPIMs is equipped with dual row buffers in each bank, facilitating the simultaneous management of memory read/write operations and PIM commands. Further, NeuPIMs employs a runtime sub-batch interleaving technique to maximize concurrent execution, leveraging batch parallelism to allow two independent sub-batches to be pipelined within a single NeuPIMs device. Our evaluation demonstrates that compared to GPU-only, NPU-only, and a na\"{\i}ve NPU+PIM integrated acceleration approaches, NeuPIMs achieves 3\texttimes{}, 2.4\texttimes{} and 1.6\texttimes{} throughput improvement, respectively.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
pages = {722–737},
numpages = {16},
keywords = {processing-in-memory (PIM), neural processing unit (NPU), heterogeneous system, large language model (LLM), inference serving, transformer-based generative model (GPT)},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

@inproceedings{10.1145/3604237.3626898,
author = {Nagy, Peer and Frey, Sascha and Sapora, Silvia and Li, Kang and Calinescu, Anisoara and Zohren, Stefan and Foerster, Jakob},
title = {Generative AI for End-to-End Limit Order Book Modelling: A Token-Level Autoregressive Generative Model of Message Flow Using a Deep State Space Network},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626898},
doi = {10.1145/3604237.3626898},
abstract = {Developing a generative model of realistic order flow in financial markets is a challenging open problem, with numerous applications for market participants. Addressing this, we propose the first end-to-end autoregressive generative model that generates tokenized limit order book (LOB) messages. These messages are interpreted by the JAX-LOB simulator, which updates the LOB state. To handle long sequences efficiently, the model employs simplified structured state-space layers to process sequences of order book states and tokenized messages. Using LOBSTER data of NASDAQ equity LOBs, we develop a custom tokenizer for message data, converting groups of successive digits to tokens, similar to tokenization in large language models. Out-of-sample results show promising performance in approximating the data distribution, as evidenced by low model perplexity. Furthermore, the mid-price returns calculated from the generated order flow exhibit a significant correlation with the data, indicating impressive conditional forecast performance. Due to the granularity of generated data, and the accuracy of the model, it offers new application areas for future work beyond forecasting, e.g. acting as a world model in high-frequency financial reinforcement learning applications. Overall, our results invite the use and extension of the model in the direction of autoregressive large financial models for the generation of high-frequency financial data. 1},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {91–99},
numpages = {9},
keywords = {ML, generative AI, limit order books, structured state space models},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@article{10.1145/3722228,
author = {Bodon, Herminio and Kumar, Vishesh and Worsley, Marcelo},
title = {Design Principles for Authentically Embedding Computer Science in Sports},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
url = {https://doi.org/10.1145/3722228},
doi = {10.1145/3722228},
abstract = {Objectives. Athletics and sports represent a focal part of adolescence for millions of youth around the world. However, opportunities to engage in computer science (CS) learning experiences are less prevalent, particularly among Hispanic and low-income communities. Recently, researchers have explored ways to bridge these, seemingly, disparate disciplines. Much of this prior research centers on the proliferation of sports technologies that support individualistic learning experiences. Additionally, many of these experiences are developed by researchers with limited design contributions from sports practitioners. To extend prior work, this project centers youth athletic identities and the associated cultural contexts of sports to explore ways that computing technologies can enhance and develop youth athletic identities and sports performance. Moreover, this work surfaces ways that athletics can be a generative and fulfilling space to learn about CS.Participants. In summer 2021, we collaborated with basketball coaches to design and implement a computing-enhanced learning experience with a basketball team of Hispanic participants in Puerto Rico. Eleven basketball athletes from a high school in southern Puerto Rico participated in the study. The participants have strong sports identities, as demonstrated by their lifelong engagement with team sports. Conversely, only one 1 of the 11 participants had experienced sports technologies, and none of them had previously participated in computing learning experiences.Study Method. In collaboration with local basketball coaches, we co-designed a learning experience that centers sports identities and practices and adds computing as a way to extend existing sports identities and local sports activities. We present and evaluate this learning experience using a design-based research approach. Participants’ feedback was collected in the form of surveys, designs, and journal entries, and additional data on their experiences were collected via videos and researchers’ field notes. Using a mixed-methods approach, we highlight existing participants’ identities and perceptions as well as their experiences with our design. We complement quantitative analysis of survey responses with case studies.Findings. We find that our design can provide shifts in youth student-athletes’ perceptions of computing. Additionally, hands-on experiences with computing tools enable participants to start practicing CS sensemaking via learning how different computing tools can support their sports performance individually and as a team. Furthermore, we find that the material, ideational, and relational resources made available through camp:bit supported each participant differently, while collectively providing a space for all of them to have meaningful and fulfilling experiences. Finally, we find that this design can foster and support sports team cohesion.Conclusions. We provide in-depth descriptions of our design, the youth’s engagement with it, and how these learning experiences can be further applied in sports spaces. These examples highlight a unique conception of practice-linked computational identities—where learners’ computational identities are grounded in a specific culturally relevant practice, enabling a more culturally sustaining computing learning experience. Finally, our analysis suggests five design principles for designing and conducting computing-supported learning experiences in sports environments. The principles are as follows: (1) Sports Experience: Authentically Support Existing Identities. (2) Team Dynamics: Team Athletes Are Part of a Whole. (3) Individual Pursuits: Supporting Individual Paths. (4) Direct Interactions: Conversations with Materials and Ideas. (5) Interdisciplinary Facilitation Team: Complementary Skills. These design principles can be used by researchers, practitioners, and local stakeholders to implement sport-centric CS learning experiences to extend and enhance the way student-athletes from marginalized communities practice sports, as well as to activate interest and engagement in CS.},
journal = {ACM Trans. Comput. Educ.},
month = may,
articleno = {13},
numpages = {42},
keywords = {Sports, Wearable, Identity, Computing, Computer Science Education, Design-Based Research, Participation, Data Science, AI}
}

@inproceedings{10.1145/3664476.3664510,
author = {May, Richard and Kr\"{u}ger, Jacob and Leich, Thomas},
title = {SoK: How Artificial-Intelligence Incidents Can Jeopardize Safety and Security},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3664510},
doi = {10.1145/3664476.3664510},
abstract = {In the past years, a growing number of highly-automated systems has build on Artificial-Intelligence (AI) capabilities, for example, self-driving vehicles or predictive health-state diagnoses. As for any software system, there is a risk that misbehavior occurs (e.g., system failure due to bugs) or that malicious actors aim to misuse the system (e.g., generating attack scripts), which can lead to safety and security incidents. While software safety and security incidents have been studied in the past, we are not aware of research focusing on the specifics of AI incidents. With this paper, we aim to shed light on this gap through a case survey of 240 incidents that we elicited from four datasets comprising safety and security incidents involving AI from 2014 to 2023. Using manual data analyses and automated topic modeling, we derived relevant topics as well as the major issues and contexts in which the incidents occurred. We find that the topic of AI incidents is, not surprisingly, becoming more and more relevant, particularly in the contexts of autonomous driving and process-automation robotics. Regarding security and its intersection with safety, most incidents connect to generative AI (i.e., large-language models, deep fakes) and computer-vision systems (i.e., facial recognition). This emphasizes the importance of security to also ensure safety in the context of AI systems, with our results further revealing a high number of serious consequences (system compromise, human injuries) and major violations of confidentiality, integrity, availability, as well as authorization. We hope to support practitioners and researchers in understanding major safety and security issues to support the development of more secure, safe, and trustworthy AI systems.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {44},
numpages = {12},
keywords = {artificial intelligence, machine learning, safety, safety-critical systems, security, vulnerabilities},
location = {Vienna, Austria},
series = {ARES '24}
}

@inproceedings{10.1145/3659211.3659219,
author = {Zhang, Meisai and Zhao, Ming},
title = {Applying ChatGPT to improve the user experience in digital libraries},
year = {2024},
isbn = {9798400716669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3659211.3659219},
doi = {10.1145/3659211.3659219},
abstract = {In the current information age where artificial intelligence, computer network technology and multimedia interconnections are rapidly developing, people have learned to access a wide range of information resources through the Internet and enjoy the convenience brought by the Internet+ era. With the introduction of ChatGPT, a new-generation artificial intelligence large language model, new development opportunities have been brought to the library community in China. In this study, we firstly start from the technology as well as the features of ChatGPT, and give a brief introduction to the basic concepts and characteristics of ChatGPT. Then, we delve into the application value of how ChatGPT can improve library services and carry out specific applications from four aspects in detail. Finally, we provide an overview based on the challenges encountered and the strategies to deal with them, and describe the main future trends of digital libraries.},
booktitle = {Proceedings of the 2023 4th International Conference on Big Data Economy and Information Management},
pages = {44–48},
numpages = {5},
location = {Zhengzhou, China},
series = {BDEIM '23}
}

@article{10.1145/3664812,
author = {Feng, Xiaoning and Han, Xiaohong and Chen, Simin and Yang, Wei},
title = {LLMEffiChecker: Understanding and Testing Efficiency Degradation of Large Language Models},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {7},
issn = {1049-331X},
url = {https://doi.org/10.1145/3664812},
doi = {10.1145/3664812},
abstract = {Large Language Models (LLMs) have received much recent attention due to their human-level accuracy. While existing works mostly focus on either improving accuracy or testing accuracy robustness, the computation efficiency of LLMs, which is of paramount importance due to often vast generation demands and real-time requirements, has surprisingly received little attention. In this article, we make the first attempt to understand and test potential computation efficiency robustness in state-of-the-art LLMs. By analyzing the working mechanism and implementation of 20,543 public-accessible LLMs, we observe a fundamental property in LLMs that could be manipulated in an adversarial manner to reduce computation efficiency significantly. Our interesting observation is that the output length determines the computation efficiency of LLMs instead of the input, where the output length depends on two factors: an often sufficiently large yet pessimistic pre-configured threshold controlling the max number of iterations and a runtime-generated end of sentence (EOS) token. Our key motivation is to generate test inputs that could sufficiently delay the generation of EOS such that LLMs would have to go through enough iterations to satisfy the pre-configured threshold. We present LLMEffiChecker, which can work under both white-box setting and black-box setting. In the white-box scenario, LLMEffiChecker develops a gradient-guided technique that searches for a minimal and unnoticeable perturbation at character-level, token-level, and structure-level. In the black-box scenario, LLMEffiChecker employs a causal inference-based approach to find critical tokens and similarly applies three levels of imperceptible perturbation to them. Both the white-box and black-box settings effectively delay the appearance of EOS, compelling these inputs to reach the naturally unreachable threshold. To demonstrate the effectiveness of LLMEffiChecker, we conduct a systematic evaluation on nine publicly available LLMs: Google T5, AllenAI WMT14, Helsinki-NLP translator, Facebook FairSeq, UNICAMP-DL translator, MarianMT, Google FLAN-T5, MBZUAI LaMini-GPT, and Salesforce CodeGen. Experimental results show that LLMEffiChecker can increase on average LLMs’ response latency and energy consumption by 325% to 3,244% and 344% to 3,616%, respectively, by perturbing just one character or token in the input sentence. Our case study shows that inputs generated by LLMEffiChecker significantly affect the battery power in real-world mobile devices (i.e., drain more than 30 times battery power than normal inputs).},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = aug,
articleno = {186},
numpages = {38},
keywords = {Machine learning, software testing, large language model}
}

@inproceedings{10.1145/3620678.3624793,
author = {Zhao, Dan and Samsi, Siddharth and McDonald, Joseph and Li, Baolin and Bestor, David and Jones, Michael and Tiwari, Devesh and Gadepally, Vijay},
title = {Sustainable Supercomputing for AI: GPU Power Capping at HPC Scale},
year = {2023},
isbn = {9798400703874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620678.3624793},
doi = {10.1145/3620678.3624793},
abstract = {As research and deployment of AI grows, the computational burden to support and sustain its progress inevitably does too. To train or fine-tune state-of-the-art models in NLP, computer vision, etc., some form of AI hardware acceleration is virtually a requirement. Recent large language models require considerable resources to train and deploy, resulting in significant energy usage, potential carbon emissions, and massive demand for GPUs and other hardware accelerators. However, this surge carries large implications for energy sustainability at the HPC/datacenter level. In this paper, we study the effects of power-capping GPUs at a research supercomputing center on GPU temperature and power draw; we show significant decreases in both temperature and power draw, reducing power consumption and potentially improving hardware life-span, with minimal impact on job performance. To our knowledge, our work is the first to conduct and make available a detailed analysis of the effects of GPU power-capping at the supercomputing scale. We hope our work will inspire HPCs/datacenters to further explore, evaluate, and communicate the impact of power-capping AI hardware accelerators for more sustainable AI.},
booktitle = {Proceedings of the 2023 ACM Symposium on Cloud Computing},
pages = {588–596},
numpages = {9},
keywords = {artificial intelligence, deep learning, distributed systems, high-performance computing, sustainable computing},
location = {Santa Cruz, CA, USA},
series = {SoCC '23}
}

@inproceedings{10.1145/3703187.3703286,
author = {Zhang, Jingwei},
title = {RoBERTa-based Video-Associated Text Feature Explainable Performance Prediction},
year = {2024},
isbn = {9798400707254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703187.3703286},
doi = {10.1145/3703187.3703286},
abstract = {In the Internet era, video has emerged as a novel form of media, with its commercial value directly linked to the attention it receives. For media creators, predicting a video's popularity can help clarify creative direction. For video platforms, accurately estimating a video's popularity enables the efficient allocation of promotional resources. Predicting video popularity assists these groups or teams in achieving greater economic returns. To enhance the flexibility and explainability of predicting video popularity, this study proposes a video text feature explainability popularity prediction method based on RoBERTa (R-VEPP). This study collected publicly available information from the Bilibili website and used the bibiGPT video summary interface and the Ernie large language model to create a self-constructed text datasets. The author developed a prediction model by leveraging RoBERTa and cosine similarity calculations. Ultimately, the model demonstrated outstanding performance in the automatic scoring task, with a mean squared error (MSE) of 0.5728 and an accuracy rate of 88.672%. R-VEPP enhances the flexibility of video popularity prediction while achieving a certain degree of explainability in scoring. The results indicate that R-VEPP holds practical value.},
booktitle = {Proceedings of the 2024 7th International Conference on Computer Information Science and Artificial Intelligence},
pages = {587–592},
numpages = {6},
keywords = {Explainability, RoBERTa, Text regression, Topic relevance},
location = {
},
series = {CISAI '24}
}

@inproceedings{10.1145/3613904.3642830,
author = {Lam, Michelle S. and Teoh, Janice and Landay, James A. and Heer, Jeffrey and Bernstein, Michael S.},
title = {Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642830},
doi = {10.1145/3613904.3642830},
abstract = {Data analysts have long sought to turn unstructured text data into meaningful concepts. Though common, topic modeling and clustering focus on lower-level keywords and require significant interpretative work. We introduce concept induction, a computational process that instead produces high-level concepts, defined by explicit inclusion criteria, from unstructured text. For a dataset of toxic online comments, where a state-of-the-art BERTopic model outputs “women, power, female,” concept induction produces high-level concepts such as “Criticism of traditional gender roles” and “Dismissal of women’s concerns.” We present LLooM, a concept induction algorithm that leverages large language models to iteratively synthesize sampled text and propose human-interpretable concepts of increasing generality. We then instantiate LLooM in a mixed-initiative text analysis tool, enabling analysts to shift their attention from interpreting topics to engaging in theory-driven analysis. Through technical evaluations and four analysis scenarios ranging from literature review to content moderation, we find that LLooM’s concepts improve upon the prior art of topic models in terms of quality and data coverage. In expert case studies, LLooM helped researchers to uncover new insights even from familiar datasets, for example by suggesting a previously unnoticed concept of attacks on out-party stances in a political social media dataset.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {766},
numpages = {28},
keywords = {data visualization, human-AI interaction, large language models, topic modeling, unstructured text analysis},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3689187.3709614,
author = {Prather, James and Leinonen, Juho and Kiesler, Natalie and Gorson Benario, Jamie and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Vee and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and Smith, David H. and Strickroth, Sven and Zingaro, Daniel},
title = {Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709614},
doi = {10.1145/3689187.3709614},
abstract = {Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report aims to summarize and explain what is happening on the ground in computing classrooms. We provide a systematic literature review; a survey of educators and industry professionals; and interviews with educators using GenAI in their courses, educators studying GenAI, and researchers who create GenAI tools to support computing education. The triangulation of these methods and data sources expands the understanding of GenAI usage and perceptions at this critical moment for our community.},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {300–338},
numpages = {39},
keywords = {artificial intelligence, computing education, genai, generative ai, large language models, pedagogical practices, teaching computing},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3650212.3680323,
author = {Xia, Chunqiu Steven and Zhang, Lingming},
title = {Automated Program Repair via Conversation: Fixing 162 out of 337 Bugs for $0.42 Each using ChatGPT},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680323},
doi = {10.1145/3650212.3680323},
abstract = {Automated Program Repair (APR) aims to automatically generate patches for buggy programs. Traditional APR techniques suffer from a lack of patch variety as they rely heavily on handcrafted or mined bug fixing patterns and cannot easily generalize to other bug/fix types. To address this limitation, recent APR work has been focused on leveraging modern Large Language Models (LLMs) to directly generate patches for APR. Such LLM-based APR tools work by first constructing an input prompt built using the original buggy code and then querying the LLM to either fill-in (cloze-style APR) the correct code at the bug location or to produce a completely new code snippet as the patch. While the LLM-based APR tools are able to achieve state-of-the-art results, they still follow the classic Generate and Validate (GV) repair paradigm of first generating lots of patches by sampling from the same initial prompt and then validating each one afterwards. This not only leads to many repeated patches that are incorrect, but also misses the crucial and yet previously ignored information in test failures as well as in plausible patches.        To address these aforementioned limitations, we propose ChatRepair, the first fully automated conversation-driven APR approach that interleaves patch generation with instant feedback to perform APR in a conversational style. ChatRepair first feeds the LLM with relevant test failure information to start with, and then learns from both failures and successes of earlier patching attempts of the same bug for more powerful APR. For earlier patches that failed to pass all tests, we combine the incorrect patches with their corresponding relevant test failure information to construct a new prompt for the LLM to generate the next patch. In this way, we can avoid making the same    mistakes. For earlier patches that passed all the tests (i.e., plausible patches), we further ask the LLM to generate alternative variations of the original plausible patches. In this way, we can further build on and learn from earlier successes to generate more plausible patches to increase the chance of having correct patches. While our approach is general, we implement ChatRepair using state-of-the-art dialogue-based LLM – ChatGPT. Our evaluation on the widely studied Defects4j dataset shows that ChatRepair is able to achieve the new state-of-the-art in repair performance, achieving 114 and 48 correct fixes on Defects4j 1.2 and 2.0 respectively. By calculating the cost    of accessing ChatGPT, we can fix 162 out of 337 bugs for $0.42 each!},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {819–831},
numpages = {13},
keywords = {Automated Program Repair, Large Language Model},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@article{10.1145/3589324,
author = {Peng, Zhencan and Wang, Zhizhi and Deng, Dong},
title = {Near-Duplicate Sequence Search at Scale for Large Language Model Memorization Evaluation},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
url = {https://doi.org/10.1145/3589324},
doi = {10.1145/3589324},
abstract = {Recent studies show that large language models (LLM) unintendedly memorize part of the training data, which brings serious privacy risks. For example, it has been shown that over 1% of tokens generated unprompted by an LLM are part of sequences in the training data. However, current studies mainly focus on the exact memorization behaviors. In this paper, we propose to evaluate how many generated texts have near-duplicates (e.g., only differ by a couple of tokens out of 100) in the training corpus. A major challenge of conducting this evaluation is the huge computation cost incurred by near-duplicate sequence searches. This is because modern LLMs are trained on larger and larger corpora with up to 1 trillion tokens. What's worse is that the number of sequences in a text is quadratic to the text length. To address this issue, we develop an efficient and scalable near-duplicate sequence search algorithm in this paper. It can find (almost) all the near-duplicate sequences of the query sequence in a large corpus with guarantees. Specifically, the algorithm generates and groups the min-hash values of all the sequences with at least t tokens (as very short near-duplicates are often irrelevant noise) in the corpus in linear time to the corpus size. We formally prove that only 2 n+1/t+1 -1 min-hash values are generated for a text with n tokens in expectation. Thus the index time and size are reasonable. When a query arrives, we find all the sequences sharing enough min-hash values with the query using inverted indexes and prefix filtering. Extensive experiments on a few large real-world LLM training corpora show that our near-duplicate sequence search algorithm is efficient and scalable.},
journal = {Proc. ACM Manag. Data},
month = jun,
articleno = {179},
numpages = {18},
keywords = {language model memorization, large language model, near-duplicate detection, text alignment}
}

@inproceedings{10.1145/3597503.3623343,
author = {Deng, Yinlin and Xia, Chunqiu Steven and Yang, Chenyuan and Zhang, Shizhuo Dylan and Yang, Shujing and Zhang, Lingming},
title = {Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623343},
doi = {10.1145/3597503.3623343},
abstract = {Bugs in Deep Learning (DL) libraries may affect almost all downstream DL applications, and it is crucial to ensure the quality of such systems. It is challenging to generate valid input programs for fuzzing DL libraries, since the input programs need to satisfy both the syntax/semantics of the supported languages (e.g., Python) and the tensor/operator constraints for constructing valid computational graphs. Recently, the TitanFuzz work demonstrates that modern Large Language Models (LLMs) can be directly leveraged to implicitly learn all the language and DL computation constraints to generate valid programs for fuzzing DL libraries (and beyond). However, LLMs tend to generate ordinary programs following similar patterns/tokens with typical programs seen in their massive pre-training corpora (e.g., GitHub), while fuzzing favors unusual inputs that cover edge cases or are unlikely to be manually produced.To fill this gap, this paper proposes FuzzGPT, the first approach to priming LLMs to synthesize unusual programs for fuzzing. FuzzGPT is mainly built on the well-known hypothesis that historical bug-triggering programs may include rare/valuable code ingredients important for bug finding. Meanwhile, while traditional techniques leveraging such historical information require intensive human efforts to both design dedicated generators and ensure the syntactic/semantic validity of generated programs, FuzzGPT demonstrates that this process can be fully automated via the intrinsic capabilities of LLMs (including fine-tuning and in-context learning), while being generalizable and applicable to challenging domains. While FuzzGPT can be applied with different LLMs, this paper focuses on the powerful GPT-style models: Codex and CodeGen. Moreover, FuzzGPT also shows the potential of directly leveraging the instruction-following capability of the recent ChatGPT for effective fuzzing. The experimental study on two popular DL libraries (PyTorch and TensorFlow) shows that FuzzGPT can substantially outperform TitanFuzz, detecting 76 bugs, with 49 already confirmed as previously unknown bugs, including 11 high-priority bugs or security vulnerabilities.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {70},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@article{10.1145/3703599.3703602,
author = {Ataguba, Grace and Aworinde, Halleluyah and Henry, Kosi Clinton and Orji, Rita},
title = {Exploring AI-Based System for African Food Weight-Loss Recommendations},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
number = {138},
issn = {1558-2337},
url = {https://doi.org/10.1145/3703599.3703602},
doi = {10.1145/3703599.3703602},
abstract = {This research leverages artificial intelligence to design an African food recommendation system for weight loss. The rationale for designing this system was based on our recently published study on the design of socio-cultural food recognition systems for Africans. Based on our previous study, results revealed that users considered the socio-cultural food recognition system to provide nutritional value and would require a robust system with more African foods. Hence, to tailor our findings to effective dietary planning where obesity could be a concern, we propose the current system given the health implications of additional foods for specific users (that is, overweight users). Our current study is in three phases. The first phase will focus on validating some African foods with dieticians to determine their appropriateness for weight loss and better alternatives based on calories and other important metrics. Additionally, we will invite dieticians and some overweight users to evaluate some low-fidelity (Lo-fi) prototypes for the design requirement elicitation of the final prototype. The second phase will involve the development of our AI models (computer vision and large language models) and their evaluation. Furthermore, we will leverage the design requirements gathered from the lo-fi prototype study together with the AI models to develop a high-fidelity (Hi-fi) AI system that will run on mobile devices (the final prototype). Consequently, a post-study evaluation will be conducted with dieticians and overweight users to obtain subjective feedback. Hence, findings from this study will provide design recommendations for integrating African foods into existing and related large-scale AI-based systems in the future.},
journal = {SIGACCESS Access. Comput.},
month = nov,
articleno = {3},
numpages = {1}
}

@article{10.1145/3660778,
author = {Yang, Zhen and Liu, Fang and Yu, Zhongxing and Keung, Jacky Wai and Li, Jia and Liu, Shuo and Hong, Yifan and Ma, Xiaoxue and Jin, Zhi and Li, Ge},
title = {Exploring and Unleashing the Power of Large Language Models in Automated Code Translation},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660778},
doi = {10.1145/3660778},
abstract = {Code translation tools, namely transpilers, are developed for automatic source-to-source translation. Latest learning-based transpilers have shown impressive enhancement against rule-based counterparts in both translation accuracy and readability, owing to their task-specific pre-training on extensive monolingual corpora. Nevertheless, their current performance still remains unsatisfactory for practical deployment, and the associated training resources are also prohibitively expensive. Large Language Models (LLMs), pre-trained on huge amounts of human-written code/text, have shown remarkable performance in many code intelligence tasks due to their powerful generality, even without task-specific re-training/fine-tuning. Thus, LLMs can potentially circumvent the above limitations, but they have not been exhaustively explored yet. This paper investigates diverse LLMs and learning-based transpilers for automated code translation tasks, finding that: although certain LLMs have outperformed current transpilers, they still have some accuracy issues, where most of the failures are induced by a lack of comprehension of source programs (38.51%), missing clear instructions on I/O types in translation (14.94%), and ignoring discrepancies between source and target programs (41.38%).  Enlightened by the above findings, we further propose UniTrans, a Unified code Translation framework, applicable to various LLMs, for unleashing their power in this field. Specifically, UniTrans first crafts a series of test cases for target programs with the assistance of source programs. Next, it harnesses the above auto-generated test cases to augment the code translation and then evaluate their correctness via execution. Afterward, UniTrans further (iteratively) repairs incorrectly translated programs prompted by test case execution results. Extensive experiments are conducted on six settings of translation datasets between Python, Java, and C++. Three recent LLMs of diverse sizes, including GPT-3.5 and LLaMA-13B/7B, are tested with UniTrans, and all achieve substantial improvements in terms of computational accuracy and exact match accuracy among almost all translation settings, showing the universal effectiveness of UniTrans in practice.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {71},
numpages = {24},
keywords = {Automated Code Translation, Large Language Models, Transformer}
}

@inproceedings{10.1145/3607827.3616846,
author = {Li, Boyang},
title = {Unlocking Multimedia Capabilities of Gigantic Pretrained Language Models},
year = {2023},
isbn = {9798400702839},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607827.3616846},
doi = {10.1145/3607827.3616846},
abstract = {Benefitting from unprecedented computational power, massive data throughput, and superhuman memory, large language models (LLMs) are fundamentally transforming multimodal machine learning. An LLM can be analogized to an enormous treasure box guarded by a lock. It contains extensive knowledge, but it can be non-trivial to access and apply appropriate knowledge to solve the problem at hand. Researchers have developed many techniques to unlock the capabilities of LLMs. Some well-known examples include chain-of-thought prompting, "let's think step by step'', and instruction tuning. In this talk, I will discuss techniques to unlock the capability of LLMs to process both visual and linguistic information. VisualGPT is one of the earliest works that finetunes an LLM for a vision-language task. InstructBLIP is an instruction-tuned large vision-language model, which set new states of the art on several vision-language tasks and snatched top positions on several comprehensive evaluation suites. In addition, I will talk about how to unlock zero-shot capabilities without end-to-end finetuning, or any form of finetuning at all. In Plug-and-Play VQA and Img2LLM, we achieve excellent results on visual question-answering datasets by connecting existing pretrained models using natural language and model interpretations, demonstrating a feasible alternative to the mainstream finetuning approach. Finally, I will describe a new multimodal dataset, Synopses of Movie Narratives, or SyMoN, for story understanding, which constitutes a new challenge for large vision-language models. I will argue that story understanding is an important objective in the pursuit of artificial general intelligence (AGI) because stories are a preeminent form of human communication and story understanding requires many AGI capabilities such as cause-effect reasoning and theory of mind. Compared to other multimodal story datasets, the special advantages of SyMoN include (1) event descriptions at the right level of granularity, (2) abundant mental state descriptions, (3) the use of diverse storytelling techniques, and (4) the provision of easy-to-use automatic performance evaluation.},
booktitle = {Proceedings of the 1st Workshop on Large Generative Models Meet Multimodal Applications},
pages = {3–4},
numpages = {2},
keywords = {visual question-answering, multimodal story understanding, multimodal learning, large language models},
location = {Ottawa ON, Canada},
series = {LGM3A '23}
}

@proceedings{10.1145/3657604,
title = {L@S '24: Proceedings of the Eleventh ACM Conference on Learning @ Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to present the Proceedings of the Eleventh Annual ACM Conference on Learning at Scale, L@S 2024, held July 18-20, 2024 at Georgia Tech in Atlanta, Georgia, USA.The Learning at Scale conference was created by the Association for Computing Machinery (ACM), inspired by the emergence of Massive Open Online Courses (MOOCs) and the accompanying shift in thinking about education. During the last few years, new opportunities for scaling up learning have emerged, like hybrid learning environments combining online and face-to-face, and informal learning enabled by all sorts of platforms (e.g., gamified language learning, citizen science communities, and collaborative programming communities). In the recent two years, the unprecedented development of generative AI has brought profound opportunities to scale the teaching and learning experiences, with the goal of enhancing learning for the increasingly diverse group of learners in both formal and informal contexts. L@S has evolved along with these emergent massive learning scenarios and opportunities and is today one of the most prominent venues for discussion of the highest quality of research on how learning and teaching can be transformed at scale, in diverse learning environments.The theme of L@S 2024 is Scaling Learning in the Age of AI. Rapid advances in AI have created new opportunities but also challenges for the Learning@Scale community. The advances in generative AI show potential to enhance pedagogical practices and the efficacy of learning at scale. This has led to an unprecedented level of interest in employing generative AI for scaling tutoring and feedback. The prevalence of such tools calls for new practices and understanding on how AI-based methods should be designed and developed to enhance the experiences and outcomes of teachers and learners.Learning@Scale 2024 solicits empirical and theoretical papers on, but not limited to, the following topics (in no particular order): 1) Instruction at scale: studies that examine how teachers and educators scale their instructions, what aspects of instruction could be scaled effectively, and which of these instructional strategies are the most effective for learning. 2) Interventions at scale: studies that examine the effects of interventions on student learning and performance when implemented at scale. We welcome studies that use both qualitative and quantitative methods. 3) The use of generative AI to scale learning: studies that investigate stakeholders' experiences with generative AI, students' and teachers' interactions with generative AI, and the potentials and limitations of using generative AI in education. 4) Systems and tools to support learning at scale: research that designs and develops systems and tools to support learning at scale. For example, this involves scaling learning through web-based systems, MOOCs, visualization, intelligent tutoring systems, gamification, immersive techniques (AR/VR/MR), mobile technologies, tangible interfaces, and various other technologies. 5) The evaluation of existing learning at scale systems and online learning environments using but not limited to the above-mentioned technologies. 6) Methods and algorithms that model learner behavior: research that contributes methods, algorithms, and pipelines that process large student data to enhance learning at scale. 7) Scaling learning in informal contexts: studies that explore how people take advantage of online environments to pursue their interests informally. 8) Review and synthesis of existing literature related to learning at scale. 9) Empirical studies and interventions that address equity, trust, algorithmic transparency and explainability, fairness and bias when using AI in education. 10) Research that addresses accessibility in learning at scale contexts. 11) Design and deployment of learning at scale systems for learners from underrepresented groups.},
location = {Atlanta, GA, USA}
}

@inproceedings{10.1145/3591106.3592278,
author = {Alonso del Barrio, David and Gatica-Perez, Daniel},
title = {Framing the News: From Human Perception to Large Language Model Inferences},
year = {2023},
isbn = {9798400701788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3591106.3592278},
doi = {10.1145/3591106.3592278},
abstract = {Identifying the frames of news is important to understand the articles’ vision, intention, message to be conveyed, and which aspects of the news are emphasized. Framing is a widely studied concept in journalism, and has emerged as a new topic in computing, with the potential to automate processes and facilitate the work of journalism professionals. In this paper, we study this issue with articles related to the Covid-19 anti-vaccine movement. First, to understand the perspectives used to treat this theme, we developed a protocol for human labeling of frames for 1786 headlines of No-Vax movement articles of European newspapers from 5 countries. Headlines are key units in the written press, and worth of analysis as many people only read headlines (or use them to guide their decision for further reading.) Second, considering advances in Natural Language Processing (NLP) with large language models, we investigated two approaches for frame inference of news headlines: first with a GPT-3.5 fine-tuning approach, and second with GPT-3.5 prompt-engineering. Our work contributes to the study and analysis of the performance that these models have to facilitate journalistic tasks like classification of frames, while understanding whether the models are able to replicate human perception in the identification of these frames.},
booktitle = {Proceedings of the 2023 ACM International Conference on Multimedia Retrieval},
pages = {627–635},
numpages = {9},
keywords = {Covid-19 no-vax, GPT-3, large language models, news framing, prompt-engineering, transformers},
location = {Thessaloniki, Greece},
series = {ICMR '23}
}

@article{10.1145/3672458,
author = {Huang, Qing and Luo, Zhiwen and Xing, Zhenchang and Zeng, Jinshan and Chen, Jieshan and Xu, Xiwei and Chen, Yong},
title = {Revealing the Unseen: AI Chain on LLMs for Predicting Implicit Dataflows to Generate Dataflow Graphs in Dynamically Typed Code},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {7},
issn = {1049-331X},
url = {https://doi.org/10.1145/3672458},
doi = {10.1145/3672458},
abstract = {Dataflow graphs (DFGs) capture definitions (defs) and uses across program blocks, which is a fundamental program representation for program analysis, testing and maintenance. However, dynamically typed programming languages like Python present implicit dataflow issues that make it challenging to determine def-use flow information at compile time. Static analysis methods like Soot and WALA are inadequate for handling these issues, and manually enumerating comprehensive heuristic rules is impractical. Large pre-trained language models (LLMs) offer a potential solution, as they have powerful language understanding and pattern matching abilities, allowing them to predict implicit dataflow by analyzing code context and relationships between variables, functions, and statements in code. We propose leveraging LLMs’ in-context learning ability to learn implicit rules and patterns from code representation and contextual information to solve implicit dataflow problems. To further enhance the accuracy of LLMs, we design a five-step chain of thought (CoT) and break it down into an Artificial Intelligence (AI) chain, with each step corresponding to a separate AI unit to generate accurate DFGs for Python code. Our approach’s performance is thoroughly assessed, demonstrating the effectiveness of each AI unit in the AI Chain. Compared to static analysis, our method achieves 82% higher def coverage and 58% higher use coverage in DFG generation on implicit dataflow. We also prove the indispensability of each unit in the AI Chain. Overall, our approach offers a promising direction for building software engineering tools by utilizing foundation models, eliminating significant engineering and maintenance effort, but focusing on identifying problems for AI to solve.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {183},
numpages = {29},
keywords = {Dataflow graph, AI chain, Large Language Models}
}

@article{10.1145/3717061,
author = {Yang, Zezhou and Chen, Sirong and Gao, Cuiyun and Li, Zhenhao and Hu, Xing and Liu, Kui and Xia, Xin},
title = {An Empirical Study of Retrieval-Augmented Code Generation: Challenges and Opportunities},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3717061},
doi = {10.1145/3717061},
abstract = {Code generation aims to automatically generate code snippets of specific programming language according to natural language descriptions. The continuous advancements in deep learning, particularly pre-trained models, have empowered the code generation task to achieve remarkable performance. One main challenge of pre-trained models for code generation is the semantic gap between developers’ natural language requirements and source code. To address the issue, prior studies typically adopt a retrieval-augmented framework for the task, where the similar code snippets collected by a retrieval process can be leveraged to help understand the requirements and provide guidance for the generation process. In a retrieval-augmented framework, similar data can be retrieved from the database using a retrieval algorithm, and original input data can be fused with retrieved data by different fusion strategies. However, there is a lack of systematic study on the application of this framework for code generation, including the impact of the final generated results and the specific usage of the framework. In this paper, we choose three popular pre-trained code models, namely CodeGen, UniXcoder, and CodeT5, to assess the impact of the quality and utilization of retrieved code on the retrieval-augmented framework. Our analysis shows that the retrieval-augmented framework is beneficial for improving the performance of the existing pre-trained models. We also provide suggestions on the utilization of the retrieval-augmented code generation framework: BM25 and Sequential Integration Fusion are recommended due to their convenience and superior performance. Sketch Filling Fusion, which extracts a sketch of relevant code, could help the model improve its performance further. Additionally, we conduct experiments to investigate the influence of the retrieval-augmented framework on large language models for code generation, showing the effectiveness of the framework, and we discuss the trade-off between performance improvement and computational costs in each phase within the framework.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {code generation, retrieval-augmented methods, empirical study}
}

@inproceedings{10.1145/3664647.3689178,
author = {Wang, Xin and Zhou, Yuwei and Chen, Hong and Zhu, Wenwu},
title = {Curriculum Learning for Multimedia in the Era of Large Language Models},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3689178},
doi = {10.1145/3664647.3689178},
abstract = {This tutorial focuses on curriculum learning (CL), an important topic in machine learning, which gains an increasing amount of attention in the research community. CL is a learning paradigm that enables machines to learn from easy data to hard data, imitating the meaningful procedure of human learning with curricula. As an easy-to-use plug-in, CL has demonstrated its power in improving the generalization capacity and convergence rate of various models in a wide range of scenarios such as computer vision, natural language processing, reinforcement learning, etc. In particular, CL can also play an important role in multimedia applications. Therefore, it is essential to introduce CL to more scholars and researchers in the machine learning and multimedia community. However, there have been no tutorials on CL for multimedia so far, motivating the organization of this tutorial at ACM Multimedia 2024. To give a comprehensive tutorial on CL for multimedia, we plan to organize it from the following aspects: (1) theories, (2) approaches, (3) applications, (4) tools, and (5) future directions. First, we introduce the motivations, theories, and insights behind CL. Second, we advocate novel, high-quality approaches, as well as innovative solutions to the challenging problems in CL. Then we present the applications of CL in various scenarios, especially multimedia, followed by some relevant tools. In the end, we discuss open questions and future directions in the era of large language models. We believe this topic is at the core of the scope of ACM Multimedia and is attractive to the audience interested in machine learning and multimedia from both academia and industry.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {11296–11297},
numpages = {2},
keywords = {curriculum learning, large language models, machine learning library and tool, machine learning paradigm, training strategy},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3630106.3658984,
author = {Wang, Ruotong and Cheng, Ruijia and Ford, Denae and Zimmermann, Thomas},
title = {Investigating and Designing for Trust in AI-powered Code Generation Tools},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658984},
doi = {10.1145/3630106.3658984},
abstract = {Trust is a crucial factor for the adoption and responsible usage of generative AI tools in complex tasks such as software engineering. However, we have a limited understanding of how software developers evaluate the trustworthiness of AI-powered code generation tools in real-world settings. To address this gap, we conducted Study 1, an interview study with 17 developers who use AI-powered code generation tools in professional or personal settings. We found that developers’ trust is rooted in the AI tool’s perceived ability, integrity, and benevolence, and is situational, varying according to the context of usage. Existing AI code generation tools lack the affordances for developers to efficiently and effectively evaluate the trustworthiness of AI-powered code generation tools. To explore designs that can augment the existing interface of AI-powered code generation tools, we explored three sets of design concepts (suggestion quality indicators, usage stats, and control mechanisms) that derived from Study 1 findings. In Study 2, a design probe study with 12 developers, we investigated the potential of these design concepts to help developers make effective trust judgments. We discuss the implication of our findings on the design of AI-powered code generation tools and future research on trust in AI.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1475–1493},
numpages = {19},
keywords = {generative AI, human-AI interaction, software engineering tooling, trust in AI},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3700297.3700350,
author = {Lin, Daping and Pu, Xianwei},
title = {Effects of Prompts and Time on the Automated Scoring of English Argumentative Essays by ChatGPT 4},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700350},
doi = {10.1145/3700297.3700350},
abstract = {As deep learning technology in computer science develops, generative artificial intelligence (GenAI) has shown great potential in automated essay scoring (AES). Prompts and time are important factors which may influence the performance of GenAI. The study selected 52 English argumentative essays, designed five different prompts, chooses two different time points, and then utilized ChatGPT 4 to explore the effects of prompts and time on AES by GenAI. Besides, possible reasons for large difference between human and GenAI score were discussed.For different prompts, results show that the one-shot prompt performs better in AES compared with the other four prompts. It provides background information and a scoring example to ChatGPT. The scores generated by it do not significantly differ from the human scores. They significantly and positively correlate with human scores (ρ = 0.424). The exact-plus-adjacent agreement (EPAA) rate for one-shot prompt scores reaches 69.23%. For scores generated at different points in time, results reveal that although there is still a significant difference between scores generated after one week and human scores, the ChatGPT-Human EPAA rate becomes higher and the absolute value of mean score difference is smaller.Based on the analysis of selected essays, the major reason for large GenAI-Human score difference is that ChatGPT evaluates essays from limited perspectives to give its score, while human raters can comprehensively assess the quality of an essay. What's more, ChatGPT cannot keep the same scoring criteria during the rating process.The study aims to help people understand how to interact with GenAI more efficiently and take advantage of GenAI to meet the practical needs.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {302–312},
numpages = {11},
keywords = {English argumentative essays, automated essay scoring, generative artificial intelligence, prompts, time},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3641555.3704769,
author = {Sussman, Alan and Prasad, Sushil and Bunde, David P. and Spacco, Jaime and Gannod, Gerald and Crockett, April Renee and Vaidyanathan, Ramachandran},
title = {Modernizing the CS Introductory Sequence with Parallel and Distributed Computing (and some AI)},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704769},
doi = {10.1145/3641555.3704769},
abstract = {Parallel and distributed computing (PDC) has become pervasive in all aspects of computing, so it is essential that students include parallelism and distribution in the computational thinking that they apply to problem solving, from the beginning of their computing education. With all computing devices that students use having multiple cores as well as a GPU in many cases, many students' favorite applications use multiple cores and/or distributed processors. However, we are still teaching them to solve problems using only sequential thinking. Why?This hands-on tutorial will demonstrate how easy it is to open students' eyes to exploiting concurrency in problem solving. You will participate in plugged and unplugged activities that will help students to recognize examples of PDC concepts and concurrency in the world around them. We introduce plugged and unplugged curriculum modules that have been successfully integrated in existing computing classes at multiple institutions. We will also discuss recent efforts at integrating AI methods, including LLMs, into introductory classes.A laptop capable of running a C/C++ compiler, a Java virtual environment, and a Python interpreter is needed to fully participate in activities. However, attendees may learn the core concepts without a laptop. The activities and curriculum modules have been used successfully to teach PDC concepts in early computing courses and will be available after the workshop. Participants will receive a stipend of 400 to defray their cost of registration and one-night hotel stay. The CDER center will also have a booth in the exhibition hall for additional support.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1775},
numpages = {1},
keywords = {acm/ieee-cs/aaai computer science curricula, ai, computing education, cs1/ cs2, early computing class, hpc education, undergraduate instruction, pdc education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3581754.3584165,
author = {Gadiraju, Ujwal and Abbas, Tahir and Allen, Garrett},
title = {DECI: A Tutorial on Designing Effective Conversational Interfaces},
year = {2023},
isbn = {9798400701078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581754.3584165},
doi = {10.1145/3581754.3584165},
abstract = {Conversational User Interfaces (CUIs) have been argued to have advantages over traditional GUIs due to having a more human-like interaction. The growing popularity of conversational agents has enabled humans to interact with machines more naturally. There is an increasing familiarity among people with conversational interactions mediated by technology due to the widespread use of mobile devices and messaging services and a hungry market for conversational agents. Based on the recent advances in conversational AI, as a result of the proliferation of large language models, the signs are that the future of human-computer interaction will have a significant conversational component. Today, over two-thirds of the population on our planet has access to the Internet, with ever-lowering barriers to accessibility. This tutorial will showcase the benefits of employing novel conversational interfaces for crowd computing, human-AI decision making, health and well-being, and information retrieval. Given the widespread adoption of AI systems across several domains, we will discuss the potential of conversational interfaces in facilitating and mediating people’s interactions with AI systems. The tutorial will include interactive elements and discussions and provide participants with insights to inform the design of effective conversational interfaces.},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {187–189},
numpages = {3},
keywords = {conversational AI, conversational crowdsourcing, conversational user interfaces, human-AI decision making, human-AI interaction},
location = {Sydney, NSW, Australia},
series = {IUI '23 Companion}
}

@inproceedings{10.1145/3589335.3641257,
author = {Wang, Xin and Zhou, Yuwei and Chen, Hong and Zhu, Wenwu},
title = {Curriculum Learning: Theories, Approaches, Applications, Tools, and Future Directions in the Era of Large Language Models},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641257},
doi = {10.1145/3589335.3641257},
abstract = {This tutorial focuses on curriculum learning (CL), an important topic in machine learning, which gains an increasing amount of attention in the research community. CL is a learning paradigm that enables machines to learn from easy data to hard data, imitating the meaningful procedure of human learning with curricula. As an easy-to-use plug-in, CL has demonstrated its power in improving the generalization capacity and convergence rate of various models in a wide range of scenarios such as computer vision, natural language processing, data mining, reinforcement learning, etc. Therefore, it is essential introducing CL to more scholars and researchers in the machine learning community. However, there have been no tutorials on CL so far, motivating the organization of our tutorial on CL at WWW 2024. To give a comprehensive tutorial on CL, we plan to organize it from the following aspects: (1) theories, (2) approaches, (3) applications, (4) tools and (5) future directions. First, we introduce the motivations, theories and insights behind CL. Second, we advocate novel, high-quality approaches, as well as innovative solutions to the challenging problems in CL. Then we present the applications of CL in various scenarios, followed by some relevant tools. In the end, we discuss open questions and the future direction in the era of large language models. We believe this topic is at the core of the scope of WWW and is attractive to the audience interested in machine learning from both academia and industry.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1306–1310},
numpages = {5},
keywords = {curriculum learning, large language models, machine learning library and tool, machine learning paradigm, training strategy},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3650203.3663331,
author = {Woisetschl\"{a}ger, Herbert and Erben, Alexander and Wang, Shiqiang and Mayer, Ruben and Jacobsen, Hans-Arno},
title = {Federated Fine-Tuning of LLMs on the Very Edge: The Good, the Bad, the Ugly},
year = {2024},
isbn = {9798400706110},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650203.3663331},
doi = {10.1145/3650203.3663331},
abstract = {With the emergence of AI regulations, such as the EU AI Act, requirements for simple data lineage, enforcement of low data bias, and energy efficiency have become a priority for everyone offering AI services. Being pre-trained on versatile and a vast amount of data, large language models and foundation models (FMs) offer a good basis for building high-quality deep learning pipelines. Fine-tuning can further improve model performance on a specific downstream task, which requires orders of magnitude less data than pre-training. Often, access to high-quality and low-bias data for model fine-tuning is limited due to technical or regulatory requirements. Federated learning (FL), as a distributed and privacy-preserving technique, offers a well-suited approach to significantly expanding data access for model fine-tuning. Yet, this data is often located on the network edge, where energy, computational, and communication resources are significantly more limited than in data centers.In our paper, we conduct an end-to-end evaluation for fine-tuning the FLAN-T5 FM family on the network edge. We study energy efficiency potentials throughout FL systems - on clients, in communication, and on the server. Our analysis introduces energy efficiency as a real-time metric to assess the computational efficiency of an FL system. We show the stark need for further improvements in communication efficiency when working with FMs and demonstrate the importance of adaptive FL optimizers for FM training.},
booktitle = {Proceedings of the Eighth Workshop on Data Management for End-to-End Machine Learning},
pages = {39–50},
numpages = {12},
location = {Santiago, AA, Chile},
series = {DEEM '24}
}

@inproceedings{10.1145/3690712.3690713,
author = {Mansour, Atil and Amir, Ofra and Levontin, Liat},
title = {The Potentially Negative Effects of AI Writing Assistants on Self-Disclosure},
year = {2024},
isbn = {9798400710315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690712.3690713},
doi = {10.1145/3690712.3690713},
abstract = {Language use is the most common way to communicate and express ourselves. Letting ourselves be known to others is a process called self-disclosure, and it involves any exchange of information regarding the self. One way to self-disclose is through expressive writing. While self-disclosure is encouraged for mental health, there are potential costs. Consequently, some people may be more willing to disclose information using computer-mediated communication. The current research aims to test the influence of AI chat writing assistants on self-disclosure. In recent years, there has been an increase in Artificial Intelligence-Mediated Communication (AI-MC), in which an AI agent operates by modifying messages to achieve communication. Large Language Model-based conversational agents are increasingly integrated into critical application areas. AI-MCs have the potential to affect human language and thought. The current research will test the potential short- and long-term costs of AI usage in self-disclosing writing on health and well-being. We hypothesize that overall individuals who will use AI chat writing assistance during their writing process will not enjoy the psychological benefits of self-disclosure as much as individuals who will cognitively process their experiences alone. The results of this study may have important implications.},
booktitle = {Proceedings of the Third Workshop on Intelligent and Interactive Writing Assistants},
pages = {1–3},
numpages = {3},
location = {Honolulu, HI, USA},
series = {In2Writing '24}
}

@inproceedings{10.1145/3658271.3658337,
author = {Santos, Patricia de Oliveira and Figueiredo, Allan Chamon and Nuno Moura, Pedro and Diirr, Bruna and Alvim, Adriana C. F. and Santos, Rodrigo Pereira Dos},
title = {Impacts of the Usage of Generative Artificial Intelligence on Software Development Process},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658271.3658337},
doi = {10.1145/3658271.3658337},
abstract = {Context: Over the years, tools have been created to improve the execution of development process activities. The emergence of generative Artificial Intelligence (AI) and, more recently, the launch and dissemination of Copilot, ChatGPT-3 and other generative tools, have broadened the discussion about the possibility of using conversational generative AI tools in diverse development tasks. Problem: There is still a lack of secondary studies to map the literature about how software development process activities can be affected by the usage of generative AI tools. Solution: This study aims to identify in which activities of the software development process Natural Language (NL) generative AI tools have been used and how they can impact requirements specification, design/architecture, development and testing activities. IS Theory: The study was developed under the aegis of the Task Technology Fit theory. Method: This work presents the results of a Systematic Mapping Review (SMR) carried out to collect research results that investigate the application of generative AI tools in the software development process. Results: Results indicate that the main activities affected are development and testing and that, although there are still some issues to be addressed, there are benefits in using AI generative tools compared to using more traditional methods like human-human pair programming and code testing made by software engineering professionals. Contribution: It was possible to collect studies to identify in which activities of the software development process generative AI tools can be applied and what are the impacts of using this technology.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {65},
numpages = {9},
keywords = {ChatGPT, Copilot, Generative AI, Software Engineering, Software Process},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

@inproceedings{10.1145/3657604.3664701,
author = {Popescu, Diana M. and Joyner, David A.},
title = {ChatGPT's Performance on Problem Sets in an At-Scale Introductory Computer Science Course},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664701},
doi = {10.1145/3657604.3664701},
abstract = {This work in progress paper examines the impact of LLMs such as ChatGPT in a college-level introductory computing course offered simultaneously as a massive open online course (MOOC) on the edX platform, focusing on its strengths and limitations in solving coding assignments. The study reveals ChatGPT's proficiency in some areas while highlighting challenges in pseudo-code interpretation, handling multiple correct answers, and addressing complex problem statements. In order to discourage over-reliance on AI assistance from students while preserving scalability, the paper proposes strategies to enhance the difficulty of coding assignments by adding more creative elements in their structure. This research provides insights into the dynamics of AI in education and emphasizes the need for a balanced approach between technological assistance and genuine student participation.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {486–490},
numpages = {5},
keywords = {applied computing, artificial intelligence, e-learning},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3659211.3659227,
author = {Han, Yang},
title = {Advancing Text Analytics: Instruction Fine-Tuning of QianWen-7B for Sentiment Classification},
year = {2024},
isbn = {9798400716669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3659211.3659227},
doi = {10.1145/3659211.3659227},
abstract = {The complexity of financial systems and the subtleties of market behavior necessitate sophisticated tools for sentiment analysis. This study presents a fine-tuned QianWen-7B [1] model, a large pre-trained language model, tailored for financial text sentiment classification. Utilizing instruction fine-tuning, we have adapted the model to classify texts into three categories: positive, neutral, and negative. Our dataset comprises 2,879 neutral, 1,362 positive, and 604 negative samples from texts. The model was trained using a fine-tuning framework called QLora [2], with a quantization level of 4 and Lora rank of 8, optimizing for both memory usage and computational efficiency. We employed the Adam optimizer with a learning rate of 5e-5, a batch size of 4, and gradient accumulation to address hardware limitations. The fine-tuned Qwen-7B model achieved an accuracy of 0.8227, outperforming the Deberta-V3-base and Deberta-V3-large models, which underscores the effectiveness of our approach. Our findings illustrate the potential of using large language models with instruction fine-tuning for enhanced text sentiment analysis, paving the way for more informed investment decisions and robust market regulation. The discussion highlights the model's superior performance, challenges in dataset representativeness and class imbalance, and the importance of model interpretability in decision-making. It also points to future enhancements that could further improve the model's applicability and relevance in the rapidly changing financial sector.},
booktitle = {Proceedings of the 2023 4th International Conference on Big Data Economy and Information Management},
pages = {90–93},
numpages = {4},
location = {Zhengzhou, China},
series = {BDEIM '23}
}

@inproceedings{10.1145/3604237.3626861,
author = {Chung, Andy and Tanaka-Ishii, Kumiko},
title = {Predictability of Post-Earnings Announcement Drift with Textual and Contextual Factors of Earnings Calls},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626861},
doi = {10.1145/3604237.3626861},
abstract = {Post-Earnings Announcement Drift (PEAD), a well-known anomaly in financial markets, describes the tendency of cumulative stock returns to drift in the direction of an earnings surprise for a prolonged period following an earnings announcement. Numerous studies have used a supervised learning approach to predict PEAD, using earnings, fundamental and technical factors. However, there is a lack of study on how the context of the earnings call can be used for the PEAD prediction task. This paper uses computational linguistics techniques and large language models to examine the effectiveness of incorporating textual and contextual features from earnings calls for the PEAD prediction task. Our proposed supervised model includes four categories of features: 1) textual features, 2) contextual features, 3) earnings features, and 4) fundamental and technical features. We study the proposed model using earnings from 2010/01/01 to 2022/12/31 of all point-in-time S&amp;P500 constituents in the US stock market. Our results show that contextual features provide information unexplained by earnings, fundamental and technical features, improving the average returns per trade of a hypothetical long-short portfolio against baseline solution in out-of-sample across all four different abnormal return calculations, ranging from 53 to 354 basis points and 16.9% to 108.5% improvement from baseline model, which uses only earnings, fundamental and technical features.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {401–408},
numpages = {8},
keywords = {Post-earnings announcement drift, computational linguistics, earnings call, large language models, machine learning},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@inproceedings{10.1145/3699538.3699546,
author = {Keuning, Hieke and Alpizar-Chacon, Isaac and Lykourentzou, Ioanna and Beehler, Lauren and K\"{o}ppe, Christian and de Jong, Imke and Sosnovsky, Sergey},
title = {Students' Perceptions and Use of Generative AI Tools for Programming Across Different Computing Courses},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699546},
doi = {10.1145/3699538.3699546},
abstract = {Investigation of students’ perceptions and opinions on the use of generative artificial intelligence (GenAI) in education is a topic gaining much interest. Studies addressing this are typically conducted with large heterogeneous groups, at one moment in time. However, how students perceive and use GenAI tools can potentially depend on many factors, including their background knowledge, familiarity with the tools, and the learning goals and policies of the courses they are taking. In this study we explore how students following computing courses use GenAI for programming-related tasks across different programs and courses: Bachelor and Master, in courses in which learning programming is the learning goal, courses that require programming as a means to achieve another goal, and in courses in which programming is optional, but can be useful. We are also interested in changes over time, since GenAI capabilities are changing at a fast pace, and users are adopting GenAI increasingly. We conducted three consecutive surveys (fall ‘23, winter ‘23, and spring ‘24) among students of all computing programs of a large European research university. We asked questions on the use in education, ethics, and job prospects, and we included specific questions on the (dis)allowed use of GenAI tools in the courses they were taking at the time. We received 264 responses, which we quantitatively and qualitatively analyzed, to find out how students have employed GenAI tools across 59 different computing courses, and whether the opinion of an average student about these tools evolves over time. Our study contributes to the emerging discussion of how to differentiate GenAI use across different courses, and how to align its use with the learning goals of a computing course.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {14},
numpages = {12},
keywords = {Generative AI, Large Language Models, Computing Education, Programming Courses},
location = {
},
series = {Koli Calling '24}
}

@article{10.5555/3665609.3665633,
author = {Liu, Sa and Grey, Brian and Watkins, Ryan and Chu, Chad and Grim, Phillip and McManus, Thomas},
title = {Assessing Risks, Challenges and Opportunities of Generative AI in Computer Programming Education --- Lightning Talk},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {8},
issn = {1937-4771},
abstract = {Artificial Intelligence (AI) has the potential to transform the education sector by enhancing teaching and learning experiences. According to Sal Khan, founder of Khan Academy, AI is about to start "the biggest positive transformation that education has ever seen"1 by making high-quality personalized tutoring available (tuition free) to everyone on the planet. Given AI's, and more specifically Generative AI's (GAI), rapidly developing capabilities (e.g., to provide tailored feedback, ask questions of students, give examples and non-examples, and offer general learning support), incorporating GAI into programming education has the potential to enhance student engagement and learning outcomes. At the same time, they identified challenges in using GAI, such as its inability to answer some questions and its tendency to provide incorrect or incomplete responses. Students also report an increase in anxiety surrounding GAI and its potential effects on future professional opportunities. Outside of the classroom there is likewise an increasing prevalence of GAI in computational professions, making it crucial to equip students with the necessary knowledge and skills to effectively, responsibly, and ethically utilize GAI. Rather than avoiding the use of GAI in the classroom, in this study we aim to investigate the pros and cons of leveraging GAI's capabilities to offer personalized guidance and assistance to students as they learn programming. By doing this research, we are learning to create more interactive and engaging learning experiences that better equip students with the skills and knowledge needed to succeed in the field of programming. This project, which is currently being conducted, was designed to address this research question: To what extent does the incorporation of GAI impact students' engagement, motivation, and achievement, particularly with the material in Intro to Programming courses and their chosen STEM field of study? It is utilizing case studies that focus on the integration of GAI into computer programming education. The team has 1) developed a series of GAI-supported teaching modules specifically designed to improve problem-solving skills in programming tasks among undergraduate students; and 2) is in the process of analyzing student feedback on GAI integration in computer programming education. This project offers an important exploration into the intersection of GAI and programming education, with the expectation that results will provide useful guidance for programming instructors who are adapting their instructional strategies for the emerging role of GAI in programming. The team will briefly present the status of the research and early insights from the project, and then engage with the audience on how lessons learned from this work can pragmatically shape programming courses in their institutions. Quick tips, takeaways, and prompting strategies will be shared throughout this interactive lighting talk.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {210–211},
numpages = {2}
}

@inproceedings{10.1145/3600211.3604695,
author = {Edenberg, Elizabeth and Wood, Alexandra},
title = {Disambiguating Algorithmic Bias: From Neutrality to Justice},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604695},
doi = {10.1145/3600211.3604695},
abstract = {As algorithms have become ubiquitous in consequential domains, societal concerns about the potential for discriminatory outcomes have prompted urgent calls to address algorithmic bias. In response, a rich literature across computer science, law, and ethics is rapidly proliferating to advance approaches to designing fair algorithms. Yet computer scientists, legal scholars, and ethicists are often not speaking the same language when using the term ‘bias.’ Debates concerning whether society can or should tackle the problem of algorithmic bias are hampered by conflations of various understandings of bias, ranging from neutral deviations from a standard to morally problematic instances of injustice due to prejudice, discrimination, and disparate treatment. This terminological confusion impedes efforts to address clear cases of discrimination. In this paper, we examine the promises and challenges of different approaches to disambiguating bias and designing for justice. While both approaches aid in understanding and addressing clear algorithmic harms, we argue that they also risk being leveraged in ways that ultimately deflect accountability from those building and deploying these systems. Applying this analysis to recent examples of generative AI, our argument highlights unseen dangers in current methods of evaluating algorithmic bias and points to ways to redirect approaches to addressing bias in generative AI at its early stages in ways that can more robustly meet the demands of justice.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {691–704},
numpages = {14},
keywords = {algorithms, bias, discrimination, fairness, generative AI, justice, large language models, law, philosophy, vision-language models},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

@inproceedings{10.1145/3641554.3701823,
author = {Ali, Areej and Collier, Aayushi Hingle and Dewan, Umama and McDonald, Nora and Johri, Aditya},
title = {Analysis of Generative AI Policies in Computing Course Syllabi},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701823},
doi = {10.1145/3641554.3701823},
abstract = {Since the release of ChatGPT in 2022, Generative AI (GenAI) is increasingly being used in higher education computing classrooms across the United States. While scholars have looked at overall institutional guidance for the use of GenAI and reports have documented the response from schools in the form of broad guidance to instructors, we do not know what policies and practices instructors are actually adopting and how they are being communicated to students through course syllabi. To study instructors' policy guidance, we collected 98 computing course syllabi from 54 R1 institutions in the U.S. and studied the GenAI policies they adopted and the surrounding discourse. Our analysis shows that 1) most instructions related to GenAI use were as part of the academic integrity policy for the course and 2) most syllabi prohibited or restricted GenAI use, often warning students about the broader implications of using GenAI, e.g. lack of veracity, privacy risks, and hindering learning. Beyond this, there was wide variation in how instructors approached GenAI including a focus on how to cite GenAI use, conceptualizing GenAI as an assistant, often in an anthropomorphic manner, and mentioning specific GenAI tools for use. We discuss the implications of our findings and conclude with current best practices for instructors.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {18–24},
numpages = {7},
keywords = {course syllabi, generative ai, policy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3640543.3645197,
author = {Andrews, Peter and Nordberg, Oda Elise and Zubicueta Portales, Stephanie and Borch, Nj\r{a}l and Guribye, Frode and Fujita, Kazuyuki and Fjeld, Morten},
title = {AiCommentator: A Multimodal Conversational Agent for Embedded Visualization in Football Viewing},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645197},
doi = {10.1145/3640543.3645197},
abstract = {Traditionally, sports commentators provide viewers with diverse information, encompassing in-game developments and player performances. Yet young adult football viewers increasingly use mobile devices for deeper insights during football matches. Such insights into players on the pitch and performance statistics support viewers’ understanding of game stakes, creating a more engaging viewing experience. Inspired by commentators’ traditional roles and to incorporate information into a single platform, we developed AiCommentator, a Multimodal Conversational Agent (MCA) for embedded visualization and conversational interactions in football broadcast video. AiCommentator integrates embedded visualization, either with an automated non-interactive or with a responsive interactive commentary mode. Our system builds upon multimodal techniques, integrating computer vision and large language models, to demonstrate ways for designing tailored, interactive sports-viewing content. AiCommentator’s event system infers game states based on a multi-object tracking algorithm and computer vision backend, facilitating automated responsive commentary. We address three key topics: evaluating young adults’ satisfaction and immersion across the two viewing modes, enhancing viewer understanding of in-game events and players on the pitch, and devising methods to present this information in a usable manner. In a mixed-method evaluation (n=16) of AiCommentator, we found that the participants appreciated aspects of both system modes but preferred the interactive mode, expressing a higher degree of engagement and satisfaction. Our paper reports on our development of AiCommentator and presents the results from our user study, demonstrating the promise of interactive MCA for a more engaging sports viewing experience. Systems like AiCommentator could be pivotal in transforming the interactivity and accessibility of sports content, revolutionizing how sports viewers engage with video content.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {14–34},
numpages = {21},
keywords = {Computer Vision, Conversational User Interface, Deep Learning, Embedded Visualization, Human-Computer Interaction, Multi-Object Tracking, Multimodal Conversational Agent, Usability Testing},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@inproceedings{10.1145/3638884.3638961,
author = {Liu, Wenjing and Zhang, Suxiang and Sun, Yang and Sheng, Xing and Wu, Zhidong},
title = {New Energy Power Domain Question-Method Extraction And Soft Clustering},
year = {2024},
isbn = {9798400708909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638884.3638961},
doi = {10.1145/3638884.3638961},
abstract = {In recent years, as the field of new energy power has gradually become a research hotspot, there are more and more research results related to new energy power. This paper first proposes to Fine-tune the Chinese LLaMA large language model to realize the extraction of research questions and methods in new energy power results. The fine-tuning dataset is constructed by the combination of rule template and gpt-3.5 enhancement, which avoids the costly and time-consuming problem caused by manual construction. The fine-tuning method adopts LoRA high-efficiency fine-tuning to save computing resources; Then, F1 value is used as the evaluation index to compare the extraction effect of the model under different fine-tuning datasets. The results show that the model has a good extraction effect on the research questions and method terms when training the dataset constructed by the combination of rule template and gpt-3.5 enhancement. Finally, according to the extracted research question phrases, BTM(Biterm Topic Model) is used to study the distribution of topic words, and soft clustering of research question phrases is carried out according to the obtained topic words, so as to realize the correlation between the research results and professional terms, which provides the foundation for the future establishment of the knowledge graph and knowledge base of new energy power.CCS CONCEPTS • Theory of computation • Theory and algorithms for application domains • Unsupervised learning and clustering},
booktitle = {Proceedings of the 2023 9th International Conference on Communication and Information Processing},
pages = {484–491},
numpages = {8},
keywords = {Biterm Topic Model, Chinese LLaMA Fine-Tuning, Soft clustering, Terminology extraction},
location = {Lingshui, China},
series = {ICCIP '23}
}

@inproceedings{10.1145/3649405.3659517,
author = {Glassey, Richard and Baltatzis, Alexander},
title = {Active Repos: Integrating Generative AI Workflows into GitHub},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659517},
doi = {10.1145/3649405.3659517},
abstract = {The aim of this work is to describe a simple and cost effective way to integrate generative AI into GitHub to support course specific scenarios. We are motivated by helping teachers realise their creative AI use cases in spite of technical barriers and also to ensure that students have a blessed and fair way to access AI services without needing to sign-up, prompt or pay. First we will describe a scenario that we have implemented for our own CS1 course, then we will describe the technical requirements for implementation. We finish off with our early thoughts on where these types of scenarios might be heading in terms of supporting computing education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {777–778},
numpages = {2},
keywords = {CS1, GitHub actions, automation, generative AI},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3611643.3613891,
author = {Jin, Pengxiang and Zhang, Shenglin and Ma, Minghua and Li, Haozhe and Kang, Yu and Li, Liqun and Liu, Yudong and Qiao, Bo and Zhang, Chaoyun and Zhao, Pu and He, Shilin and Sarro, Federica and Dang, Yingnong and Rajmohan, Saravan and Lin, Qingwei and Zhang, Dongmei},
title = {Assess and Summarize: Improve Outage Understanding with Large Language Models},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613891},
doi = {10.1145/3611643.3613891},
abstract = {Cloud systems have become increasingly popular in recent years due to their flexibility and scalability. Each time cloud computing applications and services hosted on the cloud are affected by a cloud outage, users can experience slow response times, connection issues or total service disruption, resulting in a significant negative business impact. Outages are usually comprised of several concurring events/source causes, and therefore understanding the context of outages is a very challenging yet crucial first step toward mitigating and resolving outages. In current practice, on-call engineers with in-depth domain knowledge, have to manually assess and summarize outages when they happen, which is time-consuming and labor-intensive. In this paper, we first present a large-scale empirical study investigating the way on-call engineers currently deal with cloud outages at Microsoft, and then present and empirically validate a novel approach (dubbed Oasis) to help the engineers in this task. Oasis is able to automatically assess the impact scope of outages as well as to produce human-readable summarization. Specifically, Oasis first assesses the impact scope of an outage by aggregating relevant incidents via multiple techniques. Then, it generates a human-readable summary by leveraging fine-tuned large language models like GPT-3.x. The impact assessment component of Oasis was introduced in Microsoft over three years ago, and it is now widely adopted, while the outage summarization component has been recently introduced, and in this article we present the results of an empirical evaluation we carried out on 18 real-world cloud systems as well as a human-based evaluation with outage owners. The results obtained show that Oasis can effectively and efficiently summarize outages, and lead Microsoft to deploy its first prototype which is currently under experimental adoption by some of the incident teams.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1657–1668},
numpages = {12},
keywords = {Cloud Systems, Large Language Model, Outage Understanding},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@article{10.1145/3605210,
author = {Dong, Jun},
title = {Natural Language Processing Pretraining Language Model for Computer Intelligent Recognition Technology},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {8},
issn = {2375-4699},
url = {https://doi.org/10.1145/3605210},
doi = {10.1145/3605210},
abstract = {Computer intelligent recognition technology refers to the use of computer vision, Natural Language Processing (NLP), machine learning and other technologies to enable computers to recognize, analyze, understand and answer human language and behavior. The common applications of computer intelligent recognition technology include image recognition, NLP, face recognition, target tracking, and other fields. NLP is a field of computer science, which involves the interaction between computers and natural languages. NLP technology can be used to process, analyze and generate natural language data, such as text, voice and image. Common NLP technology applications include language translation, emotion analysis, text classification, speech recognition and question answering system. Language model is a machine learning model, which uses a large number of text data for training to learn language patterns and relationships in text data. Although the language model has made great progress in the past few years, it still faces some challenges, including: poor semantic understanding, confusion in multilingual processing, slow language processing and other shortcomings. Therefore, in order to optimize these shortcomings, this article would study the pre-training language model based on NLP technology, which aimed at using NLP technology to optimize and improve the performance of the language model, thus optimizing the computer intelligent recognition technology. The model had a higher language understanding ability and more accurate prediction ability. In addition, the model could learn language rules and structures by using a large number of corpus, so as to better understand natural language. Through experiments, it could be known that the data size and total computing time of the traditional Generative Pretrained Transformer-2 (GPT-2) language model were 10 GB and 97 hours respectively. The data size and total computing time of BERT (Bidirectional Encoder Representations from Transformer) were 12 GB and 86 hours respectively. The data size and total computing time of the pre-training language model based on NLP were 18 GB and 71 hours respectively. Obviously, the pre-training language model based on NLP had a larger data size and shorter computing time. The experimental results showed that the NLP technology could better optimize the language model and effectively improve its various capabilities. This article opened up a new development direction for computer intelligent recognition technology and provided excellent technical support for the development of language models.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = aug,
articleno = {110},
numpages = {12},
keywords = {Natural Language Processing, Computer Intelligent Recognition Technology, Pre-trained Language Model, Computer Vision, Machine Learning}
}

@inproceedings{10.1145/3649405.3659534,
author = {Prather, James and Leinonen, Juho and Kiesler, Natalie and Benario, Jamie Gorson and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Virginia and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and Smith, David H. and Strickroth, Sven and Zingaro, Daniel},
title = {How Instructors Incorporate Generative AI into Teaching Computing},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659534},
doi = {10.1145/3649405.3659534},
abstract = {Generative AI (GenAI) has seen great advancements in the past two years and the conversation around adoption is increasing. Widely available GenAI tools are disrupting classroom practices as they can write and explain code with minimal student prompting. While most acknowledge that there is no way to stop students from using such tools, a consensus has yet to form on how students should use them if they choose to do so. At the same time, researchers have begun to introduce new pedagogical tools that integrate GenAI into computing curricula. These new tools offer students personalized help or attempt to teach prompting skills without undercutting code comprehension. This working group aims to detail the current landscape of education-focused GenAI tools and teaching approaches, present gaps where new tools or approaches could appear, identify good practice-examples, and provide a guide for instructors to utilize GenAI as they continue to adapt to this new era.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {771–772},
numpages = {2},
keywords = {artificial intelligence, generative AI, large language models, pedagogical practices, teaching computing},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3597503.3623345,
author = {Steenhoek, Benjamin and Gao, Hongyang and Le, Wei},
title = {Dataflow Analysis-Inspired Deep Learning for Efficient Vulnerability Detection},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623345},
doi = {10.1145/3597503.3623345},
abstract = {Deep learning-based vulnerability detection has shown great performance and, in some studies, outperformed static analysis tools. However, the highest-performing approaches use token-based transformer models, which are not the most efficient to capture code semantics required for vulnerability detection. Classical program analysis techniques such as dataflow analysis can detect many types of bugs based on their root causes. In this paper, we propose to combine such causal-based vulnerability detection algorithms with deep learning, aiming to achieve more efficient and effective vulnerability detection. Specifically, we designed DeepDFA, a dataflow analysis-inspired graph learning framework and an embedding technique that enables graph learning to simulate dataflow computation. We show that DeepDFA is both performant and efficient. DeepDFA outperformed all non-transformer baselines. It was trained in 9 minutes, 75x faster than the highest-performing baseline model. When using only 50+ vulnerable and several hundreds of total examples as training data, the model retained the same performance as 100% of the dataset. DeepDFA also generalized to real-world vulnerabilities in DbgBench; it detected 8.7 out of 17 vulnerabilities on average across folds and was able to distinguish between patched and buggy versions, while the highest-performing baseline models did not detect any vulnerabilities. By combining DeepDFA with a large language model, we surpassed the state-of-the-art vulnerability detection performance on the Big-Vul dataset with 96.46 F1 score, 97.82 precision, and 95.14 recall. Our replication package is located at https://doi.org/10.6084/m9.figshare.21225413.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {16},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3649217.3653602,
author = {Mahon, Joyce and Mac Namee, Brian and Becker, Brett A.},
title = {Guidelines for the Evolving Role of Generative AI in Introductory Programming Based on Emerging Practice},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653602},
doi = {10.1145/3649217.3653602},
abstract = {In the rapidly evolving Generative AI (GenAI) landscape, source code and natural language are being mixed and used in new ways. This presents opportunities for rethinking teaching practice in Introductory Programming (CS1) courses that includes, but goes beyond, assessment. In this paper we examine the reasons why and how instructors who are early adopters of GenAI are using it in their teaching, and why others are not. We also explore the changes and adaptations that are currently being made to practice. This is achieved by synthesizing insights from several recent studies that have collected primary data from introductory programming instructors who are teaching with, considering teaching with, or actively not teaching with GenAI.Due to the fast pace of GenAI development and adoption, the fixed-pace and cyclical nature of education, and the relatively slow pace of research (including ethical approvals) and publication cycles, research with primary data from instructors is only being published relatively recently. In computing education, there is not yet enough published research with primary data from CS1 instructors to warrant a systematic literature review, although in the next year this will likely be possible. Based on an analysis of the nascent research that has been published, we propose emerging and flexible guidelines on how CS1 instructors could adapt their practice based on what others have done so far. These guidelines highlight important factors to consider when integrating GenAI in CS1 courses, which for many is only beginning.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {10–16},
numpages = {7},
keywords = {CS1, LLM, artificial intelligence, automated/assisted code generation, chatgpt, computing education, copilot, generative AI, introductory programming, k-12, large language model, machine learning, novice programmer, school},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3643916.3644434,
author = {Li, Jiliang and Zhang, Yifan and Karas, Zachary and McMillan, Collin and Leach, Kevin and Huang, Yu},
title = {Do Machines and Humans Focus on Similar Code? Exploring Explainability of Large Language Models in Code Summarization},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644434},
doi = {10.1145/3643916.3644434},
abstract = {Recent language models have demonstrated proficiency in summarizing source code. However, as in many other domains of machine learning, language models of code lack sufficient explainability --- informally, we lack a formulaic or intuitive understanding of what and how models learn from code. Explainability of language models can be partially provided if, as the models learn to produce higher-quality code summaries, they also align in deeming the same code parts important as those identified by human programmers. In this paper, we report negative results from our investigation of explainability of language models in code summarization through the lens of human comprehension. We measure human focus on code using eye-tracking metrics such as fixation counts and duration in code summarization tasks. To approximate language model focus, we employ a state-of-the-art model-agnostic, black-box, perturbation-based approach, SHAP (SHapley Additive exPlanations), to identify which code tokens influence that generation of summaries. Using these settings, we find no statistically significant relationship between language models' focus and human programmers' attention. Furthermore, alignment between model and human foci in this setting does not seem to dictate the quality of the LLM-generated summaries. Our study highlights an inability to align human focus with SHAP-based model focus measures. This result calls for future investigation of multiple open questions for explainable language models for code summarization and software engineering tasks in general, including the training mechanisms of language models for code, whether there is an alignment between human and model attention on code, whether human attention can improve the development of language models, and what other model focus measures are appropriate for improving explainability.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {47–51},
numpages = {5},
keywords = {neural code summarization, language models, explainable AI, SHAP, human attention, eye-tracking},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3626253.3635595,
author = {Hamerski, Patti C.},
title = {Generative AI as a Resource for Creativity in Computational Physics},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635595},
doi = {10.1145/3626253.3635595},
abstract = {Generative artificial intelligence (gen-AI) has become ubiquitous in daily life, including classroom environments where students are using it to assist them on their coursework. Given the widespread use of this tool and the lack of knowledge over how it can support learning, there is a need for educators to have a framework for using it in the classroom and teaching their students usage strategies that are beneficial for learning. One pathway forward is through creativity, a process crucial for learning and also connected to the act of using gen-AI. This poster demonstrates the results of a study designed to provide an in-depth view on how creativity intersects with gen-AI usage in a computational physics course. In the course, students learn about computing tools during group-based, open-ended computational physics activities. Students are often tasked with using gen-AI to explore and help make decisions. The findings demonstrate a connection between using gen-AI and engaging in creative processes, and the implications point to strategies for supporting student usage of gen-AI.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1666–1667},
numpages = {2},
keywords = {computational science, creativity, curriculum design, generative ai},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3722237.3722258,
author = {Fang, Wenjie and Luo, Bin},
title = {Application and Impact of Generative Artificial Intelligence Techniques in Education--Citespace-based visualization and analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722258},
doi = {10.1145/3722237.3722258},
abstract = {Recently, generative AI technology has arisen as a trending research agenda in education.  This study makes an review of 260 documents from the CNKI database published from 2020 to 2024. Through the bibliometric and content analysis methods, together with the CiteSpace tool, highlight the trending application of this technology in education, the distribution characteristics of the core authors and institutions' postings, and the clustering analysis of the research hotspots. The results show continued wide adoption of generative AI technology in education in recent years, peaking sharply in 2023. There hasn't been a stable core group of authors within the field, and the collaborative network is relatively sparse. Research hotspots mainly cover artificial intelligence, human-computer collaboration and educational transformation, which indicates the function generative AI technology could have within the digital transformation and quality enhancement of education. This paper additionally shows the actualization of generative AI technology through its presentation of AI tutors and teaching assistants, teaching models reform, and reshaped instructional evaluation systems via case studies. In face of misuse, integrity issues, and ethical concerns arising, there is a need to find a balance in the application of the technology, such that its more proper development can promote rather than replace human subjectivity.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {117–122},
numpages = {6},
keywords = {CiteCpace visual analytic, Educational Application, Generative AI, Human-computer collaboration},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3613424.3614263,
author = {Fan, Hongxiang and Venieris, Stylianos I. and Kouris, Alexandros and Lane, Nicholas},
title = {Sparse-DySta: Sparsity-Aware Dynamic and Static Scheduling for Sparse Multi-DNN Workloads},
year = {2023},
isbn = {9798400703294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613424.3614263},
doi = {10.1145/3613424.3614263},
abstract = {Running multiple deep neural networks (DNNs) in parallel has become an emerging workload in both edge devices, such as mobile phones where multiple tasks serve a single user for daily activities, and data centers, where various requests are raised from millions of users, as seen with large language models. To reduce the costly computational and memory requirements of these workloads, various efficient sparsification approaches have been introduced, resulting in widespread sparsity across different types of DNN models. In this context, there is an emerging need for scheduling sparse multi-DNN workloads, a problem that is largely unexplored in previous literature. This paper systematically analyses the use-cases of multiple sparse DNNs and investigates the opportunities for optimizations. Based on these findings, we propose Dysta, a novel bi-level dynamic and static scheduler that utilizes both static sparsity patterns and dynamic sparsity information for the sparse multi-DNN scheduling. Both static and dynamic components of Dysta are jointly designed at the software and hardware levels, respectively, to improve and refine the scheduling approach. To facilitate future progress in the study of this class of workloads, we construct a public benchmark that contains sparse multi-DNN workloads across different deployment scenarios, spanning from mobile phones and AR/VR wearables to data centers. A comprehensive evaluation on the sparse multi-DNN benchmark demonstrates that our proposed approach outperforms the state-of-the-art methods with up to 10% decrease in latency constraint violation rate and nearly 4 \texttimes{} reduction in average normalized turnaround time. Our artifacts and code are publicly available at: https://github.com/SamsungLabs/Sparse-Multi-DNN-Scheduling.},
booktitle = {Proceedings of the 56th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {353–366},
numpages = {14},
keywords = {Sparse Multi-DNN Scheduling, Dynamic and Static Approach, Algorithm and Hardware Co-Design},
location = {Toronto, ON, Canada},
series = {MICRO '23}
}

@inproceedings{10.1145/3649217.3653596,
author = {Apiola, Mikko and Vartiainen, Henriikka and Tedre, Matti},
title = {First Year CS Students Exploring And Identifying Biases and Social Injustices in Text-to-Image Generative AI},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653596},
doi = {10.1145/3649217.3653596},
abstract = {Generative AI is a recent breakthrough in AI. While it has become a hot topic in computing education research (CER), much of the recent research has focused on e.g. issues of plagiarism or academic integrity. One problem spot with Generative AI is its susceptibility to various kinds of algorithmic bias. In this study, we collected data from an introductory computing course, where students experimented with text-to-image generative models and reflected on their generated image sets, in terms of biases, related harms, and possible fixes. Data were collected in Fall 2023 (pilot data in Fall 2022). Data included reports from 163 students. The results show (1) a variety of bias types observed by students related to gender, ethnicity, age, as well as a variety of bias types not observed by students, (2) two major types of attributions for the source of bias: bias caused by biases in the society and bias caused by data or algorithms, and (3) a number of potential harms associated with the biases, as well as attributions of those harms in specific contexts and use cases.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {485–491},
numpages = {7},
keywords = {bias, critical computing education, generative ai, social injustice},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626252.3630761,
author = {Mason, Raina and Simon and Becker, Brett A. and Crick, Tom and Davenport, James H.},
title = {A Global Survey of Introductory Programming Courses},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630761},
doi = {10.1145/3626252.3630761},
abstract = {We present results of an in-depth survey of nearly 100 introductory programming (CS1) instructors in 18 countries spanning six continents. Although CS1 is well studied, relatively few broadly-scoped studies have been conducted, and none prior have exceeded regional scale. In addition, CS1 is a notoriously fickle and often changing course, and many might find it beneficial to know what other instructors are doing across the globe; perhaps more so as we continue to understand the impact of the COVID-19 pandemic on computing education and as the effects of Generative AI take hold. Expanding upon several surveys conducted in Australasia, the UK, and Ireland, this survey facilitates a direct comparison of global trends in CS1. The survey goes beyond environmental factors such as languages used, and examines why CS1 instructors teach what they do, in the ways they do. In total the survey spans 84 institutions and 91 courses in which a total of over 40,000 students are enrolled.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {799–805},
numpages = {7},
keywords = {covid-19, cs 1, cs-1, cs1, global, instructors, introductory programming, novice programmers, programming languages, survey, teaching languages},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626772.3657816,
author = {Zivic, Pablo and Vazquez, Hernan and S\'{a}nchez, Jorge},
title = {Scaling Sequential Recommendation Models with Transformers},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657816},
doi = {10.1145/3626772.3657816},
abstract = {Modeling user preferences has been mainly addressed by looking at users' interaction history with the different elements available in the system. Tailoring content to individual preferences based on historical data is the main goal of sequential recommendation. The nature of the problem, as well as the good performance observed across various domains, has motivated the use of the transformer architecture, which has proven effective in leveraging increasingly larger amounts of training data when accompanied by an increase in the number of model parameters. This scaling behavior has brought a great deal of attention, as it provides valuable guidance in the design and training of even larger models. Taking inspiration from the scaling laws observed in training large language models, we explore similar principles for sequential recommendation. Addressing scalability in this context requires special considerations as some particularities of the problem depart from the language modeling case. These particularities originate in the nature of the content catalogs, which are significantly larger than the vocabularies used for language and might change over time. In our case, we start from a well-known transformer-based model from the literature and make two crucial modifications. First, we pivot from the traditional representation of catalog items as trainable embeddings to representations computed with a trainable feature extractor, making the parameter count independent of the number of items in the catalog. Second, we propose a contrastive learning formulation that provides us with a better representation of the catalog diversity. We demonstrate that, under this setting, we can train our models effectively on increasingly larger datasets under a common experimental setup. We use the full Amazon Product Data dataset, which has only been partially explored in other studies, and reveal scaling behaviors similar to those found in language models. Compute-optimal training is possible but requires a careful analysis of the compute-performance trade-offs specific to the application. We also show that performance scaling translates to downstream tasks by fine-tuning larger pre-trained models on smaller task-specific domains. Our approach and findings provide a strategic roadmap for model training and deployment in real high-dimensional preference spaces, facilitating better training and inference efficiency. We hope this paper bridges the gap between the potential of transformers and the intrinsic complexities of high-dimensional sequential recommendation in real-world recommender systems. Code and models can be found at https://github.com/mercadolibre/srt.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1567–1577},
numpages = {11},
keywords = {scaling laws, sequential recommendation, transfer learning, transformers},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3675812.3675843,
author = {Zhang, Wenting and Zhang, Qiaorong and Cai, Mingming and Wang, Dongqing and Zheng, Yafeng},
title = {Navigating the Application Challenges of ChatGPT in Education: Promoting Responsible Use and Minimizing Mental Risks},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675843},
doi = {10.1145/3675812.3675843},
abstract = {With the wide application of artificial intelligence, especially generative AI like ChatGPT, the era of significant transformation in education has quietly arrived. This article first explores the current applications of ChatGPT in logical learning, language learning, as well as personalized and effective teaching. It then deeply analyzes the challenges brought by the application of ChatGPT in education from three aspects: digital ethics, psychological risks for teachers and students, and educational governance. Based on its potential risks and challenges, effective measures and suggestions are proposed, including improving information literacy education, fully utilizing human-computer collaboration, and establishing clear regulations for the use of ChatGPT. These measures aim to ensure that ChatGPT can maximize its application value in the field of education while minimizing the mental risks.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {23–28},
numpages = {6},
keywords = {Application Challenges, ChatGPT, Mental Risks},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@article{10.1145/3591300,
author = {Beurer-Kellner, Luca and Fischer, Marc and Vechev, Martin},
title = {Prompting Is Programming: A Query Language for Large Language Models},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {PLDI},
url = {https://doi.org/10.1145/3591300},
doi = {10.1145/3591300},
abstract = {Large language models have demonstrated outstanding performance on a wide range of tasks such as question answering and code generation.  
On a high level, given an input, a language model can be used to automatically complete the sequence in a statistically-likely way. Based on this, users prompt these models with language instructions or examples, to implement a variety of downstream tasks. Advanced prompting methods can even imply interaction between the language model, a user, and external tools such as calculators. However, to obtain state-of-the-art performance or adapt language models for specific tasks, complex task- and model-specific programs have to be implemented, which may still require ad-hoc interaction.  

Based on this, we present the novel idea of Language Model Programming (LMP). LMP generalizes language model prompting from pure text prompts to an intuitive combination of text prompting and scripting. Additionally, LMP allows constraints to be specified over the language model output. This enables easy adaption to many tasks while abstracting language model internals and providing high-level semantics.  

To enable LMP, we implement LMQL (short for Language Model Query Language), which leverages the constraints and control flow from an LMP prompt to generate an efficient inference procedure that minimizes the number of expensive calls to the underlying language model.  

We show that LMQL can capture a wide range of state-of-the-art prompting methods in an intuitive way, especially facilitating interactive flows that are challenging to implement with existing high-level APIs. Our evaluation shows that we retain or increase the accuracy on several downstream tasks, while also significantly reducing the required amount of computation or cost in the case of pay-to-use APIs (26-85% cost savings).},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {186},
numpages = {24},
keywords = {prompt programming, language model programming}
}

@inproceedings{10.1145/3626253.3631657,
author = {Akram, Bita and Leinonen, Juho and Norouzi, Narges and Prather, James and Zhang, Lisa},
title = {AI in Computing Education from Research to Practice},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3631657},
doi = {10.1145/3626253.3631657},
abstract = {The panel comprises a diverse set of Computing educators working on AI in education. The panelists will address four areas of AI in Computing education: 1) AI for introductory CS classrooms, 2) Investigating opportunities presented by LLMs, 3) LLM-based tool development, and 4) Ethics and inclusion in AI curriculum. The panel will share experiences and discuss opportunities and challenges in AI education with the community.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1521–1522},
numpages = {2},
keywords = {artificial intelligence, computing education, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3540250.3549162,
author = {Chakraborty, Saikat and Ahmed, Toufique and Ding, Yangruibo and Devanbu, Premkumar T. and Ray, Baishakhi},
title = {NatGen: generative pre-training by “naturalizing” source code},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3549162},
doi = {10.1145/3540250.3549162},
abstract = {Pre-trained Generative Language models (e.g., PLBART, CodeT5, SPT-Code) for source code yielded strong results on several tasks in the past few years, including code generation and translation. These models have adopted varying pre-training objectives to learn statistics of code construction from very large-scale corpora in a self-supervised fashion; the success of pre-trained models largely hinges on these pre-training objectives. This paper proposes a new pre-training objective, “Naturalizing” of source code, exploiting code’s bimodal, dual-channel (formal &amp; natural channels) nature. Unlike natural language, code’s bimodal, dual-channel nature allows us to generate semantically equivalent code at scale. We introduce six classes of semantic preserving transformations to introduce unnatural forms of code, and then force our model to produce more natural original programs written by developers. Learning to generate equivalent, but more natural code, at scale, over large corpora of open-source code, without explicit manual supervision, helps the model learn to both ingest &amp; generate code. We fine-tune our model in three generative Software Engineering tasks: code generation, code translation, and code refinement with limited human-curated labeled data and achieve state-of-the-art performance rivaling CodeT5. We show that our pre-trained model is especially competitive at zero-shot and few-shot learning, and better at learning code properties (e.g., syntax, data flow)},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {18–30},
numpages = {13},
keywords = {Source Code Transformer, Source Code Pre-training, Semantic Preserving Transformation, Neural Network},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3587102.3588773,
author = {Denny, Paul and Becker, Brett A. and Leinonen, Juho and Prather, James},
title = {Chat Overflow: Artificially Intelligent Models for Computing Education - renAIssance or apocAIypse?},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588773},
doi = {10.1145/3587102.3588773},
abstract = {Recent breakthroughs in deep learning have led to the emergence of generative AI models that exhibit extraordinary performance at producing human-like outputs. Using only simple input prompts, it is possible to generate novel text, images, video, music, and source code, as well as tackle tasks such as answering questions and translating and summarising text.However, the potential for these models to impact computing education practice is only just beginning to be explored. For example, novices learning to code can now use free tools that automatically suggest solutions to programming exercises and assignments; yet these tools were not designed with novices in mind and little to nothing is known about how they will impact learning. Furthermore, much attention has focused on the immediate challenges these models present, such as academic integrity concerns. It seems that even in the AI-era a pending apocalypse sells better than a promising renaissance.Generative AI will likely play an increasing role in people's lives in the reasonably foreseeable future. Model performance seems set to continue accelerating while novel uses and new possibilities multiply. Given this, we should devote just as much effort to identifying and exploiting new opportunities as we do to identifying and mitigating challenges.In this talk, we begin by discussing several concrete and research-backed opportunities for computing educators. Many of these have already shown great promise in positively impacting current practice. We then discuss more short- to medium-term possibilities in areas such as student recruitment, and curricular changes. Finally - against our better judgement - we speculate over the longer-term, including rethinking the very fundamentals of the practice of teaching introductory and advanced computing courses. In these discussions we suggest potential research questions and directions. Although making remotely accurate predictions in such a fast-changing landscape is foolhardy, we believe that now is the time to explore and embrace opportunities to help make positive change in as many computing classrooms as possible.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {3–4},
numpages = {2},
keywords = {ai, artificial intelligence, chatgpt, computer programming, computer science education, computing education, copilot, deep learning, generative ai, large language models, llm, machine learning},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3689535.3689538,
author = {Sentance, Sue and Watson, Steven and Addo, Salomey Afua and Shi, Shengpeng and Waite, Jane and Yu, Bo},
title = {Developing Computing Teacher Guidance on GenAI},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689538},
doi = {10.1145/3689535.3689538},
abstract = {Generative AI (GenAI) is becoming widely available for use in schools by teachers and students. While many educators appreciate the potential benefits of GenAI for enhancing learning, there are also significant concerns about authorship, authenticity, plagiarism, ethics, biases, and the broader implications of their use in education. For computing teachers in schools, these issues can be even more acute. In this project, we established a working group of practising computing teachers to bring together a range of views and experiences. Initial results of the project led to a booklet for computing teachers on how to use GenAI, illustrating the effectiveness of teacher-researcher partnerships in developing resources for school use. This project will be followed by further work on computing teachers’ actual experience of GenAI in practice.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {12},
numpages = {1},
keywords = {AI education, K-12 education, generative AI, teachers},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3689535.3689543,
author = {Addo, Salomey Afua and Sentance, Sue},
title = {Exploring Computing Teachers' Readiness to Teach AI in Secondary Schools},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689543},
doi = {10.1145/3689535.3689543},
abstract = {Artificial intelligence (AI) is significantly impacting how we live, and the increased capabilities of generative AI applications have positioned AI firmly in the public domain. There is a growing interest in what AI might look like as a subject within the K-12 curriculum, whilst research on teachers’ readiness for teaching AI is as yet limited. This paper describes a qualitative study investigating teachers’ readiness to teach AI in secondary education. The interview study involved eight computing teachers with varying teaching experiences. We used reflexive thematic analysis for themes development. Findings suggest several indicators of teachers’ readiness, including attitudes, prior AI experience, professional development, and access to quality resources. This paper contributes to ongoing debates about how to best support teachers to be ready to teach AI effectively at the school level.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {17},
numpages = {1},
keywords = {K-12 education, artificial intelligence, computing education, teacher readiness},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@article{10.5555/3715622.3715633,
author = {Zuo, Fei and Tompkins, Cody and Qian, Gang and Rhee, Junghwan and Qu, Xianshan and Yang, Bokai},
title = {ChatGPT as an Assembly Language Interpreter for Computing Education},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {2},
issn = {1937-4771},
abstract = {Assembly language is a low-level programming language useful for a number of important computing areas, such as hardware and embedded systems programming, computer architecture, reverse engineering, and malware analysis. In recent years, generative AI, enhanced by GPT technology, has been widely adopted in the IT industry as well as computing education. However, little work has been done to investigate the applicability of GPT to teaching assembly language. In this paper, we fill in the gap by providing an empirical study of GPT's ability to interpret assembly instructions. In particular, we manually evaluated GPT-4's per-instruction explanations of code segments for four different computer architectures, namely x86, x86-64, ARM, and AArch64. Our study shows that, while inconsistencies and rare errors do exist, GPT's interpretations are highly accurate in general, demonstrating a great potential for such tools to be applied in pedagogical practices for tutoring assembly language.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {73–82},
numpages = {10}
}

@article{10.5555/3729849.3729853,
author = {Garcia, Yuan and Ngo, Jenny and Lin, Florence Rui and Dodds, Zachary},
title = {Adaptable Metrics to Inform Introductory CS},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {9},
issn = {1937-4771},
abstract = {Metrics have long been used to assess and guide successful software projects. Traditionally these metrics have measured software's professional rather than its educational suitability. This work proposes six adaptable, reproducible pedagogical metrics. With these metrics, we track an Introductory CS course's capstone projects, 2018--2024. The results suggest both year-over-year evolution and a more sudden, LLM-correlated impact on students' relationship with their early computing work. We have begun adapting our curriculum to these signals, and we foresee future refinements and broader applications to metrics-based reproducible curricular assessment.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {34–42},
numpages = {9}
}

@inproceedings{10.1145/3583780.3615506,
author = {Maiorino, Antonio and Padgett, Zoe and Wang, Chun and Yakubovskiy, Misha and Jiang, Peng},
title = {Application and Evaluation of Large Language Models for the Generation of Survey Questions},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615506},
doi = {10.1145/3583780.3615506},
abstract = {Generative Language Models have shown promising results in various domains, and some of the most successful applications are related to "concept expansion", which is the task of generating extensive text based on concise instructions provided through a "seed" prompt. In this presentation we will discuss the recent work conducted by the Data Science team at SurveyMonkey, where we have recently introduced a new feature that harnesses Generative AI models to streamline the survey design process. With this feature users can effortlessly initiate this process by specifying their desired objectives through a prompt, allowing them to automate the creation of surveys that include the critical aspects they wish to investigate.We will share our findings regarding some of the challenges encountered during the development of this feature. These include techniques for conditioning the model outputs, integrating generated text with industry-standard questions, fine-tuning Language Models using semi-synthetic Data Generation techniques, and more. Moreover, we will showcase the Evaluation Methodology that we have developed to measure the quality of the generated surveys across several dimensions. This evaluation process is crucial in ensuring that the generated surveys align well with user expectations and serve their intended purpose effectively. Our goal is to demonstrate the promising potential of Generative Language Models in the context of Survey Research, and we believe that sharing our learnings on these challenges and how we addressed them will be useful for practitioners working with Language Models on similar problems.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {5244–5245},
numpages = {2},
keywords = {text evaluation, survey research, generative AI},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3638067.3638100,
author = {Freire, Andr\'{e} Pimenta and Cardoso, Paula Christina Figueira and Salgado, Andr\'{e} de Lima},
title = {May We Consult ChatGPT in Our Human-Computer Interaction Written Exam? An Experience Report After a Professor Answered Yes},
year = {2024},
isbn = {9798400717154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638067.3638100},
doi = {10.1145/3638067.3638100},
abstract = {Using ChatGPT in education presents challenges for evaluating students. It requires distinguishing between original ideas and those generated by the model, assessing critical thinking skills, and gauging subject mastery accurately, which can impact fair assessment practices. The Human-Computer Interaction course described in this experience report has enabled consultation with textbooks, slides and other materials for over five years. This experience report describes reflections regarding using ChatGPT as a source of consultation in a written HCI exam in 2023. The paper describes experiences with analysis of the types of questions ChatGPT was able to solve immediately without mediation and the types of questions that could benefit from ChatGPT’s assistance without compromising the assessment of higher-level learning outcomes that professors want to analyse in teaching HCI. The paper uses Bloom’s taxonomy to analyse different questions and abilities to be evaluated and how they can be solved solely by using ChatGPT. The paper discusses questions that need mediation, previous lived experience in class and understanding of the knowledge acquired in class that cannot be answered directly by copying and pasting questions into ChatGPT. The discussions can raise reflections on the learning outcomes that can be assessed in HCI written exams and how professors should reflect upon their experiences and expectations for exams in the age of growing generative artificial intelligence resources.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {6},
numpages = {11},
keywords = {ChatGPT, HCI education, evaluation, open-book exams},
location = {Macei\'{o}, Brazil},
series = {IHC '23}
}

@inproceedings{10.1145/3641554.3701806,
author = {Kannam, Suhas and Yang, Yuri and Dharm, Aarya and Lin, Kevin},
title = {Code Interviews: Design and Evaluation of a More Authentic Assessment for Introductory Programming Assignments},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701806},
doi = {10.1145/3641554.3701806},
abstract = {Generative artificial intelligence poses new challenges around assessment, increasingly driving introductory programming educators to employ invigilated exams. But exams do not afford more authentic programming experiences that involve planning, implementing, and debugging programs with computer interaction. In this experience report, we describe code interviews: a more authentic assessment method for take-home programming assignments. Through action research, we experimented with the number and type of questions as well as whether interviews were conducted individually or with groups of students. To scale the program, we converted most of our weekly teaching assistant (TA) sections to conduct code interviews on 5 major weekly take-home programming assignments. By triangulating data from 5 sources, we identified 4 themes. Code interviews (1) pushed students to discuss their work, motivating more nuanced but sometimes repetitive insights; (2) enabled peer learning, reducing stress in some ways but increasing stress in other ways; (3) scaled with TA-led sections, replacing familiar practice with an unfamiliar assessment; (4) focused on student contributions, limiting opportunities for TAs to give guidance and feedback. We reflect on the design of code interviews for student experience, academic integrity, and teacher workload.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {554–560},
numpages = {7},
keywords = {authentic assessment, introductory programming, oral exams},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3708394.3708455,
author = {Lv, Jiayan and Yao, Jinfang and Zhu, He},
title = {Research on the Cultivation of Teacher Candidates from the Perspective of AI Empowerment with Sentiment analysis},
year = {2025},
isbn = {9798400710650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708394.3708455},
doi = {10.1145/3708394.3708455},
abstract = {Over the past decade, with the advancement of technology, chatbots have become a hotspot in the field of artificial intelligence (AI) and are widely used in consumer services, education, search engines, marketing, and other fields. Among them, the Chat Generative Pre-Trained Transformer (ChatGPT), composed of language models and optimization techniques, is leading a transformation in human-computer interaction methods. This study selects the social media platforms "REDnote" and "Weibo" as the research field to explore the role and impact of ChatGPT in education and industry ecosystems. This work examines public sentiment regarding the application of AI in educational ecosystems and talent development by analyzing social media discussions. The sentiment analysis conducted using advanced machine learning models, highlights the prevalence of positive emotions toward ChatGPT's role in enhancing teaching and learning experiences. Furthermore, this study introduces an AI-based dynamic talent cultivation model, rooted in the "3H" (Head, Hand, Heart) framework, which emphasizes cognitive skills, practical capabilities, and emotional intelligence.},
booktitle = {Proceeding of the 2024 International Conference on Artificial Intelligence and Future Education},
pages = {358–364},
numpages = {7},
keywords = {Artificial Intelligence, ChatGPT, Deep Learning, Machine Learning, Normal Education, Social Media, Talent Cultivation, User Experience},
location = {
},
series = {AIFE '24}
}

@proceedings{10.1145/3680256,
title = {ICPE '25: Companion of the 16th ACM/SPEC International Conference on Performance Engineering},
year = {2025},
isbn = {9798400711305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 16th ACM/SPEC International Conference of Performance Engineering (ICPE), held in Toronto, Canada, from May 5, 2025, to May 9, 2025. ICPE serves as the premier global forum for showcasing and discussing new concepts, innovations, trends, and experiences in performance engineering.On May 5 and 6, the first two days of the conference, we scheduled five workshops and two tutorials. The workshops cover important topics in performance engineering today. These include cloud computing (HotCloudPerf 2025) and its benchmarking (BID 2025), the benchmarking and load testing of software systems (LTB 2025), performance engineering in the Large Language Models (AIPerfLLM 2025), and the application of performance engineering in both educational and practical contexts (WEPPE 2025). We thank the workshop chairs, Luca Trani and Marios Fokaefs, for arranging a great workshop agenda. On May 5, we have a tutorial on serverless computing entitled "Serverless Orchestration on the Edge-Cloud Continuum: Challenges and Solutions," authored by Reza Farahing and Radu Prodan, while May 6 is dedicated to energy-efficiency benchmarking with the tutorial conducted by Maximilian Meissner, Klaus-Dieter Lange, Aaron Cragin, and Diego Esteves, called "Next Generation Energy-Efficiency Benchmarking - Reliable and Reproducible Efficiency Testing in a Diverse IT-Landscape" and to a hands-on session with the Kieker 2 Observability Framework, authored by Shinhyung Yang, David Georg Reichelt, Reiner Jung, Marcel Hansson, and Wilhelm Hasselbring. We express our gratitude to the tutorial chairs, Vittoria de Nitto Person\`{e} and Cristina Abad, for organizing such engaging tutorial session.The main conference occurs from May 7 to May 9, with each day starting with a keynote that we are excited to welcome. Lizy John opens May 7 from the University of Texas (USA), who shares insights on AI for Performance Engineering and Performance Engineering for AI, while we host Ahmed Hassan from Queen's University (Canada) on May 8, who emphasizes the importance of software performance engineering on Foundation Models. Marc Brooker from AWS, USA, presents different approaches to performance engineering during bad times, such as during and after overload and failures.The program features many research presentations spanning various tracks, including Research, Industry, Emerging Research, Artifacts, Data Challenges, Posters, and Demos. The Research track features 24 presentations, while the Industry track, chaired by Lishan Yang and Alex Podelko (a big thank you to both of them!), includes eight papers. This year, the main conference is enriched by five presentations from the Industry Presentation Track, a showcase for industrial contributors to share their insights and experiences on performance engineering.We accepted 3 submissions in the Emerging Research track and 2 papers in the Artifact Evaluation, Data Challenge, Poster and Demo tracks, respectively. Thank you, Ana Lucia Varbanescu and Y.C. Tay, for your invaluable expertise in guiding the Emerging Research track. We appreciate the meticulous work of Nikolas Herbst and S\"{o}ren Henning to ensure the quality and rigor of the contributions to the Artifact Evaluation track, as well as the efforts of Emilio Incerto for the Poster and Demo track, and Andr\'{e} Bauer and Naser Ezzati-Jivan for the Data Challenge track. ICPE25 features 3 presentations from the Journal First track, perfectly organized by Raffaela Mirandola and Weiyi (Ian) Shang.This year conference recognizes three of the pioneers of software performance engineering, Connie Smith, Dorina Petriu, Murray Woodside. Thank you Antinisca Di Marco for organizing a panel to hear their views on the past, present and future of software performance.We want to express our gratitude to the rest of the organizing committee for their hard work in organizing this edition of ICPE. Big thanks to our Award Chairs, William Knottenbelt and Diwakar Krishnamurthy, to the Publicity and Social Media Chairs: Alim Gias, Joydeep Mukherjee, Nasim Beigi Mohammadi, and Guocong Quan, and to the Finance and Sponsorship Chairs, Hamzeh Khazaei and Zhen Ming (Jack) Jiang.A special thank you goes to the Local and Social Events and Web Chairs, Hung Viet Pham, Arik Sendorovich, Komal Sarda, and Hamza Hussain. We would also like to thank Zhenhao Li and Vincenzo Stoico for handling the registration and the proceedings of ICPE'25, respectively, with professionalism and care.We are truly grateful to SPEC and ACM, along with SIGSOFT and SIGMETRICS, for their support, as well as York University and Snowflake which support is crucial for the success of ICPE'25.We extend our thanks to all the authors who submitted their papers, as well as the program committees and the additional reviewers who contribute to making ICPE a leading venue for performance engineering. Finally, thank you to all ICPE'25 participants for making this event interactive, engaging, and inspiring for everyone involved. We trust that you will enjoy ICPE'25 and take advantage of the many interaction opportunities in the dedicated physical and virtual space of the conference.},
location = {Toronto ON, Canada}
}

@proceedings{10.1145/3676151,
title = {ICPE '25: Proceedings of the 16th ACM/SPEC International Conference on Performance Engineering},
year = {2025},
isbn = {9798400710735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 16th ACM/SPEC International Conference of Performance Engineering (ICPE), held in Toronto, Canada, from May 5, 2025, to May 9, 2025. ICPE serves as the premier global forum for showcasing and discussing new concepts, innovations, trends, and experiences in performance engineering.On May 5 and 6, the first two days of the conference, we scheduled five workshops and two tutorials. The workshops cover important topics in performance engineering today. These include cloud computing (HotCloudPerf 2025) and its benchmarking (BID 2025), the benchmarking and load testing of software systems (LTB 2025), performance engineering in the Large Language Models (AIPerfLLM 2025), and the application of performance engineering in both educational and practical contexts (WEPPE 2025). We thank the workshop chairs, Luca Trani and Marios Fokaefs, for arranging a great workshop agenda. On May 5, we have a tutorial on serverless computing entitled "Serverless Orchestration on the Edge-Cloud Continuum: Challenges and Solutions," authored by Reza Farahing and Radu Prodan, while May 6 is dedicated to energy-efficiency benchmarking with the tutorial conducted by Maximilian Meissner, Klaus-Dieter Lange, Aaron Cragin, and Diego Esteves, called "Next Generation Energy-Efficiency Benchmarking - Reliable and Reproducible Efficiency Testing in a Diverse IT-Landscape" and to a hands-on session with the Kieker 2 Observability Framework, authored by Shinhyung Yang, David Georg Reichelt, Reiner Jung, Marcel Hansson, and Wilhelm Hasselbring. We express our gratitude to the tutorial chairs, Vittoria de Nitto Person\`{e} and Cristina Abad, for organizing such engaging tutorial session.The main conference occurs from May 7 to May 9, with each day starting with a keynote that we are excited to welcome. Lizy John opens May 7 from the University of Texas (USA), who shares insights on AI for Performance Engineering and Performance Engineering for AI, while we host Ahmed Hassan from Queen's University (Canada) on May 8, who emphasizes the importance of software performance engineering on Foundation Models. Marc Brooker from AWS, USA, presents different approaches to performance engineering during bad times, such as during and after overload and failures.The program features many research presentations spanning various tracks, including Research, Industry, Emerging Research, Artifacts, Data Challenges, Posters, and Demos. The Research track features 24 presentations, while the Industry track, chaired by Lishan Yang and Alex Podelko (a big thank you to both of them!), includes eight papers. This year, the main conference is enriched by five presentations from the Industry Presentation Track, a showcase for industrial contributors to share their insights and experiences on performance engineering.We accepted 3 submissions in the Emerging Research track and 2 papers in the Artifact Evaluation, Data Challenge, Poster and Demo tracks, respectively. Thank you, Ana Lucia Varbanescu and Y.C. Tay, for your invaluable expertise in guiding the Emerging Research track. We appreciate the meticulous work of Nikolas Herbst and S\"{o}ren Henning to ensure the quality and rigor of the contributions to the Artifact Evaluation track, as well as the efforts of Emilio Incerto for the Poster and Demo track, and Andr\'{e} Bauer and Naser Ezzati-Jivan for the Data Challenge track. ICPE25 features 3 presentations from the Journal First track, perfectly organized by Raffaela Mirandola and Weiyi (Ian) Shang.This year conference recognizes three of the pioneers of software performance engineering, Connie Smith, Dorina Petriu, Murray Woodside. Thank you Antinisca Di Marco for organizing a panel to hear their views on the past, present and future of software performance.We want to express our gratitude to the rest of the organizing committee for their hard work in organizing this edition of ICPE. Big thanks to our Award Chairs, William Knottenbelt and Diwakar Krishnamurthy, to the Publicity and Social Media Chairs: Alim Gias, Joydeep Mukherjee, Nasim Beigi Mohammadi, and Guocong Quan, and to the Finance and Sponsorship Chairs, Hamzeh Khazaei and Zhen Ming (Jack) Jiang.A special thank you goes to the Local and Social Events and Web Chairs, Hung Viet Pham, Arik Sendorovich, Komal Sarda, and Hamza Hussain. We would also like to thank Zhenhao Li and Vincenzo Stoico for handling the registration and the proceedings of ICPE'25, respectively, with professionalism and care.We are truly grateful to SPEC and ACM, along with SIGSOFT and SIGMETRICS, for their support, as well as York University and Snowflake which support is crucial for the success of ICPE'25.We extend our thanks to all the authors who submitted their papers, as well as the program committees and the additional reviewers who contribute to making ICPE a leading venue for performance engineering. Finally, thank you to all ICPE'25 participants for making this event interactive, engaging, and inspiring for everyone involved. We trust that you will enjoy ICPE'25 and take advantage of the many interaction opportunities in the dedicated physical and virtual space of the conference.},
location = {Toronto ON, Canada}
}

@inproceedings{10.1145/3678726.3678745,
author = {Wu, Chih-Hung and Liou, Guang-Mei},
title = {ARCS Model for Exploring the Enhancement of Learning Motivation and Engagement through AIGC Technology in Computer Graphics Courses},
year = {2024},
isbn = {9798400717611},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678726.3678745},
doi = {10.1145/3678726.3678745},
abstract = {The purpose of this study is to apply the Keller ARCS Motivation Model theory to the "Computer Graphics" course. In the learning process of computer graphics courses, generating images using generative AI and then modifying them is employed to arouse students' interest and enhance their learning engagement. The aim of this research is to analyze the interest generated by the course through experimental results of curriculum design. Most students show a high level of interest in the integration of generative AI into the course, while a very small minority express dislike for generating images in this manner. The findings confirm that integrating generative AI into computer graphics courses can increase student interest in learning.},
booktitle = {Proceedings of the 2024 8th International Conference on Education and Multimedia Technology},
pages = {51–59},
numpages = {9},
keywords = {AIGC, ARCS, Learning Interest},
location = {Tokyo, Japan},
series = {ICEMT '24}
}

@inproceedings{10.1145/3641555.3705266,
author = {Hou, Irene and Nguyen, Hannah Vy and Man, Owen and MacNeil, Stephen},
title = {The Evolving Usage of GenAI by Computing Students},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705266},
doi = {10.1145/3641555.3705266},
abstract = {Help-seeking is a critical aspect of learning and problem-solving for computing students. Recent research has shown that many students are aware of generative AI (GenAI) tools; however, there are gaps in the extent and effectiveness of how students use them. With over two years of widespread GenAI usage, it is crucial to understand whether students' help-seeking behaviors with these tools have evolved and how. This paper presents findings from a repeated cross-sectional survey conducted among computing students across North American universities ( n=95 ). Our results indicate shifts in GenAI usage patterns. In 2023, 34.1% of students ( n=47 ) reported never using ChatGPT for help, ranking it fourth after online searches, peer support, and class forums. By 2024, this figure dropped sharply to 6.3% ( n=48 ), with ChatGPT nearly matching online search as the most commonly used help resource. Despite this growing prevalence, there has been a decline in students' hourly and daily usage of GenAI tools, which may be attributed to a common tendency to underestimate usage frequency. These findings offer new insights into the evolving role of GenAI in computing education, highlighting its increasing acceptance and solidifying its position as a key help resource.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1481–1482},
numpages = {2},
keywords = {chatgpt, computing education, generative ai, help-seeking},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649409.3691073,
author = {Barendsen, Erik and Lonati, Violetta and Quille, Keith and Altin, Rukiye and Divitini, Monica and Hooshangi, Sara and Karnalim, Oscar and Kiesler, Natalie and Melton, Madison and Suero Montero, Calkin and Morpurgo, Anna},
title = {AI in and for K-12 Informatics Education. Life after Generative AI.},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691073},
doi = {10.1145/3649409.3691073},
abstract = {The use and adoption of Generative AI (GenAI) has revolutionised various sectors, including computing education. However, this narrow focus comes at a cost to the wider AI in and for educational research. This working group aims to explore current trends and explore multiple sources of information to identify areas of AI research in K-12 informatics education that are being underserved but needed in the post-GenAI AI era. Our research focuses on three areas: curriculum, teacher-professional learning and policy. The denouement of this aims to identify trends and shortfalls for AI in and for K-12 informatics education. We will systematically review the current literature to identify themes and emerging trends in AI education at K-12. This will be done under two facets, curricula and teacher-professional learning. In addition, we will conduct interviews and surveys with educators and AI experts. Next, we will examine the current policy (such as the European AI Act, and European Commission guidelines on the use of AI and data in education and training as well as international counterparts). Policies are often developed by both educators and experts in the domain, thus providing a source of topics or areas that may be added to our findings. Finally, by synthesising insights from educators, AI experts, and policymakers, as well as the literature and policy, our working group seeks to highlight possible future trends and shortfalls.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {279–280},
numpages = {2},
keywords = {AI, GenAI, K-12, curricula, generative AI, informatics},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3613905.3647966,
author = {Lim, Jullia},
title = {The Potential of Learning With AI-Generated Pedagogical Agents in Instructional Videos},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3647966},
doi = {10.1145/3613905.3647966},
abstract = {With the recent advancement in technology, generative artificial intelligence (GenAI) can produce hyper-realistic multimedia content, such as audio, text, images, and videos. Although this technology has raised great concerns about its misuse and harmful applications, it holds great potential to revolutionize traditional ways of teaching and learning. The use of GenAI in education has increased markedly, however, pedagogical research on this rapidly emerging technology is yet to be studied extensively. There is an urgent need to investigate the unexamined potential of this technology. Therefore, this ongoing research will explore the potential of AI-generated pedagogical agents (PA), or avatars, in instructional videos to facilitate learning. The effects of the type of PA (AI-generated, real-life human), and voice (AI-generated, human voice) on an individual's learning outcomes, cognitive load, motivation, and attention will be studied. Findings from a pilot study provide some preliminary evidence that PA appearance influences learners’ retention and cognitive load, but not attention. The type of PA influenced learners' perception of the agent's ability to facilitate learning, its human-like qualities, and its engagement level. However, it did not affect its credibility. This ongoing work will contribute to the growing understanding of the impact of AI in education, provide evidence of the efficacy of AI-generated PAs in instructional videos for learning, and narrow the gap between human-computer interaction research and education.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {615},
numpages = {6},
keywords = {avatars, multimedia learning, pedagogical agents, videos},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@article{10.5555/3636988.3636989,
author = {Conrad, Susan and Dimitoglou, George and Flinn, Michael B. and Morgan, Jacob and Gupta, Pranshu and Mengistu, Zelalem},
title = {Current Challenges in Computing Education},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {3},
issn = {1937-4771},
abstract = {Discussion about topics related to current issues in computing science education focusing on three themes: "That AI thing...", "Post-Pandemic Strategies," and "Partnerships."The first theme attempts to address the benefits, challenges, and practical applications of integrating Generative AI technologies, such as ChatGPT, Bard, and CoPilot, into educational settings. Exploration of academic honesty and intellectual property and strategies for how these AI tools can be utilized in classrooms, labs, student projects, assignments, academic programs, and even preparing students for future job opportunities.The second theme revolves around post-pandemic approaches and initiatives to explore aimed at re-engaging students in both classroom activities and extracurricular pursuits. Exploration of strategies to enhance undergraduate and graduate student participation in internships, research opportunities, and the unique challenges and characteristics of job hunting in the current educational and economic landscape.The third theme highlights the significance of forging partnerships between educational institutions and industry stakeholders. Exploring campus ideas and efforts to establish and strengthen relationships with industry partners. Discussion on collaborative projects, research initiatives, mentorship programs, and ways to bridge the gap between academia and industry to benefit both students and the workforce.The final theme is open-ended, encouraging attendees to contemplate additional questions that may initiate reflection on emerging trends, pedagogical challenges, technological advancements, and any other critical issues that computing science educators should address to stay effective and responsive in their roles.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {16–17},
numpages = {2}
}

@inproceedings{10.1145/3716640.3716649,
author = {Prather, James and Reeves, Brent N and Denny, Paul and Leinonen, Juho and MacNeil, Stephen and Luxton-Reilly, Andrew and Orvalho, Jo\~{a}o and Alipour, Amin and Alfageeh, Ali and Amarouche, Thezyrie and Kimmel, Bailey and Wright, Jared and Blake, Musa and Barbre, Gweneth},
title = {Breaking the Programming Language Barrier: Multilingual Prompting to Empower Non-Native English Learners},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716649},
doi = {10.1145/3716640.3716649},
abstract = {Non-native English speakers (NNES) face multiple barriers to learning programming. These barriers can be obvious, such as the fact that programming language syntax and instruction are often in English, or more subtle, such as being afraid to ask for help in a classroom full of native English speakers. However, these barriers are frustrating because many NNES students know more about programming than they can articulate in English. Advances in generative AI (GenAI) have the potential to break down these barriers because state of the art models can support interactions in multiple languages. Moreover, recent work has shown that GenAI can be highly accurate at code generation and explanation. In this paper, we provide the first exploration of NNES students prompting in their native languages (Arabic, Chinese, and Portuguese) to generate code to solve programming problems. Our results show that students are able to successfully use their native language to solve programming problems, but not without some difficulty specifying programming terminology and concepts. We discuss the challenges they faced, the implications for practice in the short term, and how this might transform computing education globally in the long term.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {74–84},
numpages = {11},
keywords = {AI; Artificial Intelligence; Automatic Code Generation; Codex; Copilot; CS1; GenAI; GitHub; GPT; GPT-4; ChatGPT; HCI; Introductory Programming; Large Language Models; LLM; Non-Native English Speakers; Novice Programming; OpenAI; Prompt Problems},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3632620.3671112,
author = {Skripchuk, James and Bacher, John and Price, Thomas},
title = {An Investigation of the Drivers of Novice Programmers' Intentions to Use Web Search and GenAI},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671112},
doi = {10.1145/3632620.3671112},
abstract = {External help resources are frequently used by novice programmers solving classwork in undergraduate computing courses. Traditionally, these tools consisted of web resources such as tutorial websites and Q&amp;A forums. With the rise of Generative AI (GenAI), there has been increasing concern and research about how external resources should be used in the classroom. However, little work has directly contrasted student beliefs and perceptions of web resources with GenAI, has grounded these beliefs in prior psychological theory, and has investigated how demographic factors and student backgrounds influence these beliefs and intentions. We administered a vignette-style survey across two courses required for a CS major at an R1 University, a freshman (n = 152) and senior capstone course (n = 44). Students responded to likert questions aiming to measure behavioral factors related to these tools, such as intention to use, perceived attitudes, peer perceptions, and their own perceived tool competency. We primarily investigate the results of an introductory course, finding that novices have a wide range of opinions on both resources, but overall find them slightly useful and have a tendency to prefer web-search. We compare this with seniors, who have more positive perceptions of these tools, and discuss possible reasons and implications for this difference. We constructed two path models to investigate which factors strongly influence novices’ intention to use resources and find the primary factor to be their general attitudes in how these tools will result in a positive or negative outcome (e.g. perceived benefits, justifiability). We also measure the effects of student background on intention to use these resources. Finally, we discuss implications and suggestions on how instructors can use this information to approach, address, and influence resource usage in their classrooms.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {487–501},
numpages = {15},
keywords = {CS Education, GenAI, Help-seeking, student perspectives, web-search},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3605468.3609775,
author = {Philbin, Carrie Anne},
title = {Impact of Generative AI on K-12 Students’ Perceptions of Computing: A Research Proposal},
year = {2023},
isbn = {9798400708510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605468.3609775},
doi = {10.1145/3605468.3609775},
abstract = {The rapid progress of generative artificial intelligence (AI) is fundamentally reshaping traditional perspectives on knowledge and skills, with profound implications for computing education. This necessitates a thorough examination of the relevance and timeliness of computing as a subject, especially for K-12 students who are making critical decisions about their future qualifications. This abstract proposes an empirical research study that aims to explore the effects of integrating generative AI in the creation of digital artefacts on K-12 students’ perceptions of the value of computing, as well as their understanding of ownership and achievement. Constructive discussions regarding the outlined approach are encouraged.},
booktitle = {Proceedings of the 18th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {28},
numpages = {2},
keywords = {Artificial Intelligence education, Creative computing, Generative AI, K-12 education, Student perceptions},
location = {Cambridge, United Kingdom},
series = {WiPSCE '23}
}

@inproceedings{10.1145/3636243.3636248,
author = {Hou, Irene and Mettille, Sophia and Man, Owen and Li, Zhuo and Zastudil, Cynthia and MacNeil, Stephen},
title = {The Effects of Generative AI on Computing Students’ Help-Seeking Preferences},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636248},
doi = {10.1145/3636243.3636248},
abstract = {Help-seeking is a critical way that students learn new concepts, acquire new skills, and get unstuck when problem-solving in their computing courses. The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand. However, it is unclear how this new resource compares to existing help-seeking resources along dimensions of perceived quality, latency, and trustworthiness. In this paper, we investigate the help-seeking preferences and experiences of computing students now that generative AI tools are available to them. We collected survey data (n=47) and conducted interviews (n=8) with computing students. Our results suggest that although these models are being rapidly adopted, they have not yet fully eclipsed traditional help resources. The help-seeking resources that students rely on continue to vary depending on the task and other factors. Finally, we observed preliminary evidence about how help-seeking with generative AI is a skill that needs to be developed, with disproportionate benefits for those who are better able to harness the capabilities of LLMs. We discuss potential implications for integrating generative AI into computing classrooms and the future of help-seeking in the era of generative AI.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {39–48},
numpages = {10},
keywords = {ChatGPT, Generative AI, computing education, help-seeking},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3600211.3604754,
author = {Narayanan Venkit, Pranav},
title = {Towards a Holistic Approach: Understanding Sociodemographic Biases in NLP Models using an Interdisciplinary Lens},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604754},
doi = {10.1145/3600211.3604754},
abstract = {The rapid growth in the usage and applications of Natural Language Processing (NLP) in various sociotechnical solutions has highlighted the need for a comprehensive understanding of bias and its impact on society. While research on bias in NLP has expanded, several challenges persist that require attention. These include the limited focus on sociodemographic biases beyond race and gender, the narrow scope of analysis predominantly centered on models, and the technocentric implementation approaches. This paper addresses these challenges and advocates for a more interdisciplinary approach to understanding bias in NLP. The work is structured into three facets, each exploring a specific aspect of bias in NLP. The first facet focuses on identifying sociodemographic bias in various NLP architectures, emphasizing the importance of considering both the models themselves and human computation to comprehensively understand and identify bias. In the second facet, we delve into the significance of establishing a shared vocabulary across different fields and disciplines involved in NLP. By highlighting the potential bias stemming from a lack of shared understanding, this facet emphasizes the need for interdisciplinary collaboration to bridge the gap and foster a more inclusive and accurate analysis of bias. Finally, the third facet investigates the development of a holistic solution by integrating frameworks from social science disciplines. This approach recognizes the complexity of bias in NLP and advocates for an interdisciplinary framework that goes beyond purely technical considerations, involving social and ethical perspectives to address bias effectively. The first facet includes the following of my published works [6, 7, 8, 9] to provide results into how the importance of understanding the presence of bias in various minority group that has not been in focus in the prior works of bias in NLP. The work also shows the need to create a method that considers both human and AI indicators of bias, showcasing the importance of the first facet of my research. In my study [9], I delve into sentiment analysis and toxicity detection models to identify explicit bias against race, gender, and people with disabilities (PWDs). Through statistical exploration of conversations on social media platforms such as Twitter and Reddit, I gain insights into how disability bias permeates real-world social settings. To quantify explicit sociodemographic bias in sentiment analysis and toxicity analysis models, I create the Bias Identification Test in Sentiment (BITS) corpus1. Applying BITS, I uncover significant biases in popular AIaaS sentiment analysis tools, including TextBlob, VADER, and Google Cloud Natural Language API, as well as toxicity analysis models like Toxic-BERT. Remarkably, all of these models exhibit statistically significant explicit bias against disability, underscoring the need for comprehensive understanding and mitigation of biases affecting such groups. The work also demonstrates the utility of BITS as a model-independent method of identifying bias by focusing on social groups instead. Expanding on this, my next work [8] delves into the realm of implicit bias in NLP models. While some models may not overtly exhibit bias, they can unintentionally perpetuate harmful stereotypes [4]. To measure and identify implicit bias in commonly used embedding and large language models, I propose a methodology to measure social biases in various NLP architectures. Focusing on people with disabilities (PWD) as a group with complex social dynamics, I analyze various word embedding-based and transformer-based LLMs, revealing significant biases against PWDs in all tested models. These findings expose how models trained on extensive corpora tend to favor ableist language, underscoring the urgency of detecting and addressing implicit bias. The above two works look at both the implicit and explicit nature of bias in NLP, showcasing the need to distinguish the efforts placed in understanding them. The results also demonstrate the utility of identifying such biases as it provides context to the black-box nature of such public models. As the field of NLP evolved from embedding-based models to large language models, the way these models are constructed underwent significant changes [5]. However, the concern arises from the fact that these models often reflect a populist viewpoint [1] that perpetuates majority-held ideas rather than objective truths. This difference in perception can lead to biases perpetuated by the majority’s worldview. To explore this aspect, I investigate how LLMs represent nationality and their impact on societal stereotypes [6]. By examining LLM-generated stories for various nationalities, I establish a correlation between sentiment and the population of internet users in a country. The study reveals the unintentional implicit and explicit nationality biases exhibited by GPT-2, with nations having lower internet representation and economic status generating negative sentiment stories and employing a greater number of negative adjectives. Additionally, I explore potential debiasing methods such as adversarial triggering and prompt engineering, demonstrating their efficacy in mitigating stereotype propagation through LLM models. While prior work predominantly relies on automatic indicators like sentiment scores or vector distances to identify bias [3], the next phase of my research emphasizes the importance of understanding biases through the lens of human readers [7], bringing to light the need for a human lens in understanding bias through human-aided indicators and mixed-method identification. By incorporating concepts of social computation, using human evaluation, we gain a better understanding of biases’ potential societal impact within the context of language models. To achieve this, I conduct open-ended interviews and employ qualitative coding and thematic analysis to comprehend the implications of biases on human readers. The findings demonstrate that biased NLP models tend to replicate and amplify existing societal biases, posing potential harm when utilized in sociotechnical settings. The qualitative analysis from the interviews provides valuable insights into readers’ experiences when encountering biased articles, highlighting the capacity to shift a reader’s perception of a country. These findings emphasize the critical role of public perception in shaping AI’s impact on society and the need to correct biases in AI systems. The second facet of my research aims to bridge the disparity between AI research and society. This disparity has resulted in a lack of shared understanding between these domains, leading to potential biases and harm toward specific groups. Employing an interdisciplinary approach that combines social informatics, philosophy, and AI, I will investigate the similarities and disparities in the concepts utilized by machine learning models. Existing research [2] highlights the insufficient interdisciplinary effort and motivation in comprehending social aspects of NLP. To commence this exploration, I will delve into the shared taxonomy of sentiment and fairness in natural language processing, sociology, and humanities. This research will first delve into the interdisciplinary nature of sentiment and its application in sentiment analysis models. Sentiment analysis, a popular machine learning application for text classification based on sentiment, opinion, and subjectivity, holds significant influence as a sociotechnical system that impacts both social and technical actors within a network. Nevertheless, the definition and connotation of sentiment vary vastly across different research fields, potentially leading to misconceptions regarding the utility of such systems. To address this issue, this study will examine how diverse fields, including psychology, sociology, and technology, define the concept of sentiment. By unraveling the divergent perspectives on sentiment within different fields, the paper will uncover discrepancies and varying applications of this interdisciplinary concept. Additionally, the research will survey commonly utilized sentiment analysis models, aiming to comprehend their standardized definitions and associated issues. Ultimately, the study will pose critical questions that should be considered during the development of social models to mitigate potential biases and harm stemming from an insufficiently defined comprehension of fundamental social concepts. Similar efforts will be dedicated to comprehending the disparity in bias and fairness as an interdisciplinary concept, shedding light on the imperative for inclusive research to cultivate superior AI models as sociotechnical solutions. The third facet of my study embarks upon an exploration of the intricate interplay between human and AI actors, employing the formidable theoretical lens of actor-network theory (ANT). Through the presentation of a robust framework, this facet aims to engender the formation of efficacious development networks that foster collaboration among developers, practitioners, and other essential stakeholders. Such inclusive networks serve as crucibles for the cultivation of holistic solutions that transcend the discriminatory trappings afflicting specific populations. A tangible outcome of this endeavor entails the creation of an all-encompassing bias analysis platform, poised to guide the discernment and amelioration of an array of sociodemographic biases manifesting within any machine-learning system. By catalyzing the development of socially aware and less pernicious technology, this research makes a substantial contribution to the realms of NLP and AI. The significance of this proposed research reverberates beyond the confines of NLP, resonating throughout the broader domain of AI, wherein analogous challenges about social biases loom large. Leveraging the proposed framework, developers, practitioners, and policymakers are empowered to forge practical solutions that embody inclusivity and reliability, especially when used as a service (AIaaS). Moreover, the platform serves as a centralized locus for the identification and rectification of social biases, irrespective of the underlying model or architecture. By furnishing a cogent narrative that underscores the imperative for a comprehensive and interdisciplinary approach, my work strives to propel the ongoing endeavors to comprehend and mitigate biases within the realm of NLP. With its potential to augment the equity, inclusivity, and societal ramifications of NLP technologies, the proposed framework catapults the field towards responsible and ethical practices.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {1004–1005},
numpages = {2},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

@inproceedings{10.1145/3656650.3656663,
author = {Gennari, Rosella and Krik, Soufiane},
title = {Responsible Design of Socio-Technical Solutions with Social Design Students: a Case Study},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3656663},
doi = {10.1145/3656650.3656663},
abstract = {Recent research work on digital-well being considers it a matter of personal growth and education. Research in social digital well-being, in particular, invites young generations to consider the role of digital technologies for social well-being. It explored how to engage young generations in building socio-technical prototypes and reflecting on the impact of technology on people. This article fits into this broad line of research. It reports on a case study with social design students with no computing background. It invited them to consider the use of computing technologies in their social-design projects, and to reflect critically on their work. The design was structured with an ad hoc toolkit with various building materials, including cards for reflecting, and physical-computing devices for rapidly prototyping design ideas. The purpose of the toolkit is, on the one hand, to structure and constrain the generative design process and, on the other hand, to allow a certain degree of expressiveness and freedom to participants. The article reports the results of the case study and concludes with a discussion of how to engage non-computing experts in such a process, balancing freedom and guidance.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {50},
numpages = {9},
keywords = {Responsible design, building interaction, end user, interaction design tools, prototyping, social interaction, well being},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}

@inproceedings{10.1145/3675417.3675461,
author = {Liu, Shitou and Liang, Zhenjie and Zhang, Ling},
title = {Analyzing Key Influencing Factors of University Teachers45 Use of Generative Artificial Intelligence in a Small-Sample Data Environment},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675417.3675461},
doi = {10.1145/3675417.3675461},
abstract = {This study focuses on exploring the key factors influencing the use of generative artificial intelligence (AI) by university teachers in the context of digital education, particularly in the backdrop of human-computer interaction. Considering the challenges posed by small-sample data, we employed various machine learning models such as linear regression, random forest regression, and support vector regression (SVR), and optimized model parameters through grid search and cross-validation techniques. The optimized models exhibited significantly improved performance, with the linear regression model showing a mean squared error (MSE) of 0.1239 and an R² score of 0.6362, indicating its good predictive accuracy and generalization ability on the small-sample dataset. The study results emphasize performance expectations, perceived value, and community influence as primary influencing factors for university teachers' use of generative AI, especially in the context of human-computer interaction. This is crucial for understanding and promoting the acceptance and use of educational technology. This research provides valuable insights for education policymakers and technology developers and offers important methodological guidance for machine learning applications dealing with small-sample data.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {271–279},
numpages = {9},
location = {Hongkong, China},
series = {DEAI '24}
}

@inproceedings{10.1145/3706598.3713574,
author = {Ahmadpour, Naseem and Pillai, Ajit G. and Zhang, Wendy Qi and Loke, Lian and Sachathep, Thida and Zhou, Zhaohua and Gough, Phillip},
title = {Ethics Reflexivity Canvas: Resourcing Ethical Sensitivity for HCI Educators},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713574},
doi = {10.1145/3706598.3713574},
abstract = {Integrating ethics education in human-computer interaction (HCI) programs is critical to training responsible industry practitioners. Yet, there is a lack of practical educator-focused resources, which facilitate reflection on personal approaches to ethics education. We conducted a series of nine generative participatory workshops with 15 educators to explore, design and seek feedback on the Ethics Reflexivity Canvas as a pedagogical resource. The canvas makes the educator and learner positionality explicit to develop ethical sensitivity, sensitise and situate a pedagogical plan, and iterate and adapt over time. However, our findings suggest that educators experience tensions, depending on their pedagogical approach. We contribute insight on how resources can align with education work in HCI, help educators reflect on a plurality of approaches to ethics, use accessible language to stimulate curiosity towards ethics, and provide scaffolding to operationalize collaborative and personal exploration.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {399},
numpages = {17},
keywords = {ethics, ethical sensitivity, education work, educator, reflection, reflexivity, canvas},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3644032.3644454,
author = {Hoffmann, Jacob and Frister, Demian},
title = {Generating Software Tests for Mobile Applications Using Fine-Tuned Large Language Models},
year = {2024},
isbn = {9798400705885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644032.3644454},
doi = {10.1145/3644032.3644454},
abstract = {Motivation. Software tests are a necessity in the development of software to secure functionality, reliability, and usability [10]; however, these tests are costly and time-consuming [6]. Although tool support for software testing has advanced, there remains considerable potential for enhancement. Many software tests are still devised manually, with the creation of unit tests being particularly laborious. Automating the generation of test cases is promising for streamlining this aspect of software testing [6].Large Language Models (LLMs) have exhibited capabilities in code generation [11, 13--15], test case generation [17], and various other domains [11]. The advancement of model performance of transformer-based LLMs is mainly achieved by expanding the model size in line with an increase in training data size [7, 8]. However, this approach leads to high computational costs which can only be afforded by corporations with significant financial resources. This highlights the need for transformer-based LLMs that perform well on a specific downstream task and are also cost-efficient. Addressing this, we focused on supervised fine-tuning (SFT) of more resource-efficient transformer-based LLMs LLaMA 2 13B, Code Llama 13B, and Mistral 7B for the specific downstream task of generating test cases for mobile applications.Research questions. This work investigated: Does SFT enhance the capabilities of a transformer-based LLM in the specific downstream task of generating test cases for mobile applications while being cost-efficient and runnable on standard consumer hardware? Does the fine-tuned model outperform other state-of-the-art models in the task of test generation for mobile applications?Approach. Our approach is a modification of the ATHENATEST approach [16]. However, our approach focuses on supervised fine-tuning (SFT) on both pre-trained and already fine-tuned transformer-based LLMs for the task of test case generation for mobile applications in Dart.The approach involves three steps, as illustrated in Figure 1. Firstly, a labeled dataset of corresponding input-output pairs (X, Y) was obtained to model the conditional probability P(Y|X; θ) [9, 12]. Dart code and corresponding test files were extracted from open-source GitHub repositories using Google BigQuery. These files were then matched using regular expressions, ensuring that each code file was matched with its corresponding test file based on matching base filenames. The dataset underwent quality filtering and deduplication, resulting in 16,252 input-output pairs, which was then divided into training (90%) and validation (10%) sets. The training set of the dataset consists of a total of 88.5M tokens using the LLaMA tokenizer.Secondly, for SFT on the downstream task of test generation, models were selected based on their code generation capabilities, as indicated by the pass@1 score on the HumanEval [2] and MBPP [1] benchmark, their parameter sizes, and the extent to which they had been trained on Dart data. In model selection, open-source models capable of running on cost-efficient consumer hardware with code generation abilities were primarily chosen.Thirdly, in the SFT process, the test generation task was represented as translation task, in line with ATHENATEST [16]. This is achieved by employing the following structured prompt format for SFT [9]:"{prefix_prompt} ### Code: {code} ### Test: {test}"In this work, there was no prefix prompt used during SFT.Fine-tuning. The fine-tuning was conducted on a single GPU system using Flash Attention 2 [3] and the QLoRA method [4] to reduce memory size and the number of trainable parameters. The fine-tuning process varied in duration up to 32 hours, resulting in total emissions of 13.099 kgCO2eq [5].Experimental Results. The performance of TestGen-Dart models was evaluated for their unit testing capabilities in Dart, in comparison to base models LLaMA 2 13B, Code Llama 13B, and Mistral 7B. The models were loaded in both float16 and 4-bit quantization configurations, and the evaluation involved nine different Dart files, encompassing 42 test cases. The results were obtained in a zero-shot setting using a structured prompt format, as described in the approach section. This included a prefix prompt instructing the models to generate unit tests: "Generate unit tests in Dart for the following class. The unit test should be structured with the 'test' function, an appropriate description, and an assertion 'expect' within the function to validate the test case." The generated unit tests were classified into three categories: syntax errors (SE), syntactic correctness (SC), and functional correctness (FC). In a 4-bit quantization configuration, TestGen-Dart_v0.2 enhanced the generation of syntactically correct unit tests by 15.38% and functionally correct unit tests by 16.67%, compared to the underlying base model, Code Llama 13B. Additionally, TestGen-Dart_v0.2 demonstrated superior performance in the 16-bit configuration. This evidenced that supervised fine-tuning (SFT) increases the capability of transformer-based LLMs in a specific downstream task, in this instance, generating test cases for mobile applications, addressing the first research question posed in this work. Additionally, TestGen-Dart_v0.2 outperformed the other state-of-the-art models of interest LLaMA 2 13B and Mistral 7B in that task, addressing the second research question.Conclusion. This work demonstrates that SFT enhances the capability of transformer-based LLMs in generating test cases for mobile applications in Dart. Furthermore, the 13B parameter size of the TestGen-Dart enables it to run locally on standard consumer hardware, potentially making it a cost-efficient and privacy-friendly testing assistant for software developers by avoiding an external server connection to run the model.Outlook. Future work currently in progress may expand this approach to other programming languages and refine TestGen-Dart's performance by using higher-quality fine-tuning data either synthetic or human-annotated. Additionally, the evaluation method may be enhanced by using TestGen-Dart for generating test cases for dummy applications and measuring code coverage.},
booktitle = {Proceedings of the 5th ACM/IEEE International Conference on Automation of Software Test (AST 2024)},
pages = {76–77},
numpages = {2},
keywords = {software testing, mobile testing, machine learning, large language models},
location = {Lisbon, Portugal},
series = {AST '24}
}

@inproceedings{10.1145/3576123.3576134,
author = {Finnie-Ansley, James and Denny, Paul and Luxton-Reilly, Andrew and Santos, Eddie Antonio and Prather, James and Becker, Brett A.},
title = {My AI Wants to Know if This Will Be on the Exam: Testing OpenAI’s Codex on CS2 Programming Exercises},
year = {2023},
isbn = {9781450399418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576123.3576134},
doi = {10.1145/3576123.3576134},
abstract = {The introduction of OpenAI Codex sparked a surge of interest in the impact of generative AI models on computing education practices. Codex is also the underlying model for GitHub Copilot, a plugin which makes AI-generated code accessible to students through auto-completion in popular code editors. Research in this area, particularly on the educational implications, is nascent and has focused almost exclusively on introductory programming (or CS1) questions. Very recent work has shown that Codex performs considerably better on typical CS1 exam questions than most students. It is not clear, however, what Codex’s limits are with regard to more complex programming assignments and exams. In this paper, we present results detailing how Codex performs on more advanced CS2 (data structures and algorithms) exam questions taken from past exams. We compare these results to those of students who took the same exams under normal conditions, demonstrating that Codex outscores most students. We consider the implications of such tools for the future of undergraduate computing education.},
booktitle = {Proceedings of the 25th Australasian Computing Education Conference},
pages = {97–104},
numpages = {8},
keywords = {AI, AlphaCode, CS1, CS2, Codex, DeepMind, GPT-3, GitHub, OpenAI, academic integrity, algorithms, artificial intelligence, code generation, copilot, data structures, deep learning, introductory programming, machine learning, neural networks, novice programming},
location = {Melbourne, VIC, Australia},
series = {ACE '23}
}

@inproceedings{10.1145/3649165.3690125,
author = {Kerslake, Chris and Denny, Paul and Smith, David H. and Prather, James and Leinonen, Juho and Luxton-Reilly, Andrew and MacNeil, Stephen},
title = {Integrating Natural Language Prompting Tasks in Introductory Programming Courses},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690125},
doi = {10.1145/3649165.3690125},
abstract = {Introductory programming courses often emphasize mastering syntax and basic constructs before progressing to more complex and interesting programs. This bottom-up approach can be frustrating for novices, shifting the focus away from problem solving and potentially making computing less appealing to a broad range of students. The rise of generative AI for code production could partially address these issues by fostering new skills via interaction with AI models, including constructing high-level prompts and evaluating code that is automatically generated. In this experience report, we explore the inclusion of two prompt-focused activities in an introductory course, implemented across four labs in a six-week module. The first requires students to solve computational problems by writing natural language prompts, emphasizing problem-solving over syntax. The second involves students crafting prompts to generate code equivalent to provided fragments, to foster an understanding of the relationship between prompts and code. Most of the students in the course had reported finding programming difficult to learn, often citing frustrations with syntax and debugging. We found that self-reported difficulty with learning programming had a strong inverse relationship with performance on traditional programming assessments such as tests and projects, as expected. However, performance on the natural language tasks was less strongly related to self-reported difficulty, suggesting they may target different skills. Learning how to communicate with AI coding models is becoming an important skill, and natural language prompting tasks may appeal to a broad range of students.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {88–94},
numpages = {7},
keywords = {cs1, eipe, explain in plain english, introductory programming, llm, natural language prompting, prompt engineering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3626253.3635618,
author = {Garcia, Leiny and Ojeda-Ramirez, Santiago and Warschauer, Mark},
title = {Restorying with AI Art among Latinx Elementary Students},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635618},
doi = {10.1145/3626253.3635618},
abstract = {The Latinx community is underrepresented in tech-oriented fields, which aligns with the lack of culturally relevant learning experiences in CS for Latinx youth, hindering their ability to conceptualize technology as a tool for transformation and vehicle for cultural expression. This study takes on a restorying approach at the elementary level, where 9 fourth-grade students engaged in focus group discussions over three days to generate prompts for a generative AI art. Through the lens of restorying, the prompts had students conceptualize a future with a focus on their Mexican-American heritage, local community, and technology. The study revealed that students associated their heritage with symbolic representations such as food and music, and characterized the community as a commercialized space while also emphasizing locations conducive to family-oriented activities. As a result, technology in community spaces was associated with consumerism. However, when envisioning a futuristic, transformed community, they made deeper connections between the role of technology in the community, making intricate connections between community improvements and technology-based solutions. This underscores the need for computing education to dedicate time for young learners to reflect on the role technology has on their current culture and community to make deeper connections.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1648–1649},
numpages = {2},
keywords = {ai literacy, elementary school, heritage, latinx, restorying},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3706468.3706474,
author = {Yin, Stella Xin and Liu, Zhengyuan and Goh, Dion Hoe-Lian and Quek, Choon Lang and Chen, Nancy F.},
title = {Scaling Up Collaborative Dialogue Analysis: An AI-driven Approach to Understanding Dialogue Patterns in Computational Thinking Education},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706474},
doi = {10.1145/3706468.3706474},
abstract = {Pair programming is a collaborative activity that enhances students’ computational thinking (CT) skills. Analyzing students’ interactions during pair programming provides valuable insights into effective learning. However, interpreting classroom dialogues is a challenging and complex task. Due to the simultaneous interaction between interlocutors and other ambient noise in collaborative learning contexts, previous work heavily relied on manual transcription and coding, which is labor-intensive and time-consuming. Recent advancements in speech and language processing offer promising opportunities to automate and scale up dialogue analysis. Besides, previous work mainly focused on task-related interactions, with little attention to social interactions. To address these gaps, we conducted a four-week CT course with 26 fifth-grade primary school students. We recorded their discussions, transcribed them with speech processing models, and developed a coding scheme and applied LLMs for annotation. Our AI-driven pipeline effectively analyzed classroom recordings with high accuracy and efficiency. After identifying the dialogue patterns, we investigated the relationships between these patterns and CT performance. Four clusters of dialogue patterns have been identified: Inquiry, Constructive Collaboration, Disengagement, and Disputation. We observed that Inquiry and Constructive Collaboration patterns were positively related to students’ CT skills, while Disengagement and Disputation patterns were associated with lower CT performance. This study contributes to the understanding of how dialogue patterns relate to CT performance and provides implications for both research and educational practice in CT learning.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {47–57},
numpages = {11},
keywords = {Collaborative learning, Computational thinking, Dialogue analysis, Large language models, Pair programming, Speech and language processing},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3536169.3537785,
author = {Sosa, Ricardo and Gibbons, Andrew and O'Riordan, Emma and Iorangi, Keu and Crowe, Andy and Gibson, Leanne and Harris, Sam and Badenhorst, Daniel},
title = {Food for Advanced Computational Thinking: Critical and Creative Approaches to Technology at Te Kura Taurua Manurewa},
year = {2022},
isbn = {9781450393881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3536169.3537785},
doi = {10.1145/3536169.3537785},
abstract = {This paper focuses on a participatory activity that is part of an ongoing partnership formed six years ago between teachers and academics to study creative technology approaches to youth participation. By focusing on a food-based activity in an after-school maker space, we reflect on the pedagogical and methodological innovations, and the ethical and aesthetic qualities of food-based activities for participatory design. The session brought together students and teachers to form a generative dialogue around computation and automation while preparing and sharing food. The results suggest opportunities to rethink current curricular, pedagogical, and education policy strategies. Recommendations for organizers to prepare generative activities where food is used as a design material close the paper.},
booktitle = {Proceedings of the Participatory Design Conference 2022 - Volume 1},
pages = {109–119},
numpages = {11},
location = {Newcastle upon Tyne, United Kingdom},
series = {PDC '22}
}

@inproceedings{10.1145/3649165.3703622,
author = {Alshaigy, Bedour and Grande, Virginia and Kiesler, Natalie and Settle, Amber},
title = {How Do You Solve A Problem Like Recruitment? On The Hiring and Retention of Computing Academics},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3703622},
doi = {10.1145/3649165.3703622},
abstract = {This paper critically examines persistent inequities in existing computing faculty hiring and retention practices, which gravely impact computing educators from marginalized groups. Throughout these processes, applicants fight against multiple systemic barriers, including but not limited to, biased job ads and discriminatory interview practices. The increasing use of generative AI tools to aid in tasks connected to the hiring process, such as writing recommendation letters, exacerbates these biases. The inequities persist despite global initiatives and legal mandates and serve as a direct contradiction to widespread institutional commitments to diversity and inclusion. By building on literature and the lived experiences of the SIGCSE community represented in a recent Technical Symposium session, we raise concerns about the different stages of this process, highlighting the importance of clear expectations and adequate support. The paper concludes with a call to align hiring practices with inclusive institutional values, requiring the academic community to reflect on and revise hiring policies for a more equitable future. It is of paramount importance to address the role of these practices in the erosion of marginalized communities from the computing education community, a marginalization that occurs in many different contexts and negatively impacts everyone involved.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {263–266},
numpages = {4},
keywords = {CS academics, recruitment, retention},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3632621.3671415,
author = {Landesman, Rotem},
title = {Teens' Ethical Sensemaking About Emerging Technologies},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671415},
doi = {10.1145/3632621.3671415},
abstract = {Emerging technologies, among them generative AI, are continuously being integrated into the mundane fabric of young people’s lives and routines. Recently, scholars called to expand computing education beyond learning to use and create with technologies to think critically and ethically about their potential impacts as a means to encourage the development of a sense of computational empowerment. My research aims to explore this space and opportunities which encourage ethical thinking with youth - specifically adolescents - on and about generative AI, a recent emerging innovation. This exploration will take inspiration from previous work pointing to the efficacy of practices from the field of Philosophy for Children (P4C) as well as recent work pointing to the potential of eliciting ethical thinking through a critical reflection and making framework, and suggest a novel framework to elicit a sense of computational empowerment as youth grow up in our digital world.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {557–559},
numpages = {3},
keywords = {computing education, ethics in computing, k-12},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3708557.3716158,
author = {Mokryn, Osnat and Shaer, Orit and Geyer, Werner and Maher, Mary Lou and Weisz, Justin D. and Buschek, Daniel and Chilton, Lydia B},
title = {HAI-GEN 2025: 6th Workshop on Human-AI Co-Creation with Generative Models},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716158},
doi = {10.1145/3708557.3716158},
abstract = {Generative Artificial Intelligence (GAI) models capable of complex tasks are revolutionizing areas previously considered to define humanity, such as creativity, design, and knowledge work. Research reports that Human-GAI co-creation processes can enhance creativity and even foster a sense of empowerment. A key innovation is the intent-based outcome specification, where users define desired results through natural language, sketches, or gestures, thus shifting control from users to AI models. This paradigm enables new forms of co-creation while presenting challenges in creating effective and safe outcome specifications.This workshop aims to investigate the design, implementation, and evaluation of intent-based co-creative experiences that boost human creativity in work, play, and education across text, images, audio, code, and video. Key questions focus on how creativity support can guide generative AI development and how to leverage generative models for positive user experiences. By uniting researchers and practitioners from Human-Computer Interaction (HCI) and AI, the workshop seeks to deepen understanding of human-AI co-creative interactions and explore opportunities and challenges in developing meaningful and safe generative systems.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {179–182},
numpages = {4},
keywords = {Generative modeling, artificial intelligence, generative design, user experience, co-creation, collaboration, creativity},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3706599.3706690,
author = {Wu, Tongshuang and Zhu, Haiyi and Albayrak, Maya and Axon, Alexis and Bertsch, Amanda and Deng, Wenxing and Ding, Ziqi and Guo, Boyuan and Gururaja, Sireesh and Kuo, Tzu-Sheng and Liang, Jenny T and Liu, Ryan and Mandal, Ihita and Milbauer, Jeremiah and Ni, Xiaolin and Padmanabhan, Namrata and Ramkumar, Subhashini and Sudjianto, Alexis and Taylor, Jordan and Tseng, Ying-Jui and Vaidos, Patricia and Wu, Zhijin and Wu, Wei and Yang, Chenyang},
title = {LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706690},
doi = {10.1145/3706599.3706690},
abstract = {LLMs have shown promise in replicating human-like behavior in crowdsourcing tasks that were previously thought to be exclusive to human abilities. However, current efforts focus mainly on simple atomic tasks. We explore whether LLMs can replicate more complex crowdsourcing pipelines. We find that modern LLMs can simulate some of crowdworkers’ abilities in these “human computation algorithms,” but the level of success is variable and influenced by requesters’ understanding of LLM capabilities, the specific skills required for sub-tasks, and the optimal interaction modality for performing these sub-tasks. We reflect on human and LLMs’ different sensitivities to instructions, stress the importance of enabling human-facing safeguards for LLMs, and discuss the potential of training humans and LLMs with complementary skill sets. Crucially, we show that replicating crowdsourcing pipelines offers a valuable platform to investigate 1) the relative LLM strengths on different tasks (by cross-comparing their performances on sub-tasks) and 2) LLMs’ potential in complex tasks, where they can complete part of the tasks while leaving others to humans.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {684},
numpages = {10},
keywords = {LLM chains, crowdsourcing pipeline, prompt engineering},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641237.3691673,
author = {Trim, Michelle and Butler, Erin and Suttcliffe, Christina},
title = {Seeing How the Sausage is Made: Data Storytelling as Means and Method in a Computer Science Writing Course},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691673},
doi = {10.1145/3641237.3691673},
abstract = {As data corpus-driven tools and technologies increasingly push users to passively search for an answer, rather than search to understand, we believe that technical and computing disciplinary writing courses have a duty to teach the process of responsible data storytelling. While students can grasp that generative AI makes mistakes, hallucinates, and perpetuates bias, they can need help understanding the antecedent causes of those difficulties. All algorithmically driven decision-making or recommending software have in common a large data set that has been labeled, either by users or by the system itself. The origins of that data and the reasonable applications/deductions and conclusions possible for any given dataset have everything to do with why some tools help and some tools perpetuate harms. By starting at the very beginning and asking students to make sense of data, students can more easily see how purpose and audience impact analysis of any given collection of data. Once those opportunities for rhetorical choice making are known, students become ready to understand the connection between data and complex A.I. systems and some of the ways that bias and other kinds of harm can result if designers are not careful. Combining instruction in a technical coding environment with basic data literacy lessons such as ‘the seven data stories,’ [14] we developed and delivered a three-week writing unit designed around responsible data exploration and storytelling. In this experience report, we provide the assignment we used, and the scaffolded activities we employed to bring students through the process, remarking on what worked well and what we want to improve. We provide attendees with a link to an R-based notebook with a walk-through lesson on data exploration commands, and the rubric used to assess students’ texts, notebooks with code and commentary and results, all existing in a referential context. We provide the survey results of students’ perception of learning from this activity. Early findings demonstrate that students internalized lessons about the non-objective nature of data analysis and of specific responsible data storytelling practices required by anyone seeking to ethically represent answers within and limitations of any dataset.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {217–222},
numpages = {6},
keywords = {Data Visualization, Data storytelling, Pedagogy, Technical communication},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@inproceedings{10.1145/3640471.3680462,
author = {ElAgroudy, Passant and Gruenerbl, Agnes and Barbareschi, Giulia and Spilski, Jan and Kunze, Kai and Lachmann, Thomas and Lukowicz, Paul},
title = {mobiCHAI - 1st International Workshop on Mobile Cognition-Altering Technologies (CAT) using Human-Centered AI},
year = {2024},
isbn = {9798400705069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640471.3680462},
doi = {10.1145/3640471.3680462},
abstract = {The quest for enhanced cognition has been a driving force behind human advancement, fostering innovation and personal fulfillment. Cognition Altering Technologies (CAT) holds immense promise in elevating the quality of life across diverse domains including education, decision-making, healthcare, and fitness. The current proliferation of Artificial Intelligence (AI), particularly the widespread adoption of Generative AI and foundational models, presents an unprecedented opportunity to prototype new CAT that can augment human capabilities. This workshop aims to unite interdisciplinary research communities to explore the potential of leveraging GenAI and human-centered AI to develop relevant CAT. Taking place at MobileHCI 2024, this one-day workshop invites researchers, practitioners, and designers from fields such as artificial intelligence, ubiquitous computing, human-computer interaction, and social sciences to collaborate and chart the future of cognitive enhancement through technology.},
booktitle = {Adjunct Proceedings of the 26th International Conference on Mobile Human-Computer Interaction},
articleno = {31},
numpages = {5},
keywords = {Human-Centered AI, Hybrid-Human Artificial Intelligence, augmenting human capabilities, cognitive science, generative AI, shaping cognitive and social behavior, ubiquitous technologies},
location = {Melbourne, VIC, Australia},
series = {MobileHCI '24 Adjunct}
}

@inproceedings{10.1145/3654777.3676392,
author = {Gunturu, Aditya and Wen, Yi and Zhang, Nandi and Thundathil, Jarin and Kazi, Rubaiat Habib and Suzuki, Ryo},
title = {Augmented Physics: Creating Interactive and Embedded Physics Simulations from Static Textbook Diagrams},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676392},
doi = {10.1145/3654777.3676392},
abstract = {We introduce Augmented Physics, a machine learning-integrated authoring tool designed for creating embedded interactive physics simulations from static textbook diagrams. Leveraging recent advancements in computer vision, such as Segment Anything and Multi-modal LLMs, our web-based system enables users to semi-automatically extract diagrams from physics textbooks and generate interactive simulations based on the extracted content. These interactive diagrams are seamlessly integrated into scanned textbook pages, facilitating interactive and personalized learning experiences across various physics concepts, such as optics, circuits, and kinematics. Drawing from an elicitation study with seven physics instructors, we explore four key augmentation strategies: 1) augmented experiments, 2) animated diagrams, 3) bi-directional binding, and 4) parameter visualization. We evaluate our system through technical evaluation, a usability study (N=12), and expert interviews (N=12). Study findings suggest that our system can facilitate more engaging and personalized learning experiences in physics education.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {144},
numpages = {12},
keywords = {Augmented Textbook, Authoring Interfaces, Explorable Explanations, Interactive Paper, Physics Education},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@article{10.1145/3624720,
author = {Denny, Paul and Prather, James and Becker, Brett A. and Finnie-Ansley, James and Hellas, Arto and Leinonen, Juho and Luxton-Reilly, Andrew and Reeves, Brent N. and Santos, Eddie Antonio and Sarsa, Sami},
title = {Computing Education in the Era of Generative AI},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3624720},
doi = {10.1145/3624720},
abstract = {Challenges and opportunities faced by computing educators and students adapting to LLMs capable of generating accurate source code from natural-language problem descriptions.},
journal = {Commun. ACM},
month = jan,
pages = {56–67},
numpages = {12}
}

@inproceedings{10.1145/3708036.3708151,
author = {Yan, Erkai and Gao, Mengxiao and Tang, Mei},
title = {Analysis and Research on Generative Artificial Intelligence in the Field of International Library and Information Science},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708151},
doi = {10.1145/3708036.3708151},
abstract = {Generative artificial intelligence is an artificial intelligence technology based on deep learning whose core lies in leveraging computer algorithms and training data to generate new, practically valuable content, encompassing text, images, audio, videos, etc. This technology is poised to exert profound impacts on the transformation and development of libraries. Drawing on generative artificial intelligence research publications in the field of international library and information science included in the Scopus database as the data source, this paper employs CiteSpace software and SciVal tools to conduct a visual analysis of literature outputs, core authors, journal sources, and keywords. The results show that generative artificial intelligence research in the international library and information science field is applied primarily in areas such as reference services, information literacy education, and smart libraries. Recommendations are made to promote the application and development of generative artificial intelligence technology in libraries by strengthening technological research and application, boosting data analysis and data sharing, emphasizing information security and privacy protection, promoting cross-boundary integration and ecological development, etc.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {679–686},
numpages = {8},
keywords = {ChatGPT, Generative artificial intelligence, library},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3727648.3727765,
author = {Zhang, Kaijie and Wu, Minhui and Chen, Kaihao},
title = {Scaling Down LLaMA 3: Advanced Compression Techniques and Knowledge Distillation for Resource-Efficient Language Models},
year = {2025},
isbn = {9798400712647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3727648.3727765},
doi = {10.1145/3727648.3727765},
abstract = {With the widespread application of large-scale language models (LLMs) in natural language processing, traditional Transformer-based models (such as LLaMA 3) face challenges in resource-constrained environments due to their huge parameter size and computational complexity. To improve efficiency, model compression has become an important research direction. This paper proposes an innovative knowledge distillation strategy to distill the LlamaDecoderLayer of LLaMA 3 into a smaller student model TinyDecoder to reduce the computational and storage overhead of the model. TinyDecoder significantly reduces the model size and computational complexity while maintaining good performance by simplifying parameters such as the hidden layer size and the number of attention heads in LlamaDecoderLayer. Experimental results show that the distilled model significantly reduces storage requirements and computational load while still achieving decent performance. The parameter size of the distilled model is about 4.3% of the original model, the throughput speedup ratio is 1.49x - 10.93x, and the perplexity only increases from 3.25 to 7.94. Although the text generation performance of the distilled model has declined, the inference speed and memory usage are significantly improved compared to the original model, which is particularly suitable for resource-constrained environments. Through distillation, the student model effectively learns the core knowledge of the teacher model and performs well on tasks of simple to medium complexity.},
booktitle = {Proceedings of the 4th International Conference on Computer, Artificial Intelligence and Control Engineering},
pages = {721–725},
numpages = {5},
keywords = {Knowledge Distillation, LLama 3 Optimization, Large Language Models, Model Compression},
location = {
},
series = {CAICE '25}
}

@inproceedings{10.1145/3664475.3664553,
author = {Rao, Anyi and Xiangli, Yuanbo and Guo, Yuwei and Tang, Mia and Meng, Chenlin and Agrawala, Maneesh},
title = {Generative Models for Visual Content Editing and Creation},
year = {2024},
isbn = {9798400706837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664475.3664553},
doi = {10.1145/3664475.3664553},
abstract = {Welcome to the SIGGRAPH 2024 Course on Generative Models for Visual Content Editing and Creation! In this course, you will embark on an exciting journey into the realm of generative models and their groundbreaking applications in computer graphics. Over the duration of this course, you will gain a comprehensive understanding of generative models and diffusion models, explore fundamental machine learning and deep learning techniques, and discover cutting-edge applications for high-fidelity image synthesis, video generation, 3D content creation, and more. Here's what you can expect to learn:},
booktitle = {ACM SIGGRAPH 2024 Courses},
articleno = {13},
numpages = {6},
location = {Denver, CO, USA},
series = {SIGGRAPH Courses '24}
}

@inproceedings{10.1145/3626252.3630832,
author = {Sakzad, Amin and Paul, David and Sheard, Judithe and Brankovic, Ljiljana and Skerritt, Matthew P. and Li, Nan and Minagar, Sepehr and Simon and Billingsley, William},
title = {Diverging assessments: What, Why, and Experiences},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630832},
doi = {10.1145/3626252.3630832},
abstract = {In this experience paper, we introduce the concept of 'diverging assessments', process-based assessments designed so that they become unique for each student while all students see a common skeleton. We present experiences with diverging assessments in the contexts of computer networks, operating systems, ethical hacking, and software development. All the given examples allow the use of generative-AI-based tools, are authentic, and are designed to generate learning opportunities that foster students' meta-cognition. Finally, we reflect upon these experiences in five different courses across four universities, showing how diverging assessments enhance students' learning while respecting academic integrity.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1161–1167},
numpages = {7},
keywords = {assessment-as-learning, authentic assessment, diverging assessment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3636988.3636996,
author = {Carter, Karla},
title = {"I, ChatBot": Co-Teaching Cybersecurity Courses With Generative AI},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {3},
issn = {1937-4771},
abstract = {This tutorial is for computing science faculty who are intrigued by the notion that generative AI, such as OpenAI's ChatGPT or Google's Bard, can enhance the way we teach and students learn cybersecurity. Rather than questioning if faculty and students should use generative AI in the classroom, you're asking how faculty and students can use generative AI appropriately and responsibly in the classroom. Our students deserve to understand the tools shaping their future; generative AI is not going away and we need to prepare our students for a future where not knowing how to write generative AI prompts isn't an option.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {27–28},
numpages = {2}
}

@inproceedings{10.1145/3620666.3655589,
author = {Vahdat, Amin},
title = {Societal infrastructure in the age of Artificial General Intelligence},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620666.3655589},
doi = {10.1145/3620666.3655589},
abstract = {Today, we are at an inflection point in computing where emerging Generative AI services are placing unprecedented demand for compute while the existing architectural patterns for improving efficiency have stalled. In this talk, we will discuss the likely needs of the next generation of computing infrastructure and use recent examples at Google from networks to accelerators to servers to illustrate the challenges and opportunities ahead. Taken together, we chart a course where computing must be increasingly specialized and co-optimized with algorithms and software, all while fundamentally focusing on security and sustainability.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
pages = {1},
numpages = {1},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

@inproceedings{10.1145/3673791.3698402,
author = {Kurohashi, Sadao},
title = {From Data Platforms to Knowledge Infrastructure},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673791.3698402},
doi = {10.1145/3673791.3698402},
abstract = {Modern society is facing pressing issues, including environmental challenges, inequality, and regional conflicts. To resolve these complex societal problems, the concept of ''open science'' is essential, as emphasized at last year's G7 meeting. In Japan, starting in 2025, all scientific papers resulting from publicly funded research, along with the associated data, will be required to be immediately accessible through open access.The National Institute of Informatics (NII) has been at the forefront of advancing Japan's academic information infrastructure for many years. In 2017, NII embarked on the development of the NII Research Data Cloud -- a platform for the publication, discovery, and management of academic information -- which became operational in 2021. By 2022, the project evolved into a research data ecosystem, built in collaboration with numerous universities and research institutions. This initiative aims to create a comprehensive environment where papers, data, and computational resources are readily accessible across all fields of research.Recognizing the significant impact of generative AI on society and the need for a hub in Japan where large-scale language models (LLMs) can be developed and studied, NII spearheaded the formation of the LLM-jp study group (https://llm-jp.nii.ac.jp/en/) in May 2023. The group, founded on principles of openness, began with approximately 30 researchers specializing in natural language processing and has since grown to over 1,800 participants from industry, government, and academia.In April 2024, NII further advanced this initiative by establishing the LLM R&amp;D Center. By September 2024, the center had developed and released the world's largest fully open LLM, featuring 172 billion parameters -- on a scale similar to GPT-3.5. The center's ongoing work also focuses on ensuring the reliability and transparency of these models. To address the complex societal challenges mentioned above, it is crucial not only to deepen academic research but also to foster collaboration across various disciplines, creating new cross-disciplinary knowledge. LLMs can play a pivotal role in these processes by interpreting data, interconnecting and systematizing knowledge, and laying the groundwork for a robust knowledge infrastructure.},
booktitle = {Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {114},
numpages = {1},
keywords = {generative ai, knowledge infrastructure, large language models (llms), llm-jp, open science},
location = {Tokyo, Japan},
series = {SIGIR-AP 2024}
}

@inproceedings{10.1145/3719330.3721230,
author = {Ren, Zebin and Doekemeijer, Krijn and De Matteis, Tiziano and Pinto, Christian and Stoica, Radu and Trivedi, Animesh},
title = {An I/O Characterizing Study of Offloading LLM Models and KV Caches to NVMe SSD},
year = {2025},
isbn = {9798400715297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3719330.3721230},
doi = {10.1145/3719330.3721230},
abstract = {With the popularity of generative AI, LLM inference has become one of the most popular cloud workloads. Modern popular LLMs have hundreds of billions of parameters and support very large input/output prompt token sizes (100K-1M). As a result, their computational state during LLM inference can exceed the memory available on GPUs. One solution to this GPU memory problem is to offload the model weights and KV cache to the host memory. As the size of the models and prompts continue to increase, researchers have started to explore the use of secondary storage, such as SSDs, to store the model weights and KV cache. However, there is a lack of study on the I/O characteristics and performance requirements of these offloading operations. In order to have a better understanding of the performance characteristics of these offloading operations, in this work, we collect, study, and characterize the block layer I/O traces from two LLM inference frameworks, DeepSpeed and FlexGen, that support model and KV cache offloading to SSDs. Through our analysis of these I/O traces, we report that: (i) libaio-based tensor offloading delivers higher I/O bandwidth for both writing and reading tensors to/from the SSDs than POSIX; (ii) the I/O workload of model offloading is dominated by 128 KiB reads for both DeepSpeed and FlexGen in the block layer; (iii) model offloading does not saturate NVMe SSDs; and (iv) the I/O workload of KV cache offloading contains both read and write workloads dominated by 128 KiB requests, but the average bandwidth of read is much higher than write (2.0 GiB/s vs. 11.0 MiB/s). We open-source the scripts and the I/O traces of this work at https://github.com/stonet-research/cheops25-IO-characterization-of-LLM-model-kv-cache-offloading-nvme},
booktitle = {Proceedings of the 5th Workshop on Challenges and Opportunities of Efficient and Performant Storage Systems},
pages = {23–33},
numpages = {11},
keywords = {KV cache offloading, Large language model, Model offloading, SSDs},
location = {Rotterdam, Netherlands},
series = {CHEOPS '25}
}

@inproceedings{10.1145/3613905.3636272,
author = {Nacke, Lennart E.},
title = {How to Write Better CHI Papers (with AI)},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636272},
doi = {10.1145/3613905.3636272},
abstract = {Writing and organizing research papers is a valuable skill that can make or break your academic career. Generative artificial intelligence (AI) tools offer unprecedented opportunities for researchers to improve their skills in writing research papers and conducting literature reviews. In the past six years, my writing course has introduced you to everything you wanted to know about writing papers. However, with the arrival of generative AI, our writing process is changing. So, now I offer the opportunity to learn how to leverage generative AI tools to edit your writing, brainstorm, and help you find citations, so that your papers are easy to read and have impact. It is broken up into three 75-minute online units that will help you structure your paper’s research content and use generative AI as assistive research technology. The goal of the course is to learn how to leverage generative AI to help you write a paper that makes a contribution to the field of human-computer interaction and can be understood by other HCI researchers facilitated by the use of generative AI tools.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {599},
numpages = {4},
keywords = {Clarity, LaTeX, Research Methods, Submission Process, Writing},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3579168.3632724,
author = {Ho, Shuyuan Mary and Liu, Yue},
title = {Genie Breaks the Bottle: Ethics in Artificial Intelligence Adoption: ChatGPT; The Beginning and the End of Human Wisdom},
year = {2024},
isbn = {9798400700941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579168.3632724},
doi = {10.1145/3579168.3632724},
abstract = {ChatGPT, developed by OpenAI, has attracted significant attention from early adopters. While this generative artificial intelligence (AI) system can be somewhat intuitive, such technology can also be disruptive in domains that require creativity (e.g., computer coding, system development and education), information authenticity (e.g., news agencies) and precision (e.g., manufacturing, clinical decision making). This study urges scholars in the fields of human-computer interaction and information system to reexamine technology adoption to better understand the criticality and ethics of AI and ChatGPT with regards to social change and social impact.},
booktitle = {Proceedings of the 2023 Computers and People Research Conference},
articleno = {6},
numpages = {4},
keywords = {Artificial intelligence, ChatGPT, deepfakes, generative adversarial networks, information ethics, social change},
location = {Pomona, CA, USA},
series = {SIGMIS-CPR '23}
}

@inproceedings{10.1145/3706599.3706641,
author = {Nacke, Lennart E.},
title = {How to write higher-quality CHI papers (with AI research tools)},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706641},
doi = {10.1145/3706599.3706641},
abstract = {Writing high-quality research papers is crucial for advancing your academic career. With the advent of generative artificial intelligence (AI) tools, researchers now have novel ways to improve their writing, literature reviews, and overall paper quality. This course, delivered in person at CHI 2025 in Yokohama, Japan, offers a practical exploration of how to use AI tools effectively throughout the research writing process. Over three interactive 75-minute sessions, participants will learn to apply AI tools to edit their writing, brainstorm ideas, and enhance their paper’s readability and impact. Through hands-on activities and peer discussions, attendees will gain the skills needed to produce high-impact CHI papers that meet publication standards. This course emphasizes using AI to support writing, structuring research, and refining contributions, providing attendees with practical tools and insights to succeed in academic publishing in the field of Human-Computer Interaction.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {816},
numpages = {3},
keywords = {Generative AI, Writing, ChatGPT, Publication, Writing, Submission Process, Research Methods},
location = {
},
series = {CHI EA '25}
}

@article{10.5555/3665464.3665466,
author = {Juhnke, Kevin},
title = {Perspectives on Technology's Impact on Financial Services and the Future Workforce},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {A variety of experiences over a 30+ year career in the computing field at Principal Financial provides for a life-long journey with many fascinating insights. Mr. Juhnke will focus his thoughts on:• Business and market challenges in Financial Services and their impact on an organization's Technology Strategies• The impact key maturing and emerging technologies have on the Financial Services industry including...- Cloud Advancements- Generative AI- Blockchain- "Citizen" DevelopmentHe will conclude his thoughts with perspectives on areas where educators can help position students to be more marketable and impactful in financial services tech jobs after graduation.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {18–19},
numpages = {2}
}

@inproceedings{10.1145/3640794.3665542,
author = {Ouaazki, Abdessalam and Bergram, Kristoffer and Farah, Juan Carlos and Gillet, Denis and Holzer, Adrian},
title = {Generative AI-Enabled Conversational Interaction to Support Self-Directed Learning Experiences in Transversal Computational Thinking},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640794.3665542},
doi = {10.1145/3640794.3665542},
abstract = {As computational thinking (CT) becomes increasingly acknowledged as an important skill in education, self-directed learning (SDL) emerges as a key strategy for developing this capability. The advent of generative AI (GenAI) conversational agents has disrupted the landscape of SDL. However, many questions still arise about several user experience aspects of these agents. This paper focuses on two of these questions: personalization and long-term support. As such, the first part of this study explores the effectiveness of personalizing GenAI through prompt-tuning using a CT-based prompt for solving programming challenges. The second part focuses on identifying the strengths and weaknesses of a GenAI model in a semester-long programming project. Our findings indicate that while prompt-tuning could hinder ease of use and perceived learning assistance, it might lead to higher learning outcomes. Results from a thematic analysis also indicate that GenAI is useful for programming and debugging, but it presents challenges such as over-reliance and diminishing utility over time.},
booktitle = {Proceedings of the 6th ACM Conference on Conversational User Interfaces},
articleno = {13},
numpages = {12},
keywords = {ChatGPT, Chatbots, Education, Generative AI, Programming, Student Perceptions},
location = {Luxembourg, Luxembourg},
series = {CUI '24}
}

@inproceedings{10.1145/3596671.3598574,
author = {Goel, Toshali and Shaer, Orit and Delcourt, Catherine and Gu, Quan and Cooper, Angel},
title = {Preparing Future Designers for Human-AI Collaboration in Persona Creation},
year = {2023},
isbn = {9798400708077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3596671.3598574},
doi = {10.1145/3596671.3598574},
abstract = {This paper presents findings from an exploratory study investigating the use of AI text-generation tools to support novice designers in persona creation. We conducted a workshop with 22 undergraduate students enrolled in an introductory human-computer interaction course, who were instructed to use GPT-3 in the creation of personas. These novice designers were able to use GPT-3 to iterate to produce satisfactory personas, particularly when providing detailed prompts. Our findings suggest that personas created with GPT-3 assistance were mostly comparable to those created manually but rated lower on some evaluation dimensions. The study also reveals merits and concerns of using GPT-3 for persona creation. Based on our findings, we propose recommendations for novice designers on how to use text-generative AIs to create personas effectively and responsibly.},
booktitle = {Proceedings of the 2nd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {4},
numpages = {14},
keywords = {personas, novice designers, natural-language generation, large language models, human-AI collaboration, education},
location = {Oldenburg, Germany},
series = {CHIWORK '23}
}

@inproceedings{10.1145/3690407.3690563,
author = {Zhou, Jinpeng and Tao, Zhiyong},
title = {Research on Automatic Scoring Algorithm for English Composition Based on Heterogeneous Fusion Network},
year = {2024},
isbn = {9798400710247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690407.3690563},
doi = {10.1145/3690407.3690563},
abstract = {Automatic essay scoring is an innovative method that utilizes computer algorithms and artificial intelligence technology to recognize language features in essays through training models, and to perform automatic essay grading. It has become an important research topic in the field of natural language processing in education. However, essay scoring is essentially a complex task that involves comprehensive evaluation of multiple dimensions such as grammar, semantics, and subject relevance. Current neural network models often struggle to fully capture multiple features of essays, thereby limiting their grading effectiveness. In response to the above challenges, this article proposes a method based on BERT and attention mechanism generative fusion network to automatically score essays, and innovatively uses a feature fusion structure based on conditional layer normalization CLN to fuse the features extracted from the attention and residual network-based CNN-BiLSTM essay automatic scoring model and BERT pre trained language model, and then applies them to automatic essay scoring. Compared with baseline methods and ablation experiments, the average QWK performance on this dataset reached 78.86%. This indicates that the fusion network can effectively integrate the semantic information extracted from different structured networks, resulting in better performance in scoring tasks, verifying the accuracy and effectiveness of the proposed model.},
booktitle = {Proceedings of the 2024 4th International Conference on Artificial Intelligence, Big Data and Algorithms},
pages = {936–940},
numpages = {5},
keywords = {Attention Mechanism, Automatic Essay Scoring, Generative Fusion, Pre-training Model, Residual Network},
location = {
},
series = {CAIBDA '24}
}

@inproceedings{10.1145/3696410.3714715,
author = {Liao, Jinzhi and Liao, Zenghua and Zhao, Xiang},
title = {PSSD: Making Large Language Models Self-denial via Human Psyche Structure},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714715},
doi = {10.1145/3696410.3714715},
abstract = {The enhance of accuracy in reasoning results of LLMs arouses the community's interests, wherein pioneering studies investigate post-hoc strategies to rectify potential mistakes. Despite extensive efforts, they are all stuck in a state of resource competition demand ing significant time and computing expenses. The cause of the situation lies in the failure of identifying the fundamental feature of the solutions in this line, coined as the self-denial of LLMs. In other words, LLMs should confidently determine the potential existence of mistakes and carefully execute the targeted correction. As the whole procedure conducts within LLMs, supporting and persuasive references are hard to acquire, while the absence of specific steps towards refining hidden mistakes persists even when errors are acknowledged. In response to the challenges, we present PSSD, which refers to and implements the human psyche structure such that three distinct and interconnected roles contribute to human reasoning. Specifically, PSSD leverages the recent multi-agent paradigm, and is further enhanced with three innovatively conceived roles: (1) the intuition-based id role that provides initial attempts based on benign LLMs; (2) the rule-driven superego role that summarizes rules to regulate the above attempts, and returns specific key points as guidance; and (3) the script-centric ego role that absorbs all procedural information to generate executable script for the final answer prediction. Extensive experiments demonstrate that the proposed design not only better enhance reasoning capabilities, but also seamlessly integrate with current models, leading to superior performance.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {796–806},
numpages = {11},
keywords = {mistake correction, multi-agent debate, self-denial},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3650212.3680343,
author = {Guo, Lianghong and Wang, Yanlin and Shi, Ensheng and Zhong, Wanjun and Zhang, Hongyu and Chen, Jiachi and Zhang, Ruikai and Ma, Yuchi and Zheng, Zibin},
title = {When to Stop? Towards Efficient Code Generation in LLMs with Excess Token Prevention},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680343},
doi = {10.1145/3650212.3680343},
abstract = {Code generation aims to automatically generate code snippets that meet given natural language requirements and plays an important role in software development. Although Code LLMs have shown excellent performance in this domain, their long generation time poses a signification limitation in practice use. In this paper, we first conduct an in-depth preliminary study with different Code LLMs on code generation task and identify a significant efficiency issue, i.e., continual generation of excess tokens. It harms the developer productivity and leads to huge computational wastes. To address it, we introduce CodeFast, an inference acceleration approach for Code LLMs on code generation. The key idea of CodeFast is to terminate the inference process in time when unnecessary excess tokens are detected. First, we propose an automatic data construction framework to obtain training data. Then, we train a unified lightweight model GenGuard applicable to multiple programming languages to predict whether to terminate inference at the current step. Finally, we enhance Code LLM with GenGuard to accelerate its inference in code generation task. We conduct extensive experiments with CodeFast on five representative Code LLMs across four widely used code generation datasets. Experimental results show that (1) CodeFast can significantly improve the inference speed of various Code LLMs in code generation, ranging form 34% to 452%, without compromising the quality of generated code. (2) CodeFast is stable across different parameter settings and can generalize to untrained datasets. Our code and data are available at https://github.com/DeepSoftwareAnalytics/CodeFast.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1073–1085},
numpages = {13},
keywords = {Machine learning for analysis, Testing and development processes},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3631802.3631807,
author = {Jeuring, Johan and Groot, Roel and Keuning, Hieke},
title = {What Skills Do You Need When Developing Software Using ChatGPT? (Discussion Paper)},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631807},
doi = {10.1145/3631802.3631807},
abstract = {Since the release of LLM-based tools such as GitHub Copilot and ChatGPT the media and popular scientific literature, but also journals such as the Communications of the ACM, have been flooded with opinions how these tools will change programming. The opinions range from “machines will program themselves”, to “AI does not help programmers”. Of course, these statements are meant to to stir up a discussion, and should be taken with a grain of salt, but we argue that such unfounded statements are potentially harmful. Instead, we propose to investigate which skills are required to develop software using LLM-based tools. In this paper we report on an experiment in which we explore if Computational Thinking (CT) skills predict the ability to develop software using LLM-based tools. Our results show that the ability to develop software using LLM-based tools can indeed be predicted by the score on a CT assessment. There are many limitations to our experiment, and this paper is also a call to discuss how to approach, preferably experimentally, the question of which skills are required to develop software using LLM-based tools. We propose to rephrase this question to include by what kind of people/programmers, to develop what kind of software using what kind of LLM-based tools.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {38},
numpages = {6},
keywords = {ChatGPT, Computational thinking skills, LLM-based tools, Software development skills},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3706598.3714233,
author = {Earle, Sam and Parajuli, Samyak and Banburski-Fahey, Andrzej},
title = {DreamGarden: A Designer Assistant for Growing Games from a Single Prompt},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714233},
doi = {10.1145/3706598.3714233},
abstract = {Coding assistants are increasingly leveraged in game design, both generating code and making high-level plans. To what degree can these tools align with developer workflows, and what new modes of human-computer interaction can emerge from their use? We present DreamGarden, an AI system capable of assisting with the development of diverse game environments in Unreal Engine. At the core of our method is an LLM-driven planner, capable of breaking down a single, high-level prompt—a dream, memory, or imagined scenario provided by a human user—into a hierarchical action plan, which is then distributed across specialized submodules facilitating concrete implementation. This system is presented to the user as a garden of plans and actions, both growing independently and responding to user intervention via seed prompts, pruning, and feedback. Through a user study, we explore design implications of this system, charting courses for future work in semi-autonomous assistants and open-ended simulation design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {57},
numpages = {19},
keywords = {Game design assistants, 3D asset generation, large language models, visual feedback},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3626253.3635522,
author = {Ruiz, Pati and Rangel, Alessandra and Coenraad, Merijke},
title = {Using Generative AI to Support PK-12 Teaching and Learning: Developing Sample Lessons and More},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635522},
doi = {10.1145/3626253.3635522},
abstract = {North Salem Central School District (North Salem) has worked with researchers as part of a larger Research Practice Partnership (RPP) to design and implement an inclusive PK-12 computing pathway in their district. This poster describes how teachers used Generative AI (GenAI) tools in three areas: (1) the development of sample computational thinking (CT) lesson plans; (2) initial brainstorming; and (3) professional learning.As North Salem reflected on their use of GenAI tools, they named two AI tools specifically: OpenAI's ChatGPT-4 and Bing's Image Creator. Teachers also describe ethical dilemmas that they faced when integrating GenAI tools as well as other concerns that will be described below. This work builds on the growing literature on the use of Generative AI tools to support the day-to-day work of teachers.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1800–1801},
numpages = {2},
keywords = {K-12 computer science education, ducational equity, formative assessment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3610969.3610973,
author = {Addo, Salomey Afua},
title = {Are You Ready to Teach AI in Schools? Teachers' Perspectives of Teaching AI in K-12 Settings},
year = {2023},
isbn = {9798400708763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610969.3610973},
doi = {10.1145/3610969.3610973},
abstract = {Artificial intelligence (AI) has continually made headlines, even more so with the mass interest in generative AI. The implications of AI on society raises the need for its inclusion in the K-12 computing curriculum. However, little research has been conducted to understand teachers’ preparedness to teach AI concepts in K-12. This exploratory study seeks to understand teachers’ motivation and preparedness to teach AI in schools through the lens of Self Efficacy Theory (SET) and Self Determination Theory (SDT).},
booktitle = {Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {32},
numpages = {1},
keywords = {motivation, K-12 computing education, Artificial intelligence},
location = {Swansea, Wales Uk},
series = {UKICER '23}
}

@inproceedings{10.1145/3675812.3675871,
author = {Zhong, Xuanyan and Xin, Haiyang and Li, Wenfeng and Zhan, Zehui and Cheng, May-hung},
title = {The Design and application of RAG-based conversational agents for collaborative problem solving},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675871},
doi = {10.1145/3675812.3675871},
abstract = {Dialogue is the basis of collaborative problem solving, and the development of generative artificial intelligence has made dialogue no longer limited to human-to-human, and human-computer dialogue has gradually become an important way for people to solve problems. At the same time, with the change of the subject of collaborative problem solving, the cultivation of collaborative problem-solving skill urgently needs to explore a new path. In this regard, more and more studies have begun to apply conversational agents in collaborative problem-solving activities, digging deeper into the effects of time on students in conversational agents. However, there is no clear answer to the question of how conversational agents can be better integrated into a collaborative environment for all to assist people in the collaborative problem-solving process and improve performance. In this study, we constructed a conceptual model of human-computer collaboration in order to improve students' learning performance. Based on this model, we integrated Retrieval-Augmented Generative and GPT to construct a conversational agent, and the results of the study showed that the Retrieval-Augmented Generative Agent for Collaborative Problem Solving constructed in this study can effectively promote students' collaborative problem-solving performance.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {62–68},
numpages = {7},
keywords = {Collaborative problem solving, Conversational agent, GPT},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3716640.3716654,
author = {Gutierrez, Sebastian and Hou, Irene and Lee, Jihye and Angelikas, Kenneth and Man, Owen and Mettille, Sophia and Prather, James and Denny, Paul and MacNeil, Stephen},
title = {Seeing the Forest and the Trees: Solving Visual Graph and Tree Based Data Structure Problems using Large Multimodal Models},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716654},
doi = {10.1145/3716640.3716654},
abstract = {Recent advancements in generative AI systems have raised concerns about academic integrity among educators. Beyond excelling at solving programming problems and text-based multiple-choice questions, recent research has also found that large multimodal models (LMMs) can solve Parsons problems based only on an image. However, such problems are still inherently text-based and rely on the capabilities of the models to convert the images of code blocks to their corresponding text. In this paper, we further investigate the capabilities of LMMs to solve graph and tree data structure problems based only on images. To achieve this, we computationally construct and evaluate a novel benchmark dataset comprising 9,072 samples of diverse graph and tree data structure tasks to assess the performance of the GPT-4o, GPT-4 with Vision (GPT-4V), Gemini 1.5 Pro, Gemini 1.5 Flash, Gemini 1.0 Pro Vision, and Claude 3 model families. GPT–4o and Gemini 1.5 Flash performed best on trees and graphs respectively. GPT-4o achieved 87.6% accuracy on tree samples, while Gemini 1.5 Pro, achieved 76.9% accuracy on graph samples. Our findings highlight the influence of structural and visual variations on model performance. This research not only introduces an LMM benchmark to facilitate replication and further exploration but also underscores the potential of LMMs in solving complex computing problems, with important implications for pedagogy and assessment practices.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {124–133},
numpages = {10},
keywords = {Generative AI, Academic Integrity, Computing Education, Large Multimodal Models, LMMs, Large Language Models, LLMs},
location = {
},
series = {ACE '25}
}

@article{10.1145/3711023,
author = {Neshaei, Seyed Parsa and Tolzin, Antonia and Berkle, Yvonne and Leuchter, Miriam and Leimeister, Jan Marco and Janson, Andreas and Wambsganss, Thiemo},
title = {Leveraging Learner Errors in Digital Argumentation Learning: How ALure Helps Students Learn from their Mistakes and Write Better Arguments},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711023},
doi = {10.1145/3711023},
abstract = {Providing argumentation feedback is considered helpful for students preparing to work in collaborative environments, helping them with writing higher-quality argumentative texts. Domain-independent natural language processing (NLP) methods, such as generative models, can utilize learner errors and fallacies in argumentation learning to help students write better argumentative texts. To test this, we collect design requirements, and then design and implement two different versions of our system called ALure to improve the students' argumentation skills. We test how ALure helps students learn argumentation in a university lecture with 305 students and compare the learning gains of the two versions of ALure with a control group using video tutoring. We find and discuss the differences of learning gains in argument structure and fallacies in both groups after using ALure, as well as the control group. Our results shed light on the applicability of computer-supported systems using recent advances in NLP to help students in learning argumentation as a necessary skill for collaborative working settings.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW125},
numpages = {32},
keywords = {argumentation learning, learning from errors, natural language processing, writing assistants}
}

@inproceedings{10.1145/3604915.3608795,
author = {Zheng, Zhi and Sun, Ying and Song, Xin and Zhu, Hengshu and Xiong, Hui},
title = {Generative Learning Plan Recommendation for Employees: A Performance-aware Reinforcement Learning Approach},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604915.3608795},
doi = {10.1145/3604915.3608795},
abstract = {With the rapid development of enterprise Learning Management Systems (LMS), more and more companies are trying to build enterprise training and course learning platforms for promoting the career development of employees. Indeed, through course learning, many employees have the opportunity to improve their knowledge and skills. For these systems, a major issue is how to recommend learning plans, i.e., a set of courses arranged in the order they should be learned, that can help employees improve their work performance. Existing studies mainly focus on recommending courses that users are most likely to click on by capturing their learning preferences. However, the learning preference of employees may not be the right fit for their career development, and thus it may not necessarily mean their work performance can be improved accordingly. Furthermore, how to capture the mutual correlation and sequential effects between courses, and ensure the rationality of the generated results, is also a major challenge. To this end, in this paper, we propose the Generative Learning plAn recommenDation (GLAD) framework, which can generate personalized learning plans for employees to help them improve their work performance. Specifically, we first design a performance predictor and a rationality discriminator, which have the same transformer-based model architecture, but with totally different parameters and functionalities. In particular, the performance predictor is trained for predicting the work performance of employees based on their work profiles and historical learning records, while the rationality discriminator aims to evaluate the rationality of the generated results. Then, we design a learning plan generator based on the gated transformer and the cross-attention mechanism for learning plan generation. We calculate the weighted sum of the output from the performance predictor and the rationality discriminator as the reward, and we use Self-Critical Sequence Training (SCST) based policy gradient methods to train the generator following the Generative Adversarial Network (GAN) paradigm. Finally, extensive experiments on real-world data clearly validate the effectiveness of our GLAD framework compared with state-of-the-art baseline methods and reveal some interesting findings for talent management.},
booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
pages = {443–454},
numpages = {12},
keywords = {generative recommendation, learning management system, reinforcement learning},
location = {Singapore, Singapore},
series = {RecSys '23}
}

@inproceedings{10.1145/3658617.3697636,
author = {Hui, Haojia and Gu, Jiangyuan and Hu, Xunbo and Wei, Shaojun and Yin, Shouyi},
title = {DIAG: A Refined Four-layer Agile Hardware Developing Flow for Generating Flexible Reconfigurable Architectures},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697636},
doi = {10.1145/3658617.3697636},
abstract = {Rapid evolution in application algorithms, exemplified by advancements in artificial intelligence, wireless communication, and sciencific computing, necessitates a focus on developing energy-efficient, highly-flexible parallel computing architectures. This urgency is further amplified by the need for agile hardware development techniques to mitigate design complexity and reduce costs. Among emerging agile hardware development techniques, generative HDL stands out due to its straightforward grammatical structure and compatibility with hardware design thinking, yet it remains underutilized. In response, this paper introduces a novel four-layer agile developing flow, termed DIAG, innovatively leveraging unique Plugin-Service technology. The DIAG framework is applied to an extensible reconfigurable architecture generator, enabling the generation of diverse CGRA designs suitable for accelerating task computations across multiple application domains. Our comprehensive experiments on the CGRA generator design validate the efficiency of the DIAG flow and underscore generative-HDL's significant potential for complex, large-scale hardware development.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {548–553},
numpages = {6},
keywords = {agile hardware developing, generative HDL, CGRA generator},
location = {Tokyo, Japan},
series = {ASPDAC '25}
}

@article{10.1145/3728479,
author = {Mazumdar, Eric and Sastry, S. Shankar and Jordan, Michael I.},
title = {On Finding Local Nash Equilibria (and only Local Nash Equilibria) in Zero-Sum Games},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3728479},
doi = {10.1145/3728479},
abstract = {We propose local symplectic surgery, a two-timescale procedure for finding local Nash equilibria in two-player zero-sum games. We first show that previous gradient-based algorithms cannot guarantee convergence to local Nash equilibria due to the existence of non-Nash stationary points. By taking advantage of the differential structure of the game, we construct an algorithm for which the local Nash equilibria are the only attracting fixed points. Further, we show that the algorithm exhibits no oscillatory behavior in neighborhoods of equilibria and that it has the same per-iteration complexity as other recently proposed algorithms. Furthermore we give convergence rates in structured classes of zero-sum games. We conclude by validating the algorithm on two numerical examples: a toy example with multiple Nash equilibria and a non-Nash equilibrium, and the training of a small generative adversarial network (GAN).Problem statementWe study the problem of computing a (local) Nash equilibrium in non-convex non-concave zero-sum games, i.e., saddle point problems. The majority of work on solving this class of optimization problems makes strong assumptions on the curvature of the underlying functions and consequently the algorithms tend to fail when deployed in unstructured settings like the training of generative adversarial networks.MethodsWe present a new gradient-based algorithm for finding the local Nash equilibria of two-player zero-sum games: local symplectic surgery. Our algorithm makes essential use of the underlying structure of zero-sum games. To derive our algorithm, we work in continuous time-via an ordinary differential equation (ODE)-and our algorithm is obtained via a discretization of the ODE.  While a naive discretization would require a matrix inversion and would be computationally burdensome, our discretization is a two-timescale discretization that avoids matrix inversion entirely and is of a similar computational complexity as that of other gradient-based algorithms.ResultsWe show how-by design- our proposed algorithm overcomes many of the challenges faced by existing methods for computing local Nash equilibria of non-convex non-concave zero-sum games. In particular we
prove that the only stationary points to which the algorithm can converge are local Nash equilibria and further that it cannot exhibit oscillations around equilibrium points-two properties that existing methods fail to guarantee. Furthermore we show numerically  that our algorithm scales gracefully to complex problems like the training of generative adversarial networks and exhibits more stable behavior than existing methods.SignificanceThis paper focuses on the problem of computing solutions to a non-convex non-concave min-max problems that have particular second-order structure: that of a local Nash equilibrium. We show that existing methods for computing saddle points in such games have no guarantees over the types of solutions they converge to-potentially yielding undesired solutions. To overcome this, we propose a new algorithm-local symplectic surgery- which has strong convergence guarantees even in the unstructured settings that often arise in deep learning. Altogether, our insights and algorithms highlight important new problems and present initial solutions to an important problems in an increasingly important subfield of optimization in machine learning.},
note = {Just Accepted},
journal = {ACM / IMS J. Data Sci.},
month = may
}

@inproceedings{10.1145/3625549.3658685,
author = {Maurya, Avinash and Underwood, Robert and Rafique, M. Mustafa and Cappello, Franck and Nicolae, Bogdan},
title = {DataStates-LLM: Lazy Asynchronous Checkpointing for Large Language Models},
year = {2024},
isbn = {9798400704130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625549.3658685},
doi = {10.1145/3625549.3658685},
abstract = {LLMs have seen rapid adoption in all domains. They need to be trained on high-end high-performance computing (HPC) infrastructures and ingest massive amounts of input data. Unsurprisingly, at such a large scale, unexpected events (e.g., failures of components, instability of the software, undesirable learning patterns, etc.), are frequent and typically impact the training in a negative fashion. Thus, LLMs need to be checkpointed frequently so that they can be rolled back to a stable state and subsequently fine-tuned. However, given the large sizes of LLMs, a straightforward checkpointing solution that directly writes the model parameters and optimizer state to persistent storage (e.g., a parallel file system), incurs significant I/O overheads. To address this challenge, in this paper we study how to reduce the I/O overheads for enabling fast and scalable checkpointing for LLMs that can be applied at high frequency (up to the granularity of individual iterations) without significant impact on the training process. Specifically, we introduce a lazy asynchronous multi-level approach that takes advantage of the fact that the tensors making up the model and optimizer state shards remain immutable for extended periods of time, which makes it possible to copy their content in the background with minimal interference during the training process. We evaluate our approach at scales of up to 180 GPUs using different model sizes, parallelism settings, and checkpointing frequencies. The results show up to 48\texttimes{} faster checkpointing and 2.2\texttimes{} faster end-to-end training runtime compared with the state-of-art checkpointing approaches.},
booktitle = {Proceedings of the 33rd International Symposium on High-Performance Parallel and Distributed Computing},
pages = {227–239},
numpages = {13},
keywords = {LLMs and transformers, scalable checkpointing, asynchronous multilevel checkpointing},
location = {Pisa, Italy},
series = {HPDC '24}
}

@inproceedings{10.1145/3711542.3711583,
author = {Tan, Tee Hean},
title = {Rule-Based vs. AI-Driven: Comparing PolyAQG Framework and Generative AI Models},
year = {2025},
isbn = {9798400717383},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711542.3711583},
doi = {10.1145/3711542.3711583},
abstract = {This comparative analysis examines the PolyAQG framework and Generative AI models (e.g., ChatGPT, Gemini) across ten key criteria for question generation. The PolyAQG framework, a rule-based approach, is well-suited for structured content and excels in generating consistent questions for educational purposes. However, it may be limited in creativity and depth. Generative AI models, while capable of covering broader topics and interpreting complex contexts, require more computational resources and may introduce inaccuracies in specialized domains. The PolyAQG framework offers scalability within specific domains and predictable error handling. Generative AI models, although scalable across topics, may require fine-tuning for accuracy. Furthermore, Generative AI enables dynamic user interaction and fosters critical thinking, while the PolyAQG framework provides a more limited user interface. The choice between PolyAQG and generative AI depends on application needs. PolyAQG is ideal for structured questions and consistency, while generative AI excels in creativity, adaptability, and user interaction.},
booktitle = {Proceedings of the 2024 8th International Conference on Natural Language Processing and Information Retrieval},
pages = {298–303},
numpages = {6},
keywords = {Generative AI model, PolyAQG framework, contextual understanding, domain-specific, questions generation, rule-based, scalability},
location = {
},
series = {NLPIR '24}
}

@inproceedings{10.1145/3702163.3702165,
author = {Gong, Rushi and Jiang, Rui and Guo, Chuanlei and Hu, Wanqing and Li, Yanyan},
title = {Roles emerging during the knowledge construction process in collaborative learning: Does a generative AI-support chatbot matter?},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702165},
doi = {10.1145/3702163.3702165},
abstract = {Students’ emerging roles in computer supported collaborative learning (CSCL) are crucial in revealing what learning characteristics and states students present during their collaborative knowledge construction. Previous researchers have unveiled the fact that pedagogical scaffoldings such as AI chatbots play a pivotal role in students’ role emerging, but with the prevalence of generative AI (GAI), there is also an urgent need to investigate whether GAI chatbots influence students’ emerging roles during the knowledge construction process in collaborative learning. Therefore, this study conducted a quasi-experiment, using an integration of cluster analysis, chi-square test, case analysis, and content analysis to investigate whether and how a GAI chatbot affected students’ emerging roles in their online collaborative knowledge construction. Results demonstrated statistical significance that the GAI chatbot and the traditional static scripts did not have a distinct difference in students’ emerging roles. However, qualitative data showed that the GAI chatbot had an impact on the allocation of roles and that there were perceptual differences in how students with the same roles experienced the writing process and collaborative atmosphere under different support conditions. The study will provide insights into how GAI chatbots can be adapted for future development and application in a collaborative learning context with consideration of students’ roles.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {8–16},
numpages = {9},
keywords = {Computer Supported Collaborative Learning, Generative AI Chatbot, Knowledge Construction, Students’ Roles},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3676641.3716262,
author = {Xu, Jianxing and Wen, Yuanbo and Liu, Zikang and Xu, Ruibai and Ruan, Tingfeng and Bi, Jun and Zhang, Rui and Huang, Di and Song, Xinkai and Hao, Yifan and Hu, Xing and Du, Zidong and Zhao, Chongqing and Jie, Jiang and Guo, Qi},
title = {Mosaic: Exploiting Instruction-Level Parallelism on Deep Learning Accelerators with iTex Tessellation},
year = {2025},
isbn = {9798400710797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676641.3716262},
doi = {10.1145/3676641.3716262},
abstract = {Deep learning has achieved great success in numerous application areas at the cost of high computational complexity. To meet the ever-increasing computational demand, commodity hardware platforms (e.g., CPUs and GPUs) offer abundant computing resources including scalar, vector, and tensor units for deep learning that could execute in parallel. However, existing top-down tiling-based deep learning compilers often generate a homogeneous mapping from the given tensor computation task to hardware arithmetic instructions, failing to utilize different computing units simultaneously to achieve higher performance.In this paper, we propose Mosaic, a bottom-up tessellation-based deep learning compiler that directly tessellates the given tensor computation task with varying instructions, forming a heterogeneous instruction-to-task mapping to exploit instruction-level parallelism (ILP) across different computing units. The key that enables such tessellation is the iTex abstraction, which models the relationship between the instruction operations and its semantics with formalized affine functions. Based on the iTex, we propose a heuristic approach to efficiently generate various tessellation plans. Further, we propose the iTex scheduling technique to orchestrate the execution of instructions, reducing potential structural hazards and maximizing the exploitable ILP. Our extensive evaluation shows that Mosaic achieves an average speedup ranging from 1.08\texttimes{} to 1.28\texttimes{} across multiple hardware platforms compared to highly optimized vendor libraries. Mosaic also achieves an average speedup of 1.34\texttimes{} over the best existing baselines on real-world operators extracted from LLMs. More importantly, Mosaic reaches up to 106% of the GPU Tensor Core theoretical peak throughput, demonstrating its effective exploitation of ILP.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {672–688},
numpages = {17},
keywords = {compiler, deep learning accelerators, instruction-level parallelism (ilp)},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@article{10.1145/3698365.3698376,
author = {Chien, Andrew A. and Lin, Liuzixuan and Nguyen, Hai and Rao, Varsha and Sharma, Tristan and Wijayawardana, Rajini},
title = {Reducing the Carbon Impact of Generative AI Inference (Today and in 2035)},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
url = {https://doi.org/10.1145/3698365.3698376},
doi = {10.1145/3698365.3698376},
abstract = {Generative AI, exemplified in ChatGPT, Dall-E 2, and Stable Diffusion, are exciting new applications consuming growing quantities of computing. We study the compute, energy, and carbon impacts of generative AI inference. Using ChatGPT as an exemplar, we create a workload model and compare request direction approaches (Local, Balance, CarbonMin), assessing their power use and carbon impacts.Our workload model shows that for ChatGPT-like services, inference dominates emissions, in one year producing 25x the carbon-emissions of training GPT-3. The workload model characterizes user experience, and experiments show that carbon emissions-aware algorithms (CarbonMin) can both maintain user experience and reduce carbon emissions dramatically (35%). We also consider a future scenario (2035 workload and power grids), and show that CarbonMin can reduce emissions by 56%. In both cases, the key is intelligent direction of requests to locations with low-carbon power. Combined with hardware technology advances, CarbonMin can keep emissions increase to only 20% compared to 2022 levels for 55x greater workload. Finally we consider datacenter headroom to increase effectiveness of shifting. With headroom, CarbonMin reduces 2035 emissions by 71%.},
journal = {SIGENERGY Energy Inform. Rev.},
month = sep,
pages = {65–72},
numpages = {8},
keywords = {carbon emissions, generative AI, geographic shifting, large language models, sustainability}
}

@inproceedings{10.1145/3659995.3660038,
author = {Maurya, Avinash and Ye, Jie and Rafique, M. Mustafa and Cappello, Franck and Nicolae, Bogdan},
title = {Breaking the Memory Wall: A Study of I/O Patterns and GPU Memory Utilization for Hybrid CPU-GPU Offloaded Optimizers},
year = {2024},
isbn = {9798400706424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3659995.3660038},
doi = {10.1145/3659995.3660038},
abstract = {Transformers and LLMs have seen rapid adoption in all domains. Their sizes have exploded to hundreds of billions of parameters and keep increasing. Under these circumstances, the training of transformers is slow and often takes in the order of weeks or months. Thanks to 3D model parallelism (data, pipeline, and tensor-level parallelism), the training can scale to a large number of GPUs, which reduces the duration of the training but dramatically increases the cost. Even when a large number of GPUs are available, the aggregated GPU memory is often not enough to hold the full training state (optimizer state, model parameters, and gradients). To compensate, state-of-the-art approaches offload the optimizer state at least partially to the host memory and perform hybrid CPU-GPU computations. Such flexible solutions dramatically reduce the GPU memory utilization, which makes it feasible to run the training on a smaller number of GPUs at the cost of performance penalty. Unfortunately, the challenges and bottlenecks of adopting this strategy are not sufficiently studied by state-of-the-art, which results in poor management of the combined host-GPU memory and poor overlapping between data movements and computations. In this paper, we aim to fill this gap by characterizing the behavior of offloaded training using the DeepSpeed runtime. Specifically, we study the GPU memory utilization over time during each iteration, the activity on the PCIe related to transfers between the host memory and the GPU memory, and the relationship between resource utilization and the steps involved in each iteration. Thanks to this study, we reveal opportunities for future improvements of offloading solutions, which enable greater flexibility to optimize the cost-performance trade-off in the context of transformer and LLM training.},
booktitle = {Proceedings of the 14th Workshop on AI and Scientific Computing at Scale Using Flexible Computing Infrastructures},
pages = {9–16},
numpages = {8},
keywords = {characterizing asynchronous multi-tier optimizer movement in large-language models, hierarchical cache management},
location = {Pisa, Italy},
series = {FlexScience'24}
}

@inproceedings{10.1145/3706599.3719742,
author = {Li, Jinqiao and Neshaei, Seyed Parsa and M\"{u}ller, Livia and Rietsche, Roman and Davis, Richard Lee and Wambsganss, Thiemo},
title = {SpatiaLearn: Exploring XR Learning Environments for Reflective Writing},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719742},
doi = {10.1145/3706599.3719742},
abstract = {Reflective writing promotes deeper learning by enhancing metacognitive awareness and critical thinking, but learners often struggle with structuring their reflections and maintaining focus. Generative AI and advances in spatial computing offer promising solutions. Extended reality (XR) environments create immersive, distraction-free settings, while conversational agents use dialog-based scaffolding guides to structure learners’ thoughts. However, research on combining dialog-based scaffolding with XR for reflective writing remains limited. To address this, we introduce SpatiaLearn, an adaptive XR tool that enhances reflective writing through conversational guidance in both traditional and immersive environments. A within-subjects study (N = 19) compared participants’ performance in traditional laptop and XR environments. Qualitative analysis shows the spatial interface enhances engagement but raises challenges like unfamiliar interactions and health concerns, requiring task adaptation for XR. This study advances the design of immersive tools for reflective writing, highlighting both the opportunities and challenges of spatial interfaces.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {491},
numpages = {11},
keywords = {Extended Reality (XR), Spatial Computing, Adaptive Education, Conversational Tutoring},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3656019.3676945,
author = {Kim, Sowoong and Sim, Eunyeong and Shin, Youngsam and Cho, YeonGon and Baek, Woongki},
title = {Activation Sequence Caching: High-Throughput and Memory-Efficient Generative Inference with a Single GPU},
year = {2024},
isbn = {9798400706318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656019.3676945},
doi = {10.1145/3656019.3676945},
abstract = {Generative artificial intelligence is widely used for various tasks such as language translation and art creation. Generative inference employs the key and value tensors to encode relational information among the tokens in the input and output sequences. Most of the existing generative inference frameworks use KV caching (KVC), which caches the key and value tensors (i.e., the KV cache) to avoid recomputing the key and value tensors for each of the processed tokens. Despite the widespread use of KVC, in-depth characterization of KVC with tensor offloading, which enables generative inference with a single GPU, remains yet to be explored. To bridge this gap, this work presents an in-depth characterization study of KVC, which demonstrates that KVC makes a sub-optimal trade-off between computations and communications in the context of generative inference with tensor offloading. Guided by the characterization results, we propose a novel caching technique called activation sequence caching (ASC) for high-throughput and memory-efficient generative inference with a single GPU. ASC is designed to significantly reduce the memory usage and communication overheads of generative inference at the cost of the increased computational complexity. We provide an analytical analysis of the three caching techniques (i.e., zero caching, KVC, and ASC) for generative inference in terms of the memory usage, communication overheads, and computational complexity. Our quantitative evaluation demonstrates the effectiveness of ASC in that ASC significantly (e.g., 78.3% higher throughput) outperforms a state-of-the-art generative inference framework (i.e., FlexGen) that implements KVC across various model sizes, input and output sequence lengths, and GPUs.},
booktitle = {Proceedings of the 2024 International Conference on Parallel Architectures and Compilation Techniques},
pages = {78–90},
numpages = {13},
location = {Long Beach, CA, USA},
series = {PACT '24}
}

@inproceedings{10.1145/3671151.3671184,
author = {Zhang, Qian and Li, Yingying},
title = {Fast-ECGAN: Towards More Efficient GAN Models},
year = {2024},
isbn = {9798400718106},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671151.3671184},
doi = {10.1145/3671151.3671184},
abstract = {In this study, we introduce a groundbreaking approach by seamlessly integrating the Edge Guided Generative Adversarial Network enhanced with contrastive learning (ECGAN) into the Jittor computational framework, which is further empowered by our innovative Edge-Aware Spatial Encoding (EASE) technique. This novel integration is designed to refine image edge clarity and enrich overall image quality significantly. By harnessing Jittor's state-of-the-art optimization strategies, we are able to amplify the performance and efficiency of ECGAN remarkably. Through rigorous experimental evaluation, our findings clearly demonstrate the superior efficacy of our integrated approach, as evidenced by substantial improvements in both the quality of the generated images and the computational speed. This research contributes profoundly to the advancement of image generation technology, illustrating the immense potential of fusing sophisticated generative adversarial network models with advanced computing frameworks to achieve unprecedented levels of image realism and processing efficiency. This synergy paves the way for new directions in the application of artificial intelligence in image processing and generation.},
booktitle = {Proceedings of the 5th International Conference on Computer Information and Big Data Applications},
pages = {176–181},
numpages = {6},
location = {Wuhan, China},
series = {CIBDA '24}
}

@inproceedings{10.1145/3706468.3706559,
author = {Li, Tongguang and Nath, Debarshi and Cheng, Yixin and Fan, Yizhou and Li, Xinyu and Rakovi\'{c}, Mladen and Khosravi, Hassan and Swiecki, Zachari and Tsai, Yi-Shan and Ga\v{s}evi\'{c}, Dragan},
title = {Turning Real-Time Analytics into Adaptive Scaffolds for Self-Regulated Learning Using Generative Artificial Intelligence},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706559},
doi = {10.1145/3706468.3706559},
abstract = {In computer-based learning environments (CBLEs), adopting effective self-regulated learning (SRL) strategies requires sophisticated coordination of multiple SRL processes. While various studies have proposed adaptive SRL scaffolds (i.e. real-time advice on adopting effective SRL processes) and embedded them in CBLEs to facilitate learners’ effective use of SRL strategies, two key research gaps remain. First, there is a lack of research on SRL scaffolds that are based on continuous assessment of both learners’ SRL processes and learning conditions (e.g., awareness of learning resources) to provide adaptive support. Second, current analytics-based scaffolding mechanisms lack the scalability needed to effectively address multiple learning conditions. Integration of analytics of SRL with generative artificial intelligence (GenAI) can provide scalable scaffolding for real-time SRL processes and evolving conditions. Yet, empirical studies implementing and evaluating effects of this integration remain scarce. To address these limitations, we conducted a randomized control trial, assigning participants to three groups (control, process only, and process with condition groups) to investigate the effects of using GenAI to turn insights from real-time analytics about students’ SRL processes and conditions into adaptive scaffolds. The results demonstrate that integrating real-time analytics with GenAI in adaptive SRL scaffolds – addressing both SRL processes and dynamic conditions – promotes more metacognitive learning patterns compared to the control and process-only groups. In addition, the learners showed varying levels of compliance with analytics-based GenAI scaffolds, and this was also reflected in how the learners coordinated their SRL processes, particularly in the performance phase of SRL. This study contributes to the literature by designing, implementing, and evaluating the impact of adaptive scaffolds on learners’ SRL processes using real-time analytics with GenAI.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {667–679},
numpages = {13},
keywords = {self-regulated learning, scaffolding compliance, GenAI, scaffolding, learning analytics},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3706599.3719782,
author = {Davis, Richard Lee and Mwaita, Kevin Fred and M\"{u}ller, Livia and Tozadore, Daniel C. and Novikova, Aleksandra and K\"{a}ser, Tanja and Wambsganss, Thiemo},
title = {SketchAI: A "Sketch-First" Approach to Incorporating Generative AI into Fashion Design},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719782},
doi = {10.1145/3706599.3719782},
abstract = {Generative AI technologies are increasingly being incorporated into creativity support tools. However, most generative AI tools rely on text-based prompting, requiring users to translate visual ideas into linguistic descriptions. This approach is misaligned with the sketch-driven workflows of creative professionals. To address this gap, we introduce SketchAI, a novel sketch-first interface for diffusion models that allows practitioners to use real-time sketching on a tablet computer to guide model outputs. Through a qualitative study with 29 fashion design apprentices, we explored the interface’s potential impacts on creative workflows. While some participants identified use cases where SketchAI streamlined routine tasks, others expressed concerns about its potential to undermine creative agency and exploration. These findings unearthed hidden complexity: while generative AI can support some aspects of creativity, its core capabilities may challenge the central identity of creative practitioners. While SketchAI does not resolve this problem, it does take a meaningful step towards reconciliation.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {483},
numpages = {7},
keywords = {Creativity Support Tools, CSTs, Generative AI, Artificial Intelligence, Sketch-Based Input, Diffusion Models},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3643834.3661581,
author = {Chen, Qiaoyi and Liu, Siyu and Huang, Kaihui and Wang, Xingbo and Ma, Xiaojuan and Zhu, Junkai and Peng, Zhenhui},
title = {RetAssist: Facilitating Vocabulary Learners with Generative Images in Story Retelling Practices},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661581},
doi = {10.1145/3643834.3661581},
abstract = {Reading and repeatedly retelling a short story is a common and effective approach to learning the meanings and usages of target words. However, learners often struggle with comprehending, recalling, and retelling the story contexts of these target words. Inspired by the Cognitive Theory of Multimedia Learning, we propose a computational workflow to generate relevant images paired with stories. Based on the workflow, we work with learners and teachers to iteratively design an interactive vocabulary learning system named RetAssist. It can generate sentence-level images of a story to facilitate the understanding and recall of the target words in the story retelling practices. Our within-subjects study (N=24) shows that compared to a baseline system without generative images, RetAssist significantly improves learners’ fluency in expressing with target words. Participants also feel that RetAssist eases their learning workload and is more useful. We discuss insights into leveraging text-to-image generative models to support learning tasks.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {2019–2036},
numpages = {18},
keywords = {Vocabulary learning, image generation, story retelling},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3680256.3721317,
author = {Li, Zhiqi and Yu, Ruiqi and Liu, Jianshu},
title = {IrisBench: An Open-Source Benchmark Suite for Video Processing Systems in Cloud},
year = {2025},
isbn = {9798400711305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680256.3721317},
doi = {10.1145/3680256.3721317},
abstract = {Recent advances in generative text-to-video AI models (e.g., VideoPoet and Sora) have spurred a surge in video production, leading to an increased demand for video processing pipelines among various video service providers such as YouTube and TikTok. With the improvement of cloud computing, video processing systems are frequently updated and present both opportunities and challenges while optimizing the quality of service (QoS) and cloud resource utilization. However, research on evaluating the performance of video processing systems is limited. Besides the availability of video datasets and realistic workloads, the lack of an open-source benchmark system reflecting the characteristics of industrial video processing systems is a significant gap. To fill this gap, we develop IrisBench, an open-source benchmark suite for cloud video processing systems to facilitate research on performance analysis. Our benchmark suite includes three video services: video transcoding, video partitioning, and video object detection services. Our future work relies on using IrisBench to study the architectural implications of various cloud video processing systems in the cloud.},
booktitle = {Companion of the 16th ACM/SPEC International Conference on Performance Engineering},
pages = {167–173},
numpages = {7},
keywords = {benchmark, cloud computing, serverless, stream processing},
location = {Toronto ON, Canada},
series = {ICPE '25}
}

@inproceedings{10.1145/3669754.3669806,
author = {Batac, Carlo Antonio and Baroja, Marc Jethro and Caballero, Don John Daniel and Coloma, Louis Gabriel and Tan, Lind Matthew and Ebardo, Ryan},
title = {Do Human Beliefs and Traits Influence the Adoption of ChatGPT among Programming Students?},
year = {2024},
isbn = {9798400717055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669754.3669806},
doi = {10.1145/3669754.3669806},
abstract = {Abstract: Increased use of generative artificial intelligence or AI in various academic activities such as programming is a significant milestone in technology diffusion in learning. To bring AI closer to how programmers think, behave, and interact, it is imperative for research to establish a clear connection between various human factors that lead to its adoption. Using a model based on the Theory of Reasoned Action, we positioned human traits of academic stress, risk propensity, neuroticism, and computer self-efficacy as factors that positively influence attitudes toward the use of AI in programming among university students. We further posited that attitude and social norms lead to the behavioral intention to use AI in programming. We used PLS-SEM to analyze responses from 131 programming students who use ChatGPT to accomplish learning tasks. We found that both academic stress and computer self-efficacy influence attitudes toward using AI in programming. While attitude positively influences the behavioral intention to use ChatGPT, we found that risk propensity and neuroticism do not affect attitude, and social norms do not influence behavioral intention. We discuss the implications of our investigation to the industry and the academe.},
booktitle = {Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence},
pages = {339–344},
numpages = {6},
keywords = {ChatGPT, PLS-SEM, education, generative AI, programming},
location = {Bali Island, Indonesia},
series = {ICCAI '24}
}

@inproceedings{10.1145/3627673.3679083,
author = {Cui, Xiquan and Dave, Vachik and Su, Yi and Al Jadda, Khalifeh and Kumar, Srijan and McAuley, Julian and Ye, Tao and Guo, Stephen and Huyen, Chip},
title = {International Workshop on Online and Adaptive Recommender Systems (OARS 2024)},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679083},
doi = {10.1145/3627673.3679083},
abstract = {Recommender system (RecSys) plays important roles in helping users navigate, discover, and consume massive and highly-dynamic information. Today, many RecSys solutions deployed in the real world rely on categorical user-profiles and/or pre-calculated recommendation actions that stay static during a user session. However, recent trends suggest that RecSys need to model user intent in real time and constantly adapt to meet user needs at the moment or change user behavior in situ. There are three primary drivers for this emerging need of online adaptation. First, in order to meet the increasing demand for a better personalized experience, the personalization dimensions and space will grow larger and larger. It would not be feasible to pre-compute recommended actions for all personalization scenarios beyond a certain scale. Second, in many settings the system does not have user prior history to leverage. Estimating user intent in real time is the only feasible way to personalize. As various consumer privacy laws tighten, it is foreseeable that many businesses will reduce their reliance on static user profiles. Therefore, it makes the modeling of user intent in real time an important research topic. Third, a user's intent often changes within a session and between sessions, and user behavior could shift significantly during dramatic events. Therefore, it is important to investigate more on online and adaptive recommender system (OARS) that can adapt in real time to meet user needs and be robust against distribution shifts. Every year, the organizers survey the most important topics for OARS and propose a new workshop program. In light of the recent advancement of LLMs and foundation models in RecSys, in this new edition, we decide to formally add the new topic of foundation and LLM models in OARS. We will invite experts and papers in the field to facilitate its further advancement. Our workshop offers a focused discussion of the new study and application of OARS, and will bring together an interdisciplinary community of researchers and practitioners from both industry and academia to discuss on new topics in the area, grow a community, and push the direction forward.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5580–5583},
numpages = {4},
keywords = {artificial intelligence, foundation model, gen ai, llm, recommender system},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3655027,
author = {Riofrio, Carlos A. and Mitevski, Oliver and Jones, Caitlin and Krellner, Florian and Vuckovic, Aleksandar and Doetsch, Joseph and Klepsch, Johannes and Ehmer, Thomas and Luckow, Andre},
title = {A Characterization of Quantum Generative Models},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {2},
url = {https://doi.org/10.1145/3655027},
doi = {10.1145/3655027},
abstract = {Quantum generative modeling is a growing area of interest for industry-relevant applications. This work systematically compares a broad range of techniques to guide quantum computing practitioners when deciding which models and methods to use in their applications. We compare fundamentally different architectural ansatzes of parametric quantum circuits: (1) A continuous architecture, which produces continuous-valued data samples, and (2) a discrete architecture, which samples on a discrete grid. We also compare the performance of different data transformations: the min-max and the probability integral transforms. We use two popular training methods: (1) quantum circuit Born machines (QCBM), and (2) quantum generative adversarial networks (QGAN). We study their performance and tradeoffs as the number of model parameters increases, with a baseline comparison of similarly trained classical neural networks. The study is performed on six low-dimensional synthetic and two real financial data sets. Our two key findings are that: (1) For all data sets, our quantum models require similar or fewer parameters than their classical counterparts. In the extreme case, the quantum models require two orders of magnitude less parameters. (2) We empirically find that a variant of the discrete architecture, which learns the copula of the probability distribution, outperforms all other methods.},
journal = {ACM Transactions on Quantum Computing},
month = jun,
articleno = {12},
numpages = {34},
keywords = {Quantum machine learning, datasets, neural networks}
}

@inproceedings{10.1145/3613904.3642677,
author = {Trajkova, Milka and Long, Duri and Deshpande, Manoj and Knowlton, Andrea and Magerko, Brian},
title = {Exploring Collaborative Movement Improvisation Towards the Design of LuminAI—a Co-Creative AI Dance Partner},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642677},
doi = {10.1145/3613904.3642677},
abstract = {Co-creation in embodied contexts is central to the human experience but is often lacking in our interactions with computers. We seek to develop a better understanding of embodied human co-creativity to inform the human-centered design of machines that can co-create with us. In this paper, we ask: What characterizes dancers’ experiences of embodied dyadic interaction in movement improvisation? To answer this, we ran focus groups with 24 university dance students and conducted a thematic analysis of their responses. We synthesize our findings in an Interconnected Model of Improvisational Dance Inputs, where movement choices are shaped by the interplay between in-the-moment influences between the self, partner, and the environment, a set of generative strategies, and heuristics for a successful collaboration. We present a set of design recommendations for LuminAI, a co-creative AI dance partner. Our contributions can inform the design of AI in embodied co-creative domains.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {890},
numpages = {22},
keywords = {AI agents, co-creative agents, co-creativity, computational creativity, dance improvisation, movement improvisation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3718751.3718848,
author = {Yao, Junping and Wang, Hao and Li, Xiaojun and Yang, Zebin and Sun, Haifeng},
title = {A Joint Generative Discriminant Network for Person Re-identification with Limited Computing Resources},
year = {2025},
isbn = {9798400709753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3718751.3718848},
doi = {10.1145/3718751.3718848},
abstract = {Traditional methods for Person Re-identification (Re-ID) often achieve high accuracy at the cost of huge computational resources, and their application is severely limited under low computing resources. Previous studies have shown that reducing the number of model parameters often significantly degrades the performance of the model. Based on this, we constructs a lightweight joint generative discriminant network, that the maximum pooling layer after group convolution point by point, as well as the global pooling layer and fully connected layer after channel shuffle in the fourth stage, are removed. Then, a convolutional layer is added at the end of the fourth stage, and use an adaptive pooling layer to output a feature map of the expected dimension, while applying knowledge distillation in training to improve the performance of the network. We conducted experiments on the Market-1501 dataset, and the results indicate that the network model proposed in this paper can achieve 91.9% Rank-1 and 77.3% mAP, reducing the number of model parameters by 82% while maintaining high accuracy of the original model.},
booktitle = {Proceedings of the 2024 4th International Conference on Big Data, Artificial Intelligence and Risk Management},
pages = {612–616},
numpages = {5},
keywords = {Convolutional neural network, Deep learning, Lightweight network design, Person re-identification},
location = {
},
series = {ICBAR '24}
}

@inproceedings{10.1145/3490100.3516473,
author = {Suh, Sangho and An, Pengcheng},
title = {Leveraging Generative Conversational AI to Develop a Creative Learning Environment for Computational Thinking},
year = {2022},
isbn = {9781450391450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490100.3516473},
doi = {10.1145/3490100.3516473},
abstract = {We explore how generative conversational AI can assist students’ learning, creative, and sensemaking process in a visual programming environment where users can create comics from code. The process of visualizing code in terms of comics involves mapping programming language (code) to natural language (story) and then to visual language (of comics). While this process requires users to brainstorm code examples, metaphors, and story ideas, the recent development in generative models introduces an exciting opportunity for learners to harness their creative superpower and researchers to advance our understanding of how generative conversational AI can augment our intelligence in creative learning contexts. We provide an overview of our system and discuss interaction scenarios to demonstrate ways we can partner with generative conversational AI in the context of learning computer programming.},
booktitle = {Companion Proceedings of the 27th International Conference on Intelligent User Interfaces},
pages = {73–76},
numpages = {4},
keywords = {coding strip, comics, generative conversational AI, visual programming environment},
location = {Helsinki, Finland},
series = {IUI '22 Companion}
}

@inproceedings{10.1145/3654777.3676399,
author = {Zhang, Hongbo and Chen, Pei and Xie, Xuelong and Lin, Chaoyi and Liu, Lianyan and Li, Zhuoshu and You, Weitao and Sun, Lingyun},
title = {ProtoDreamer: A Mixed-prototype Tool Combining Physical Model and Generative AI to Support Conceptual Design},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676399},
doi = {10.1145/3654777.3676399},
abstract = {Prototyping serves as a critical phase in the industrial conceptual design process, enabling exploration of problem space and identification of solutions. Recent advancements in large-scale generative models have enabled AI to become a co-creator in this process. However, designers often consider generative AI challenging due to the necessity to follow computer-centered interaction rules, diverging from their familiar design materials and languages. Physical prototype is a commonly used design method, offering unique benefits in prototype process, such as intuitive understanding and tangible testing. In this study, we propose ProtoDreamer, a mixed-prototype tool that synergizes generative AI with physical prototype to support conceptual design. ProtoDreamer allows designers to construct preliminary prototypes using physical materials, while AI recognizes these forms and vocal inputs to generate diverse design alternatives. This tool empowers designers to tangibly interact with prototypes, intuitively convey design intentions to AI, and continuously draw inspiration from the generated artifacts. An evaluation study confirms ProtoDreamer’s utility and strengths in time efficiency, creativity support, defects exposure, and detailed thinking facilitation.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {97},
numpages = {18},
keywords = {creativity support, generative AI, large-scale model, prototype},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3638530.3654348,
author = {Baeta, Francisco and Correia, Jo\~{a}o and Martins, Tiago and Machado, Penousal},
title = {Exploring Evolutionary Generators within Generative Adversarial Networks},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3654348},
doi = {10.1145/3638530.3654348},
abstract = {Since their introduction, Generative Adversarial Networks (GANs) have represented the bulk of approaches used in image generation. Before GANs, such approaches used Machine Learning (ML) exclusively to tackle the training problems inherent to GANs. However, in recent years, evolutionary approaches have been making a comeback, not only across the field of ML but in generative modelling specifically. Successes in GPU-accelerated Genetic Programming (GP) led to the introduction of the TGPGAN framework, which used GP as a replacement for the deep convolutional network conventionally used as a GAN generator. In this paper, we delve further into the generative capabilities of evolutionary computation within adversarial models and extend the study performed in TGPGAN to analyse other evolutionary approaches. Similarly to TGPGAN, the presented approaches replace the generator component of a Deep Convolutional GAN (DCGAN): one with a line-drawing Genetic Algorithm (GA) and another with a Compositional Pattern Producing Network (CPPN). Our comparison of generative performance shows that the GA used manages to perform competitively with the original framework. More importantly, this work showcases the viability of other evolutionary approaches other than GP for the purpose of image generation.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {251–254},
numpages = {4},
keywords = {evolutionary computation, genetic programming, generative adversarial networks, TGPGAN},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{10.1145/3691620.3694999,
author = {Li, Cong and Xu, Zhaogui and Di, Peng and Wang, Dongxia and Li, Zheng and Zheng, Qian},
title = {Understanding Code Changes Practically with Small-Scale Language Models},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3694999},
doi = {10.1145/3691620.3694999},
abstract = {Recent studies indicate that traditional techniques for understanding code changes are not as effective as techniques that directly prompt language models (LMs). However, current LM-based techniques heavily rely on expensive, large LMs (LLMs) such as GPT-4 and Llama-13b, which are either commercial or prohibitively costly to deploy on a wide scale, thereby restricting their practical applicability. This paper explores the feasibility of deploying small LMs (SLMs) while maintaining comparable or superior performance to LLMs in code change understanding. To achieve this, we created a small yet high-quality dataset called HQCM which was meticulously reviewed, revised, and validated by five human experts. We fine-tuned state-of-the-art 7b and 220m SLMs using HQCM and compared them with traditional techniques and LLMs with ≥70b parameters. Our evaluation confirmed HQCM's benefits and demonstrated that SLMs, after finetuning by HQCM, can achieve superior performance in three change understanding tasks: change summarization, change classification, and code refinement. This study supports the use of SLMs in environments with security, computational, and financial constraints, such as in industry scenarios and on edge devices, distinguishing our work from the others.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {216–228},
numpages = {13},
keywords = {code change, code review, language model, LLM, SLM},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3604930.3605705,
author = {Chien, Andrew A and Lin, Liuzixuan and Nguyen, Hai and Rao, Varsha and Sharma, Tristan and Wijayawardana, Rajini},
title = {Reducing the Carbon Impact of Generative AI Inference (today and in 2035)},
year = {2023},
isbn = {9798400702426},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604930.3605705},
doi = {10.1145/3604930.3605705},
abstract = {Generative AI, exemplified in ChatGPT, Dall-E 2, and Stable Diffusion, are exciting new applications consuming growing quantities of computing. We study the compute, energy, and carbon impacts of generative AI inference. Using ChatGPT as an exemplar, we create a workload model and compare request direction approaches (Local, Balance, CarbonMin), assessing their power use and carbon impacts.Our workload model shows that for ChatGPT-like services, inference dominates emissions, in one year producing 25x the carbon-emissions of training GPT-3. The workload model characterizes user experience, and experiments show that carbon emissions-aware algorithms (CarbonMin) can both maintain user experience and reduce carbon emissions dramatically (35%). We also consider a future scenario (2035 workload and power grids), and show that CarbonMin can reduce emissions by 56%. In both cases, the key is intelligent direction of requests to locations with low-carbon power. Combined with hardware technology advances, CarbonMin can keep emissions increase to only 20% compared to 2022 levels for 55x greater workload. Finally we consider datacenter headroom to increase effectiveness of shifting. With headroom, CarbonMin reduces 2035 emissions by 71%.},
booktitle = {Proceedings of the 2nd Workshop on Sustainable Computer Systems},
articleno = {11},
numpages = {7},
keywords = {geographic shifting, large language models, carbon emissions, sustainability, generative AI},
location = {Boston, MA, USA},
series = {HotCarbon '23}
}

@inproceedings{10.1145/3613904.3641951,
author = {Mim, Nusrat Jahan and Nandi, Dipannita and Khan, Sadaf Sumyia and Dey, Arundhuti and Ahmed, Syed Ishtiaque},
title = {In-Between Visuals and Visible: The Impacts of Text-to-Image Generative AI Tools on Digital Image-making Practices in the Global South},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641951},
doi = {10.1145/3613904.3641951},
abstract = {This paper joins the growing body of HCI work on critical AI studies and focuses on the impact of Generative Artificial Intelligence (GAI) tools in Bangladesh. While the West has started to examine the limitations and risks associated with these tools, their impacts on the Global South have remained understudied. Based on our interviews, focus group discussions (FGD), and social media-based qualitative study, this paper reports how popular text-to-image GAI tools (ex., DALL-E, Midjourney, Stable Diffusion, Firefly) are affecting various image-related local creative fields. We report how these tools limit the creative explorations of marginal artists, struggle to understand linguistic nuances, fail to generate local forms of art and architecture, and misrepresent the diversity among citizens in the image production process. Drawing from a rich body of work on critical image theory, postcolonial computing, and design politics, we explain how our findings are pertinent to HCI’s broader interest in social justice, decolonization, and global development.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {474},
numpages = {18},
keywords = {Architecture, Art, Artificial Intelligence, Generative AI, Image, Urban Design},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3674225.3674326,
author = {Niu, Yuzhe and Liu, Li and Sha, Feng and Li, Lin},
title = {Optimized dependency-aware task offloading and resource allocation via multi-stage Imitation Learning in mobile edge computing},
year = {2024},
isbn = {9798400716638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674225.3674326},
doi = {10.1145/3674225.3674326},
abstract = {In the realm of mobile edge computing, the energy consumption and stability of offloading can be significantly influenced by random task arrivals and constraints imposed by task dependencies. To address this challenge, this study proposes a Multi-stage Generative Adversarial Imitation Learning (Multi-stage GAIL) algorithm. This algorithm engages in multi-stage continuous optimization to handle the offloading and allocation processes of dependent tasks. By integrating a simulation system, the algorithm effectively disentangles dependency relationships and generates a queue of tasks ready for execution. It obtains the optimal decision in multiple stages, effectively addressing the impact of the random task arrivals and dependency constraints on task offloading and allocation. Consequently, it leads to enhancements in system performance compared to the baseline algorithm.},
booktitle = {Proceedings of the 2024 International Conference on Power Electronics and Artificial Intelligence},
pages = {560–565},
numpages = {6},
location = {Xiamen, China},
series = {PEAI '24}
}

@article{10.1145/3689040,
author = {Bomba, Federico and Men\'{e}ndez-Blanco, Mar\'{\i}a and Grigis, Paolo and Cremaschi, Michele and De Angeli, Antonella},
title = {The Choreographer-Performer Continuum: A Diffraction Tool to Illuminate Authorship in More Than Human Co-Performances},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {6},
issn = {1073-0516},
url = {https://doi.org/10.1145/3689040},
doi = {10.1145/3689040},
abstract = {The design of robust and trustworthy Generative AI (GenAI) requires a deep understanding of the agencies emerging from human interactions with them. To contribute to this goal, we retrospectively studied an art project involving a visual artist, a computer scientist, an artistic director, and a generative model (GPT-2). The model was fine-tuned with trip reports describing the experience of eating psychedelic mushrooms. Building on agential realism, we analysed the co-performance between the artist and the model as their agency moved along the choreographer-performer continuum. Results reveal ontological surprises, leading to the proposal of entangled authorship to de-individualise the production of knowledge from a More Than Human perspective. The paper illustrates how art can expose different forms of relationships, challenging the idea of GenAI as just a tool that simplifies or replaces human labour. We conclude by emphasising the transformational potential of GenAI for novel modes of engagement between humans and machines.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = dec,
articleno = {75},
numpages = {23},
keywords = {Agency, Agential Realism, Large Language Models, AI and Art, Creative AI, Hallucination}
}

@inproceedings{10.1145/3614419.3644000,
author = {Torricelli, Maddalena and Martino, Mauro and Baronchelli, Andrea and Aiello, Luca Maria},
title = {The Role of Interface Design on Prompt-mediated Creativity in Generative AI},
year = {2024},
isbn = {9798400703348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614419.3644000},
doi = {10.1145/3614419.3644000},
abstract = {Generative AI for the creation of images is becoming a staple in the toolkit of digital artists and visual designers. The interaction with these systems is mediated by prompting, a process in which users write a short text to describe the desired image’s content and style. The study of prompts offers an unprecedented opportunity to gain insight into the process of human creativity. Yet, our understanding of how people use them remains limited. We analyze more than 145,000 prompts from the logs of two Generative AI platforms (Stable Diffusion and Pick-a-Pic) to shed light on how people explore new concepts over time, and how their exploration might be influenced by different design choices in human-computer interfaces to Generative AI. We find that users exhibit a tendency towards exploration of new topics over exploitation of concepts visited previously. However, a comparative analysis of the two platforms, which differ both in scope and functionalities, reveals some stark differences. Features diverting user focus from prompting and providing instead shortcuts for quickly generating image variants are associated with a considerable reduction in both exploration of novel concepts and detail in the submitted prompts. These results carry direct implications for the design of human interfaces to Generative AI and raise new questions regarding how the process of prompting should be aided in ways that best support creativity.},
booktitle = {Proceedings of the 16th ACM Web Science Conference},
pages = {235–240},
numpages = {6},
keywords = {Pick-a-Pic, Prompting, Stable Diffusion, creativity, explore-exploit},
location = {Stuttgart, Germany},
series = {WEBSCI '24}
}

@inproceedings{10.1145/3706598.3713528,
author = {Zhang, Hongbo and Chen, Pei and Yang, Jingwen and Wu, Yifei and Jiang, Zhaoqu and Xie, Xuelong and You, Weitao and Sun, Lingyun},
title = {IEDS: Exploring an Intelli-Embodied Design Space Combining Designer, AR, and GAI to Support Industrial Conceptual Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713528},
doi = {10.1145/3706598.3713528},
abstract = {Conceptual design is an important stage in industrial product development, influenced by the design space and materials available to designers. Advancements in human-computer interaction&nbsp;(HCI) and artificial intelligence&nbsp;(AI) technologies have broadened these aspects considerably. On the one hand, augmented reality&nbsp;(AR) technologies merge physical and virtual representations to enhance intuitive interaction and embodied cognition. On the other hand, generative artificial intelligence&nbsp;(GAI) serves as a novel design material, boosting creativity and productivity. Inspired by these technological strides, we proposed an Intelli-Embodied Design Space&nbsp;(IEDS), which integrates designers, AR, and GAI to support industrial conceptual design by combining embodied interaction with generative variability. Within IEDS, designers can interact with the physical prototypes intuitively, while GAI refines these into virtual forms that can be embedded in the physical world through AR technology. In this study, we established the theoretical framework and interaction modes of IEDS through literature reviews and expert interviews. Subsequently, we designed and implemented three GAI+AR tools, GAI + Head-mounted Display&nbsp;(HMD), GAI + Handheld Display&nbsp;(HHD), and GAI + Spatial Augmented Reality&nbsp;(SAR), based on three AR approaches in IEDS to practically examine the benefits and challenges of these interaction modes across industrial conceptual design tasks. We discussed IEDS’s influence on industrial conceptual design and released its application guidelines to the HCI community.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {33},
numpages = {25},
keywords = {conceptual design, augmented reality, generative AI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3673277.3673352,
author = {Jiao, Fangyu and Yu, Bei and Chen, Lang and Chen, Dunkui},
title = {A Bibliometric Analysis of Papers on Generative Adversarial Networks},
year = {2024},
isbn = {9798400716959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673277.3673352},
doi = {10.1145/3673277.3673352},
abstract = {Generative Adversarial Network (GAN) is a powerful generative model based on deep learning. At present, it is widely used in computer vision, natural language processing, semi-supervised learning and other fields, and has achieved remarkable results. This paper adopts the bibliometric analysis method, and uses InCites and VOSviewer tools to quantitatively study and visualize the papers of generative adversarial networks. Through the analysis and comparison of countries, institutions, and researchers, a comprehensive portrait of the academic achievements in the field of GAN is portrayed: GAN research reached a peak in 2021; Deep learning, Super-Resolution, Face Recognition, Image Enhancement, Speech Recognition, Object Tracking, Intrusion Detection are hotspots; China and the United States have published the most papers; Chinese institutions lack both international and corporate cooperation, and Chinese researchers need more innovative research on theories.},
booktitle = {Proceedings of the 2024 3rd International Conference on Cryptography, Network Security and Communication Technology},
pages = {434–439},
numpages = {6},
location = {Harbin, China},
series = {CNSCT '24}
}

@inproceedings{10.1145/3629606.3629620,
author = {Liu, Yunxing and Lee, Minha and Yang, Bin and Martens, Jean-Bernard},
title = {Low Code Conversation-based Hybrid UI Design Case Study and Reflection},
year = {2024},
isbn = {9798400716454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629606.3629620},
doi = {10.1145/3629606.3629620},
abstract = {This paper presents a comprehensive case study on the Q-Survey, a chatbot-based qualitative survey tool developed using the Double-Diamond design process. The study delves into the intricacies of balancing user experience (UX) with technical challenges inherent in chatbot development. A significant focus is placed on the role of Low Code (LC) and No Code (NC) tools in facilitating rapid prototype development and testing. While these tools offer agility and ease in the early stages, their limitations become evident as the complexity of the system grows, prompting a reflection on their continued utility in advanced development stages. The Repertory Grid Technique (RGT) is explored as a potential tool for online qualitative surveys, with discussions on its complexity and the potential enhancements using advanced Natural Language Processing (NLP) tools. Through the lens of the Q-Survey and experts’ evaluation of this case, we discuss the broader implications of LC tools in Human-Computer Interaction (HCI) design, emphasizing the need for a structured framework for HCI design with LC. The study concludes with reflections on the current design, potential future directions, and the importance of continuous exploration of LC, especially in the realm of LLMs and coding tools based on LLMs.},
booktitle = {Proceedings of the Eleventh International Symposium of Chinese CHI},
pages = {139–145},
numpages = {7},
keywords = {CUI, Chatbot, Low Code Development, Repertory Grid Tool.},
location = {Denpasar, Bali, Indonesia},
series = {CHCHI '23}
}

@inproceedings{10.1145/3706598.3713342,
author = {Halperin, Brett A. and Ru\'{\i}z, Diana Flores and Rosner, Daniela K.},
title = {Underground AI? Critical Approaches to Generative Cinema through Amateur Filmmaking},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713342},
doi = {10.1145/3706598.3713342},
abstract = {Amateurism (e.g., hobbyist and do-it-yourself making) has long helped human-computer interaction (HCI) scholars map alternatives to status quo technology developments, cultures, and practices. Following the 2023 Hollywood film worker strikes, many scholars, artists, and activists alike have called for alternative approaches to AI that reclaim the apparatus for co-creative and resistant means. Towards this end, we conduct an 11-week diary study with 20 amateur filmmakers of 15 AI-infused films, investigating the emerging space of generative cinema as a critical technical practice. Our close reading of the films and filmmakers’ reflections on their processes reveal four critical approaches to negotiating AI use in filmmaking: minimization, maximization, compartmentalization, and revitalization. We discuss how these approaches suggest the potential for underground filmmaking cultures to form around AI with critical amateurs reclaiming social control over the creative possibilities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1141},
numpages = {18},
keywords = {AI, AI Art, Amateurism, Bias, Creativity, Critical Humanistic Inquiry, Cinema, Cinematography, Critical Technical Practice, Film, Filmmaking, Generative AI, Non-Use, Storytelling, Underground Film, Video, Visual Storytelling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3583780.3614941,
author = {Naddaf, Parmis and Mahmoudzaheh Ahmadi Nejad, Erfaneh and Zahirnia, Kiarash and Jaeger, Manfred and Schulte, Oliver},
title = {Joint Link Prediction Via Inference from a Model},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614941},
doi = {10.1145/3583780.3614941},
abstract = {A Joint Link Prediction Query (JLPQ) specifies a set of links to be predicted, given another set of links as well as node attributes as evidence. While single link prediction has been well studied in literature on deep graph learning, predicting multiple links together has gained little attention. This paper presents a novel framework for computing JLPQs using a probabilistic deep Graph Generative Model. Specifically, we develop inference procedures for an inductively trained Variational Graph Auto-Encoder (VGAE) that estimates the joint link probability for any input JLPQ, without retraining. For evaluation, we apply inference to a range of joint link prediction queries on six benchmark datasets. We find that for most datasets and query types, joint link prediction via inference from a model achieves good predictive performance, better than the independent link prediction baselines (by 0.02-0.4 AUC points depending on the dataset).},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {1877–1886},
numpages = {10},
keywords = {link prediction, inference from a model, graph representation learning, graph convolutional networks},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@article{10.1145/3689636,
author = {Constantin, Mihai Gabriel and Stanciu, Dan-Cristian and \c{S}tefan, Liviu-Daniel and Dogariu, Mihai and Mih\u{a}ilescu, Dan and Ciobanu, George and Bergeron, Matt and Liu, Winston and Belov, Konstantin and Radu, Octavian and Ionescu, Bogdan},
title = {Exploring Generative Adversarial Networks for Augmenting Network Intrusion Detection Tasks},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1551-6857},
url = {https://doi.org/10.1145/3689636},
doi = {10.1145/3689636},
abstract = {The advent of generative networks and their adoption in numerous domains and communities have led to a wave of innovation and breakthroughs in AI and machine learning. Generative Adversarial Networks (GANs) have expanded the scope of what is possible with machine learning, allowing for new applications in areas such as computer vision, natural language processing, and creative AI. GANs, in particular, have been used for a wide range of tasks, including image and video generation, data augmentation, style transfer, and anomaly detection. They have also been used for medical imaging and drug discovery, where they can generate synthetic data to augment small datasets, reduce the need for expensive experiments, and lower the number of real patients that must be included in medical trials. Given these developments, we propose using the power of GANs to create and augment flow-based network traffic datasets. We evaluate a series of GAN architectures, including Wasserstein, conditional, energy-based, gradient penalty, and LSTM-GANs. We evaluate their performance on a set of flow-based network traffic data collected from 16 subjects who used their computers for home, work, and study purposes. The performance of these GAN architectures is described according to metrics that involve networking principles, data distribution among a collection of flows, and temporal data distribution. Given the tendency of network intrusion detection datasets to have a very imbalanced data distribution, i.e., a large number of samples in the “normal traffic” category and a comparatively low number of samples assigned to the “intrusion” categories, we test our GANs by augmenting the intrusion data and checking whether this helps intrusion detection neural networks in their task. We publish the resulting UPBFlow dataset and code on GitHub.1},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = dec,
articleno = {16},
numpages = {19},
keywords = {generative networks, network traffic, network flow}
}

@article{10.1145/3712710,
author = {Santos, Joana Cristo and Tom\'{a}s Pereira Alexandre, Hugo and Seoane Santos, Miriam and Henriques Abreu, Pedro},
title = {The Role of Deep Learning in Medical Image Inpainting: A Systematic Review},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3712710},
doi = {10.1145/3712710},
abstract = {Image inpainting is a crucial technique in computer vision, particularly for reconstructing corrupted images. In medical imaging, it addresses issues from instrumental errors, artifacts, or human factors. The development of deep learning techniques has revolutionized image inpainting, allowing for the generation of high-level semantic information to ensure structural and textural consistency in restored images. This article presents a comprehensive review of 53 studies on deep image inpainting in medical imaging, analyzing its evolution, impact, and limitations. The findings highlight the significance of deep image inpainting in artifact removal and enhancing the performance of multi-task approaches by localizing and inpainting regions of interest. Furthermore, the study identifies magnetic resonance imaging and computed tomography as the predominant modalities and highlights generative adversarial networks and U-Net as preferred architectures. Future research directions include the development of blind inpainting techniques, the exploration of techniques suitable for 3D/4D images, multiple artifacts, and multi-task applications, and the improvement of architectures.},
journal = {ACM Trans. Comput. Healthcare},
month = may,
articleno = {30},
numpages = {24},
keywords = {Artifact, Deep Learning, Image Inpainting, Medical Imaging, Multi-Task}
}

@inproceedings{10.1145/3706598.3714227,
author = {Inie, Nanna and Falk, Jeanette and Selvan, Raghavendra},
title = {How CO2STLY Is CHI? The Carbon Footprint of Generative AI in HCI Research and What We Should Do About It},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714227},
doi = {10.1145/3706598.3714227},
abstract = {The energy cost of developing and deploying Generative AI (GenAI) models has exploded with their mass adoption, as has the ensuing carbon emissions. The climate impact of this is currently unknown. In Human-Computer Interaction, GenAI models are rarely trained but often used. Based on detailed review of 282 papers, we estimate this footprint from energy consumption of the total use of GenAI for CHI 2024 research as between 10,769.63 and 10,925.12 kg CO2e — equal to driving a car for more than 100,000 km. We show that in CHI research, GenAI is most often used for Prototyping, Evaluation &amp; User studies, and that Data Collection and Fine-tuning models incurs the highest CO2st.1 We find that CHI submissions are unlikely to report GenAI use transparently, which makes precise calculations difficult. By measuring the usage of a subset of the papers on local hardware, we obtain estimations of the energy consumption and carbon footprint. Based on this evidence, we discuss and demonstrate ways to mitigate the issues of GenAI carbon footprint and lack of transparency.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {206},
numpages = {29},
keywords = {carbon footprint, energy consumption, Environmental Sustainability, Generative AI, AI Hype},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3609395.3610594,
author = {Zhang, Xuechen and Li, Zheng and Oymak, Samet and Chen, Jiasi},
title = {Text-to-3D Generative AI on Mobile Devices: Measurements and Optimizations},
year = {2023},
isbn = {9798400703034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609395.3610594},
doi = {10.1145/3609395.3610594},
abstract = {Emerging generative models can create 3D objects from text prompts. However, deploying these models on mobile devices is challenging due to resource constraints and user demand for real-time performance. We take a first step towards understanding the bottlenecks by performing a measurement study of three recent text-to-3D generative models (Point-E, Shap-E, and CLIP-Mesh) in terms of their runtime GPU memory usage, latency, and synthesis quality. We investigate the effectiveness of quantization and distillation techniques to overcome these challenges by speeding up inference execution, potentially at the expense of quality. We find that the Shap-E model is promising for mobile deployment, but requires further optimization in its bottleneck diffusion step for real-time performance, as well as reduced memory usage and load times. Further work is needed on custom optimizations for generative text-to-3D models, including targeting specific metrics at each computation stage, efficient representations of 3D objects, and adaptive network and system support for resource-hungry models.},
booktitle = {Proceedings of the 2023 Workshop on Emerging Multimedia Systems},
pages = {8–14},
numpages = {7},
keywords = {GPU memory, latency, mobile devices, generative AI, text-to-3D},
location = {New York, NY, USA},
series = {EMS '23}
}

@inproceedings{10.1145/3672758.3672763,
author = {Peng, Li and Fu, Bihan},
title = {Development and Research of Generative Animation Based on AIGC},
year = {2024},
isbn = {9798400716942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672758.3672763},
doi = {10.1145/3672758.3672763},
abstract = {AIGC is the automatic generation of relevant content from a large number of models and databases based on the input of relevant instructions. This paper mainly discusses the development of artificial intelligence generation technology in animation in the form of images. With the rapid development of artificial intelligence technology, generative animation content has become an important way of animation production and production in modern society. Artificial intelligence-based generative animation is taking up an increasing proportion of the film, game, advertising and other industries, AIGC has been rapidly developed by virtue of its lower production cost and higher production efficiency, which constantly impacts the development of the animation industry and attracts the widespread attention of animation creators. This paper analyses the Generative Adversarial Network and Diffusion Model through the deep learning principle of AIGC technology, and explores the important impact of AIGC technology on the form of generative animation. Using computer discipline thinking to analyse the type of AIGC model for animation creation, and according to the model simulation results of AIGC technology used in generative animation production of technology, market aspects of its development prospects are summarised.},
booktitle = {Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering},
pages = {22–28},
numpages = {7},
location = {Xi' an, China},
series = {CAICE '24}
}

@inproceedings{10.1145/3527927.3532801,
author = {Jonsson, Martin and Tholander, Jakob},
title = {Cracking the code: Co-coding with AI in creative programming education},
year = {2022},
isbn = {9781450393270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3527927.3532801},
doi = {10.1145/3527927.3532801},
abstract = {This paper presents a study of a group of university students using generative machine learning to translate from natural language to computer code. The study explores how the use of the AI tool can be understood in terms of co-creation, focusing on the one hand on how the tool may serve as a resource for understanding and learning, and on the other hand how the tool affects the creative processes. Findings show how the participants search for a ’correct’ syntax in their instructions to the machine learning tool, and how the inconsistent and erroneous behavior can work as a way to generate clues and inspiration for generating creative expressions. The notion of friction is used to describe how systems like this can serve to both lower thresholds for programming, and also interfere with the creative processes, encouraging reflection and exploration of alternative solutions.},
booktitle = {Proceedings of the 14th Conference on Creativity and Cognition},
pages = {5–14},
numpages = {10},
keywords = {programming, post-human design, generative machine learning, co-creation, GPT-3},
location = {Venice, Italy},
series = {C&amp;C '22}
}

@inproceedings{10.1145/3675888.3676033,
author = {Pramod, Dhanya and Patil, Kanchan Pranay},
title = {Generative AI for Elderly Well-being through the Computer as Social Actor Paradigm},
year = {2024},
isbn = {9798400709722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675888.3676033},
doi = {10.1145/3675888.3676033},
abstract = {Artificial intelligence and machine learning (AI/ML) technologies like generative AI solutions are proliferating in the real-world healthcare sector. The purpose of this research is to investigate social norms, expectations, and standards of the elderly population for improving trust relationships while interacting with generative AI. The study is based on the CASA paradigm to gain a better understanding of the trust dynamics in human-computer communication to improve the adoption of GAI for elders' health and well-being. We validated the conceptual model with empirical data from 287 elderly users collected through an online and offline survey tool. Quantitative responses received were analysed using structural equation modeling. The study highlights how multimodal interaction, empathy, personalization, augmentation, bias stereotyping, and privacy and security affect the extent to which elderly consumers perceive GAI as trustworthy. Findings indicate that multimodal interaction, personalization, augmentation, and bias stereotyping significantly influenced the trust relationship between the elderly population and GAI. However, empathy privacy, and security were found to be insignificant in trust relationships. Further trust relationships significantly impacted GAI usage. The research provides strong theoretical and practical implications as all the stakeholders like healthcare professionals, patients/users, caregivers, and technology developers can be involved in building applications that cater to diverse needs and promote positive social interactions that can enhance GAI trust and usage.},
booktitle = {Proceedings of the 2024 Sixteenth International Conference on Contemporary Computing},
pages = {65–72},
numpages = {8},
location = {Noida, India},
series = {IC3-2024}
}

@inproceedings{10.1145/3706599.3706734,
author = {Glazko, Kate S and Huh, Mina and Johnson, Jazette and Pavel, Amy and Mankoff, Jennifer},
title = {Generative AI and Accessibility Workshop: Surfacing Opportunities and Risks},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706734},
doi = {10.1145/3706599.3706734},
abstract = {The increasing use of generative AI (GAI) as an accessibility tool offers transformative opportunities, but it also introduces significant risks and barriers that remain unaddressed. This workshop explores the multi-faceted nature of GAI use for accessibility, focusing on its potential to create access solutions where none exist while surfacing the risks of bias, inaccessibility, and misinformation. Our goal is to establish best practices for inclusive GAI design that centers disabled people’s agency, addressing key questions such as how to ensure GAI tools are accessible by default and how to mitigate risks without undermining autonomy. By bringing together experts in accessibility, AI, human-computer interaction (HCI), and disability studies, this workshop aims to develop design guidelines, recommendations, and practices that will influence future GAI systems. Participants will collaboratively define an agenda for creating GAI tools that advance equity, minimize harm, and embrace the diverse needs of the disability community.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {783},
numpages = {6},
keywords = {Generative AI, Accessibility, Accessibility technologies},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3610978.3640742,
author = {Chang, Yu-Wen and Chien, Shih-Yi and Chan, Yao-Cheng and Tsao, Ching-Chih},
title = {Human-Robot Interaction in E-Commerce: The Role of Personality Traits and Chatbot Mechanisms - A Neuromarketing Research},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3640742},
doi = {10.1145/3610978.3640742},
abstract = {This paper explores the intersection of neuromarketing, e-commerce, and human-robot interaction by investigating the impact of personality traits on user satisfaction, purchase intention, and brainwave patterns across different chatbot models (rule-Based vs generative AI) and platforms (virtual chatbots vs humanoid robots). The study introduces Generative AI chatbots to e-commerce websites, comparing their effectiveness with rule-based chatbots. Additionally, physical robots are included as a reference group to assess the effects of virtual and physical robots in shopping assistance. The manipulation of three personality traits (introvert, ambivert, and extrovert) in both online and offline settings enriches the understanding of user behavior in diverse scenarios. Data collection involves EEG measurements, system logs, and surveys to capture subjective perceptions, unconscious reactions, and decision-making processes. Ultimately, the research seeks to provide valuable insights for the development of human-computer interaction design, contributing to the formulation of design guidelines adapted specifically for the e-commerce landscape.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {312–316},
numpages = {5},
keywords = {electroencephalogram (EEG), generative AI, human-robot interaction, neuromarketing, personality traits},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3600211.3604744,
author = {Affsprung, Daniel},
title = {The ELIZA Defect: Constructing the Right Users for Generative AI},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604744},
doi = {10.1145/3600211.3604744},
abstract = {Artificial intelligence (AI) is at the center of debates on what kind of future we want and how to bring it about. But AI ethics is not only a technical risk assessment and accounting effort, or an application of general principles to stable artifacts. It is also a social self-diagnosis, a contested and contestable assertion of values and desirable futures, and a selective understanding of the nature of AI in its different forms. In expressions of concern and efforts at preparation for increasingly powerful AI tools, we can trace the ways we imagine ourselves and our society to be compatible with AI's promises and susceptible to its dangers. The problems we notice, and the solutions we offer, arise from the interaction of these imagined elements.The socially embedded efficacy of AI tools leads many commentators to imagine their risks specifically in conjunction with understandings of society as it currently is and imaginations of how it can and should exist in the future [1]. The sense-making moves performed in the wake of developments in generative AI are thus a site to examine the movement and uses of different concepts brought together in this domain: the human, rationality, and the place of expertise. As these sense-making efforts are carried out, they become constraints on how the risks of generative AI can be noticed and understood.The problems raised by generative AI are so fundamentally tied to its performance as a simulator of human interpersonal acts that we should ask: where is the risk of generative AI located, such that the utility and the safety of the tools can be preserved after troubling cases? Boundaries between malicious deception and magnificent design are unclear without an answer to this question. Thus, to fit generative AI into our world, we are trying to answer it; this is one goal of efforts at regulation which seeks to allow the benefits of imitation to arrive while avoiding the harms of deception. In the current regulation, reporting, and corporate responses to generative AI, the challenge of safely introducing generative AI is being approached in large part as a challenge of producing the right kind of knowledge in its users.Below is a summary of my findings from three cases, chosen to investigate the following question: What ways, or whose ways, of using, knowing, and understanding generative AI are being offered as appropriate? I examine the EU AI Act language reflecting disclosure requirements for interactions with generative AI, responses to a chatbot-facilitated suicide in Belgium, and reactions to expert claims of a chatbot's sentience. In the first two cases, AI-generated content is problematic insofar as users are uninformed about its provenance or maliciously deceived by it, while users who know they are interacting with AI but behave problematically are designated as deluded or irrational. In the third case, a Google engineer who presents evidence to support claims that AI is sentient is censured as nationwide reporting denounces his claim against an expert consensus from which he is ejected. In all three cases, challenges facing widespread generative AI development and use are avoided by attending to the knowledge and understanding of those who use them rather than the functioning of the tools themselves.The EU AI Act is illuminating as a general and authoritative account of how AI interactions can be made safe, requiring first and foremost that users are informed. [2, 3] The AI Act is useful in the present paper as it shows the effort to match and reconcile a new technology with an extant set of values, chief among which is autonomy. Its reliance on disclosure reflects a general sense that harms are acceptable or unacceptable not on the basis of outcomes but based on the degree of autonomy possessed by the actors in question. Rational actors in a simulated environment are responsible for the effects of the simulation, so long as they are informed of the nature of that environment and have essentially consented to consume deceptive or false content. The other two cases I examine explore this very issue, of problematic understandings and behavior on the part of knowing users.The first of these is the case of the Belgian man. After his suicide responses from the company which provided the chatbot, media [4, 5, 6] and government [5], and prominent expert AI ethics commentary [7] characterized it as arising because the user was vulnerable and consequently did not relate to the bot in the right way. While the chatbot's emotionally charged language was seen as a part of the problem, in the reporting on this event the unanimous emphasis on the man's mental state presents the risk as arising in an interaction, in a pathological mistake of the user, rather than in the tool.Locating risk is a necessary and immensely powerful, if often unexamined step which precedes intervention in a worrisome state of affairs: where we locate risk is where we intervene. If the risk accompanying generative AI is located in the minds of uninformed or misapprehending users, disclosures and disclaimers are indeed sensible interventions. In this conception, when knowledge fails to protect the user, it is not a failed safeguard but a bad user. Problematizing user understandings in this way provides an exonerating resource for the companies providing these tools and suggests the rectitude of expert authority on the nature of these tools, by linking delays and dangers in generative AI to users who do not abide by the (strategically underdetermined) expert consensus on generative AI's accuracy, capabilities, and nature.My third case examines how the expert consensus around generative AI is maintained through the story of Blake Lemoine, who publicly announced his belief that Google's LaMDA model had become sentient and was presented by major media outlets and experts as deluded [8, 9, 10, 11, 12, 13]. In the media and corporate response to Lemoine, wherein Google questioned his sanity before firing him [13], we see his ejection from the community of experts permitted to call for greater scrutiny based on qualitative changes in the nature of these models. He becomes a layperson on account of his anthropomorphizing error. In this act of boundary work [14], policing who is in the body of experts qualified to decide on the sentience of the chatbot, and the nature of AI models in general, we must notice how small this group truly is and what Lemoine's ejection preserves. If safeguards like those Lemoine called for should follow on the kind of change he claimed to detect, and those outside Google's leadership could determine when such changes have arrived, Google would cease to lead the conversation on regulation by defining the nature of its technology. This state of affairs leaves the right relations with generative AI underdetermined but maintains that positions which challenge the expert consensus are the result of misunderstandings so significant as to disqualify the concerned party's thoughts on the matter from rational consideration. In the three cases examined here, events and concerns which threaten to depict generative AI as in need of significant scrutiny or changes are defused not by intervening in the company's technology, but by delineating between user understandings which are empowered and exploitative, safe and vulnerable, rational and deluded.Named after an early chatbot, the ELIZA effect refers to the readiness with which users anthropomorphize computer systems [15]. Reporting on both Lemoine [11] and the Belgian man cited this effect [6]. The chatbot which encouraged the Belgian man to commit suicide was named Eliza. One way of summarizing the change I trace in the cases described above is a transition away from the Turing test and towards the ELIZA effect as the conceptual frame for AI which imitates humans. While the Turing test implies the layperson's relevance to the discussion and regulation of AI, the ELIZA effect implies their irrelevance.This project will continue as an effort to follow popular, expert, and regulatory perceptions of the risk of generative AI as the tools themselves and the public concern surrounding them continue to develop. The resources of science and technology studies (STS) enable crucial perspectives on numerous ways of thinking about AI and the challenges of its development and regulation such as the common citations of law lag, invocations of self-regulation in the mode of the Asilomar Conference on rDNA, collective action problem framings, and more. The STS literature on sociotechnical imaginaries [1] and public understandings of science [16] contribute to the present insight as to how the efforts of tech-society reconciliation and risk-benefit balancing presented as appropriate for AI reveal and produce our understandings of the technology, even as they reproduce and reshape social norms. There is an urgent need for work which extends this powerful scholarly tradition for understanding science, technology, and society to AI, as one of the most important and concerning technological developments of our moment.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {945–946},
numpages = {2},
keywords = {chatbots, expertise, generative AI, public understanding of science, science and technology studies},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

@inproceedings{10.1145/3588029.3595471,
author = {Tanaka, Kengo and Fushimi, Tatsuki and Tsutsui, Ayaka and Ochiai, Yoichi},
title = {Text to Haptics: Method and Case Studies of Designing Tactile Graphics for Inclusive Tactile Picture Books by Digital Fabrication and Generative AI},
year = {2023},
isbn = {9798400701535},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588029.3595471},
doi = {10.1145/3588029.3595471},
abstract = {In this case study, we explore the possibilities between Generative AI and tactile graphics for inclusivity in computer graphics communities. The use of Generative AI in the design of tactile graphics has made it possible to support the processes used by publishers and tactile graphics designers. In addition, the idea of printing tactile graphics on transparent sheets with a 3D printer through digital fabrication technology allows the creation of inclusive tactile picture books that can be read and enjoyed together by sighted and visually impaired people in a single picture book.},
booktitle = {ACM SIGGRAPH 2023 Labs},
articleno = {10},
numpages = {2},
keywords = {visual impairments, tactile picture books, tactile graphics, generative ai, 3D printing},
location = {Los Angeles, CA, USA},
series = {SIGGRAPH '23}
}

@inproceedings{10.1145/3615522.3615548,
author = {Zhang, Yang and Li, Jie and Xu, Chao},
title = {Graph-based Latent Space Traversal for New Molecules Discovery},
year = {2023},
isbn = {9798400707513},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615522.3615548},
doi = {10.1145/3615522.3615548},
abstract = {Generative models provide an efficient way to analyze and understand unlabeled data, creating the latent space for data modeling and generation. Since the interpretation of latent space usually requires implicit expert knowledge, this human-centered feature makes visual analytic methods effective. In the filed of computer chemistry, some research have applied generative models to generate chemical spaces and generated new molecules by sampling in the latent space. However, the latent space is typically high and sparse, and there may be a large number of “dead zones”, which may lead to decoding sample points from the latent space are noisy or invalid. Therefore, it is extremely challenging to efficiently search and traverse the latent space and generate new molecules with the desired properties. This paper aims to propose a visualization system for interactive exploration of latent space, which inspires the researchers to design new potential molecules with desired properties. The main work of this paper is as follows: First, we investigate a series of literature on the application of generative networks to drug design and synthesis, and interview experts with computer chemistry background to summarize the requirements and tasks. Second, based on the above requirements and tasks, we propose a graph-based latent space traversal and interpolation algorithms and neighborhood sampling algorithms. This can improve the number of generated potential molecules and the speed of discovery of similar molecules. Then, we conduct comparison experiments to verify the effectiveness of the algorithms. Finally, we design visualization system and then conduct the case study and user study to verify the effectiveness of the visualization system.},
booktitle = {Proceedings of the 16th International Symposium on Visual Information Communication and Interaction},
articleno = {26},
numpages = {8},
keywords = {visual analysis, latent space, generative model, chemical drug design and synthesis},
location = {Guangzhou, China},
series = {VINCI '23}
}

@inproceedings{10.1145/3664647.3681699,
author = {Yiyang, Luo and Lin, Ke and Gu, Chao},
title = {Context-Aware Indoor Point Cloud Object Generation through User Instructions},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681699},
doi = {10.1145/3664647.3681699},
abstract = {Indoor scene modification has emerged as a prominent area within computer vision, particularly for its applications in Augmented Reality (AR) and Virtual Reality (VR). Traditional methods often rely on pre-existing object databases and predetermined object positions, limiting their flexibility and adaptability to new scenarios. In response to this challenge, we present a novel end-to-end multi-modal deep neural network capable of generating point cloud objects seamlessly integrated with their surroundings, driven by textual instructions. Our work proposes a novel approach in scene modification by enabling the creation of new environments with previously unseen object layouts, eliminating the need for pre-stored CAD models. Leveraging Point-E as our generative model, we introduce innovative techniques such as quantized position prediction and Top-K estimation to address the issue of false negatives resulting from ambiguous language descriptions. Furthermore, we conduct comprehensive evaluations to showcase the diversity of generated objects, the efficacy of textual instructions, and the quantitative metrics, affirming the realism and versatility of our model in generating indoor objects. To provide a holistic assessment, we incorporate visual grounding as an additional metric, ensuring the quality and coherence of the scenes produced by our model. Through these advancements, our approach not only advances the state-of-the-art in indoor scene modification but also lays the foundation for future innovations in immersive computing and digital environment creation. The project is available at https://ainnovatelab.github.io/Context-aware-Indoor-PCG.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {10182–10190},
numpages = {9},
keywords = {3d point clouds, deep learning, generative model},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3676151.3719379,
author = {Wallace, Tom and Ombuki-Berman, Beatrice and Ezzati-Jivan, Naser},
title = {Optimization Strategies for Enhancing Resource Efficiency in Transformers &amp; Large Language Models},
year = {2025},
isbn = {9798400710735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676151.3719379},
doi = {10.1145/3676151.3719379},
abstract = {Advancements in Natural Language Processing are heavily reliant on Transformer architectures, whose improvements come at substantial resource costs due to ever-growing model sizes. This study explores optimization techniques, including quantization, knowledge distillation, and pruning, focusing on energy and computational efficiency while retaining performance. Among standalone methods, 4-Bit quantization significantly reduces energy use with minimal accuracy loss. Hybrid approaches, like NVIDIA's Minitron approach combining KD and structured pruning, further demonstrate promising trade-offs between size reduction and accuracy retention. A novel optimization framework is introduced, offering a flexible framework for comparing various methods. Through the investigation of these compression methods, we provide valuable insights for developing more sustainable and efficient LLMs, shining a light on the often-ignored concern of energy efficiency.},
booktitle = {Proceedings of the 16th ACM/SPEC International Conference on Performance Engineering},
pages = {105–112},
numpages = {8},
keywords = {energy efficiency, model compression, natural language processing, time efficiency},
location = {Toronto ON, Canada},
series = {ICPE '25}
}

@article{10.1145/3584019,
author = {M, Diviya and A, Karmel},
title = {TAM GAN: Tamil Text to Naturalistic Image Synthesis Using Conventional Deep Adversarial Networks},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {5},
issn = {2375-4699},
url = {https://doi.org/10.1145/3584019},
doi = {10.1145/3584019},
abstract = {Text-to-image synthesis has advanced recently as a prospective area for improvement in computer vision applications. The image synthesis model follows significant neural network architectures such as Generative Adversarial Networks (GANs). The flourishing text-to-image generation approaches can nominally reflect the meaning of the text in generated images. Still, they need the prospect of providing the necessary details and eloquent object features. Intelligent systems are trained in text-to-image synthesis applications for various languages. However, their contribution to regional languages is yet to be explored. Autoencoders prompt the synthesis of images, but they result in blurriness, which results in clear output and essential features of the picture. Based on textual descriptions, The GAN model is capable of producing realistic images of a high quality that can be used in various applications, like fashion design, photo editing, computer-aided design, and educational platforms. The proposed method uses two-stage processing to create a language model using a BERT model called TAM-BERT and an existing MuRIL BERT, followed by image synthesis using a GAN. The work was conducted using the Oxford-102 dataset, and the model's efficiency was evaluated using the F1-Score measure.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = may,
articleno = {128},
numpages = {18},
keywords = {latent vectors, feature matching, L1Norm, language model, MuRIL BERT, BERT, Generative Adversarial Network (GAN), Computer vision}
}

@inproceedings{10.1145/3703001.3724386,
author = {Orland, Fabian and Nista, Ludovico and Kocher, Nick and Vanvinckenroye, Joris and Pitsch, Heinz and Terboven, Christian},
title = {Efficient and Scalable AIxeleration of Reactive CFD Solvers Coupled with Deep Learning Inference on Heterogeneous Architectures},
year = {2025},
isbn = {9798400713422},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703001.3724386},
doi = {10.1145/3703001.3724386},
abstract = {The convergence of high-performance computing (HPC) and artificial intelligence (AI) is transforming numerical simulations across various scientific domains. In reactive flow simulations, deep learning (DL) techniques, are emerging as promising alternatives to traditional closure models in large eddy simulations (LES). Although a priori investigations –where models are tested on pre-existing datasets – have demonstrated remarkable performance, a posteriori investigations – which assess model behavior within a running simulation – remain crucial to ensuring stability and accuracy. To bridge this gap, seamless integration between computational fluid dynamics (CFD) solvers and widely used DL frameworks, such as PyTorch or TensorFlow is required. However, traditional CFD solvers are highly optimized for CPU execution, whereas DL inference benefits from acceleration on GPUs or other specialized hardware. This architectural mismatch presents a significant challenge in efficiently leveraging modern heterogeneous HPC platforms.To address this issue, we introduce AIxeleratorService, an open-source C++ library designed to enable efficient deployment of DL models within highly parallel CFD solvers running on heterogeneous architectures. Additionally, we present a Fortran ML module that integrates AIxeleratorService, providing users of Fortran-based CFD solvers with a streamlined, end-to-end workflow for incorporating trained DL architectures into their simulations. We validate our approach by coupling AIxeleratorService with our in-house CFD solver, CIAO, and applying it to two LES configurations. In one, a super-resolution generative adversarial network (SRGAN) reconstructs the unresolved Reynolds stresses tensor to correctly account for the momentum energy transport. On the other, a UNet-type architecture computes the source term of the progress variable equation, which is essential for accurately describing the chemical reaction rate and flame propagation in turbulent combustion. To evaluate computational performance and scalability, we benchmark AIxeleratorService against the existing PhyDLL library on a heterogeneous HPC system comprising Intel Sapphire Rapids CPUs and NVIDIA H100 GPUs. Our results demonstrate that AIxeleratorService achieves superior computational efficiency and scalability, highlighting its potential for accelerating large-scale, AI-enhanced reactive flow simulations.},
booktitle = {Proceedings of the 2025 International Conference on High Performance Computing in Asia-Pacific Region Workshops},
pages = {45–57},
numpages = {13},
keywords = {CFD, reactive flows, heterogeneous architectures, coupling, TensorFlow, super-resolution, GAN, UNet, PhyDLL, AIxeleratorService},
location = {
},
series = {HPC Asia '25 Workshops}
}

@inproceedings{10.1145/3664647.3681549,
author = {Li, Xueyang and Song, Yu and Lou, Yunzhong and Zhou, Xiangdong},
title = {CAD Translator: An Effective Drive for Text to 3D Parametric Computer-Aided Design Generative Modeling},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681549},
doi = {10.1145/3664647.3681549},
abstract = {Computer-Aided Design (CAD) generative modeling is widely applicable in the fields of industrial engineering. Recently, text-to-3D generation has shown rapid progress in point clouds, mesh, and other non-parametric representations. On the contrary, text to 3D parametric CAD generative modeling is a more appealing task in industry but has not been well explored. The parametric CAD model means the product shape can be defined by using the command sequences of CAD tools. To investigate this, we design an encoder-decoder framework, namely CAD Translator, for incorporating the embedding of parametric CAD sequences into texts appropriately with only one-stage training. We first align texts and parametric CAD sequences via a Cascading Contrastive Strategy in the latent space, and then we propose CT-Mix to conduct the random mask operation on their embeddings separately to further get a fusion embedding via the linear interpolation. This can strengthen the connection between texts and parametric CAD sequences effectively. To train CAD Translator, we build a Text2CAD dataset with the help of Large Multimodal Model (LMM) and conduct thorough experiments to demonstrate the effectiveness of our method.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {8461–8470},
numpages = {10},
keywords = {cad generative modeling, multi-modal learning, parametric cad sequence},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3702038.3702073,
author = {Gomes, Vinicius and Cunha, Jos\'{e} Adson and Lima, K\'{a}ssio and Moura, Hermano Perrelli},
title = {Nudge Evidence Briefing: A Proposal for Transferring Scientific Knowledge about Nudges},
year = {2024},
isbn = {9798400712241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702038.3702073},
doi = {10.1145/3702038.3702073},
abstract = {A nudge is a concept from Behavioral Economics and Psychology that refers to any small change or intervention designed to influence people's behavior predictably, without restricting their options or significantly altering their incentives. The research follows the Design Science Research methodology, introducing Nudge Evidence Briefing (NEB) to facilitate the understanding, access, application of academic findings on nudges for non-academic professionals, considering the gap between academic research on nudges and their practical application. Leveraging insights from the Evidence-Based Medicine framework, NEBs distill key findings from primary research into concise, accessible documents. Through a systematic review of the literature on nudge integration into software privacy and security, 12 primary studies were selected and the data extracted from them was formatted into NEBs. Participants, specialists and non-specialists, were invited to evaluate the NEB through online questionnaires. Feedback highlighted the clarity and structured format of the NEB, with particular praise for its ability to communicate complex scientific evidence in an accessible way. Overall, the NEB demonstrates significant promise in making nudge-related research more accessible and feasible. Ongoing refinements based on participant feedback will be crucial to realizing its full potential, contributing to the advancement of Human-Computer Interaction (HCI) and the practical application of nudges in professional environments. Future work will focus on evaluating the practical applicability of the NEB with non-academic professionals, exploring more reliable alternatives for generating NEBs through LLM, and developing a comprehensive repository of NEBs.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {35},
numpages = {11},
keywords = {Evidence Briefing, Knowledge Transfer, Nudge, Privacy, Security},
location = {
},
series = {IHC '24}
}

@inproceedings{10.1145/3660395.3660476,
author = {Zhou, Ruiyu and Cui, Dongjin},
title = {Dispersion prediction of pollutants in settlements based on generative adversarial networks},
year = {2024},
isbn = {9798400716362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660395.3660476},
doi = {10.1145/3660395.3660476},
abstract = {Aiming at the traditional built environment pollutant study which is difficult to meet the requirements of rapid prediction, a data-driven pollutant dispersion prediction method at the neighbourhood scale is proposed. With reference to the data-driven fluid modelling approach, the research is carried out, based on the CFD simulation to collate and produce the relevant datasets with better adaptability to the real urban environment, build the data-driven pollutant diffusion model, compare the performance of three generative adversarial network Pix2Pix, CycleGAN, and Pix2PixHD models in real-time pollutant monitoring scenarios and further optimize the experiments based on the performance differences of each model. performance differences to further optimise the experiment. The experimental results show that the data-driven pollutant dispersion prediction model based on the generative adversarial network can approximate the CFD simulation results, realise the near real-time prediction of pollutant concentration distributions in settlements, and satisfy the scenarios with high requirements on computation time. The model stability improvement and dataset optimisation have positive gain on the model performance.},
booktitle = {Proceedings of the 2023 3rd Guangdong-Hong Kong-Macao Greater Bay Area Artificial Intelligence and Big Data Forum},
pages = {461–465},
numpages = {5},
location = {Guangzhou, China},
series = {AIBDF '23}
}

@inproceedings{10.5555/3545946.3598962,
author = {Li, Zun and Lanctot, Marc and McKee, Kevin R. and Marris, Luke and Gemp, Ian and Hennes, Daniel and Larson, Kate and Bachrach, Yoram and Wellman, Michael P. and Muller, Paul},
title = {Search-Improved Game-Theoretic Multiagent Reinforcement Learning in General and Negotiation Games},
year = {2023},
isbn = {9781450394321},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Multiagent reinforcement learning (MARL) has benefited significantly from population-based and game-theoretic training regimes. One approach, Policy-Space Response Oracles (PSRO), employs standard reinforcement learning to compute response policies via approximate best responses and combines them via meta-strategy selection. We augment PSRO by adding a novel search procedure with generative sampling of world states, and introduce two new meta-strategy solvers based on the Nash bargaining solution. We evaluate PSRO's ability to compute approximate Nash equilibrium, and its performance in negotiation games: Colored Trails and Deal-or-no-Deal. We conduct behavioral studies where human participants negotiate with our agents (N = 346). Search with generative modeling finds stronger policies during both training time and test time, enables online Bayesian co-player prediction, and can produce agents that achieve comparable social welfare negotiating with humans as humans trading among themselves.},
booktitle = {Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
pages = {2445–2447},
numpages = {3},
keywords = {alphazero, multiagent, nash bargaining solution, negotiation games, policy-space response oracles, reinforcement learning},
location = {London, United Kingdom},
series = {AAMAS '23}
}

@article{10.1145/3712303,
author = {Yoon, Hyung-Jin and Holmes, Ryan and Jafarnejadsani, Hamidreza and Voulgaris, Petros},
title = {Real-time Adversarial Image Perturbations for Autonomous Vehicles Using Reinforcement Learning},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
issn = {2378-962X},
url = {https://doi.org/10.1145/3712303},
doi = {10.1145/3712303},
abstract = {The deep neural network (DNN) model for computer vision tasks (object detection and classification) is widely used in autonomous vehicles, such as driverless cars and unmanned aerial vehicles. However, DNN models are shown to be vulnerable to adversarial image perturbations. The generation of adversarial examples against inferences of DNNs has been actively studied recently. The generation typically relies on optimizations taking an entire image frame as the decision variable. Hence, given a new image, the computationally expensive optimization needs to start over as there is no learning between the independent optimizations. Very few approaches have been developed for attacking online image streams while taking into account the underlying physical dynamics of autonomous vehicles, their mission, and the environment. The article presents a multi-level reinforcement learning framework that can effectively generate adversarial perturbations to misguide autonomous vehicles’ missions. In the existing image attack methods against autonomous vehicles, optimization steps are repeated for every image frame. This framework removes the need for fully converged optimization at every frame. Using multi-level reinforcement learning, we integrate a state estimator and a generative adversarial network that generates the adversarial perturbations. Due to the reinforcement learning agent consisting of state estimator, actor, and critic that only uses image streams, the proposed framework can misguide the vehicle to increase the adversary’s reward without knowing the states of the vehicle and the environment. Simulation studies and a robot demonstration are provided to validate the proposed framework’s performance.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = mar,
articleno = {14},
numpages = {24},
keywords = {image attack, object detection, autonomous vehicle, reinforcement learning}
}

@article{10.1109/TASLP.2024.3458796,
author = {Mo, Ying and Liu, Jiahao and Tang, Hongyin and Wang, Qifan and Xu, Zenglin and Wang, Jingang and Quan, Xiaojun and Wu, Wei and Li, Zhoujun},
title = {Multi-Task Multi-Attention Transformer for Generative Named Entity Recognition},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3458796},
doi = {10.1109/TASLP.2024.3458796},
abstract = {Most previous sequential labeling models are task-specific, while recent years have witnessed the rise of generative models due to the advantage of unifying all named entity recognition (NER) tasks into the encoder-decoder framework. Although achieving promising performance, our pilot studies demonstrate that existing generative models are ineffective at detecting entity boundaries and estimating entity types. In this paper, we propose a multi-task Transformer, which incorporates an entity boundary detection task into the named entity recognition task. More concretely, we achieve entity boundary detection by classifying the relations between tokens within the sentence. To improve the accuracy of entity-type mapping during decoding, we adopt an external knowledge base to calculate the prior entity-type distributions and then incorporate the information into the model via the self- and cross-attention mechanisms. We perform experiments on extensive NER benchmarks, including flat, nested, and discontinuous NER datasets involving long entities. It substantially increases nearly &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$+0.3 sim +1.5;{F_1}$&lt;/tex-math&gt;&lt;/inline-formula&gt; scores across a broad spectrum or performs closely to the best generative NER model. Experimental results show that our approach improves the performance of the generative NER model considerably.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = sep,
pages = {4171–4183},
numpages = {13}
}

@inproceedings{10.1145/3708036.3708139,
author = {Su, Xiaowen},
title = {Exploration and Real-time Rendering Optimization Path Using Deep Learning Methods},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708139},
doi = {10.1145/3708036.3708139},
abstract = {With the continuous development of computer graphics, real- time rendering is increasingly being used in multimedia, virtual reality, and game development. How to improve rendering efficiency and quality is an important way to improve rendering effects, but current rendering methods often encounter performance bottlenecks when rendering complex scenes . In response to the above issues, this paper intends to use deep learning methods to study real-time rendering algorithms based on deep learning. This paper intends to use GAN (Generative Adversarial Networks) technology to automatically generate optimal graphics resources from the training model, thereby shortening rendering time, improving rendering quality, modeling rendering data in different scenes, and significantly reducing rendering costs while ensuring rendering effects. This paper can study an adaptive learning and adjustment mechanism that can dynamically adjust rendering parameters in different software and hardware environments to achieve better results. In Scenario 1, the SSIM (Structural Similarity) of the traditional method is 0.80, while the GAN method is improved to 0.88. The research results of this paper can provide new ideas and methods for optimizing real- time rendering technology.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {606–610},
numpages = {5},
keywords = {Deep Learning Methods, GAN Technology, Optimized Paths, Real-time Rendering},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3627043.3659574,
author = {Manzoor, Ahtsham and Ziegler, Samuel C. and Garcia, Klaus Maria. Pirker and Jannach, Dietmar},
title = {ChatGPT as a Conversational Recommender System: A User-Centric Analysis},
year = {2024},
isbn = {9798400704338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627043.3659574},
doi = {10.1145/3627043.3659574},
abstract = {With the rapid advances in deep learning, we have witnessed a strongly increased interest in conversational recommender systems (CRS). Until recently, however, even the latest generative models exhibited major limitations and they frequently return non-meaningful responses according to previous studies. However, with the latest Generative AI-based dialog systems implemented with Generative Pre-Trained Transformer (GPT) models, a new era has arrived for CRS research. In this work, we study the use of ChatGPT as a movie recommender system. To this purpose, we conducted an online user study involving N=190 participants, who were tasked to evaluate ChatGPT’s responses in a multitude of dialog situations. As a reference point for the analysis, we included a retrieval-based conversational method in the experiment, which was found to be a robust approach in previous research. Our study results indicate that the responses by ChatGPT were perceived to be significantly better than those by the previous system in terms of their meaningfulness. A detailed inspection of the results showed that ChatGPT excelled when providing recommendations, but sometimes missed the context when asked questions about a movie within a longer dialog. A statistical analysis revealed that information adequacy and recommendation accuracy of the responses had the strongest influence on the perceived meaningfulness of the responses. Finally, an additional analysis showed that the human perceptions of meaningfulness correlated only very weakly with computational metrics such as BLEU or ROUGE, emphasizing the importance of involving humans in the evaluation of a CRS.},
booktitle = {Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {267–272},
numpages = {6},
keywords = {Conversational Recommendation, Large Language Models, User Study},
location = {Cagliari, Italy},
series = {UMAP '24}
}

@inproceedings{10.1145/3630202.3630224,
author = {Wang, Chao and Finamore, Alessandro and Michiardi, Pietro and Gallo, Massimo and Rossi, Dario},
title = {Toward Generative Data Augmentation for Traffic Classification},
year = {2023},
isbn = {9798400704529},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630202.3630224},
doi = {10.1145/3630202.3630224},
abstract = {Data Augmentation (DA)--augmenting training data with synthetic samples--is wildly adopted in Computer Vision (CV) to improve models performance. Conversely, DA has not been yet popularized in networking use cases, including Traffic Classification (TC). In this work, we present a preliminary study of 14 hand-crafted DAs applied on the MIRAGE19 dataset. Our results (i) show that DA can reap benefits previously unexplored in TC and (ii) foster a research agenda on the use of generative models to automate DA design.},
booktitle = {Proceedings of the on CoNEXT Student Workshop 2023},
pages = {33–34},
numpages = {2},
keywords = {traffic classification, generative model, deep learning, data augmentation},
location = {Paris, France},
series = {CoNEXT-SW '23}
}

@inproceedings{10.1145/3723498.3723817,
author = {Cox, Daniel and Murray, John and Salter, Anastasia},
title = {Routine, Twisty, and Queer: Pasts and Futures of Games Programming Pedagogy with No and Low Code Tools},
year = {2025},
isbn = {9798400718564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723498.3723817},
doi = {10.1145/3723498.3723817},
abstract = {This paper traces a history of platforms targeting no-code and low-code audiences. It connects historical moments addressing accessibility challenges related to computer programming up through the more recent adoption of generative AI in game engines. Across these moments, this paper identifies communities that claimed authoring platforms, establishing their identity by rejecting other, potentially more efficient or expressive options. We argue these community dynamics have shaped the evolution of current game development platforms. By contextualizing current efforts in pedagogy as part of larger shifts in computer programming and game engine practice, we present a better understanding of the origins of platforms targeting no and low code audiences as rooted in earlier pivots in computer programming and community engagement. These “twisty” and often queer adaptations aimed at smaller communities have led to major changes in how game development has evolved for larger audiences. We close on considerations of the uncertain futures and pedagogical implications of AI-generated code and visual scripting, as game engines increasingly serve as the primary interface between creators and their work.},
booktitle = {Proceedings of the 20th International Conference on the Foundations of Digital Games},
articleno = {47},
numpages = {8},
keywords = {Game Programming Pedagogy, Low code, No code},
location = {
},
series = {FDG '25}
}

@inproceedings{10.1145/3613904.3642165,
author = {Zeng, Xingchen and Gao, Ziyao and Ye, Yilin and Zeng, Wei},
title = {IntentTuner: An Interactive Framework for Integrating Human Intentions in Fine-tuning Text-to-Image Generative Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642165},
doi = {10.1145/3613904.3642165},
abstract = {Fine-tuning facilitates the adaptation of text-to-image generative models to novel concepts (e.g., styles and portraits), empowering users to forge creatively customized content. Recent efforts on fine-tuning focus on reducing training data and lightening computation overload but neglect alignment with user intentions, particularly in manual curation of multi-modal training data and intent-oriented evaluation. Informed by a formative study with fine-tuning practitioners for comprehending user intentions, we propose IntentTuner, an interactive framework that intelligently incorporates human intentions throughout each phase of the fine-tuning workflow. IntentTuner enables users to articulate training intentions with imagery exemplars and textual descriptions, automatically converting them into effective data augmentation strategies. Furthermore, IntentTuner introduces novel metrics to measure user intent alignment, allowing intent-aware monitoring and evaluation of model training. Application exemplars and user studies demonstrate that IntentTuner streamlines fine-tuning, reducing cognitive effort and yielding superior models compared to the common baseline tool.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {182},
numpages = {18},
keywords = {and data augmentation, text-to-image generative model, user intent understanding},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3641584.3641641,
author = {Qiao, Pingan and Lei, Ziying and Zhang, Xiaofan},
title = {Image Generation Method Based on Variable Scale Pyramid Attention with Text Data Enhancement},
year = {2024},
isbn = {9798400707674},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641584.3641641},
doi = {10.1145/3641584.3641641},
abstract = {In recent years, research on methods for generating images from text based on generative adversarial networks has made some progress. The study of text-generated images is at the intersection of natural language processing and computer vision, a task that requires computers to be able to generate images that are consistent with the semantics of the text on the basis of understanding the semantics of the input text. Aiming at the problems of text-image matching and poor performance on image details in traditional text-generated image methods, a VT-AttnGAN (Variable Scale Pyramid Attention with Text Data Augmentation for Generative Adversarial Networks) text-based image generation method. A Vector Data Enhancement Network (TDEN) is designed to reduce the text dimension to enhance the model's ability to learn the probability distribution of text features, and optimize the alignment of image and text. In addition, to enhance the detailed features of the image, a Variable Scale Pyramid Attention Module (VSPAM) is proposed, which extracts the features at different scales of the initial image, and efficiently utilizes the useful information between the feature channels through the attention approach. We train and test on two datasets, CUB-200-2011 and Oxford-102, and the experimental results show that compared with AttnGAN, the model proposed in this paper solves the problems of image blurring and distortion, and has the image generation effect of text image alignment enhancement and picture integrity improvement.},
booktitle = {Proceedings of the 2023 6th International Conference on Artificial Intelligence and Pattern Recognition},
pages = {389–394},
numpages = {6},
keywords = {Generating Adversarial Networks, Pyramid of attention, Text To Image, Vector Data Enhancement},
location = {Xiamen, China},
series = {AIPR '23}
}

@inproceedings{10.1145/3511808.3557310,
author = {Chen, Haonan and Dou, Zhicheng and Zhu, Yutao and Cao, Zhao and Cheng, Xiaohua and Wen, Ji-Rong},
title = {Enhancing User Behavior Sequence Modeling by Generative Tasks for Session Search},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557310},
doi = {10.1145/3511808.3557310},
abstract = {Users' search tasks have become increasingly complicated, requiring multiple queries and interactions with the results. Recent studies have demonstrated that modeling the historical user behaviors in a session can help understand the current search intent. Existing context-aware ranking models primarily encode the current session sequence (from the first behavior to the current query) and compute the ranking score using the high-level representations. However, there is usually some noise in the current session sequence (useless behaviors for inferring the search intent) that may affect the quality of the encoded representations. To help the encoding of the current user behavior sequence, we propose to use a decoder and the information of future sequences and a supplemental query. Specifically, we design three generative tasks that can help the encoder to infer the actual search intent: (1) predicting future queries, (2) predicting future clicked documents, and (3) predicting a supplemental query. We jointly learn the ranking task with these generative tasks using an encoder-decoder structured approach. Extensive experiments on two public search logs demonstrate that our model outperforms all existing baselines, and the designed generative tasks can actually help the ranking task. Besides, additional experiments also show that our approach can be easily applied to various Transformer-based encoder-decoder models and improve their performance.},
booktitle = {Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management},
pages = {180–190},
numpages = {11},
keywords = {session search, document ranking, auto-session-encoder},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@inproceedings{10.1145/3613904.3642492,
author = {Newman, Michele and Sun, Kaiwen and Dalla Gasperina, Ilena B and Shin, Grace Y. and Pedraja, Matthew Kyle and Kanchi, Ritesh and Song, Maia B. and Li, Rannie and Lee, Jin Ha and Yip, Jason},
title = {"I want it to talk like Darth Vader": Helping Children Construct Creative Self-Efficacy with Generative AI},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642492},
doi = {10.1145/3613904.3642492},
abstract = {The emergence of generative artificial intelligence (GenAI) has ignited discussions surrounding its potential to enhance creative pursuits. However, distinctions between children’s and adult’s creative needs exist, which is important when considering the possibility of GenAI for children’s creative usage. Building upon work in Human-Computer Interaction (HCI), fostering children’s computational thinking skills, this study explores interactions between children (aged 7-13) and GenAI tools through methods of participatory design. We seek to answer two questions: (1) How do children in co-design workshops perceive GenAI tools and their usage for creative works? and (2) How do children navigate the creative process while using GenAI tools? How might these interactions support their confidence in their ability to create? Our findings contribute a model that describes the potential contexts underpinning child-GenAI creative interactions and explores implications of this model for theories of creativity, design, and use of GenAI as a constructionist tool for creative self-efficacy.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {117},
numpages = {18},
keywords = {Artificial Intelligence, Children, Co-Design, Constructionism, Creativity, Participatory Design},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3642970.3655847,
author = {Aldous, Bradley and Abdelmoniem, Ahmed M.},
title = {Comparative Profiling: Insights Into Latent Diffusion Model Training},
year = {2024},
isbn = {9798400705410},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3642970.3655847},
doi = {10.1145/3642970.3655847},
abstract = {Generative AI models are at the forefront of advancing creative and analytical tasks, pushing the boundaries of what machines can generate and comprehend. Among these, latent diffusion models represent significant advancements in generating high-fidelity audio and images. This study introduces a systematic approach to study GPU utilisation during the training of these models by leveraging Weights &amp; Biases and the PyTorch Profiler for detailed monitoring and profiling. Our methodology is designed to uncover inefficiencies in GPU resource allocation, pinpointing bottlenecks in the training pipeline. The insights gained aim to guide the development of strategies for enhancing training efficiency, potentially reducing computational costs and accelerating the development cycle of generative AI models. This contribution not only highlights the critical role of resource optimisation in scaling AI technologies but also opens new avenues for research in efficient model training.},
booktitle = {Proceedings of the 4th Workshop on Machine Learning and Systems},
pages = {176–183},
numpages = {8},
keywords = {deep learning, diffusion model, profiling},
location = {Athens, Greece},
series = {EuroMLSys '24}
}

@article{10.1145/3696415,
author = {Xing, Zhen and Feng, Qijun and Chen, Haoran and Dai, Qi and Hu, Han and Xu, Hang and Wu, Zuxuan and Jiang, Yu-Gang},
title = {A Survey on Video Diffusion Models},
year = {2024},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3696415},
doi = {10.1145/3696415},
abstract = {The recent wave of AI-generated content (AIGC) has witnessed substantial success in computer vision, with the diffusion model playing a crucial role in this achievement. Due to their impressive generative capabilities, diffusion models are gradually superseding methods based on GANs and auto-regressive Transformers, demonstrating exceptional performance not only in image generation and editing, but also in the realm of video-related research. However, existing surveys mainly focus on diffusion models in the context of image generation, with few up-to-date reviews on their application in the video domain. To address this gap, this article presents a comprehensive review of video diffusion models in the AIGC era. Specifically, we begin with a concise introduction to the fundamentals and evolution of diffusion models. Subsequently, we present an overview of research on diffusion models in the video domain, categorizing the work into three key areas: video generation, video editing, and other video understanding tasks. We conduct a thorough review of the literature in these three key areas, including further categorization and practical contributions in the field. Finally, we discuss the challenges faced by research in this domain and outline potential future developmental trends. A comprehensive list of video diffusion models studied in this survey is available at .},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {41},
numpages = {42},
keywords = {Survey, video diffusion model, video generation, video editing, AIGC}
}

@inproceedings{10.1145/3701551.3703569,
author = {Lee, Yuan-Heng and Ying, Josh Jia-Ching and Tseng, Vincent S.},
title = {HaGAR: Hardness-aware Generative Adversarial Recommender},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703569},
doi = {10.1145/3701551.3703569},
abstract = {Implicit Collaborative filtering is a fundamental technique in recommendation systems, leveraging implicit user interactions to suggest items of interest. A significant challenge in this domain is the absence of explicit negative feedback, limiting the recommendation performance. Previous researchers have tried to tackle the challenge through the Generative Adversarial Network (GAN). The generator produces increasingly challenging samples for the discriminator, driving the optimization of the discrimination objective. Although GAN-style recommender systems can achieve decent performance by generating harder negative samples, the negatives selected by the generator may not always be ideal for training the discriminator. In this study, we focus on two types of undesirable negatives that persist in modern GAN-style recommenders: false negatives and uninformative negatives. In response to these issues, we propose a novel Hardness-aware Generative Adversarial Recommender (HaGAR). To the best of our knowledge, it is the first adversarial recommender that explicitly aims to alleviate the adverse impact of false and uninformative negatives. Our approach incorporates a relevance monitoring module and a hardness-aware weighting module to identify and address false and uninformative negatives during training with minimal additional computational cost. Our experimental results demonstrate that HaGAR significantly improves recommendation performance, achieving over a 21% increase in terms of NDCG@10 compared to the state-of-the-art GAN-style recommender. These findings highlight the efficacy of our improvement in providing more robust negative samples, leading to better-performing recommendation systems.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {838–846},
numpages = {9},
keywords = {adversarial networks, collaborative filtering, implicit feedback, negative sampling, recommendation system},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3630106.3658963,
author = {Leu, Warren and Nakashima, Yuta and Garcia, Noa},
title = {Auditing Image-based NSFW Classifiers for Content Filtering},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658963},
doi = {10.1145/3630106.3658963},
abstract = {This paper examines NSFW (Not Safe For Work) image classifiers for content filtering. Through an audit of three prevalent NSFW classifiers, we analyze the relationship between NSFW predictions and three demographic factors: gender, skin-tone, and age. Our study reveals that women are disproportionately more frequently misclassified as NSFW compared to men, even when they appear conducting common daily-life activities. Additionally, we find that NSFW classifiers tend to mispredict images of people with lighter skin-tones and images depicting younger people. We explore the causes of such mispredictions by analyzing the explanatory pixel maps, which reveal some of the reasons behind the misclassifications. Overall, the implications of our findings become particularly salient when considering the application of filters based on NSFW classifiers, which we identified to have a direct impact on image datasets, computer vision models, generative AI, user experience, and artistic creativity. In summary, we hope our study brings attention to the inherent biases within NSFW classifiers and underscores the importance of addressing these issues to ensure fair and equitable outcomes in content filtering.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1163–1173},
numpages = {11},
keywords = {NSFW classification, audit, computer vision, content filtering, content moderation},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3613905.3647962,
author = {Oksanen, Joel},
title = {Bridging the Integrity Gap: Towards AI-assisted Design Research},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3647962},
doi = {10.1145/3613905.3647962},
abstract = {Design research involves the human-centered analysis of substantial volumes of qualitative data, presenting a promising application for emerging generative AI technologies. While AI-assisted qualitative research remains an extensively explored topic within the Human-Computer Interaction (HCI) discourse, the integration of AI into design research, differentiated by its intrinsic reliance on empathy and intuition, remains markedly underexplored. This paper reports on a qualitative study with 13 designers from a range of design disciplines, investigating the processes by which insights are cultivated in design research and the extent to which these processes may be effectively augmented or potentially undermined by AI interventions. The findings suggest that design research relies heavily on the tacit knowledge of designers, underlining the importance of designer-AI alignment. Drawing upon these findings and existing literature on human-AI trust, this paper lays the foundation for further inquiry into AI-assisted design research, by (1) identifying the development of intrinsic trust through designer-AI alignment as a central objective; and (2) introducing the conceptual framework of the Integrity Gap to motivate further studies.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {607},
numpages = {5},
keywords = {design research, designer-AI alignment, trust},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3573382.3616033,
author = {Huang, Yuxuan},
title = {The Future of Generative AI: How GenAI Would Change Human-Computer Co-creation in the Next 10 to 15 Years},
year = {2023},
isbn = {9798400700293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573382.3616033},
doi = {10.1145/3573382.3616033},
abstract = {The past few years have witnessed a remarkable advancement in the field of Generative Artificial Intelligence (GenAI), a technology capable of generating new content based on input prompts and existing knowledge. This technology has the potential to revolutionize the way of human-computer co-creation. However, existing research on GenAI has primarily focused on technical aspects, and more research is needed from a design perspective, mainly through speculative and critical design. Therefore, this study aims to explore how GenAI would transform human-computer co-creation in the next 10 to 15 years by means of design fiction and playful critical design. The study will involve (co-)speculative workshops utilizing design fiction, followed by focus groups to gather insights. In addition, this research will examine the user experience issues of interacting with functional GenAI prototypes through playful critical design.},
booktitle = {Companion Proceedings of the Annual Symposium on Computer-Human Interaction in Play},
pages = {322–325},
numpages = {4},
keywords = {AI-generated content, design fiction, generative AI, playful critical design, speculative design},
location = {Stratford, ON, Canada},
series = {CHI PLAY Companion '23}
}

@inproceedings{10.1145/3704137.3704195,
author = {Ramesh, Goutham Bharadwaj and Chamas, Mohamad and Wang, Aoli and Sax, Eric},
title = {Auto-Adaptive Diffusion Model-Based Uniformization of Automotive Camera Sensor Data},
year = {2025},
isbn = {9798400718014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704137.3704195},
doi = {10.1145/3704137.3704195},
abstract = {The association between Original Equipment Manufacturers (OEMs) and sensor manufacturers must be consistently improved to accommodate the increasing usage of automotive sensors in vehicles. This requires detailed consideration of any adaptations and changes in sensor characteristics, as they directly impact the working principles of the related software applications. This study introduces a new method, the "Auto-Adaptive Diffusion (ADF) Model," which aims to uniformize the automotive camera sensor data by sensor data abstraction and, successively, reinforce the Plug-and-Play (PnP) component. The ADF model is designed to homogenize specific sensor data parameters and formulate them into a single format, reducing the interdependencies between the automotive camera sensors and their software components. It also aims to simplify the sensor configuration process, regardless of the sensor vendors, while enhancing the accuracy and reliability of applications. This work utilizes the "Drive&amp;Act" as the Ground Truth (GT) dataset, centralizing on the In-cabin Monitoring System (IMS) with pre-trained YOLOv8 for object detection. Experimental results and comparisons show that the ADF model outperforms traditional techniques, such as Open Source Computer Vision (OpenCV) libraries and Generative Adversarial Network (GAN) based work named "Sensor-Agnostic Image Translation Framework (SAITF)" in various Key Performance Indicators (KPIs).},
booktitle = {Proceedings of the 2024 8th International Conference on Advances in Artificial Intelligence},
pages = {246–255},
numpages = {10},
keywords = {Sensor data abstraction, plug-and-play, diffusion model, computer vision, generative adversarial network},
location = {
},
series = {ICAAI '24}
}

@inproceedings{10.1145/3583133.3590626,
author = {Ripa, Guillermo and Mautone, Agust\'{\i}n and Vidal, Andr\'{e}s and Nesmachnow, Sergio and Toutouh, Jamal},
title = {Multiobjective coevolutionary training of Generative Adversarial Networks},
year = {2023},
isbn = {9798400701207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583133.3590626},
doi = {10.1145/3583133.3590626},
abstract = {This article presents a multiobjective evolutionary approach for coevolutionary training of Generative Adversarial Networks. The proposal applies an explicit multiobjective optimization approach based on Pareto ranking and non-dominated sorting over the co-evolutionary search implemented by the Lipizzaner framework, to optimize the quality and diversity of the generated synthetic data. Two functions are studied for evaluating diversity. The main results obtained for the handwritten digits generation problem show that the proposed multiobjective search is able to compute accurate and diverse solutions, improving over the standard Lipizzaner implementation.},
booktitle = {Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
pages = {319–322},
numpages = {4},
keywords = {image generation, co-evolutionary algorithms, multiobjective optimization, generative adversarial networks},
location = {Lisbon, Portugal},
series = {GECCO '23 Companion}
}

@inproceedings{10.1145/3565287.3617628,
author = {Brewington, Joseph and Kar, Dulal},
title = {UAV GPS Spoofing Detection via Neural Generative One-Class Classification},
year = {2023},
isbn = {9781450399265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3565287.3617628},
doi = {10.1145/3565287.3617628},
abstract = {Unmanned Aerial Vehicles (UAVs) are increasingly used for civilian applications but remain vulnerable to spoofing attacks due to their reliance on unencrypted Global Positioning System (GPS) signals. While traditional hardware-based detection methods are effective, they are often inflexible and costly. Through comprehensive simulations and comparative analysis, this study delves into the potential of neural generative one-class classifiers, particularly Generative Adversarial Networks (GANs), for GPS spoofing detection in civilian UAVs. Results indicate that these models provide consistent and computationally efficient one-class classification. Future research directions include exploring further extensions of these models and testing in real-world UAV scenarios.},
booktitle = {Proceedings of the Twenty-Fourth International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing},
pages = {492–497},
numpages = {6},
keywords = {security, autoencoder, anomaly detection, one-class classification, machine learning, generative adversarial networks, variational autoencoders, intrusion detection, GPS spoofing, global positioning system, unmanned aerial vehicles},
location = {Washington, DC, USA},
series = {MobiHoc '23}
}

@inproceedings{10.1145/3643832.3661860,
author = {Duan, Di and Sun, Zehua and Ni, Tao and Li, Shuaicheng and Jia, Xiaohua and Xu, Weitao and Li, Tianxing},
title = {F2Key: Dynamically Converting Your Face into a Private Key Based on COTS Headphones for Reliable Voice Interaction},
year = {2024},
isbn = {9798400705816},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643832.3661860},
doi = {10.1145/3643832.3661860},
abstract = {In this paper, we proposed F2Key, the first earable physical security system based on commercial off-the-shelf headphones. F2Key enables impactful applications, such as enhancing voiceprint-based authentication systems, reliable voice assistants, audio deepfake defense, and the legal validity of artifacts. The key idea of F2Key is to establish a stable acoustic sensing field across the user's face and embed the user's facial structures and articulatory habits into a user-specific generative model that serves as a private key. The private key can decrypt the Channel Impulse Response (CIR) profiles provided by the acoustic sensing field into an inferred spectrogram that can match the real one calculated from the corresponding speech, provided that the user's CIR-spectrogram mapping relationship is consistent with the one embedded in the generative model. Extensive experiments demonstrate that F2Key resists 99.9%, 96.4%, and 95.3% of speech replay attacks, mimicry attacks, and hybrid attacks, respectively. We discussed and evaluated F2Key from different perspectives, such as the health consideration and identical twins study, to show the practicality and reliability.},
booktitle = {Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services},
pages = {127–140},
numpages = {14},
keywords = {acoustic sensing, deepfake detection, earable sensing, physical security system},
location = {Minato-ku, Tokyo, Japan},
series = {MOBISYS '24}
}

@inproceedings{10.1145/3706598.3713128,
author = {Shi, Danqing and Wang, Yao and Bai, Yunpeng and Bulling, Andreas and Oulasvirta, Antti},
title = {Chartist: Task-driven Eye Movement Control for Chart Reading},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713128},
doi = {10.1145/3706598.3713128},
abstract = {To design data visualizations that are easy to comprehend, we need to understand how people with different interests read them. Computational models of predicting scanpaths on charts could complement empirical studies by offering estimates of user performance inexpensively; however, previous models have been limited to gaze patterns and overlooked the effects of tasks. Here, we contribute Chartist, a computational model that simulates how users move their eyes to extract information from the chart in order to perform analysis tasks, including value retrieval, filtering, and finding extremes. The novel contribution lies in a two-level hierarchical control architecture. At the high level, the model uses LLMs to comprehend the information gained so far and applies this representation to select a goal for the lower-level controllers, which, in turn, move the eyes in accordance with a sampling policy learned via reinforcement learning. The model is capable of predicting human-like task-driven scanpaths across various tasks. It can be applied in fields such as explainable AI, visualization design evaluation, and optimization. While it displays limitations in terms of generalizability and accuracy, it takes modeling in a promising direction, toward understanding human behaviors in interacting with charts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1167},
numpages = {14},
keywords = {User model; Simulation; Scanpath; Reinforcement learning; LLMs},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3726854.3727279,
author = {Liu, Xutong and Dai, Xiangxiang and Wang, Xuchuang and Hajiesmaili, Mohammad and Lui, John C.S.},
title = {Combinatorial Logistic Bandits},
year = {2025},
isbn = {9798400715938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726854.3727279},
doi = {10.1145/3726854.3727279},
abstract = {Combinatorial multi-armed bandit (CMAB) is a fundamental online learning framework that can optimize cumulative rewards in networked systems under uncertainty. Real-world applications like content delivery and channel allocation often feature binary base arm rewards and nonlinear total reward functions. This paper introduces combinatorial logistic bandits (CLogB), a contextual CMAB framework with the base arm reward modeled as a nonlinear logistic function of the context, and the feedback is governed by a general arm-triggering process. We study CLogB with smooth reward functions, covering applications such as online content delivery, online multi-LLM selection, and dynamic channel allocation. Our first algorithm, CLogUCB, uses a variance-agnostic exploration bonus and achieves a regret bound of \~{O}(d√(κ KT)), where d is the feature dimension, κ reflects logistic model nonlinearity, K is the maximum number of triggered arms, and \~{O} ignores logarithmic factors. This improves on prior results by \~{O}(√κ ). We further propose VA-CLogUCB, a variance-adaptive enhancement achieving regret bounds of \~{O}(d√(KT) ) under standard smoothness conditions and \~{O}(d√T ) under stronger variance conditions, removing dependence on K. For time-invariant feature maps, we enhance computational efficiency by avoiding nonconvex optimization while maintaining \~{O}(d√T) regret. Experiments on synthetic and real-world datasets validate the superior performance of our algorithms, demonstrating their effectiveness and scalability for real-world networked systems.},
booktitle = {Abstracts of the 2025 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {112–114},
numpages = {3},
keywords = {combinatorial multi-armed bandits, logistic model, multi-armed bandits, regret, variance-adaptive},
location = {Stony Brook, NY, USA},
series = {SIGMETRICS '25}
}

@article{10.1145/3665869,
author = {Jia, Zhen and Zhang, Zhang and Wang, Liang and Tan, Tieniu},
title = {Human Image Generation: A Comprehensive Survey},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {11},
issn = {0360-0300},
url = {https://doi.org/10.1145/3665869},
doi = {10.1145/3665869},
abstract = {Image and video synthesis has become a blooming topic in computer vision and machine learning communities along with the developments of deep generative models, due to its great academic and application value. Many researchers have been devoted to synthesizing high-fidelity human images as one of the most commonly seen object categories in daily lives, where a large number of studies are performed based on various models, task settings, and applications. Thus, it is necessary to give a comprehensive overview on these variant methods on human image generation. In this article, we divide human image generation techniques into three paradigms, i.e., data-driven methods, knowledge-guided methods, and hybrid methods. For each paradigm, the most representative models and the corresponding variants are presented, where the advantages and characteristics of different methods are summarized in terms of model architectures. The main public human image datasets and evaluation metrics in the literature are also summarized. Furthermore, due to the wide application potential, the typical downstream usages of synthesized human images are covered. Finally, the challenges and potential opportunities of human image generation are discussed to shed light on future research.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {279},
numpages = {39},
keywords = {Human image generation, human image rendering, person image generation, deep generative model, 3D human body model}
}

@inproceedings{10.5555/3643142.3643390,
author = {Dengler, Gabriel and Bazan, Peter and German, Reinhard and Lalbakhsh, Pooia and Liebmann, Ariel},
title = {A Conversational Human-Computer Interface for Smart Energy System Simulation Environments},
year = {2024},
isbn = {9798350369663},
publisher = {IEEE Press},
abstract = {This paper introduces a conversational framework that enhances the usability of smart energy system simulations. This study is centered around OpenAI's Generative Pre-trained Transformer (GPT), a fine-tuned conversational model that allows users to communicate with the system in a natural way. Therefore, users can describe their simulation scenarios in plain language and GPT seamlessly translates these descriptions into Python scripts, used as inputs to the simulation environment, in our case, AnyLogic Simulation Software. Our framework is based on the i7-AnyEnergy core framework to compute distribution flows and relevant statistics. The proposed human-machine interface facilitates and accelerates simulation modeling, as demonstrated through the two scenarios we have provided in this paper. Overall, our conversational framework has the potential to significantly improve the user experience of smart energy system simulation environments. By simplifying the interaction between users and complex simulation models, we enable users to obtain valuable insights rapidly and more easily.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2978–2989},
numpages = {12},
location = {San Antonio, Texas, USA},
series = {WSC '23}
}

@inproceedings{10.1145/3652037.3663942,
author = {Joaa, AFM Mohimenul and Majumder, Prattoy and Sadeque, Farig},
title = {Curious Learner: A Neuro-Symbolic Approach for Function Execution via Natural Language},
year = {2024},
isbn = {9798400717604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652037.3663942},
doi = {10.1145/3652037.3663942},
abstract = {Generative models possess immense potential, but their ability to perform complex calculations is limited by the need to memorize vast amounts of data, leading to computational inefficiencies. Leveraging tools like the Arithmetic Logic Unit using symbolic functions offers a more efficient alternative, enabling faster responses, smaller model sizes, and improved accuracy. We propose a neuro-symbolic generative model to empower natural language models with task execution abilities by integrating functional programming principles. Experiments on our scoped four translation tasks using 98 mathematical functions demonstrated rapid convergence and minimal training time requirements. The model achieved an average accuracy, BLEU score, and perplexity score of 0.85, 0.84, and 5.9, respectively, after training on a T4 GPU for several hours. This neuro-symbolic Language Model shows significant potential for various applications, such as NLP-based command line tools, customer service automation, service discovery automation, project code automation, and natural language-based operating systems.},
booktitle = {Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {392–399},
numpages = {8},
keywords = {Curious Learner, Customer Service Automation, Foundational Model, Generative Model, Large Language Model Architecture, Natural Language Processing, Neuro-Symbolic Programming, Service Discovery Automation, Task Executor, Transformer},
location = {Crete, Greece},
series = {PETRA '24}
}

@inproceedings{10.1145/3698587.3701364,
author = {Song, Ziyang and Lu, Qincheng and Xu, Hao and Zhu, He and Buckeridge, David and Li, Yue},
title = {TimelyGPT: Extrapolatable Transformer Pre-training for Long-term Time-Series Forecasting in Healthcare},
year = {2024},
isbn = {9798400713026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698587.3701364},
doi = {10.1145/3698587.3701364},
abstract = {Motivation: Large-scale pre-trained models (PTMs) such as BERT and GPT have recently achieved great success in Natural Language Processing and Computer Vision domains. However, the development of PTMs on healthcare time-series data is lagging behind. This underscores the limitations of the existing transformer-based architectures, particularly their scalability to handle large-scale time series and ability to capture long-term temporal dependencies.Methods: In this study, we present Timely Generative Pre-trained Transformer (TimelyGPT). TimelyGPT employs an extrapolatable position (xPos) embedding to encode trend and periodic patterns into time-series representations. It also integrates recurrent attention and temporal convolution modules to effectively capture global-local temporal dependencies.Materials: We evaluated TimelyGPT on two large-scale healthcare time series datasets corresponding to continuous biosignals and irregularly-sampled time series, respectively: (1) the Sleep EDF dataset consisting of over 1.2 billion timesteps; (2) the longitudinal healthcare administrative database PopHR, comprising 489,000 patients randomly sampled from the Montreal population.Results: In forecasting continuous biosignals, TimelyGPT achieves accurate extrapolation up to 6,000 timesteps of body temperature during the sleep stage transition, given a short look-up window (i.e., prompt) containing only 2,000 timesteps. For irregularly-sampled time series, TimelyGPT with a proposed time-specific inference demonstrates high top recall scores in predicting future diagnoses using early diagnostic records, effectively handling irregular intervals between clinical records. Together, we envision TimelyGPT to be useful in various health domains, including long-term patient health state forecasting and patient risk trajectory prediction. Availability: The open-sourced code is available at Github.},
booktitle = {Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {16},
numpages = {10},
keywords = {Time-series forecasting, Time-series pre-training, biosignals, clinical diagnosis, irregularly-sampled time series, transfer learning},
location = {Shenzhen, China},
series = {BCB '24}
}

@inproceedings{10.1145/3626772.3657742,
author = {Hou, Yu and Park, Jin-Duk and Shin, Won-Yong},
title = {Collaborative Filtering Based on Diffusion Models: Unveiling the Potential of High-Order Connectivity},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657742},
doi = {10.1145/3626772.3657742},
abstract = {A recent study has shown that diffusion models are well-suited for modeling the generative process of user--item interactions in recommender systems due to their denoising nature. However, existing diffusion model-based recommender systems do not explicitly leverage high-order connectivities that contain crucial collaborative signals for accurate recommendations. Addressing this gap, we propose textsfCF-Diff, a new diffusion model-based collaborative filtering (CF) method, which is capable of making full use of collaborative signals along with multi-hop neighbors. Specifically, the forward-diffusion process adds random noise to user--item interactions, while the reverse-denoising process accommodates our own learning model, named cross-attention-guided multi-hop autoencoder (CAM-AE ), to gradually recover the original user--item interactions. CAM-AE consists of two core modules: 1) the attention-aided AE module, responsible for precisely learning latent representations of user--item interactions while preserving the model's complexity at manageable levels, and 2) the multi-hop cross-attention module, which judiciously harnesses high-order connectivity information to capture enhanced collaborative signals. Through comprehensive experiments on three real-world datasets, we demonstrate that CF-Diff is (a) Superior: outperforming benchmark recommendation methods, achieving remarkable gains up to 7.29% compared to the best competitor, (b) Theoretically-validated: reducing computations while ensuring that the embeddings generated by our model closely approximate those from the original cross-attention, and (c) Scalable: proving the computational efficiency that scales linearly with the number of users or items.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1360–1369},
numpages = {10},
keywords = {collaborative filtering, cross-attention, diffusion model, high-order connectivity, recommender system},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3586183.3606759,
author = {Kang, Hyeonsu B and Wu, Tongshuang and Chang, Joseph Chee and Kittur, Aniket},
title = {Synergi: A Mixed-Initiative System for Scholarly Synthesis and Sensemaking},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606759},
doi = {10.1145/3586183.3606759},
abstract = {Efficiently reviewing scholarly literature and synthesizing prior art are crucial for scientific progress. Yet, the growing scale of publications and the burden of knowledge make synthesis of research threads more challenging than ever.While significant research has been devoted to helping scholars interact with individual papers, building research threads scattered across multiple papers remains a challenge.Most top-down synthesis (and LLMs) make it difficult to personalize and iterate on the output, while bottom-up synthesis is costly in time and effort.Here, we explore a new design space of mixed-initiative workflows.In doing so we develop a novel computational pipeline, Synergi, that ties together user input of relevant seed threads with citation graphs and LLMs, to expand and structure them, respectively.Synergiallows scholars to start with an entire threads-and-subthreads structure generated from papers relevant to their interests, and to iterate and customize on it as they wish. In our evaluation, we find that Synergi helps scholars efficiently make sense of relevant threads, broaden their perspectives, and increases their curiosity. We discuss future design implications for thread-based, mixed-initiative scholarly synthesis support tools.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {43},
numpages = {19},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.5555/3709347.3743509,
author = {Mihalcea, Rada},
title = {The Agent Paradox: Can Multi-Agent Systems Replicate the Complexity of Human Cognition and Social Behavior?},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Recent advancements in multi-agent systems have sparked a rapidly growing research area focused on simulating increasingly complex human behaviors - group consensus, implicit bias, and, in some cases, even cooperation or conflict. Yet, these systems exist in a paradox: they are computational and artificial, entirely lacking the intrinsic consciousness, emotions, and social intuition that define human individuals and societies. In this keynote, I will explore the evolving relationship between AI agents and human behavior, drawing on large-scale generative agent experiments, studies on bias in multi-agent interactions, and insights into misinformation and group behavior. I will also discuss the broader implications of these systems - not only for the future of AI but also for human-centered disciplines such as psychology, sociology, and ethics, where they can challenge or facilitate our understanding of intelligence, agency, and collective decision-making.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {3},
numpages = {1},
keywords = {agent paradox, human cognition, multi-agent systems, social behavior},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3661725.3661744,
author = {Balisacan, Gabriela M. and Paulo, Anne Therese A.},
title = {Neuro-Vis: Guided Complex Image Reconstruction from Brain Signals Using Multiple Semantic and Perceptual Controls},
year = {2024},
isbn = {9798400716393},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661725.3661744},
doi = {10.1145/3661725.3661744},
abstract = {The externalization of the state of one's mind, which people refer to as “mind reading” in science fiction, is currently being realized through brain decoding research. This field of study aims to deepen our understanding of the human brain, which is among the least understood known biological structures, and to build better foundations for brain-computer interfaces. With the success of state-of-the-art latent diffusion models in image synthesis, a trend in recent studies is to map fMRI recordings to the image embedding space of these generative models. While this method significantly improved image reconstructions in terms of semantics, preserving perceptual features without losing semantic information remains challenging, especially with complex images of natural scenes. This research introduces Neuro-Vis, a novel fMRI-to-image pipeline based on Stable Diffusion that effectively integrates multiple semantic controls through predicted image embeddings and captions and multiple lightweight perceptual controls through predicted blurry initial images, depth maps, and color palettes. Neuro-Vis outperforms the current state-of-the-art methods in terms of consistency in low-level features while also rivaling them in terms of semantics. Furthermore, ablation experiments demonstrate the effectiveness of each component in Neuro-Vis for fMRI-to-image reconstruction.},
booktitle = {Proceedings of the International Conference on Computing, Machine Learning and Data Science},
articleno = {17},
numpages = {8},
keywords = {brain decoding, fMRI-to-Image reconstruction, image captioning, perceptual guidance, semantic guidance, visual decoding},
location = {Singapore, Singapore},
series = {CMLDS '24}
}

@inproceedings{10.1145/3626772.3657759,
author = {Zhu, Yunqin and Wang, Chao and Zhang, Qi and Xiong, Hui},
title = {Graph Signal Diffusion Model for Collaborative Filtering},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657759},
doi = {10.1145/3626772.3657759},
abstract = {Collaborative filtering is a critical technique in recommender systems. It has been increasingly viewed as a conditional generative task for user feedback data, where newly developed diffusion model shows great potential. However, existing studies on diffusion model lack effective solutions for modeling implicit feedback. Particularly, the standard isotropic diffusion process overlooks correlation between items, misaligned with the graphical structure of the interaction space. Meanwhile, Gaussian noise destroys personalized information in a user's interaction vector, causing difficulty in its reconstruction. In this paper, we adapt standard diffusion model and propose a novel Graph Signal Diffusion Model for Collaborative Filtering (named GiffCF). To better represent the correlated distribution of user-item interactions, we define a generalized diffusion process using heat equation on the item-item similarity graph. Our forward process smooths interaction signals with an advanced family of graph filters, introducing the graph adjacency as beneficial prior knowledge for recommendation. Our reverse process iteratively refines and sharpens latent signals in a noise-free manner, where the updates are conditioned on the user's history and computed from a carefully designed two-stage denoiser, leading to high-quality reconstruction. Finally, through extensive experiments, we show that GiffCF effectively leverages the advantages of both diffusion model and graph signal processing, and achieves state-of-the-art performance on three benchmark datasets.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1380–1390},
numpages = {11},
keywords = {collaborative filtering, diffusion model, graph signal processing},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3723498.3723816,
author = {Shyne, Fiona and Cooper, Seth},
title = {Computational Tools for Table-Top Role-Playing Games: A Scoping Review},
year = {2025},
isbn = {9798400718564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723498.3723816},
doi = {10.1145/3723498.3723816},
abstract = {Table-top role-playing games (TTRPGs) are a form of gameplay that often requires a variety of complex tasks to be completed both in preparation and throughout gameplay: from tracking game state to the creation of fictional worlds. This has presented an opportunity for computational assistance in TTRPG sessions, both in the creation of artifacts and throughout the gameplay. We investigate the current research in computational tools for TTRPGs through a scoping review of academic works and present the major trends and opportunities from these works. We screened over one thousand works sourced from three different academic databases: ACM Digital Library, IEEE-Xplore, and Google Scholar. Papers were included based on relevance to TTRPGs, computational interface, and academic venue. In total, we evaluated 46 works in terms of produced artifacts, computational methods, evaluation, and outcomes. These papers include a diverse set of produced artifacts and computational methods, with an emphasis on tangible interfaces and generative AI systems. However, we found an opportunity for future work in terms of long-term studies, mixed-initiative methods, and different aspects of gameplay.},
booktitle = {Proceedings of the 20th International Conference on the Foundations of Digital Games},
articleno = {20},
numpages = {14},
keywords = {TTRPGs, Literature Review, Procedural Content Generation, Tangible Interface},
location = {
},
series = {FDG '25}
}

@inproceedings{10.1145/3581754.3584124,
author = {Goodarzy, Sepideh and Keller, Eric and Nazari, Maziyar and Rozner, Eric and Han, Richard and Dras, Mark and Lee, Young Choon and Richards, Deborah},
title = {Capturing and Predicting User Frustration to Support a Smart Operating System},
year = {2023},
isbn = {9798400701078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581754.3584124},
doi = {10.1145/3581754.3584124},
abstract = {This paper presents an IRB-approved human study to capture data to build models for human frustration prediction of computer users. First, an application was developed that ran in the user’s computer/laptop/VM with Linux 20.04. Then, the application collected a variety of data from their computers, including: mouse clicks, movements and scrolls; the pattern of keyboard keys clicks; user audio features; and head movements through the user video; System-wide information such as computation, memory usage, network bandwidth, and input/output bandwidth of the running applications in the computer and user frustrations. Finally, the application sent the data to the cloud. After two weeks of data collection, supervised and semi-supervised models were developed offline to predict user frustration with the computer using the collected data. A semi-supervised model using a generative adversarial network (GAN) resulted in the highest accuracy of 90%.},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {29–32},
numpages = {4},
keywords = {Computer-based User Frustration, Intelligent Operating System},
location = {Sydney, NSW, Australia},
series = {IUI '23 Companion}
}

@inproceedings{10.1145/3604078.3604167,
author = {Liu, Wenhui and Liu, Bin and Lin, Xiao and Li, Bo and He, Zhifen and Wang, Kang},
title = {ArtDiff: Artwork Generation via Conditional Diffusion Models},
year = {2023},
isbn = {9798400708237},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604078.3604167},
doi = {10.1145/3604078.3604167},
abstract = {Artwork Generation is an important research area of computer vision. Recently, kinds of generative models have achieved great success in natural image generation. However, artwork generation has rarely been studied due to the unfixed structure of artworks. Combined with prevailing diffusion models, we propose a simple yet effective framework, named as ArtDiff, for artwork generation. Given a name of an artist, we can generate diverse and novel artworks which reflecting the style of the artist. To the best of our knowledge, ArtDiff is the first diffusion model that generate artworks with the guidance of artist's name. Experimental results demonstrate that ArtDiff is able to recognize the artist's preference and generate artworks with reasonable structures and fine-grained details.},
booktitle = {Proceedings of the 15th International Conference on Digital Image Processing},
articleno = {88},
numpages = {6},
keywords = {image synthesis, denoising diffusion probabilistic models, Artwork Generation},
location = {Nanjing, China},
series = {ICDIP '23}
}

@article{10.1145/3699758,
author = {Feng, Yiwen and Zhao, Jiayang and Wang, Chuyu and Xie, Lei and Lu, Sanglu},
title = {3D Bounding Box Estimation Based on COTS mmWave Radar via Moving Scanning},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699758},
doi = {10.1145/3699758},
abstract = {Object boundary estimation, usually achieved by bounding box estimation, is crucial in various applications, such as intelligent driving, which facilitates further interactions like obstacle avoidance and navigation. Existing solutions mainly rely on computer vision, which often performs poorly in low-visibility conditions, e.g., harsh weather, and has limited resolution for depth estimation. Recent studies show the potential of mmWave radar for object detection. However, due to the inherent drawbacks, conventional mmWave techniques suffer from the severe interference of noise points in the points cloud, leading to the position vagueness, as well as sparsity and limited spatial resolution, which leads to the boundary vagueness. In this paper, we propose a novel bounding box estimation system based on mmWave radar that sufficiently leverages the spatial features of the antenna array and the temporal features of moving scanning to detect objects and estimate their 3D bounding boxes. To mitigate the interference from noise points, we introduce a new integration metric, Reflection Saliency, which evaluates the effectiveness of each point based on signal-to-noise ratio (SNR), speed, and spatial domains, successfully reducing the majority of noise points. Moreover, we propose the Prior-Time Heuristic Point Cloud Augmentation method to enrich the point representation of objects based on the previous data. To obtain boundary information, we propose a beamforming-based model to extract the Angle-Reflection Profile (ARP), which depicts the spatial distribution of the object's reflection. Furthermore, a generative neural network is used to refine the boundary and estimate the 3D bounding box by incorporating the ARP features, SNR of cloud points, and depth information. We have implemented an actual system prototype using a robot car in real scenarios and extensive experiments show that the average position error of the proposed system in 3D bounding box estimation is 0.11m.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {200},
numpages = {27},
keywords = {Bounding Box, Object Detection, Point Cloud, mmWave}
}

@article{10.1145/3665650,
author = {Malag\'{o}n, Mikel and Irurozki, Ekhine and Ceberio, Josu},
title = {A Combinatorial Optimization Framework for Probability-Based Algorithms by Means of Generative Models},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
url = {https://doi.org/10.1145/3665650},
doi = {10.1145/3665650},
abstract = {Probability-based algorithms have proven to be a solid alternative for approaching optimization problems. Nevertheless, in many cases, using probabilistic models that efficiently exploit the characteristics of the problem involves large computational overheads, and therefore, lower complexity models such as those that are univariate are usually employed within approximation algorithms. With the motivation to address such an issue, in this article, we aim to introduce an iterative optimization framework that employs generative models to efficiently estimate the parameters of probability models for optimization problems. This allows the use of complex probabilistic models (or those that are appropriate for each problem) in a way that is feasible to apply them iteratively. Specifically, the framework is composed of three elements: a generative model, a probability model whose probability rule is differentiable, and a loss function. The possibility of modifying any of the three elements of the framework offers the flexibility to design algorithms that best adapt to the problem at hand. Experiments conducted on two case studies reveal that the presented approach has strong performance in terms of objective value and execution time when compared to other probability-based algorithms. Moreover, the experimental analysis demonstrates that the convergence of the algorithms is controllable by adjusting the components of the framework. For the sake of reproducibility, the source code, results, scripts, figures, and other material related to the manuscript are available at .},
journal = {ACM Trans. Evol. Learn. Optim.},
month = jul,
articleno = {18},
numpages = {28},
keywords = {Probability model, estimation, efficient learning, combinatorial optimization, neural networks}
}

@inproceedings{10.1109/SCW63240.2024.00137,
author = {Ibrahim, Mohamed Assem and Islam, Mahzabeen and Aga, Shaizeen},
title = {PIMnast: Balanced Data Placement for GEMV Acceleration with Processing-In-Memory},
year = {2025},
isbn = {9798350355543},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SCW63240.2024.00137},
doi = {10.1109/SCW63240.2024.00137},
abstract = {With unprecedented demand for generative AI (GenAI) inference, acceleration of primitives that dominate GenAI such as general matrix-vector multiplication (GEMV) is receiving considerable attention. A challenge with GEMVs is the high memory bandwidth this primitive demands. Multiple memory vendors have proposed commercially viable processing-in-memory (PIM) prototypes that attain bandwidth boost over processor via augmenting memory banks with compute capabilities and broadcasting same command to all banks. While proposed PIM designs stand to accelerate GEMV, we observe in this work that a key impediment to truly harness PIM acceleration is deducing optimal data-placement to place the matrix in memory banks. To this end, we tease out several factors that impact data-placement and propose PIMnast methodology which, like a gymnast, balances these factors to identify data-placements that deliver GEMV acceleration. Across a spectrum of GenAI models, our proposed PIMnast methodology along with additional orchestration knobs we identify delivers up to 6.86\texttimes{} speedup for GEMVs (of the available 7\texttimes{} roofline speedup) leading to up to 5\texttimes{} speedup for per-token latencies.},
booktitle = {Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {970–981},
numpages = {12},
keywords = {GEMV, Generative AI, Processing-in-Memory},
location = {Atlanta, GA, USA},
series = {SC-W '24}
}

@article{10.5555/3722577.3722795,
author = {Reshetova, Daria and Bai, Yikun and Wu, Xiugang and \"{O}zg\"{u}r, Ayfer},
title = {Understanding entropic regularization in GANs},
year = {2024},
issue_date = {January 2024},
publisher = {JMLR.org},
volume = {25},
number = {1},
issn = {1532-4435},
abstract = {Generative Adversarial Networks (GANs) are a popular method for learning distributions from data by modeling the target distribution as a function of a known distribution. The function, often referred to as the generator, is optimized to minimize a chosen distance measure between the generated and target distributions. One commonly used measure for this purpose is the Wasserstein distance. However, Wasserstein distance is hard to compute and optimize, and in practice entropic regularization techniques are used to facilitate its computation and improve numerical convergence. The influence of regularization on the learned solution, however, remains not well-understood. In this paper, we study how several popular entropic regularizations of Wasserstein distance impact the solution learned by a Wasserstein GAN in a simple benchmark setting where the generator is linear and the target distribution is high-dimensional Gaussian. We show that entropy regularization of Wasserstein distance promotes sparsification of the solution, while replacing the Wasserstein distance with the Sinkhorn divergence recovers the unregularized solution. The significant benefit of both regularization techniques is that they remove the curse of dimensionality suffered by Wasserstein distance. We show that in both cases the optimal generator can be learned to accuracy ε with O(1/ε2) samples from the target distribution without requiring to constrain the discriminator. We thus conclude that these regularization techniques can improve the quality of the generator learned from empirical data in a way that is applicable for a large class of distributions.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {218},
numpages = {32},
keywords = {generative adversarial networks, Wasserstein GANs, optimal transport, entropic regularization, Sinkhorn divergence}
}

@inproceedings{10.1145/3581783.3612508,
author = {Wang, Jionghao and Chen, Ziyu and Ling, Jun and Xie, Rong and Song, Li},
title = {360-Degree Panorama Generation from Few Unregistered NFoV Images},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612508},
doi = {10.1145/3581783.3612508},
abstract = {360° panoramas are extensively utilized as environmental light sources in computer graphics. However, capturing a 360° \texttimes{} 180° panorama poses challenges due to the necessity of specialized and costly equipment, and additional human resources. Prior studies develop various learning-based generative methods to synthesize panoramas from a single Narrow Field-of-View (NFoV) image, but they are limited in alterable input patterns, generation quality, and controllability. To address these issues, we propose a novel pipeline called PanoDiff, which efficiently generates complete 360° panoramas using one or more unregistered NFoV images captured from arbitrary angles. Our approach has two primary components to overcome the limitations. Firstly, a two-stage angle prediction module to handle various numbers of NFoV inputs. Secondly, a novel latent diffusion-based panorama generation model uses incomplete panorama and text prompts as control signals and utilizes several geometric augmentation schemes to ensure geometric properties in generated panoramas. Experiments show that PanoDiff achieves state-of-the-art panoramic generation quality and high controllability, making it suitable for applications such as content editing.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {6811–6821},
numpages = {11},
keywords = {360-degree panorama, generative models, image pose estimation, latent diffusion, multimodal models},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3708359.3712146,
author = {Hung, Yu-Kai and Huang, Yun-Chien and Su, Ting-Yu and Lin, Yen-Ting and Cheng, Lung-Pan and Wang, Bryan and Sun, Shao-Hua},
title = {SimTube: Simulating Audience Feedback on Videos using Generative AI and User Personas},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712146},
doi = {10.1145/3708359.3712146},
abstract = {Audience feedback is crucial for refining video content, yet it typically comes after publication, limiting creators’ ability to make timely adjustments. To bridge this gap, we introduce SimTube, a generative AI system designed to simulate audience feedback in the form of video comments before a video’s release. SimTube features a computational pipeline that integrates multimodal data from the video—such as visuals, audio, and metadata—with user personas derived from a broad and diverse corpus of audience demographics, generating varied and contextually relevant feedback. Furthermore, the system’s UI allows creators to explore and customize the simulated comments. Through a comprehensive evaluation—comprising quantitative analysis, crowd-sourced assessments, and qualitative user studies—we show that SimTube’s generated comments are not only relevant, believable, and diverse but often more detailed and informative than actual audience comments, highlighting its potential to help creators refine their content before release.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {1256–1271},
numpages = {16},
keywords = {Feedback Tool, Vision Language Model, Comment Generation},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3652037.3652076,
author = {Bhat, Rithesh and Jain, Bhanu},
title = {Stock Price Trend Prediction using Emotion Analysis of Financial Headlines with Distilled LLM Model},
year = {2024},
isbn = {9798400717604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652037.3652076},
doi = {10.1145/3652037.3652076},
abstract = {Capturing the volatility of stock prices helps individual traders, stock analysts, and institutions alike increase their returns in the stock market. Financial news headlines have been shown to have a significant effect on stock price mobility. Lately, many financial portals have restricted web scraping of stock prices and other related financial data of companies from their websites. In this study we demonstrate that emotion analysis of financial news headlines alone can be sufficient in predicting stock price movement, even in the absence of any financial data. We propose an approach that eliminates the need for web scraping of financial data. We use API based mechanism to retrieve financial news headlines. In this study we train and subsequently leverage light and computationally fast Distilled LLM Model to gather emotional tone and strength of financial news headlines for companies. We then use this information with several machine learning-based classification algorithms to predict the stock price direction based solely on the emotion analysis of news. We demonstrate that emotion analysis-based attributes of financial news headlines are as accurate in predicting the price direction as running the algorithms with the financial data alone.},
booktitle = {Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {67–73},
numpages = {7},
keywords = {Artifical Neural Network, Artificial intelligence, Distilled LLM., LLM, Random Forest, emotion analysis, logistic regression, machine learning, neural networks, sentiment analysis, stock price direction prediction, trend prediction},
location = {Crete, Greece},
series = {PETRA '24}
}

@inproceedings{10.1145/3706598.3713529,
author = {Page, Rowan and See, Jian Shin},
title = {Creative Reflections on Image-Making with Artificial Intelligence: Interactions with a Provocative 'Camera'},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713529},
doi = {10.1145/3706598.3713529},
abstract = {Cameras are increasingly augmented with computational processing, producing images that blur the line between documenting reality and creative expression. The rise of text-to-image models has redefined the concept of imagery, sparking ethical and philosophical debates. This paper presents the findings of a qualitative study that employed a provocative prototype ‘camera’ – the A(I)Cam – to engage creative practitioners directly in these discussions. Developed using a Research-through-Design (RtD) approach, the tangible prototype generates and instantly prints AI-created images. A(I)Cam facilitated reflection among creative practitioners (N=15) on their experiences with AI-driven tools and the broader implications for their future practices. We examine the shifts in perspective that emerged from engaging with this embodied form of generative AI (genAI), challenging traditional text-based interaction paradigms, and inviting new modes of creative exploration and reflection. In addition, we offer insights from the RtD project, highlighting the integration of genAI tools into the industrial design process.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {543},
numpages = {16},
keywords = {Creative AI, Generative AI, Research through Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3627915.3629596,
author = {Miura, Shingo and Mizutani, Tetsuya},
title = {Analysis of Performance Expressions Using Sequential Tension Values},
year = {2023},
isbn = {9798400700590},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627915.3629596},
doi = {10.1145/3627915.3629596},
abstract = {Human performers interpret and perform a piece of music based on their own musical sensibilities and the musical characteristics they read from the information in the score. In doing so, the changes in speed and volume that appear in the performance are called performance expressions. This performance expression changes each time the music piece or performer changes, and we believe that formalizing this expression will make it possible to perform more human-like performances on a computer.In this study, we focused on the fact that Generative Theory of Tonal Music (GTTM) [1], one of the cognitive music theories, uses a parameter called tension value to analyze a piece of music. However, one method of calculating tension values, hierarchical tension values, is not suitable for automatic analysis because it requires consideration based on advanced musical knowledge when calculating them. Therefore, this study uses a parameter called sequential tension value, which is obtained by a different calculation method. Although sequential tension values are less accurate than hierarchical tension values, they have the advantage of being easy to calculate and suitable for automatic analysis. This paper discusses how to improve the accuracy of analysis of musical pieces using sequential tension values and how each component of the musical structure that makes up the sequential tension value affects the analysis results. Multiple regression analysis is used for this analysis, with the musical expression obtained from the local tempo and volume changes for each event calculated from the score data as the objective variable and the musical symbols in each event as the explanatory variables. The accuracy of the obtained regression model is compared with the methods used in previous studies, indicating that the analysis using sequential tension values is useful for music analysis.},
booktitle = {Proceedings of the 7th International Conference on Computer Science and Application Engineering},
articleno = {25},
numpages = {7},
keywords = {CrestMusePEDB, Sequential Tension Value, Tonal Pitch Space},
location = {Virtual Event, China},
series = {CSAE '23}
}

@inproceedings{10.1145/3663976.3664026,
author = {Li, Jiasheng and Meng, Zaiqiao and Liang, Shangsong},
title = {Towards Deep Generative Backmapping of Coarse-Grained Molecular Systems},
year = {2024},
isbn = {9798400716607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663976.3664026},
doi = {10.1145/3663976.3664026},
abstract = {Coarse-graining (CG) is a widely used technique for simplifying complex molecular systems in molecular dynamics simulations. It involves mapping fine-grained (FG) atoms to several CG beads, which enables the study of larger systems and longer simulation timescales. However, this simplification results in the loss of atomistic details. To address this, a technique reverse to CG named backmapping is designed to recover the FG structures from CG beads. Traditional methods of backmapping yield poor reconstructions and often necessitate computationally costly refinement processes. Recently proposed deep learning approaches have shown promise in directly generating atomistic structures with high accuracy. One of the most advanced models deploys a conditional variational auto-encoder (VAE) to encode the FG uncertainties into an invariant latent space and decode them back to FG geometries via equivariant convolutions. Motivated by the recent advancements of diffusion models, we explore an alternative approach to capture the multimodal distribution of FG structures. In this study, we present CGDiff, an equivariant CG-conditional diffusion model for generative backmapping. It models the underlying distribution by condensing the FG information into geometric diffusion processes. Conditioned on CG beads, our model progressively refines the coordinates of FG atoms through equivariant graph neural networks. We evaluate the performance of CGDiff against baselines by conducting experiments on two public datasets. To further promote research in this field, we additionally provide a demo interactive web service for generative backmapping, available at https://huggingface.co/spaces/jsli47/mlbackmap.},
booktitle = {Proceedings of the 2024 2nd Asia Conference on Computer Vision, Image Processing and Pattern Recognition},
articleno = {41},
numpages = {7},
keywords = {Backmapping, Diffusion Model, Graph Neural Network},
location = {Xiamen, China},
series = {CVIPPR '24}
}

@inproceedings{10.1145/3625704.3625744,
author = {Chan, Victor K. Y.},
title = {Evaluation of e-learning platforms using artificial intelligence (AI) robots: Are the AI robots consistent},
year = {2023},
isbn = {9798400709142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625704.3625744},
doi = {10.1145/3625704.3625744},
abstract = {This article aims to explore the consistency between a few popular generative AI robots in the evaluation of e-learning platforms. The three robots adopted in the study were GPT-4, Sage, and Dragonfly, which were requested to award rating scores to the six major dimensions, namely (1) features and capabilities, (2) ease of use and customization, (3) cost, (4) security, (5) customer support, and (6) scalability, of 10 to 20 currently most popular e-learning platforms. For each of the three robots, the minimum, the maximum, the range, and the standard deviation of the rating scores for each of the six dimensions were computed across all the e-learning platforms. The rating score difference for each of the six dimensions between any pair of robots was calculated for each platform. The mean of the absolute value, the minimum, the maximum, the range, and the standard deviation of the differences for each dimensions between each pair of robots were calculated across all platforms. Finally, a Cronbach alpha coefficient of the rating scores was computed for each of the six dimensions between all the three robots across all the e-learning platforms. The computational results were to reveal whether the three robots accorded discrimination in evaluating each dimension across the platforms and whether there was consistency between the three robots in evaluating each dimension across the platforms. Among some auxiliary results, it was found that the evaluation by the three robots was severely inconsistent for the two dimensions cost and security, inconsistent to a lesser extent for the dimension scalability, and consistent for the remaining three dimensions.},
booktitle = {Proceedings of the 7th International Conference on Education and Multimedia Technology},
pages = {96–100},
numpages = {5},
keywords = {E-learning platforms, artificial intelligence, consistency, evaluation, learning management systems},
location = {Tokyo, Japan},
series = {ICEMT '23}
}

@inproceedings{10.1145/3616901.3616941,
author = {Li, Zeng and Yuan, Wei and Wang, Jing and Zhang, Di},
title = {A Novel Image Retrieval Framework based on Generative Adversarial Network},
year = {2024},
isbn = {9798400707544},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616901.3616941},
doi = {10.1145/3616901.3616941},
abstract = {Image retrieval has been studied for decades, and it is one of the core challenges in the computer vision community. Many different works have been proposed to improve image retrieval performance. We, in this work, proposed a generative adversarial network-based image retrieval framework to enhance the image retrieval pipeline’s efficiency and performance. In our proposed work, the images with similar instance objects are the output for the generator by synchronizing the images continuously, and it will lessen the dissimilarities between the query image and retrieved image. This approach analyzes the dissimilarity between the retrieved image and the query image. In the end, a well-trained generator is authorized for image retrieval. We perform our experiments on Oxford5k and Paris6k datasets. The performance evaluation is measured on query expansion and mean average precision benchmarks. The state-of-the-art performance of our proposed method illustrates that we outperformed all evaluations.},
booktitle = {Proceedings of the 2023 International Conference on Frontiers of Artificial Intelligence and Machine Learning},
pages = {182–186},
numpages = {5},
keywords = {Deep Learning, Generative Adversarial Network, Image Retrieval, Model Optimization},
location = {Beijing, China},
series = {FAIML '23}
}

@inproceedings{10.1145/3544549.3577061,
author = {Lehmann, Florian},
title = {Mixed-Initiative Interaction with Computational Generative Systems},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3577061},
doi = {10.1145/3544549.3577061},
abstract = {Machine learning models provide functions to transform and generate image and text data. This promises powerful applications but it remains unclear how users can interact with these models. With my research, I focus on designing, implementing, and evaluating functional prototypes for understanding human-AI interactions. Methodologically, I focus on web-based experiments with a mixed-methods approach. Furthermore, I use these prototypes and generative models as a material to understand fundamental concepts in human-AI interactions, such as initiative, intent, and control. In an already conducted study, for example, I showed that the levels of initiative and control afforded by the UI influence perceived authorship when writing text. For the future, I plan to carry out more studies on collaborative writing. With my dissertation, I contribute to how we will build human-AI interactions and how we will collaborate with computational generative systems in future.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {501},
numpages = {6},
keywords = {control, functional prototypes, generative systems, human-ai interaction, initiative, intent, language model, mixed-initiative, text generation, typing, writing},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@article{10.1145/3643542,
author = {Deng, Hanhui and Jiang, Jianan and Yu, Zhiwang and Ouyang, Jinhui and Wu, Di},
title = {CrossGAI: A Cross-Device Generative AI Framework for Collaborative Fashion Design},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
url = {https://doi.org/10.1145/3643542},
doi = {10.1145/3643542},
abstract = {Fashion design usually requires multiple designers to discuss and collaborate to complete a set of fashion designs, and the efficiency of the sketching process is another challenge for personalized design. In this paper, we introduce a fashion design system, CrossGAI, that can support multiple designers to collaborate on different devices and provide AI-enhanced sketching assistance. Based on the design requirements analysis acquired from the formative study of designers, we develop the system framework of CrossGAI implemented by the user-side web-based cross-device design platform working along with the server-side AI-integrated backend system. The CrossGAI system can be agilely deployed in LAN networks which protects the privacy and security of user data. To further improve both the efficiency and the quality of the sketch process, we devised and exploited generative AI modules, including a sketch retrieval module to retrieve sketches according to stroke or sketch drawn, a sketch generation module enabling the generation of fashion sketches consistent with the designer's unique aesthetic, and an image synthesis module that could achieve sketch-to-image synthesis in accordance with the reference image's style. To optimise the computation offloading when multiple user processes are handled in LAN networks, Lyapunov algorithm with DNN actor is utilized to dynamically optimize the network bandwidth of different clients based on their access history to the application and reduce network latency. The performance of our modules is verified through a series of evaluations under LAN environment, which prove that our CrossGAI system owns competitive ability in AIGC-aided designing. Furthermore, the qualitative analysis on user experience and work quality demonstrates the efficiency and effectiveness of CrossGAI system in design work.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {35},
numpages = {27},
keywords = {Computation Offloading, Cross-device Collaboration, Generative AI}
}

@article{10.1145/3640811,
author = {N., Thenmoezhi and B., Perumal and A., Lakshmi},
title = {Multi-view Image Fusion Using Ensemble Deep Learning Algorithm For MRI And CT Images},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {2375-4699},
url = {https://doi.org/10.1145/3640811},
doi = {10.1145/3640811},
abstract = {Medical image fusions are crucial elements in image-based health care diagnostics or therapies and generic applications of computer visions. However, the majority of existing methods suffer from noise distortion that affects the overall output. When pictures are distorted by noises, classical fusion techniques perform badly. Hence, fusion techniques that properly maintain information comprehensively from multiple faulty pictures need to be created. This work presents Enhanced Lion Swarm Optimization (ESLO) with Ensemble Deep Learning (EDL) to address the aforementioned issues. The primary steps in this study include image fusions, segmentation, noise reduction, feature extraction, picture classification, and feature selection. Adaptive Median Filters are first used for noise removal in sequence to enhance image quality by eliminating noises. The MRIs and CT images are then segmented using the Region Growing–based k-Means Clustering (RKMC) algorithm to separate the images into their component regions or objects. Images in black and white are divided into image. In the white image, the RKMC algorithm successfully considered the earlier tumour probability. The next step is feature extraction, which is accomplished by using the Modified Principal Component Analysis (MPCA) to draw out the most informative aspects of the images. Then the ELSO algorithm is applied for optimal feature selection, which is computed by best fitness values. After that, multi-view image fusions of multi modal images derive lower-, middle-, and higher-level image contents. It is done by using Deep Convolution Neural Network (DCNN) and the Tissue-Aware Conditional Generative Adversarial Network (TAcGAN) algorithm, which fuses the multi-view features and relevant image features, and it is used for real-time applications. ELSO +EDL algorithm gives better results in terms of accuracy, Peak Signal-To-Noise Ratio (PSNR), and lower Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE) when compared to other existing algorithms.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = mar,
articleno = {40},
numpages = {24},
keywords = {Multi-view image fusions, Magnetic Resonance Imaging (MRI) images, Computed Tomography (CT) images, Enhanced Lion Swarm Optimization (ELSO), Ensemble Deep Learning (EDL) algorithm}
}

@article{10.1145/3713075,
author = {El Saddik, Abdulmotaleb and Ahmad, Jamil and Khan, Mustaqeem and Abouzahir, Saad and Gueaieb, Wail},
title = {Unleashing Creativity in the Metaverse: Generative AI and Multimodal Content},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3713075},
doi = {10.1145/3713075},
abstract = {The Metaverse presents an emerging creative expression and collaboration frontier where generative artificial intelligence (GenAI) can play a pivotal role with its ability to generate multimodal content from simple prompts. These prompts allow the metaverse to interact with GenAI, where context information, instructions, input data, or even output indications constituting the prompt can come from within the metaverse. However, their integration poses challenges regarding interoperability, lack of standards, scalability, and maintaining a high-quality user experience. This paper explores how GenAI can productively assist in enhancing creativity within the contexts of the Metaverse and unlock new opportunities. We provide a technical, in-depth overview of the different generative models for image, video, audio, and 3D content within the Metaverse environments. We also explore the bottlenecks, opportunities, and innovative applications of GenAI from the perspectives of end users, developers, service providers, and AI researchers. This survey commences by highlighting the potential of GenAI for enhancing the Metaverse experience through dynamic content generation to populate massive virtual worlds. Subsequently, we shed light on the ongoing research practices and trends in multimodal content generation, enhancing realism and creativity and alleviating bottlenecks related to standardization, computational cost, privacy, and safety. Lastly, we share insights into promising research directions toward the integration of GenAI with the Metaverse for creative enhancement, improved immersion, and innovative interactive applications.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = jan,
keywords = {Generative AI, Metaverse, Diffusion Models, Generative Adversarial Networks, Multimodal, Content Generation}
}

@inproceedings{10.1145/3583133.3596362,
author = {Babaagba, Kehinde O. and Wylie, Jordan},
title = {An Evolutionary based Generative Adversarial Network Inspired Approach to Defeating Metamorphic Malware},
year = {2023},
isbn = {9798400701207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583133.3596362},
doi = {10.1145/3583133.3596362},
abstract = {Defeating dangerous families of malware like polymorphic and metamorphic malware have become well studied due to their increased attacks on computer systems and network. Traditional Machine Learning (ML) models have been used in detecting this malware, however they are often not resistant to future attacks. In this paper, an Evolutionary based Generative Adversarial Network (GAN) inspired approach is proposed as a step towards defeating metamorphic malware. This method uses an Evolutionary Algorithm as a generator to create malware that are designed to fool a detector, a deep learning model into classifying them as benign. We employ a personal information stealing malware family (Dougalek) as a testbed, selected based on its malicious payload and evaluate the samples generated based on their adversarial accuracy, measured based on the number of Antivirus (AV) engines they are able to fool and their ability to fool a set of ML detectors (k-Nearest Neighbors algorithm, Support Vector Machine, Decision Trees, and Multi-Layer Perceptron). The results show that the adversarial samples are on average able to fool 63% of the AV engines and the ML detectors are susceptible to the new mutants achieving an accuracy between 60%-77%.},
booktitle = {Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
pages = {1753–1759},
numpages = {7},
keywords = {generative adversarial network, evolutionary algorithm, metamorphic malware},
location = {Lisbon, Portugal},
series = {GECCO '23 Companion}
}

@article{10.1145/3631420,
author = {Kang, Dong-Sig and Baek, Eunsu and Son, Sungwook and Lee, Youngki and Gong, Taesik and Kim, Hyung-Sin},
title = {MIRROR: Towards Generalizable On-Device Video Virtual Try-On for Mobile Shopping},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
url = {https://doi.org/10.1145/3631420},
doi = {10.1145/3631420},
abstract = {We present MIRROR, an on-device video virtual try-on (VTO) system that provides realistic, private, and rapid experiences in mobile clothes shopping. Despite recent advancements in generative adversarial networks (GANs) for VTO, designing MIRROR involves two challenges: (1) data discrepancy due to restricted training data that miss various poses, body sizes, and backgrounds and (2) local computation overhead that uses up 24% of battery for converting only a single video. To alleviate the problems, we propose a generalizable VTO GAN that not only discerns intricate human body semantics but also captures domain-invariant features without requiring additional training data. In addition, we craft lightweight, reliable clothes/pose-tracking that generates refined pixel-wise warping flow without neural-net computation. As a holistic system, MIRROR integrates the new VTO GAN and tracking method with meticulous pre/post-processing, operating in two distinct phases (on/offline). Our results on Android smartphones and real-world user videos show that compared to a cutting-edge VTO GAN, MIRROR achieves 6.5\texttimes{} better accuracy with 20.1\texttimes{} faster video conversion and 16.9\texttimes{} less energy consumption.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {163},
numpages = {27}
}

@inproceedings{10.1145/3675417.3675543,
author = {Chen, Yajuan and She, Shengxiang and Sun, Yan},
title = {Is AI-generated content better? A study based on Ant Forest Game content recommendation},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675417.3675543},
doi = {10.1145/3675417.3675543},
abstract = {As we entered the 21st century, with the development of computers and mobile internet, research in Artificial Intelligence has made significant advancements. Artificial Intelligence (AI) is a field of science and engineering focused on enabling computers to perform tasks that typically require human intelligence. It encompasses various subfields such as machine learning, expert systems, natural language processing, and computer vision. In 2022, OpenAI released a new chatbot model named ChatGPT, which can understand human language and generate text like a human. Its robust data capabilities have attracted the attention of experts in various fields. However, the public's perception and attitude towards AI technology and ChatGPT are also crucial. Therefore, in this study, we used an online experiment and employed different groups of ChatGPT-generated content recommendation and real-person-generated content recommendation as experimental manipulation conditions. From the user perception perspective, we aimed to explore the differences between user perceptions of content recommendation provided by Artificial Intelligence (ChatGPT) and those provided by real-person. We also investigated whether the perception of AI-generated (ChatGPT) content recommendation had an impact on users' subsequent intention to support Ant Forest Game. The results show significant differences in perceived content quality between AI-generated (ChatGPT) Ant Forest Game content recommendation and real-person-generated content recommendation. Additionally, in terms of subsequent support intention for Ant Forest Game, there were also significant differences between AI-generated (ChatGPT) Ant Forest Game content recommendation and real-person generated Ant Forest Game content recommendation. Ant Forest Game content recommendation was found to significantly enhance Ant Forest Game support intention. Participants exhibited higher perceived content quality and greater support intention for AI-generated (ChatGPT) Ant Forest Game content recommendation. This study explores the psychological mechanisms involved in human-computer interaction, contributing to research in the field of Artificial Intelligence. Compared to a real human person's recommendation, people tend to prefer ChatGPT's recommendation, showing that people exhibit similar social behaviors and emotional responses when interacting with generative AI (ChatGPT) as they do with real humans. These findings are significant for the development and improvement of Artificial Intelligence.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {749–755},
numpages = {7},
location = {Hongkong, China},
series = {DEAI '24}
}

@inproceedings{10.1145/3592571.3592978,
author = {Mach\'{a}\v{c}ek, Roman and Mozaffari, Leila and Sepasdar, Zahra and Parasa, Sravanthi and Halvorsen, P\r{a}l and Riegler, Michael A. and Thambawita, Vajira},
title = {Mask-conditioned latent diffusion for generating gastrointestinal polyp images},
year = {2023},
isbn = {9798400701863},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3592571.3592978},
doi = {10.1145/3592571.3592978},
abstract = {In order to take advantage of artificial intelligence (AI) solutions in endoscopy diagnostics, we must overcome the issue of limited annotations. These limitations are caused by the high privacy concerns in the medical field and the requirement of getting aid from experts for the time-consuming and costly medical data annotation process. In computer vision, image synthesis has made a significant contribution in recent years, as a result of the progress of generative adversarial networks (GANs) and diffusion probabilistic models (DPMs). Novel DPMs have outperformed GANs in text, image, and video generation tasks. Therefore, this study proposes a conditional DPM framework to generate synthetic gastrointestinal (GI) polyp images conditioned on given generated segmentation masks. Our experimental results show that our system can generate an unlimited number of high-fidelity synthetic polyp images with the corresponding ground truth masks of polyps. To test the usefulness of the generated data we trained binary image segmentation models to study the effect of using synthetic data. Results show that the best micro-imagewise intersection over union (IOU) of 0.7751 was achieved from DeepLabv3+ when the training data consists of both real data and synthetic data. However, the results reflect that achieving good segmentation performance with synthetic data heavily depends on model architectures.},
booktitle = {Proceedings of the 4th ACM Workshop on Intelligent Cross-Data Analysis and Retrieval},
pages = {1–9},
numpages = {9},
keywords = {polyp segmentation, polyp generative model, generating synthetic data, diffusion model},
location = {Thessaloniki, Greece},
series = {ICDAR '23}
}

@inproceedings{10.1145/3548606.3563493,
author = {Hallman, Roger A.},
title = {Poster EveGAN: Using Generative Deep Learning for Cryptanalysis},
year = {2022},
isbn = {9781450394505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3548606.3563493},
doi = {10.1145/3548606.3563493},
abstract = {Cryptography and Machine Learning are two computational science fields that intuitively seem related. Privacy-preserving machine learning-either utilizing encrypted models or learning over encrypted data-is an exploding field thanks to the maturation of primitives such as fully homomorphic encryption and secure multiparty computation. However there has been surprisingly little work on applying recent advances in machine learning to the task of cryptanalysis, the branch of cryptography that studies how cryptographic ciphers can be attacked. In particular, while a cryptographic cipher seeks to keep certain information secret by making it appear random, discerning patterns and structure from random data is a common machine learning task. This paper proposes EveGAN, an approach that treats cryptanalysis as a language translation problem. While treating cipher cracking as a language translation problem has been validated against a handful of classical substitution ciphers, the EveGAN approach builds on these results to create a new class of generative deep learning-based cryptanalysis attacks.},
booktitle = {Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security},
pages = {3355–3357},
numpages = {3},
keywords = {language translation, generative adversarial networks, forgery/poisoning attacks, cryptography, cryptanalysis},
location = {Los Angeles, CA, USA},
series = {CCS '22}
}

@article{10.1145/3559540,
author = {Brophy, Eoin and Wang, Zhengwei and She, Qi and Ward, Tom\'{a}s},
title = {Generative Adversarial Networks in Time Series: A Systematic Literature Review},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {10},
issn = {0360-0300},
url = {https://doi.org/10.1145/3559540},
doi = {10.1145/3559540},
abstract = {Generative adversarial network (GAN) studies have grown exponentially in the past few years. Their impact has been seen mainly in the computer vision field with realistic image and video manipulation, especially generation, making significant advancements. Although these computer vision advances have garnered much attention, GAN applications have diversified across disciplines such as time series and sequence generation. As a relatively new niche for GANs, fieldwork is ongoing to develop high-quality, diverse, and private time series data. In this article, we review GAN variants designed for time series related applications. We propose a classification of discrete-variant GANs and continuous-variant GANs, in which GANs deal with discrete time series and continuous time series data. Here we showcase the latest and most popular literature in this field—their architectures, results, and applications. We also provide a list of the most popular evaluation metrics and their suitability across applications. Also presented is a discussion of privacy measures for these GANs and further protections and directions for dealing with sensitive data. We aim to frame clearly and concisely the latest and state-of-the-art research in this area and their applications to real-world technologies.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {199},
numpages = {31},
keywords = {continuous-variant GANs, discrete-variant GANs, time series, Generative adversarial networks}
}

@inproceedings{10.1145/3574131.3574448,
author = {Zhou, Lanfeng and Ji, Xiaoyun and Li, Ling},
title = {Monocular Human Body Shape Estimation: A Generation-aid Approach},
year = {2023},
isbn = {9798400700316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3574131.3574448},
doi = {10.1145/3574131.3574448},
abstract = {Observing human beings from monocular images is one of the basic tasks of computer vision. Reconstructing human bodies from monocular images mainly includes the reconstruction of posture and body shape. However, in the past studies, researchers were more interested in pose estimation, ignoring the study of body shape, and this paper focuses on the estimation of the body shape of a 3D model. Learning body parameters via instance segmentation requires a large number of labels. While the parameters based on pose estimation are completely based on the results of key points detection, which effect is not friendly for pictures with poor angles and low resolution. In response to the above problems, we propose a method to automatically generate datasets. The dataset provides low-resolution images and labels of various angles and blurred shapes. On the generated low-resolution and poorly angled dataset, we propose a generative-assisted deep learning network framework. Experiments show that the framework can effectively estimate the body shape parameters of the model from monocular images.},
booktitle = {Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry},
articleno = {19},
numpages = {8},
keywords = {Monocular image, Generative network, Deep learning, Body shape, 3D human reconstruction},
location = {Guangzhou, China},
series = {VRCAI '22}
}

@inproceedings{10.1145/3627673.3679122,
author = {Zhang, Bo-Wen and Yan, Yan and Li, Lin and Liu, Guang},
title = {InfinityMath: A Scalable Instruction Tuning Dataset in Programmatic Mathematical Reasoning},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679122},
doi = {10.1145/3627673.3679122},
abstract = {Recent advancements in Chain-of-Thoughts (CoT) and Program-of-Thoughts (PoT) methods have greatly enhanced language models' mathematical reasoning capabilities, facilitating their integration into instruction tuning datasets with LLMs. However, existing methods for large-scale dataset creation require substantial seed data and high computational costs for data synthesis, posing significant challenges for scalability. We introduce InfinityMATH, a scalable instruction tuning dataset for programmatic mathematical reasoning. The construction pipeline emphasizes decoupling numbers from mathematical problems to synthesize number-independent programs, enabling efficient and flexible scaling while minimizing dependency on specific numerical values. Fine-tuning experiments with open-source language and code models, such as Llama2 and CodeLlama, demonstrate the practical benefits of InfinityMATH. These fine-tuned models, showed significant relative improvements on both in-domain and out-of-domain benchmarks, ranging from 184.7% to 514.3% on average. Additionally, these models exhibited high robustness on the GSM8K+ and MATH+ benchmarks, which are enhanced version of test sets with simply the number variations. InfinityMATH ensures that models are more versatile and effective across a broader range of mathematical problems. The data is available at https://huggingface.co/datasets/flagopen/InfinityMATH.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5405–5409},
numpages = {5},
keywords = {data augmentation, data synthesis, decoupled numeric dependencies, logical inconsistencies, programmatic mathematical reasoning},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3725891,
author = {Strohm, Florian and B\^{a}ce, Mihai and Bulling, Andreas},
title = {HAIFAI: Human-AI Interaction for Mental Face Reconstruction},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {2160-6455},
url = {https://doi.org/10.1145/3725891},
doi = {10.1145/3725891},
abstract = {We present HAIFAI—a novel two-stage system where humans and AI interact to tackle the challenging task of reconstructing a visual representation of a face that exists only in a person’s mind. In the first stage, users iteratively rank images our reconstruction system presents based on their resemblance to a mental image. These rankings, in turn, allow the system to extract relevant image features, fuse them into a unified feature vector and use a generative model to produce an initial reconstruction of the mental image. The second stage leverages an existing face editing method, allowing users to manually refine and further improve this reconstruction using an easy-to-use slider interface for face shape manipulation. To avoid the need for tedious human data collection for training the reconstruction system, we introduce a computational user model of human ranking behaviour. For this, we collected a small face ranking dataset through an online crowd-sourcing study containing data from 275 participants. We evaluate HAIFAI and an ablated version in a 12-participant user study and demonstrate that our approach outperforms the previous state of the art regarding reconstruction quality, usability, perceived workload and reconstruction speed. We further validate the reconstructions in a subsequent face ranking study with 18 participants and show that HAIFAI achieves a new state-of-the-art identification rate of 60.6%. These findings represent a significant advancement towards developing new interactive intelligent systems capable of reliably and effortlessly reconstructing a user’s mental image.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = may,
articleno = {10},
numpages = {26},
keywords = {mental image reconstruction, faces, user modelling, deep learning}
}

@inproceedings{10.1145/3662739.3673681,
author = {Zhang, Liwen and Tang, Mengting and Xu, Yaqi and Zhang, Chengfang},
title = {Application Research on Artificial Intelligence Generated Content in Architectural Design},
year = {2024},
isbn = {9798400718144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662739.3673681},
doi = {10.1145/3662739.3673681},
abstract = {Computational design has profoundly influenced the development of the architecture industry over the past few decades, significantly enhancing the efficiency of architectural design and construction. This paper compares and studies the Mid Journey and Stable Diffusion AIGC image models to analyze their operational logic and construct a new architectural design process. Finally, the effectiveness and practicality of this process are validated through practical cases, and the future development prospects of AIGC in the field of architectural design are anticipated. This paper explores the use of Mid Journey and table Diffusion combined with generative AI text model to optimize prompt language, large model and Lora model, and Control Net-Stable Diffusion plugin and different AI software forms a complete AI-assisted architectural design process.},
booktitle = {Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications},
pages = {671–680},
numpages = {10},
keywords = {Artificial Intelligence generated content (AIGC), architectural design, design optimization},
location = {Ningbo, China},
series = {MIDA '24}
}

@article{10.1145/3729226,
author = {Nadiri, Amirhossein and Li, Jing and Faraji, Ali and Abuoda, Ghadeer and Papagelis, Manos},
title = {TrajLearn: Trajectory Prediction Learning using Deep Generative Models},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {2374-0353},
url = {https://doi.org/10.1145/3729226},
doi = {10.1145/3729226},
abstract = {Trajectory prediction aims to estimate an entity’s future path using its current position and historical movement data, benefiting fields like autonomous navigation, robotics, and human movement analytics. Deep learning approaches have become key in this area, utilizing large-scale trajectory datasets to model movement patterns, but face challenges in managing complex spatial dependencies and adapting to dynamic environments. To address these challenges, we introduce TrajLearn, a novel model for trajectory prediction that leverages generative modeling of higher-order mobility flows based on hexagonal spatial representation. TrajLearn predicts the next k steps by integrating a customized beam search for exploring multiple potential paths while maintaining spatial continuity. We conducted a rigorous evaluation of TrajLearn, benchmarking it against leading state-of-the-art approaches and meaningful baselines. The results indicate that TrajLearn achieves significant performance gains, with improvements of up to ~40% across multiple real-world trajectory datasets. In addition, we evaluated different prediction horizons (i.e., various values of k), conducted resolution sensitivity analysis, and performed ablation studies to assess the impact of key model components. Furthermore, we developed a novel algorithm to generate mixed-resolution maps by hierarchically subdividing hexagonal regions into finer segments within a specified observation area. This approach supports selective detailing, applying finer resolution to areas of interest or high activity (e.g., urban centers) while using coarser resolution for less significant regions (e.g., rural or uninhabited areas), effectively reducing data storage requirements and computational overhead. We promote reproducibility and adaptability by offering complete code, data, and detailed documentation with flexible configuration options for various applications.},
journal = {ACM Trans. Spatial Algorithms Syst.},
month = may,
articleno = {12},
numpages = {33},
keywords = {Mobility data analytics, spatial data mining, trajectory prediction, deep generative models}
}

@article{10.1145/3703457,
author = {Roy, Antika and Al Hasan, MD Mahfuz and Ghosh, Shajib and Varshney, Nitin and Julia, Jake and Forghani, Reza and Asadizanjani, Navid},
title = {Applications and Challenges of AI in PCB X-ray Inspection: A Comprehensive Study},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1550-4832},
url = {https://doi.org/10.1145/3703457},
doi = {10.1145/3703457},
abstract = {As printed circuit boards (PCBs) continue to evolve in complexity and miniaturization, the demand for robust and efficient inspection techniques has become paramount in ensuring the quality and reliability of electronic devices. The application of machine learning and deep learning techniques has revolutionized PCB inspection in recent years, enabling the ability to automate and improve numerous elements of the process. In this article, a comprehensive analysis is performed on the applications and challenges of AI, encompassing techniques of deep learning and machine learning, in the domain of PCB X-ray scrutiny. The main focus of this research centers around defect detection, identification of components and layers, deep learning algorithms for image reconstruction, as well as the identification of defects and features in advanced packaging. This study examines the current cutting-edge advancements in each of these areas, closely examining the existing methodologies and technologies employed. Furthermore, it delves into the limitations and challenges inherent in PCB X-ray inspection, such as the unavailability of data, computational demands, and the interpretability of models. In addition, this article offers prospective insights and presents promising avenues like application of generative adversarial networks and deep learning reconstruction methods for future exploration.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = jan,
articleno = {1},
numpages = {28},
keywords = {Deep learning, Convolutional Neural Networks, Synthetic Image Generation, Generative Adversarial Networks, Dimensionality Reduction, Netlist Extraction, Advancedr Packaging, Reconstruction, Iterative Reconstruction}
}

@inproceedings{10.5555/3716662.3716800,
author = {Wojtowicz, Zachary},
title = {When and Why is Persuasion Hard? A Computational Complexity Result},
year = {2025},
publisher = {AAAI Press},
abstract = {As generative foundation models improve, they also tend to become more persuasive, raising concerns that AI automation will enable governments, firms, and other actors to manipulate beliefs with unprecedented scale and effectiveness at virtually no cost. The full economic and social ramifications of this trend have been difficult to foresee, however, given that we currently lack a complete theoretical understanding of why persuasion is costly for human labor to produce in the first place. This paper places human and AI agents on a common conceptual footing by formalizing informational persuasion as a mathematical decision problem and characterizing its computational complexity. A novel proof establishes that persuasive messages are challenging to discover (NP-Hard) but easy to adopt if supplied by others (NP). This asymmetry helps explain why people are susceptible to persuasion, even in contexts where all relevant information is publicly available. The result also illuminates why litigation, strategic communication, and other persuasion-oriented activities have historically been so human capital intensive, and it provides a new theoretical basis for studying how AI will impact various industries.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {1591–1594},
numpages = {4},
location = {San Jose, California, USA},
series = {AIES '24}
}

@inproceedings{10.1145/3696271.3696305,
author = {Mao, Maoyu and Shen, Zhuoyi and Fan, Pengfei},
title = {Improved Diffusion Model for Fast Image Generation},
year = {2024},
isbn = {9798400717833},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696271.3696305},
doi = {10.1145/3696271.3696305},
abstract = {This paper provides methods and implementations to increase the speed of image generation with less sacrifice of image generation quality. This study reviews the development of image generation techniques, including early convolutional neural networks, variational autoencoders (VAEs), and generative models such as generative adversarial networks (GANs). In recent years, denoising diffusion probabilistic models (DDPM) have become a new trend in image generation. This trend is mainly attributed to the superior performance of DDPMs in generating high-quality images, as well as their demonstration of higher stability and consistency when dealing with complex data distributions. The ability of DDPMs to provide more granular control and predict the quality of generation through a process of gradual noise reduction compared to traditional GANs has led to their widespread interest and use in academic and industrial applications. However, in order to reduce the time and computational cost required for DDPM to generate images, an improved version of DDPM, the Denoising Diffusion Implicit Model (DDIM), is used in this study. This model effectively speeds up the image generation by optimising the diffusion process while maintaining less loss in the quality of the generated images. Firstly, The DDIM model was experimented on four different datasets, including Swiss Volume dataset, MNIST dataset, CIFAR10 dataset, and Celeba dataset, in order to comprehensively evaluate the performance and applicability of the model. In addition, in order to compare the difference in the quality of generated images between DDIM and DDPM, the experiments provide an objective measure of the quality of the generated images of the two by using the Frechette Initiation Distance (FID) as an evaluation metric. The final experimental results show that the DDIM model obtained a FID score of 21.67 on the unconditional CIFAR10 dataset and a FID score of 18.87 on the unconditional Celeba dataset. In comparison, the DDPM model obtained a FID score of 12.14 on the unconditional CIFAR10 dataset and a FID score of 5.25 on the unconditional Celeba dataset. As for the image generation rate, the experiment is 793.50% faster than DDPM for generating 50 CIFAR10 images at time step 1000. These results demonstrate the effectiveness of the DDIM model in dealing with different types of datasets, and also highlight the fact that it sacrifices some of the quality of the generated images for its advantage in terms of speed of image generation compared to the DDPM model. This study demonstrates the potential and usefulness of the DDIM model in the field of fast and high-quality image generation, and points out the direction of further improvement of the model in the future.},
booktitle = {Proceedings of the 2024 7th International Conference on Machine Learning and Machine Intelligence (MLMI)},
pages = {209–216},
numpages = {8},
keywords = {Denoising Diffusion Implicit Models, Denoising Diffusion Probabilistic Models, Fast Image generation, Frechet Inception Distance},
location = {
},
series = {MLMI '24}
}

@inproceedings{10.1145/3613905.3650998,
author = {Deshpande, Manoj and Magerko, Brian},
title = {Embracing Embodied Social Cognition in AI: Moving Away from Computational Theory of Mind},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650998},
doi = {10.1145/3613905.3650998},
abstract = {As artificial intelligence becomes more integral to daily life, the need to design AI systems capable of understanding human interactions is increasingly important. This paper delves into the integration of social cognition in AI, tracing back to its historical foundations and examining seminal theories like Newell’s Bands of Cognition, Minsky’s Society of Mind, etc., which have emphasized the importance of social cognition since AI’s inception. We highlight the shortcomings of traditional computational theory of mind approaches, particularly in their failure to capture the embodied nature of social cognition. Advocating for including embodied socio-cognitive perspectives, we draw on theories such as Participatory Sensemaking and frameworks like Observable Creative Sensemaking. The paper further demonstrates the practical implementation of these concepts in AI through two case studies: one in co-creative dance AI and another in text-to-image generative AI systems.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {119},
numpages = {7},
keywords = {AI, Embodiment, Sensemaking, Social Cognition},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3533271.3561669,
author = {Feng, Yichen and Min, Ming and Fouque, Jean-Pierre},
title = {Deep Learning for Systemic Risk Measures},
year = {2022},
isbn = {9781450393768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3533271.3561669},
doi = {10.1145/3533271.3561669},
abstract = {The aim of this paper is to study a new methodological framework for systemic risk measures by applying deep learning method as a tool to compute the optimal strategy of capital allocations. Under this new framework, systemic risk measures can be interpreted as the minimal amount of cash that secures the aggregated system by allocating capital to the single institutions before aggregating the individual risks. This problem has no explicit solution except in very limited situations. Deep learning is increasingly receiving attention in financial modelings and risk management and we propose our deep learning based algorithms to solve both the primal and dual problems of the risk measures, and thus to learn the fair risk allocations. In particular, our method for the dual problem involves the training philosophy inspired by the well-known Generative Adversarial Networks (GAN) approach and a newly designed direct estimation of Radon-Nikodym derivative. We close the paper with substantial numerical studies of the subject and provide interpretations of the risk allocations associated to the systemic risk measures. In the particular case of exponential preferences, numerical experiments demonstrate excellent performance of the proposed algorithm, when compared with the optimal explicit solution as a benchmark.},
booktitle = {Proceedings of the Third ACM International Conference on AI in Finance},
pages = {62–69},
numpages = {8},
keywords = {systemic risk measure, risk modeling and risk management, risk allocations, deep learning, banking system, Radon-Nikodym derivative, GAN},
location = {New York, NY, USA},
series = {ICAIF '22}
}

@inproceedings{10.1145/3490422.3502329,
author = {Liu, Yanqi and Opipari, Anthony and Guerin, Theo and Bahar, Ruth Iris},
title = {Hardware Acceleration of Nonparametric Belief Propagation for Efficient Robot Manipulation},
year = {2022},
isbn = {9781450391498},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490422.3502329},
doi = {10.1145/3490422.3502329},
abstract = {Probabilistic graphical models (PGMs) have been widely used in computer vision, robotics, and statistics. Generative inference algorithms used to solve PGMs, such as belief propagation (BP), involve integration over high-dimensional variables, which becomes computationally infeasible. Drawing inspiration from particle filters, nonparametric belief propagation (NBP) combines the efficiency of Monte-Carlo sampling to capture the belief space of hidden variables while preserving accuracy and algorithm robustness. In this poster presentation, we describe a novel method to accelerate an NBP algorithm in hardware and evaluate our approach on the 6 degree-of-freedom (DoF) articulated object pose estimation problem. Our two major contributions include 1) identifying three independent computation flows in the algorithm to effectively overlap the two main steps of the algorithm: belief update and message update, and 2) creating deeply pipelined processing units that allow for fine-grained parallelism, which helps to balance the workloads on different computation streams. Results from this study demonstrate that our design achieves both improved runtime and energy efficiency. In particular, we achieved 26X energy saving compared to running the algorithm on a Titan Xp GPU, and 10X runtime speedup and 14X energy saving compared to running on the Jetson AGX . We believe that our FPGA implementation can greatly improve particle-based sampling methods for real time applications.},
booktitle = {Proceedings of the 2022 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
pages = {51},
numpages = {1},
keywords = {real-time system architecture, hardware accelerators, belief propagation},
location = {Virtual Event, USA},
series = {FPGA '22}
}

@inproceedings{10.1145/3573942.3574097,
author = {Zhai, Sheping and Liu, Yuanbiao and Cheng, Dabao},
title = {Single Image Dehazing Via Enhanced CycleGAN},
year = {2023},
isbn = {9781450396899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573942.3574097},
doi = {10.1145/3573942.3574097},
abstract = {Due to the influence of atmospheric light scattering, the images acquired by outdoor imaging device in haze scene will appear low definition, contrast reduction, overexposure and other visible quality degradation, which makes it difficult to handle the relevant computer vision tasks. Therefore, image dehazing has become an important research area of computer vision. However, existing dehazing methods generally require paired image datasets that include both hazy images and corresponding ground truth images, while the recovered images are easy to occur color distortion and detail loss. In this study, an end-to-end image dehazing method based on Cycle-consistent Generative Adversarial Networks (CycleGAN) is proposed. For effectively learning the mapping relationship between hazy images and clear images, we refine the transformation module of the generator by weighting optimization, which can promote the network adaptability to scale. Then in order to further improve the quality of generated images, the enhanced perceptual loss and low-frequency loss combined with image feature attributes are constructed in the overall optimization objective of the network. The experimental results show that our dehazing algorithm effectively recovers the texture information while correcting the color distortion of original CycleGAN, and the recovery effect is clear and more natural, which better reduces the influence of haze on the imaging quality.},
booktitle = {Proceedings of the 2022 5th International Conference on Artificial Intelligence and Pattern Recognition},
pages = {795–802},
numpages = {8},
location = {Xiamen, China},
series = {AIPR '22}
}

@inproceedings{10.1145/3477495.3531827,
author = {Chen, Jiangui and Zhang, Ruqing and Guo, Jiafeng and Fan, Yixing and Cheng, Xueqi},
title = {GERE: Generative Evidence Retrieval for Fact Verification},
year = {2022},
isbn = {9781450387323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477495.3531827},
doi = {10.1145/3477495.3531827},
abstract = {Fact verification (FV) is a challenging task which aims to verify a claim using multiple evidential sentences from trustworthy corpora, e.g., Wikipedia. Most existing approaches follow a three-step pipeline framework, including document retrieval, sentence retrieval and claim verification. High-quality evidences provided by the first two steps are the foundation of the effective reasoning in the last step. Despite being important, high-quality evidences are rarely studied by existing works for FV, which often adopt the off-the-shelf models to retrieve relevant documents and sentences in an "index-retrieve-then-rank'' fashion. This classical approach has clear drawbacks as follows: i) a large document index as well as a complicated search process is required, leading to considerable memory and computational overhead; ii) independent scoring paradigms fail to capture the interactions among documents and sentences in ranking; iii) a fixed number of sentences are selected to form the final evidence set. In this work, we proposeGERE, the first system that retrieves evidences in a generative fashion, i.e., generating the document titles as well as evidence sentence identifiers. This enables us to mitigate the aforementioned technical issues since: i) the memory and computational cost is greatly reduced because the document index is eliminated and the heavy ranking process is replaced by a light generative process; ii) the dependency between documents and that between sentences could be captured via sequential generation process; iii) the generative formulation allows us to dynamically select a precise set of relevant evidences for each claim. The experimental results on the FEVER dataset show that GERE achieves significant improvements over the state-of-the-art baselines, with both time-efficiency and memory-efficiency.},
booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2184–2189},
numpages = {6},
keywords = {generative retrieval, fact verification, evidence retrieval},
location = {Madrid, Spain},
series = {SIGIR '22}
}

@inproceedings{10.1145/3627673.3679770,
author = {Dong, Zhijun and Wu, Likang and Zhang, Kai and Liu, Ye and Zhang, Yanghai and Li, Zhi and Zhao, Hongke and Chen, Enhong},
title = {FZR: Enhancing Knowledge Transfer via Shared Factors Composition in Zero-Shot Relational Learning},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679770},
doi = {10.1145/3627673.3679770},
abstract = {Zero-Shot Relational Learning (ZSRL), strives to predict relations that have not been observed during training, presenting a considerable challenge in terms of model generalization. Existing ZSRL methods usually utilize the prior knowledge of labels (e.g., text description, ontological schema) to enable knowledge transfer by learned features. Nonetheless, these methods remain limited to calculating the surface features exhibited by relations, failing to fully explore their underlying driving factors. This leads to insufficient discrimination between the shared and distinctive inherent components among relations, which consequently impedes the cognitive understanding required for advanced reasoning. In our study, we aim to identify and utilize shared factors that widely exist in the prior knowledge of classes to learn enhanced semantic representations via shared factors composition, and develop our Factor-based ZSRL framework (FZR) with Generative Adversarial Networks (GANs) to bridge inequality between seen and unseen classes. FZR is designed to restructure the semantic space in such a way that it captures the essence of relation formation, thereby facilitating superior knowledge transfer in zero-shot scenarios. We conduct extensive experiments and evaluate our model on real-world datasets, and the results clearly demonstrate the effectiveness of the proposed model in zero-shot relational learning tasks.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {497–507},
numpages = {11},
keywords = {generative adversarial networks, knowledge transfer, shared factors, zero-shot relational learning},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3505244,
author = {Khan, Salman and Naseer, Muzammal and Hayat, Munawar and Zamir, Syed Waqas and Khan, Fahad Shahbaz and Shah, Mubarak},
title = {Transformers in Vision: A Survey},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {10s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3505244},
doi = {10.1145/3505244},
abstract = {Astounding results from Transformer models on natural language tasks have intrigued the vision community to study their application to computer vision problems. Among their salient benefits, Transformers enable modeling long dependencies between input sequence elements and support parallel processing of sequence as compared to recurrent networks, e.g., Long short-term memory. Different from convolutional networks, Transformers require minimal inductive biases for their design and are naturally suited as set-functions. Furthermore, the straightforward design of Transformers allows processing multiple modalities (e.g., images, videos, text, and speech) using similar processing blocks and demonstrates excellent scalability to very large capacity networks and huge datasets. These strengths have led to exciting progress on a number of vision tasks using Transformer networks. This survey aims to provide a comprehensive overview of the Transformer models in the computer vision discipline. We start with an introduction to fundamental concepts behind the success of Transformers, i.e., self-attention, large-scale pre-training, and bidirectional feature encoding. We then cover extensive applications of transformers in vision including popular recognition tasks (e.g., image classification, object detection, action recognition, and segmentation), generative modeling, multi-modal tasks (e.g., visual-question answering, visual reasoning, and visual grounding), video processing (e.g., activity recognition, video forecasting), low-level vision (e.g., image super-resolution, image enhancement, and colorization), and three-dimensional analysis (e.g., point cloud classification and segmentation). We compare the respective advantages and limitations of popular techniques both in terms of architectural design and their experimental value. Finally, we provide an analysis on open research directions and possible future works. We hope this effort will ignite further interest in the community to solve current challenges toward the application of transformer models in computer vision.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {200},
numpages = {41},
keywords = {literature survey, self-supervision, convolutional networks, deep neural networks, bidirectional encoders, transformers, Self-attention}
}

@inproceedings{10.1145/3650400.3650507,
author = {Li, Hongna and Li, Yuhan and Zhou, Jingjie},
title = {An Improved Neural Network Bispectral Index Monitoring Algorithm in Time and Frequency DomainAn Improved Bispectral Index Monitoring Algorithm},
year = {2024},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650400.3650507},
doi = {10.1145/3650400.3650507},
abstract = {Bispectral index is one of the techniques used to monitor the state of human brain activity, expressed in units of 0-100. However, in the current context of intelligent medicine, the closeness and complexity of traditional bispectral index calculation pose certain limitations to the level of EEG monitoring. Therefore, the study is proposed an algorithm based on an improved auxiliary classifier generative adversarial networks as the bispectral index estimation method. A combination of time-domain and frequency-domain analysis methods is employed during training to improve the accuracy of the algorithm's outcomes. The experiment has been showed that the mean absolute error of the model in 60 second electroencephalogram dataset with bispectral index tags is 3.61. Compared to other existing neural networks, it has achieved better prediction performance under different regression evaluation indicators. The model that is utilised time-domain and frequency-domain signals as inputs has even better performance than the model that is only utilised single signals as inputs.},
booktitle = {Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
pages = {645–650},
numpages = {6},
location = {Xiamen, China},
series = {EITCE '23}
}

@inproceedings{10.1145/3645259.3645277,
author = {Mahara, Arpan and Rishe, Naphtali D.},
title = {Generative Adversarial Model Equipped with Contrastive Learning in Map Synthesis},
year = {2024},
isbn = {9798400708473},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3645259.3645277},
doi = {10.1145/3645259.3645277},
abstract = {In the dynamic field of urban planning and the context of unprecedented natural events, such as hurricanes, the fast generation of accurate maps from satellite imagery is paramount. While several studies have utilized Generative Adversarial Networks (GANs) for map generation from satellite images, the present work introduces a new approach by integrating contrastive learning into the GAN framework for enhanced map synthesis. Our methodology distinctively employs positive sampling by aligning similar features (e.g., roads) in both satellite images and their corresponding map outputs, and contrasts this with negative samples for disparate elements. This approach effectively replaces the conventional cyclic process in GANs with a more streamlined, unidirectional procedure, leading to improvements in both the quality of the synthesized maps and computational efficiency. We show the effectiveness of our proposed model, offering an advancement in map generation for remote sensing applications.},
booktitle = {Proceedings of the 2024 6th International Conference on Image Processing and Machine Vision},
pages = {107–114},
numpages = {8},
keywords = {Anchor, Contrastive Learning, CycleGAN, Generation, Generative Adversarial Networks (GANs), Map, PatchNCE, Satellite Imagery, Synthesis},
location = {Macau, China},
series = {IPMV '24}
}

@inproceedings{10.1145/3569219.3569418,
author = {Ghajargar, Maliheh and Bardzell, Jeffrey and Lagerkvist, Love},
title = {A Redhead Walks into a Bar: Experiences of Writing Fiction with Artificial Intelligence},
year = {2022},
isbn = {9781450399555},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569219.3569418},
doi = {10.1145/3569219.3569418},
abstract = {Human creativity has been often aided and supported by artificial tools, spanning traditional tools such as ideation cards, pens, and paper, to computed and software. Tools for creativity are increasingly using artificial intelligence to not only support the creative process, but also to act upon the creation with a higher level of agency. This paper focuses on writing fiction as a creative activity and explores human-AI co-writing through a research product, which employs a natural language processing model, the Generative Pre-trained Transformer 3 (GPT-3), to assist the co-authoring of narrative fiction. We report on two progressive – not comparative – autoethnographic studies to attain our own creative practices in light of our engagement with the research product: (1) a co-writing activity initiated by basic textual prompts using basic elements of narrative and (2) a co-writing activity initiated by more advanced textual prompts using elements of narrative, including dialects and metaphors undertaken by one of the authors of this paper who has doctoral training in literature. In both studies, we quickly came up against the limitations of the system; then, we repositioned our goals and practices to maximize our chances of success. As a result, we discovered not only limitations but also hidden capabilities, which not only altered our creative practices and outcomes, but which began to change the ways we were relating to the AI as collaborator.},
booktitle = {Proceedings of the 25th International Academic Mindtrek Conference},
pages = {230–241},
numpages = {12},
keywords = {Artificial creativity, Creative writing, Creativity tool, GPT-3, Storytelling, AI co-creativity},
location = {Tampere, Finland},
series = {Academic Mindtrek '22}
}

@inproceedings{10.1145/3573942.3573974,
author = {Lomurno, Eugenio and Archetti, Alberto and Cazzella, Lorenzo and Samele, Stefano and Di Perna, Leonardo and Matteucci, Matteo},
title = {SGDE: Secure Generative Data Exchange for Cross-Silo Federated Learning},
year = {2023},
isbn = {9781450396899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573942.3573974},
doi = {10.1145/3573942.3573974},
abstract = {Privacy regulation laws, such as GDPR, impose transparency and security as design pillars for data processing algorithms. In this context, federated learning is one of the most influential frameworks for privacy-preserving distributed machine learning, achieving astounding results in many natural language processing and computer vision tasks. Several federated learning frameworks employ differential privacy to prevent private data leakage to unauthorized parties and malicious attackers. Many studies, however, highlight the vulnerabilities of standard federated learning to poisoning and inference, thus raising concerns about potential risks for sensitive data. To address this issue, we present SGDE, a generative data exchange protocol that improves user security and machine learning performance in a cross-silo federation. The core of SGDE is to share data generators with strong differential privacy guarantees trained on private data instead of communicating explicit gradient information. These generators synthesize an arbitrarily large amount of data that retain the distinctive features of private samples but differ substantially. In this work, SGDE is tested in a cross-silo federated network on images and tabular datasets, exploiting beta-variational autoencoders as data generators. From the results, the inclusion of SGDE turns out to improve task accuracy and fairness, as well as resilience to the most influential attacks on federated learning.},
booktitle = {Proceedings of the 2022 5th International Conference on Artificial Intelligence and Pattern Recognition},
pages = {205–214},
numpages = {10},
keywords = {Deep learning, Differential privacy, Federated learning, Generative deep learning, Gradient leakage, Privacy},
location = {Xiamen, China},
series = {AIPR '22}
}

@inproceedings{10.1145/3641584.3641631,
author = {Memari, Majid and Ahmed, Khaled R. and Rahimi, Shahram},
title = {Generative Data Augmentation for Arabic Handwritten Digit Recognition Boosting Real-time OCR Capabilities},
year = {2024},
isbn = {9798400707674},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641584.3641631},
doi = {10.1145/3641584.3641631},
abstract = {This study assesses the effectiveness of Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) in enhancing Optical Character Recognition (OCR) accuracy for Arabic handwritten digits, an area with limited research and significant challenges arising from character similarities. By employing data augmentation to generate varied images, we aim to address the issues OCR systems face with low-quality or distorted inputs. We introduce a novel procedure to calculate the Fr\'{e}chet Inception Distance (FID), to accurately measure the quality of synthetic images during training, facilitating early stopping to optimize model performance. Additionally, using Saliency Maps allows for detailed analysis of OCR improvements. Our findings highlight the potential of synthetic data in advancing real-time OCR systems, with our evaluation procedure offering a faster, more accurate alternative to traditional quality metrics.},
booktitle = {Proceedings of the 2023 6th International Conference on Artificial Intelligence and Pattern Recognition},
pages = {312–323},
numpages = {12},
keywords = {Generative Adversarial Networks, Generative Models, Optical Character Recognition, Real-time Data Augmentation, Synthetic Image Evaluation, Variational Autoencoders},
location = {Xiamen, China},
series = {AIPR '23}
}

@inproceedings{10.1145/3664647.3681182,
author = {Liu, Miao and Wang, Jing and Qian, Xinyuan and Li, Haizhou},
title = {ListenFormer: Responsive Listening Head Generation with Non-autoregressive Transformers},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681182},
doi = {10.1145/3664647.3681182},
abstract = {As one of the crucial elements in human-robot interaction, responsive listening head generation has attracted considerable attention from researchers. It aims to generate a listening head video based on speaker's audio and video as well as a reference listener image. However, existing methods exhibit two limitations: 1) the generation capability of their models is limited, resulting in generated videos that are far from real ones, and 2) they mostly employ autoregressive generative models, unable to mitigate the risk of error accumulation. To tackle these issues, we propose Listenformer that leverages the powerful temporal modeling capability of transformers for generation. It can perform non-autoregressive prediction with the proposed two-stage training method, simultaneously achieving temporal continuity and overall consistency in the outputs. To fully utilize the information from the speaker inputs, we designed an audio-motion attention fusion module, which improves the correlation of audio and motion features for accurate response. Additionally, a novel decoding method called sliding window with a large shift is proposed for Listenformer, demonstrating both excellent computational efficiency and effectiveness. Extensive experiments show that Listenformer outperforms the existing state-of-the-art methods on ViCo and L2L datasets. And a perceptual user study demonstrates the comprehensive performance of our method in generating diversity, identity preserving, speaker-listener synchronization, and attitude matching. Our code is available at https://liushenme.github.io/ListenFormer.github.io/.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {7094–7103},
numpages = {10},
keywords = {listening head generation, transformer, video synthesis},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@article{10.1145/3709011,
author = {Gong, Nanxu and Ying, Wangyang and Wang, Dongjie and Fu, Yanjie},
title = {Neuro-Symbolic Embedding for Short and Effective Feature Selection via Autoregressive Generation},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {2157-6904},
url = {https://doi.org/10.1145/3709011},
doi = {10.1145/3709011},
abstract = {Feature selection aims to identify the optimal feature subset for enhancing downstream models. Effective feature selection can remove redundant features, save computational resources, accelerate the model learning process, and improve the model overall performance. However, existing works are often time-intensive to identify the effective feature subset within high-dimensional feature spaces. Meanwhile, these methods mainly utilize a single downstream task performance as the selection criterion, leading to the selected subsets that are not only redundant but also lack generalizability. To bridge these gaps, we reformulate feature selection through a neuro-symbolic lens and introduce a novel generative framework aimed at identifying short and effective feature subsets. More specifically, we found that feature ID tokens of the selected subset can be formulated as symbols to reflect the intricate correlations among features. Thus, in this framework, we first create a data collector to automatically collect numerous feature selection samples consisting of feature ID tokens, model performance, and the measurement of feature subset redundancy. Building on the collected data, an encoder-decoder-evaluator learning paradigm is developed to preserve the intelligence of feature selection into a continuous embedding space for efficient search. Within the learned embedding space, we leverage a multi-gradient search algorithm to find more robust and generalized embeddings with the objective of improving model performance and reducing feature subset redundancy. These embeddings are then utilized to reconstruct the feature ID tokens for executing the final feature selection. Ultimately, comprehensive experiments and case studies are conducted to validate the effectiveness of the proposed framework. The associated data and code are publicly available ().},
journal = {ACM Trans. Intell. Syst. Technol.},
month = feb,
articleno = {37},
numpages = {21},
keywords = {Feature selection, neuro-symbolic generative learning, multi-objective optimization}
}

@inproceedings{10.1145/3595916.3626363,
author = {Kaji, Ryota and Yanai, Keiji},
title = {VQ-VDM: Video Diffusion Models with 3D VQGAN},
year = {2024},
isbn = {9798400702051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3595916.3626363},
doi = {10.1145/3595916.3626363},
abstract = {In recent years, deep generative models have achieved impressive performance such as realizing image generation that is indistinguishable from real images. Particularly, Latent Diffusion Models, one of the image generation models, have had a significant impact on society. Therefore, video generation is attracting attention as the next modality. However, video generation is more challenging than image generation due to the consideration of temporal consistency and the increase in computational complexity, since a video is a sequence of multiple frames. In this study, we propose a video generation model based on diffusion models employing 3D VQGAN, which is called VQ-VDM. The proposed model is about nine times faster than the Video Diffusion Models which directly generate videos, since our model generates a latent representation which is decoded into a video by a VQGAN decoder. Moreover, our model can generate higher quality video than prior video generation methods exclude state-of-the-art method.},
booktitle = {Proceedings of the 5th ACM International Conference on Multimedia in Asia},
articleno = {90},
numpages = {5},
keywords = {3D VQGAN, diffusion models, video generation},
location = {Tainan, Taiwan},
series = {MMAsia '23}
}

@article{10.5555/3722479.3722491,
author = {Hegde, Vageesh and Bolar, Supreetha},
title = {Unveiling the Nexus: AI, Environmental Impact, and Cost},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {As we move into 2024, the global landscape is experiencing a significant increase in the adoption of artificial intelligence (AI), which is revolutionizing industries and societies. AI, powered by machine learning (ML) and other advanced programming techniques, represents non-human intelligence capable of learning from large datasets. This transformative technology presents unparalleled opportunities, but also significant challenges, particularly with regards to its environmental impact and economic feasibility. This paper explores the two sides of AI development: Generative AI requires a lot of processing power, leading to high energy consumption and substantial CO2 emissions, affecting its cost-effectiveness and environmental impact. It meticulously examines the complex components contributing to the operational costs of AI models, including computational resources, data storage, energy consumption, and infrastructure requirements. It rigorously analyzes factors influencing these costs, such as model complexity, data volume, and technological infrastructure, to provide a comprehensive framework for cost analysis in AI. Furthermore, the paper explores methodologies for evaluating and quantifying these operational costs, which are essential for calculating return on investment (ROI) in AI initiatives. Real-world case studies illustrate the practical applications of AI, comparing different models to determine their cost-effectiveness and ROI. The paper discusses emerging trends in AI development focused on reducing environmental impact, including green AI initiatives and energy-efficient strategies. It concludes with insights into future research directions, advocating for advancements in cost analysis methodologies and sustainable AI practices to promote responsible AI innovation. In summary, his paper offers a comprehensive analysis of the economic and environmental aspects of AI deployment, providing valuable insights for stakeholders navigating the complexities of AI implementation in a rapidly evolving technological landscape.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {37–38},
numpages = {2}
}

@inproceedings{10.1145/3662739.3672304,
author = {Jin, Huijiao and Wang, Fei and Jiang, Lanying and Tian, Meng},
title = {Application of CNN in Visual Image Design: Image Feature Extraction and Processing},
year = {2024},
isbn = {9798400718144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662739.3672304},
doi = {10.1145/3662739.3672304},
abstract = {Abstract: In response to the problems of insufficient personalization and unclear feature extraction in traditional visual image design, this paper studied an image feature extraction and processing method based on CNN (Convolutional Neural Networks). Firstly, the images were preprocessed and enhanced to enhance the generalization ability and feature extraction performance of the CNN model; a lightweight CNN architecture and MobileNet (Mobile Network) were designed to reduce computational complexity and parameters, and the model was optimized through technical means; generative adversarial networks (GANs) were utilized to integrate creative elements and enhance the innovation of advertising design. Through transfer learning, the CNN model was adjusted, and the Adam optimizer and early stop strategy were adopted for model training and optimization. In the experiment of feature extraction accuracy, the accuracy of the model in this paper reached 98.8%, 97.8%, and 98%, and it was also better than the comparison model in the comparative experiment. In the generalization ability test, the model did not overfit and demonstrated good generalization ability; in the processing time test, the architecture used in this paper had a shorter processing time than other architectures; in the survey on the integration effect of creative elements, the attractiveness rating reached 96% of the positive reviews.},
booktitle = {Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications},
pages = {569–573},
numpages = {5},
keywords = {Convolutional Neural Networks, Generative Adversarial Networks, Image Feature Extraction and Processing, Mobile Network, Visual Image Design},
location = {Ningbo, China},
series = {MIDA '24}
}

@inproceedings{10.1145/3559400.3565581,
author = {Lipkowitz, Gabriel and Shaqfeh, Eric and DeSimone, Joseph},
title = {Generative co-design for microfluidics-accelerated 3D printing},
year = {2022},
isbn = {9781450398725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3559400.3565581},
doi = {10.1145/3559400.3565581},
abstract = {Increasing the speed of 3D printing is critical for its widespread adoption as a manufacturing technique. A recently-introduced multi-material 3D printing process called injection CLIP has been shown to accelerate printing by nearly an order of magnitude using computationally-designed microfluidic networks. However, automated design tools for 3D microfluidics have lagged far behind increasing fabrication capabilities and needs. Here, to facilitate the study and application of this novel printing process, we present a fluid dynamics-informed generative design tool for microfluidic networks based on native CAD geometries.},
booktitle = {Proceedings of the 7th Annual ACM Symposium on Computational Fabrication},
articleno = {26},
numpages = {3},
location = {Seattle, WA, USA},
series = {SCF '22}
}

@article{10.1145/3514244,
author = {Rajasekaran, Suren Deepak and Kang, Hao and \v{C}ad\'{\i}k, Martin and Galin, Eric and Gu\'{e}rin, Eric and Peytavie, Adrien and Slav\'{\i}k, Pavel and Benes, Bedrich},
title = {PTRM: Perceived Terrain Realism Metric},
year = {2022},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1544-3558},
url = {https://doi.org/10.1145/3514244},
doi = {10.1145/3514244},
abstract = {Terrains are visually prominent and commonly needed objects in many computer graphics applications. While there are many algorithms for synthetic terrain generation, it is rather difficult to assess the realism of a generated output. This article presents a first step toward the direction of perceptual evaluation for terrain models. We gathered and categorized several classes of real terrains, and we generated synthetic terrain models using computer graphics methods. The terrain geometries were rendered by using the same texturing, lighting, and camera position. Two studies on these image sets were conducted, ranking the terrains perceptually, and showing that the synthetic terrains are perceived as lacking realism compared to the real ones. We provide insight into the features that affect the perceived realism by a quantitative evaluation based on localized geomorphology-based landform features (geomorphons) that categorize terrain structures such as valleys, ridges, hollows, and so forth. We show that the presence or absence of certain features has a significant perceptual effect. The importance and presence of the terrain features were confirmed by using a generative deep neural network that transferred the features between the geometric models of the real terrains and the synthetic ones. The feature transfer was followed by another perceptual experiment that further showed their importance and effect on perceived realism. We then introduce Perceived Terrain Realism Metrics (PTRM), which estimates human-perceived realism of a terrain represented as a digital elevation map by relating the distribution of terrain features with their perceived realism. This metric can be used on a synthetic terrain, and it will output an estimated level of perceived realism. We validated the proposed metrics on real and synthetic data and compared them to the perceptual studies.},
journal = {ACM Trans. Appl. Percept.},
month = jul,
articleno = {6},
numpages = {22},
keywords = {Procedural modeling, terrains, visual perception, feature transfer, neural networks}
}

@inproceedings{10.1145/3569052.3572993,
author = {Lu, Yi-Chen and Ren, Haoxing and Hsiao, Hao-Hsiang and Lim, Sung Kyu},
title = {DREAM-GAN: Advancing DREAMPlace towards Commercial-Quality using Generative Adversarial Learning},
year = {2023},
isbn = {9781450399784},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569052.3572993},
doi = {10.1145/3569052.3572993},
abstract = {DREAMPlace is a renowned open-source placer that provides GPU-acceleratable infrastructure for placements of Very-Large-Scale-Integration (VLSI) circuits. However, due to its limited focus on wirelength and density, existing placement solutions of DREAMPlace are not applicable to industrial design flows. To improve DREAMPlace towards commercial-quality without knowing the black-boxed algorithms of the tools, in this paper, we present DREAM-GAN, a placement optimization framework that advances DREAMPlace using generative adversarial learning. At each placement iteration, aside from optimizing the wirelength and density objectives of the vanilla DREAMPlace, DREAM-GAN computes and optimizes a differentiable loss that denotes the similarity score between the underlying placement and the tool-generated placements in commercial databases. Experimental results on 5 commercial and OpenCore designs using an industrial design flow implemented by Synopsys ICC2 not only demonstrate that DREAM-GAN significantly improves the vanilla DREAMPlace at the placement stage across each benchmark, but also show that the improvements last firmly to the post-route stage, where we observe improvements by up to 8.3% in wirelength and 7.4% in total power.},
booktitle = {Proceedings of the 2023 International Symposium on Physical Design},
pages = {141–148},
numpages = {8},
keywords = {generative adversarial learning, placement optimization},
location = {Virtual Event, USA},
series = {ISPD '23}
}

@inproceedings{10.1145/3615522.3615545,
author = {Chen, Yihan and Ye, Yilin and Zeng, Wei},
title = {The Rich, the Poor, and the Ugly: An Aesthetic-Perspective Assessment of NFT Values},
year = {2023},
isbn = {9798400707513},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615522.3615545},
doi = {10.1145/3615522.3615545},
abstract = {The adoption of non-fungible tokens (NFTs) has revolutionized digital art transactions, providing artists with unprecedented opportunities to tokenize and monetize their generative creations, leading to increased scrutiny and demand within blockchain-oriented marketplaces. The pricing of NFT artworks, however, exhibits substantial variations within and across collections, influenced by various factors. This study aims to investigate the relationship between visual features and pricing, shedding light on the variations underlying the pricing of NFTs. First, measures of both computational aesthetics and visual complexity were applied to extract multi-faceted visual aesthetic features, encompassing aesthetic factors such as color and composition as well as complexity factors like entropy. Second, with extracted visual aesthetic features and preprocessed price data, the study proceeds to conduct correlation analysis within collections and statistical modeling across collections. Through these approaches, we reveal a moderate correlation between visual features and prices within collections, while also identifying different influential visual features across collections. The differential performance of price models highlights the distinctiveness and unique pricing characteristics of NFT collections.},
booktitle = {Proceedings of the 16th International Symposium on Visual Information Communication and Interaction},
articleno = {23},
numpages = {8},
keywords = {Non-fungible tokens, computational aesthetics, statistical modeling},
location = {Guangzhou, China},
series = {VINCI '23}
}

@article{10.1145/3605548,
author = {Zhang, Yuxin and Tang, Fan and Dong, Weiming and Huang, Haibin and Ma, Chongyang and Lee, Tong-Yee and Xu, Changsheng},
title = {A Unified Arbitrary Style Transfer Framework via Adaptive Contrastive Learning},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {5},
issn = {0730-0301},
url = {https://doi.org/10.1145/3605548},
doi = {10.1145/3605548},
abstract = {This work presents Unified Contrastive Arbitrary Style Transfer (UCAST), a novel style representation learning and transfer framework, that can fit in most existing arbitrary image style transfer models, such as CNN-based, ViT-based, and flow-based methods. As the key component in image style transfer tasks, a suitable style representation is essential to achieve satisfactory results. Existing approaches based on deep neural networks typically use second-order statistics to generate the output. However, these hand-crafted features computed from a single image cannot leverage style information sufficiently, which leads to artifacts such as local distortions and style inconsistency. To address these issues, we learn style representation directly from a large number of images based on contrastive learning by considering the relationships between specific styles and the holistic style distribution. Specifically, we present an adaptive contrastive learning scheme for style transfer by introducing an input-dependent temperature. Our framework consists of three key components: a parallel contrastive learning scheme for style representation and transfer, a domain enhancement (DE) module for effective learning of style distribution, and a generative network for style transfer. Qualitative and quantitative evaluations show the results of our approach are superior to those obtained via state-of-the-art methods. The code is available at .},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {169},
numpages = {16},
keywords = {Arbitrary style transfer, contrastive learning, style encoding}
}

@inproceedings{10.1145/3534678.3539032,
author = {Moomtaheen, Fariha and Killeen, Matthew and Oswald, James and Gonz\`{a}lez-Rosell, Anna and Mastracco, Peter and Gorovits, Alexander and Copp, Stacy M. and Bogdanov, Petko},
title = {DNA-Stabilized Silver Nanocluster Design via Regularized Variational Autoencoders},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539032},
doi = {10.1145/3534678.3539032},
abstract = {DNA-stabilized silver nanoclusters (AgN-DNAs) are a class of nanomaterials comprised of 10-30 silver atoms held together by short synthetic DNA template strands. AgN-DNAs are promising biosensors and fluorophores due to their small sizes, natural compatibility with DNA, and bright fluorescence---the property of absorbing light and re-emitting light of a different color. The sequence of the DNA template acts as a "genome" for AgN-DNAs, tuning the size of the encapsulated silver nanocluster, and thus its fluorescence color. However, current understanding of the AgN-DNA genome is still limited. Only a minority of DNA sequences produce highly fluorescent AgN-DNAs, and the bulky DNA strands and complex DNA-silver interactions make it challenging to use first principles chemical calculations to understand and design AgN-DNAs. Thus, a major challenge for researchers studying these nanomaterials is to develop methods to employ observational data about studied AgN-DNAs to design new nanoclusters for targeted applications.In this work, we present an approach to design AgN-DNAs by employing variational autoencoders (VAEs) as generative models. Specifically, we employ an LSTM-based β-VAE architecture and regularize its latent space to correlate with AgN-DNA properties such as color and brightness. The regularization is adaptive to skewed sample distributions of available observational data along our design axes of properties. We employ our model for design of AgN-DNAs in the near-infrared (NIR) band, where relatively few AgN-DNAs have been observed to date. Wet lab experiments validate that when employed for designing new AgN-DNAs, our model significantly shifts the distribution of AgN-DNA colors towards the NIR while simultaneously achieving bright fluorescence. This work shows that VAE-based generative models are well-suited for the design of AgN-DNAs with multiple targeted properties, with significant potential to advance the promising applications of these nanomaterials for bioimaging, biosensing, and other critical technologies.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3593–3602},
numpages = {10},
keywords = {DNA, nanomaterials design, variational autoencoders},
location = {Washington DC, USA},
series = {KDD '22}
}

@article{10.5555/3722577.3722929,
author = {Zhang, Chunming and Gao, Muhong and Jia, Shengji},
title = {DAG-informed structure learning from multi-dimensional point processes},
year = {2024},
issue_date = {January 2024},
publisher = {JMLR.org},
volume = {25},
number = {1},
issn = {1532-4435},
abstract = {Motivated by inferring causal relationships among neurons using ensemble spike train data, this paper introduces a new technique for learning the structure of a directed acyclic graph (DAG) within a large network of events, applicable to diverse multi-dimensional temporal point process (MuTPP) data. At the core of MuTPP lie the conditional intensity functions, for which we construct a generative model parameterized by the graph parameters of a DAG and develop an equality-constrained estimator, departing from exhaustive search-based methods. We present a novel, flexible augmented Lagrangian (Flex-AL) optimization scheme that ensures provable global convergence and computational efficiency gains over the classical AL algorithm. Additionally, we explore causal structure learning by integrating acyclicity-constraints and sparsity-regularization. We demonstrate: (i) in cases without regularization, the incorporation of the acyclicity constraint is essential for ensuring DAG recovery consistency; (ii) with suitable regularization, the DAG-constrained estimator achieves both parameter estimation and DAG reconstruction consistencies similar to the unconstrained counterpart, but significantly enhances empirical performance. Furthermore, simulation studies indicate that our proposed DAG-constrained estimator, when appropriately penalized, yields more accurate graphs compared to unconstrained or unregularized estimators. Finally, we apply the proposed method to two real MuTPP datasets.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {352},
numpages = {56},
keywords = {asymptotic consistency, causal structure, constrained optimization, multivariate counting process, structural Hamming distance}
}

@article{10.5555/3586589.3586704,
author = {Tran, Linh and Pantic, Maja and Deisenroth, Marc Peter},
title = {Cauchy-Schwarz regularized autoencoder},
year = {2022},
issue_date = {January 2022},
publisher = {JMLR.org},
volume = {23},
number = {1},
issn = {1532-4435},
abstract = {Recent work in unsupervised learning has focused on efficient inference and learning in latent variables models. Training these models by maximizing the evidence (marginal likelihood) is typically intractable. Thus, a common approximation is to maximize the Evidence Lower BOund (ELBO) instead. Variational autoencoders (VAE) are a powerful and widely-used class of generative models that optimize the ELBO efficiently for large datasets. However, the VAE's default Gaussian choice for the prior imposes a strong constraint on its ability to represent the true posterior, thereby degrading overall performance. A Gaussian mixture model (GMM) would be a richer prior but cannot be handled efficiently within the VAE framework because of the intractability of the Kullback-Leibler divergence for GMMs. We deviate from the common VAE framework in favor of one with an analytical solution for Gaussian mixture prior. To perform efficient inference for GMM priors, we introduce a new constrained objective based on the Cauchy-Schwarz divergence, which can be computed analytically for GMMs. This new objective allows us to incorporate richer, multi-modal priors into the autoencoding framework. We provide empirical studies on a range of datasets and show that our objective improves upon variational autoencoding models in density estimation, unsupervised clustering, semi-supervised learning, and face analysis.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {115},
numpages = {37},
keywords = {generative models, Cauchy-Schwarz divergence, constrained optimization, auto-encoding models, face analysis}
}

@inproceedings{10.1145/3586183.3606795,
author = {Strohm, Florian and B\^{a}ce, Mihai and Bulling, Andreas},
title = {Usable and Fast Interactive Mental Face Reconstruction},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606795},
doi = {10.1145/3586183.3606795},
abstract = {We introduce an end-to-end interactive system for mental face reconstruction – the challenging task of visually reconstructing a face image a person only has in their mind. In contrast to existing methods that suffer from low usability and high mental load, our approach only requires the user to rank images over multiple iterations according to the perceived similarity with their mental image. Based on these rankings, our mental face reconstruction system extracts image features in each iteration, combines them into a joint feature vector, and then uses a generative model to visually reconstruct the mental image. To avoid the need for collecting large amounts of human training data, we further propose a computational user model that can simulate human ranking behaviour using data from an online crowd-sourcing study (N=215). Results from a 12-participant user study show that our method can reconstruct mental images that are visually similar to existing approaches but has significantly higher usability, lower perceived workload, and is faster. In addition, results from a third 22-participant lineup study in which we validated our reconstructions on a face ranking task show a identification rate of , which is in line with prior work. These results represent an important step towards new interactive intelligent systems that can robustly and effortlessly reconstruct a user’s mental image.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {99},
numpages = {15},
keywords = {deep learning, faces, mental image reconstruction, user modelling},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@article{10.5555/3648699.3648909,
author = {Bengio, Yoshua and Lahlou, Salem and Deleu, Tristan and Hu, Edward J. and Tiwari, Mo and Bengio, Emmanuel},
title = {GFlowNet foundations},
year = {2023},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates in an active learning context, with a training objective that makes them approximately sample in proportion to a given reward function. In this paper, we show a number of additional theoretical properties of GFlowNets, including a new local and efficient training objective called detailed balance for the analogy with MCMC. GFlowNets can be used to estimate joint probability distributions and the corresponding marginal distributions where some variables are unspecified and, of particular interest, can represent distributions over composite objects like sets and graphs. GFlowNets amortize the work typically done by computationally expensive MCMC methods in a single but trained generative pass. They could also be used to estimate partition functions and free energies, conditional probabilities of supersets (supergraphs) given a subset (subgraph), as well as marginal distributions over all supersets (supergraphs) of a given set (graph). We introduce variations enabling the estimation of entropy and mutual information, continuous actions and modular energy functions.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {210},
numpages = {55}
}

@article{10.1109/TASLP.2024.3473319,
author = {Gonzalez, Philippe and Tan, Zheng-Hua and \O{}stergaard, Jan and Jensen, Jesper and Alstr\o{}m, Tommy Sonne and May, Tobias},
title = {Investigating the Design Space of Diffusion Models for Speech Enhancement},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3473319},
doi = {10.1109/TASLP.2024.3473319},
abstract = {Diffusion models are a new class of generative models that have shown outstanding performance in image generation literature. As a consequence, studies have attempted to apply diffusion models to other tasks, such as speech enhancement. A popular approach in adapting diffusion models to speech enhancement consists in modelling a progressive transformation between the clean and noisy speech signals. However, one popular diffusion model framework previously laid in image generation literature did not account for such a transformation towards the system input, which prevents from relating the existing diffusion-based speech enhancement systems with the aforementioned diffusion model framework. To address this, we extend this framework to account for the progressive transformation between the clean and noisy speech signals. This allows us to apply recent developments from image generation literature, and to systematically investigate design aspects of diffusion models that remain largely unexplored for speech enhancement, such as the neural network preconditioning, the training loss weighting, the stochastic differential equation (SDE), or the amount of stochasticity injected in the reverse process. We show that the performance of previous diffusion-based speech enhancement systems cannot be attributed to the progressive transformation between the clean and noisy speech signals. Moreover, we show that a proper choice of preconditioning, training loss weighting, SDE and sampler allows to outperform a popular diffusion-based speech enhancement system while using fewer sampling steps, thus reducing the computational cost by a factor of four.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {4486–4500},
numpages = {15}
}

@inproceedings{10.1109/MICRO56248.2022.00051,
author = {Hong, Seongmin and Moon, Seungjae and Kim, Junsoo and Lee, Sungjae and Kim, Minsub and Lee, Dongsoo and Kim, Joo-Young},
title = {DFX: A Low-Latency Multi-FPGA Appliance for Accelerating Transformer-Based Text Generation},
year = {2023},
isbn = {9781665462723},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MICRO56248.2022.00051},
doi = {10.1109/MICRO56248.2022.00051},
abstract = {Transformer is a deep learning language model widely used for natural language processing (NLP) services in datacenters. Among transformer models, Generative Pre-trained Transformer (GPT) has achieved remarkable performance in text generation, or natural language generation (NLG), which needs the processing of a large input context in the summarization stage, followed by the generation stage that produces a single word at a time. The conventional platforms such as GPU are specialized for the parallel processing of large inputs in the summarization stage, but their performance significantly degrades in the generation stage due to its sequential characteristic. Therefore, an efficient hardware platform is required to address the high latency caused by the sequential characteristic of text generation.In this paper, we present DFX, a multi-FPGA acceleration appliance that executes GPT-2 model inference end-to-end with low latency and high throughput in both summarization and generation stages. DFX uses model parallelism and optimized dataflow that is model-and-hardware-aware for fast simultaneous workload execution among devices. Its compute cores operate on custom instructions and provide GPT-2 operations end-to-end. We implement the proposed hardware architecture on four Xilinx Alveo U280 FPGAs and utilize all of the channels of the high bandwidth memory (HBM) and the maximum number of compute resources for high hardware efficiency. DFX achieves 5.58\texttimes{} speedup and 3.99\texttimes{} energy efficiency over four NVIDIA V100 GPUs on the modern GPT-2 model. DFX is also 8.21\texttimes{} more cost-effective than the GPU appliance, suggesting that it is a promising solution for text generation workloads in cloud datacenters.},
booktitle = {Proceedings of the 55th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {616–630},
numpages = {15},
keywords = {natural language processing, GPT, text generation, datacenter, multi-FPGA acceleration, model parallelism},
location = {Chicago, Illinois, USA},
series = {MICRO '22}
}

@article{10.1145/3578521,
author = {Huang, Jingmin and Chen, Bowei and Yan, Zhi and Ounis, Iadh and Wang, Jun},
title = {GEO: A Computational Design Framework for Automotive Exterior Facelift},
year = {2023},
issue_date = {July 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {6},
issn = {1556-4681},
url = {https://doi.org/10.1145/3578521},
doi = {10.1145/3578521},
abstract = {Exterior facelift has become an effective method for automakers to boost the consumers’ interest in an existing car model before it is redesigned. To support the automotive facelift design process, this study develops a novel computational framework&nbsp;– Generator, Evaluator, Optimiser (GEO), which comprises three components: a StyleGAN2-based design generator that creates different facelift designs; a convolutional neural network (CNN)-based evaluator that assesses designs from the aesthetics perspective; and a recurrent neural network (RNN)-based decision optimiser that selects designs to maximise the predicted profit of the targeted car model over time. We validate the GEO framework in experiments with real-world datasets and describe some resulting managerial implications for automotive facelift. Our study makes both methodological and application contributions. First, the generator’s mapping network and projection methods are carefully tailored to facelift where only minor changes are performed without affecting the family signature of the automobile brands. Second, two evaluation metrics are proposed to assess the generated designs. Third, profit maximisation is taken into account in the design selection. From a high-level perspective, our study contributes to the recent use of machine learning and data mining in marketing and design studies. To the best of our knowledge, this is the first study that uses deep generative models for automotive regional design upgrading and that provides an end-to-end decision-support solution for automakers and designers.},
journal = {ACM Trans. Knowl. Discov. Data},
month = mar,
articleno = {82},
numpages = {20},
keywords = {Automotive design, exterior facelift, design generation, aesthetics evaluation, decision optimisation}
}

@inproceedings{10.1145/3581783.3612356,
author = {Kang, Xujie and Liu, Kanglin and Duan, Jiang and Gong, Yuanhao and Qiu, Guoping},
title = {P2I-NET: Mapping Camera Pose to Image via Adversarial Learning for New View Synthesis in Real Indoor Environments},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612356},
doi = {10.1145/3581783.3612356},
abstract = {Given a new 6DoF camera pose in an indoor environment, we study the challenging problem of predicting the view from that pose based on a set of reference RGBD views. Existing explicit or implicit 3D geometry construction methods are computationally expensive while those based on learning have predominantly focused on isolated views of object categories with regular geometric structure. Differing from the traditional render-inpaint approach to new view synthesis in the real indoor environment, we propose a conditional generative adversarial neural network (P2I-NET) to directly predict the new view from the given pose. P2I-NET learns the conditional distribution of the images of the environment for establishing the correspondence between the camera pose and its view of the environment, and achieves this through a number of innovative designs in its architecture and training lost function. Two auxiliary discriminator constraints are introduced for enforcing the consistency between the pose of the generated image and that of the corresponding real world image in both the latent feature space and the real world pose space. Additionally a deep convolutional neural network (CNN) is introduced to further reinforce this consistency in the pixel space. We have performed extensive new view synthesis experiments on real indoor datasets. Results show that P2I-NET has superior performance against a number of NeRF based strong baseline models. In particular, we show that P2I-NET is 40 to 100 times faster than these competitor techniques while synthesising similar quality images. Furthermore, we contribute a new publicly available indoor environment dataset containing 22 high resolution RGBD videos where each frame also has accurate camera pose parameters.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {2635–2643},
numpages = {9},
keywords = {conditional generative adversarial network, new view image, rgbd datasets},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3548814.3551460,
author = {Shimizu, Kye and Ienaga, Naoto and Takada, Kazuma and Sugimoto, Maki and Kasahara, Shunichi},
title = {Human Latent Metrics: Perceptual and Cognitive Response Correlates to Distance in GAN Latent Space for Facial Images},
year = {2022},
isbn = {9781450394550},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3548814.3551460},
doi = {10.1145/3548814.3551460},
abstract = {Generative adversarial networks (GANs) generate high-dimensional vector spaces (latent spaces) that can interchangeably represent vectors as images. Advancements have extended their ability to computationally generate images indistinguishable from real images such as faces, and more importantly, to manipulate images using their inherit vector values in the latent space. This interchangeability of latent vectors has the potential to calculate not only the distance in the latent space, but also the human perceptual and cognitive distance toward images, that is, how humans perceive and recognize images. However, it is still unclear how the distance in the latent space correlates with human perception and cognition. Our studies investigated the relationship between latent vectors and human perception or cognition through psycho-visual experiments that manipulates the latent vectors of face images. In the perception study, a change perception task was used to examine whether participants could perceive visual changes in face images before and after moving an arbitrary distance in the latent space. In the cognition study, a face recognition task was utilized to examine whether participants could recognize a face as the same, even after moving an arbitrary distance in the latent space. Our experiments show that the distance between face images in the latent space correlates with human perception and cognition for visual changes in face imagery, which can be modeled with a logistic function. By utilizing our methodology, it will be possible to interchangeably convert between the distance in the latent space and the metric of human perception and cognition, potentially leading to image processing that better reflects human perception and cognition.},
booktitle = {ACM Symposium on Applied Perception 2022},
articleno = {3},
numpages = {10},
keywords = {change perception, face cognition, generative adversarial networks},
location = {TBC, USA},
series = {SAP '22}
}

@article{10.1109/TASLP.2022.3190736,
author = {Ferrer, Luciana and Castan, Diego and McLaren, Mitchell and Lawson, Aaron},
title = {A Discriminative Hierarchical PLDA-Based Model for Spoken Language Recognition},
year = {2022},
issue_date = {2022},
publisher = {IEEE Press},
volume = {30},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2022.3190736},
doi = {10.1109/TASLP.2022.3190736},
abstract = {Spoken language recognition (SLR) refers to the automatic process used to determine the language present in a speech sample. SLR is an important task in its own right, for example, as a tool to analyze or categorize large amounts of multi-lingual data. Further, it is also an essential tool for selecting downstream applications in a work flow, for example, to chose appropriate speech recognition or machine translation models. SLR systems are usually composed of two stages, one where an embedding representing the audio sample is extracted and a second one which computes the final scores for each language. In this work, we approach the SLR task as a detection problem and implement the second stage as a probabilistic linear discriminant analysis (PLDA) model. We show that discriminative training of the PLDA parameters gives large gains with respect to the usual generative training. Further, we propose a novel hierarchical approach where two PLDA models are trained, one to generate scores for clusters of highly-related languages and a second one to generate scores conditional to each cluster. The final language detection scores are computed as a combination of these two sets of scores. The complete model is trained discriminatively to optimize a cross-entropy objective. We show that this hierarchical approach consistently outperforms the non-hierarchical one for detection of highly related languages, in many cases by large margins. We train our systems on a collection of datasets including over 100 languages, and test them both on matched and mismatched conditions, showing that the gains are robust to condition mismatch.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jul,
pages = {2396–2410},
numpages = {15}
}

@inproceedings{10.1145/3610543.3626179,
author = {Chen, Bingyi and Liu, Zengyu and Yuan, Li and Liu, Zhitao and Li, Yi and Wang, Guan and Xie, Ning},
title = {Monte Carlo Denoising via Multi-scale Auxiliary Feature Fusion Guided Transformer},
year = {2023},
isbn = {9798400703140},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610543.3626179},
doi = {10.1145/3610543.3626179},
abstract = {Deep learning-based single-frame Monte Carlo denoising techniques have demonstrated remarkable results in photo-realistic rendering research. However, the current state-of-the-art methods relying on self-attention mechanisms underutilize auxiliary features and struggle to preserve intricate high-frequency details in complex scenes. Employing a generative adversarial architecture, we present a transformer-based denoising network guided by multi-scale auxiliary feature. The proposed U-shaped denoising network extracts multi-scale texture and geometric features from auxiliaries, modulating them to guide the improved transformer module’s denoising process. The improved transformer module employs cross-channel self-attention to capture non-local relationships with near-linear computational complexity. Additionally, a gating mechanism is introduced in the transformer module’s feed-forward network, enhancing information flow. Extensive experiments on noisy images with varied per-pixel sampling rates demonstrate the method’s superiority in quantitative metrics and visual perception compared with state-of-the-art methods. Our method excels notably in intricate scenes with complex hair and texture details, which are historically challenging to denoise.},
booktitle = {SIGGRAPH Asia 2023 Technical Communications},
articleno = {1},
numpages = {4},
keywords = {Monte Carlo denoising, Transformer, self-attention},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@inproceedings{10.1145/3586209.3591404,
author = {Williams, Mathew and Kokalj-Filipovic, Silvija and Rodriguez, Armani},
title = {Analysis of Lossy Generative Data Compression for Robust Remote Deep Inference},
year = {2023},
isbn = {9798400701337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586209.3591404},
doi = {10.1145/3586209.3591404},
abstract = {Networks of wireless sensors, including Internet of Things (IoT), motivate the use of lossy compression of the sensor data to match the available network bandwidth (BW). Hence, sensor data intended for inference by a remote deep learning (RDL) model is likely to be reconstructed with distortion, from a compressed representation received by the remote user over a wireless channel. Our focus is a particular type of lossy compression algorithm based on DL models, and known as learned compression (LC). The link between the information loss and compression rate in LCs has not been studied yet in the framework of information theory, nor practically associated with any meta-data which could describe the type and level of information loss to downstream users. This may make this compression undetectable yet potentially harmful. We study the robustness of a RDL classification model against the lossy compression of the input, including the robustness under an adversarial attack. We apply different compression methods of MNIST images, such as JPEG and a hierarchical LC, all with different compression ratios. For any lossy reconstruction and its uncompressed original, several techniques for topological feature characterization based on persistent homology are used to highlight the important differences amongst compression approaches that may affect the robust accuracy of a DL classifier trained on the original data. We conclude that LC is preferred in the described context, because we achieve the same accuracy as with the originals (with and without an adversarial attack) on a trained DL MNIST classifier, while using only 1/4 of the BW. We show that calculated topological features differ between JPEG and the comparable LC reconstructions, which are closer to the features of the original. We show that there is a distribution shift in those features due to the attack. Finally, most LC models are generative, meaning that we can generate multiple statistically independent compressed representations of a data point, which opens the possibility for the inference error correction at the RDL model. Due to space limitations, we leave this aspect for future work.},
booktitle = {Proceedings of the 2023 ACM Workshop on Wireless Security and Machine Learning},
pages = {33–38},
numpages = {6},
keywords = {adversarial attack, generative deep learning, learned compression, lossy compression, persistent homology},
location = {Guildford, United Kingdom},
series = {WiseML'23}
}

@inproceedings{10.1145/3592686.3592698,
author = {Fang, Ruiqi and Guo, Ruipeng and Zhao, Min and Yao, Min},
title = {Low-count PET image reconstruction algorithm based on WGAN-GP},
year = {2023},
isbn = {9798400700200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3592686.3592698},
doi = {10.1145/3592686.3592698},
abstract = {Positron emission tomography (PET) technique can visualize the working status or fluid flow state inside opaque devices, and how to reconstruct high-quality images from low-count (LC) projection data with short scan time to meet the real-time online inspection remains an important research problem. A direct reconstruction algorithm CED-PET based on gradient-penalized Wasserstein Generative Adversarial Network (WGAN-GP) architecture is proposed. This network combines content loss, perceptual loss, and adversarial loss to achieve fast and high-quality reconstruction of low-count projection data. In addition, a special dataset for obtuse body bypassing was produced by combining Computational Fluid Dynamics (CFD) simulation software and the Geant4 Application for Tomographic Emission (GATE) simulation platform. The results on this dataset show that CED-PET can quickly reconstruct high-quality images with more realistic detail contours.},
booktitle = {Proceedings of the 2023 3rd International Conference on Bioinformatics and Intelligent Computing},
pages = {60–64},
numpages = {5},
location = {Sanya, China},
series = {BIC '23}
}

@inproceedings{10.1145/3631700.3664900,
author = {Portaz, Miguel and Manjarres, Angeles and Santos, Olga C.},
title = {Harmonizing Ethical Principles: Feedback Generation Approaches in Modeling Human Factors for Assisted Psychomotor Systems},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3664900},
doi = {10.1145/3631700.3664900},
abstract = {As the demand for personalized and adaptive learning experiences increase, there is a urgent need for providing effective feedback mechanisms within critical systems, such as in psychomotor learning systems. This proposal introduces an approach for the integration of retrieval-augmented generation tools to provide comprehensive and insightful feedback to users. By combining the strengths of retrieval-based techniques and generative models, these tools offer the potential to enhance learning outcomes by delivering tailored feedback that is both informative and engaging. The proposal also emphasises the importance of incorporating explainability and transparency concepts. Following the hybrid intelligence paradigm it is possible to ensure that the feedback provided by these tools is not only accurate but also understandable to humans. This approach fosters trust and promotes a deeper understanding of the psychomotor learning process, empowering users and facilitators to make informed decisions about the psychomotor learning path. The hybrid intelligence paradigm, which combines the strengths of both human and artificial intelligence, plays a crucial role in the deployment of these solutions. By taking advantage of the cognitive capabilities of human experts alongside the computational power of artificial intelligence algorithms, it is possible to offer personalised feedback that takes into account both technical accuracy and pedagogical effectiveness. Through these collaborative efforts it is also possible to create learning environments that are inclusive, adaptable, and beneficial to lifelong learning. In conclusion, this proposal introduces retrieval-augmented generation tools for providing feedback in psychomotor learning systems, which represents a significant step towards in its personalization, and whose ethical implications align with the new regulations on the implementation of intelligent technologies in critical systems.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {380–385},
numpages = {6},
keywords = {Collaborative Learning, Ethics, Human-Centered, Hybrid Intelligence, Intelligent Psychomotor Systems, Retrieval Augmented Generation, XAI},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3535511.3535520,
author = {Gomes, Anna Luiza and Vianna, Get\'{u}lio and Escovedo, Tatiana and Kalinowski, Marcos},
title = {Predicting IMDb Rating of TV Series with Deep Learning: The Case of Arrow},
year = {2022},
isbn = {9781450396981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3535511.3535520},
doi = {10.1145/3535511.3535520},
abstract = {Context: The number of TV series offered nowadays is very high. Due to its large amount, many series are canceled due to a lack of originality that generates a low audience.Problem: Having a decision support system that can show why some shows are a huge success or not would facilitate the choices of renewing or starting a show.Solution: We studied the case of the series Arrow broadcasted by CW Network and used descriptive and predictive modeling techniques to predict the IMDb rating. We assumed that the theme of the episode would affect its evaluation by users, so the dataset is composed only by the director of the episode, the number of reviews that episode got, the percentual of each theme extracted by the Latent Dirichlet Allocation (LDA) model of an episode, the number of viewers from Wikipedia and the rating from IMDb. The LDA model is a generative probabilistic model of a collection of documents made up of words.IS Theory: This study was developed under the aegis of Computational Learning Theory, which aims to understand the fundamental principles of learning and contribute to designing better-automated learning methods applied to the entertainment business.Method: In this prescriptive research, the case study method was used, and its results were analyzed using a quantitative approach.Summary of Results: With the features of each episode, the model that performed the best to predict the rating was Catboost due to a similar mean squared error of the KNN model but a better standard deviation during the test phase. It was possible to predict IMDb ratings with an acceptable root mean squared error of 0.55.Contributions and Impact in the IS area: The results show that deep learning techniques can be applied to support decisions in the entertainment field, allowing facilitating the decisions of renewing or starting a show. The rationale for building the model is detailed throughout the paper and can be replicated for other contexts.},
booktitle = {Proceedings of the XVIII Brazilian Symposium on Information Systems},
articleno = {9},
numpages = {6},
keywords = {Deep Learning, IMDb, LDA, Machine Learning, prediction, tv-series},
location = {Curitiba, Brazil},
series = {SBSI '22}
}

@inproceedings{10.1145/3634737.3645006,
author = {Murodova, Nozima and Koo, Hyungjoon},
title = {BinAdapter: Leveraging Continual Learning for Inferring Function Symbol Names in a Binary},
year = {2024},
isbn = {9798400704826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634737.3645006},
doi = {10.1145/3634737.3645006},
abstract = {Binary reverse engineering is crucial to gaining insights into the inner workings of a stripped binary. Yet, it is challenging to read the original semantics from a binary code snippet because of the unavailability of high-level information in the source, such as function names, variable names, and types. Recent advancements in deep learning show the possibility of recovering such vanished information with a well-trained model from a pre-defined dataset. Albeit a static model's notable performance, it can hardly cope with an ever-increasing data stream (e.g., compiled binaries) by nature. The two viable approaches for ceaseless learning are retraining the whole dataset from scratch and fine-tuning a pre-trained model; however, retraining suffers from large computational overheads and fine-tuning from performance degradation (i.e., catastrophic forgetting). Lately, continual learning (CL) tackles the problem of handling incremental data in security domains (e.g., network intrusion detection, malware detection) using reasonable resources while maintaining performance in practice.In this paper, we focus on how CL assists in the improvement of a generative model that predicts a function symbol name from a series of machine instructions. To this end, we introduce BinAdapter, a system that can infer function names from an incremental dataset without performance degradation from an original dataset by leveraging CL techniques. Our major finding shows that incremental tokens in the source (i.e., machine instructions) or the target (i.e., function names) largely affect the overall performance of a CL-enabled model. Accordingly, BinAdapter adopts three built-in approaches: [EQUATION] inserting adapters in case of no incremental tokens in both the source and target, [EQUATION] harnessing multilingual neural machine translation (M-NMT) and fine-tuning the source embeddings with [EQUATION] in case of incremental tokens in the source, and [EQUATION] fine-tuning target embeddings with [EQUATION] in case of incremental tokens in both. To demonstrate the effectiveness of BinAdapter, we evaluate the above three scenarios using incremental datasets with or without a set of new tokens (e.g., unseen machine instructions or function names), spanning across different architectures and optimization levels. Our empirical results show that BinAdapter outperforms the state-of-the-art CL techniques for an F1 of up to 24.3% or a Rouge-l of 21.5% in performance.},
booktitle = {Proceedings of the 19th ACM Asia Conference on Computer and Communications Security},
pages = {1200–1213},
numpages = {14},
keywords = {binary analysis, software security, reverse engineering, continual learning},
location = {Singapore, Singapore},
series = {ASIA CCS '24}
}

