@inproceedings{10.1145/3701716.3715508,
author = {Xu, Jian and Luo, Sichun and Chen, Xiangyu and Huang, Haoming and Hou, Hanxu and Song, Linqi},
title = {RALLRec: Improving Retrieval Augmented Large Language Model Recommendation with Representation Learning},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715508},
doi = {10.1145/3701716.3715508},
abstract = {Large Language Models (LLMs) have been integrated into recommendation systems to enhance user behavior comprehension. The Retrieval Augmented Generation (RAG) technique is further incorporated into these systems to retrieve more relevant items and improve system performance. However, existing RAG methods rely primarily on textual semantics and often fail to incorporate the most relevant items, limiting the effectiveness of the systems.In this paper, we propose Representation learning for retrieval-Augmented Large Language model Recommendation (RALLRec). Specifically, we enhance textual semantics by prompting LLMs to generate more detailed item descriptions, followed by joint representation learning of textual and collaborative semantics, which are extracted by the LLM and recommendation models, respectively. Considering the potential time-varying characteristics of user interest, a simple yet effective reranking method is further introduced to capture the dynamics of user preference. We conducted extensive experiments on three real-world datasets, and the evaluation results validated the effectiveness of our method. Code is made public at https://github.com/JianXu95/RALLRec.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1436–1440},
numpages = {5},
keywords = {large language model, recommender system, retrieval-augmented generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3696410.3714800,
author = {Sun, Zhongxiang and Si, Zihua and Zang, Xiaoxue and Zheng, Kai and Song, Yang and Zhang, Xiao and Xu, Jun},
title = {LargePiG for Hallucination-Free Query Generation: Your Large Language Model is Secretly a Pointer Generator},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714800},
doi = {10.1145/3696410.3714800},
abstract = {Recent research on query generation has focused on using Large Language Models (LLMs), which, despite achieving state-of-the-art performance, also introduce hallucination issues in generated queries. In this work, we categorize these issues into relevance hallucination and factuality hallucination, proposing a new typology for hallucinations arising from LLM-based query generation. We present an effective approach to decouple content from form in LLM-generated queries, preserving the factual knowledge extracted and integrated from inputs while leveraging the LLM's linguistic capabilities to construct syntactic structures, including function words. Specifically, we introduce a model-agnostic and training-free method that transforms the Large Language Model into a Pointer-Generator (LargePiG), where the pointer attention distribution utilizes the LLM's inherent attention weights, and the copy probability is derived from the difference between the vocabulary distribution in the model's high layers and the last layer. To validate the effectiveness of LargePiG, we constructed two datasets for assessing hallucination issues in query generation, covering both document and video scenarios. Empirical studies on various LLMs demonstrated LargePiG's superiority across both datasets. Additional experiments further verified that LargePiG reduces hallucination in large vision-language models and enhances the accuracy of document-based question-answering and factuality evaluation tasks. The source code and dataset are available at https://github.com/Jeryi-Sun/LargePiG.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4766–4779},
numpages = {14},
keywords = {hallucination, pointer generator, query generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3716815.3729013,
author = {Mason, Christopher and Aleroud, Ahmed and Melhem, Abdullah and Halloush, Zain and Williams, Jason A.},
title = {Generative AI vs. Human Deception: A Comparative Analysis of ChatGPT, Gemini, and Human-Generated Disinformation},
year = {2025},
isbn = {9798400715013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716815.3729013},
doi = {10.1145/3716815.3729013},
abstract = {Large Language Models (LLMs) are powerful tools for generating human-like text, yet their potential to produce and automate disinformation poses significant challenges. This study investigates the characteristics and detectability of disinformation created by both humans and generative AI using Large Language models such as ChatGPT and Google’s Gemini. We began with a dataset of verified health statements from peer-reviewed journals, which we then paired with falsified statements generated by both humans and AI models using structured prompts. This approach allowed us to compare the stylistic features of AI-generated and human-generated health disinformation. Through machine learning models, we assessed the accuracy of detecting disinformation generated by humans and AI based on features of verified and falsified statements. We investigated how stylistic, readability, sentiment, and stance features differentiate AI- from human-crafted disinformation. Our findings reveal that AI-crafted disinformation exhibits predictable stylistic and structural features, making human-crafted disinformation harder to detect by machine learning classifiers. Our results emphasize the need for customized disinformation detection approaches to address the differences between disinformation generated by LLMs and that produced by humans.},
booktitle = {Proceedings of the 10th ACM International Workshop on Security and Privacy Analytics},
pages = {13–22},
numpages = {10},
keywords = {llms, disinformation, human deception, ai, chatgpt, gemini},
location = {Pittsburgh, PA, USA},
series = {IWSPA '25}
}

@inproceedings{10.1145/3626253.3635592,
author = {Niousha, Rose and Hoq, Muntasir and Akram, Bita and Norouzi, Narges},
title = {Use of Large Language Models for Extracting Knowledge Components in CS1 Programming Exercises},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635592},
doi = {10.1145/3626253.3635592},
abstract = {This study utilizes large language models to extract foundational programming concepts in programming assignments in a CS1 course. We seek to answer the following research questions: RQ1. How effectively can large language models identify knowledge components in a CS1 course from programming assignments? RQ2. Can large language models be used to extract program-level knowledge components, and how can the information be used to identify students' misconceptions? Preliminary results demonstrated a high similarity between course-level knowledge components retrieved from a large language model and that of an expert-generated list.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1762–1763},
numpages = {2},
keywords = {cs1, curriculum design, knowledge component},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3712298,
author = {Bany Abdelnabi, Ahmad A and Soykan, Bulent and Bhatti, Danish and Rabadi, Ghaith},
title = {Usefulness of Large Language Models (LLMs) for Student Feedback on H&amp;P During Clerkship: Artificial Intelligence for Personalized Learning},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712298},
doi = {10.1145/3712298},
abstract = {Large Language Models (LLMs) notably GPT-4, demonstrate exceptional language generation and comprehension abilities, and they have potential uses in clinical practice, learning, and medical research. In this study, we explore practical use of Large Language Models (LLMs) in enhancing case-based learning in medical education. The study employes a designed mixed-methods approach, combining quantitative metrics with qualitative feedback from 100 medical students, providing comprehensive insights into both the technical performance and educational value of LLM-based feedback systems. Our results indicate that LLMs can enhance medical students’ History and Physical (H&amp;P) skills by providing personalized insights, fostering critical thinking, and improving their abilities to analyze, diagnose, and present clinical cases. This study has surfaced significant insights into the potential benefits and limitations of integrating LLMs into medical education. Our findings show the positive impact of LLMs on enhancing personalized learning experiences, critical thinking, and the effectiveness of case-based learning aids and highlighting its limitations.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Healthcare},
month = jan,
keywords = {Large language models, medical education, history and physical examination, chain of thought reasoning}
}

@inproceedings{10.1145/3626772.3661383,
author = {Bao, Keqin and Zhang, Jizhi and Lin, Xinyu and Zhang, Yang and Wang, Wenjie and Feng, Fuli},
title = {Large Language Models for Recommendation: Past, Present, and Future},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3661383},
doi = {10.1145/3626772.3661383},
abstract = {Large language models (LLMs) have significantly influenced recommender systems, spurring interest across academia and industry in leveraging LLMs for recommendation tasks. This includes using LLMs for generative item retrieval and ranking, and developing versatile LLMs for various recommendation tasks, potentially leading to a paradigm shift in the field of recommender systems. This tutorial aims to demystify the Large Language Model for Recommendation (LLM4Rec) by reviewing its evolution and delving into cutting-edge research. We will explore how LLMs enhance recommender systems in terms of architecture, learning paradigms, and functionalities such as conversational abilities, generalization, planning, and content generation. The tutorial will shed light on the challenges and open problems in this burgeoning field, including trustworthiness, efficiency, online training, and evaluation of LLM4Rec. We will conclude by summarizing key learnings from existing studies and outlining potential avenues for future research, with the goal of equipping the audience with a comprehensive understanding of LLM4Rec and inspiring further exploration in this transformative domain.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2993–2996},
numpages = {4},
keywords = {generative models, generative recommendation, large language models, recommender systems},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3661167.3661273,
author = {Mezzaro, Simone and Gambi, Alessio and Fraser, Gordon},
title = {An Empirical Study on How Large Language Models Impact Software Testing Learning},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661273},
doi = {10.1145/3661167.3661273},
abstract = {Software testing is a challenging topic in software engineering education and requires creative approaches to engage learners. For example, the Code Defenders game has students compete over a Java class under test by writing effective tests and mutants. While such gamified approaches deal with problems of motivation and engagement, students may nevertheless require help to put testing concepts into practice. The recent widespread diffusion of Generative AI and Large Language Models raises the question of whether and how these disruptive technologies could address this problem, for example, by providing explanations of unclear topics and guidance for writing tests. However, such technologies might also be misused or produce inaccurate answers, which would negatively impact learning. To shed more light on this situation, we conducted the first empirical study investigating how students learn and practice new software testing concepts in the context of the Code Defenders testing game, supported by a smart assistant based on a widely known, commercial Large Language Model. Our study shows that students had unrealistic expectations about the smart assistant, “blindly” trusting any output it generated, and often trying to use it to obtain solutions for testing exercises directly. Consequently, students who resorted to the smart assistant more often were less effective and efficient than those who did not. For instance, they wrote 8.6% fewer tests, and their tests were not useful in 78.0% of the cases. We conclude that giving unrestricted and unguided access to Large Language Models might generally impair learning. Thus, we believe our study helps to raise awareness about the implications of using Generative AI and Large Language Models in Computer Science Education and provides guidance towards developing better and smarter learning tools.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {555–564},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, Generative AI, Smart Learning Assistant},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3643479.3662056,
author = {Vu, Sinh Trong and Truong, Huong Thu and Do, Oanh Tien and Le, Tu Anh and Mai, Tai Tan},
title = {A ChatGPT-based approach for questions generation in higher education},
year = {2024},
isbn = {9798400705472},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643479.3662056},
doi = {10.1145/3643479.3662056},
abstract = {Large language models have been widely applied in many aspects of real life, bringing significant efficiency to businesses and offering distinctive user experiences. In this paper, we focus on exploring the application of ChatGPT, a chatbot based on a large language model, to support higher educator in generating quiz questions and assessing learners. Specifically, we explore interactive prompting patterns to design an optimal AI-powered question bank creation process. The generated questions are evaluated through a "Blind test" survey sent to various stakeholders including lecturers and learners. Initial results at the Banking Academy of Vietnam are relatively promising, suggesting a potential direction to streamline the time and effort involved in assessing learners at higher education institutes.},
booktitle = {Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia},
pages = {13–18},
numpages = {6},
keywords = {ChatGPT, Large language model, question generation},
location = {Phuket, Thailand},
series = {AIQAM '24}
}

@inproceedings{10.1145/3640457.3688146,
author = {Yang, Ting and Chen, Li},
title = {Unleashing the Retrieval Potential of Large Language Models in Conversational Recommender Systems},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688146},
doi = {10.1145/3640457.3688146},
abstract = {Conversational recommender systems (CRSs) aim to capture user preferences and provide personalized recommendations through interactive natural language interaction. The recent advent of large language models (LLMs) has revolutionized human engagement in natural conversation, driven by their extensive world knowledge and remarkable natural language understanding and generation capabilities. However, introducing LLMs into CRSs presents new technical challenges. Directly prompting LLMs for recommendation generation requires understanding a large and evolving item corpus, as well as grounding the generated recommendations in the real item space. On the other hand, generating recommendations based on external recommendation engines or directly integrating their suggestions into responses may constrain the overall performance of LLMs, since these engines generally have inferior representation abilities compared to LLMs. To address these challenges, we propose an end-to-end large-scale CRS model, named as ReFICR, a novel LLM-enhanced conversational recommender that empowers a retrievable large language model to perform conversational recommendation by following retrieval and generation instructions through lightweight tuning. By decomposing the complex CRS task into multiple subtasks, we formulate these subtasks into two types of instruction formats: retrieval and generation. The hidden states of ReFICR are utilized for generating text embeddings for retrieval, and simultaneously ReFICR is fine-tuned to handle generation subtasks. We optimize the contrastive objective to enhance text embeddings for retrieval and jointly fine-tune the large language model objective for generation. Our experimental results on public datasets demonstrate that ReFICR significantly outperforms baselines in terms of recommendation accuracy and response quality. Our code is publicly available at the link: https://github.com/yt556677/ReFICR.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {43–52},
numpages = {10},
keywords = {Conversational Recommender Systems, Instruction Tuning, Retrievable Large Language Models},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3641554.3701867,
author = {Yeh, Thomas Y. and Tran, Karena and Gao, Ge and Yu, Tyler and Fong, Wai On and Chen, Tzu-Yi},
title = {Bridging Novice Programmers and LLMs with Interactivity},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701867},
doi = {10.1145/3641554.3701867},
abstract = {While Large Language Models (LLMs) enable experienced programmers to increase their productivity, LLMs' impact on learning and productivity for novices is currently unclear. Recent work showed novice programmers struggle with prompting LLMs for code generation and suggested that the use of LLMs in CS education could exacerbate existing equity issues. Educators are now faced with the difficult question of whether and when to incorporate the use of LLMs into the CS curriculum without adversely impacting student learning and equity. To address these concerns, we study the effects of using an interactive LLM on code generation with novice programmers. We find that using our interactive LLM improves the accuracy of code generation over the baseline LLM. Additionally, after using the interactive LLM, novices write improved prompts even when using the baseline LLM. Based on our findings, we plan to create iGPTs, a set of customized, interactive LLMs spanning CS education learning goals as templates to facilitate LLM integration for improving student learning and retention.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1295–1301},
numpages = {7},
keywords = {cs1, generative ai, llms, novice programmers},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1613/jair.1.17028,
author = {Karev, Alexey and Xu, Dong},
title = {ConSCompF: Consistency-focused Similarity Comparison Framework for Generative Large Language Models},
year = {2025},
issue_date = {May 2025},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {82},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.17028},
doi = {10.1613/jair.1.17028},
abstract = {Large Language Models (LLM) are one of the most important discoveries in machine learning in recent years. LLM-based artificial intelligence (AI) assistants, such as ChatGPT, have consistently attracted attention from researchers, investors, and the general public, driving the rapid growth of this industry. With dozens of new LLMs released every month, it becomes quite challenging to differentiate between them, thereby creating a demand for new LLM comparison methods.
In this research, the Consistency-focused Similarity Comparison Framework (ConSCompF) for generative large language models is proposed. It compares texts generated by two LLMs and produces a similarity score, indicating the overall degree of similarity between their responses. The main advantage of this framework is that it can operate on a small number of unlabeled data, such as chatbot instruction prompts, and does not require LLM developers to disclose any information about their product.
To evaluate the efficacy of ConSCompF, two experiments aimed at identifying similarities between multiple LLMs are conducted. Additionally, these experiments examine the correlation between the similarity scores generated by ConSCompF and the differences in outputs produced by other benchmarking techniques, such as ROUGE-L. Finally, a series of few-shot LLM comparison experiments is conducted to evaluate the performance of ConSCompF in a few-shot LLM comparison scenario.
The proposed framework can be used for calculating similarity matrices of multiple LLMs, which can be effectively visualized using principal component analysis (PCA). The outputs of ConSCompF may provide useful insights into data that might have been used during LLM training and help detect potential investment fraud attempts.},
journal = {J. Artif. Int. Res.},
month = apr,
numpages = {23},
keywords = {electronic health records, Medical Information, NLP, EHR, document level, deep learning, machine learning}
}

@inproceedings{10.1145/3638530.3664121,
author = {Guo, Ping and Liu, Fei and Lin, Xi and Zhao, Qingchuan and Zhang, Qingfu},
title = {L-AutoDA: Large Language Models for Automatically Evolving Decision-based Adversarial Attacks},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3664121},
doi = {10.1145/3638530.3664121},
abstract = {In the rapidly evolving field of machine learning, adversarial attacks pose a significant threat to the robustness and security of models. Amongst these, decision-based attacks are particularly insidious due to their nature of requiring only the model's decision output, which makes them notably challenging to counteract. This paper presents L-AutoDA (Large Language Model-based Automated Decision-based Adversarial Attacks), an innovative methodology that harnesses the generative capabilities of large language models (LLMs) to streamline the creation of such attacks. L-AutoDA employs an evolutionary strategy, where iterative interactions with LLMs lead to the autonomous generation of potent attack algorithms, thereby reducing human intervention. The performance of L-AutoDA was evaluated on the CIFAR-10 dataset, where it demonstrated substantial superiority over existing baseline methods in terms of success rate and computational efficiency. Ultimately, our results highlight the formidable utility of language models in crafting adversarial attacks and reveal promising directions for constructing more resilient AI systems.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1846–1854},
numpages = {9},
keywords = {large language models, adversarial attacks, automated algorithm design, evolutionary algorithms},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{10.1145/3686215.3688378,
author = {Molto, Joaquin and Fields, Jonathan and Visser, Ubbo and Lisetti, Christine},
title = {An LLM-powered Socially Interactive Agent with Adaptive Facial Expressions for Conversing about Health},
year = {2024},
isbn = {9798400704635},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686215.3688378},
doi = {10.1145/3686215.3688378},
abstract = {Virtual Socially Interactive Agents (SIA) have shown great promise for human interactions with computer applications in which not only domain-relevant content is needed, but also the way in which the content is delivered (e.g. socio-emotionally adaptive tutoring agents, socio-emotionally responsive health agents). While recent progress on Large Language Models (LLMs) has made rich verbal interactions possible, LLMs cannot communicate nonverbal social cues through a simple text-based interface. We propose an expressive conversational SIA system, powered by an OpenAI Large Language Model (LLM) for text generation, integrated with a 3D humanoid model with real-time behavior generation of FACS-based facial expressions that mirror the user’s to increase rapport and engagement using HumeAI’s Facial Expression Recognition and Empathic Voice Interface (EVI) models to drive the model’s animations. As a case study, we use prompt-engineering to focus the conversation on discussing health-related behaviors. We ground the generation of the LLM’s questions based on the World Health Organization’s (WHO) Alcohol Use Disorders Identification Test (AUDIT) 10-question inventory, a test that help identify whether someone is at risk of alcohol use disorder.},
booktitle = {Companion Proceedings of the 26th International Conference on Multimodal Interaction},
pages = {75–77},
numpages = {3},
keywords = {Adaptation, Health Information Technologies, LLMs, Virtual Agent},
location = {San Jose, Costa Rica},
series = {ICMI Companion '24}
}

@inproceedings{10.1145/3641555.3705195,
author = {Marwan, Samiha and Ibrahim, Mohamed and Morrison, Briana},
title = {How Good are Large Language Models at Generating Subgoal Labels?},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705195},
doi = {10.1145/3641555.3705195},
abstract = {The use of subgoal labels in introduction to programming classrooms has been shown to improve student performance, learning, retention, and reduce students' drop out rates. However, creating and adding subgoal labels to programming assignments is often hard to articulate and very time-intensive for instructors. In Computing Education Research, Large Language Models (LLMs) have been widely used to generate human-like outputs such as worked examples and source code. In this work, we explore whether ChatGPT could be used to generate high-quality and appropriate subgoal labels in two programming curricula. Our qualitative data analysis suggests that LLMs can assist instructors in creating subgoal labels in their classrooms, opening up directions to empower students' learning experience in programming classrooms.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1541–1542},
numpages = {2},
keywords = {large language models, subgoal labels, subgoals},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inbook{10.1145/3672608.3707764,
author = {Heilala, Ville and Araya, Roberto and H\"{a}m\"{a}l\"{a}inen, Raija},
title = {Beyond Text-to-Text: An Overview of Multimodal and Generative Artificial Intelligence for Education Using Topic Modeling},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707764},
abstract = {Generative artificial intelligence (GenAI) can reshape education and learning. While large language models (LLMs) like ChatGPT dominate current educational research, multimodal capabilities—such as text-to-speech and text-to-image—are less explored. This study uses topic modeling to map the research landscape of multimodal and generative AI in education. An extensive literature search yielded 4175 articles. Employing a topic modeling approach, latent topics were extracted, resulting in 38 interpretable topics organized into 14 thematic areas. Findings indicate a predominant focus on text-to-text models in educational contexts, with other modalities underexplored, overlooking the broader potential of multimodal approaches. The results suggest a research gap, stressing the importance of more balanced attention across different AI modalities and educational levels. In summary, this research provides an overview of current trends in generative AI for education, underlining opportunities for future exploration of multimodal technologies to fully realize the transformative potential of artificial intelligence in education.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {54–63},
numpages = {10}
}

@inproceedings{10.1145/3706599.3720291,
author = {Jamie, Pooriya and HajiHashemi, Reyhaneh and Alipour, Sharareh},
title = {Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720291},
doi = {10.1145/3706599.3720291},
abstract = {Integrating large language models (LLMs) like ChatGPT into computer science education offers transformative potential for complex courses such as data structures and algorithms (DSA). This study examines ChatGPT as a supplementary tool for teaching assistants (TAs), guided by structured prompts and human oversight, to enhance instruction and student outcomes. A controlled experiment compared traditional TA-led instruction with a hybrid approach where TAs used ChatGPT-4o and ChatGPT o1 to generate exercises, clarify concepts, and provide feedback. Structured prompts emphasized problem decomposition, real-world context, and code examples, enabling tailored support while mitigating over-reliance on AI. Results demonstrated the hybrid approach’s efficacy, with students in the ChatGPT-assisted group scoring 16.50 points higher on average and excelling in advanced topics. However, ChatGPT’s limitations necessitated TA verification. This framework highlights the dual role of LLMs: augmenting TA efficiency while ensuring accuracy through human oversight, offering a scalable solution for human-AI collaboration in education.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {567},
numpages = {7},
keywords = {LLMs, ChatGPT, Teaching Assistant, Data Structures and Algorithms Course, Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3622896.3622906,
author = {Sun, Gang and Shen, Ran and Jin, Liangfeng and Wang, Yifan and Xu, Shiyu and Chen, Jinpeng and Jiang, Weihao},
title = {Instruction Tuning Text-to-SQL with Large Language Models in the Power Grid Domain},
year = {2023},
isbn = {9798400708190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622896.3622906},
doi = {10.1145/3622896.3622906},
abstract = {This paper explores the large language models to address the Text-to-SQL task in real-world scenarios in the electricity domain. To tackle the lack of training data and corresponding databases for vertical domain real-world scenarios, the paper devised specific prompts to leverage ChatGPT for data generation, achieving significant improvements in annotation efficiency through automated data generation. Furthermore, to apply the powerful semantic parsing and generation capabilities of large language models to Text-to-SQL, the paper utilized a large language model for instruction tuning for SQL generation. This model has undergone secondary pre-training with electrical knowledge, tailoring it to the specific SQL generation task. On the power grid test set, the paper’s matching accuracy reached 65.7%, and the execution accuracy reached 80.9%. Additionally, the paper conducted further tests on various general large language models for zero-shot learning and single-sample prompt-based Text-to-SQL. The results indicate that while simple single-table queries can be achieved, meeting the requirements for complex queries remains challenging.},
booktitle = {Proceedings of the 2023 4th International Conference on Control, Robotics and Intelligent System},
pages = {59–63},
numpages = {5},
keywords = {GPT, Instruction Tuning, Large Language Models, Power Grid, Text-To-SQL},
location = {Guangzhou, China},
series = {CCRIS '23}
}

@article{10.5555/3737313.3737334,
author = {Fernandez, Amanda S. and Patrick, David and Gomez, Mauricio and Cornell, Kimberly A.},
title = {Incorporating LLM Activities into Established CS1 Curriculum: An Experience Report},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {Large Language Models (LLMs), including Gemini, CoPilot, and ChatGPT, have experienced significant growth in usage and adoption in recent years. As these models become more sophisticated, particularly in code generation capabilities, educators need to adapt their CS1 courses. In this experience report, we share observations we made while designing and teaching LLM activities for CS1 students at two academic institutions during the spring 2024 term. Drawing on recent research, our activities consist of four short 10-15 minute exercises that guide students in how to properly utilize LLMs within their CS1 coursework. These activities can be easily added to the existing CS1 course curriculum to supplement the existing course materials. Post-activity surveys indicated a positive impact on students' understanding of CS concepts and indicated enthusiasm for learning how to use LLMs safely in programming.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {79–93},
numpages = {15}
}

@inproceedings{10.1145/3706599.3721208,
author = {Wang, Amy and Ruparel, Roma and Iurchenko, Anna and Jhun, Paul and S\'{e}guin, Julie Anne and Strachan, Patricia and Wong, Renee and Karthikesalingam, Alan and Matias, Yossi and Hassidim, Avinatan and Webster, Dale and Semturs, Christopher and Krause, Jonathan and Schaekermann, Mike},
title = {Generative AI for medical education: Insights from a case study with medical students and an AI tutor for clinical reasoning},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3721208},
doi = {10.1145/3706599.3721208},
abstract = {Generative Artificial Intelligence (AI), particularly Large Language Models (LLMs), have demonstrated significant potential in clinical reasoning skills such as history-taking and differential diagnosis generation—critical aspects of medical education. This work explores how LLMs can augment medical curricula through interactive learning. We conducted a participatory design process with medical students, residents and medical education experts to co-create an AI-powered tutor prototype for clinical reasoning. As part of the co-design process, we conducted a qualitative user study, investigating learning needs and practices via interviews, and conducting concept evaluations through interactions with the prototype. Findings highlight the challenges learners face in transitioning from theoretical knowledge to practical application, and how an AI tutor can provide personalized practice and feedback. We conclude with design considerations, emphasizing the importance of context-specific knowledge and emulating positive preceptor traits, to guide the development of AI tools for medical education.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {303},
numpages = {8},
keywords = {Education, Medicine, Generative AI, Large Language Models},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3705300,
author = {Xu, Xiaodan and Ni, Chao and Guo, Xinrong and Liu, Shaoxuan and Wang, Xiaoya and Liu, Kui and Yang, Xiaohu},
title = {Distinguishing LLM-Generated from Human-Written Code by Contrastive Learning},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3705300},
doi = {10.1145/3705300},
abstract = {Large language models (LLMs), such as ChatGPT released by OpenAI, have attracted significant attention from both industry and academia due to their demonstrated ability to generate high-quality content for various tasks. Despite the impressive capabilities of LLMs, there are growing concerns regarding their potential risks in various fields, such as news, education, and software engineering. Recently, several commercial and open source LLM-generated content detectors have been proposed, which, however, are primarily designed for detecting natural language content without considering the specific characteristics of program code. This article aims to fill this gap by proposing a novel ChatGPT-generated code detector, CodeGPTSensor, based on a contrastive learning framework and a semantic encoder built with UniXcoder. To assess the effectiveness of CodeGPTSensor on differentiating ChatGPT-generated code from human-written code, we first curate a large-scale Human and Machine comparison Corpus (HMCorp), which includes 550k pairs of human-written and ChatGPT-generated code (i.e., 288k Python code pairs and 222k Java code pairs). Based on the HMCorp dataset, our qualitative and quantitative analysis of the characteristics of ChatGPT-generated code reveals the challenge and opportunity of distinguishing ChatGPT-generated code from human-written code with their representative features. Our experimental results indicate that CodeGPTSensor can effectively identify ChatGPT-generated code, outperforming all selected baselines.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {91},
numpages = {31},
keywords = {Large Language Model, ChatGPT, AI-generated Code Detection, Contrastive Learning}
}

@inproceedings{10.1145/3715669.3725868,
author = {Mohamed, Suad and Ismail, Najma and Amaya Hernandez, Kimberly and Parvin, Abdullah and Oliver, Michael and Parra, Esteban},
title = {Design of An Eye-Tracking Study Towards Assessing the Impact of Generative AI Use on Code Summarization},
year = {2025},
isbn = {9798400714870},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715669.3725868},
doi = {10.1145/3715669.3725868},
abstract = {As large language models (LLMs) become more integrated into software engineering and computer science education, it is crucial to understand their impact on student learning. While recent research has explored student perceptions of generative AI, little is known about how these tools influence students’ cognitive processes during programming tasks, such as code comprehension, a valuable skill in software development and maintenance. This paper presents the design of a study that aims to investigate how computer science students interact with LLMs, such as Google’s Gemini, in the context of code summarization using eye-tracking. This study will examine differences in visual attention, fixation behaviors, and performance of students engaged in code summarization with and without AI assistance across varying experience levels.},
booktitle = {Proceedings of the 2025 Symposium on Eye Tracking Research and Applications},
articleno = {80},
numpages = {8},
keywords = {Code Summarization, Eye tracking, empirical study, code comprehension, Large Language Models, AI4SE},
location = {
},
series = {ETRA '25}
}

@inproceedings{10.1145/3581783.3610953,
author = {Wang, Zheng and Long, Cheng and Xu, Shihao and Gan, Bingzheng and Shi, Wei and Cao, Zhao and Chua, Tat-Seng},
title = {LGM3A '23: 1st Workshop on Large Generative Models Meet Multimodal Applications},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3610953},
doi = {10.1145/3581783.3610953},
abstract = {A large language model is a type of artificial intelligence model designed to understand and generate natural language text, such as GPT, T5, RoBERTa, BERT, etc. These models are trained on vast amounts of text data, allowing them to learn the patterns and structures of human language. With the increasing amount of multimodal information such as audio, visual, and text data generated, there is a growing need of leveraging large generative language model for multimodal applications. Recently, a few notable multimodal models (e.g., BLIP, Flamingo, KOSMOS, PaLM-E, LLaVA, Visual ChatGPT, GPT-4, etc.) with a combination of large language models significantly enhanced their understanding and generate more accurate and nuanced responses. The workshop will provide an opportunity for researchers, practitioners, and industry professionals to explore the latest trends and best practices in the field of multimodal applications of large generative models. The workshop will also focus on exploring the challenges and opportunities of integrating large language models with other AI technologies such as computer vision and speech recognition.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {9744–9745},
numpages = {2},
keywords = {generative models, large language models, multimodal applications},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@article{10.5555/3722479.3722506,
author = {Liao, Weidong and Guzide, Osman},
title = {Enhancing Undergraduate Computing Education with LMMs and ChatGPT-4o},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {Large Language Models (LLMs) and ChatGPT have significantly impacted programming practices and computer science education. The rapid advancements in natural language processing, recurrent neural networks, and Transformer architectures have captured the attention of students and educators alike. These tools aid students in brainstorming, coding, analyzing code, and writing reports. Although concerns about cheating and plagiarism persist, these tools also provide educators with novel ways to create and assess assignments. Despite some hesitancy among educators to integrate these AI tools into the classroom, the advert and development of Large MultiModal Models (LMMs), the enhancement of LLMs that can deal with multimedia inputs and outputs, illustrates a significant evolution in generative AI capabilities.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {62},
numpages = {1}
}

@inproceedings{10.1145/3688268.3688288,
author = {Dwight, Joshua},
title = {Building Cyber Attack Trees with the Help of My LLM? A Mixed Method Study},
year = {2024},
isbn = {9798400718038},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3688268.3688288},
doi = {10.1145/3688268.3688288},
abstract = {Cybercrimes and attacks are frequent and increasingly sophisticated, making the identification and understanding of these attacks challenging. Generative AI has the potential to help develop and build cyber-attack models. The study aims to understand and explore the differences and usefulness of the Generative models of ChatGPT, Google, and Microsoft.  This study uses an explanatory sequential mixed methods design that uses an analysis of variance (ANOVA) and thematic analysis to understand the differences between well-known large language models (LLMs). Cybercrime press releases were collected from the United States Department of Justice (USDOJ) to generate attack trees. The LLMs generated a sample of 45 outputs from 15 press releases to conduct the ANOVA, and then a thematic analysis of the output from three large language models (LLMs).},
booktitle = {Proceedings of the 2024 12th International Conference on Computer and Communications Management},
pages = {132–138},
numpages = {7},
keywords = {Cyber Attack Tree, Cyber Incident Response, ANOVA, Thematic Analysis, Generative AI},
location = {
},
series = {ICCCM '24}
}

@inproceedings{10.1145/3637528.3671646,
author = {Guan, Yanchu and Wang, Dong and Chu, Zhixuan and Wang, Shiyu and Ni, Feiyue and Song, Ruihua and Zhuang, Chenyi},
title = {Intelligent Agents with LLM-based Process Automation},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671646},
doi = {10.1145/3637528.3671646},
abstract = {While intelligent virtual assistants like Siri, Alexa, and Google Assistant have become ubiquitous in modern life, they still face limitations in their ability to follow multi-step instructions and accomplish complex goals articulated in natural language. However, recent breakthroughs in large language models (LLMs) show promise for overcoming existing barriers by enhancing natural language processing and reasoning capabilities. Though promising, applying LLMs to create more advanced virtual assistants still faces challenges like ensuring robust performance and handling variability in real-world user commands. This paper proposes a novel LLM-based virtual assistant that can automatically perform multi-step operations within mobile apps based on high-level user requests. The system represents an advance in assistants by providing an end-to-end solution for parsing instructions, reasoning about goals, and executing actions. LLM-based Process Automation (LLMPA) has modules for decomposing instructions, generating descriptions, detecting interface elements, predicting next actions, and error checking. Experiments demonstrate the system completing complex mobile operation tasks in Alipay based on natural language instructions. This showcases how large language models can enable automated assistants to accomplish real-world tasks. The main contributions are the novel LLMPA architecture optimized for app process automation, the methodology for applying LLMs to mobile apps, and demonstrations of multi-step task completion in a real-world environment. Notably, this work represents the first real-world deployment and extensive evaluation of a large language model-based virtual assistant in a widely used mobile application with an enormous user base numbering in the hundreds of millions.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5018–5027},
numpages = {10},
keywords = {agents, explainable, intelligent virtual assistants, large language models, process automation},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3641554.3701863,
author = {Raihan, Nishat and Siddiq, Mohammed Latif and Santos, Joanna C.S. and Zampieri, Marcos},
title = {Large Language Models in Computer Science Education: A Systematic Literature Review},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701863},
doi = {10.1145/3641554.3701863},
abstract = {Large language models (LLMs) are becoming increasingly better at a wide range of Natural Language Processing tasks (NLP), such as text generation and understanding. Recently, these models have extended their capabilities to coding tasks, bridging the gap between natural languages (NL) and programming languages (PL). Foundational models such as the Generative Pre-trained Transformer (GPT) and LLaMA series have set strong baseline performances in various NL and PL tasks. Additionally, several models have been fine-tuned specifically for code generation, showing significant improvements in code-related applications. Both foundational and fine-tuned models are increasingly used in education, helping students write, debug, and understand code. We present a comprehensive systematic literature review to examine the impact of LLMs in computer science and computer engineering education. We analyze their effectiveness in enhancing the learning experience, supporting personalized education, and aiding educators in curriculum development. We address five research questions to uncover insights into how LLMs contribute to educational outcomes, identify challenges, and suggest directions for future research.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {938–944},
numpages = {7},
keywords = {code generation, cs education, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3714313,
author = {Shao, Zekai and Yuan, Siyu and Gao, Lin and He, Yixuan and Yang, Deqing and Chen, Siming},
title = {Unlocking Scientific Concepts: How Effective Are LLM-Generated Analogies for Student Understanding and Classroom Practice?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714313},
doi = {10.1145/3706598.3714313},
abstract = {Teaching scientific concepts is essential but challenging, and analogies help students connect new concepts to familiar ideas. Advancements in large language models (LLMs) enable generating analogies, yet their effectiveness in education remains underexplored. In this paper, we first conducted a two-stage study involving high school students and teachers to assess the effectiveness of LLM-generated analogies in biology and physics through a controlled in-class test and a classroom field study. Test results suggested that LLM-generated analogies could enhance student understanding particularly in biology, but require teachers’ guidance to prevent over-reliance and overconfidence. Classroom experiments suggested that teachers could refine LLM-generated analogies to their satisfaction and inspire new analogies from generated ones, encouraged by positive classroom feedback and homework performance boosts. Based on findings, we developed and evaluated a practical system to help teachers generate and refine teaching analogies. We discussed future directions for developing and evaluating LLM-supported teaching and learning by analogy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {143},
numpages = {19},
keywords = {Analogy Generation, Large Language Models, Scientific Concept Understanding, Classroom Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3705754.3705771,
author = {Lu, Yanyan and Peng, Jiao and Xu, Xing and He, Yue and Li, Tao and Wei, Jie and Jing, Hongyu and Wang, Heqing and Xu, Bo and Song, Hui},
title = {A Retrieval-Augmented Generation Framework for Electric Power Industry Question Answering},
year = {2025},
isbn = {9798400710193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3705754.3705771},
doi = {10.1145/3705754.3705771},
abstract = {Retrieval-augmented Generation has achieved significant success in improving the performance of large language models by utilizing external knowledge sources. However, despite its advancements, it still faces challenges in domain-specific structured documents such as the electric power industry, exhibiting low recall rates and response inaccuracies. To solve these issues, this paper designs a question-answering framework specifically for the electric power industry using the large language model. This study first analyzes the characteristics of documents in the electric power industry and proposes the Hierarchical Adaptive Semantic Segmentation(HASS) method, which improves the accuracy of responses and the precision of queries by subdividing knowledge points and integrating metadata. In the retrieval strategy, a Hybrid Search(HS) method is designed, combining the advantages of sparse and dense retrieval to improve the recall rate. To enable large language models to focus on relevant documents when generating responses, we propose the Irrelevant Document Filtering(IDF) method for minimizing the noise impact from irrelevant documents. Additionally, the model is designed with prompts and fine-tuned to further enhance its ability to utilize context and the accuracy of answer generation. Finally, due to the lack of publicly available datasets for document question-answering in the electricity sector, this work constructs a dataset manually for training and evaluation, comprising 1300 QA items covering several types of questions. Experimental results demonstrate that the methods proposed in this paper effectively improve the accuracy of LLMs in the electric power industry, with our method showing a 9% improvement in accuracy over the traditional RAG approach.},
booktitle = {Proceedings of the 2024 2nd International Conference on Electronics, Computers and Communication Technology},
pages = {95–100},
numpages = {6},
keywords = {language model, semantic segmentation, hybrid search, semantic screening},
location = {
},
series = {CECCT '24}
}

@article{10.1145/3712065,
author = {Tan, Kehui and Yao, Jiayang and pang, tianqi and Fan, Chenyou and Song, Yu},
title = {ELF: Educational LLM Framework of Improving and Evaluating AI Generated Content for Classroom Teaching},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1936-1955},
url = {https://doi.org/10.1145/3712065},
doi = {10.1145/3712065},
abstract = {Recent studies&nbsp;[48, 7] have demonstrated that Large Language Models (LLMs), like ChatGPT&nbsp;[3, 46] and LLAMA&nbsp;[59], can assist with routine teaching tasks and have the potential to revolutionize traditional education. However, other studies&nbsp;[35] highlight that LLMs often contain inaccuracies and demonstrate limited effectiveness in educational contexts. To address this issue, we propose a unified Education LLM Framework (ELF) that integrates LLM into classroom teaching practice to enrich high-quality dialogical content and teacher-student interactions. Unlike complex data-driven models that require vast amounts of data, our framework can quickly enhance educational engagement and teaching strategies by utilizing a few carefully selected teaching examples from master teachers with our prompting techniques. We focus on two typical classroom teaching scenarios that require AI-generated content: Dialogue Completion and Expertise Transfer Learning. The former scenario requires generating contextually appropriate dialogues, while the latter scenario requires migrating the instructional styles and organization to new teaching topics. We demonstrate the effectiveness of our data quality-centered approach in generating semantically clear and factually accurate content as organized instructions for teaching materials. We comprehensively evaluate these materials by utilizing Perplexity-based Statistical Evaluation, Human Evaluation with Questionnaires (HEQ), BertScore, Rouge, and BLEU. Experiments on two self-collected datasets show that our method significantly improves various metrics in Dialogue Completion and Expertise Transfer Learning tasks, enhancing the overall utility of AI for educational purposes.},
note = {Just Accepted},
journal = {J. Data and Information Quality},
month = feb,
keywords = {Envision Artificial Intelligence (AI) for Education, AI in Classroom Teaching, AI Generated Content (AIGC), Dialogue Generation, Human-in-the-loop AI, Generation Evaluation.}
}

@inproceedings{10.1145/3650400.3650526,
author = {Li, Wenqing and Qi, Xiaoman and Zhao, Qi and Wang, Chen and Wu, Qiongyu and Tang, Xue-song},
title = {Knowledge Graph-Based Credibility Evaluation Method for Electric Grid Large Language Model Knowledge Question-Answering},
year = {2024},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650400.3650526},
doi = {10.1145/3650400.3650526},
abstract = {In the field of electricity, specialized terminology is often intricate and complex, making it challenging for non-experts to comprehend. However, with the advancement of artificial intelligence technology, the emergence of large language models provides a new technological solution to address this issue. Large language models, based on deep learning techniques, have the capability to quickly understand and interpret specialized terminology in the electricity domain through learning from a vast corpus of professional literature and data. They can then be applied to various domains, including question-answering systems. However, existing large language models still face issues of unreliable outputs, necessitating a method to evaluate their results and improve the quality of their applications. We propose a knowledge graph-based credibility evaluation method for electric grid large language model knowledge question-answering. This method aligns the answers generated by large language models with the knowledge graph of a local knowledge base and calculates their cosine similarity and Pearson correlation coefficient. We batch-process the answers from the large language model into an electricity dataset and validate them using this method. Experimental results demonstrate that this method can accurately and efficiently reflect the relevance between texts, providing a reliable scoring basis for question-answering by large models in vertical domains. Future research can focus on exploring other embedding methods that can better extract semantic relationships between texts and validating the feasibility of this method in vertical domains other than electricity.},
booktitle = {Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
pages = {754–759},
numpages = {6},
location = {Xiamen, China},
series = {EITCE '23}
}

@inproceedings{10.1145/3706599.3720206,
author = {Ouyang, Yang and Xu, Yuansong and Jiang, Chang and Li, Quan},
title = {CaseMaster: Designing a Probe for Oral Case Presentation Training with LLM Assistance},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720206},
doi = {10.1145/3706599.3720206},
abstract = {Preparing an oral case presentation (OCP) is a crucial skill for medical students, requiring clear communication of patient information, clinical findings, and treatment plans. However, inconsistent student participation and limited guidance can make this task challenging. While Large language models (LLMs) can provide structured content to streamline the process, their role in enhancing these skills and integrating into medical education remains underexplored. To address this, we conducted a formative study with six medical educators and developedCaseMaster, an interactive probe that leverages LLM-generated content tailored to medical education to help users train their OCP skills. Through a preliminary user study from the expert perspective, we validated the effectiveness of the probe.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {129},
numpages = {11},
keywords = {Large language models, medical education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.5555/3709347.3743784,
author = {Nagpal, Kartik and Dong, Dayi and Mehr, Negar},
title = {Leveraging Large Language Models for Effective and Explainable Multi-Agent Credit Assignment},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Recent work, spanning from autonomous vehicle coordination to in-space assembly, has shown the importance of learning collaborative behavior for enabling robots to achieve shared goals. A common approach for learning this cooperative behavior is to utilize the centralized-training decentralized-execution paradigm. However, this approach also introduces a new challenge: how do we evaluate the contributions of each agent's actions to the overall success or failure of the team. This ''credit assignment'' problem has remained open, and has been extensively studied in the Multi-Agent Reinforcement Learning (MARL) literature. In fact, humans manually inspecting agent behavior often generate better credit evaluations than existing methods. We combine this observation with recent works which show Large Language Models (LLMs) demonstrate human-level performance at many pattern recognition tasks. Our key idea is to reformulate credit assignment to the two pattern recognition problems of sequence improvement and attribution, which motivates our novel Large Language Model Multi-agent Credit Assignment (LLM-MCA) method. Our approach utilizes a centralized LLM reward-critic which numerically decomposes the environment reward based on the individualized contribution of each agent in the scenario. We then update the agents' policy networks based on this feedback. We also propose an extension LLM-TACA where our LLM critic performs explicit task assignment by passing an intermediary goal directly to each agent policy in the scenario. Both our methods far outperform the state-of-the-art on a variety of benchmarks, including Level-Based Foraging, Robotic Warehouse, and our new ''Spaceworld'' benchmark which incorporates collision-related safety constraints. As an artifact of our methods, we generate large trajectory datasets with each timestep annotated with per-agent reward information, as sampled from our LLM critics. By making this dataset available, we aim to enable future works which can directly train a set of collaborative, decentralized policies offline.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {1501–1510},
numpages = {10},
keywords = {credit assignment, foundation models, large language models, multi-agent reinforcement learning, task allocation},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@article{10.1145/3737885,
author = {Brown, Neil C. C. and Weill-Tessier, Pierre and Leinonen, Juho and Denny, Paul and K\"{o}lling, Michael},
title = {Howzat? Appealing to Expert Judgement for Evaluating Human and AI Next-Step Hints for Novice Programmers},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3737885},
doi = {10.1145/3737885},
abstract = {Motivation: Students learning to program often reach states where they are stuck and can make no forward progress – but this may be outside the classroom where no instructor is available to help. In this situation, an automatically generated next-step hint can help them make forward progress and support their learning. It is important to know what makes a good hint or a bad hint, and how to generate good hints automatically in novice programming tools, for example using Large Language Models (LLMs).Method and participants: We recruited 44 Java educators from around the world to participate in an online study. We used a set of real student code states as hint-generation scenarios. Participants used a technique known as comparative judgement to rank a set of candidate next-step Java hints, which were generated by Large Language Models (LLMs) and by five human experienced educators. Participants ranked the hints without being told how they were generated. The hints were generated with no explicit detail given to the LLMs/humans on what the target task was. Participants then filled in a survey with follow-up questions. The ranks of the hints were analysed against a set of extracted hint characteristics using a random forest approach.Findings: We found that LLMs had considerable variation in generating high quality next-step hints for programming novices, with GPT-4 outperforming other models tested. When used with a well-designed prompt, GPT-4 outperformed human experts in generating pedagogically valuable hints. A multi-stage prompt was the most effective LLM prompt. According to a fitted random forest model, the two most important factors of a good hint were length (80–160 words being best), and reading level (US grade nine or below being best). Offering alternative approaches to solving the problem was considered bad, and we found no effect of sentiment.Conclusions: Automatic generation of these hints is immediately viable, given that LLMs outperformed humans – even when the students’ task is unknown. Hint length and reading level were more important than several pedagogical features of hints. The fact that it took a group of experts several rounds of experimentation and refinement to design a prompt that achieves this outcome suggests that students on their own are unlikely to be able to produce the same benefit. The prompting task, therefore, should be embedded in an expert-designed tool.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Educ.},
month = may,
keywords = {LLMs, AI, Java, Next-step hints, comparative judgement}
}

@article{10.1145/3705734,
author = {George, Amrita and Storey, Veda Catherine and Hong, Shuguang},
title = {Unraveling the Impact of ChatGPT as a Knowledge Anchor in Business Education},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3705734},
doi = {10.1145/3705734},
abstract = {The emergence of Large Language Models (LLM), such as ChatGPT, is considered a productivity revolution in many areas of business and society. For a classroom setting, especially, it would be useful to understand whether, and how, to incorporate ChatGPT, similar to any other productivity revolution technology, such as calculators or a Google search engine. Although there are concerns regarding the use of LLMs in business education, the positive or negative impact of LLM use is not well-understood. In this research, we examine the substitution and complementarity effects of using ChatGPT in business curricula on learning outcomes and well-being in a socially supportive learning environment. Specifically, we examine whether technology anchors impact students’ goal orientation, learning outcomes, and well-being by conducting an empirical study with students majoring in Information Systems. Our analysis reveals that a technology anchor (computer playfulness) can complement the effects of social support on learning outcomes, while enhancing well-being for simple tasks. Students’ well-being and learning outcomes are hindered by LLM use (specifically, the computer anxiety anchor), substituting social support for simple and difficult tasks. These findings have implications for educational institutions that are assessing how to incorporate LLMs into business curricula.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {4},
numpages = {30},
keywords = {ChatGPT, Large language model (LLM), technology self-efficacy, computer anxiety, goal orientation, computer playfulness, social support, technology anchors, generative AI, knowledge anchor, OpenAI, technology anchors, artificial intelligence (AI), achievement theory}
}

@inproceedings{10.1145/3706598.3713971,
author = {Ravi, Prerna and Masla, John and Kakoti, Gisella and Lin, Grace C. and Anderson, Emma and Taylor, Matt and Ostrowski, Anastasia K. and Breazeal, Cynthia and Klopfer, Eric and Abelson, Hal},
title = {Co-designing Large Language Model Tools for Project-Based Learning with K12 Educators},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713971},
doi = {10.1145/3706598.3713971},
abstract = {The emergence of generative AI, particularly large language models (LLMs), has opened the door for student-centered and active learning methods like project-based learning (PBL). However, PBL poses practical implementation challenges for educators around project design and management, assessment, and balancing student guidance with student autonomy. The following research documents a co-design process with interdisciplinary K-12 teachers to explore and address the current PBL challenges they face. Through teacher-driven interviews, collaborative workshops, and iterative design of wireframes, we gathered evidence for ways LLMs can support teachers in implementing high-quality PBL pedagogy by automating routine tasks and enhancing personalized learning. Teachers in the study advocated for supporting their professional growth and augmenting their current roles without replacing them. They also identified affordances and challenges around classroom integration, including resource requirements and constraints, ethical concerns, and potential immediate and long-term impacts. Drawing on these, we propose design guidelines for future deployment of LLM tools in PBL.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {138},
numpages = {25},
keywords = {Generative AI, LLMs, AI for education, project-based learning, co-design, teachers, interviews},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3690931.3690982,
author = {Zhang, Ye and Nie, Yiming},
title = {InternDrive: A Multimodal Large Language Model for Autonomous Driving Scenario Understanding},
year = {2024},
isbn = {9798400710049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690931.3690982},
doi = {10.1145/3690931.3690982},
abstract = {With the rapid development of autonomous driving technology, accurately understanding complex driving scenarios has become a critical challenge. Existing computer vision-based solutions exhibit limitations when dealing with dynamic driving environments. Therefore, this paper proposes a method for understanding autonomous driving scenarios using multimodal large language models. Firstly, we designed a set of questions to guide multimodal large language models in comprehensively understanding driving scenarios, and based on this, we constructed a multimodal driving scenario dataset. This dataset combines open-source nuScenes image data with natural language annotations automatically generated and manually reviewed via the OpenAI API. Subsequently, we conducted visual instruction tuning on the open-source multimodal large language model InternVL-1.5 and proposed the InternDrive model. Furthermore, this paper introduces an evaluation method based on a proprietary large model and conducts a comprehensive assessment of InternDrive's ability to understand driving scenarios. Experimental results demonstrate that InternDrive exhibits superior accuracy in multiple driving scenario understanding tasks. Our research provides new methods and perspectives for enhancing the scene understanding capabilities of autonomous driving systems and showcases the potential application of multimodal large language models in the field of autonomous driving.},
booktitle = {Proceedings of the 2024 4th International Conference on Artificial Intelligence, Automation and High Performance Computing},
pages = {294–305},
numpages = {12},
location = {Zhuhai, China},
series = {AIAHPC '24}
}

@inproceedings{10.1145/3650400.3650405,
author = {Wang, Chen and Hua, Min and Song, Jiale and Tang, Xue-song},
title = {Knowledge Graphs Enhanced Large Language Model Prompt for Electric Power Question Answering},
year = {2024},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650400.3650405},
doi = {10.1145/3650400.3650405},
abstract = {With the continuous development and digital transformation in the field of electric power, the application of large language models in the electric power industry has become a remarkable trend. The electric power industry is an information-intensive domain involving extensive data processing, predictive analysis, and decision-making. Therefore, the application of large language models in the electric power sector is of great significance. Current large language models such as GPT3.5 and GLM can perform well in tasks such as question answering dialogues. However, these models still face challenges such as answer hallucination and inaccurate responses. This paper proposes a method to enhance question answering in large language models using knowledge graphs, aiming to improve the accuracy and reliability of these models in question answering tasks in the electric power domain.The proposed method first utilizes local electric power data to extract triplets and generate a question answering dataset specific to the electric power domain using a large language model. Then, the relationships of the knowledge graph triplets are incorporated into the question prompt to enhance the quality of the model's answers. Furthermore, we fine-tune the large language model using the expanded question set derived from the triplets as knowledge enhanced data. Subsequently, we conduct experiments on both an electric power question answering dataset and a knowledge graph question answering dataset. The experimental results demonstrate that our method significantly improves various metrics of the large language model in the electric power question answering task. This research provides new insights and approaches to enhance the effectiveness of question answering systems in the electric power domain. Future studies can further explore and optimize this prompt expansion method for application in broader domains and tasks.},
booktitle = {Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
pages = {24–29},
numpages = {6},
location = {Xiamen, China},
series = {EITCE '23}
}

@inproceedings{10.1145/3641555.3705189,
author = {Wang, Jiayi and Xiao, Ruiwei and Tseng, Ying-Jui},
title = {Generating AI Literacy MCQs: A Multi-Agent LLM Approach},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705189},
doi = {10.1145/3641555.3705189},
abstract = {Artificial intelligence (AI) is transforming society, making it crucial to prepare the next generation through AI literacy in K-12 education. However, scalable and reliable AI literacy materials and assessment resources are lacking. To address this gap, our study presents a novel approach to generating multiple-choice questions (MCQs) for AI literacy assessments. Our method utilizes large language models (LLMs) to automatically generate scalable, high-quality assessment questions. These questions align with user-provided learning objectives, grade levels, and Bloom's Taxonomy levels. We introduce an iterative workflow incorporating LLM-powered critique agents to ensure the generated questions meet pedagogical standards. In the preliminary evaluation, experts expressed strong interest in using the LLM-generated MCQs, indicating that this system could enrich existing AI literacy materials and provide a valuable addition to the toolkit of K-12 educators.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1651–1652},
numpages = {2},
keywords = {AI literacy, LLM-based agent, assessment, large language model, multi-agent workflow, question generation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3728725.3728736,
author = {Fang, Heng},
title = {ColKGC: Collaborative Enhancement using Large Language Model for Knowledge Graph Completion},
year = {2025},
isbn = {9798400713453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3728725.3728736},
doi = {10.1145/3728725.3728736},
abstract = {Knowledge Graph Completion (KGC) aims to address incomplete facts in Knowledge Graphs (KGs). As a mainstream approach for KGC, text-based methods are limited in performance due to insufficient knowledge caused by constraints in fine-tuning data. To incorporate broader external knowledge, some researchers explored KGC approaches based on large language models (LLMs), but general-purpose LLMs lack direct awareness of knowledge graph domain knowledge, making it challenging for them to independently perform KGC tasks. To balance the dependence of text-based methods on knowledge graph domain knowledge and LLMs on external knowledge, we propose Collaborative Enhancement using Large Language Model for KGC (ColKGC). We define the prompt template to implement the interaction between the text-based model and the LLMs, and divide the knowledge graph completion process into two stages. In the concept enhancement stage, we supplement the fine-tuning data by interacting with the prompts of the LLMs to enrich the graph domain knowledge learned by the text-based model. In completion inference stage, we adopted the iterative interaction strategy, taking the text-based model output as the prompt and taking the interaction content of the previous stage as the context to enhance the inference, which improved the LLMs' understanding of the KGC task. Our experiments demonstrate that ColKGC achieves superior results across various standard knowledge graph benchmarks. Extensive experiments also bear out ColKGC's efectiveness in generated data and the iterative interaction framework in assisting LLMs reasoning.},
booktitle = {Proceedings of the 2025 2nd International Conference on Generative Artificial Intelligence and Information Security},
pages = {66–71},
numpages = {6},
keywords = {Knowledge graph completion, Large language models, Link prediction},
location = {
},
series = {GAIIS '25}
}

@inproceedings{10.1145/3638530.3664181,
author = {Pluhacek, Michal and Kovac, Jozef and Viktorin, Adam and Janku, Peter and Kadavy, Tomas and Senkerik, Roman},
title = {Using LLM for Automatic Evolvement of Metaheuristics from Swarm Algorithm SOMA},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3664181},
doi = {10.1145/3638530.3664181},
abstract = {This study investigates the use of the GPT-4 Turbo, a large language model, to enhance the Self-Organizing Migrating Algorithm (SOMA), specifically its All to All variant (SOMA-ATA). Utilizing the model's extensive context capacity for iterative prompting without feedback, we sought to autonomously generate superior algorithmic versions. Contrary to our initial hypothesis, the improvements did not progress linearly. Nevertheless, one iteration stood out significantly, consistently outperforming the baseline across various pairwise comparisons and showing a robust performance profile. This iteration's structure deviated substantially from traditional SOMA principles, underscoring the potential of large language models to create distinctive and effective algorithmic strategies. The results affirm the methodology's ability to produce high-performing algorithms without expert intervention, setting the stage for future research to integrate feedback mechanisms and conduct detailed code analyses to understand further the modifications made by the Large Language Models.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {2018–2022},
numpages = {5},
keywords = {evolutionary computation, large language models, metaheuristic optimization, self-organizing migrating algorithm, automatic algorithm design, GPT},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{10.1145/3706599.3719857,
author = {Wang, Xinyu Jessica and Lee, Christine P. and Mutlu, Bilge},
title = {LearnMate: Enhancing Online Education with LLM-Powered Personalized Learning Plans and Support},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719857},
doi = {10.1145/3706599.3719857},
abstract = {With the increasing prevalence of online learning, adapting education to diverse learner needs remains a persistent challenge. Recent advancements in artificial intelligence (AI), particularly large language models (LLMs), promise powerful tools and capabilities to enhance personalized learning in online educational environments. In this work, we explore how LLMs can improve personalized learning experiences by catering to individual user needs toward enhancing the overall quality of online education. We designed personalization guidelines based on the growing literature on personalized learning to ground LLMs in generating tailored learning plans. To operationalize these guidelines, we implemented LearnMate, an LLM-based system that generates personalized learning plans and provides users with real-time learning support. We discuss the implications and future directions of this work, aiming to move beyond the traditional one-size-fits-all approach by integrating LLM-based personalized support into online learning environments.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {373},
numpages = {10},
keywords = {large-language models; personalized learning; human-centered AI},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706599.3720203,
author = {Tang, Xiaohang and Wong, Sam and Huynh, Marcus and He, Zicheng and Yang, Yalong and Chen, Yan},
title = {SPHERE: Supporting Personalized Feedback at Scale in Programming Classrooms with Structured Review of Generative AI Outputs},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720203},
doi = {10.1145/3706599.3720203},
abstract = {This paper introduces SPHERE, a system that enables instructors to effectively create and review personalized feedback for in-class coding activities. Comprehensive personalized feedback is crucial for programming learning. However, providing such feedback in large programming classrooms poses significant challenges for instructors. While Large Language Models (LLMs) offer potential assistance, how to efficiently ensure the quality of LLM-generated feedback remains an open question. SPHERE guides instructors’ attention to critical students’ issues, empowers them with guided control over LLM-generated feedback, and provides visual scaffolding to facilitate verification of feedback quality. Our between-subject study with 20 participants demonstrates SPHERE’s effectiveness in creating more high-quality feedback while not increasing the time spent on the overall review process compared to a baseline system. This work contributes a synergistic approach to scaling personalized feedback in programming education, addressing the challenges of real-time response, issue prioritization, and large-scale personalization.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {467},
numpages = {17},
keywords = {Generative AI, Large Language Model, Programming Education at Scale, Feedback, Computing Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3701716.3715199,
author = {Zhang, Yifan and Zhao, Xinkui and Wang, Zuxin and Zhou, Zhengyi and Cheng, Guanjie and Deng, Shuiguang and Yin, Jianwei},
title = {SortingHat: Redefining Operating Systems Education with a Tailored Digital Teaching Assistant},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715199},
doi = {10.1145/3701716.3715199},
abstract = {Operating Systems (OS) courses are among the most challenging in computer science education due to the complexity of internal structures and the diversity of running environments. Traditional teaching methods often fail to address the diverse backgrounds, learning speeds, and practical needs of students. To tackle these challenges, we present SortingHat, a personalized digital teaching assistant tailored specifically for OS education. SortingHat integrates advanced AI technologies, including a retrieval-augmented generation (RAG) framework and multi-agent reinforcement learning (MARL), to deliver adaptive, scalable, and effective educational support. SortingHat features a 3D digital human interface powered by large language models (LLMs) to provide personalized, empathetic, and context-aware guidance. It generates tailored exercises based on each student's learning history and academic performance, reinforcing weak areas and challenging advanced concepts. Additionally, the system incorporates a robust evaluation pipeline that ensures fair, consistent, and unbiased grading of student submissions while delivering personalized, actionable feedback for improvement. By combining personalized guidance, adaptive content creation, and automated assessment, SortingHat transforms OS education into an engaging, immersive, and scalable experience.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2951–2954},
numpages = {4},
keywords = {digital human, education, large language models, multi agent reinforcement learning, retrieval augmented generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3641554.3701917,
author = {Wang, Kevin Shukang and Lawrence, Ramon},
title = {Quantitative Evaluation of Using Large Language Models and Retrieval-Augmented Generation in Computer Science Education},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701917},
doi = {10.1145/3641554.3701917},
abstract = {Generative artificial intelligence (GenAI) is transforming Computer Science education, and every instructor is reflecting on how AI will impact their courses. Instructors must determine how students may use AI for course activities and what AI systems they will support and encourage students to use. This task is challenging with the proliferation of large language models (LLMs) and related AI systems. The contribution of this work is an experimental evaluation of the performance of multiple open-source and commercial LLMs utilizing retrieval-augmented generation in answering questions for computer science courses and a cost-benefit analysis for instructors when determining what systems to use. A key factor is the time an instructor has to maintain their supported AI systems and the most effective activities for improving their performance. The paper offers recommendations for deploying, using, and enhancing AI in educational settings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1183–1189},
numpages = {7},
keywords = {artificial intelligence, human-in-the-loop, large language model, question answering, retrieval-augmented generation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3589334.3645408,
author = {Li, Cheng and Zhang, Mingyang and Mei, Qiaozhu and Kong, Weize and Bendersky, Michael},
title = {Learning to Rewrite Prompts for Personalized Text Generation},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645408},
doi = {10.1145/3589334.3645408},
abstract = {Facilitated by large language models (LLMs), personalized text generation has become a rapidly growing research direction. Most existing studies focus on designing specialized models for a particular domain, or they require fine-tuning the LLMs to generate personalized text. We consider a typical scenario in which the large language model, which generates personalized output, is frozen and can only be accessed through APIs. Under this constraint, all one can do is to improve the input text (i.e., text prompts) sent to the LLM, a procedure that is usually done manually. In this paper, we propose a novel method to automatically revise prompts for personalized text generation. The proposed method takes the initial prompts generated by a state-of-the-art, multistage framework for personalized generation and rewrites a few critical components that summarize and synthesize the personal context. The prompt rewriter employs a training paradigm that chains together supervised learning (SL) and reinforcement learning (RL), where SL reduces the search space of RL and RL facilitates end-to-end training of the rewriter. Using datasets from three representative domains, we demonstrate that the rewritten prompts outperform both the original prompts and the prompts optimized via supervised learning or reinforcement learning alone. In-depth analysis of the rewritten prompts shows that they are not only human readable, but also able to guide manual revision of prompts when there is limited resource to employ reinforcement learning to train the prompt rewriter, or when it is costly to deploy an automatic prompt rewriter for inference.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3367–3378},
numpages = {12},
keywords = {large language models, personalized text generation, prompt rewrite},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.5555/3737313.3737340,
author = {Crocetti, Giancarlo and Bak, Seonwoo and Noory, Naqib A. and Vautor-Laplaceliere, Daena D.},
title = {Evaluating the Pedagogical Impact of Large Language Models on Programming Skills in Higher Education},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {This empirical study investigated the impact of Generative AI (GenAI) tools, particularly large language models (LLMs), on college students' Python programming skills in a graduate-level data science course. Using a pretest-posttest methodology and accounting for variables like prior programming experience, the research examined how guided LLM usage affected students' self-assessed programming abilities. The findings revealed that while LLMs positively influenced students' capacity to develop complex applications, work with Python libraries, and write quality code, they had no significant impact on students' grasp of fundamental Python concepts or their general comfort with the language. These results suggest that LLMs serve as effective tools for advancing practical programming skills but cannot substitute for the foundational programming knowledge that must be developed through traditional learning.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {163–177},
numpages = {15}
}

@article{10.1145/3643758,
author = {Wang, Wei and Ning, Huilong and Zhang, Gaowei and Liu, Libo and Wang, Yi},
title = {Rocks Coding, Not Development: A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643758},
doi = {10.1145/3643758},
abstract = {Recently, large language models (LLM) based generative AI has been gaining momentum for their impressive high-quality performances in multiple domains, particularly after the release of the ChatGPT. Many believe that they have the potential to perform general-purpose problem-solving in software development and replace human software developers. Nevertheless, there are in a lack of serious investigation into the capability of these LLM techniques in fulfilling software development tasks. In a controlled 2 \texttimes{} 2 between-subject experiment with 109 participants, we examined whether and to what degree working with ChatGPT was helpful in the coding task and typical software development task and how people work with ChatGPT. We found that while ChatGPT performed well in solving simple coding problems, its performance in supporting typical software development tasks was not that good. We also observed the interactions between participants and ChatGPT and found the relations between the interactions and the outcomes. Our study thus provides first-hand insights into using ChatGPT to fulfill software engineering tasks with real-world developers and motivates the need for novel interaction mechanisms that help developers effectively work with large language models to achieve desired outcomes.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {32},
numpages = {23},
keywords = {controlled experiment, human-AI collaboration, large langauge models, software development task}
}

@inproceedings{10.1145/3680533.3697070,
author = {Zhao, Zhuoran and Yin, Zhizhuo and Sun, Jia and Hui, Pan},
title = {Embodied AI-Guided Interactive Digital Teachers for Education},
year = {2024},
isbn = {9798400711367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680533.3697070},
doi = {10.1145/3680533.3697070},
abstract = {Traditional education is considered incapable of providing prompt feedback, facilitating proactive learning, and giving indiscriminate responses. This has been observed in both in-person classes and online courses, especially when students’ questions fall outside the instructors’ knowledge base or are considered trivial by instructors. Nowadays, the advent of large language models (LLMs) has transformed knowledge acquisition. The LLM-based chatbots enable fast learning through interactive question-answering, which serves as an effective supplement to traditional educational approaches and even shows potential for replacement. To utilize such advancements in education, we propose MAGI, a novel system providing Embodied AI-Guided Interactive digital teachers for education, which integrates LLM-based chatbot technology. To ensure MAGI generates answers without hallucination, we employ a novel retrieval-augmented generation (RAG) paradigm to organize and retrieve useful educational documents for the LLM. Moreover, we create animatable 3D avatars powered by text-to-speech and audio-to-motion models to provide students with interactive conversation experiences. We highlight the possibility of MAGI to enhance education accessibility and improve the overall learning experience.},
booktitle = {SIGGRAPH Asia 2024 Educator's Forum},
articleno = {6},
numpages = {8},
keywords = {AI for education, large language models, multi-modal generation},
location = {
},
series = {SA '24}
}

@inproceedings{10.1145/3706468.3706479,
author = {R\"{u}dian, Sylvio and Podelo, Julia and Ku\v{z}\'{\i}lek, Jakub and Pinkwart, Niels},
title = {Feedback on Feedback: Student’s Perceptions for Feedback from Teachers and Few-Shot LLMs},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706479},
doi = {10.1145/3706468.3706479},
abstract = {Large language models (LLMs) can be a valuable resource for generating texts and performing various instruction-based tasks. In this paper, we explored the use of LLMs, particularly for generating feedback for students in higher education. More precisely, we conducted an experiment to examine students’ perceptions regarding LLM-generated feedback. This has the overall aim of assisting teachers in the feedback creation process. First, we examine the different student perceptions regarding the feedback that students got without being aware of whether it was created by their teacher or an LLM. Our results reveal that the feedback source has not impacted how it was perceived by the students, except in cases where repetitive content has been generated, which is a known limitation of LLMs. Second, students have been asked to identify whether the feedback comes from an LLM or the teacher. The results demonstrate, that students were unable to identify the feedback source. A small subset of indicators has been identified, that clearly revealed from whom the feedback comes from. Third, student perceptions are analyzed while knowing that feedback has been auto-generated. This examination indicates that generated feedback is likely to be met with resistance. It contradicts the findings of the first examination. This emphasizes the need of a teacher-in-the-loop approach when employing auto-generated feedback in higher education.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {82–92},
numpages = {11},
keywords = {Large Language Models, Prompt Engineering, Feedback Indicators, Language Learning},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3701716.3715283,
author = {Tran, Khoa-Dang},
title = {Explainable Manipulated Videos Detection Using Multimodal Large Language Models},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715283},
doi = {10.1145/3701716.3715283},
abstract = {Misinformation detection is receiving significant attention due to their impact on modern social stability. Extensive research has been conducted on multimodal misinformation detection, employing either deep learning approaches or large language models (LLMs). However, existing literature on explainable LLM-based methods remained unexplored when applied to video data. Furthermore, most of the existing datasets focus on facial manipulation and human speech, whereas social media content encompasses a wide range of manipulations such as altering background context and color, adding or removing entities, editing audio and text. This paper proposed a framework based on multimodal large language models (MLLMs) for explainable manipulated videos detection. The framework involves fine-tuning two MLLMs for rationales generation and making final predictions, respectively. In addition, pre-trained encoders, cross-attention mechanisms, and a fusion gate are utilized to extract deeper features for fine-tuning the second MLLM. The goal is to predict manipulated content, identify the specific attack applied to the input video, and provide detailed explanations. This research discusses preliminary findings in literature, presents initial experimental results, and outlines key directions for future work.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {725–728},
numpages = {4},
keywords = {explainable ai, large language models, multimodal misinformation detection, reasoning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3691573.3691597,
author = {Gomes de Siqueira, Alexandre and Yao, Heng and Bloch-elkouby, Sarah and Lawrence, Olivia and Sarli, Giuseppe and Rogers, Megan L. and Venkatakrishnan, Rohith and Venkatakrishnan, Roshan and Galynker, Igor and Lok, Benjamin},
title = {Enhancing Virtual Human Interactions by Designing a Real-Time Dialog Filter for Mitigating Nonsensical Responses},
year = {2024},
isbn = {9798400709791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691573.3691597},
doi = {10.1145/3691573.3691597},
abstract = {Virtual Humans (VHs) are crucial in facilitating discussions on sensitive topics and training interpersonal interactions. However, conversational errors, like nonsensical responses, challenge VH simulation effectiveness. This paper explores real-time dialog filters to detect such undesired exchanges. We employ a five-step prompt design iteratively and leverage OpenAI’s GPT large language model to demonstrate feasibility. Our filter distinguishes meaningful from nonsensical responses generated by a rule-based system, achieving high F1 scores (0.84) and accuracy (0.78). Comparison with human-expert classifications validates its efficacy. Filtering nonsensical responses ensures coherent and relevant interactions, significantly enhancing efficacy. This study underscores how leveraging large language models can refine existing VH systems and improve virtual human dialogues.},
booktitle = {Proceedings of the 26th Symposium on Virtual and Augmented Reality},
pages = {51–60},
numpages = {10},
keywords = {Large Language Models, Nonsensical Responses, Real-Time Dialog Filter, Virtual Human Simulation, Virtual Humans},
location = {Manaus, Brazil},
series = {SVR '24}
}

@inproceedings{10.1145/3641554.3701940,
author = {Riazi, Sara and Rooshenas, Pedram},
title = {LLM-Driven Feedback for Enhancing Conceptual Design Learning in Database Systems Courses},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701940},
doi = {10.1145/3641554.3701940},
abstract = {The integration of LLM-generated feedback into educational settings has shown promise in enhancing student learning outcomes. This paper presents a novel LLM-driven system that provides targeted feedback for conceptual designs in a Database Systems course. The system converts student-created entity-relationship diagrams (ERDs) into JSON format, allows the student to prune the diagram by isolating a relationship, extracts relevant requirements for the selected relationship, and utilizes a large language model (LLM) to generate detailed feedback. Additionally, the system creates a tailored set of questions and answers to further aid student understanding. Our pilot implementation in a Database System course demonstrates effective feedback generation that helped the students improve their design skills.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1001–1007},
numpages = {7},
keywords = {conceptual design, database systems, educational technology, large language models, llm-generated feedback},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3711403.3711488,
author = {Lin, Jian and Mai, Shanyin and Bu, Bingqian and He, Musheng and Wang, Xiaoyi},
title = {Research on the Application of STEM Practical Teaching Based on RAG Knowledge Graph and Large Models},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711488},
doi = {10.1145/3711403.3711488},
abstract = {Practical experience plays a pivotal role in STEM education, effectively cultivating students' practical skills, innovation capabilities, and critical thinking. However, the scarcity of domain-specific practical experience data within Large Language Models (LLMs) has not fully met the deep-level practical knowledge demands of STEM education, impacting the learners' application outcomes. This paper proposes a STEM practical teaching and inquiry system based on Retrieval-Augmented Generation (RAG) technology and knowledge graphs, aiming to enhance learners' learning experiences and interdisciplinary learning abilities, achieving an intelligent upgrade of STEM practical teaching.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {520–527},
numpages = {8},
keywords = {Knowledge Graph, Large Language Models (LLMs), RAG, STEM Practical Teaching},
location = {
},
series = {ICETM '24}
}

@article{10.5555/3722479.3722490,
author = {Wills, Tyler and Burgan, Cara and Guzide, Osman and Liao, Weidong},
title = {Building a Voice-Activated RAG Chatbot with Generative AI and LLMs},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {We have developed a voice-controlled Retrieval-Augmented Generation (RAG) chatbot application at Shepherd University that utilizes Generative AI and Large Language Models (LLMs) to transform how students interact with their student handbook. This application combines cutting-edge natural language processing and voice recognition technologies to create a more dynamic and user-friendly experience. The chatbot leverages LLMs to understand and respond to diverse queries, delivering detailed, contextually appropriate responses directly sourced from the handbook. The RAG methodology ensures responses are not only generated by the AI but also precisely retrieved from relevant handbook sections, preserving response integrity and accuracy.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {35–36},
numpages = {2}
}

@inproceedings{10.1145/3706598.3713731,
author = {Kang, Wenhui and Zhang, Lin and Peng, Xiaolan and Zhang, Hao and Li, Anchi and Wang, Mengyao and Huang, Jin and Tian, Feng and Dai, Guozhong},
title = {TutorCraftEase: Enhancing Pedagogical Question Creation with Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713731},
doi = {10.1145/3706598.3713731},
abstract = {Pedagogical questions are crucial for fostering student engagement and learning. In daily teaching, teachers pose hundreds of questions to assess understanding, enhance learning outcomes, and facilitate the transfer of theory-rich content. However, even experienced teachers often struggle to generate a large volume of effective pedagogical questions. To address this, we introduce TutorCraftEase, an interactive generation system that leverages large language models (LLMs) to assist teachers in creating pedagogical questions. TutorCraftEase enables the rapid generation of questions at varying difficulty levels with a single click, while also allowing for manual review and refinement. In a comparative user study with 39 participants, we evaluated TutorCraftEase against a traditional manual authoring tool and a basic LLM tool. The results show that TutorCraftEase can generate pedagogical questions comparable in quality to those created by experienced teachers, while significantly reducing their workload and time.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1076},
numpages = {22},
keywords = {large language models, intelligent tutoring systems, human-AI collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641555.3705076,
author = {Chen, Matt},
title = {Early Adoption of Custom Generative AI Bots in Online Forums for CS Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705076},
doi = {10.1145/3641555.3705076},
abstract = {This lightning talk presents insights from a pilot program in an IT Faculty, where custom generative AI bots were integrated into online forums across 20 courses over two semesters in 2024. The AI bots were trained on specific course content and past student questions to provide tailored responses to student inquiries, with all responses reviewed by teaching staff before being released to students.This approach, distinct from the direct use of large language models (LLMs) like ChatGPT or Claude, offers targeted information aligned with course material and ensures accuracy while preventing the disclosure of assignment answers. The mechanism is designed to support large computer science courses, including first-year courses with over 1,000 students, where timely and comprehensive staff responses can be challenging.This talk will explore the benefits and drawbacks of using generative AI bots in the CS context. It will also examine the factors influencing staff acceptance and trust in chatbot responses and how AI impacts the types and quality of student questions in forums. Key lessons learned and challenges encountered during the program's implementation will also be shared.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1739},
numpages = {1},
keywords = {custom AI integration, generative AI bots},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3715908,
author = {Li, Jia and Tao, Chongyang and Li, Jia and Li, Ge and Jin, Zhi and Zhang, Huangzhao and Fang, Zheng and Liu, Fang},
title = {Large Language Model-Aware In-Context Learning for Code Generation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715908},
doi = {10.1145/3715908},
abstract = {Large Language Models (LLMs) have shown impressive In-Context Learning (ICL) ability in code generation. LLMs take a prompt context consisting of a few demonstration examples and a new requirement as input, and output new programs without any parameter update. Existing studies have found that the performance of ICL-based code generation heavily depends on the quality of demonstration examples and thus arises research on selecting demonstration examples: given a new requirement, a few demonstration examples are selected from a candidate pool, where LLMs are expected to learn the pattern hidden in these selected demonstration examples. Existing approaches are mostly based on heuristics or randomly selecting examples. However, the distribution of randomly selected examples usually varies greatly, making the performance of LLMs less robust. The heuristics retrieve examples by only considering textual similarities of requirements, leading to sub-optimal performance.To fill this gap, we propose a Large language model-Aware selection approach for In-context-Learning-based code generation named LAIL. LAIL uses LLMs themselves to select examples. It requires LLMs themselves to label a candidate example as a positive example or a negative example for a requirement. Positive examples are helpful for LLMs to generate correct programs, while negative examples are trivial and should be ignored. Based on the labeled positive and negative data, LAIL trains a model-aware retriever to learn the preference of LLMs and select demonstration examples that LLMs need. During the inference, given a new requirement, LAIL uses the trained retriever to select a few examples and feed them into LLMs to generate desired programs. We apply LAIL to four widely used LLMs and evaluate it on five code generation datasets. Extensive experiments demonstrate that LAIL outperforms the state-of-the-art (SOTA) baselines by 11.58%, 3.33%, and 5.07% on CodeGen-Multi-16B, 1.32%, 2.29%, and 1.20% on CodeLlama-34B, and achieves 4.38%, 2.85%, and 2.74% improvements on Text-davinci-003 in terms of Pass@1 at MBJP, MBPP, and MBCPP, respectively. In addition to function-level code generation, LAIL improves the performance of LLMs on DevEval, a repository-level code generation dataset, which achieves 10.04%, 8.12%, and 4.63% improvements compared to the SOTA baselines at Pass@1, 3, and 5 on CodeLlama-7B. Human evaluation further verifies that the generated programs of LAIL are superior in correctness, code quality, and maintainability. Besides, LAIL has satisfactory transferability across different LLMs and datasets, where the retriever learned on one LLM (dataset) can be transferred to other LLMs (datasets).},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {Code generation, in-context-learning, large language model}
}

@inproceedings{10.1145/3696410.3714640,
author = {Wang, Tianlong and Jiao, Xianfeng and Zhu, Yinghao and Chen, Zhongzhi and He, Yifan and Chu, Xu and Gao, Junyi and Wang, Yasha and Ma, Liantao},
title = {Adaptive Activation Steering: A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714640},
doi = {10.1145/3696410.3714640},
abstract = {Recent studies have indicated that Large Language Models (LLMs) harbor an inherent understanding of truthfulness, yet often fail to consistently express it and generate false statements. This gap between ''knowing'' and ''telling'' poses a challenge for ensuring the truthfulness of generated content. Inspired by recent work on the practice of encoding human-interpretable concepts linearly within large language models, we treat truthfulness as a specially linearly encoded concept within LLMs, and introduce Adaptive Activation Steering (ACT), a tuning-free method that adaptively shifts LLM's activations in the ''truthful'' direction during inference. ACT addresses diverse categories of hallucinations by utilizing diverse truthfulness-related steering vectors and adjusting the steering intensity adaptively. Applied as an add-on across various models, ACT significantly improves truthfulness in LLaMA (↑142%), LLaMA2 (↑24%), Alpaca (↑36%), Vicuna (↑28%), LLaMA2-Chat (↑19%), and LLaMA3(↑34%). Furthermore, we verify ACT's scalability across larger models (13B, 33B, 65B), underscoring the adaptability of ACT to large-scale language models. Our code is available at https://github.com/tianlwang/ACT.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {2562–2578},
numpages = {17},
keywords = {hallucination, large language model, tuning-free},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3706599.3719889,
author = {Smirnova, Anastasia and Chun, Kyu beom and Rothman, Wil Louis and Sarma, Siyona},
title = {Text Simplification for Children: Evaluating LLMs vis-\`{a}-vis Human Experts},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719889},
doi = {10.1145/3706599.3719889},
abstract = {Large Language Models (LLMs) can facilitate teaching and learning by generating educational content for specific grade levels. Generation of age and grade-appropriate materials often involves text simplification. Previous work evaluating LLMs’ text simplification for children in educational context showed that LLMs can reduce lexical complexity of a text and improve its readability, but they often use vocabulary that is still too difficult for the targeted grade. In this study we focus on GPT-4o, the most advanced LLM at the time of writing. We evaluate its ability to simplify text for elementary school children and compare its performance vis-\`{a}-vis the human baseline. We show that GPT-4o can successfully reduce text complexity on lexical, syntactic, and discourse levels. However, compared to human experts, it generates syntactically more complex text. This suggests that further fine-tuning with focus on syntax is needed before LLM-generated output reaches the intended user group.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {512},
numpages = {10},
keywords = {Text Simplification, Children, LLMs, GPT-4o, Syntactic Complexity},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3636243.3636257,
author = {Budhiraja, Ritvik and Joshi, Ishika and Challa, Jagat Sesh and Akolekar, Harshal D. and Kumar, Dhruv},
title = {“It's not like Jarvis, but it's pretty close!” - Examining ChatGPT's Usage among Undergraduate Students in Computer Science},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636257},
doi = {10.1145/3636243.3636257},
abstract = {Large language models (LLMs) such as ChatGPT and Google Bard have garnered significant attention in the academic community. Previous research has evaluated these LLMs for various applications such as generating programming exercises and solutions. However, these evaluations have predominantly been conducted by instructors and researchers, not considering the actual usage of LLMs by students. This study adopts a student-first approach to comprehensively understand how undergraduate computer science students utilize ChatGPT, a popular LLM, released by OpenAI. We employ a combination of student surveys and interviews to obtain valuable insights into the benefits, challenges, and suggested improvements related to ChatGPT. Our findings suggest that a majority of students (over 57%) have a convincingly positive outlook towards adopting ChatGPT as an aid in coursework-related tasks. However, our research also highlights various challenges that must be resolved for long-term acceptance of ChatGPT amongst students. The findings from this investigation have broader implications and may be applicable to other LLMs and their role in computing education.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {124–133},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, User Study},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3702163.3702184,
author = {Feng, Yang and Wang, Xiya},
title = {Exploring the Development of Chinese College Students' Proficiency in English through ChatGPT: An Experimental Study},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702184},
doi = {10.1145/3702163.3702184},
abstract = {A semester-long teaching reform experiment was conducted at a university in China, utilizing ChatGPT and other large language models to support the teaching of College English (Comprehensive English). In the experimental class, students employed a ChatGPT-assisted teaching mode, through a “fragmented mobile use” approach for English acquisition under the guidance of the researchers. This method significantly improved weekly English learning time, English learning interest and learning autonomy, classroom participation, and the final examination results of College English courses. Consequently, English learning anxiety was reduced. In contrast, the control class, which followed a traditional teaching mode, did not exhibit similar improvements in these parameters. The experiment demonstrated that the effective use of generative large language models, such as ChatGPT, can significantly enhance second language acquisition and gain high student approval. However, a few students still showed a lack of interest in English learning, and AI struggled to address issues related to learning initiative.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {148–154},
numpages = {7},
keywords = {ChatGPT application, College English, Experiment, Teaching reform},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3691620.3695062,
author = {Liu, Fang and Liu, Zhenwei and Zhao, Qianhui and Jiang, Jing and Zhang, Li and Sun, Zian and Li, Ge and Li, Zhongqi and Ma, Yuchi},
title = {FastFixer: An Efficient and Effective Approach for Repairing Programming Assignments},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695062},
doi = {10.1145/3691620.3695062},
abstract = {Providing personalized and timely feedback for student's programming assignments is useful for programming education. Automated program repair (APR) techniques have been used to fix the bugs in programming assignments, where the Large Language Models (LLMs) based approaches have shown promising results. Given the growing complexity of identifying and fixing bugs in advanced programming assignments, current fine-tuning strategies for APR are inadequate in guiding the LLM to identify bugs and make accurate edits during the generative repair process. Furthermore, the autoregressive decoding approach employed by the LLM could potentially impede the efficiency of the repair, thereby hindering the ability to provide timely feedback. To tackle these challenges, we propose FastFixer, an efficient and effective approach for programming assignment repair. To assist the LLM in accurately identifying and repairing bugs, we first propose a novel repair-oriented fine-tuning strategy, aiming to enhance the LLM's attention towards learning how to generate the necessary patch and its associated context. Furthermore, to speed up the patch generation, we propose an inference acceleration approach that is specifically tailored for the program repair task. The evaluation results demonstrate that FastFixer obtains an overall improvement of 20.46% in assignment fixing when compared to the state-of-the-art baseline. Considering the repair efficiency, FastFixer achieves a remarkable inference speedup of 16.67\texttimes{} compared to the autoregressive decoding algorithm.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {669–680},
numpages = {12},
keywords = {automated program repair, large language models, programming education, inference acceleration},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3706599.3720079,
author = {Shin, Subin and Oh, Jeesun and Lee, Sangwon},
title = {Can LLMs See What I See? A Study on Five Prompt Engineering Techniques for Evaluating UX on a Shopping Site},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720079},
doi = {10.1145/3706599.3720079},
abstract = {Usability testing is essential for improving digital user experiences but has practical limitations in terms of cost-effectiveness. Recent advancements in multimodal Large Language Models (LLMs), like ChatGPT-4, offer new possibilities for UX evaluations. This study investigated the most effective prompt engineering techniques for identifying UX issues in digital interfaces. To achieve this, five prompt engineering techniques were carefully selected based on previous research, and the outputs generated using these techniques were analyzed based on severity assessment criteria. We discovered that Role Prompting and (Zero-Shot) Chain of Thought Prompting were highly effective. Further investigation revealed that a hybrid approach combining both techniques produced the best results. Our findings shed light on the possibility of using multimodal LLM as a UX evaluator, offering meaningful value for future advancements in LLM-based UX evaluations.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {125},
numpages = {7},
keywords = {UX Evaluation, Large Language Model (LLM), Multimodal LLM, Prompt Engineering, Role Prompting, (Zero-Shot) Chain of Thought Prompting},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641555.3705171,
author = {Gonzaga, Justin T. and Jiang, Yuchao and Vassar, Alexandra},
title = {Empowering CS1 Educators: Enhancing Automated Feedback Instruction with Cognitive Load Theory},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705171},
doi = {10.1145/3641555.3705171},
abstract = {Delivering personalised and timely feedback is crucial for helping students address gaps in their understanding. However, the increasing demands of large class sizes make this task particularly challenging for CS1 educators, especially for casual teaching assistants who lack formal training and experience. Existing feedback training methods are often inconsistent and ineffective, leaving educators unprepared to handle diverse student needs.To address this, we designed an adaptive fading procedure based on Cognitive Load Theory (CLT) to support educators in delivering high-quality, personalised feedback. This pedagogical technique is integrated into FeedbackPulse-CLT, an automated tool that evaluates feedback in real-time and provides guidance for improvement. This paper outlines our approach to designing scalable, evidence-based feedback instruction using Generative AI and large language models (LLMs) to overcome feedback quality concerns in CS1 education.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1461–1462},
numpages = {2},
keywords = {cognitive load theory, cs1, feedback, generative ai, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3689535.3689554,
author = {Santos, Eddie Antonio and Becker, Brett A.},
title = {Not the Silver Bullet: LLM-enhanced Programming Error Messages are Ineffective in Practice},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689554},
doi = {10.1145/3689535.3689554},
abstract = {The sudden emergence of large language models (LLMs) such as ChatGPT has had a disruptive impact throughout the computing education community. LLMs have been shown to excel at producing correct code to CS1 and CS2 problems, and can even act as friendly assistants to students learning how to code. Recent work shows that LLMs demonstrate unequivocally superior results in being able to explain and resolve compiler error messages—for decades, one of the most frustrating parts of learning how to code. However, LLM-generated error message explanations have only been assessed by expert programmers in artificial conditions. This work sought to understand how novice programmers resolve programming error messages (PEMs) in a more realistic scenario. We ran a within-subjects study with n = 106 participants in which students were tasked to fix six buggy C programs. For each program, participants were randomly assigned to fix the problem using either a stock compiler error message, an expert-handwritten error message, or an error message explanation generated by GPT-4. Despite promising evidence on synthetic benchmarks, we found that GPT-4 generated error messages outperformed conventional compiler error messages in only 1 of the 6 tasks, measured by students’ time-to-fix each problem. Handwritten explanations still outperform LLM and conventional error messages, both on objective and subjective measures.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {5},
numpages = {7},
keywords = {AI, C, CS1, GPT-4, GenAI, Generative AI, LLMs, PEM, compiler error messages, computing education, debugging, feedback, large language models, novice programmers, programming error messages},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inbook{10.1145/3728725.3728767,
author = {Jiang, Nan and Liu, Chenyu and Yu, Shaofei},
title = {Research on Deep Data Annotation Methods Based on Expertise in the Power Industry},
year = {2025},
isbn = {9798400713453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3728725.3728767},
abstract = {This study presents the development of an automated annotation tool for energy industries such as power, leveraging large language models to address challenges in processing unstructured text data efficiently and accurately. The tool comprises two main subsystems: data cleaning and preprocessing, and data generation. The data cleaning subsystem normalizes multi-format documents, converting them into structured formats suitable for annotation. The data generation subsystem, based on a large language model, includes modules for text, table, terminology, and image annotation, enabling the automatic generation of diverse question-answer pairs. The tool's performance was evaluated on 574 documents of eight common types of documents. Results show the tool's strong annotation capability, achieving high accuracy and coverage rates. However, limitations were observed in areas such as term recognition, context understanding, and multimodal content handling, highlighting avenues for future improvement. This automated annotation tool offers a scalable, cost-effective solution for data annotation in the power industry and lays the groundwork for enhancing data-driven decision-making and knowledge extraction across similar industries.},
booktitle = {Proceedings of the 2025 2nd International Conference on Generative Artificial Intelligence and Information Security},
pages = {266–271},
numpages = {6}
}

@inproceedings{10.1145/3637528.3671470,
author = {Fan, Wenqi and Ding, Yujuan and Ning, Liangbo and Wang, Shijie and Li, Hengyun and Yin, Dawei and Chua, Tat-Seng and Li, Qing},
title = {A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671470},
doi = {10.1145/3637528.3671470},
abstract = {As one of the most advanced techniques in AI, Retrieval-Augmented Generation (RAG) can offer reliable and up-to-date external knowledge, providing huge convenience for numerous tasks. Particularly in the era of AI-Generated Content (AIGC), the powerful capacity of retrieval in providing additional knowledge enables RAG to assist existing generative AI in producing high-quality outputs. Recently, Large Language Models (LLMs) have demonstrated revolutionary abilities in language understanding and generation, while still facing inherent limitations such as hallucinations and out-of-date internal knowledge. Given the powerful abilities of RAG in providing the latest and helpful auxiliary information, Retrieval-Augmented Large Language Models (RA-LLMs) have emerged to harness external and authoritative knowledge bases, rather than solely relying on the model's internal knowledge, to augment the quality of the generated content of LLMs. In this survey, we comprehensively review existing research studies in RA-LLMs, covering three primary technical perspectives: Furthermore, to deliver deeper insights, we discuss current limitations and several promising directions for future research. Updated information about this survey can be found at: https://advanced-recommender-systems.github.io/RAG-Meets-LLMs/},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6491–6501},
numpages = {11},
keywords = {fine-tuning, in-context learning, large language model (llm), pre-training, prompting, retrieval augmented generation (rag)},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3626252.3630897,
author = {Jordan, Mollie and Ly, Kevin and Soosai Raj, Adalbert Gerald},
title = {Need a Programming Exercise Generated in Your Native Language? ChatGPT's Got Your Back: Automatic Generation of Non-English Programming Exercises Using OpenAI GPT-3.5},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630897},
doi = {10.1145/3626252.3630897},
abstract = {Large language models (LLMs) like ChatGPT are changing computing education and may create additional barriers to those already faced by non-native English speakers (NNES) learning computing. We investigate an opportunity for a positive impact of LLMs on NNES through multilingual programming exercise generation. Following previous work with LLM exercise generation in English, we prompt OpenAI GPT-3.5 in 4 natural languages (English, Tamil, Spanish, and Vietnamese) to create introductory programming problems, sample solutions, and test cases. We evaluate these problems on their sensibility, readability, translation, sample solution accuracy, topicality, and cultural relevance. We find that problems generated in English, Spanish, and Vietnamese are largely sensible, easily understood, and accurate in their sample solutions. However, Tamil problems are mostly non-sensible and have a much lower passing test rate, indicating that the abilities of LLMs for problem generation are not generalizable across languages. Our analysis suggests that these problems could not be given verbatim to students, but with minimal effort, most errors can be fixed. We further discuss the benefits of these problems despite their flaws, and their opportunities to provide personalized and culturally relevant resources for students in their native languages.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {618–624},
numpages = {7},
keywords = {introductory programming, large language models, non-native english speakers, problem generation},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626772.3657783,
author = {Salemi, Alireza and Kallumadi, Surya and Zamani, Hamed},
title = {Optimization Methods for Personalizing Large Language Models through Retrieval Augmentation},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657783},
doi = {10.1145/3626772.3657783},
abstract = {This paper studies retrieval-augmented approaches for personalizing large language models (LLMs), which potentially have a substantial impact on various applications and domains. We propose the first attempt to optimize the retrieval models that deliver a limited number of personal documents to large language models for the purpose of personalized generation. We develop two optimization algorithms that solicit feedback from the downstream personalized generation tasks for retrieval optimization--one based on reinforcement learning whose reward function is defined using any arbitrary metric for personalized generation and another based on knowledge distillation from the downstream LLM to the retrieval model. This paper also introduces a pre- and post-generation retriever selection model that decides what retriever to choose for each LLM input. Extensive experiments on diverse tasks from the language model personalization (LaMP) benchmark reveal statistically significant improvements in six out of seven datasets.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {752–762},
numpages = {11},
keywords = {personalization, ranking optimization, retrieval-augmented generation, text generation},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3678610.3678631,
author = {Robledo-Rella, V\'{\i}ctor and Toh, Bee-Yen},
title = {Artificial Intelligence in Physics Courses to Support Active Learning},
year = {2024},
isbn = {9798400716799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678610.3678631},
doi = {10.1145/3678610.3678631},
abstract = {The integration of generative artificial intelligence (AI), particularly Large Language Models (LLMs) like OpenAI's ChatGPT and Microsoft's Copilot, is transforming educational methodologies, including undergraduate physics courses for engineering students. Despite their potential, these LLMs typically rely on statistical learning methods and often exhibit algebraic inaccuracies in solving standard university-level physics problems. This study explores the use of LLMs in physics courses for N = 91 freshman engineering students over two academic terms (Spring and Fall 2023). Students engaged in AI-assisted activities to solve physics problems and were asked to identify and correct the errors made by the chatbot. The outcomes were compared with those from traditional teaching methods without AI involvement, and no significant difference in student learning gains was found. To assess the impact of AI tools in education, a more detailed approach using pre-test and post-test instruments&nbsp;with control and experimental groups is necessary. Survey results revealed, however, that AI-assisted sessions enhanced student engagement, problem-solving skills, and understanding of physics concepts. Students also indicated a strong preference for AI-assisted activities, citing increased motivation and a firm belief in the educational benefits of using these tools. Our findings suggest that well-designed AI interventions can effectively complement traditional instructional methods, especially when the LLMs are integrated with symbolic computational tools like WolframAlpha to improve their accuracy.},
booktitle = {Proceedings of the 2024 10th International Conference on E-Society, e-Learning and e-Technologies (ICSLT)},
pages = {68–75},
numpages = {8},
keywords = {ChatGPT, Copilot, Educational Innovation, Generative AI, Higher Education, Interactive Learning, Physics Education Research},
location = {
},
series = {ICSLT '24}
}

@inproceedings{10.1145/3706599.3719852,
author = {Cao, Yiming and Li, Zhen and Cui, Lizhen and Miao, Chunyan},
title = {Adaptive Human-LLMs Interaction Collaboration: Reinforcement Learning driven Vision-Language Models for Medical Report Generation},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719852},
doi = {10.1145/3706599.3719852},
abstract = {The large language models (LLMs) and vision models have demonstrated great potential in the field of healthcare. The integration of vision-language models (VLMs) has led to significant advancements in automatic medical report generation. However, effectively incorporating doctor feedback into the report generation process remains an unresolved challenge in clinical practice. In this paper, we propose an adaptive human-LLMs collaborative vision-language model that dynamically adjusts the report generation process based on the feedback of doctors and LLMs. We designed a reinforcement learning module to dynamically update the generated content generated by the VLMs according to doctor feedback, addressing the challenge of integrating doctor feedback into the generation model. To mitigate over-reliance on doctor feedback, we introduced the RL-LLM module, which uses an LLM to assess the quality of the generated report. The model adopts a participatory design approach in collaboration with clinical doctors to improve report accuracy and clinical availability.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {62},
numpages = {6},
keywords = {Human LLMs interaction, Medical report generation, Health informatics},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3613904.3642706,
author = {Nguyen, Sydney and Babe, Hannah McLean and Zi, Yangtian and Guha, Arjun and Anderson, Carolyn Jane and Feldman, Molly Q},
title = {How Beginning Programmers and Code LLMs (Mis)read Each Other},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642706},
doi = {10.1145/3613904.3642706},
abstract = {Generative AI models, specifically large language models (LLMs), have made strides towards the long-standing goal of text-to-code generation. This progress has invited numerous studies of user interaction. However, less is known about the struggles and strategies of non-experts, for whom each step of the text-to-code problem presents challenges: describing their intent in natural language, evaluating the correctness of generated code, and editing prompts when the generated code is incorrect. This paper presents a large-scale controlled study of how 120 beginning coders across three academic institutions approach writing and editing prompts. A novel experimental design allows us to target specific steps in the text-to-code process and reveals that beginners struggle with writing and editing prompts, even for problems at their skill level and when correctness is automatically determined. Our mixed-methods evaluation provides insight into student processes and perceptions with key implications for non-expert Code LLM use within and outside of education.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {651},
numpages = {26},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3649217.3653612,
author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Denny, Paul},
title = {Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653612},
doi = {10.1145/3649217.3653612},
abstract = {Large language models (LLMs) have shown great potential for the automatic generation of feedback in a wide range of computing contexts. However, concerns have been voiced around the privacy and ethical implications of sending student work to proprietary models. This has sparked considerable interest in the use of open source LLMs in education, but the quality of the feedback that such open models can produce remains understudied. This is a concern as providing flawed or misleading generated feedback could be detrimental to student learning. Inspired by recent work that has utilised very powerful LLMs, such as GPT-4, to evaluate the outputs produced by less powerful models, we conduct an automated analysis of the quality of the feedback produced by several open source models using a dataset from an introductory programming course. First, we investigate the viability of employing GPT-4 as an automated evaluator by comparing its evaluations with those of a human expert. We observe that GPT-4 demonstrates a bias toward positively rating feedback while exhibiting moderate agreement with human raters, showcasing its potential as a feedback evaluator. Second, we explore the quality of feedback generated by several leading open-source LLMs by using GPT-4 to evaluate the feedback. We find that some models offer competitive performance with popular proprietary LLMs, such as ChatGPT, indicating opportunities for their responsible use in educational settings.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {52–58},
numpages = {7},
keywords = {automatic evaluation, automatic feedback, code llama, generative ai, gpt-4, large language models, llm-as-a-judge, llms, open source, programming feedback, zephyr},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3571884.3604316,
author = {Liesenfeld, Andreas and Lopez, Alianda and Dingemanse, Mark},
title = {Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators},
year = {2023},
isbn = {9798400700149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571884.3604316},
doi = {10.1145/3571884.3604316},
abstract = {Large language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI’s ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as ‘open source’, many inherit undocumented data of dubious legality, few share the all-important instruction-tuning (a key site where human annotation labour is involved), and careful scientific documentation is exceedingly rare. Degrees of openness are relevant to fairness and accountability at all points, from data collection and curation to model architecture, and from training and fine-tuning to release and deployment.},
booktitle = {Proceedings of the 5th International Conference on Conversational User Interfaces},
articleno = {47},
numpages = {6},
keywords = {RLHF, chatGPT, large language models, open source, survey},
location = {Eindhoven, Netherlands},
series = {CUI '23}
}

@inproceedings{10.1145/3641555.3705040,
author = {Garcia, Frank Ley},
title = {LLM+RAG Driven Topic Modeling},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705040},
doi = {10.1145/3641555.3705040},
abstract = {This paper explores the use of Large Language Models (LLMs) combined with Retrieval-Augmented Generation (RAG) to assist instructors in identifying course-wide student challenges through topic modeling. Unlike previous studies that primarily generate personalized resources for individual students, this research focuses on analyzing reflections from an entire class to inform curriculum design and intervention strategies. Using the LLaMa-3.1-8B model, experiments across varying cosine similarity thresholds reveal both the strengths and limitations of integrating retrieval-based models. While RAG did not consistently outperform standalone LLMs, it offers key insights into the complexities of applying retrieval-augmented approaches in educational settings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1754},
numpages = {1},
keywords = {large language models, natural language processing, probabilistic modeling, retrieval-augmented generation, text analysis, topic modeling},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701785,
author = {Ramirez Osorio, Valeria and Zavaleta Bernuy, Angela and Simion, Bogdan and Liut, Michael},
title = {Understanding the Impact of Using Generative AI Tools in a Database Course},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701785},
doi = {10.1145/3641554.3701785},
abstract = {Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) have led to changes in educational practices by creating opportunities for personalized learning and immediate support. Computer science student perceptions and behaviors towards GenAI tools have been studied, but the effects of such tools on student learning have yet to be determined conclusively. We investigate the impact of GenAI tools on computing students' performance in a database course and aim to understand why students use GenAI tools in assignments. Our mixed-methods study (N=226) asked students to self-report whether they used a GenAI tool to complete a part of an assignment and why. Our results reveal that students utilizing GenAI tools performed better on the assignment part in which LLMs were permitted but did worse in other parts of the assignment and in the course overall. Also, those who did not use GenAI tools viewed more discussion board posts and participated more than those who used ChatGPT. This suggests that using GenAI tools may not lead to better skill development or mental models, at least not if the use of such tools is unsupervised, and that engagement with official course help supports may be affected. Further, our thematic analysis of reasons for using or not using GenAI tools, helps understand why students are drawn to these tools. Shedding light into such aspects empowers instructors to be proactive in how to encourage, supervise, and handle the use or integration of GenAI into courses, fostering good learning habits.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {959–965},
numpages = {7},
keywords = {computing education, databases, generative artificial intelligence, large language models, student behavior, student performance},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705080,
author = {Morales, Jamie and Raman, Preeti},
title = {Prompt-Engineering Strategies for Minimizing Bias in Large Language Model Outputs: Applications in Computing Education},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705080},
doi = {10.1145/3641555.3705080},
abstract = {As large language models (LLMs) increasingly permeate educational applications, concerns about the perpetuation of bias persist. We present our preliminary work on developing prompt-engineering strategies to mitigate bias in content generated by LLMs in computer science (CS) education. This work investigates both empirical insights into fairness-aware prompt formulation and actionable takeaways for educators. We focus on an initial list of prompting strategies for mitigating bias and explore their impact on educational content generation. Recent research has shown the efficacy of prompt-base debiasing [1] as well as the potential disadvantages of using prompts that have not been mitigated for bias, from user dissatisfaction [2] to unsafe outputs [5, 6]. Additionally, a growing body of empirical work points to the idea that certain properties of in-context examples such as flow [7], illustration [3], and order [4] could either improve or derail LLM performance. Our study leverages these findings in the context of generating educational content. The goal is to promote fairness-aware approaches which can be applied to the automated generation of learning materials and the development of LLM-based educational tools. This work also contributes practical insights on prompt-engineering to the evolving curriculum of Ethics in Artificial Intelligence (AI).},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1743},
numpages = {1},
keywords = {bias, education, ethics, generative ai, in-context examples, language model, language technology, llm, nlp, prompt-engineering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3699538.3699588,
author = {Pereira Cipriano, Bruno and Silva, Miguel and Correia, Rodrigo and Alves, Pedro},
title = {Towards the Integration of Large Language Models and Automatic Assessment Tools: Enhancing Student Support in Programming Assignments},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699588},
doi = {10.1145/3699538.3699588},
abstract = {The rise of Large Language Models (LLMs) has sparked discussion in Computer Science Education (CSE) due to their ability to generate code from text prompts. Students may rely on these tools, neglecting core skills like computational thinking and program design. Thus, it’s crucial to responsibly integrate them into computer science courses.To address this, we integrated an open-source Automatic Assessment Tool with GPT, enabling students to receive LLM assistance on their programming assignments. This tool can be adopted and improved by educators, promoting more responsible integration of LLMs in CSE.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {52},
numpages = {2},
keywords = {large language models, automatic assessment tools, feedback},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3649409.3691094,
author = {Feng, Ty and Liu, Sa and Ghosal, Dipak},
title = {CourseAssist: Pedagogically Appropriate AI Tutor for Computer Science Education},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691094},
doi = {10.1145/3649409.3691094},
abstract = {The growing enrollments in computer science courses and increase in class sizes necessitate scalable, automated tutoring solutions to adequately support student learning. While Large Language Models (LLMs) like GPT-4 have demonstrated potential in assisting students through question-answering, educators express concerns over student overreliance, miscomprehension of generated code, and the risk of inaccurate answers. Rather than banning these tools outright, we advocate for a constructive approach that harnesses the capabilities of AI while mitigating potential risks. This poster introduces CourseAssist, a novel LLM-based tutoring system tailored for computer science education. Unlike generic LLM systems, CourseAssist uses retrieval-augmented generation, user intent classification, and question decomposition to align AI responses with specific course materials and learning objectives, thereby ensuring pedagogical appropriateness of LLMs in educational settings. We evaluated CourseAssist against a baseline of GPT-4 using a dataset of 50 question-answer pairs from a programming languages course, focusing on the criteria of usefulness, accuracy, and pedagogical appropriateness. Evaluation results show that CourseAssist significantly outperforms the baseline, demonstrating its potential to serve as an effective learning assistant. We have also deployed CourseAssist in 6 computer science courses at a large public R1 research university reaching over 500 students. Interviews with 20 student users show that CourseAssist improves computer science instruction by increasing the accessibility of course-specific tutoring help and shortening the feedback loop on their programming assignments. Future work will include extensive pilot testing at more universities and exploring better collaborative relationships between students, educators, and AI that improve computer science learning experiences.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {310–311},
numpages = {2},
keywords = {AI tutor, computer science education, intelligent tutoring systems, large language models, pedagogical appropriateness, question answering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3709026.3709030,
author = {Liew, Pei Yee and Tan, Ian K. T.},
title = {On Automated Essay Grading using Large Language Models},
year = {2025},
isbn = {9798400718182},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709026.3709030},
doi = {10.1145/3709026.3709030},
abstract = {Automated Essay Grading (AEG), combining Automated Essay Scoring (AES) and Automated Writing Evaluation (AWE), is a time-saving solution to the challenges of manual essay evaluation. It aims to reduce the workload on educators by offering a more consistent grading approach. Inspired by ChatGPT’s impressive language comprehension and generation capabilities, this study explored the potential of various Large Language Models (LLMs) in AEG tasks. The models examined include GPT-4, GPT-3.5, PaLM, and LLaMA2. Tailored prompts were designed and their performance was assessed in conjunction with each LLM through prompt engineering. Our study shows that LLMs can achieve substantial agreement with human markers in AES, with a Quadratic Weighted Kappa (QWK) score of 0.68. In AWE, the feedback on the essay was assessed qualitatively. It achieved an agreement level score of 4.9 (out of 5) with a standard deviation of 0.05, closely aligned with human assessment. This study provided valuable insights into the effectiveness of LLMs in automated essay grading. It highlighted their potential to enhance educational assessment practices.},
booktitle = {Proceedings of the 2024 8th International Conference on Computer Science and Artificial Intelligence},
pages = {204–211},
numpages = {8},
keywords = {automated essay scoring, automated writing evaluation, large language models, prompt engineering},
location = {
},
series = {CSAI '24}
}

@inproceedings{10.1145/3641555.3705237,
author = {Mittal, Meenakshi and Bailey, Azalea and Phelps, Victoria and Miroyan, Mihran and Mitra, Chancharik and Jain, Rishi and Niousha, Rose and Ranade, Gireeja and Norouzi, Narges},
title = {Raising the Bar: Automating Consistent and Equitable Student Support with LLMs},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705237},
doi = {10.1145/3641555.3705237},
abstract = {Large Language Models (LLMs) can be used to automate many aspects of the educational field. In this paper, we look into the benefits of automating responses to student questions in course discussion forums using our Retrieval-Augmented Generation (RAG)-based LLM pipeline (Edison). Our research questions are:RQ1 How do the responses generated by Edison compare to those of TAs in terms of level of detail and use of examples?RQ2 How does the tone of responses generated by Edison compare to that of TA responses?RQ3 Are responses generated by Edison more self-consistent than TA responses?Our results suggest that Edison generates responses with more detail, examples, positive tone, and self-consistency than TAs. We envision Edison being used as a baseline for TAs to build responses on, reduce response times, and promote equitable feedback.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1549–1550},
numpages = {2},
keywords = {cs1, discussion forum, large language models, student feedback},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3718491.3718520,
author = {Ran, Zhou and Chen, Yuhan and Jiang, Quanli and E, Kunpeng},
title = {Intent Recognition in Dialogue Systems},
year = {2025},
isbn = {9798400710865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3718491.3718520},
doi = {10.1145/3718491.3718520},
abstract = {This paper reviews the evolution of intent recognition in dialogue systems, from traditional machine learning methods to modern deep learning and large language models (LLMs). It highlights challenges in open environments, such as unknown intents and adversarial attacks, and explores recent advancements, including generative models and adaptive optimization.},
booktitle = {Proceedings of the 4th Asia-Pacific Artificial Intelligence and Big Data Forum},
pages = {165–173},
numpages = {9},
keywords = {Conversational Systems, Deep Learning, Intent Recognition, Open Environments, Robustness},
location = {
},
series = {AIBDF '24}
}

@article{10.1145/3697010,
author = {Ouyang, Shuyin and Zhang, Jie M. and Harman, Mark and Wang, Meng},
title = {An Empirical Study of the Non-Determinism of ChatGPT in Code Generation},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3697010},
doi = {10.1145/3697010},
abstract = {There has been a recent explosion of research on Large Language Models (LLMs) for software engineering tasks, in particular code generation. However, results from LLMs can be highly unstable; non-deterministically returning very different code for the same prompt. Such non-determinism affects the correctness and consistency of the generated code, undermines developers’ trust in LLMs, and yields low reproducibility in LLM-based papers. Nevertheless, there is no work investigating how serious this non-determinism threat is.To fill this gap, this article conducts an empirical study on the non-determinism of ChatGPT in code generation. We chose to study ChatGPT because it is already highly prevalent in the code generation research literature. We report results from a study of 829 code generation problems across three code generation benchmarks (i.e., CodeContests, APPS and HumanEval) with three aspects of code similarities: semantic similarity, syntactic similarity, and structural similarity. Our results reveal that ChatGPT exhibits a high degree of non-determinism under the default setting: the ratio of coding tasks with zero equal test output across different requests is 75.76%, 51.00% and 47.56% for three different code generation datasets (i.e., CodeContests, APPS and HumanEval), respectively. In addition, we find that setting the temperature to 0 does not guarantee determinism in code generation, although it indeed brings less non-determinism than the default configuration (temperature  (=)  1). In order to put LLM-based research on firmer scientific foundations, researchers need to take into account non-determinism in drawing their conclusions.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
articleno = {42},
numpages = {28},
keywords = {code generation, non-determinism, large language model}
}

@inproceedings{10.1145/3706468.3706523,
author = {Khalil, Mohammad and Vadiee, Farhad and Shakya, Ronas and Liu, Qinyi},
title = {Creating Artificial Students that Never Existed: Leveraging Large Language Models and CTGANs for Synthetic Data Generation},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706523},
doi = {10.1145/3706468.3706523},
abstract = {In this study, we explore the growing potential of AI and deep learning technologies, particularly Generative Adversarial Networks (GANs) and Large Language Models (LLMs), for generating synthetic tabular data. Access to quality students’ data is critical for advancing learning analytics, but privacy concerns and stricter data protection regulations worldwide limit their availability and usage. Synthetic data offers a promising alternative. We investigate whether synthetic data can be leveraged to create artificial students for serving learning analytics models. Using the popular GAN model- CTGAN and three LLMs- GPT2, DistilGPT2, and DialoGPT, we generate synthetic tabular student data. Our results demonstrate the strong potential of these methods to produce high-quality synthetic datasets that resemble real students’ data. To validate our findings, we apply a comprehensive set of utility evaluation metrics to assess the statistical and predictive performance of the synthetic data and compare the different generator models used, specially the performance of LLMs. Our study aims to provide the learning analytics community with valuable insights into the use of synthetic data, laying the groundwork for expanding the field’s methodological toolbox with new innovative approaches for learning analytics data generation.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {439–450},
numpages = {12},
keywords = {Synthetic Data Generation; Artificial data; Learning Analytics (LA); Artificial Intelligence for Education (AIED); Large Language Models (LLMs); Conditional Tabular GAN (CTGAN); Deep Learning},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3626253.3635624,
author = {Fan, Aysa X. and Hendrawan, Rully A. and Shi, Yang and Ma, Qianou},
title = {Enhancing Code Tracing Question Generation with Refined Prompts in Large Language Models},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635624},
doi = {10.1145/3626253.3635624},
abstract = {This study refines Large Language Models (LLMs) prompts to enhance the generation of code tracing questions, where the new expert-guided prompts consider features identified from prior research. Expert evaluations compared new LLM-generated questions against previously preferred ones, revealing improved quality in aspects like complexity and concept coverage. While providing insights into effective question generation and affirming LLMs' potential in educational content creation, the study also contributes an expert-evaluated question dataset to the computing education community. However, generating high-quality reverse tracing questions remains a nuanced challenge, indicating a need for further LLM prompting refinement.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1640–1641},
numpages = {2},
keywords = {computer science education, large language model, programming education, tracing question},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3701551.3707416,
author = {Somov, Oleg},
title = {The Generalization and Error Detection in LLM-based Text-to-SQL Systems},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3707416},
doi = {10.1145/3701551.3707416},
abstract = {Text-to-SQL systems streamline human-database interactions, improving data retrieval and decision-making. Although large language models (LLMs) can now generate SQL code, challenges with generalization and uncontrolled generation hinder their use in production. Text-to-SQL tasks are particularly sensitive to distribution shifts, where performance declines with unfamiliar database elements or novel queries. Effective systems must maintain quality, measured in terms of generalization (correct processing of novel user requests) and error detection (identification of incorrect generations). This study empirically assesses LLM-based Text-to-SQL systems limitations, defining reliable production scenarios. Current contributions include a cross-lingual generalization research, study on generative model generalization abilities and the quality of selective classification for error detection risk under different distribution shifts in task of Text-to-SQL.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {1077–1079},
numpages = {3},
keywords = {distribution shift, error detection, generalization, text-to-sql},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3711542.3711578,
author = {Murogaki, Takumi and Nishimura, Toshikazu},
title = {Enhancing Multi-Person Dialogue with Large Language Models: A Structured Approach to Natural Communication},
year = {2025},
isbn = {9798400717383},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711542.3711578},
doi = {10.1145/3711542.3711578},
abstract = {The rise of social networking services has increased text-based communication, often leading to misunderstandings. This study aims to develop a system using large language models (LLMs) like ChatGPT to provide real-time support in human dialogues. Traditional LLM chatbots, designed for one-on-one interactions, struggle with multi-person conversations, often leading to unnatural responses. This research proposes methods to enhance LLM's ability to distinguish between different speakers and improve its reasoning capabilities. By implementing "conversation structure tags" and simulating multi-person arguments, the system aims to generate natural, context-aware responses, enhancing the dialogue's quality and engagement.},
booktitle = {Proceedings of the 2024 8th International Conference on Natural Language Processing and Information Retrieval},
pages = {317–323},
numpages = {7},
keywords = {Conversation Structure Tags, Dialogue Support Systems, Large Language Models, Multi-Party Dialogue, Multi-Personality Debate Simulation},
location = {
},
series = {NLPIR '24}
}

@inproceedings{10.1145/3657604.3664699,
author = {Hutt, Stephen and Hieb, Grayson},
title = {Scaling Up Mastery Learning with Generative AI: Exploring How Generative AI Can Assist in the Generation and Evaluation of Mastery Quiz Questions},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664699},
doi = {10.1145/3657604.3664699},
abstract = {Generative AI has the potential to scale a number of educational practices, previously limited by resources. One such instructional approach is mastery learning, a pedagogy emphasizing proficiency before progression that is highly resource (teacher time, materials) intensive. The rise of computer-based instruction offered partial solutions, tailoring student progression and automating some facets of the mastery learning process. This work in progress considers the application of large language models for content generation tailored to mastery learning. We present a paired framework for analyzing and evaluating the generated content relative to rubrics designed by the teacher. Recognizing the potential of large language models, we critically assess the potential of improving mastery-based instruction. We close our discussion by considering the applications and limitations of this approach.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {310–314},
numpages = {5},
keywords = {content evaluation, content generation, generative ai, large language models, mastery learning},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3723178.3723224,
author = {Siam, Md Kamrul and Gu, Huanying and Cheng, Jerry Q.},
title = {Programming with AI: Evaluating ChatGPT, Gemini, AlphaCode, and GitHub Copilot for Programmers},
year = {2025},
isbn = {9798400713828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723178.3723224},
doi = {10.1145/3723178.3723224},
abstract = {Our everyday lives now heavily rely on artificial intelligence (AI) powered large language models (LLMs). Like regular users, programmers are also benefiting from the newest large language models. In response to the critical role that AI models play in modern software development, this study presents a thorough evaluation of leading programming assistants, including ChatGPT, Gemini (Bard AI), AlphaCode, and GitHub Copilot. The evaluation is based on tasks like natural language processing and code generation accuracy in different programming languages like Java, Python and C++. Based on the results, it has emphasized their strengths and weaknesses and the importance of further modifications to increase the reliability and accuracy of the latest popular models. Although these AI assistants illustrate a high level of progress in language understanding and code generation, along with ethical considerations and responsible usage, they provoke a necessity for discussion. With time, developing more refined AI technology is essential for achieving advanced solutions in various fields, especially with the knowledge of the feature intricacies of these models and their implications. This study offers a comparison of different LLMs and provides essential feedback on the rapidly changing area of AI models. It also emphasizes the need for ethical developmental practices to actualize AI models’ full potential.},
booktitle = {Proceedings of the 3rd International Conference on Computing Advancements},
pages = {346–354},
numpages = {9},
keywords = {AI models, chatbot, Gemini, GitHub Copilot, ChatGPT, AlphaCode, LLM, code generation, ethical considerations, responsible deployment, AI model accuracy},
location = {
},
series = {ICCA '24}
}

@inproceedings{10.1145/3649165.3690100,
author = {MacNeil, Stephen and Rogalska, Magdalena and Leinonen, Juho and Denny, Paul and Hellas, Arto and Crosland, Xandria},
title = {Synthetic Students: A Comparative Study of Bug Distribution Between Large Language Models and Computing Students},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690100},
doi = {10.1145/3649165.3690100},
abstract = {Large language models (LLMs) present an exciting opportunity for generating synthetic classroom data. Such data could include code containing a typical distribution of errors, simulated student behavior to address the cold start problem when developing education tools, and synthetic user data when access to authentic data is restricted due to privacy reasons. In this research paper, we conduct a comparative study examining the distribution of bugs generated by LLMs in contrast to those produced by computing students. Leveraging data from two previous large-scale analyses of student-generated bugs, we investigate whether LLMs can be coaxed to exhibit bug patterns that are similar to authentic student bugs when prompted to inject errors into code. The results suggest that unguided, LLMs do not generate plausible error distributions, and many of the generated errors are unlikely to be generated by real students. However, with guidance including descriptions of common errors and typical frequencies, LLMs can be shepherded to generate realistic distributions of errors in synthetic code.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {137–143},
numpages = {7},
keywords = {buggy code, generative ai, gpt-4, llms, synthetic data},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@article{10.1145/3712709,
author = {Ataguba, Grace and Orji, Rita},
title = {Exploring Large Language Models for Personalized Recipe Generation and Weight-Loss Management},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
url = {https://doi.org/10.1145/3712709},
doi = {10.1145/3712709},
abstract = {The emergence of large language models (LLMs) is transforming various health-related domains, including approaches to obesity management. Obesity remains one of the world’s leading health issues, prompting the research community to develop various weight-loss applications focused on physical activity, dietary planning, and related interventions. In this study, we explore the capability of the LLM ChatGPT for personalized dietary planning. We conducted two case studies: Case Study 1 examined self-supervised recipe generation using ChatGPT alone, while Case Study 2 investigated a self-supervised approach combining National Institute of Health standards with ChatGPT recipe recommendations. We also performed a user study to evaluate recipe recommendations from ChatGPT. Our results show that ChatGPT recommends appropriate recipes based on comparisons with the United States Department of Agriculture’s (USDA) recipe calculator. We found no significant difference between ChatGPT-generated recipe recommendation calories and USDA standards for either Case Study 1 (p = 0.8530) or Case Study 2 (p = 0.0687). In addition, we found significant weight loss in participants following these recipes in both Case Study 1 (p &lt; 0.00001) and Case Study 2 (p = 0.0014). Furthermore, the user study with potential weight-loss participants revealed varying levels of satisfaction (p = 0.001) and identified themes related to meal preferences, effective prompt generation, and mixed concerns regarding privacy, trust, user consent, and data storage. We conclude by discussing additional findings from our case and user studies, and present opportunities, challenges, and design and ethical considerations for the research community.},
journal = {ACM Trans. Comput. Healthcare},
month = apr,
articleno = {22},
numpages = {57},
keywords = {large language model, obesity, weight loss, ChatGPT, recipes, diet plan}
}

@inproceedings{10.1145/3706599.3719785,
author = {Huffman, Shuxu and Chen, Si and Mack, Kelly Avery and Su, Haotian and Wang, Qi and Kushalnagar, Raja},
title = {"We do use it, but not how hearing people think": How the Deaf and Hard of Hearing Community Uses Large Language Model Tools},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719785},
doi = {10.1145/3706599.3719785},
abstract = {Generative AI tools, particularly those utilizing large language models (LLMs), are increasingly used in everyday contexts. While these tools enhance productivity and accessibility, little is known about how Deaf and Hard of Hearing (DHH) individuals engage with them or the challenges they face when using them. This paper presents a mixed-method study exploring how the DHH community uses Text AI tools like ChatGPT to reduce communication barriers and enhance information access. We surveyed 80 DHH participants and conducted interviews with 9 participants. Our findings reveal important benefits, such as eased communication and bridging Deaf and hearing cultures, alongside challenges like lack of American Sign Language (ASL) support and Deaf cultural understanding. We highlight unique usage patterns, propose inclusive design recommendations, and outline future research directions to improve Text AI accessibility for the DHH community.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {33},
numpages = {9},
keywords = {Accessibility, LLM, ChatGPT, Deaf and Hard of hearing},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3673791.3698432,
author = {Staudinger, Moritz and Kusa, Wojciech and Piroi, Florina and Lipani, Aldo and Hanbury, Allan},
title = {A Reproducibility and Generalizability Study of Large Language Models for Query Generation},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673791.3698432},
doi = {10.1145/3673791.3698432},
abstract = {Systematic literature reviews (SLRs) are a cornerstone of academic research, yet they are often labour-intensive and time-consuming due to the detailed literature curation process. The advent of generative AI and large language models (LLMs) promises to revolutionize this process by assisting researchers in several tedious tasks, one of them being the generation of effective Boolean queries that will select the publications to consider including in a review. This paper presents an extensive study of Boolean query generation using LLMs for systematic reviews, reproducing and extending the work of Wang et al. and Alaniz et al. Our study investigates the replicability and reliability of results achieved using ChatGPT and compares its performance with open-source alternatives like Mistral and Zephyr to provide a more comprehensive analysis of LLMs for query generation.Therefore, we implemented a pipeline, which automatically creates a Boolean query for a given review topic by using a previously defined LLM, retrieves all documents for this query from the PubMed database and then evaluates the results. With this pipeline we first assess whether the results obtained using ChatGPT for query generation are reproducible and consistent. We then generalize our results by analyzing and evaluating open-source models and evaluating their efficacy in generating Boolean queries.Finally, we conduct a failure analysis to identify and discuss the limitations and shortcomings of using LLMs for Boolean query generation. This examination helps to understand the gaps and potential areas for improvement in the application of LLMs to information retrieval tasks. Our findings highlight the strengths, limitations, and potential of LLMs in the domain of information retrieval and literature review automation. Our code is available online.},
booktitle = {Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {186–196},
numpages = {11},
keywords = {boolean query, llms, query generation, systematic reviews},
location = {Tokyo, Japan},
series = {SIGIR-AP 2024}
}

@inproceedings{10.1145/3636243.3636256,
author = {Doughty, Jacob and Wan, Zipiao and Bompelli, Anishka and Qayum, Jubahed and Wang, Taozhi and Zhang, Juran and Zheng, Yujia and Doyle, Aidan and Sridhar, Pragnya and Agarwal, Arav and Bogart, Christopher and Keylor, Eric and Kultur, Can and Savelka, Jaromir and Sakr, Majd},
title = {A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636256},
doi = {10.1145/3636243.3636256},
abstract = {There is a constant need for educators to develop and maintain effective up-to-date assessments. While there is a growing body of research in computing education on utilizing large language models&nbsp;(LLMs) in generation and engagement with coding exercises, the use of LLMs for generating programming MCQs has not been extensively explored. We analyzed the capability of GPT-4 to produce multiple-choice questions (MCQs) aligned with specific learning objectives (LOs) from Python programming classes in higher education. Specifically, we developed an LLM-powered (GPT-4) system for generation of MCQs from high-level course context and module-level LOs. We evaluated 651 LLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python courses. We found that GPT-4 was capable of producing MCQs with clear language, a single correct choice, and high-quality distractors. We also observed that the generated MCQs appeared to be well-aligned with the LOs. Our findings can be leveraged by educators wishing to take advantage of the state-of-the-art generative models to support MCQ authoring efforts.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {114–123},
numpages = {10},
keywords = {Assessments, Automated Content Generation, Automatic Generation, GPT-4, LLMs, LOs, Large Language Models, Learning Objectives, MCQs, Multiple-choice Questions},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@article{10.1109/TASLP.2024.3419446,
author = {Mei, Xinhao and Meng, Chutong and Liu, Haohe and Kong, Qiuqiang and Ko, Tom and Zhao, Chengqi and Plumbley, Mark D. and Zou, Yuexian and Wang, Wenwu},
title = {WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3419446},
doi = {10.1109/TASLP.2024.3419446},
abstract = {The advancement of audio-language (AL) multimodal learning tasks has been significant in recent years, yet the limited size of existing audio-language datasets poses challenges for researchers due to the costly and time-consuming collection process. To address this data scarcity issue, we introduce &lt;italic&gt;WavCaps&lt;/italic&gt;, the first large-scale weakly-labelled audio captioning dataset, comprising approximately 400 k audio clips with paired captions. We sourced audio clips and their raw descriptions from web sources and a sound event detection dataset. However, the online-harvested raw descriptions are highly noisy and unsuitable for direct use in tasks such as automated audio captioning. To overcome this issue, we propose a three-stage processing pipeline for filtering noisy data and generating high-quality captions, where ChatGPT, a large language model, is leveraged to filter and transform raw descriptions automatically. We conduct a comprehensive analysis of the characteristics of WavCaps dataset and evaluate it on multiple downstream audio-language multimodal learning tasks. The systems trained on WavCaps outperform previous state-of-the-art (SOTA) models by a significant margin. Our aspiration is for the WavCaps dataset we have proposed to facilitate research in audio-language multimodal learning and demonstrate the potential of utilizing large language models (LLMs) to enhance academic research.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jun,
pages = {3339–3354},
numpages = {16}
}

@inproceedings{10.1145/3613904.3642414,
author = {Shaer, Orit and Cooper, Angelora and Mokryn, Osnat and Kun, Andrew L and Ben Shoshan, Hagit},
title = {AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642414},
doi = {10.1145/3613904.3642414},
abstract = {The growing availability of generative AI technologies such as large language models (LLMs) has significant implications for creative work. This paper explores twofold aspects of integrating LLMs into the creative process – the divergence stage of idea generation, and the convergence stage of evaluation and selection of ideas. We devised a collaborative group-AI Brainwriting ideation framework, which incorporated an LLM as an enhancement into the group ideation process, and evaluated the idea generation process and the resulted solution space. To assess the potential of using LLMs in the idea evaluation process, we design an evaluation engine and compared it to idea ratings assigned by three expert and six novice evaluators. Our findings suggest that integrating LLM in Brainwriting could enhance both the ideation process and its outcome. We also provide evidence that LLMs can support idea evaluation. We conclude by discussing implications for HCI education and practice.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1050},
numpages = {17},
keywords = {Brainwriting, LLM, human-AI collaboration},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3699538.3699541,
author = {Korpimies, Kai and Laaksonen, Antti and Luukkainen, Matti},
title = {Unrestricted Use of LLMs in a Software Project Course: Student Perceptions on Learning and Impact on Course Performance},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699541},
doi = {10.1145/3699538.3699541},
abstract = {Large language models (LLMs) provide round-the-clock personalized programming assistance, unlike course instructors or traditional online information sources such as Stack Overflow. While LLMs can aid in code generation, concerns about over-reliance and the impact on learning persist. This study discusses students’ experiences with LLMs in a software project course where students were allowed to use LLMs freely except for unit test generation. We conducted surveys during course instances in autumn 2023 and spring 2024. The surveys assessed the extent of LLM usage, methods of application, and perceived impact on learning. Results indicate diverse usage patterns, with many students finding LLMs beneficial for efficiency and problem-solving, though over-reliance and poor-quality outputs were noted concerns. The usage patterns can be linked to course performance and time spent on the project.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {23},
numpages = {7},
keywords = {Large language models, Computer Science Education, User Study, Code generation, Software project},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3701625.3701687,
author = {Sampaio, Savio Sousa and Lima, M\'{a}rcia Sampaio and de Souza, Eriky Rodrigues and Meireles, Maria Alcimar and Pessoa, Marcela Savia and Conte, Tayana Uchoa},
title = {Exploring the Use of Large Language Models in Requirements Engineering Education: An Experience Report with ChatGPT 3.5},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701687},
doi = {10.1145/3701625.3701687},
abstract = {Large Language Models (LLMs) are becoming common in educational settings. This trend presents a challenge for teachers, who must focus on teaching the proper usage of LLMs. In the context of Software Engineering (SE), ChatGPT can support various software development tasks. This work reports an experience with students using ChatGPT 3.5 to support the Requirements Engineering (RE) phase. We conducted a two-phase study with 42 students. First, the students elicited requirements for systems using RE techniques. Then, the students used ChatGPT 3.5 to generate requirements for the same systems. Finally, they compared both sets of requirements based on equivalence, innovation, and relevance. On average, 65.26% of the requirements generated by ChatGPT were considered equivalents to the requirements the students had elicited. However, students reported that ChatGPT generates broad and non-specific requirements. Students also reported that ChatGPT 3.5 can foster the requirements elicitation, but it is necessary to establish well-defined prompts for generating requirements.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {624–634},
numpages = {11},
keywords = {Requirement Elicitation, ChatGPT 3.5, Software engineering education},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3664647.3681339,
author = {Lu, Feihong and Wang, Weiqi and Luo, Yangyifei and Zhu, Ziqin and Sun, Qingyun and Xu, Baixuan and Shi, Haochen and Gao, Shiqi and Li, Qian and Song, Yangqiu and Li, Jianxin},
title = {Miko: Multimodal Intention Knowledge Distillation from Large Language Models for Social-Media Commonsense Discovery},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681339},
doi = {10.1145/3664647.3681339},
abstract = {Social media has become ubiquitous for connecting with others, staying updated with news, expressing opinions, and finding entertainment. However, understanding the intention behind social media posts remains challenging due to the implicit and commonsense nature of these intentions, the need for cross-modality understanding of both text and images, and the presence of noisy information such as hashtags, misspelled words, and complicated abbreviations. To address these challenges, we present MIKO, a Multimodal Intention Knowledge DistillatiOn framework that collaboratively leverages a Large Language Model (LLM) and a Multimodal Large Language Model (MLLM) to uncover users' intentions. Specifically, our approach uses an MLLM to interpret the image, an LLM to extract key information from the text, and another LLM to generate intentions. By applying MIKO to publicly available social media datasets, we construct an intention knowledge base featuring 1,372K intentions rooted in 137,287 posts. Moreover, We conduct a two-stage annotation to verify the quality of the generated knowledge and benchmark the performance of widely used LLMs for intention generation, and further apply MIKO to a sarcasm detection dataset and distill a student model to demonstrate the downstream benefits of applying intention knowledge.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3303–3312},
numpages = {10},
keywords = {intention knowledge distillation, large language model, large vision language model, social media},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@article{10.5555/3715602.3715612,
author = {Crandall, Johannah L. and Crandall, Aaron S.},
title = {Large Language Model-Supported Software Testing with the CS Matrix Taxonomy},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {New breakthroughs in code synthesis from Generative Pre-Trained Transformers (GPT) and Large Language Model (LLM) algorithms are driving significant changes to software engineering education. Having algorithms able to generate components of a software project means that software developers will need stronger skills in requirements specification to guide code generation as well as stronger skills in code review, testing, and integration to incorporate AI-generated code into projects. Shifts in industry and classroom practices are already occurring with the availability of inline code generation tools like GitHub's Copilot, which makes discussion of pedagogical strategies in this area a timely topic. Of immediate concern in computer science education is the potential for LLM-generated code and code help to undermine the learning of CS students. In order to avoid such undermining in even intentional uses of LLM-enhanced learning supports, it is necessary to clarify the roles such supports need to play in the pedagogical process. The Computer Science Matrix Taxonomy provides a strong framework for organizing software testing learning outcomes as well as delineating the operational space in which LLM-based feedback tools should operate to support those learning outcomes. In this paper, the authors operationalize the CS Matrix Taxonomy for software testing learning outcomes and illustrate the integration of LLM-generated test strategy suggestions as an extension of the peer coding/testing model. The work includes examples of AI-generated code testing suggestions that students would use to help guide their own code synthesis for assignments or projects.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {49–58},
numpages = {10}
}

@article{10.1145/3715007,
author = {Chen, Xiang and Gao, Chaoyang and Chen, Chunyang and Zhang, Guangbei and Liu, Yong},
title = {An Empirical Study on Challenges for LLM Application Developers},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715007},
doi = {10.1145/3715007},
abstract = {In recent years, large language models (LLMs) have seen rapid advancements, significantly impacting various fields such as computer vision, natural language processing, and software engineering. These LLMs, exemplified by OpenAI’s ChatGPT, have revolutionized the way we approach language understanding and generation tasks. However, in contrast to traditional software development practices, LLM development introduces new challenges for AI developers in design, implementation, and deployment. These challenges span different areas (such as prompts, APIs, and plugins), requiring developers to navigate unique methodologies and considerations specific to LLM application development.Despite the profound influence of LLMs, to the best of our knowledge, these challenges have not been thoroughly investigated in previous empirical studies. To fill this gap, we present the first comprehensive study on understanding the challenges faced by LLM developers. Specifically, we crawl and analyze 29,057 relevant questions from a popular OpenAI developer forum. We first examine their popularity and difficulty. After manually analyzing 2,364 sampled questions, we construct a taxonomy of challenges faced by LLM developers. Based on this taxonomy, we summarize a set of findings and actionable implications for LLM-related stakeholders, including developers and providers (especially the OpenAI organization).},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {Mining Software Repository, Empirical Study, LLM Developer, Development Challenges, Prompt Engineering}
}

@inproceedings{10.1145/3678717.3695759,
author = {Nie, Ying and Gao, Song},
title = {ChatGPT for Intelligent Spatial Analysis Workflow Construction},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678717.3695759},
doi = {10.1145/3678717.3695759},
abstract = {The capability of constructing executable scientific workflows that integrate data, models, and domain-specific knowledge using AI tools remains quite limited. This study utilizes large language model (LLM)-powered chatbots such as ChatGPT to streamline the process of automating spatial analysis workflow construction. By exploring prompt engineering techniques in ChatGPT, we aim to generate scientific workflows that address spatial analysis problems using ArcGIS geoprocessing tools. We identify key challenges and propose strategies involving geo-knowledge and structured prompts to enhance GIS workflow generation. Our preliminary results show that the accuracy and effectiveness of ChatGPT-generated GIS workflow are improved by adopting these strategies.},
booktitle = {Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
pages = {713–714},
numpages = {2},
keywords = {GeoAI, large language model, spatial analysis},
location = {Atlanta, GA, USA},
series = {SIGSPATIAL '24}
}

@inproceedings{10.1145/3706599.3720027,
author = {Schirra, Steven and Volkov, Sasha G and Bentley, Frank},
title = {"It's Something to Polish Your Own Thoughts, Rather than Create Thoughts for You": Understanding Participants' Use of Chatbots and LLMs During Online Research Participation},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720027},
doi = {10.1145/3706599.3720027},
abstract = {There are growing discussions within the research community about how to adapt study design given the widespread availability of Generative Artificial Intelligence (GenAI), including Large Language Models (LLMs). While much prior research has focused on LLM use from a researcher perspective (e.g. detecting and screening for LLM use) we present a complementary study from the perspective of participants who use LLMs during their research participation. In this exploratory interview study with 17 participants, we found a range of LLM use cases, from sourcing studies, to generating or modifying responses, to asking clarification questions about studies. We also explored participants’ ethical considerations, finding that participants considered researchers’ needs for authentic data when setting ethical boundaries. Participants also discussed how attempts to thwart their LLM use have negatively impacted their everyday participant experience. We propose a set of recommendations that researchers can incorporate into their studies to proactively address participant LLM use.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {20},
numpages = {6},
keywords = {participant experience, LLMs, GenAI, data quality, participant ethics, chatbots},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3643795.3648380,
author = {S Kumar, Smitha and Adam Lones, Michael and Maarek, Manuel and Zantout, Hind},
title = {Investigating the Proficiency of Large Language Models in Formative Feedback Generation for Student Programmers},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648380},
doi = {10.1145/3643795.3648380},
abstract = {Generative AI has considerably altered traditional workplace practice across numerous industries. Ever since the emergence of large language models (LLMs), their potential to generate formative feedback for introductory programming courses has been extensively researched. However, most of these studies have focused on Python. In this work, we examine the bug-fixing and feedback-generation abilities of Code Llama and ChatGPT for Java programming assignments using our new Java benchmark called CodeWBugs. The results indicate that ChatGPT performs reasonably well, and was able to fix 94.33% programs. By comparison, we observed high variability in the results from Code Llama. We further analyzed the impact of different types of prompts and observed that prompts that included task descriptions and test inputs yielded better results. In most cases, the LLMs precisely localized the bugs and also offered guidance on how to proceed. Nevertheless, we also noticed incorrect responses generated by the LLMs, emphasizing the need to validate responses before disseminating feedback to learners.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {88–93},
numpages = {6},
keywords = {large language models (LLM), GPT-4, feedback, java programming, program repair},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3584371.3613016,
author = {Oduro-Afriyie, Joel and Jamil, Hasan M},
title = {Enabling the Informed Patient Paradigm with Secure and Personalized Medical Question Answering},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3613016},
doi = {10.1145/3584371.3613016},
abstract = {Quality patient care is a complex and multifaceted problem requiring the integration of data from multiple sources. We propose Medicient, a knowledge-graph-based question answering system that processes heterogeneous data sources, including patient health records, drug databases, and medical literature, into a unified knowledge graph with zero training. The knowledge graph is then utilized to provide personalized recommendations for treatment or medication. The system leverages the power of large language models for question understanding and natural language response generation, while hiding sensitive patient information. We compare our system to a large language model (ChatGPT), which does not have access to patient health records, and show that our system provides better recommendations. This study contributes to a growing body of research on knowledge graphs and their applications in healthcare.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {33},
numpages = {6},
keywords = {informed patients, personal health library, data integration, semantic graph search, large language models, knowledge graphs},
location = {Houston, TX, USA},
series = {BCB '23}
}

@article{10.1145/3579592,
author = {Karinshak, Elise and Liu, Sunny Xun and Park, Joon Sung and Hancock, Jeffrey T.},
title = {Working With AI to Persuade: Examining a Large Language Model's Ability to Generate Pro-Vaccination Messages},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW1},
url = {https://doi.org/10.1145/3579592},
doi = {10.1145/3579592},
abstract = {Artificial Intelligence (AI) is a transformative force in communication and messaging strategy, with potential to disrupt traditional approaches. Large language models (LLMs), a form of AI, are capable of generating high-quality, humanlike text. We investigate the persuasive quality of AI-generated messages to understand how AI could impact public health messaging. Specifically, through a series of studies designed to characterize and evaluate generative AI in developing public health messages, we analyze COVID-19 pro-vaccination messages generated by GPT-3, a state-of-the-art instantiation of a large language model. Study 1 is a systematic evaluation of GPT-3's ability to generate pro-vaccination messages. Study 2 then observed peoples' perceptions of curated GPT-3-generated messages compared to human-authored messages released by the CDC (Centers for Disease Control and Prevention), finding that GPT-3 messages were perceived as more effective, stronger arguments, and evoked more positive attitudes than CDC messages. Finally, Study 3 assessed the role of source labels on perceived quality, finding that while participants preferred AI-generated messages, they expressed dispreference for messages that were labeled as AI-generated. The results suggest that, with human supervision, AI can be used to create effective public health messages, but that individuals prefer their public health messages to come from human institutions rather than AI sources. We propose best practices for assessing generative outputs of large language models in future social science research and ways health professionals can use AI systems to augment public health messaging.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {116},
numpages = {29},
keywords = {AI-mediated communication, large language models, message factors, natural language processing, persuasion, public health messaging}
}

@inproceedings{10.1145/3613904.3641965,
author = {Calle, Paul and Shao, Ruosi and Liu, Yunlong and H\'{e}bert, Emily T and Kendzor, Darla and Neil, Jordan and Businelle, Michael and Pan, Chongle},
title = {Towards AI-Driven Healthcare: Systematic Optimization, Linguistic Analysis, and Clinicians’ Evaluation of Large Language Models for Smoking Cessation Interventions},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641965},
doi = {10.1145/3613904.3641965},
abstract = {Creating intervention messages for smoking cessation is a labor-intensive process. Advances in Large Language Models (LLMs) offer a promising alternative for automated message generation. Two critical questions remain: 1) How to optimize LLMs to mimic human expert writing, and 2) Do LLM-generated messages meet clinical standards? We systematically examined the message generation and evaluation processes through three studies investigating prompt engineering (Study 1), decoding optimization (Study 2), and expert review (Study 3). We employed computational linguistic analysis in LLM assessment and established a comprehensive evaluation framework, incorporating automated metrics, linguistic attributes, and expert evaluations. Certified tobacco treatment specialists assessed the quality, accuracy, credibility, and persuasiveness of LLM-generated messages, using expert-written messages as the benchmark. Results indicate that larger LLMs, including ChatGPT, OPT-13B, and OPT-30B, can effectively emulate expert writing to generate well-written, accurate, and persuasive messages, thereby demonstrating the capability of LLMs in augmenting clinical practices of smoking cessation interventions.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {436},
numpages = {16},
keywords = {Computational Linguistic Analysis, Expert Review, Large Language Model, Message Generation, Smoking Cessation Intervention},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3706599.3721349,
author = {Lee, Chaeyeon and Lee, Chungnyeong and Kim, Sangyong and Choi, Yongsoon and Kim, Jusub},
title = {StorageChat Timeline: A Generative AI-Based Art Appreciation System for Enhancing Immersion and Exploratory Experience},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3721349},
doi = {10.1145/3706599.3721349},
abstract = {This video showcases StorageChat Timeline, an AI-powered system utilizing a Large Language Model (LLM) and generative AI technologies (e.g., style transfer, image-to-video) for art appreciation education. By offering real-time interactive question-and-answer experiences, the system enables users to construct the meaning of artworks based on their knowledge and experiences. It also provides immersive generative animations reflecting the artworks’ styles and multimodal features, including text-to-speech and dynamic visuals, to enhance emotional engagement. Through this design, the system aims to enhance immersion, learning motivation, and visual literacy, fostering active participation in art appreciation. This innovative approach enhances accessibility to art and proposes a generative AI-driven methodology for art education. The video demonstrates how the system’s key features—AI conversational interface, immersive animations, and multimodal integration—create an engaging and visually interactive experience, showcasing its potential to transform art appreciation.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {921},
numpages = {2},
keywords = {Generative AI, Large Language Models (LLM), Museum Education, Immersive Learning},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3672608.3707735,
author = {Mazzullo, Elisabetta and Bulut, Okan and Walsh, Cole and Sitarenios, Gill and MacIntosh, Alexander},
title = {Fine-Tuning GPT-3.5-Turbo for Automatic Feedback Generation},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707735},
doi = {10.1145/3672608.3707735},
abstract = {Scaling up the delivery of effective feedback remains an open challenge in education. Existing automatic feedback generation (AFG) methods fall short in providing feedback highly tailored to tasks, students, and instructors' preferences, simultaneously. Recent evidence suggests that Large Language Models (LLMs), with their ability to follow instructions and generate text, could address this limitation. Existing studies have generated feedback using GPT models in their ready-to-use Chat version, using almost exclusively prompting strategies to direct the model towards the desired output. Results are largely positive; however, space for improvement remains. For the first time, the present study reports observations and results from fine-tuning GPT-3.5-turbo for AFG for open-ended situational judgment questions from the high-stakes test Casper. The LLM was fine-tuned using a small set of hand-written feedback examples, and independent judges and text experts evaluated model performance using a rubric based on qualities of effective feedback identified in the literature. Moreover, a survey study measured users' satisfaction with automatic feedback. Results show that, although not perfect, the fine-tuned model generated outputs largely aligned with the desired qualities and often aligned with the given guidelines, satisfying the majority of users. The strengths and weaknesses of our model are discussed, and directions for future research are suggested.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {40–47},
numpages = {8},
keywords = {large language models, feedback, fine-tuning},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3688866.3696056,
author = {Xu, Shihao and Luo, Yiyang and Dauwels, Justin and Khong, Andy and Wang, Zheng and Chen, Qianqian and Cai, Chen and Shi, Wei and Chua, Tat-Seng},
title = {LGM3A '24: the 2nd Workshop on Large Generative Models Meet Multimodal Applications},
year = {2024},
isbn = {9798400711930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3688866.3696056},
doi = {10.1145/3688866.3696056},
abstract = {This workshop aims to explore the potential of large generative models to revolutionize how we interact with multimodal information. A Large Language Model (LLM) represents a sophisticated form of artificial intelligence engineered to comprehend and produce natural language text, exemplified by technologies such as GPT, LLaMA, Flan-T5, ChatGLM, Qwen, etc. These models undergo training on extensive text datasets, exhibiting commendable attributes including robust language generation, zero-shot transfer capabilities, and In-Context Learning (ICL). With the surge in multimodal content-encompassing images, videos, audio, and 3D models-over the recent period, Large MultiModal Models (LMMs) have seen significant enhancements. These improvements enable the augmentation of conventional LLMs to accommodate multimodal inputs or outputs, as seen in BLIP, Flamingo, KOSMOS, LLaVA, Gemini, GPT-4, etc. Concurrently, certain research initiatives have developed specific modalities, with Kosmos2 and MiniGPT-5 focusing on image generation, and SpeechGPT on speech production. There are also endeavors to integrate LLMs with external tools to achieve a near "any-to-any" multimodal comprehension and generation capacity, illustrated by projects like Visual-ChatGPT, ViperGPT, MMREACT, HuggingGPT, and AudioGPT. Collectively,these models, spanning not only text and image generation but also other modalities, are referred to as large generative models. This workshop will allow researchers, practitioners, and industry professionals to explore the latest trends and best practices in the multimodal applications of large generative models.},
booktitle = {Proceedings of the 2nd Workshop on Large Generative Models Meet Multimodal Applications},
pages = {1–3},
numpages = {3},
keywords = {generative models, large language models, multimodal applications},
location = {Melbourne VIC, Australia},
series = {LGM3A '24}
}

@inproceedings{10.1145/3701716.3716886,
author = {Goswami, Kanika and Mathur, Puneet and Rossi, Ryan and Dernoncourt, Franck},
title = {ChartCitor: Answer Citations for ChartQA via Multi-Agent LLM Retrieval},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3716886},
doi = {10.1145/3701716.3716886},
abstract = {Large Language Models (LLMs) can perform chart question answering tasks but often generate unverified hallucinated responses. Existing answer attribution methods struggle to ground responses in source charts due to limited visual-semantic context, complex visual-text alignment requirements, and difficulties in bounding box prediction across complex layouts. We present ChartCitor, a multi-agent framework that provides fine-grained bounding box citations by identifying supporting evidence within chart images. The system orchestrates LLM agents to perform chart-to-table extraction, answer reformulation, table augmentation, evidence retrieval through pre-filtering and re-ranking, and table-to-chart mapping. ChartCitor outperforms existing baselines across different chart types. Qualitative user studies show that ChartCitor helps increase user trust in Generative AI by providing enhanced explainability for LLM-assisted chart QA and enables professionals to be more productive.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1668–1671},
numpages = {4},
keywords = {information extraction, llm agents, multimodal retrieval, visual fact checking},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3691620.3695529,
author = {Yang, Lin and Yang, Chen and Gao, Shutao and Wang, Weijing and Wang, Bo and Zhu, Qihao and Chu, Xiao and Zhou, Jianyi and Liang, Guangtai and Wang, Qianxiang and Chen, Junjie},
title = {On the Evaluation of Large Language Models in Unit Test Generation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695529},
doi = {10.1145/3691620.3695529},
abstract = {Unit testing is an essential activity in software development for verifying the correctness of software components. However, manually writing unit tests is challenging and time-consuming. The emergence of Large Language Models (LLMs) offers a new direction for automating unit test generation. Existing research primarily focuses on closed-source LLMs (e.g., ChatGPT and CodeX) with fixed prompting strategies, leaving the capabilities of advanced open-source LLMs with various prompting settings unexplored. Particularly, open-source LLMs offer advantages in data privacy protection and have demonstrated superior performance in some tasks. Moreover, effective prompting is crucial for maximizing LLMs' capabilities. In this paper, we conduct the first empirical study to fill this gap, based on 17 Java projects, five widely-used open-source LLMs with different structures and parameter sizes, and comprehensive evaluation metrics. Our findings highlight the significant influence of various prompt factors, show the performance of open-source LLMs compared to the commercial GPT-4 and the traditional Evosuite, and identify limitations in LLM-based unit test generation. We then derive a series of implications from our study to guide future research and practical use of LLM-based unit test generation.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1607–1619},
numpages = {13},
keywords = {large language model, unit test generation, empirical study},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3626253.3635609,
author = {Mitra, Chancharik and Miroyan, Mihran and Jain, Rishi and Kumud, Vedant and Ranade, Gireeja and Norouzi, Narges},
title = {Elevating Learning Experiences: Leveraging Large Language Models as Student-Facing Assistants in Discussion Forums},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635609},
doi = {10.1145/3626253.3635609},
abstract = {Recent advancements in instruction-tuned large language models offer new potential for enhancing students' experiences in large-scale classes. Deploying LLMs as student-facing assistants, however, presents challenges. Key issues include integrating class-specific content into responses and applying effective pedagogical techniques. This study addresses these challenges through retrieval and prompting techniques, focusing on mitigating hallucinations in LLM-generated responses, a crucial concern in education. Furthermore, practical deployment brings further challenges related to student data privacy and computational constraints. This research strives to enhance the quality and relevance of LLM responses while addressing practical deployment issues, with an emphasis on creating a versatile system for diverse domains and teaching styles.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1752–1753},
numpages = {2},
keywords = {discussion forum, educational tools, natural language processing},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3691620.3695330,
author = {Ouedraogo, Wendkuuni C. and Kabore, Kader and Tian, Haoye and Song, Yewei and Koyuncu, Anil and Klein, Jacques and Lo, David and Bissyande, Tegawende F.},
title = {LLMs and Prompting for Unit Test Generation: A Large-Scale Evaluation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695330},
doi = {10.1145/3691620.3695330},
abstract = {Unit testing, essential for identifying bugs, is often neglected due to time constraints. Automated test generation tools exist but typically lack readability and require developer intervention. Large Language Models (LLMs) like GPT and Mistral show potential in test generation, but their effectiveness remains unclear.This study evaluates four LLMs and five prompt engineering techniques, analyzing 216 300 tests for 690 Java classes from diverse datasets. We assess correctness, readability, coverage, and bug detection, comparing LLM-generated tests to EvoSuite. While LLMs show promise, improvements in correctness are needed. The study highlights both the strengths and limitations of LLMs, offering insights for future research.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2464–2465},
numpages = {2},
keywords = {automatic test generation, unit tests, large language models, prompt engineering, empirical evaluation},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3627673.3679830,
author = {Pan, Bo and Zhang, Zheng and Zhang, Yifei and Hu, Yuntong and Zhao, Liang},
title = {Distilling Large Language Models for Text-Attributed Graph Learning},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679830},
doi = {10.1145/3627673.3679830},
abstract = {Text-Attributed Graphs (TAGs) are graphs of connected textual documents. Graph models can efficiently learn TAGs, but their training heavily relies on human-annotated labels, which are scarce or even unavailable in many applications. Large language models (LLMs) have recently demonstrated remarkable capabilities in few-shot and zero-shot TAG learning, but they suffer from scalability, cost, and privacy issues. Therefore, in this work, we focus on synergizing LLMs and graph models with their complementary strengths by distilling the power of LLMs into a local graph model on TAG learning. To address the inherent gaps between LLMs (generative models for texts) and graph models (discriminative models for graphs), we propose first to let LLMs teach an interpreter with rich rationale and then let a student model mimic the interpreter's reasoning without LLMs' rationale. We convert LLM's textual rationales to multi-level graph rationales to train the interpreter model and align the student model with the interpreter model based on the features of TAGs. Extensive experiments validate the efficacy of our proposed framework.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {1836–1845},
numpages = {10},
keywords = {knowledge distillation, large language models, text-attributed graphs},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3716640.3716647,
author = {Leinonen, Juho and Denny, Paul and Kiljunen, Olli and MacNeil, Stephen and Sarsa, Sami and Hellas, Arto},
title = {LLM-itation is the Sincerest Form of Data: Generating Synthetic Buggy Code Submissions for Computing Education},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716647},
doi = {10.1145/3716640.3716647},
abstract = {There is a great need for data in computing education research. Data is needed to understand how students behave, to train models of student behavior to optimally support students, and to develop and validate new assessment tools and learning analytics techniques. However, relatively few computing education datasets are shared openly, often due to privacy regulations and issues in making sure the data is anonymous. Large language models (LLMs) offer a promising approach to create large-scale, privacy-preserving synthetic data, which can be used to explore various aspects of student learning, develop and test educational technologies, and support research in areas where collecting real student data may be challenging or impractical. This work explores generating synthetic buggy code submissions for introductory programming exercises using GPT-4o. We compare the distribution of test case failures between synthetic and real student data from two courses to analyze the accuracy of the synthetic data in mimicking real student data. Our findings suggest that LLMs can be used to generate synthetic incorrect submissions that are not significantly different from real student data with regard to test case failure distributions. Our research contributes to the development of reliable synthetic datasets for computing education research and teaching, potentially accelerating progress in the field while preserving student privacy.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {56–63},
numpages = {8},
keywords = {generative AI, genAI, large language models, LLMs, GPT-4o, prompt engineering, synthetic data, bugs, submissions, data generation},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3706598.3714238,
author = {Ge, Yate and Li, Meiying and Huang, Xipeng and Hu, Yuanda and Wang, Qi and Sun, Xiaohua and Guo, Weiwei},
title = {GenComUI: Exploring Generative Visual Aids as Medium to Support Task-Oriented Human-Robot Communication},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714238},
doi = {10.1145/3706598.3714238},
abstract = {This work investigates the integration of generative visual aids in human-robot task communication. We developed GenComUI, a system powered by large language models (LLMs) that dynamically generates contextual visual aids—such as map annotations, path indicators, and animations—to support verbal task communication and facilitate the generation of customized task programs for the robot. This system was informed by a formative study that examined how humans use external visual tools to assist verbal communication in spatial tasks. To evaluate its effectiveness, we conducted a user experiment (n = 20) comparing GenComUI with a voice-only baseline. The results demonstrate that generative visual aids, through both qualitative and quantitative analysis, enhance verbal task communication by providing continuous visual feedback, thus promoting natural and effective human-robot communication. Additionally, the study offers a set of design implications, emphasizing how dynamically generated visual aids can serve as an effective communication medium in human-robot interaction. These findings underscore the potential of generative visual aids to inform the design of more intuitive and effective human-robot communication, particularly for complex communication scenarios in human-robot interaction and LLM-based end-user development.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {433},
numpages = {21},
keywords = {Human-Robot Interaction, Robot Programming, Service Robots, Conversational Interaction, Large Language Models, Generative UI},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3674399.3674402,
author = {Luo, Xiaoyu and Liu, Daping and Dang, Fan and Luo, Hanjiang},
title = {Integration of LLMs and the Physical World: Research and Application},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674399.3674402},
doi = {10.1145/3674399.3674402},
abstract = {The emergence of large language models (LLMs) offers a new opportunity to build LLMs-based applications, such as smart home, as these models have demonstrated general-purpose language understanding by generating coherent and contextually relevant text. However, LLMs are trained on massive amounts of text data to predict tokens, so these models have limitations and it is difficult for them performing physical world tasks directly. To further exploit the potential of LLMs to solve the challenge of integrating them with the physical world, LLMs enhanced and augmented techniques should be addressed, especially reinforcement learning based techniques. In this paper, we study the issue of integrating LLMs with physical world. We first describe the large language models and limitations. Then, we revisit LLMs enhanced and augmented techniques. After that, we present methods of interaction LLMs with physical world, such as integration IoT sensing with LLMs, embodied agent post-training with LLMs, and robot task planning with LLMs. Finally, we provide a case study of smart home powered by LLMs to discuss future research directions of next-generation intelligent smart home, personal health assistant, and LLM-based household robot.},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2024},
pages = {1–5},
numpages = {5},
keywords = {Internet of Things, LLM-based Agent, Large Language Model, Smart Home},
location = {Changsha, China},
series = {ACM-TURC '24}
}

@inproceedings{10.1145/3696410.3714632,
author = {Mai, Wuyuao and Hong, Geng and Chen, Pei and Pan, Xudong and Liu, Baojun and Zhang, Yuan and Duan, Haixin and Yang, Min},
title = {You Can't Eat Your Cake and Have It Too: The Performance Degradation of LLMs with Jailbreak Defense},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714632},
doi = {10.1145/3696410.3714632},
abstract = {With the rise of generative large language models (LLMs) like LLaMA and ChatGPT, these models have significantly transformed daily life and work by providing advanced insights. However, as jailbreak attacks continue to circumvent built-in safety mechanisms, exploiting carefully crafted scenarios or tokens, the safety risks of LLMs have come into focus. While numerous defense strategies-such as prompt detection, modification, and model fine-tuning-have been proposed to counter these attacks, a critical question arises: do these defenses compromise the utility and usability of LLMs for legitimate users? Existing research predominantly focuses on the effectiveness of defense strategies without thoroughly examining their impact on performance, leaving a gap in understanding the trade-offs between LLM safety and performance.Our research addresses this gap by conducting a comprehensive study on the utility degradation, safety elevation, and exaggerated-safety escalation of LLMs with jailbreak defense strategies. We propose USEBench, a novel benchmark designed to evaluate these aspects, along with USEIndex, a comprehensive metric for assessing overall model performance. Through experiments on seven state-of-the-art LLMs, we found that mainstream jailbreak defenses fail to ensure both safety and performance simultaneously. Although model-finetuning performs the best overall, their effectiveness varies across LLMs. Furthermore, vertical comparisons reveal that developers commonly prioritize performance over safety when iterating or fine-tuning their LLMs.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {872–883},
numpages = {12},
keywords = {LLM benchmark, LLM jailbreak, LLM performance downgrade, jailbreak evaluation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3701716.3715570,
author = {Lian, Zhaorui and Geng, Binzong and Chang, Xiyu and Zhang, Yu and Ding, Ke and Lyu, Ziyu and Yuan, Guanghu and Li, Chengming and Yang, Min and Huan, Zhaoxin and Shen, Bin and He, Yong and Mo, Linjian and Zhang, Liang and Zhu, Xing},
title = {EGRec: Leveraging Generative Rich Intents for Enhanced Recommendation with Large Language Models},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715570},
doi = {10.1145/3701716.3715570},
abstract = {Recent advancements in Large Language Models (LLMs) leverage their extensive knowledge and reasoning to reduce semantic information loss in traditional Click-Through Rate (CTR) tasks. However, existing methods often neglect rich intent utilization, limiting the generative capabilities of LLMs. To address this, we propose an &lt;u&gt;E&lt;/u&gt;nd-to-End &lt;u&gt;G&lt;/u&gt;enerative framework for learning rich &lt;u&gt;Rec&lt;/u&gt;ommendation intents with LLMs, termed EGRec. EGRec employs a joint training paradigm for LLMs and CTR models, where LLMs generate rich user intents that are integrated into CTR models to enhance recommendation accuracy. By combining LLMs' semantic understanding with CTR models' predictive analytics, EGRec improves overall recommendation performance. Extensive experiments on the Amazon-Book dataset and proprietary Industrial-Ads data demonstrate EGRec's superiority over robust baseline methods.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1113–1117},
numpages = {5},
keywords = {generative modeling, large language models, recommender systems},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3657054.3657128,
author = {Tsai, Chun-Hua and Nandy, Gargi and House, Deanna and Carroll, John},
title = {Ensuring Transparency in Using ChatGPT for Public Sentiment Analysis},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657128},
doi = {10.1145/3657054.3657128},
abstract = {The advancement of generative AI, involving the utilization of large language models (LLMs) like ChatGPT to assess public opinion and sentiment, has become increasingly prevalent. However, this upsurge in usage raises significant questions about the transparency and interpretability of the predictions made by these LLM Models. Hence, this paper explores the imperative of ensuring transparency in the application of ChatGPT for public sentiment analysis. To tackle these challenges, we propose using a lexicon-based model as a surrogate to approximate both global and local predictions. Through case studies, we demonstrate how transparency mechanisms, bolstered by the lexicon-based model, can be seamlessly integrated into ChatGPT’s deployment for sentiment analysis. Drawing on the results of our study, we further discuss the implications for future research involving the utilization of LLMs in governmental functions, policymaking, and public engagement.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {627–636},
numpages = {10},
keywords = {AI Ethics and Governance, CDC, COVID, Civic Engagement},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

@inproceedings{10.1145/3708557.3716160,
author = {Dinakar, Karthik and Lieberman, Henry and Wu, Meng-Hsin},
title = {MIND (Mixed-Initiative Next-gen Design): Workshop on Blending Agents and Direct Manipulation for Harnessing LLMs},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716160},
doi = {10.1145/3708557.3716160},
abstract = {Since the 1980s, a key debate in human-centered computing involving machine learning at IUI is between agent-driven systems and direct manipulation. The explosion of Large Language Models (LLMs), particularly auto-regressive as agents serving as chatbots, generative search, and work automation tools, has also brought with it inherent limitations. We posit that efforts to address and alleviate these LLM challenges—hallucinations, unpredictable outputs, lack of transparency, and difficulties in customization—cannot be solved through algorithmic improvements alone but require elevated mixed-initiative interface design at the heart of the IUI community. This workshop aims to bridge the gap between agent-driven automation and direct manipulation by exploring mixed-initiative interaction models that blend the strengths of both paradigms to empower end-users seeking to harness LLMs.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {187–188},
numpages = {2},
keywords = {Direct manipulation, Agents, Human-Centered Design, Mixed-Initiative Interfaces},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3716640.3716657,
author = {Arora, Utkarsh and Garg, Anupam and Gupta, Aryan and Jain, Samyak and Mehta, Ronit and Oberoi, Rupin and Prachi and Raina, Aryaman and Saini, Manav and Sharma, Sachin and Singh, Jaskaran and Tyagi, Sarthak and Kumar, Dhruv},
title = {Analyzing LLM Usage in an Advanced Computing Class in India},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716657},
doi = {10.1145/3716640.3716657},
abstract = {This study examines the use of large language models (LLMs) by undergraduate and graduate students for programming assignments in advanced computing classes. Unlike existing research, which primarily focuses on introductory classes and lacks in-depth analysis of actual student-LLM interactions, our work fills this gap. We conducted a comprehensive analysis involving 411 students from a Distributed Systems class at an Indian university, where they completed three programming assignments and shared their experiences through Google Form surveys and interviews.Our findings reveal that students leveraged LLMs for a variety of tasks, including code generation, debugging, conceptual inquiries, and test case creation. They employed a spectrum of prompting strategies, ranging from basic contextual prompts to advanced techniques like chain-of-thought prompting and iterative refinement. While students generally viewed LLMs as beneficial for enhancing productivity and learning, we noted a concerning trend of over-reliance, with many students submitting entire assignment descriptions to obtain complete solutions. Given the increasing use of LLMs in the software industry, our study highlights the need to update undergraduate curricula to include training on effective prompting strategies and to raise awareness about the benefits and potential drawbacks of LLM usage in academic settings.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {154–163},
numpages = {10},
keywords = {Large Language Models, Computing Education, User Study},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3716640.3716651,
author = {Qiao, Shuying and Denny, Paul and Giacaman, Nasser},
title = {Oversight in Action: Experiences with Instructor-Moderated LLM Responses in an Online Discussion Forum},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716651},
doi = {10.1145/3716640.3716651},
abstract = {The integration of large language models (LLMs) into computing education offers many potential benefits to student learning, and several novel pedagogical approaches have been reported in the literature. However LLMs also present challenges, one of the most commonly cited being that of student over-reliance. This challenge is compounded by the fact that LLMs are always available to provide instant help and solutions to students, which can undermine their ability to independently solve problems and diagnose and resolve errors. Providing instructor oversight of LLM-generated content can mitigate this problem, however it is often not practical in real-time learning contexts. Online class discussion forums, which are widely used in computing education, present an opportunity for exploring instructor oversight because they operate asynchronously. Unlike real-time interactions, the discussion forum format aligns with the expectation that responses may take time, making oversight not only feasible but also pedagogically appropriate. In this practitioner paper, we present the design, deployment, and evaluation of a ‘bot’ module that is controlled by the instructor, and integrated into an online discussion forum. The bot assists the instructor by generating draft responses to student questions, which are reviewed, modified, and approved before release. Key features include the ability to leverage course materials, access archived discussions, and publish responses anonymously to encourage open participation. We report our experiences using this tool in a 12-week second-year software engineering course on object-oriented programming. Instructor feedback confirmed the tool successfully alleviated workload but highlighted a need for improvement in handling complex, context-dependent queries. We report the features that were viewed as most beneficial, and suggest avenues for future exploration.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {95–104},
numpages = {10},
keywords = {Large language models, LLMs, discussion forums, instructor-in-the-loop, software engineering education, chatbots, computing education},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3706598.3713146,
author = {Qin, Peinuan and Yang, Chi-Lan and Li, Jingshu and Wen, Jing and Lee, Yi-Chieh},
title = {Timing Matters: How Using LLMs at Different Timings Influences Writers' Perceptions and Ideation Outcomes in AI-Assisted Ideation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713146},
doi = {10.1145/3706598.3713146},
abstract = {Large Language Models (LLMs) have been widely used to support ideation in the writing process. However, whether generating ideas with the help of LLMs leads to idea fixation or idea expansion is unclear. This study examines how different timings of LLM usage - either at the beginning or after independent ideation - affect people’s perceptions and ideation outcomes in a writing task. In a controlled experiment with 60 participants, we found that using LLMs from the beginning reduced the number of original ideas and lowered creative self-efficacy and self-credit, mediated by changes in autonomy and ownership. We discuss the challenges and opportunities associated with using LLMs to assist in idea generation. We propose delaying the use of LLMs to support ideation while considering users’ self-efficacy, autonomy, and ownership of the ideation outcomes.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {25},
numpages = {16},
keywords = {AI-assisted ideation, AI timing effect, Idea fixation, Autonomy, Creative self-efficacy},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641555.3704749,
author = {Hare, Brian K. and Gladbach, Joan and Shah, S. Jawad and Xu, Dianxiang},
title = {Building AI-Powered Responsible Workforce by Integrating Large Language Models into Computer Science Curriculum},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704749},
doi = {10.1145/3641555.3704749},
abstract = {Software development is undergoing a revolutionary transformation, fueled by remarkable advancements in Large Language Models (LLMs). This wave of innovation is reshaping the entire landscape and holds the promise of streamlining the development process, leading to increased productivity and efficiency. By providing text prompts, developers can now receive entirely generated code outputs, representing a fundamental shift in how software is built. This paradigm change can accelerate development cycles and unlock new levels of creativity and ingenuity, resulting in the realization of novel applications and business outcomes. However, this paradigm shift also brings new challenges and necessitates acquiring additional skills for software developers to fully harness the capabilities of LLM-powered tools. These skills include prompt engineering for software development, structural complexity management, debugging of AI errors, and compliance with ethical guidelines and principles.The special session will introduce our NSF-sponsored 3-year project, which aims to integrate LLMs into the standard CS curriculum. To the best of our knowledge, this project is among the first department-level initiatives to renovate CS curriculum, rather than individual courses, with the new developments of LLMs. Our project focuses on (a) enhancing students' problem-solving and programming skills by leveraging LLMs as a learning tool in core programming courses, (b) improving students' software development skills by integrating LLM-powered tools into the software engineering course sequence, and (c) educating students on ethical and responsible AI practices. The special session will discuss the objectives and methods of our project, as well as the current results and lessons learned.This NSF-supported project aims to integrate LLMs into the standard CS curriculum. The revolutionized computer science education will cultivate a new generation of AI-powered responsible developers. The objectives are to enhance student programming, software development, and problem-solving skills; educate students on ethical and responsible AI practices; and develop faculty development materials and workshops. Our presentation will discuss the objectives and methods of our project, currently in year 1 of a 3-year timeline.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1709–1710},
numpages = {2},
keywords = {AI, curriculum development, large language models, undergraduate education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.5555/3709347.3744082,
author = {Hedi, Tebourbi and Nouzri, Sana and Mualla, Yazan and Najjar, Amro},
title = {Personalized Language Learning: A Multi-Agent System Leveraging LLMs for Teaching Luxembourgish.},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {The integration of Artificial Intelligence (AI) into education is transforming language learning. Current chatbot-based tools primarily focus on vocabulary acquisition and conversation, overlooking the holistic needs of effective language learning, such as grammar, reading, and listening skills. These limitations are further compounded by the challenges of low-resource languages like Luxembourgish. This demonstration https://www.youtube.com/watch?v=5bxVHsuK-Hs presents a Multi-Agent System (MAS) powered by Large Language Models (LLMs), integrated with Retrieval-Augmented Generation (RAG) to address these challenges. Our system personalizes learning by employing specialized agents for specialized tasks, ensuring a comprehensive and adaptive experience. To mitigate inaccuracies, human-on-the-loop (here teacher) validation enhances content quality and aligns with pedagogical standards inspired by the National Institute of Languages of Luxembourg (INL). Attendees will experience interactive demonstrations showcasing how the system delivers tailored educational experiences through innovative agent workflows and user-centric design.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {3032–3034},
numpages = {3},
keywords = {language learning, llms, mas, personalized learning, rag},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3706599.3720141,
author = {Ko, Kangbeen and Oh, Minwoo and Seong, Minwoo and Kim, SeungJun},
title = {LEGOLAS: Learning &amp; Enhancing Golf Skills through LLM-Augmented System},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720141},
doi = {10.1145/3706599.3720141},
abstract = {Effective skill acquisition in sports like golf requires both physical practice and proper feedback. Beyond error detection, valuable feedback helps learners understand underlying causes, refine mental representations, and enhance performance. While visual feedback (ViF) in self-training systems excels at identifying errors, it often lacks the capacity to address root causes or guide meaningful corrections—areas where verbal feedback (VeF) has proven highly beneficial. This study investigates the use of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) to deliver expert-level VeF for self-training. The results show that LLM-generated VeF retains the proven advantages of traditional VeF, improving learners’ mental representations and facilitating consistent progress. Additionally, integrating VeF with ViF enhances learning efficiency, self-assessment confidence, and overall performance without increasing cognitive load. This approach offers a scalable solution for effective self-training, leveraging LLMs to capture the proven advantages of VeF and bridging the gap between traditional coaching and automated systems.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {368},
numpages = {10},
keywords = {Motor skill learning, Principle-based Verbal feedback, XR training systems, Cognitive engagement},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641554.3701965,
author = {Miroyan, Mihran and Mitra, Chancharik and Jain, Rishi and Ranade, Gireeja and Norouzi, Narges},
title = {Analyzing Pedagogical Quality and Efficiency of LLM Responses with TA Feedback to Live Student Questions},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701965},
doi = {10.1145/3641554.3701965},
abstract = {While Large Language Models (LLMs) have emerged as promising methods for automated student question-answering, guaranteeing consistent instructional effectiveness of the response remains a key challenge. Therefore, there is a need for fine-grained analysis of State-Of-The-Art (SOTA) LLM-powered educational assistants.  This work evaluates Edison: a Retrieval Augmented Generation (RAG) pipeline based on GPT-4. We determine the pedagogical effectiveness of Edison's responses through expert Teaching Assistant (TA) evaluation of the answers. After the TA edits and improves the response, we analyze the original LLM response, the TA-assigned ratings, and the TA's edits to ascertain the essential characteristics of a high-quality response. Some key insights of our evaluation are as follows: (1) Edison can give relevant and factual answers in an educational style for conceptual and assignment questions, (2) Most TA edits are deletions made to improve the style of the response, and finally (3) Our analysis indicates that Edison improves TAs' efficiency by reducing the effort required to respond to student questions.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {770–776},
numpages = {7},
keywords = {expert feedback, instructional technologies, language models, question answering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701791,
author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Ashraf, Syed and Denny, Paul},
title = {Evaluating Language Models for Generating and Judging Programming Feedback},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701791},
doi = {10.1145/3641554.3701791},
abstract = {The emergence of large language models (LLMs) has transformed research and practice across a wide range of domains. Within the computing education research (CER) domain, LLMs have garnered significant attention, particularly in the context of learning programming. Much of the work on LLMs in CER, however, has focused on applying and evaluating proprietary models. In this article, we evaluate the efficiency of open-source LLMs in generating high-quality feedback for programming assignments and judging the quality of programming feedback, contrasting the results with proprietary models. Our evaluations on a dataset of students' submissions to introductory Python programming exercises suggest that state-of-the-art open-source LLMs are nearly on par with proprietary models in both generating and assessing programming feedback. Additionally, we demonstrate the efficiency of smaller LLMs in these tasks and highlight the wide range of LLMs accessible, even for free, to educators and practitioners.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {624–630},
numpages = {7},
keywords = {automatic evaluation, automatic feedback, generative ai, large language models, llm-as-a-judge, open source, programming feedback},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3613905.3637148,
author = {Abolnejadian, Mohammad and Alipour, Sharareh and Taeb, Kamyar},
title = {Leveraging ChatGPT for Adaptive Learning through Personalized Prompt-based Instruction: A CS1 Education Case Study},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3637148},
doi = {10.1145/3613905.3637148},
abstract = {In this research paper, we discuss our attempt to teach high school students introductory programming with Python using a custom learning platform that leverages ChatGPT to generate personalized learning materials based on each student’s educational background. The platform features topics and subtopics, each supported by prompts for Explanation, Example, Exercise, and Exercise Solution, with a context-setting prompt tailored to individual students’ backgrounds while respecting their privacy. The case study brought up compelling insights. Students exhibited heightened engagement, and the lecturers transitioned from being traditional instructors teaching content to becoming mentors who guide students on what to do next, clarifying misunderstandings and addressing potential questions. Furthermore, students gained hands-on programming experience during the learning process, eliminating the traditional post-class experimentation phase. This innovative approach not only enhances traditional CS1 education but also suggests a broader application of Large Language Models (LLMs) for personalized learning across diverse fields, providing tailored instruction and fostering engagement.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {521},
numpages = {8},
keywords = {CS1, ChatGPT, Course Design, Introductory Programming, LLM, Learning Platform, Prompt Engineering},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@article{10.1145/3708889,
author = {Boutadjine, Amal and Harrag, Fouzi and Shaalan, Khaled},
title = {Human vs. Machine: A Comparative Study on the Detection of AI-Generated Content},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {2},
issn = {2375-4699},
url = {https://doi.org/10.1145/3708889},
doi = {10.1145/3708889},
abstract = {The surge in advancements in large language models (LLMs) has expedited the generation of synthetic text imitating human writing styles. This, however, raises concerns about the potential misuse of synthetic textual data, which could compromise trust in online content. Against this backdrop, the present research aims to address the key challenges of detecting LLMs-generated texts. In this study, we used ChatGPT (v 3.5) because of its widespread and capability to comprehend and keep conversational context, allowing it to produce meaningful and contextually suitable responses. The problem revolves around the task of discerning between authentic and artificially generated textual content. To tackle this problem, we first created a dataset containing both real and DeepFake text. Subsequently, we employed transfer-learning (TL) and conducted DeepFake-detection utilizing SOTA large pre-trained LLMs. Furthermore, we conducted validation using benchmark datasets comprising unseen data samples to ensure that the model's performance reflects its ability to generalize to new data. Finally, we discussed this study's theoretical contributions, practical implications, limitations and potential avenues for future research, aiming to formulate strategies for identifying and detecting large-generative-models’ produced texts. The results were promising, with accuracy ranging from 94% to 99%. The comparison between automatic detection and the human ability to detect DeepFake text revealed a significant gap in the human capacity for its identification, emphasizing an increasing need for sophisticated automated detectors. The investigation into AI-generated content detection holds central importance in the age of LLMs and technology convergence. This study is both timely and adds value to the ongoing discussion regarding the challenges associated with the pertinent theme of "DeepFake text detection", with a special focus on examining the boundaries of human detection.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = feb,
articleno = {12},
numpages = {26},
keywords = {Language processing, Large Language Models, Generative AI, AI-Generated Content detection, Comparative Study, ChatGPT}
}

@inproceedings{10.1145/3706599.3720212,
author = {Jeong, Jin and Lee, Tak Yeon},
title = {LIGS: Developing an LLM-infused Game System for Emergent Narrative},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720212},
doi = {10.1145/3706599.3720212},
abstract = {Games with emergent narratives enable users to craft their own stories through simulation-based mechanics, but have shown various limitations due to the deterministic nature of traditional algorithms. Generative AI, including LLMs(large language models), is proposed as a solution by automating tasks and dynamically generating content tailored to evolving gameplay contexts. While prior studies have explored the applications of LLMs, there is still limited understanding of the challenges and user experiences that emerge when integrating these models into systems. This paper introduces LIGS, an LLM-Infused Game System designed for emergent narratives, and presents a prototype game used to observe actual gameplay experiences and progression. Our findings indicate that participants find the freedom of action and the resulting narrative progression engaging. However, LLM can cause various misunderstandings, posing potential risks to the overall experience of the game. Based on these findings, we propose design considerations to address these issues.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {369},
numpages = {12},
keywords = {Generative AI, Large Language Models, LLMs, Game, Digital Game, Emergent, Emergent Interaction, Emergent Narrative, User Study},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3626252.3630826,
author = {Hoq, Muntasir and Shi, Yang and Leinonen, Juho and Babalola, Damilola and Lynch, Collin and Price, Thomas and Akram, Bita},
title = {Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630826},
doi = {10.1145/3626252.3630826},
abstract = {The emergence of publicly accessible large language models (LLMs) such as ChatGPT poses unprecedented risks of new types of plagiarism and cheating where students use LLMs to solve exercises for them. Detecting this behavior will be a necessary component in introductory computer science (CS1) courses, and educators should be well-equipped with detection tools when the need arises. However, ChatGPT generates code non-deterministically, and thus, traditional similarity detectors might not suffice to detect AI-created code. In this work, we explore the affordances of Machine Learning (ML) models for the detection task. We used an openly available dataset of student programs for CS1 assignments and had ChatGPT generate code for the same assignments, and then evaluated the performance of both traditional machine learning models and Abstract Syntax Tree-based (AST-based) deep learning models in detecting ChatGPT code from student code submissions. Our results suggest that both traditional machine learning models and AST-based deep learning models are effective in identifying ChatGPT-generated code with accuracy above 90%. Since the deployment of such models requires ML knowledge and resources that are not always accessible to instructors, we also explore the patterns detected by deep learning models that indicate possible ChatGPT code signatures, which instructors could possibly use to detect LLM-based cheating manually. We also explore whether explicitly asking ChatGPT to impersonate a novice programmer affects the code produced. We further discuss the potential applications of our proposed models for enhancing introductory computer science instruction.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {526–532},
numpages = {7},
keywords = {artificial intelligence, chatgpt, cheat detection, cs1, introductory programming course, large language model, plagiarism detection},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3732938,
author = {Le, Huong and Luu, Ngoc and Nguyen, Thanh and Dao, Tuan and Dinh, Sang},
title = {Optimizing Answer Generator in Vietnamese Legal Question Answering Systems Using Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3732938},
doi = {10.1145/3732938},
abstract = {The development of large language models (LLMs) such as ChatGPT and Gemini has led to impressive advancements in question answering (QA) systems. However, they often rely on generic knowledge from the internet, resulting in hallucinated answers when applied to domain-specific QA tasks. Furthermore, their operational dependence on powerful GPUs poses challenges for practical software deployment. Building a QA systems for low-resource languages like Vietnamese is even more challenging due to the scarcity of labeled data and limited pre-trained language models. In this study, we aim to construct a Vietnamese legal QA system using a retrieval-augmented generation approach to reduce incorrect outputs. Our focus is on improving answer generation accuracy by training small-scale LLMs suitable for real-world deployment. Our contributions are: (i) constructing Vietnamese legal provisions and QA datasets for training the system; and (ii) proposing methods to fine-tune language models with QA capabilities in the legal domain. Experimental results demonstrate that it is possible to train an LLM with fewer computational resources and a smaller dataset while maintaining effectiveness. Our findings highlight that designing an efficient training and fine-tuning strategy is crucial for overcoming these challenges, particularly in the context of Vietnamese legal question-answering tasks.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = apr,
keywords = {Vietnamese, Legal, Question Answering, answer generator, BartPho, VinaLlama}
}

@inproceedings{10.1145/3632620.3671098,
author = {Padiyath, Aadarsh and Hou, Xinying and Pang, Amy and Viramontes Vargas, Diego and Gu, Xingjian and Nelson-Fromm, Tamara and Wu, Zihan and Guzdial, Mark and Ericson, Barbara},
title = {Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671098},
doi = {10.1145/3632620.3671098},
abstract = {The capability of large language models (LLMs) to generate, debug, and explain code has sparked the interest of researchers and educators in undergraduate programming, with many anticipating their transformative potential in programming education. However, decisions about why and how to use LLMs in programming education may involve more than just the assessment of an LLM’s technical capabilities. Using the social shaping of technology theory as a guiding framework, our study explores how students’ social perceptions influence their own LLM usage. We then examine the correlation of self-reported LLM usage with students’ self-efficacy and midterm performances in an undergraduate programming course. Triangulating data from an anonymous end-of-course student survey (n = 158), a mid-course self-efficacy survey (n=158), student interviews (n = 10), self-reported LLM usage on homework, and midterm performances, we discovered that students’ use of LLMs was associated with their expectations for their future careers and their perceptions of peer usage. Additionally, early self-reported LLM usage in our context correlated with lower self-efficacy and lower midterm scores, while students’ perceived over-reliance on LLMs, rather than their usage itself, correlated with decreased self-efficacy later in the course.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {114–130},
numpages = {17},
keywords = {Generative AI, Large Language Models, Self-Efficacy, Social Shaping Theory, Technology Appropriation Model},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3649405.3659473,
author = {Cipriano, Bruno Pereira},
title = {Towards the Integration of Large Language Models in an Object-Oriented Programming Course},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659473},
doi = {10.1145/3649405.3659473},
abstract = {The advent of Large Language Models (LLMs) has created multiple challenges for the Computer Science Education Community. This research project aims at integrating LLMs into Object-Oriented Programming courses, by generating and evaluating new teaching methodologies and tools suitable for this paradigm's specificities.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {832–833},
numpages = {2},
keywords = {bard, gpt-3.5, gpt-4, large language models, object-oriented programming},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3627673.3679569,
author = {Wang, Wenjie and Bao, Honghui and Lin, Xinyu and Zhang, Jizhi and Li, Yongqi and Feng, Fuli and Ng, See-Kiong and Chua, Tat-Seng},
title = {Learnable Item Tokenization for Generative Recommendation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679569},
doi = {10.1145/3627673.3679569},
abstract = {Utilizing powerful Large Language Models (LLMs) for generative recommendation has attracted much attention. Nevertheless, a crucial challenge is transforming recommendation data into the language space of LLMs through effective item tokenization. Current approaches, such as ID, textual, and codebook-based identifiers, exhibit shortcomings in encoding semantic information, incorporating collaborative signals, or handling code assignment bias. To address these limitations, we propose LETTER (a LEarnable Tokenizer for generaTivE Recommendation), which integrates hierarchical semantics, collaborative signals, and code assignment diversity to satisfy the essential requirements of identifiers. LETTER incorporates Residual Quantized VAE for semantic regularization, a contrastive alignment loss for collaborative regularization, and a diversity loss to mitigate code assignment bias. We instantiate LETTER on two models and propose a ranking-guided generation loss to augment their ranking ability theoretically. Experiments on three datasets validate the superiority of LETTER, advancing the state-of-the-art in the field of LLM-based generative recommendation.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2400–2409},
numpages = {10},
keywords = {LLMs for recommendation, generative recommendation, item tokenization, learnable tokenizer},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3673791.3698406,
author = {Liu, Sijie and Hu, Yuyang and Tian, Zihang and Jin, Zhe and Ruan, Shijin and Mao, Jiaxin},
title = {Investigating Users' Search Behavior and Outcome with ChatGPT in Learning-oriented Search Tasks},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673791.3698406},
doi = {10.1145/3673791.3698406},
abstract = {Searching has become an essential method for acquiring knowledge. The field of Search as Learning (SAL) has traditionally explored how users engage with search engines for learning tasks, yet these engines frequently falter with complex cognitive challenges. The emergence of large language models (LLMs) like ChatGPT has addressed these shortcomings, marking a shift towards conversational search methods. Despite its potential, few research has investigated how ChatGPT supports users in the SAL context. To bridge this gap, we conducted a dedicated user study involving thirty-one undergraduates performing nine distinct learning-related search tasks. These tasks were divided into three topics, each explored at three levels of cognitive complexity. Using a Latin square design, we analyzed users' search behavior and outcome when using three search modes -- traditional search engines, ChatGPT, and their combination -- across various topics and cognitive complexities. The findings suggest that ChatGPT significantly boosts efficiency and enhances user experience and outcomes, particularly in more complex tasks. This research highlights the increasing importance of generative AI in enriching users' information-seeking endeavors.},
booktitle = {Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {103–113},
numpages = {11},
keywords = {chatgpt, search as learning, search behavior, search tasks, user studies},
location = {Tokyo, Japan},
series = {SIGIR-AP 2024}
}

@inproceedings{10.1145/3706599.3719939,
author = {Holmquist, Lars Erik and Nemeth, Sam},
title = {“Don't believe anything I tell you, it's all lies!”:  A Synthetic Ethnography on Untruth in Large Language Models},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719939},
doi = {10.1145/3706599.3719939},
abstract = {Large Language Models (LLMs) have many practical uses in areas like journalism, search, coding and more. However, a growing concern is that they are also prone to presenting incorrect information, sometimes called “hallucinations”. Here, we are not interested in what specific untruths LLMs presents, but how they do it. We used synthetic ethnography, a methodology for the qualitative study of generative models, to study two LLMs with different size and capability. We collected 3 cases where LLMs presented incorrect information and observed the strategies they used to justify this. From these observations we can start to form an understanding of what happens when an LLM reaches the edge of its knowledge-base and takes corrective action. Our conclusion is that the interfaces should be better designed to reveal this tendency of LLMs to “fill in” information they are missing, but that this ability may also be one of their strengths.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {617},
numpages = {6},
keywords = {Large Language Models, synthetic ethnography},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706468.3706529,
author = {Hassany, Mohammad and Brusilovsky, Peter and Savelka, Jaromir and Lekshmi Narayanan, Arun Balajiee and Akhuseyinoglu, Kamil and Agarwal, Arav and Hendrawan, Rully Agus},
title = {Generating Effective Distractors for Introductory Programming Challenges: LLMs vs Humans},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706529},
doi = {10.1145/3706468.3706529},
abstract = {As large language models (LLMs) show great promise in generating a wide spectrum of educational materials, robust yet cost-effective assessment of the quality and effectiveness of such materials becomes an important challenge. Traditional approaches, including expert-based quality assessment and student-centered evaluation, are resource-consuming, and do not scale efficiently. In this work, we explored the use of pre-existing student learning data as a promising approach to evaluate LLM-generated learning materials. Specifically, we used a dataset where students were completing the program construction challenges by picking the correct answers among human-authored distractors to evaluate the quality of LLM-generated distractors for the same challenges. The dataset included responses from 1,071 students across 22 classes taught from Fall 2017 to Spring 2023. We evaluated five prominent LLMs (OpenAI-o1, GPT-4, GPT-4o, GPT-4o-mini, and Llama-3.1-8b) across three different prompts to see which combinations result in more effective distractors, i.e., those that are plausible (often picked by students), and potentially based on common misconceptions. Our results suggest that GPT-4o was the most effective model, matching close to 50% of the functional distractors originally authored by humans. At the same time, all of the evaluated LLMs generated many novel distractors, i.e., those that did not match the pre-existing human-authored ones. Our preliminary analysis shows that those appear to be promising. Establishing their effectiveness in real-world classroom settings is left for future work.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {484–493},
numpages = {10},
keywords = {Large Language Models (LLMs), Distractor Generation and Evaluation, Student Learning Data, Introductory Programming, GPT, LLaMA},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3663649.3664371,
author = {Prakash, Kishore and Rao, Shashwat and Hamza, Rayan and Lukich, Jack and Chaudhari, Vatsal and Nandi, Arnab},
title = {Integrating LLMs into Database Systems Education},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664371},
doi = {10.1145/3663649.3664371},
abstract = {Large Language Models (LLMs) have sparked a drastic improvement in the ways computers can understand, process, and generate language. As LLM-based offerings become mainstream, we explore the incorporation of such LLMs into introductory or undergraduate database systems education. Students and instructors are both faced with the calculator dilemma: while the use of LLM-based tools may “solve” tasks such as assignments and exams, do they impede or accelerate the learning itself? We review deficiencies of using existing off-the-shelf tools for learning, and further articulate the differentiated needs of database systems students as opposed to trained data practitioners. Building on our exploration, we outline a vision that integrates LLMs into database education in a principled manner, keeping pedagogical best practices in mind. If implemented correctly, we posit that LLMs can drastically amplify the impact of existing instruction, minimizing costs and barriers towards learning database systems fundamentals.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {33–39},
numpages = {7},
keywords = {ChatGPT, database systems education, foundation models, intro to db, large language models, llm, undergrad databases},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{10.1145/3641554.3701844,
author = {Yu, Zezhu and Liu, Suqing and Denny, Paul and Bergen, Andreas and Liut, Michael},
title = {Integrating Small Language Models with Retrieval-Augmented Generation in Computing Education: Key Takeaways, Setup, and Practical Insights},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701844},
doi = {10.1145/3641554.3701844},
abstract = {Leveraging a Large Language Model (LLM) for personalized learning in computing education is promising, yet cloud-based LLMs pose risks around data security and privacy. To address these concerns, we developed and deployed a locally stored Small Language Model (SLM) utilizing Retrieval-Augmented Generation (RAG) methods to support computing students' learning. Previous work has demonstrated that SLMs can match or surpass popular LLMs (gpt-3.5-turbo and gpt-4-32k) in handling conversational data from a CS1 course. We deployed SLMs with RAG (SLM + RAG) in a large course with more than 250 active students, fielding nearly 2,000 student questions, while evaluating data privacy, scalability, and feasibility of local deployments. This paper provides a comprehensive guide for deploying SLM + RAG systems, detailing model selection, vector database choice, embedding methods, and pipeline frameworks. We share practical insights from our deployment, including scalability concerns, accuracy versus context length trade-offs, guardrails and hallucination reduction, as well as data privacy maintenance. We address the "Impossible Triangle" in RAG systems, which states that achieving high accuracy, short context length, and low time consumption simultaneously is not feasible. Furthermore, our novel RAG framework, Intelligence Concentration (IC), categorizes information into multiple layers of abstraction within Milvus collections mitigating trade-offs and enabling educational assistants to deliver more relevant and personalized responses to students quickly.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1302–1308},
numpages = {7},
keywords = {computer science education, computing education, conversational agent, intelligence concentration, intelligent tutoring system, large language models, milvus, personalized ai agent, retrieval-augmented generation, small language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649409.3691074,
author = {Zarb, Mark and Brown, John N.A. and Goodfellow, Martin and Liaskos, Konstantinos and Young, Tiffany},
title = {Ethical Implications of Gen-AI and LLMs in Computing Education},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691074},
doi = {10.1145/3649409.3691074},
abstract = {The panel convenes five educators to discuss the ethical implications of utilising Generative AI (Gen-AI) and Large Language Models (LLMs) in computing education. Their expertise spans various domains, including organising national workshops on the implications of generative AI tools, conducting surveys on their use within curricula, implementing institutional policies related to technology use, and engaging with students directly in the classroom. They reflect on the evolution of Gen-AI and LLMs from challenging-to-use technologies to indispensable tools for users of all levels. Furthermore, they examine the ethical dilemmas arising from the widespread adoption of these technologies in educational contexts, particularly regarding issues of originality, integrity, and responsible use. In addition, they explore practical strategies for integrating ethics education into computing curriculum design and classroom practices. This includes discussions on the role of educators in guiding students towards ethical technology usage, addressing uncertainties surrounding Gen-AI tools, and fostering a culture of responsible innovation within educational institutions. Through their collective insights and experiences, the panel aims to provide recommendations for navigating the ethical complexities inherent in the integration of Gen-AI technologies into computing education curricula.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {293–294},
numpages = {2},
keywords = {ChatGPT, curriculum design, ethics, generative AI, large language models, responsibility},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3633598.3633614,
author = {Soygazi, Fatih and Oguz, Damla},
title = {An Analysis of Large Language Models and LangChain in Mathematics Education},
year = {2024},
isbn = {9798400708985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633598.3633614},
doi = {10.1145/3633598.3633614},
abstract = {The development of large language models (LLMs) has led to the consideration of new approaches, particularly in education. Word problems, especially in subjects like mathematics, and the need to solve these problems by collectively addressing specific stages of reasoning, have raised the question of whether LLMs can be successful in this area as well. In our study, we conducted analyses by asking mathematics questions especially related to word problems using ChatGPT, which is based on the latest language models like Generative Pretrained Transformer (GPT). Additionally, we compared the correct and incorrect answers by posing the same questions to LLMMathChain, a mathematics-specific LLM based on the latest language models like LangChain. It was observed that the answers obtained were more successful with ChatGPT (GPT 3.5), particularly in the field of mathematics. However, both language models were found to be below expectations, particularly in word problems, and suggestions for improvement were provided.},
booktitle = {Proceedings of the 2023 7th International Conference on Advances in Artificial Intelligence},
pages = {92–97},
numpages = {6},
keywords = {ChatGPT, LangChain, Large Language Models (LLMs), Mathematics Education},
location = {Istanbul, Turkiye},
series = {ICAAI '23}
}

@inproceedings{10.1145/3701268.3701274,
author = {Riello, Pasquale and Quille, Keith and Jaiswal, Rajesh and Sansone, Carlo},
title = {Reimagining Student Success Prediction: Applying LLMs in Educational AI with XAI},
year = {2024},
isbn = {9798400711596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701268.3701274},
doi = {10.1145/3701268.3701274},
abstract = {Since the conception of Large Language Models (LLMs), their areas of application have increased significantly over time. This is due to their nature of being able to perform natural language processing (NLP) tasks (like question answering, text generation, text summarization, text classification etc.), which gives them flexibility in a multitude of spaces, including in Educational AI (EdAI). Despite their incredible wide range of use, LLMs are typically applied to generative AI, from text to image generation.This paper aims to apply LLMs for a classification task in EdAI, by reproposing the original PreSS (Predicting Student Success) model which makes use of more traditional Machine Learning (ML) algorithms for predicting CS1 students at risk of failing or dropping out. There are two main goals for this work: the first is to identify the best and most accurate method to re-purpose LLMs for a classification task; the second is to explore and access the explainability of the model outputs. For the former we investigate different techniques for using LLMs like Few-Shot Prompting, Fine-Tuning and Transfer Learning using Gemma 2B as base model along with two different kind of prompting techniques. For the latter we focus on attention scores of LLMs transformers, aiming to understanding what are the most important features that the model considers for generating the response. The obtained results are then compared with the previous PreSS model to evaluate whether LLMs can outperform traditional ML algorithms: this paper finds that Na\"{\i}ve Bayes still outperforms all the others, once again confirmed as the best algorithm for predicting student success.},
booktitle = {Proceedings of the 2024 Conference on Human Centred Artificial Intelligence - Education and Practice},
pages = {34–40},
numpages = {7},
keywords = {Computer Science Education, Large Language Models, Explainability},
location = {
},
series = {HCAIep '24}
}

@inproceedings{10.1145/3643991.3645074,
author = {Jin, Kailun and Wang, Chung-Yu and Pham, Hung Viet and Hemmati, Hadi},
title = {Can ChatGPT Support Developers? An Empirical Evaluation of Large Language Models for Code Generation},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645074},
doi = {10.1145/3643991.3645074},
abstract = {Large language models (LLMs) have demonstrated notable proficiency in code generation, with numerous prior studies showing their promising capabilities in various development scenarios. However, these studies mainly provide evaluations in research settings, which leaves a significant gap in understanding how effectively LLMs can support developers in real-world. To address this, we conducted an empirical analysis of conversations in DevGPT, a dataset collected from developers' conversations with ChatGPT (captured with the Share Link feature on platforms such as GitHub). Our empirical findings indicate that the current practice of using LLM-generated code is typically limited to either demonstrating high-level concepts or providing examples in documentation, rather than to be used as production-ready code. These findings indicate that there is much future work needed to improve LLMs in code generation before they can be integral parts of modern software development.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {167–171},
numpages = {5},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3635636.3656204,
author = {Anderson, Barrett R and Shah, Jash Hemant and Kreminski, Max},
title = {Homogenization Effects of Large Language Models on Human Creative Ideation},
year = {2024},
isbn = {9798400704857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635636.3656204},
doi = {10.1145/3635636.3656204},
abstract = {Large language models (LLMs) are now being used in a wide variety of contexts, including as creativity support tools (CSTs) intended to help their users come up with new ideas. But do LLMs actually support user creativity? We hypothesized that the use of an LLM as a CST might make the LLM’s users feel more creative, and even broaden the range of ideas suggested by each individual user, but also homogenize the ideas suggested by different users. We conducted a 36-participant comparative user study and found, in accordance with the homogenization hypothesis, that different users tended to produce less semantically distinct ideas with ChatGPT than with an alternative CST. Additionally, ChatGPT users generated a greater number of more detailed ideas, but felt less responsible for the ideas they generated. We discuss potential implications of these findings for users, designers, and developers of LLM-based CSTs.},
booktitle = {Proceedings of the 16th Conference on Creativity &amp; Cognition},
pages = {413–425},
numpages = {13},
keywords = {creativity support tools, divergent ideation, large language models, user study},
location = {Chicago, IL, USA},
series = {C&amp;C '24}
}

@inproceedings{10.1145/3706599.3720278,
author = {Helgert, Andre and Weis, Latoya and Strassmann, Carolin},
title = {Prompt it Colorful with Rainbow Bot: Enhancing Video-Based Collaborative Learning by using a Multi-Party AI-Driven Chatbot},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720278},
doi = {10.1145/3706599.3720278},
abstract = {Multi-party AI-driven chatbots remain largely unexplored, despite their potential to enhance internal communication and coordination within student learning groups. These benefits are increasingly feasible with the advent of large language models (LLMs), which enable more efficient content generation and chatbot customization. To bridge this gap, we carried out an exploratory study to examine students’ perceptions, practical applications, and concerns regarding the use of multi-party AI-driven chatbots in video-based collaborative learning environments. Based on the findings, we designed the Rainbow Bot, an optimized multi-party AI-driven chatbot. It features an interactive reflection process to strengthen group dynamics, customization options to adjust response length and content focus, and a unique color scheme for visual clarity. By combining colors from group members in refined prompts, Rainbow Bot fosters collaboration and promotes shared understanding within teams. Future work will assess its effectiveness in real educational settings, with a focus on its impact on group dynamics and collaborative learning outcomes.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {450},
numpages = {7},
keywords = {Collaborative Learning, Multi-party AI-driven chatbots, AI-driven chatbots, Artifical Intelligence, Higher Education, Chatbot},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706599.3721261,
author = {Bush, Annika and Alibakhshi, Amin},
title = {Bridging the Early Science Gap with Artificial Intelligence: Evaluating Large Language Models as Tools for Early Childhood Science Education},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3721261},
doi = {10.1145/3706599.3721261},
abstract = {Early childhood science education is crucial for developing scientific literacy, yet translating complex scientific concepts into age-appropriate content remains challenging for educators. Our study evaluates four leading Large Language Models (LLMs) - GPT-4, Claude, Gemini, and Llama - on their ability to generate preschool-appropriate scientific explanations across biology, chemistry, and physics. Through systematic evaluation by 30 nursery teachers using established pedagogical criteria, we identify significant differences in the models’ capabilities to create engaging, accurate, and developmentally appropriate content. Unexpectedly, Claude outperformed other models, particularly in biological topics, while all LLMs struggled with abstract chemical concepts. Our findings provide practical insights for educators leveraging AI in early science education and offer guidance for developers working to enhance LLMs’ educational applications. The results highlight the potential and current limitations of using LLMs to bridge the early science literacy gap.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {115},
numpages = {6},
keywords = {Early Childhood Education, Natural Sciences, Large Language Models, Educational Technology, Preschool, Science Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3652620.3687803,
author = {Buchmann, Thomas and Peinl, Ren\'{e} and Schw\"{a}gerl, Felix},
title = {White-box LLM-supported Low-code Engineering: A Vision and First Insights},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687803},
doi = {10.1145/3652620.3687803},
abstract = {Low-code development (LCD) platforms promise to empower citizen developers to define core domain models and rules for business applications. However, as domain rules grow complex, LCD platforms may fail to do so effectively. Generative AI, driven by large language models (LLMs), offers source code generation from natural language but suffers from its non-deterministic black-box nature and limited explainability. Therefore, rather than having LLMs generate entire applications from single prompts, we advocate for a white-box approach allowing citizen developers to specify domain models semi-formally, attaching constraints and operations as natural language annotations. These annotations are fed incrementally into an LLM contextualized with the generated application stub. This results in deterministic and better explainable generation of static application components, while offering citizen developers an appropriate level of abstraction. We report on a case study in manufacturing execution systems, where the implementation of the approach provides first insights.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {556–560},
numpages = {5},
keywords = {model-driven engineering, large language models, low-code, semiformal, artificial intelligence},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3623762.3633499,
author = {Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir},
title = {The Robots Are Here: Navigating the Generative AI Revolution in Computing Education},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633499},
doi = {10.1145/3623762.3633499},
abstract = {Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {108–159},
numpages = {52},
keywords = {ai, artificial intelligence, chatgpt, code generation, codex, computer programming, copilot, cs1, curriculum, generative ai, github, gpt, gpt-3, gpt-4, large language models, llm, llms, novice programming, openai, pedagogical practices, programming},
location = {Turku, Finland},
series = {ITiCSE-WGR '23}
}

@inproceedings{10.1145/3641555.3705125,
author = {Zhang, Shan and Meshram, Pragati Shuddhodhan and Ganapathy Prasad, Priyadharshini and Israel, Maya and Bhat, Suma},
title = {An LLM-Based Framework for Simulating, Classifying, and Correcting Students' Programming Knowledge with the SOLO Taxonomy},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705125},
doi = {10.1145/3641555.3705125},
abstract = {Novice programmers often face challenges in designing computational artifacts and fixing code errors, which can lead to task abandonment and over-reliance on external support. While research has explored effective meta-cognitive strategies to scaffold novice programmers' learning, it is essential to first understand and assess students' conceptual, procedural, and strategic/conditional programming knowledge at scale. To address this issue, we propose a three-model framework that leverages Large Language Models (LLMs) to simulate, classify, and correct student responses to programming questions based on the SOLO Taxonomy. The SOLO Taxonomy provides a structured approach for categorizing student understanding into four levels: Pre-structural, Uni-structural, Multi-structural, and Relational. Our results showed that GPT-4o achieved high accuracy in generating and classifying responses for the Relational category, with moderate accuracy in the Uni-structural and Pre-structural categories, but struggled with the Multi-structural category. The model successfully corrected responses to the Relational level. Although further refinement is needed, these findings suggest that LLMs hold significant potential for supporting computer science education by assessing programming knowledge and guiding students toward deeper cognitive engagement.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1681–1682},
numpages = {2},
keywords = {computer science education, large language model, solo taxonomy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3610978.3640592,
author = {Borg, Alexander and Parodis, Ioannis and Skantze, Gabriel},
title = {Creating Virtual Patients using Robots and Large Language Models: A Preliminary Study with Medical Students},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3640592},
doi = {10.1145/3610978.3640592},
abstract = {This paper presents a virtual patient (VP) platform for medical education, combining a social robot, Furhat, with large language models (LLMs). Aimed at enhancing clinical reasoning (CR) training, particularly in rheumatology, this approach introduces more interactive and realistic patient simulations. The use of LLMs both for driving the dialogue, but also for the expression of emotions in the robot's face, as well as automatic analysis and generation of feedback to the student, is discussed. The platform's effectiveness was tested in a pilot study with 15 medical students, comparing it against a traditional semi-linear VP platform. The evaluation indicates a preference for the robot platform in terms of authenticity and learning effect. We conclude that this novel integration of a social robot and LLMs in VP simulations shows potential in medical education, offering a more engaging learning experience.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {273–277},
numpages = {5},
keywords = {human-robot interaction, large language models, robots in education, virtual patients},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.5555/3709347.3744012,
author = {Willis, Richard and Du, Yali and Leibo, Joel Z.},
title = {Will Systems of LLM Agents Lead to Cooperation: An Investigation into a Social Dilemma},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {This study investigates the emergent cooperative tendencies of systems of Large Language Model (LLM) agents in a social dilemma. Unlike previous research, where LLMs output individual actions, we prompt state-of-the-art LLMs to generate complete strategies for iterated Prisoner's Dilemma. Our findings reveal that LLMs exhibit biases when prompted to display certain behavioural dispositions, and the format of the prompt affects the relative success of aggressive versus cooperative strategies.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {2786–2788},
numpages = {3},
keywords = {emergent behaviour, game theory, multiagent system},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3706468.3706491,
author = {Wang, Zuo and Lin, Weiyue and Hu, Xiao},
title = {Self-service Teacher-facing Learning Analytics Dashboard with Large Language Models},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706491},
doi = {10.1145/3706468.3706491},
abstract = {With the rise of online learning platforms, the need for effective learning analytics (LA) has become critical for teachers. However, the development of traditional LA dashboards often requires technical expertise and a certain level of data literacy, preventing many teachers from integrating LA dashboards effectively and flexibly into their teaching practice. This paper explores the development of a self-service teacher-facing learning analytics dashboard powered by large language models (LLMs), for improving teaching practices. By leveraging LLMs, the self-service system aims to simplify the implementation of data queries and visualizations, allowing teachers to create personalized LA dashboards using natural languages. This study also investigates the capabilities of LLMs in generating charts for LA dashboards and evaluates the effectiveness of the self-service system through usability tests with 15 teachers. Preliminary findings suggest that LLMs demonstrate high capabilities in generating charts for LA dashboards, and the LLM-powered self-service system can effectively address participating teachers’ pedagogical needs for LA. This research contributes to the ongoing research on the intersection of LLMs and education, emphasizing the potential of self-service systems to empower teachers in daily teaching practices.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {824–830},
numpages = {7},
keywords = {data visualization, large language models, learning analytics dashboard, self-service learning analytics},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3626253.3635543,
author = {Glynn, Colin and Hed, Emily and Pexa, Abbigail and Pohlmann, Tyler and Rahal, Imad and Hesse, Robert},
title = {CAET: Code Analysis and Education Tutor},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635543},
doi = {10.1145/3626253.3635543},
abstract = {The introduction of OpenAI's ChatGPT in 2022 kickstarted the release of Generative Artificial Intelligence (GAI) applications to the public domain. Such chat interfaces are based on large language models (LLMs) and possess a vast array of abilities spanning conversation, the writing and debugging of code, the writing of papers, and the creation of images, music, and songs. With students now having access to a myriad of GAI tools, academia has been permanently altered.Our proposed system, named Code Analysis and Education Tutor (CAET), integrates GAI into early Computer Science education by providing students with an ethical alternative to existing GAI tools. CAET is designed to assist students with programming tasks in a manner tailored to their individual needs without jeopardizing the integrity of their learning. A point of uniqueness from existing works is CAET's ability to display or hide generated code based on its pertinence to the problem at hand. After subjecting multiple GAI models to common programming errors and queries, we settled on OpenAI's GPT-3.5 Turbo model due to its comprehensive capabilities and cost-effectiveness. Overall, CAET underscored the model's conversational dynamics and provided insights for creating a more personalized learning experience for students in an introductory computer science course.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1656–1657},
numpages = {2},
keywords = {computer science education, generative artificial intelligence, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3627673.3679558,
author = {Sun, Zhongxiang and Si, Zihua and Zang, Xiaoxue and Zheng, Kai and Song, Yang and Zhang, Xiao and Xu, Jun},
title = {Large Language Models Enhanced Collaborative Filtering},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679558},
doi = {10.1145/3627673.3679558},
abstract = {Recent advancements in Large Language Models (LLMs) have attracted considerable interest among researchers to leverage these models to enhance Recommender Systems (RSs). Existing work predominantly utilizes LLMs to generate knowledge-rich texts or utilizes LLM-derived embeddings as features to improve RSs. Although the extensive world knowledge embedded in LLMs generally benefits RSs, the application can only take a limited number of users and items as inputs, without adequately exploiting collaborative filtering information. Considering its crucial role in RSs, one key challenge in enhancing RSs with LLMs lies in providing better collaborative filtering information through LLMs. In this paper, drawing inspiration from the in-context learning and chain of thought reasoning in LLMs, we propose the Large Language Models enhanced Collaborative Filtering (LLM-CF) framework, which distills the world knowledge and reasoning capabilities of LLMs into collaborative filtering. We also explored a concise and efficient instruction-tuning method, which improves the recommendation capabilities of LLMs while preserving their general functionalities (e.g., not decreasing on the LLM benchmark). Comprehensive experiments on three real-world datasets demonstrate that LLM-CF significantly enhances several backbone recommendation models and consistently outperforms competitive baselines, showcasing its effectiveness in distilling the world knowledge and reasoning capabilities of LLM into collaborative filtering.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2178–2188},
numpages = {11},
keywords = {collaborative filtering, large language models},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3641520.3665309,
author = {He, Kevin and Lapham, Annette and Li, Zenan},
title = {Enhancing Narratives with SayMotion's text-to-3D animation and LLMs},
year = {2024},
isbn = {9798400705267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641520.3665309},
doi = {10.1145/3641520.3665309},
abstract = {SayMotion, a generative AI text-to-3D animation platform, utilizes deep generative learning and advanced physics simulation to transform text descriptions into realistic 3D human motions for applications in gaming, extended reality (XR), film production, education and interactive media. SayMotion addresses challenges due to the complexities of animation creation by employing a Large Language Model (LLM) fine-tuned to human motion with further AI-based animation editing components including spatial-temporal Inpainting via a proprietary Large Motion Model (LMM). SayMotion is a pioneer in the animation market by offering a comprehensive set of AI generation and AI editing functions for creating 3D animations efficiently and intuitively. With an LMM at its core, SayMotion aims to democratize 3D animations for everyone through language and generative motion.},
booktitle = {ACM SIGGRAPH 2024 Real-Time Live!},
articleno = {2},
numpages = {2},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{10.1145/3701716.3715553,
author = {Yu, Hang and Yu, Haoyi},
title = {Enhancing Zero-Shot Knowledge Graph Relation Prediction through Large Language Models and Contrastive Learning},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715553},
doi = {10.1145/3701716.3715553},
abstract = {Knowledge graph completion (KGC) aims to predict missing facts in a knowledge graph (KG), with zero-shot relation prediction remaining a significant challenge due to limited descriptive information. In this paper, we propose ROCKGC, a framework that leverages large language models (LLMs) to generate enriched relation descriptions and integrates contrastive learning with a conditional variational autoencoder (C-VAE) to enhance relational separation in the embedding space. By combining LLM-generated semantic representations with C-VAE and contrastive loss, ROCKGC effectively captures nuanced relational differences and improves zero-shot learning performance. Extensive experiments on benchmark datasets show that our method outperforms state-of-the-art approaches, achieving superior accuracy and robustness in predicting unseen relations.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1490–1494},
numpages = {5},
keywords = {contrastive learning, knowledge graph completion, large language models, zero-shot relation learning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3715669.3726846,
author = {Ilyas, Chaudhary Muhammad Aqdus and Noor, Sifat-E and Tashk, Ashkan and Cooreman, Bart and Beier, Sofie and B\ae{}kgaard, Per},
title = {Reading the Readers Mind through Eye Tracking: Can AI Generated Texts Match Human Authors?},
year = {2025},
isbn = {9798400714870},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715669.3726846},
doi = {10.1145/3715669.3726846},
abstract = {While Generative AI models like Large Language Models (LLMs) are capable of generating extensive text, their efficacy in producing readable content for human participants in experimental settings remains to be evaluated. Further, eye-tracking technology is increasingly utilized to study cognition and behavior, yet its application to readers’ cognitive processes when exposed to AI-generated versus human-authored texts remains unexplored. This study investigates how text generated by LLMs influences reading by analyzing gaze patterns.The study collects gaze data from 13 participants as they read AI-generated and human-authored passages. A comparative analysis is conducted within subjects to assess gaze patterns between authors and between text types based on the robust two-means clustering (I2MC) algorithm to identify fixations. In addition, pupil dilation and reading speed were examined.Our findings reveal significant differences in fixation characteristics not only between authors but also between AI-generated and human-authored texts.},
booktitle = {Proceedings of the 2025 Symposium on Eye Tracking Research and Applications},
articleno = {113},
numpages = {7},
keywords = {Eye tracking, Fixation Detection, AI and Human authored reading patterns},
location = {
},
series = {ETRA '25}
}

@inproceedings{10.1145/3696410.3714933,
author = {Hong, Minjie and Xia, Yan and Wang, Zehan and Zhu, Jieming and Wang, Ye and Cai, Sihang and Yang, Xiaoda and Dai, Quanyu and Dong, Zhenhua and Zhang, Zhimeng and Zhao, Zhou},
title = {EAGER-LLM: Enhancing Large Language Models as Recommenders through Exogenous Behavior-Semantic Integration},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714933},
doi = {10.1145/3696410.3714933},
abstract = {Large language models (LLMs) are increasingly leveraged as foundational backbones in the development of advanced recommender systems, offering enhanced capabilities through their extensive knowledge and reasoning. Existing llm-based recommender systems (RSs) often face challenges due to the significant differences between the linguistic semantics of pre-trained LLMs and the collaborative semantics essential for RSs. These systems use pre-trained linguistic semantics but learn collaborative semantics from scratch via the llm-Backbone. However, LLMs are not designed for recommendations, leading to inefficient collaborative learning, weak result correlations, and poor integration of traditional RS features. To address these challenges, we propose EAGER-LLM, a decoder-only llm-based generative recommendation framework that integrates endogenous and exogenous behavioral and semantic information in a non-intrusive manner. Specifically, we propose 1) dual-source knowledge-rich item indices that integrates indexing sequences for exogenous signals, enabling efficient link-wide processing; 2) non-invasive multiscale alignment reconstruction tasks guide the model toward a deeper understanding of both collaborative and semantic signals; 3) an annealing adapter designed to finely balance the model's recommendation performance with its comprehension capabilities. We demonstrate EAGER-LLM's effectiveness through rigorous testing on three public benchmarks.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {2754–2762},
numpages = {9},
keywords = {LLM-as-recommender, behavior-semantic collaboration, generative recommendation, large language models},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3654777.3676390,
author = {Fan, Haoxiang and Chen, Guanzheng and Wang, Xingbo and Peng, Zhenhui},
title = {LessonPlanner: Assisting Novice Teachers to Prepare Pedagogy-Driven Lesson Plans with Large Language Models},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676390},
doi = {10.1145/3654777.3676390},
abstract = {Preparing a lesson plan, e.g., a detailed road map with strategies and materials for instructing a 90-minute class, is beneficial yet challenging for novice teachers. Large language models (LLMs) can ease this process by generating adaptive content for lesson plans, which would otherwise require teachers to create from scratch or search existing resources. In this work, we first conduct a formative study with six novice teachers to understand their needs for support of preparing lesson plans with LLMs. Then, we develop LessonPlanner that assists users to interactively construct lesson plans with adaptive LLM-generated content based on Gagne’s nine events. Our within-subjects study (N = 12) shows that compared to the baseline ChatGPT interface, LessonPlanner can significantly improve the quality of outcome lesson plans and ease users’ workload in the preparation process. Our expert interviews (N = 6) further demonstrate LessonPlanner ’s usefulness in suggesting effective teaching strategies and meaningful educational resources. We discuss concerns on and design considerations for supporting teaching activities with LLMs.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {146},
numpages = {20},
keywords = {Large language models, lesson plan preparation, pedagogy-driven system},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3639474.3640068,
author = {Pan, Wei Hung and Chok, Ming Jie and Wong, Jonathan Leong Shan and Shin, Yung Xin and Poon, Yeong Shian and Yang, Zhou and Chong, Chun Yong and Lo, David and Lim, Mei Kuan},
title = {Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640068},
doi = {10.1145/3639474.3640068},
abstract = {Educators are increasingly concerned about the usage of Large Language Models (LLMs) such as ChatGPT in programming education, particularly regarding the potential exploitation of imperfections in Artificial Intelligence Generated Content (AIGC) Detectors for academic misconduct.In this paper, we present an empirical study where the LLM is examined for its attempts to bypass detection by AIGC Detectors. This is achieved by generating code in response to a given question using different variants. We collected a dataset comprising 5,069 samples, with each sample consisting of a textual description of a coding problem and its corresponding human-written Python solution codes. These samples were obtained from various sources, including 80 from Quescol, 3,264 from Kaggle, and 1,725 from Leet-Code. From the dataset, we created 13 sets of code problem variant prompts, which were used to instruct ChatGPT to generate the outputs. Subsequently, we assessed the performance of five AIGC detectors. Our results demonstrate that existing AIGC Detectors perform poorly in distinguishing between human-written code and AI-generated code.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {1–11},
numpages = {11},
keywords = {software engineering education, AI-generated code, AI-generated code detection},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1109/SCW63240.2024.00010,
author = {Valero-Lara, Pedro and Godoy, William F. and Teranishi, Keita and Balaprakash, Prasanna and Vetter, Jeffrey S.},
title = {ChatBLAS: The First AI-Generated and Portable BLAS Library},
year = {2025},
isbn = {9798350355543},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SCW63240.2024.00010},
doi = {10.1109/SCW63240.2024.00010},
abstract = {We present ChatBLAS, the first AI-generated and portable Basic Linear Algebra Subprograms (BLAS) library on different CPU/GPU configurations. The purpose of this study is (i) to evaluate the capabilities of current large language models (LLMs) to generate a portable and HPC library for BLAS operations and (ii) to define the fundamental practices and criteria to interact with LLMs for HPC targets to elevate the trustworthiness and performance levels of the AI-generated HPC codes. The generated C/C++ codes must be highly optimized using device-specific solutions to reach high levels of performance. Additionally, these codes are very algorithm-dependent, thereby adding an extra dimension of complexity to this study. We used OpenAI's LLM ChatGPT and focused on vector-vector BLAS level-1 operations. ChatBLAS can generate functional and correct codes, achieving high-trustworthiness levels, and can compete or even provide better performance against vendor libraries.},
booktitle = {Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {19–24},
numpages = {6},
keywords = {JACC, Julia, high-bandwidth on-chip memory, metaprogramming, performance portability},
location = {Atlanta, GA, USA},
series = {SC-W '24}
}

@inproceedings{10.1145/3644815.3644945,
author = {Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
title = {Seven Failure Points When Engineering a Retrieval Augmented Generation System},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644945},
doi = {10.1145/3644815.3644945},
abstract = {Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {194–199},
numpages = {6},
keywords = {retrieval augmented generation, RAG, SE4AI, case study},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@article{10.1145/3697012,
author = {Gu, Xiaodong and Chen, Meng and Lin, Yalan and Hu, Yuhan and Zhang, Hongyu and Wan, Chengcheng and Wei, Zhao and Xu, Yong and Wang, Juhong},
title = {On the Effectiveness of Large Language Models in Domain-Specific Code Generation},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3697012},
doi = {10.1145/3697012},
abstract = {Large language models (LLMs) such as ChatGPT have shown remarkable capabilities in code generation. Despite significant achievements, they rely on enormous training data to acquire a broad spectrum of open-domain knowledge. Besides, their evaluation revolves around open-domain benchmarks like HumanEval, which primarily consist of programming contests. Therefore, it is hard to fully characterize the intricacies and challenges associated with particular domains (e.g., Web, game, and math). In this article, we conduct an in-depth study of the LLMs in domain-specific code generation. Our results demonstrate that LLMs exhibit sub-optimal performance in generating domain-specific code, due to their limited proficiency in utilizing domain-specific libraries. We further observe that incorporating API knowledge as prompts can empower LLMs to generate more professional code. Based on these findings, we further investigate how to effectively incorporate API knowledge into the code generation process. We experiment with three strategies for incorporating domain knowledge, namely, external knowledge inquirer, chain-of-thought prompting, and chain-of-thought fine-tuning. We refer to these strategies as a new code generation approach called DomCoder. Experimental results show that all strategies of DomCoder improve the effectiveness of domain-specific code generation under certain settings.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
articleno = {78},
numpages = {22},
keywords = {large language models, code generation, domain-specific program generation}
}

@inproceedings{10.1145/3706599.3720165,
author = {Li, Zong-Ying and Lai, Yen-Hua and Lin, Chi-Yu and Chou, Chien-Hsing and Han, Ping-Hsuan},
title = {Visualizing Exercise Data from Combat Exergame for Exploring the Insight from Personal Informatics with Large Language Models},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720165},
doi = {10.1145/3706599.3720165},
abstract = {Previous research has explored the potential of personal informatics and data visualization to enhance reflection. However, these studies primarily focus on improving user performance in traditional sports. In this work, we present a visualization system for innovative sports integrating sports data collected from a VR combat exergame with personalized narratives generated by Large Language Models (LLMs). We conducted a user study with Data Visualization and LLM Suggestions to evaluate their impact on self-reflection and reflection. The results show that our system facilitated data exploration and comparison with reflection. In addition, this study reveals the potential of combining LLMs and VR-based data visualization to provide personalized feedback for users.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {579},
numpages = {8},
keywords = {personal informatics, reflection, data visualization, large language model, Exergame},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641554.3701800,
author = {Shah, Anshul and Chernova, Anya and Tomson, Elena and Porter, Leo and Griswold, William G. and Soosai Raj, Adalbert Gerald},
title = {Students' Use of GitHub Copilot for Working with Large Code Bases},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701800},
doi = {10.1145/3641554.3701800},
abstract = {Large language models (LLMs) are already heavily used by professional software engineers. An important skill for new university graduates to possess will be the ability to use such LLMs to effectively navigate and modify a large code base. While much of the prior work related to LLMs in computing education focuses on novice programmers learning to code, less work has focused on how upper-division students use and trust these tools, especially while working with large code bases. In this study, we taught students about various GitHub Copilot features, including Copilot chat, in an upper-division software engineering course and asked students to add a feature to a large code base using Copilot. Our analysis revealed a novel interaction pattern that we call one-shot prompting, in which students ask Copilot to implement the entire feature at once and spend the next few prompts asking Copilot to debug the code or asking Copilot to regenerate its incorrect response. Finally, students reported significantly more trust in the code comprehension features than code generation features of Copilot, perhaps due to the presence of trust affordances in the Copilot chat that are absent in the code generation features. Our study takes the first steps in understanding how upper-division students use Github Copilot so that our instruction can adequately prepare students for a career in software engineering.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1050–1056},
numpages = {7},
keywords = {github copilot, large code bases, program comprehension, trust},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3672608.3707732,
author = {Raimondi, Bianca and Giallorenzo, Saverio and Gabbrielli, Maurizio},
title = {Affordably Fine-tuned LLMs Provide Better Answers to Course-specific MCQs},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707732},
doi = {10.1145/3672608.3707732},
abstract = {In education, the capability of generating human-like text of Large Language Models (LLMs) inspired work on how they can increase the efficiency of learning and teaching. We study the affordability of these models for educators and students by investigating how LLMs answer multiple-choice questions (MCQs) with respect to hardware constraints and refinement techniques. We explore this space by using generic pre-trained LLMs (the 7B, 13B, and 70B variants of LLaMA-2) to answer 162 undergraduate-level MCQs from a course on Programming Languages (PL)—the MCQ dataset is a contribution of this work, which we make publicly available. Specifically, we dissect how different factors, such as using readily-available material—(parts of) the course's textbook—for fine-tuning and quantisation (to decrease resource usage) can change the accuracy of the responses. The main takeaway is that smaller textbook-based fine-tuned models outperform generic larger ones (whose pre-training requires conspicuous resources), making the usage of LLMs for answering MCQs resource- and material-wise affordable.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {32–39},
numpages = {8},
keywords = {education, large language models, multiple-choice questions, fine-tuning, quantisation},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3701551.3703485,
author = {Deldjoo, Yashar and He, Zhankui and McAuley, Julian and Korikov, Anton and Sanner, Scott and Ramisa, Arnau and Vidal, Ren\'{e} and Sathiamoorthy, Maheswaran and Kasirzadeh, Atoosa and Milano, Silvia},
title = {Tutorial on Recommendation with Generative Models (Gen-RecSys)},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703485},
doi = {10.1145/3701551.3703485},
abstract = {This intermediate-level tutorial, titled "Gen-RecSys", merges both industrial and academic perspectives on recent advances in Generative AI for recommender systems (beyond LLMs). It aims to highlight the transformative role of generative models in modern recommender systems, which have significantly impacted the AI field-particularly with the rise of large language models (LLMs) like ChatGPT-and have contributed to a rapid convergence of the fields of search, data mining, and recommendation. By providing attendees with a modern perspective on GenAI applications in recommendation, the tutorial will emphasize how generative models can drive recommendation by unlocking and interacting with rich data representations, including behavioral, textual, and multi-modal data-knowledge highly transferable across many applications of interest to the WSDM community. Participants will learn about the categorization of generative models in recommender systems based on underlying data modalities: (i) ID-based collaborative models, (ii) text-driven models such as LLMs, and (iii) multi-modal models. Within each category, various deep generative model paradigms (e.g., AR, GAN, diffusion models) will be introduced, along with insights into their application areas. The tutorial will also cover evaluation aspects, including benchmarks, metrics, and assessments of social and ethical impacts and harms. This tutorial presents a condensed version of the industrial and academic work featured in the forthcoming book at FntIR 2024-25, titled "Recommendation with Generative Models [7]," and a shorter version prepared, and presented by the team, see GenRecSys-Survey [6].},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {1002–1004},
numpages = {3},
keywords = {GANs, LLMs, VAEs, ethical and societal considerations, generative models, multimodal, recommender systems, vLLMs},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3641555.3705061,
author = {Liu, Rongxin and Xu, Benjamin and Perez, Christopher and Zhao, Julianna and Zhukovets, Yuliia and Malan, David J.},
title = {Assessment in CS50 with AI: Leveraging Generative Artificial Intelligence for Personalized Student Evaluation},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705061},
doi = {10.1145/3641555.3705061},
abstract = {The scalability challenges of code review and pair-programming assessments in large computer science courses, such as CS50 at Harvard University, have opened up opportunities for the application of Generative AI. Leveraging large language models (LLMs), CS50.ai offers a suite of AI-based tools that assist both students and instructors in mastering course material while overcoming the limitations posed by human resource constraints. This demo highlights how generative AI can be employed to conduct code reviews and pair-programming simulations, providing real-time feedback, code explanations, and collaborative programming insights. By integrating these AI tools into students' learning journeys, we aim to mimic the 1:1 interaction between instructor and student, improving both formative and summative assessments. We will showcase how these tools are implemented to scale personalized feedback, ensure academic integrity, and maintain pedagogical efficacy. Our presentation will also reflect on lessons learned from deploying these AI-driven tools in recent course offerings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1735},
numpages = {1},
keywords = {AI, LLMs, artificial intelligence, generative AI, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3712001,
author = {Das, Badhan Chandra and Amini, M. Hadi and Wu, Yanzhao},
title = {Security and Privacy Challenges of Large Language Models: A Survey},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3712001},
doi = {10.1145/3712001},
abstract = {Large language models (LLMs) have demonstrated extraordinary capabilities and contributed to multiple fields, such as generating and summarizing text, language translation, and question-answering. Today, LLMs have become quite popular tools in natural language processing tasks, with the capability to analyze complicated linguistic patterns and provide relevant responses depending on the context. While offering significant advantages, these models are also vulnerable to security and privacy attacks, such as jailbreaking attacks, data poisoning attacks, and personally identifiable information leakage attacks. This survey provides a thorough review of the security and privacy challenges of LLMs, along with the application-based risks in various domains, such as transportation, education, and healthcare. We assess the extent of LLM vulnerabilities, investigate emerging security and privacy attacks against LLMs, and review potential defense mechanisms. Additionally, the survey outlines existing research gaps and highlights future research directions.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {152},
numpages = {39},
keywords = {Large language models, attack and defense mechanisms}
}

@inproceedings{10.1145/3706599.3716299,
author = {Hwang, Angel Hsing-Chi and Bernstein, Michael S. and Sundar, S. Shyam and Zhang, Renwen and Horta Ribeiro, Manoel and Lu, Yingdan and Chang, Serina and Wu, Tongshuang and Yang, Aimei and Williams, Dmitri and Park, Joon Sung and Ognyanova, Katherine and Xiao, Ziang and Shaw, Aaron and Shamma, David A.},
title = {Human Subjects Research in the Age of Generative AI: Opportunities and Challenges of Applying LLM-Simulated Data to HCI Studies},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3716299},
doi = {10.1145/3706599.3716299},
abstract = {Rapid advances in generative artificial intelligence suggest new possibilities for how human subjects research can be conducted in HCI studies. The panel invites both computer and social scientists to discuss future directions for applying simulated responses from large language models (LLM) for human subjects research. We discuss current challenges and opportunities in LLM simulations and brainstorm how insights across different disciplines might inform breakthroughs. We pay close attention to when and how applications of LLM simulations might augment human subjects research instead of steering it toward unintended directions. Discussions from the panel will provide preliminary ideas for when and how HCI researchers can apply LLM simulations to human subjects research pipelines. Through this engagement, we also aim to build a research community with shared interests.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {761},
numpages = {7},
keywords = {LLM simulation, synthetic data, human subject research, social science in HCI},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3696673.3723065,
author = {Tamascelli, Michael and Bunch, Olivia and Fowler, Blake and Taeb, Maryam and Cohen, Achraf},
title = {Academic Advising Chatbot Powered with AI Agent},
year = {2025},
isbn = {9798400712777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696673.3723065},
doi = {10.1145/3696673.3723065},
abstract = {Academic advising plays a crucial role in fostering student success. However, challenges such as limited advisor availability can hinder effective support. Generative AI, particularly AI-powered chatbots, offers the potential to enhance student advising in higher education by providing personalized guidance. These technologies help college students find the information and resources needed to create degree plans aligned with their academic goals. This research introduces ARGObot, an intelligent advising system that facilitates student navigation of university policies through automated interpretation of the student handbook as its primary knowledge base. ARGObot enhances accessibility to critical academic policies and procedures, supporting incoming students' success through personalized guidance. Our system integrates a multifunctional agent enhanced by a Large Language Model (LLM). The architecture employs multiple external tools to enhance its capabilities: a Retrieval-Augmented Generation (RAG) system accesses verified university sources; email integration facilitates Human-in-the-Loop (HITL) interaction; and a web search function expands the system's knowledge base beyond predefined constraints. This approach enables the system to provide contextually relevant and verified responses to various student queries. This architecture evolved from our initial implementation based on Gemini 1 Pro, which revealed significant limitations due to its lack of agent-based functionality, resulting in hallucination issues and irrelevant responses. Subsequent evaluation demonstrated that our enhanced version, integrating GPT-4 with the text-embedding-ada-002 model, achieved superior performance across all metrics. This paper also presents a comparative analysis of both implementations, highlighting the architectural improvements and their impact on system performance.},
booktitle = {Proceedings of the 2025 ACM Southeast Conference},
pages = {195–202},
numpages = {8},
keywords = {academic advising, AI agent, chatbot, higher education, large language models, retrieval-augmented generation},
location = {Southeast Missouri State University, Cape Girardeau, MO, USA},
series = {ACMSE 2025}
}

@inproceedings{10.1145/3704137.3704146,
author = {Wu, Shi and Zhou, Jianlong and Dong, Yifei and Chen, Fang},
title = {Enhancing Explainability of Deep Learning-Based ECG Diagnosis Using Large Language Models},
year = {2025},
isbn = {9798400718014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704137.3704146},
doi = {10.1145/3704137.3704146},
abstract = {The electrocardiogram (ECG) is an essential diagnostic tool for monitoring heart health. Traditional manual methods for ECG interpretation are increasingly challenged by the complexity of heart diseases and the volume of ECG data. Recent advancements in artificial intelligence (AI), particularly deep learning, have improved the efficiency and accuracy of ECG diagnostics. However, the "black-box" nature of AI models poses trust and verification challenges. To address this, we propose a novel approach integrating Explainable AI (XAI) techniques with multimodal large language models to enhance ECG diagnostic interpretability. Our methodology employs a 2D convolutional neural network (CNN) to classify ECG signals, followed by Grad-CAM to generate heatmaps highlighting critical areas influencing AI decisions. These enhanced ECG images and their classifications are then input into a multimodal large language model to produce comprehensive explanatory outputs. This approach combines the visual processing power of CNNs with the contextual understanding of multimodal models, offering clearer insights into AI reasoning. Our research demonstrates improved diagnostic accuracy and interpretability, setting a new standard for AI integration in clinical practices. Specifically, our method achieved an F1-score of 0.67 for ECG classification using Inception and a BERT-Score of 0.818 for text generation using Gemini_GradCAM.},
booktitle = {Proceedings of the 2024 8th International Conference on Advances in Artificial Intelligence},
pages = {61–65},
numpages = {5},
keywords = {Electrocardiogram (ECG), Explainable AI (XAI), Multimodal Large Language Models (MLLMs), Grad-CAM},
location = {
},
series = {ICAAI '24}
}

@inproceedings{10.1145/3717867.3717914,
author = {Trinh, Quang Minh and Zarin, Samiha and Rezapour, Rezvaneh},
title = {Master of Deceit: Comparative Analysis of Human and Machine-Generated Deceptive Text},
year = {2025},
isbn = {9798400714832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3717867.3717914},
doi = {10.1145/3717867.3717914},
abstract = {Deception, the intentional act of creating false impressions, has long been studied in human interactions. With the emergence of AI and large language models (LLMs), deception now extends to machine-generated content, raising concerns about distinguishing between human and AI-created content. In this study, we compare deceptive and truthful texts produced by humans and LLMs (GPT-3.5 and GPT-4o) using two datasets; a crowdsourced online Review Dataset and a transcribed interview dataset (MU3D). We replicate the data generation process with LLMs, introducing personas into prompts to examine linguistic differences and potential biases. Using LIWC, we analyze word choice, complexity, and cognitive patterns across human- and LLM-generated deception and truthful texts. Our findings show that LLM-generated deception differs significantly from human deception, exhibiting greater verbosity, formality, and lexical sophistication, while human deception is more socially driven, relying more on social references, interpersonal cues, and natural conversational patterns. Despite improvements in LLMs, context-dependent biases remain embedded in LLM-generated texts, emphasizing the need for stronger bias mitigation strategies and responsible AI deployment. Our study identifies key linguistic markers that differentiate LLM-generated from human deception and highlights the importance of assessing hidden biases and potential risks in AI-generated deceptive text and misinformation.},
booktitle = {Proceedings of the 17th ACM Web Science Conference 2025},
pages = {189–198},
numpages = {10},
keywords = {large language models, deception detection, text generation, natural language processing, bias analysis},
location = {
},
series = {Websci '25}
}

@inproceedings{10.1145/3678884.3681921,
author = {Progga, Farhat Tasnim and Khan, Amal and Rubya, Sabirat},
title = {Large Language Models and Personalized Storytelling for Postpartum Wellbeing},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678884.3681921},
doi = {10.1145/3678884.3681921},
abstract = {The study explored the potential of large language models (LLMs) (advanced AI trained models to understand and generate human-like language) like ChatGPT to generate personalized narratives about perinatal mental health concerns and wellbeing. With perinatal mental health concerns affecting many women and technology playing a role in addressing their challenges, the study investigated LLMs' ability to craft relatable stories considering emotional nuances, cultural sensitivity, and narrative variation. Of the 45 stories generated, 85% (n=38) adhered to prompts. Qualitative analysis identified challenges with relatability, such as repetitive content and diminished empathy compared to user-generated stories. However, despite limitations, AI-generated stories showcased the potential for raising awareness about perinatal wellbeing.},
booktitle = {Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
pages = {653–657},
numpages = {5},
location = {San Jose, Costa Rica},
series = {CSCW Companion '24}
}

@inproceedings{10.1145/3649405.3659504,
author = {Bernstein, Seth and Denny, Paul and Leinonen, Juho and Littlefield, Matt and Hellas, Arto and MacNeil, Stephen},
title = {Analyzing Students' Preferences for LLM-Generated Analogies},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659504},
doi = {10.1145/3649405.3659504},
abstract = {Introducing students to new concepts in computer science can often be challenging, as these concepts may differ significantly from their existing knowledge and conceptual understanding. To address this, we employed analogies to help students connect new concepts to familiar ideas. Specifically, we generated analogies using large language models (LLMs), namely ChatGPT, and used them to help students make the necessary connections. In this poster, we present the results of our survey, in which students were provided with two analogies relating to different computing concepts, and were asked to describe the extent to which they were accurate, interesting, and useful. This data was used to determine how effective LLM-generated analogies can be for teaching computer science concepts, as well as how responsive students are to this approach.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {812},
numpages = {1},
keywords = {analogies, computer science education, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3672608.3707848,
author = {Chen, Bingxiang and Tackman, John and Set\"{a}l\"{a}, Manu and Poranen, Timo and Zhang, Zheying},
title = {Integrating Access Control with Retrieval-Augmented Generation: A Proof of Concept for Managing Sensitive Patient Profiles},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707848},
doi = {10.1145/3672608.3707848},
abstract = {With advancements in Generative AI, particularly large language models (LLMs), there is significant potential for developing domain-specific AI chatbots. However, training on sensitive data, such as healthcare information, poses risks of unauthorized data leakage. Access control is essential to ensure that only authorized personnel can access sensitive training documents. This study proposes integrating fine-grained access control with Retrieval-Augmented Generation (RAG), a promising architecture that enables models to retrieve external data and generate contextually accurate responses. By combining RAG with access control, Generative AI can produce answers strictly based on documents permitted by user rights. This is particularly critical in healthcare, where only authorized personnel, such as doctors and nurses involved in treatment, should access patient-specific information. Using the design science research methodology, we developed a proof-of-concept system and evaluated it with patient profiles and varying access permissions. While not solving all data management challenges, this approach offers a promising solution for secure, domain-specific knowledge applications within LLMs.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {915–919},
numpages = {5},
keywords = {large language models, retrieval-augmented generation, RAG, access control},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@article{10.1145/3735636,
author = {Yang, Guang and Zhou, Yu and Cheng, Wei and Zhang, Xiangyu and Chen, Xiang and Zhuo, Terry Yue and Liu, Ke and Zhou, Xin and Lo, David and Chen, Taolue},
title = {Less is More: DocString Compression in Code Generation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3735636},
doi = {10.1145/3735636},
abstract = {The widespread use of Large Language Models (LLMs) in software engineering has intensified the need for improved model and resource efficiency. In particular, for neural code generation, LLMs are used to translate function/method signature and DocString to executable code. DocStrings, which capture user requirements for the code and are typically used as the prompt for LLMs, often contain redundant information. Recent advancements in prompt compression have shown promising results in Natural Language Processing (NLP), but their applicability to code generation remains uncertain. Our empirical study show that the state-of-the-art prompt compression methods achieve only about 10% reduction, as further reductions would cause significant performance degradation. In our study, we propose a novel compression method, ShortenDoc, dedicated to DocString compression for code generation. Our experiments on six code generation datasets, five open-source LLMs (1B to 10B parameters) and one closed-source LLM GPT-4o confirm that ShortenDoc achieves 25–40% compression while preserving the quality of generated code, outperforming other baseline methods at similar compression levels. The benefit of this method is to improve efficiency and reduce the token processing cost while maintaining the quality of the generated code, especially when calling third-party APIs.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {DocString Compression, Code Generation, Large Language Model}
}

@inproceedings{10.1145/3613905.3647957,
author = {Lieb, Anna and Goel, Toshali},
title = {Student Interaction with NewtBot: An LLM-as-tutor Chatbot for Secondary Physics Education},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3647957},
doi = {10.1145/3613905.3647957},
abstract = {Chatbots based on state-of-the-art large language models (LLMs) hold potential to act as beneficial educational tools. However, challenges to LLMs in education include concerns about not only the accuracy and interpretability of AI-generated text, but also about productive student engagement and positive user experience with LLM chatbots. In this paper, we introduce a physics education chatbot called NewtBot. We designed NewtBot to act as a personalized automated tutor to support secondary students’ learning as they complete physics tasks. NewtBot’s web interface has a modifiable back-end that internally prompts GPT-3.5 to produce different LLM behaviors. In a user study with German secondary school students (n=50), we evaluated student interactions with three different configurations of the GPT-3.5 back-end: a general-purpose “baseline” model, a setting-specific “tutor” model, and a problem-specific “feedback” model. We find that students had overall positive experiences using NewtBot, and that the setting-specific “tutor” model had the highest user experience ratings. Additionally, despite a majority of participants (72%) expressing apprehensions about using chatbots for school, 70% said they would use NewtBot to help with their physics school work.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {614},
numpages = {8},
keywords = {ChatGPT, GPT 3.5, chatbot, large language models, physics education, prompt engineering, secondary education, tutor},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3641554.3701827,
author = {Renzella, Jake and Vassar, Alexandra and Lee Solano, Lorenzo and Taylor, Andrew},
title = {Compiler-Integrated, Conversational AI for Debugging CS1 Programs},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701827},
doi = {10.1145/3641554.3701827},
abstract = {Large Language Models (LLMs) present a transformative opportunity to address longstanding challenges in computing education. This paper presents a conversational AI extension to an LLM-enhanced C/C++ compiler which generates pedagogically sound programming error explanations. Our new tool, DCC Sidekick, retains compiler integration, allowing students to see their code, error messages, and stack frames alongside a conversational AI interface. Compiler context improves error explanations, and provides a seamless development experience. We present quantitative analyses of Sidekick's usage and engagement patterns in a large CS1 course. In the first seven weeks of use, 959 students initiated 11,222 DCC Sidekick sessions, generating 17,982 error explanations. Over half of all conversations occur outside of business hours, highlighting the value of these always-available tools. Early results indicate strong adoption of conversational AI debugging tools, demonstrating scalability in supporting large CS1 courses. We share implementation details and lessons learned, offering guidance to educators considering integrating AI tools with pedagogical guardrails.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {994–1000},
numpages = {7},
keywords = {ai in education, cs1, generative ai, programming error messages},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705212,
author = {Baek, Jeonghun and Yamazaki, Tetsuro and Morihata, Akimasa and Mori, Junichiro and Yamakata, Yoko and Taura, Kenjiro and Chiba, Shigeru},
title = {Leveraging LLM for Detecting and Explaining LLM-generated Code in Python Programming Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705212},
doi = {10.1145/3641555.3705212},
abstract = {As large language models (LLMs) have become more advanced, generating code to solve exercises in programming courses has become significantly easier. However, this convenience raises the concern of over-reliance on these tools, potentially hindering students from developing independent coding skills. To address this concern, we introduce an LLM-based detector that not only detects LLM-generated code but also explains the reasons for its judgments. These reasons provide insight into the characteristics of LLM-generated code, enhancing transparency in the detection process. We evaluate the detector in an introductory Python programming course, achieving over 99% accuracy. Additionally, instructors manually reviewed the reasons provided by the detector and verified that 64.7% of reasons for classifying code as LLM-generated were appropriate. These reasons can also serve as feedback, helping students improve their coding skills by understanding the characteristics of expert-level LLM-generated code.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1369–1370},
numpages = {2},
keywords = {detecting and explaining llm-generated code, large language model, llm-based detector, llm-generated code, python programming courses, reasons for judgment},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3714461,
author = {Weyssow, Martin and Zhou, Xin and Kim, Kisub and Lo, David and Sahraoui, Houari},
title = {Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3714461},
doi = {10.1145/3714461},
abstract = {Large language models (LLMs) demonstrate impressive capabilities to generate accurate code snippets given natural language intents in a zero-shot manner, i.e., without the need for specific fine-tuning. While prior studies have highlighted the advantages of fine-tuning LLMs, this process incurs high computational costs, making it impractical in resource-scarce environments, particularly for models with billions of parameters. To address these challenges, previous research explored in-context learning (ICL) and retrieval-augmented generation (RAG) as strategies to guide the LLM generative process with task-specific prompt examples. However, ICL and RAG introduce inconveniences, such as the need for designing contextually relevant prompts and the absence of learning task-specific parameters, thereby limiting downstream task performance. In this context, we foresee parameter-efficient fine-tuning (PEFT) as a promising approach to efficiently specialize LLMs to task-specific data while maintaining reasonable resource consumption. In this paper, we deliver a comprehensive study of PEFT techniques for LLMs in the context of automated code generation. Our comprehensive investigation of PEFT techniques for LLMs reveals their superiority and potential over ICL and RAG across a diverse set of LLMs and three representative Python code generation datasets: Conala, CodeAlpacaPy, and APPS. Furthermore, our study highlights the potential for tuning larger LLMs and significant reductions in memory usage by combining PEFT with quantization. Therefore, this study opens opportunities for broader applications of PEFT in software engineering scenarios.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {code generation, large language models, parameter-efficient fine-tuning, quantization, retrieval-augmented generation, empirical study}
}

@inproceedings{10.1145/3708597.3708606,
author = {Han, Xiaotian},
title = {Generative Artificial Intelligence for Future Education: Current Research Status, Hot Spots, and Research Trends},
year = {2025},
isbn = {9798400718304},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708597.3708606},
doi = {10.1145/3708597.3708606},
abstract = {Generative artificial intelligence (GenAI), leveraging deep learning techniques such as neural networks, is revolutionizing education. This study explores the current research status, key areas, and emerging trends by analyzing 2,856 papers from 2014 to 2023 using CiteSpace software. Key findings reveal that: 1. The focus of GenAI research has shifted towards large language models, such as ChatGPT, especially since 2022. 2. Major research contributions come from China, the U.S., and South Korea, with China leading in institutional involvement. 3. Research trends indicate growing interest in AI applications for immersive education, deep learning models, and medical education. 4. Ethical considerations and data processing methodologies, including anomaly detection and data augmentation, are crucial emerging topics in the field. This paper outlines the most active research clusters and provides future directions for interdisciplinary applications and ethical AI.},
booktitle = {Proceedings of the 2024 8th International Conference on Algorithms, Computing and Systems},
pages = {56–61},
numpages = {6},
keywords = {Generative artificial intelligence 1, current research status 3, future educationn2, hot spots 4, research trends 5},
location = {
},
series = {ICACS '24}
}

@inproceedings{10.1145/3706599.3719899,
author = {Neshaei, Seyed Parsa and Tashkovska, Matea and Mejia-Domenzain, Paola and Wambsganss, Thiemo and K\"{a}ser, Tanja},
title = {User-centric Reflective Writing Assistance: Leveraging RAG for Enhanced Personalized Support},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719899},
doi = {10.1145/3706599.3719899},
abstract = {Reflective writing, a valuable educational practice, helps learners analyze their thoughts and experiences. However, learners often struggle to translate their experiences and thoughts into written form. Recent advancements in large language models (LLMs) have demonstrated their potential for writing assistance and learning support, but they lack personalization, as their responses are not typically grounded in the personal experiences and prior knowledge states of individual learners. Retrieval-augmented generation (RAG) offers the potential to enable LLMs to incorporate learners’ past data to provide personalized support. Despite potential, RAG has yet to be fully evaluated for reflective writing. In this late-breaking work, we introduce Memoire, a reflective writing assistant using RAG to provide learners with personalized suggestions. We evaluate the effectiveness of our tool on 100 students in a classroom study, comparing three types of suggestions identified in prior research. Our study provides early insights into the potential of RAG-based methods to support reflective writing among students.1},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {562},
numpages = {8},
keywords = {reflective writing, intelligent writing assistants, retrieval-augmented generation, large language models},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3654777.3676374,
author = {Xie, Liwenhan and Zheng, Chengbo and Xia, Haijun and Qu, Huamin and Zhu-Tian, Chen},
title = {WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676374},
doi = {10.1145/3654777.3676374},
abstract = {Large language models (LLMs) support data analysis through conversational user interfaces, as exemplified in OpenAI’s ChatGPT (formally known as Advanced Data Analysis or Code Interpreter). Essentially, LLMs produce code for accomplishing diverse analysis tasks. However, presenting raw code can obscure the logic and hinder user verification. To empower users with enhanced comprehension and augmented control over analysis conducted by LLMs, we propose a novel approach to transform LLM-generated code into an interactive visual representation. In the approach, users are provided with a clear, step-by-step visualization of the LLM-generated code in real time, allowing them to understand, verify, and modify individual data operations in the analysis. Our design decisions are informed by a formative study (N=8) probing into user practice and challenges. We further developed a prototype named WaitGPT and conducted a user study (N=12) to evaluate its usability and effectiveness. The findings from the user study reveal that WaitGPT facilitates monitoring and steering of data analysis performed by LLMs, enabling participants to enhance error detection and increase their overall confidence in the results.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {119},
numpages = {14},
keywords = {Code Verification, Conversational Data Analysis, Generative AI, Human-AI Interaction, LLM Agent, Visual Programming},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3641555.3705141,
author = {Alba, Charles and Xi, Wang and Wang, Chenyu and An, Ruopeng},
title = {ChatGPT Comes to Campus: Unveiling Core Themes in AI Policies Across U.S. Universities with Large Language Models},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705141},
doi = {10.1145/3641555.3705141},
abstract = {The release of popular generative artificial intelligence (AI) tools like ChatGPT have prompted universities to introduce new policies or update existing ones. Currently, most institutions adapt their policies reactively as challenges arise, often without adopting a systematic framework, with minimal guidance and limited knowledge of the approaches taken by other institutions across the United States (U.S.). This study aims to bridge this gap by identifying core themes surrounding AI policies and guidelines across the top 50 U.S. universities. Given the labor- and time-intensive nature required to manually synthesize multiple policy documents across many institutions, we leverage large language models (LLMs) to identify common and prevalent themes. Our framework first summarizes AI policies at the institutional level, followed by the generation of multiple sets of themes through an iterative process of prompt chaining and self-refinement. Finally, the common themes from these distinct sets were consolidated. This framework is designed to address potential flaws in pre-trained LLMs, such as hallucinations. Seven distinct themes are uncovered: (1) academic integrity and responsible AI use, (2) communication of AI policies, (3) data privacy and security concerns, (4) ethical considerations in AI use, (5) continuous adaptation and policy evolution, (6) documentation and transparency in AI usage, and (7) instructor discretion in AI integration. Our work lays the foundation for future analyses or recommendations in developing comprehensive and equitable AI policies. Furthermore, leveraging LLMs allows us to respond swiftly to developments surrounding AI policies across universities.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1359–1360},
numpages = {2},
keywords = {AI policies at universities, ChatGPT, academic integrity, generative AI, generative AI use in classrooms, large language models, teaching with AI},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649217.3653533,
author = {Bernstein, Seth and Denny, Paul and Leinonen, Juho and Kan, Lauren and Hellas, Arto and Littlefield, Matt and Sarsa, Sami and Macneil, Stephen},
title = {"Like a Nesting Doll": Analyzing Recursion Analogies Generated by CS Students Using Large Language Models},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653533},
doi = {10.1145/3649217.3653533},
abstract = {Grasping complex computing concepts often poses a challenge for students who struggle to anchor these new ideas to familiar experiences and understandings. To help with this, a good analogy can bridge the gap between unfamiliar concepts and familiar ones, providing an engaging way to aid understanding. However, creating effective educational analogies is difficult even for experienced instructors. We investigate to what extent large language models (LLMs), specifically ChatGPT, can provide access to personally relevant analogies on demand. Focusing on recursion, a challenging threshold concept, we conducted an investigation analyzing the analogies generated by more than 350 first-year computing students. They were provided with a code snippet and tasked to generate their own recursion-based analogies using ChatGPT, optionally including personally relevant topics in their prompts. We observed a great deal of diversity in the analogies produced with student-prescribed topics, in contrast to the otherwise generic analogies, highlighting the value of student creativity when working with LLMs. Not only did students enjoy the activity and report an improved understanding of recursion, but they described more easily remembering analogies that were personally and culturally relevant.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {122–128},
numpages = {7},
keywords = {analogies, computing education, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649217.3653624,
author = {Grande, Virginia and Kiesler, Natalie and Francisco R., Mar\'{\i}a Andre\'{\i}na},
title = {Student Perspectives on Using a Large Language Model (LLM) for an Assignment on Professional Ethics},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653624},
doi = {10.1145/3649217.3653624},
abstract = {The advent of Large Language Models (LLMs) started a serious discussion among educators on how LLMs would affect, e.g., curricula, assessments, and students' competencies. Generative AI and LLMs also raised ethical questions and concerns for computing educators and professionals.This experience report presents an assignment within a course on professional competencies, including some related to ethics, that computing master's students need in their careers. For the assignment, student groups discussed the ethical process by Lennerfors et al. by analyzing a case: a fictional researcher considers whether to attend the real CHI 2024 conference in Hawaii. The tasks were (1) to participate in in-class discussions on the case, (2) to use an LLM of their choice as a discussion partner for said case, and (3) to document both discussions, reflecting on their use of the LLM.Students reported positive experiences with the LLM as a way to increase their knowledge and understanding, although some identified limitations. The LLM provided a wider set of options for action in the studied case, including unfeasible ones. The LLM would not select a course of action, so students had to choose themselves, which they saw as coherent.From the educators' perspective, there is a need for more instruction for students using LLMs: some students did not perceive the tools as such but rather as an authoritative knowledge base. Therefore, this work has implications for educators considering the use of LLMs as discussion partners or tools to practice critical thinking, especially in computing ethics education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {478–484},
numpages = {7},
keywords = {chatgpt, ethics, experience report, large language models, llms, student perspective},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3706599.3719677,
author = {Qian, Crystal and Liu, Michael Xieyang and Reif, Emily and Simon, Grady and Hussein, Nada and Clement, Nathan and Wexler, James and Cai, Carrie J and Terry, Michael and Kahng, Minsuk},
title = {LLM Adoption in Data Curation Workflows: Industry Practices and Insights},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719677},
doi = {10.1145/3706599.3719677},
abstract = {As large language models (LLMs) grow more proficient at processing unstructured text data, they offer new opportunities to enhance data curation workflows. This paper presents findings from a user study involving 12 industry practitioners from various roles and organizations across a large technology company (N=12). The study examines their data curation workflows before and after LLM adoption, using two custom design probes that integrate LLMs into existing tools. Our study reveals a shift from heuristics-driven, bottom-up curation to insights-driven, top-down workflows supported by LLMs. To navigate increasingly complex data landscapes, practitioners supplement traditional subject-expert-created “golden datasets” with LLM-generated “silver” datasets and rigorously validated “super golden” datasets curated by diverse experts. This research highlights the transformative potential of LLMs in large-scale analysis of unstructured data and highlights opportunities for further tool development.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {370},
numpages = {10},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3696379,
author = {Bui, Minh-Thanh and Boffa, Matteo and Valentim, Rodolfo Vieira and Navarro, Jose Manuel and Chen, Fuxing and Bao, Xiaosheng and Houidi, Zied Ben and Rossi, Dario},
title = {A Systematic Comparison of Large Language Models Performance for Intrusion Detection},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CoNEXT4},
url = {https://doi.org/10.1145/3696379},
doi = {10.1145/3696379},
abstract = {We explore the capabilities of Large Language Models (LLMs) to assist or substitute devices (i.e., firewalls) and humans (i.e., security experts) respectively in the detection and analysis of security incidents. We leverage transformer-based technologies, from relatively small to foundational sizes, to address the problem of correctly identifying the attack severity (and accessorily identifying and explaining the attack type). We contrast a broad range of LLM techniques (prompting, retrieval augmented generation, and fine-tuning of several models) using state-of-the-art machine learning models as a baseline. Using proprietary data from commercial deployment, our study provides an unbiased picture of the strengths and weaknesses of LLM for intrusion detection.},
journal = {Proc. ACM Netw.},
month = nov,
articleno = {22},
numpages = {23},
keywords = {computing methodologies, firewalls, intrusion detection systems, machine learning, natural language processing, security and privacy}
}

@inproceedings{10.1145/3701551.3703577,
author = {Tian, Yijun and Han, Yikun and Chen, Xiusi and Wang, Wei and Chawla, Nitesh V.},
title = {Beyond Answers: Transferring Reasoning Capabilities to Smaller LLMs Using Multi-Teacher Knowledge Distillation},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703577},
doi = {10.1145/3701551.3703577},
abstract = {Transferring the reasoning capability from stronger large language models (LLMs) to smaller ones has been quite appealing, as smaller LLMs are more flexible to deploy with less expense. Among the existing solutions, knowledge distillation stands out due to its outstanding efficiency and generalization. However, existing methods suffer from several drawbacks, including limited knowledge diversity and the lack of rich contextual information. To solve the problems and facilitate the learning of compact language models, we propose TinyLLM, a new knowledge distillation paradigm to learn a small student LLM from multiple large teacher LLMs. In particular, we encourage the student LLM to not only generate the correct answers but also understand the rationales behind these answers. Given that different LLMs possess diverse reasoning skills, we guide the student model to assimilate knowledge from various teacher LLMs. We further introduce an in-context example generator and a teacher-forcing Chain-of-Thought strategy to ensure that the rationales are accurate and grounded in contextually appropriate scenarios. Extensive experiments on six datasets across two reasoning tasks demonstrate the superiority of our method. Results show that TinyLLM can outperform large teacher LLMs significantly, despite a considerably smaller model size. The source code is available at: https://github.com/YikunHan42/TinyLLM.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {251–260},
numpages = {10},
keywords = {knowledge distillation, knowledge reasoning, large language models},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3706598.3713698,
author = {Yarmand, Matin and Reed, Courtney N. and Tandon, Udayan and Hekler, Eric B. and Weibel, Nadir and Wang, April Yi},
title = {Towards Dialogic and On-Demand Metaphors for Interdisciplinary Reading},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713698},
doi = {10.1145/3706598.3713698},
abstract = {The interdisciplinary field of Human-Computer Interaction (HCI) thrives on productive engagement with different domains, yet this engagement often breaks due to idiosyncratic writing styles and unfamiliar concepts. Inspired by the dialogic model of abstract metaphors, as well as the potential of Large Language Models (LLMs) to produce on-demand support, we investigate the use of metaphors to facilitate engagement between Science and Technology Studies (STS) and System HCI. Our reflective-style survey with early-career HCI researchers (N=48) reported that limited prior exposure to STS research can hinder perceived openness of the work, and ultimately interest in reading. The survey also revealed that metaphors enhance likelihood to continue reading STS papers, and alternative perspectives can build critical thinking skills to mitigate potential risks of LLM-generated metaphors. We lastly offer a specified model of metaphor exchange (within this generative context) that incorporates alternative perspectives to construct shared understanding in interdisciplinary engagement.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1069},
numpages = {19},
keywords = {Metaphor Exchange, Large Language Models, Reflective Survey},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641554.3701910,
author = {Gonzalez-Maldonado, David and Liu, Jonathan and Franklin, Diana},
title = {Evaluating GPT for use in K-12 Block Based CS Instruction Using a Transpiler and Prompt Engineering},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701910},
doi = {10.1145/3641554.3701910},
abstract = {Though the increased availability of Large Language Models (LLMs) presents significant potential for change in the way students learn to program, the text-based nature of the available tools currently preclude block-based languages from much of that innovation. In an attempt to remedy this, we identify the strengths and weaknesses of using a transpiler to leverage the existing learning in commercially available LLMs and Scratch, a visual block-based programming language.Using only prompt engineering, we evaluate an LLM's performance on two common classroom tasks in a Scratch curriculum. We evaluate the LLM's ability to: 1) Create project solutions that compile and satisfy project requirements and 2) Analyze student projects' completion of project requirements using natural language. In both cases, we find results indicating that prompt-engineering alone is insufficient to reliably produce high-quality results. For projects of medium complexity, the LLM-generated solutions consistently failed to follow correct syntax or, in the few instances with correct syntax, produce correct solutions. When used for auto-grading, we found a correlation between scores assigned by the official Scratch Encore autograder and those generated by the LLM, nevertheless the discrepancies between the 'real' scores and the scores assigned by the LLM remained too great for the tool to be reliable in a classroom setting.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {388–394},
numpages = {7},
keywords = {block based programming, generative ai, k-12, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3663548.3675660,
author = {Seo, JooYoung and Kamath, Sanchita S. and Zeidieh, Aziz and Venkatesh, Saairam and McCurry, Sean},
title = {MAIDR Meets AI: Exploring Multimodal LLM-Based Data Visualization Interpretation by and with Blind and Low-Vision Users},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3675660},
doi = {10.1145/3663548.3675660},
abstract = {This paper investigates how blind and low-vision (BLV) users interact with multimodal large language models (LLMs) to interpret data visualizations. Building upon our previous work on the multimodal access and interactive data representation (MAIDR) framework, our mixed-visual-ability team co-designed maidrAI, an LLM extension providing multiple AI responses to users’ visual queries. To explore generative AI-based data representation, we conducted user studies with 8 BLV participants, tasking them with interpreting box plots using our system. We examined how participants personalize LLMs through prompt engineering, their preferences for data visualization descriptions, and strategies for verifying LLM responses. Our findings highlight three dimensions affecting BLV users’ decision-making process: modal preference, LLM customization, and multimodal data representation. This research contributes to designing more accessible data visualization tools for BLV users and advances the understanding of inclusive generative AI applications.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {57},
numpages = {31},
keywords = {Accessibility, Blind, Data Visualization, Generative AI, Large Language Models, Low Vision, Multimodality, Screen Readers},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@inproceedings{10.1145/3643916.3645030,
author = {Khajezade, Mohamad and Wu, Jie JW and Fard, Fatemeh Hendijani and Rodriguez-Perez, Gema and Shehata, Mohamed Sami},
title = {Investigating the Efficacy of Large Language Models for Code Clone Detection},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3645030},
doi = {10.1145/3643916.3645030},
abstract = {Large Language Models (LLMs) have demonstrated remarkable success in various natural language processing and software engineering tasks, such as code generation. The LLMs are mainly utilized in the prompt-based zero/few-shot paradigm to guide the model in accomplishing the task. GPT-based models are one of the popular ones studied for tasks such as code comment generation or test generation. These tasks are 'generative' tasks. However, there is limited research on the usage of LLMs for 'non-generative' tasks such as classification using the prompt-based paradigm. In this preliminary exploratory study, we investigated the applicability of LLMs for Code Clone Detection (CCD), a non-generative task. By building a mono-lingual and cross-lingual CCD dataset derived from CodeNet, we first investigated two different prompts using ChatGPT to detect Type-4 code clones in Java-Java and Java-Ruby pairs in a zero-shot setting. We then conducted an analysis to understand the strengths and weaknesses of ChatGPT in CCD. ChatGPT surpasses the baselines in cross-language CCD attaining an F1-score of 0.877 and achieves comparable performance to fully fine-tuned models for mono-lingual CCD, with an F1-score of 0.878. Also, the prompt and the difficulty level of the problems has an impact on the performance of ChatGPT. Finally, we provide insights and future directions based on our initial analysis1.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {161–165},
numpages = {5},
keywords = {large language models, code clone detection, zero-shot learning, few-shot learning},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3654777.3676352,
author = {Chung, John Joon Young and Kreminski, Max},
title = {Patchview: LLM-powered Worldbuilding with Generative Dust and Magnet Visualization},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676352},
doi = {10.1145/3654777.3676352},
abstract = {Large language models (LLMs) can help writers build story worlds by generating world elements, such as factions, characters, and locations. However, making sense of many generated elements can be overwhelming. Moreover, if the user wants to precisely control aspects of generated elements that are difficult to specify verbally, prompting alone may be insufficient. We introduce Patchview, a customizable LLM-powered system that visually aids worldbuilding by allowing users to interact with story concepts and elements through the physical metaphor of magnets and dust. Elements in Patchview are visually dragged closer to concepts with high relevance, facilitating sensemaking. The user can also steer the generation with verbally elusive concepts by indicating the desired position of the element between concepts. When the user disagrees with the LLM’s visualization and generation, they can correct those by repositioning the element. These corrections can be used to align the LLM’s future behaviors to the user’s perception. With a user study, we show that Patchview supports the sensemaking of world elements and steering of element generation, facilitating exploration during the worldbuilding process. Patchview provides insights on how customizable visual representation can help sensemake, steer, and align generative AI model behaviors with the user’s intentions.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {77},
numpages = {19},
keywords = {dust and magnet visualization, large language models, worldbuilding},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3657604.3664673,
author = {Fung, Sze Ching Evelyn and Wong, Man Fai and Tan, Chee Wei},
title = {Automatic Feedback Generation on K-12 Students' Data Science Education by Prompting Cloud-based Large Language Models},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664673},
doi = {10.1145/3657604.3664673},
abstract = {Since data science is traditionally an advanced field taught at the college or university level, introducing its concepts to K-12 students can present unique learning challenges. As educational environments increasingly adopt data science curricula for K-12 students, the need for scalable, personalized teaching tools becomes critical. While the integration of large language models (LLMs) in educational environments offers significant potential for scalability and automation, it is important to note that the generated language output may not always be highly suitable for K-12 students. In this paper, we introduce the DSRAG, a novel educational automatic feedback generation framework that leverages Retrieval-Augmented Generation (RAG) and cloud-based LLMs to provide automated and personalized feedback for K-12 students engaged in data science education. DSRAG employs Langchain question-answering and RAG systems to manage educational content and generate feedback on the top of GPT-4. We also demonstrate the framework's capability to simplify complex concepts and align its responses to be pedagogically appropriate and understandable for K-12 students.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {255–258},
numpages = {4},
keywords = {large language models, learning technologies, prompt engineering, retrieval-augmented generation},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3633637.3633648,
author = {Xiao, Le and Shan, Xin and Chen, Xiaolin},
title = {PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation},
year = {2024},
isbn = {9798400707988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633637.3633648},
doi = {10.1145/3633637.3633648},
abstract = {Large language models(LLMS) have shown excellent text generation capabilities, capable of generating fluent human-like responses for many downstream tasks. However, applying large language models to real-world critical tasks remains challenging due to their susceptibility to hallucinations and inability to directly use external knowledge. To cope with the above challenges, this paper proposes PatternGPT, a pattern-driven text generation framework for Large Language Models. Firstly, the framework utilizes the extraction capability of Large Language Models to generate rich and diversified structured and formalized patterns, which facilitates the introduction of external knowledge to do the computation, and then draws on the idea of federated learning to use multiple agents to achieve the sharing in order to obtain more diversified patterns, and finally uses judgment criteria and optimization algorithm to search for high-quality patterns to guide the generation of models. Finally, external knowledge such as judgment criteria and optimization algorithms are used to search for high-quality patterns, and the searched patterns are used to guide model generation. This framework has the advantages of generating diversified patterns, protecting data privacy, combining external knowledge, and improving the quality of generation, which provides an effective method to optimize the text generation capability of large language models, and make it better applied to the field of intelligent dialogue and content generation.},
booktitle = {Proceedings of the 2023 12th International Conference on Computing and Pattern Recognition},
pages = {72–78},
numpages = {7},
keywords = {LLM, framework, pattern, text generation},
location = {Qingdao, China},
series = {ICCPR '23}
}

@inproceedings{10.1145/3701716.3715242,
author = {Shang, Hongwei and Vo, Nguyen and Yadav, Nitin and Zhang, Tian and Puthenputhussery, Ajit and Cai, Xunfan and Chen, Shuyi and Chandran, Prijith and Kang, Changsung},
title = {Knowledge Distillation for Enhancing Walmart E-commerce Search Relevance Using Large Language Models},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715242},
doi = {10.1145/3701716.3715242},
abstract = {Ensuring the products displayed in e-commerce search results are relevant to users' queries is crucial for improving the user experience. With their advanced semantic understanding, deep learning models have been widely used for relevance matching in search tasks. While large language models (LLMs) offer superior ranking capabilities, it is challenging to deploy LLMs in real-time systems due to the high-latency requirements. To leverage the ranking power of LLMs while meeting the low-latency demands of production systems, we propose a novel framework that distills a high-performing LLM into a more efficient, low-latency student model. To help the student model learn more effectively from the teacher model, we first train the teacher LLM as a classification model with soft targets. Then, we train the student model to capture the relevance margin between pairs of products for a given query using mean squared error loss. Instead of using the same training data as the teacher model, we significantly expand the student model's dataset by generating unlabeled data and labeling it with the teacher model's predictions. Experimental results show that the student model's performance continues to improve as the size of the augmented training data increases. In fact, with enough augmented data, the student model can outperform the teacher model. The student model has been successfully deployed in production at Walmart.com with significantly positive metrics.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {449–457},
numpages = {9},
keywords = {e-commerce search, knowledge distillation, llm},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3701716.3717531,
author = {Sayana, Krishna and Vasudeva, Raghavendra and Vasilevski, Yuri and Su, Kun and Hebert, Liam and Pine, James and Pham, Hubert and Jash, Ambarish and Sodhi, Sukhdeep},
title = {Beyond Retrieval: Generating Narratives in Conversational Recommender Systems},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717531},
doi = {10.1145/3701716.3717531},
abstract = {Large Language Models (LLMs) have shown remarkable progress in generating human-quality text and engaging in complex reasoning. This presents a unique opportunity to revolutionize conversational recommender systems by enabling them to generate rich, engaging and personalized narratives that go beyond recommendations. However, the lack of suitable datasets limits research in this area. This paper addresses this challenge by making two key contributions.First, we introduce REGEN Reviews Enhanced with GEnerative Narratives, a new dataset extending the Amazon Product Reviews with rich user narratives. Furthermore, we perform an extensive automated evaluation of the dataset using a rater LLM. Second, the paper introduces a fusion architecture (CF model with an LLM) which serves as a baseline for REGEN. To the best of our knowledge, this represents the first attempt to analyze the capabilities of LLMs in understanding recommender signals and generating rich narratives. We demonstrate that LLMs can effectively learn from simple fusion architectures utilizing interaction-based CF embeddings, and this can be further enhanced using the metadata and personalization data associated with items. Our experiments show that combining CF and content embeddings leads to improvements of 4-12% in key language metrics compared to using either type of embedding individually. We also provide an analysis to interpret their contributions to this new generative task.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2411–2420},
numpages = {10},
keywords = {language models, recommenders},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3695993,
author = {Yu, Yongda and Rong, Guoping and Shen, Haifeng and Zhang, He and Shao, Dong and Wang, Min and Wei, Zhao and Xu, Yong and Wang, Juhong},
title = {Fine-Tuning Large Language Models to Improve Accuracy and Comprehensibility of Automated Code Review},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3695993},
doi = {10.1145/3695993},
abstract = {As code review is a tedious and costly software quality practice, researchers have proposed several machine learning-based methods to automate the process. The primary focus has been on accuracy, that is, how accurately the algorithms are able to detect issues in the code under review. However, human intervention still remains inevitable since results produced by automated code review are not 100% correct. To assist human reviewers in making their final decisions on automatically generated review comments, the comprehensibility of the comments underpinned by accurate localization and relevant explanations for the detected issues with repair suggestions is paramount. However, this has largely been neglected in the existing research. Large language models (LLMs) have the potential to generate code review comments that are more readable and comprehensible by humans, thanks to their remarkable processing and reasoning capabilities. However, even mainstream LLMs perform poorly in detecting the presence of code issues because they have not been specifically trained for this binary classification task required in code review. In this article, we contribute Comprehensibility of Automated Code Review using Large Language Models (Carllm), a novel fine-tuned LLM that has the ability to improve not only the accuracy but, more importantly, the comprehensibility of automated code review, as compared to state-of-the-art pre-trained models and general LLMs.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {14},
numpages = {26},
keywords = {Automated Code Review, Human-machine Collaboration, LLM, LORA}
}

@inproceedings{10.1145/3706468.3706531,
author = {Thomas, Danielle R and Borchers, Conrad and Kakarla, Sanjit and Lin, Jionghao and Bhushan, Shambhavi and Guo, Boyuan and Gatz, Erin and Koedinger, Kenneth R},
title = {Do Tutors Learn from Equity Training and Can Generative AI Assess It?},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706531},
doi = {10.1145/3706468.3706531},
abstract = {Equity is a core concern of learning analytics. However, applications that teach and assess equity skills, particularly at scale are lacking, often due to barriers in evaluating language. Advances in generative AI via large language models (LLMs) are being used in a wide range of applications, with this present work assessing its use in the equity domain. We evaluate tutor performance within an online lesson on enhancing tutors’ skills when responding to students in potentially inequitable situations. We apply a mixed-method approach to analyze the performance of 81 undergraduate remote tutors. We find marginally significant learning gains with increases in tutors’ self-reported confidence in their knowledge in responding to middle school students experiencing possible inequities from pretest to posttest. Both GPT-4o and GPT-4-turbo demonstrate proficiency in assessing tutors ability to predict and explain the best approach. Balancing performance, efficiency, and cost, we determine that few-shot learning using GPT-4o is the preferred model. This work makes available a dataset of lesson log data, tutor responses, rubrics for human annotation, and generative AI prompts. Future work involves leveling the difficulty among scenarios and enhancing LLM prompts for large-scale grading and assessment.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {505–515},
numpages = {11},
keywords = {Tutor Training, Generative AI, Large Language Models, Assessment, Equity},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3625549.3658689,
author = {Nichols, Daniel and Davis, Joshua H. and Xie, Zhaojun and Rajaram, Arjun and Bhatele, Abhinav},
title = {Can Large Language Models Write Parallel Code?},
year = {2024},
isbn = {9798400704130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625549.3658689},
doi = {10.1145/3625549.3658689},
abstract = {Large language models are increasingly becoming a popular tool for software development. Their ability to model and generate source code has been demonstrated in a variety of contexts, including code completion, summarization, translation, and lookup. However, they often struggle to generate code for complex programs. In this paper, we study the capabilities of state-of-the-art language models to generate parallel code. In order to evaluate language models,we create a benchmark, ParEval, consisting of prompts that represent 420 different coding tasks related to scientific and parallel computing. We use ParEval to evaluate the effectiveness of several state-of-the-art open- and closed-source language models on these tasks. We introduce novel metrics for evaluating the performance of generated code, and use them to explore how well each large language model performs for 12 different computational problem types and six different parallel programming models.},
booktitle = {Proceedings of the 33rd International Symposium on High-Performance Parallel and Distributed Computing},
pages = {281–294},
numpages = {14},
keywords = {large language models, parallel code generation, performance evaluation, benchmarking, HPC},
location = {Pisa, Italy},
series = {HPDC '24}
}

@inproceedings{10.1145/3568812.3603476,
author = {Phung, Tung and P\u{a}durean, Victor-Alexandru and Cambronero, Jos\'{e} and Gulwani, Sumit and Kohn, Tobias and Majumdar, Rupak and Singla, Adish and Soares, Gustavo},
title = {Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603476},
doi = {10.1145/3568812.3603476},
abstract = {Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies. State-of-the-art models like OpenAI’s ChatGPT&nbsp;[8] and GPT-4&nbsp;[9] could enhance programming education in various roles, e.g., by acting as a personalized digital tutor for a student, a digital assistant for an educator, and a digital peer for collaborative learning&nbsp;[1, 2, 7]. In our work, we seek to comprehensively evaluate and benchmark state-of-the-art large language models for various scenarios in programming education. Recent works have evaluated several large language models in the context of programming education&nbsp;[4, 6, 10, 11, 12]. However, these works are limited for several reasons: they have typically focused on evaluating a specific model for a specific education scenario (e.g., generating explanations), or have considered models that are already outdated (e.g., OpenAI’s Codex&nbsp;[3] is no longer publicly available since March 2023). Consequently, there is a lack of systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios in programming education. These scenarios are designed to capture distinct roles these models could play, namely digital tutors, assistants, and peers, as discussed above. More concretely, we consider the following six scenarios: (1) program repair, i.e., fixing a student’s buggy program; (2) hint generation, i.e., providing a natural language hint to the student to help resolve current issues; (3) grading feedback, i.e., grading a student’s program w.r.t. a given rubric; (4) peer programming, i.e., completing a partially written program or generating a sketch for the solution program; (5) task creation, i.e., generating new tasks that exercise specific types of concepts or bugs; (6) contextualized explanation, i.e., explaining specific concepts or functions in the context of a given program. Our study uses a mix of quantitative and qualitative evaluation to compare the performance of these models with the performance of human tutors. We conduct our evaluation based on 5 introductory Python programming problems with a diverse set of input/output specifications. For each of these problems, we consider 5 buggy programs based on publicly accessible submissions from geeksforgeeks.org &nbsp;[5] (see Figure&nbsp;1); these buggy programs are picked to capture different types of bugs for each problem. We will provide a detailed analysis of the data and results in a longer version of this poster. Our preliminary results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors’ performance for several scenarios.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {41–42},
numpages = {2},
keywords = {ChatGPT, generative AI, introductory programming education, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@proceedings{10.1145/3688866,
title = {LGM3A '24: Proceedings of the 2nd Workshop on Large Generative Models Meet Multimodal Applications},
year = {2024},
isbn = {9798400711930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the organizing committee, it is our distinct pleasure to extend a warm welcome to the LGM3A Workshop. As Chairs of this conference, we are delighted to bring together a community of scholars, researchers, and professionals from diverse backgrounds, all driven by a shared passion for advancing the frontiers of knowledge in our field.This workshop aims to explore the potential of large generative models to revolutionize the way we interact with multimodal information. A Large Language Model (LLM) represents a sophisticated form of artificial intelligence engineered to comprehend and produce natural language text, exemplified by technologies such as GPT, LLaMA, Flan-T5, ChatGLM, and Qwen, etc. These models undergo training on extensive text datasets, exhibiting commendable attributes including robust language generation, zero-shot transfer capabilities, and In-Context Learning (ICL). With the surge in multimodal content encompassing images, videos, audio, and 3D models over the recent period, Large MultiModal Models (LMMs) have seen significant enhancements. These improvements enable the augmentation of conventional LLMs to accommodate multimodal inputs or outputs, as seen in BLIP, Flamingo, KOSMOS, LLaVA, Gemini, GPT-4, etc. Concurrently, certain research initiatives have delved into generating specific modalities, with Kosmos2 and MiniGPT-5 focusing on image generation, and SpeechGPT on speech production. There are also endeavors to integrate LLMs with external tools to achieve a near any-to-any multimodal comprehension and generation capacity, illustrated by projects like Visual-ChatGPT, ViperGPT, MMREACT, HuggingGPT, and AudioGPT. Collectively, these models, spanning not only text and image generation but also other modalities, are referred to as large generative models.},
location = {Melbourne VIC, Australia}
}

@inproceedings{10.1145/3706599.3720282,
author = {Mhasakar, Manas and Baker-Ramos, Rachel and Carter, Benjamin and Helekahi-Kaiwi, Evyn-Bree and Hester, Josiah},
title = {"I Would Never Trust Anything Western": Kumu (Educator) Perspectives on Use of LLMs for Culturally Revitalizing CS Education in Hawaiian Schools},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720282},
doi = {10.1145/3706599.3720282},
abstract = {As large language models (LLMs) become increasingly integrated into educational technology, their potential to assist in developing curricula has gained interest among educators. Despite this growing attention, their applicability in culturally responsive Indigenous educational settings like Hawai‘i’s public schools and Kaiapuni (immersion language) programs, remains understudied. Additionally, ‘undefinedlelo Hawai‘i, the Hawaiian language, as a low-resource language, poses unique challenges and concerns about cultural sensitivity and the reliability of generated content. Through surveys and interviews with kumu (educators), this study explores the perceived benefits and limitations of using LLMs for culturally revitalizing computer science (CS) education in Hawaiian public schools with Kaiapuni programs. Our findings highlight AI’s time-saving advantages while exposing challenges such as cultural misalignment and reliability concerns. We conclude with design recommendations for future AI tools to better align with Hawaiian cultural values and pedagogical practices, towards the broader goal of trustworthy, effective, and culturally grounded AI technologies.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {13},
numpages = {10},
keywords = {Culturally responsive pedagogy, Artificial Intelligence in education, Culturally-relevant CS, Hawaiian Immersion Language Schools, Large Language Models, Human-centered AI, Education technology, Indigenous knowledge, Low-resource languages},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3672459,
author = {Dong, Yihong and Jiang, Xue and Jin, Zhi and Li, Ge},
title = {Self-Collaboration Code Generation via ChatGPT},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {7},
issn = {1049-331X},
url = {https://doi.org/10.1145/3672459},
doi = {10.1145/3672459},
abstract = {Although large language models (LLMs) have demonstrated remarkable code-generation ability, they still struggle with complex tasks. In real-world software development, humans usually tackle complex tasks through collaborative teamwork, a strategy that significantly controls development complexity and enhances software quality. Inspired by this, we present a self-collaboration framework for code generation employing LLMs, exemplified by ChatGPT. Specifically, through role instructions, (1) Multiple LLM agents act as distinct “experts,” each responsible for a specific subtask within a complex task; (2) Specify the way to collaborate and interact, so that different roles form a virtual team to facilitate each other’s work, ultimately the virtual team addresses code generation tasks collaboratively without the need for human intervention. To effectively organize and manage this virtual team, we incorporate software-development methodology into the framework. Thus, we assemble an elementary team consisting of three LLM roles (i.e., analyst, coder, and tester) responsible for software development’s analysis, coding, and testing stages. We conduct comprehensive experiments on various code-generation benchmarks. Experimental results indicate that self-collaboration code generation relatively improves 29.9–47.1% Pass@1 compared to the base LLM agent. Moreover, we showcase that self-collaboration could potentially enable LLMs to efficiently handle complex repository-level tasks that are not readily solved by the single LLM agent.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {189},
numpages = {38},
keywords = {Code generation, large language models, multi-agent collaboration, software development}
}

@inproceedings{10.1145/3713081.3731748,
author = {Zhao, Shengming and Wang, Jiawei},
title = {Best practice for supply chain in LLM-assisted medical applications},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3731748},
doi = {10.1145/3713081.3731748},
abstract = {The application of large language models in medical applications is crucial for enhancing diagnostic accuracy, improving patient communication, and boosting healthcare efficiency. Their ability to process vast amounts of data, generate concise information, and automate tasks positions LLM applications as transformative tools. Recent studies and real-world examples underscore the importance of delivering secure and responsible LLM-assisted applications. In this manuscript, we outline our intention of uncovering best software practices in the supply chain of LLM medical applications.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {174–177},
numpages = {4},
keywords = {software best practice, large language models, medical system, software supply chain},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@inproceedings{10.1145/3658644.3691384,
author = {Fu, Weimin and Zhao, Yifang and Jin, Yier and Guo, Xiaolong},
title = {Poster: Enhance Hardware Domain Specific Large Language Model with Reinforcement Learning for Resilience},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3691384},
doi = {10.1145/3658644.3691384},
abstract = {To enhance the performance of large language models (LLMs) on hardware design tasks, we focus on training with reinforcement learning(RL) to improve LLMs' syntax synthesis and functional verification performance. We observed significant gains in power, performance, and area (PPA) metrics by applying RL. Specifically, DeepSeek Code saw a 23.6% performance increase, while the RTLCoder improved by 7.86%. Our findings demonstrate the effectiveness of RL in refining LLMs for more accurate hardware generation, considering power and area consumption. This approach offers a promising direction for generating hardware resilient to side-channel attacks in computer systems.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {5060–5062},
numpages = {3},
keywords = {eda tools, hardware security, large language model},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3657604.3664640,
author = {Morales-Chan, Miguel and Amado-Salvatierra, Hector R. and Hernandez-Rizzardini, Rocael},
title = {AI-Driven Content Creation: Revolutionizing Educational Materials},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664640},
doi = {10.1145/3657604.3664640},
abstract = {The integration of Artificial Intelligence (AI) into the field of education is an unprecedented trend with the potential to revolutionize teaching approaches and significantly improve the overall learning experience. This workshop offers an opportunity for a strategic implementation of generative artificial intelligence in higher education, demonstrating its capacity to substantially enhance the creation and customization of digital educational materials. It is essential for educators to possess the capacity to utilize generative artificial intelligence tools, specifically when it comes to developing prompts for Large Language Models (LLMs). In addition to fostering a more interactive learning environment, these LLMs are driving the transition to educational systems that are more autonomous and adaptable. An in-depth exploration of the pragmatic and ethical aspects of generative AI implementation is undertaken to equip educators with the necessary knowledge and skills to employ AI in a responsible manner, thereby cultivating an engaging and equitable learning environment. This workshop was prepared based on successful previous experiences in different conferences and meetings in Spain, Portugal, Germany, M\'{e}xico, Guatemala, Colombia, and USA.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {556–558},
numpages = {3},
keywords = {LLMs, artificial intelligence, generative AI, prompt engineering},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3706598.3713554,
author = {Zindulka, Tim and Sekowski, Jannek Maximilian and Lehmann, Florian and Buschek, Daniel},
title = {Exploring Mobile Touch Interaction with Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713554},
doi = {10.1145/3706598.3713554},
abstract = {Interacting with Large Language Models (LLMs) for text editing on mobile devices currently requires users to break out of their writing environment and switch to a conversational AI interface. In this paper, we propose to control the LLM via touch gestures performed directly on the text. We first chart a design space that covers fundamental touch input and text transformations. In this space, we then concretely explore two control mappings: spread-to-generate and pinch-to-shorten, with visual feedback loops. We evaluate this concept in a user study (N=14) that compares three feedback designs: no visualisation, text length indicator, and length + word indicator. The results demonstrate that touch-based control of LLMs is both feasible and user-friendly, with the length + word indicator proving most effective for managing text generation. This work lays the foundation for further research into gesture-based interaction with LLMs on touch devices.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {727},
numpages = {21},
keywords = {Writing assistance, Large language models, Human-AI interaction, Mobile interaction, Touch interaction, Direct manipulation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3701047.3701074,
author = {Wei, Xueling},
title = {KPI-based enterprise management decision-making system Artificial Intelligence Generated Content modeling},
year = {2025},
isbn = {9798400711688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701047.3701074},
doi = {10.1145/3701047.3701074},
abstract = {In terms of business decision-making, there are still issues to be resolved regarding the intelligence of key performance indicators. To address this technical problem, from the perspective of Artificial Intelligence Generated Content, modeling methods such as support vector machines, random search, and machine learning for key performance indicators (KPI) in business decision-making systems have been proposed. The system integrates with large language models, driving the generative efficiency and accuracy of KPI data cleaning, feature extraction, and model optimization training. Using MATLAB to conduct predictive simulation experiments on the integrated system, compared to general information systems for KPIs that do not utilize large language models or Artificial Intelligence Generated Content, the volume of reference data for business decision-making based on large language models increased by 93.61 times, and decision-making efficiency improved by 36.59%, indicating that the Artificial Intelligence Generated Content modeling scheme for business decision-making systems based on operational KPIs is feasible.},
booktitle = {Proceedings of the 2024 2nd International Conference on Communication Networks and Machine Learning},
pages = {147–151},
numpages = {5},
keywords = {Artificial Intelligence Generated Content, KPI, business decision-making},
location = {
},
series = {CNML '24}
}

@inproceedings{10.1145/3696673.3723053,
author = {Vasudevan, Poonkuzhali and Reddivari, Sandeep},
title = {The Role of Generative AI Models in Requirements Engineering: A Systematic Literature Review},
year = {2025},
isbn = {9798400712777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696673.3723053},
doi = {10.1145/3696673.3723053},
abstract = {The software engineering field is experiencing rapid growth, driven by recent advancements in Artificial Intelligence (AI), particularly in Generative AI (GenAI) and Large Language Models (LLMs). Requirements Engineering (RE), a critical phase in software development, involves gathering and defining software requirements. However, research on the impact of GenAI and LLMs within RE remains limited. This paper examines the adoption of GenAI in RE, with the aim of exploring its practical implications, identifying current research trends, and highlighting areas for future development. To achieve this, a systematic literature review was conducted, addressing three research questions and analyzing 44 studies published over the past decade. The findings reveal that GenAI models, especially LLMs, are extensively employed in a variety of RE tasks, underscoring the versatility and potential of LLMs in enhancing the RE process.},
booktitle = {Proceedings of the 2025 ACM Southeast Conference},
pages = {188–194},
numpages = {7},
keywords = {requirements engineering, generative AI, large language models},
location = {Southeast Missouri State University, Cape Girardeau, MO, USA},
series = {ACMSE 2025}
}

@article{10.1145/3709154,
author = {Tariq, Amara and Trivedi, Shubham and Urooj, Aisha and Ramasamy, Gokul and Fathizadeh, Sam and Stib, Matthew and Tan, Nelly and Patel, Bhavik and Banerjee, Imon},
title = {Patient-centric Summarization of Radiology Findings Using Two-step Training of Large Language Models},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
url = {https://doi.org/10.1145/3709154},
doi = {10.1145/3709154},
abstract = {Education-level or socioeconomic background of patients may dictate their ability to understand medical jargon. Inability to understand primary findings from a radiology report may lead to unnecessary anxiety among patients or missed follow up. We aim to meet this challenge by developing a patient-sensitive summarization model for radiology reports. We selected computed tomography (CT) exams of chest as a use-case and collected 7,000 studies from Mayo Clinic. Summarization model was built on top of the T5 large language model (LLM) as our experiments indicated that its text-to-text transfer architecture was suited for abstractive text summarization, resulting in a model with 0.77B trainable parameters. Noisy ground truth for model training was collected by prompting LLaMA-13B model. We recruited experts (board-certified radiologists) and laymen to manually evaluate model-generated summaries generated by model. Our model rarely missed information as marked by majority opinion of radiologists. Laymen indicated 63% improvement in their understanding by reading model-generated layman summaries. Comparison with zero-shot performance of ChatGPT indicated that the proposed model reduced the rate of hallucination by half and rate of missing important information by fivefold. The proposed model can generate reliable summaries for radiology reports understandable by patients with vastly different levels of medical knowledge.},
journal = {ACM Trans. Comput. Healthcare},
month = apr,
articleno = {21},
numpages = {15},
keywords = {large language models, domain-specific training, chest computed tomography}
}

@inproceedings{10.1145/3707127.3707138,
author = {Chiu, Yen-Jung and Chuang, Chao-Chun and Hwa, Kuo-Yuan},
title = {Enhancing Medical Diagnosis with Fine-Tuned Large Language Models: Addressing Cardiogenic Pulmonary Edema (CPE)},
year = {2025},
isbn = {9798400718274},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3707127.3707138},
doi = {10.1145/3707127.3707138},
abstract = {Large Language Models (LLMs) have revolutionized natural language processing (NLP) with significant advancements in text generation. LLMs often struggle with complex domain-specific tasks, such as medical report analysis, despite their capabilities. This study focuses on enhancing LLM performance for medical applications, particularly in diagnosing and managing cardiogenic pulmonary edema (CPE). This research explores fine-tuning LLMs to develop a real-time CPE chatbot for Intensive Care Units (ICUs). The chatbot aims to provide diagnostic suggestions and explanations based on patient data. In the results, the LLaMa3-8B model performed better in predicting patients' CPE stage and keyword extraction. The accuracies achieved 72% and 86%.},
booktitle = {Proceedings of the 2024 11th International Conference on Biomedical and Bioinformatics Engineering},
pages = {66–71},
numpages = {6},
keywords = {Edema, LLM, Medical report, Natural language model, hospital},
location = {
},
series = {ICBBE '24}
}

@inproceedings{10.1145/3589334.3645671,
author = {Wang, Yuling and Tian, Changxin and Hu, Binbin and Yu, Yanhua and Liu, Ziqi and Zhang, Zhiqiang and Zhou, Jun and Pang, Liang and Wang, Xiao},
title = {Can Small Language Models be Good Reasoners for Sequential Recommendation?},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645671},
doi = {10.1145/3589334.3645671},
abstract = {Large language models (LLMs) open up new horizons for sequential recommendations, owing to their remarkable language comprehension and generation capabilities. However, there are still numerous challenges that should be addressed to successfully implement sequential recommendations empowered by LLMs. Firstly, user behavior patterns are often complex, and relying solely on one-step reasoning from LLMs may lead to incorrect or task-irrelevant responses. Secondly, the prohibitively resource requirements of LLM (e.g., ChatGPT-175B) are overwhelmingly high and impractical for real sequential recommender systems. In this paper, we propose a novel Step-by-step knowLedge dIstillation fraMework for recommendation (SLIM), paving a promising path for sequential recommenders to enjoy the exceptional reasoning capabilities of LLMs in a "slim" (i.e. resource-efficient) manner. We introduce CoT prompting based on user behavior sequences for the larger teacher model. The rationales generated by the teacher model are then utilized as labels to distill the downstream smaller student model (e.g., LLaMA2-7B). In this way, the student model acquires the step-by-step reasoning capabilities in recommendation tasks. We encode the generated rationales from the student model into a dense vector, which empowers recommendation in both ID-based and ID-agnostic scenarios. Extensive experiments demonstrate the effectiveness of SLIM over state-of-the-art baselines, and further analysis showcasing its ability to generate meaningful recommendation reasoning at affordable costs.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3876–3887},
numpages = {12},
keywords = {distillation, large language models, recommender systems},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3708036.3708178,
author = {Niu, Hailong and Gong, Xinlu},
title = {The Role of Generative AI in Higher Education: A Decade of Current Status and Future Prospects},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708178},
doi = {10.1145/3708036.3708178},
abstract = {With the rapid development of Generative AI technology, particularly large language models like ChatGPT. Generative AI has brought profound transformations to teaching methods, learning experiences, and assessment models, but it also presents challenges related to academic integrity and educational equity. The purpose of this study is to analyze the current state of Generative AI applications in higher education over the past decade and its future development trends using a comprehensive bibliometric and scientometric approach. The study selects 620 papers from the Web of Science database, published between 2014 and 2024, related to Generative AI and higher education, and employs VOSviewer and CiteSpace software for data analysis and visualization. The results show a significant increase in research on the application of Generative AI in higher education since 2018, with a particular focus on personalized learning, teaching assessment, and interdisciplinary education, which have garnered widespread attention. Through network analyses of collaboration among authors, institutions. This study not only provides researchers with insights into the current status and development trends of Generative AI in higher education but also lays the foundation for deeper discussions on issues such as educational equity and academic integrity.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {848–852},
numpages = {5},
keywords = {generative AI, higher education, large language models},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3657604.3662041,
author = {Pal Chowdhury, Sankalan and Zouhar, Vil\'{e}m and Sachan, Mrinmaya},
title = {AutoTutor meets Large Language Models: A Language Model Tutor with Rich Pedagogy and Guardrails},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662041},
doi = {10.1145/3657604.3662041},
abstract = {Large Language Models (LLMs) have found several use cases in education, ranging from automatic question generation to essay evaluation. In this paper, we explore the potential of using LLMs to author Intelligent Tutoring Systems. A common pitfall of using LLMs as tutors is their straying from desired pedagogical strategies such as leaking the answer to the student, and in general, providing no guarantees on the validity or appropriateness of the tutor assistance. We argue that while LLMs with certain guardrails can take the place of subject experts, the overall pedagogical design still needs to be handcrafted for the best learning results. Based on this principle, we create a sample end-to-end tutoring system named MWPTutor, which uses LLMs to fill in the state space of a predefined finite state transducer. This approach retains the structure and the pedagogy of traditional tutoring systems that has been developed over the years by learning scientists but brings in additional flexibility of LLM-based approaches. Through a human evaluation study on two datasets with math word problems, we show that our hybrid approach achieves a better overall tutoring score than an instructed, but otherwise free-form, GPT-4. MWPTutor is completely modular and opens up the scope for the community to improve its performance by refining its individual modules or using different teaching strategies that it can follow.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {5–15},
numpages = {11},
keywords = {autotutor, finite state transducers, large language models, math word problems, tutoring},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3636555.3636882,
author = {Dunder, Nora and Lundborg, Saga and Wong, Jacqueline and Viberg, Olga},
title = {Kattis vs ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636882},
doi = {10.1145/3636555.3636882},
abstract = {AI-powered education technologies can support students and teachers in computer science education. However, with the recent developments in generative AI, and especially the increasingly emerging popularity of ChatGPT, the effectiveness of using large language models for solving programming tasks has been underexplored. The present study examines ChatGPT’s ability to generate code solutions at different difficulty levels for introductory programming courses. We conducted an experiment where ChatGPT was tested on 127 randomly selected programming problems provided by Kattis, an automatic software grading tool for computer science programs, often used in higher education. The results showed that ChatGPT independently could solve 19 out of 127 programming tasks generated and assessed by Kattis. Further, ChatGPT was found to be able to generate accurate code solutions for simple problems but encountered difficulties with more complex programming tasks. The results contribute to the ongoing debate on the utility of AI-powered tools in programming education.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {821–827},
numpages = {7},
keywords = {Academic Integrity, Automated Grading, ChatGPT, Programming Education},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3696673.3723069,
author = {Meda, Kavya Nikhita and Nara, Pavan Subhash Chandrabose and Bozenka, Svoboda and Zormati, Tarek and Turner, Seth and Worley, Wayne and Mitra, Reshmi},
title = {Integrating Prompt Structures Using LLM Embeddings for Cybersecurity Threats},
year = {2025},
isbn = {9798400712777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696673.3723069},
doi = {10.1145/3696673.3723069},
abstract = {This paper aims to develop a specialized Large Language Model (LLM) for cybersecurity training, designed to educate users on fundamental cybersecurity concepts. This paper focuses on creating an interactive system where users can ask questions about computer security and receive accurate, informative responses. By addressing cybersecurity as a critical national issue, the LLM empowers individuals and organizations to defend against malicious cyber threats. Our system was developed using Python, utilizing Google Sheets as a database, Gradio for the user interface, and Google Gemini's API for advanced language processing. The implementation followed a test-driven development approach, iterating between coding and testing to ensure functionality and reliability. Key technologies include Mistral's Large 2 model and embedding models for clustering related data. The Retrieval-Augmented Generation (RAG) framework was employed to integrate information retrieval with the LLM, enhancing its accuracy and relevance. Tools such as Google Suite, Colab, and Gradio contributed to creating a robust and user-friendly system. This paper highlights the potential of domain-specific LLMs, offering a practical solution to the growing need for accessible cybersecurity education and fostering awareness to mitigate the risks posed by malicious hackers.},
booktitle = {Proceedings of the 2025 ACM Southeast Conference},
pages = {180–187},
numpages = {8},
keywords = {large language model (LLM), embedding models, retrieval-augmented generation (RAG), information retrieval, cybersecurity education},
location = {Southeast Missouri State University, Cape Girardeau, MO, USA},
series = {ACMSE 2025}
}

@inproceedings{10.1145/3711403.3711452,
author = {Lin, Jian and Wang, Xiaoyi and Li, Bingjun and He, Musheng and Luo, Yufei},
title = {The Research on the Application Modes of Intelligent Instructional Design Generation in Primary and Secondary Schools Supported by Large Models},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711452},
doi = {10.1145/3711403.3711452},
abstract = {As the development of large language models and generative artificial intelligence technologies continues to advance, the application of digital teaching resources is exhibiting a new trend of human-machine collaboration and co-creation. As an important digital teaching resource for the implementation of smart teaching, the application of instructional design documents has been significantly influenced by the development of intelligent technologies, especially in the field of primary and secondary education, which holds significant research value. However, there is a clear gap between the value claims and actual effects of traditional instructional design, which limits the professional development of teachers and hinders the comprehensive development of students. This research aims to combine ChatGPT-4 models and generative artificial intelligence technology to construct an intelligent instructional design system platform, achieving the intelligent transformation and upgrading of instructional design.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {290–298},
numpages = {9},
keywords = {Artificial intelligence, Intelligence instructional design, Large-scale AI models, Lesson plan},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3627673.3680093,
author = {Bai, Xiao and Wu, Xue and Stojkovic, Ivan and Tsioutsiouliklis, Kostas},
title = {Leveraging Large Language Models for Improving Keyphrase Generation for Contextual Targeting},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680093},
doi = {10.1145/3627673.3680093},
abstract = {Generating a set of keyphrases that convey the main concepts discussed in a document has been applied to improve various applications including document retrieval and online advertising. The state-of-the-art approaches mostly rely on the neural sequence-to-sequence framework to generate keyphrases. However, training such deep neural networks either requires a significant amount of human efforts in obtaining ground truth keyphrases or suffers from lower quality training data derived from weakly supervised signals. More recently, pre-trained language models are fine-tuned to build more data-efficient keyphrase generation models. Yet, the documents often need to be truncated to adapt to the pre-trained context window. On the other hand, large language models (LLMs) have demonstrated impressive abilities in understanding very long text and generating answers for a wide range of natural language processing tasks, making them great candidates for improving keyphrase generation. There however is a lack of a systematic study on how to use LLMs, especially in an industrial setting that requires low generation latency. In this work, we present an empirical study to facilitate a more informed use of LLMs for keyphrase generation. We compare zero-shot and few-shot in-context learning with parameter efficient fine-tuning using a number of open-source LLMs. We show that using only a handful of well selected human annotated samples, the LLMs already outperform the fine-tuned language model baselines. When thousands of human labeled samples are available, fine-tuned large language models significantly improve the amount and the quality of the generated keyphrases. To enable efficient keyphrase generation at scale, we distill the knowledge from LLMs to a base-size language model. Our evaluation shows significant increase in user reach when the generated keyphrases are used for contextual targeting at Yahoo.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4349–4357},
numpages = {9},
keywords = {LLM, keyphrase generation, knowledge distillation, large language models},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3691620.3695297,
author = {Zhang, Chi and Wang, Zifan and Zhao, Ruoshi and Mangal, Ravi and Fredrikson, Matt and Jia, Limin and Pasareanu, Corina},
title = {Attacks and Defenses for Large Language Models on Coding Tasks},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695297},
doi = {10.1145/3691620.3695297},
abstract = {Modern large language models (LLMs), such as ChatGPT, have demonstrated impressive capabilities for coding tasks, including writing and reasoning about code. They improve upon previous neural network models of code, such as code2seq or seq2seq, that already demonstrated competitive results when performing tasks such as code summarization and identifying code vulnerabilities. However, these previous code models were shown vulnerable to adversarial examples, i.e., small syntactic perturbations designed to "fool" the models. In this paper, we first aim to study the transferability of adversarial examples, generated through white-box attacks on smaller code models, to LLMs. We also propose a new attack using an LLM to generate the perturbations. Further, we propose novel cost-effective techniques to defend LLMs against such adversaries via prompting, without incurring the cost of retraining. These prompt-based defenses involve modifying the prompt to include additional information, such as examples of adversarially perturbed code and explicit instructions for reversing adversarial perturbations. Our preliminary experiments show the effectiveness of the attacks and the proposed defenses on popular LLMs such as GPT-3.5 and GPT-4.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2268–2272},
numpages = {5},
keywords = {LLMs, code models, adversarial attacks, robustness},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3657604.3664707,
author = {Zhao, Yuhui and Zou, Chunhao and Sridhar, Rohit and Cui, Christopher and Starner, Thad},
title = {Leveraging Past Assignments to Determine If Students Are Using ChatGPT for Their Essays},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664707},
doi = {10.1145/3657604.3664707},
abstract = {The proliferation of powerful large language models with human-like abilities, like ChatGPT, pose serious challenges for educators to enforce academic integrity policies. To address this problem, we propose a novel approach that uses past students' essay submissions dated before the popularization of ChatGPT, and ChatGPT generated essay responses as ground truth to train classifiers to detect ChatGPT usage for current student submissions. Our case study found that, for the same question prompt, student written answers and ChatGPT generated answers are very different. Testing on the ground truth data shows very simple machine learning methods, including multinomial naive Bayes, linear discriminant analysis, and logistic regression, can achieve close to perfect accuracies in detecting ChatGPT generated responses. Using this approach, we suspect around 7% of current student submissions are ChatGPT generated.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {320–324},
numpages = {5},
keywords = {academic integrity, large language model detection, plagiarism detection},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3657604.3662032,
author = {Hou, Xinying and Wu, Zihan and Wang, Xu and Ericson, Barbara J.},
title = {CodeTailor: LLM-Powered Personalized Parsons Puzzles for Engaging Support While Learning Programming},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662032},
doi = {10.1145/3657604.3662032},
abstract = {Learning to program can be challenging, and providing high-quality and timely support at scale is hard. Generative AI and its products, like ChatGPT, can create a solution for most intro-level programming problems. However, students might use these tools to just generate code for them, resulting in reduced engagement and limited learning. In this paper, we present CodeTailor, a system that leverages a large language model (LLM) to provide personalized help to students while still encouraging cognitive engagement. CodeTailor provides a personalized Parsons puzzle to support struggling students. In a Parsons puzzle, students place mixed-up code blocks in the correct order to solve a problem. A technical evaluation with previous incorrect student code snippets demonstrated that CodeTailor could deliver high-quality (correct, personalized, and concise) Parsons puzzles based on their incorrect code. We conducted a within-subjects study with 18 novice programmers. Participants perceived CodeTailor as more engaging than just receiving an LLM-generated solution (the baseline condition). In addition, participants applied more supported elements from the scaffolded practice to the posttest when using CodeTailor than baseline. Overall, most participants preferred using CodeTailor versus just receiving the LLM-generated code for learning. Qualitative observations and interviews also provided evidence for the benefits of CodeTailor, including thinking more about solution construction, fostering continuity in learning, promoting reflection, and boosting confidence. We suggest future design ideas to facilitate active learning opportunities with generative AI techniques.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {51–62},
numpages = {12},
keywords = {active learning, generative ai, gpt, introductory programming, large language models, parsons problems, personalization},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.5555/3715602.3715619,
author = {Hong, Alexander and Hong, Gongbing},
title = {The Effectiveness of Coding LLMs and the Challenges in Teaching CS1/2: A Case Study},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {This paper presents a case study that evaluates the effectiveness of coding Large Language Models (LLMs) in introductory computer science courses at the university level. The study assesses six different AI-powered code generators. The evaluation focuses on the accuracy of these AI code generators in solving ten programming problems from a set of problems that instructors at Duke University can assign to students for weekly completion. The results demonstrate the effectiveness of coding LLMs in solving these problems.Based on the findings, the paper discusses the challenges faced by the computer science education community and potential strategies to address them. The advent of coding LLMs poses significant challenges to traditional teaching and learning methods in computer science. These challenges include the need for strategies to mitigate any negative impact of LLMs on the learning process. At the same time, these code LLMs also offer tremendous opportunities for enhancing teaching and learning.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {122–131},
numpages = {10}
}

@inproceedings{10.1145/3658644.3670392,
author = {Liu, Zeyan and Yao, Zijun and Li, Fengjun and Luo, Bo},
title = {On the Detectability of ChatGPT Content: Benchmarking, Methodology, and Evaluation through the Lens of Academic Writing},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670392},
doi = {10.1145/3658644.3670392},
abstract = {With ChatGPT under the spotlight, utilizing large language models (LLMs) to assist academic writing has drawn a significant amount of debate in the community. In this paper, we aim to present a comprehensive study of the detectability of ChatGPT-generated content within the academic literature, particularly focusing on the abstracts of scientific papers, to offer holistic support for the future development of LLM applications and policies in academia. Specifically, we first present GPABench2, a benchmarking dataset of over 2.8 million comparative samples of human-written, GPT-written, GPT-completed, and GPT-polished abstracts of scientific writing in computer science, physics, and humanities and social sciences. Second, we explore the methodology for detecting ChatGPT content. We start by examining the unsatisfactory performance of existing ChatGPT detecting tools and the challenges faced by human evaluators (including more than 240 researchers or students). We then test the hand-crafted linguistic features models as a baseline and develop a deep neural framework named CheckGPT to better capture the subtle and deep semantic and linguistic patterns in ChatGPT written literature. Last, we conduct comprehensive experiments to validate the proposed CheckGPT framework in each benchmarking task over different disciplines. To evaluate the detectability of ChatGPT content, we conduct extensive experiments on the transferability, prompt engineering, and robustness of CheckGPT.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2236–2250},
numpages = {15},
keywords = {aigc detection, large language models, responsible ai},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3696410.3714720,
author = {Bouadi, Mohamed and Alavi, Arta and Benbernou, Salima and Ouziri, Mourad},
title = {Synergizing Large Language Models and Knowledge-Based Reasoning for Interpretable Feature Engineering},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714720},
doi = {10.1145/3696410.3714720},
abstract = {Feature engineering stands as a pivotal step in enhancing the performance of machine learning (ML) models, particularly with tabular data. However, traditional feature engineering methods are often time-consuming and requires case-by-case domain knowledge. In addition, as ML systems become more common, interpretability becomes increasingly important, especially among domain experts. To this end, we propose ReaGen, an automated feature engineering (AutoFE) approach that combines knowledge graphs (KGs) with large language models (LLMs) to generate interpretable features. ReaGen begins by symbolic REAsoning over the KG to extract relevant information based on datasets description. Then, it uses an LLM to iteratively GENerate meaningful features. Finally, to overcome challenges such as hallucinations and handling long contexts typical in LLMs, our model performs logical reasoning on the KG to ensure that the generated features maintain interpretability. ReaGen provides Python code for automatic feature generation and detailed explanations of feature utility. It leverages both LLM's internal knowledge and retrieved information from KGs. Experiments on public datasets demonstrate that ReaGen significantly improves prediction accuracy while ensuring high interpretability through human-like explanations for each feature. This work highlights the potential of integrating LLMs and KGs in feature engineering, paving the way for interpretable ML models.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {2606–2620},
numpages = {15},
keywords = {automated feature engineering, interpretable ML, knowledge graphs, large language models, symbolic reasoning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3715107,
author = {Molina, Facundo and Gorla, Alessandra and d’Amorim, Marcelo},
title = {Test Oracle Automation in the Era of LLMs},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715107},
doi = {10.1145/3715107},
abstract = {The effectiveness of a test suite in detecting faults highly depends on the quality of its test oracles. Large Language Models (LLMs) have demonstrated remarkable proficiency in tackling diverse software testing tasks. This article aims to present a roadmap for future research on the use of LLMs for test oracle automation. We discuss the progress made in the field of test oracle automation before the introduction of LLMs, identifying the main limitations and weaknesses of existing techniques. Additionally, we discuss recent studies on the use of LLMs for this task, highlighting the main challenges that arise from their use, e.g., how to assess quality and usefulness of the generated oracles. We conclude with a discussion about the directions and opportunities for future research on LLM-based oracle automation.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {150},
numpages = {24},
keywords = {Test Oracle Problem, Large Language Models}
}

@article{10.1145/3704739,
author = {Le, Linh and Tran, Dung},
title = {A Metric-Based Detection System for Large Language Model Texts},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3704739},
doi = {10.1145/3704739},
abstract = {More efforts are being put into improving the capabilities of Large Language Models (LLM) than into dealing with their implications. Current LLMs are able to generate high-quality texts seemingly indistinguishable from those written by human experts. While offering great potential, such breakthroughs also pose new challenges for safe and ethical uses of LLMs in education, science, and a multitude of other areas. Thus, majority of current approaches in LLM text detection are either computationally expensive or need access to the LLMs’ internal computations, both of which hinder their public accessibility. With such motivation, this article presents a novel metric learning paradigm for detection of LLM-generated texts that is able to balance computational costs, accessibility, and performances. Specifically, the detection is based on learning a similarity function between a given text and an equivalent example generated by LLMs that outputs high values for LLM-LLM text pairs and low values for LLM-human text pairs. In terms of architecture, the detection framework includes a pre-trained language model for the text embedding task and a newly designed deep metric model. The metric component can be trained on triplets or pairs of same-context instances to signify the distances between human and LLM texts while reducing that among LLM texts. Next, we develop five datasets totaling more than 95,000 contexts and triplets of responses in which one is from humans and two are from GPT-3.5 TURBO or GPT-4 TURBO for benchmarking. Experiment studies show that our best architectures maintain F1 scores between 0.87 and 0.95 across the tested corpora in multiple experiment settings. The metric framework also demands significantly less time in training and inference compared to RoBERTa, LLaMA 3, Mistral v0.3, and Ghostbuster, while keeping 90% to 150% performance of the best benchmark.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {8},
numpages = {19},
keywords = {LLM text detection, contrastive learning, triplet learning, metric learning}
}

@inproceedings{10.1145/3677388.3696321,
author = {Li, Danrui and Sohn, Samuel S. and Zhang, Sen and Chang, Che-Jui and Kapadia, Mubbasir},
title = {From Words to Worlds: Transforming One-line Prompts into Multi-modal Digital Stories with LLM Agents},
year = {2024},
isbn = {9798400710902},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677388.3696321},
doi = {10.1145/3677388.3696321},
abstract = {Digital storytelling, essential in entertainment, education, and marketing, faces challenges in generation efficiency. The StoryAgent framework, introduced in this paper, utilizes Large Language Models and generative tools to automate and refine digital storytelling. Employing a top-down story drafting and bottom-up asset generation approach, StoryAgent tackles key issues such as manual intervention, interactive scene orchestration, and narrative consistency. This framework enables efficient production of interactive and consistent digital storytellings across multiple modalities, democratizing content creation and enhancing engagement.},
booktitle = {Proceedings of the 17th ACM SIGGRAPH Conference on Motion, Interaction, and Games},
articleno = {21},
numpages = {12},
keywords = {Communicative Agents, Digital storytelling, Large Language Models},
location = {Arlington, VA, USA},
series = {MIG '24}
}

@inproceedings{10.1145/3701716.3717810,
author = {Syah, Riza Alaudin and Haryanto, Christoforus Yoga and Lomempow, Emily and Malik, Krishna and Putra, Irvan},
title = {EdgePrompt: Engineering Guardrail Techniques for Offline LLMs in K-12 Educational Settings},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717810},
doi = {10.1145/3701716.3717810},
abstract = {EdgePrompt is a prompt engineering framework that implements pragmatic guardrails for Large Language Models (LLMs) in the K-12 educational settings through structured prompting inspired by neural-symbolic principles. The system addresses educational disparities in Indonesia's Frontier, Outermost, Underdeveloped (3T) regions by enabling offline-capable content safety controls. It combines: (1) content generation with structured constraint templates, (2) assessment processing with layered validation, and (3) lightweight storage for content and result management. The framework implements a multi-stage verification workflow that maintains safety boundaries while preserving model capabilities in connectivity-constrained environments. Initial deployment targets Grade 5 language instruction, demonstrating effective guardrails through structured prompt engineering without formal symbolic reasoning components.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1635–1638},
numpages = {4},
keywords = {ai safety, content filtering, edge computing, educational technology, guardrails, k-12 education, large language models, offline ai, prompt engineering},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3637528.3671469,
author = {Zhang, Yunyi and Zhong, Ming and Ouyang, Siru and Jiao, Yizhu and Zhou, Sizhe and Ding, Linyi and Han, Jiawei},
title = {Automated Mining of Structured Knowledge from Text in the Era of Large Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671469},
doi = {10.1145/3637528.3671469},
abstract = {Massive amount of unstructured text data are generated daily, ranging from news articles to scientific papers. How to mine structured knowledge from the text data remains a crucial research question. Recently, large language models (LLMs) have shed light on the text mining field with their superior text understanding and instruction-following ability. There are typically two ways of utilizing LLMs: fine-tune the LLMs with human-annotated training data, which is labor intensive and hard to scale; prompt the LLMs in a zero-shot or few-shot way, which cannot take advantage of the useful information in the massive text data. Therefore, it remains a challenge on automated mining of structured knowledge from massive text data in the era of large language models. In this tutorial, we cover the recent advancements in mining structured knowledge using language models with very weak supervision. We will introduce the following topics in this tutorial: (1) introduction to large language models, which serves as the foundation for recent text mining tasks, (2) ontology construction, which automatically enriches an ontology from a massive corpus, (3) weakly-supervised text classification in flat and hierarchical label space, (4) weakly-supervised information extraction, which extracts entity and relation structures.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6644–6654},
numpages = {11},
keywords = {large language models, text mining, weak supervision},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3727200.3727217,
author = {Wilkins, Grant and Keshav, Srinivasan and Mortier, Richard},
title = {Offline Energy-Optimal LLM Serving: Workload-Based Energy Models for LLM Inference on Heterogeneous Systems},
year = {2025},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {5},
url = {https://doi.org/10.1145/3727200.3727217},
doi = {10.1145/3727200.3727217},
abstract = {The rapid adoption of large language models (LLMs) has led to significant advances in natural language processing and text generation. However, the energy consumed through LLM model inference remains a major challenge for sustainable AI deployment. To address this problem, we model the workload-dependent energy consumption and runtime of LLM inference tasks on heterogeneous GPU-CPU systems. By conducting an extensive characterization study of several state-of-the-art LLMs and analyzing their energy and runtime behavior across different magnitudes of input prompts and output text, we develop accurate (R2 &gt; 0.96) energy and runtime models for each LLM. We employ these models to explore an offline, energy-optimal LLM workload scheduling framework. Through a case study, we demonstrate the advantages of energy and accuracy aware scheduling compared to existing best practices.},
journal = {SIGENERGY Energy Inform. Rev.},
month = apr,
pages = {113–119},
numpages = {7},
keywords = {sustainable computing, heterogeneous computing, large language models, artificial intelligence}
}

@inproceedings{10.1145/3701716.3715599,
author = {Liu, Zhiwei and Zhang, Xin and Yang, Kailai and Xie, Qianqian and Huang, Jimin and Ananiadou, Sophia},
title = {FMDLlama: Financial Misinformation Detection Based on Large Language Models},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715599},
doi = {10.1145/3701716.3715599},
abstract = {The emergence of social media has made the spread of misinformation easier. In the financial domain, the accuracy of information is crucial for various aspects of financial market, which has made financial misinformation detection (FMD) an urgent problem that needs to be addressed. Large language models (LLMs) have demonstrated outstanding performance in various fields. However, current studies mostly rely on traditional methods and have not explored the application of LLMs in the field of FMD. The main reason is the lack of FMD instruction tuning datasets and evaluation benchmarks. In this paper, we propose FMDLlama, the first open-sourced instruction-following LLMs for FMD task based on fine-tuning Llama3.1 with instruction data, the first multi-task FMD instruction dataset (FMDID) to support LLM instruction tuning, and a comprehensive FMD evaluation benchmark (FMD-B) with classification and explanation generation tasks to test the FMD ability of LLMs. We compare our models with a variety of LLMs on FMD-B, where our model outperforms other open-sourced LLMs as well as OpenAI's products. This project is available at https://github.com/lzw108/FMD.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1153–1157},
numpages = {5},
keywords = {evaluation benchmark, financial misinformation, large language model},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inbook{10.1145/3724504.3724622,
author = {Liang, Bohan},
title = {Artificial Intelligence in Language Education: CiteSpace-based Visualisation and Analysis},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724622},
abstract = {Over the past five years, the rapid development of generative artificial intelligence (AI) has led to a significant increase in research on AI in language education. This article uses CiteSpace software to conduct a visual analysis of research related to AI in language education from the SCI and SSCI databases over the past five years. The research results indicate that from 2020 to 2024, the number of papers related to AI in language education has been increasing steadily with the improvement of AI technologies. What's more, China, the United States, South Korea, England, and Saudi Arabia are the leading countries in terms of publication volume. Institutions such as the Chinese University of Hong Kong, Education University of Hong Kong, and Indiana University System (including Indiana University Bloomington), etc. have a significant number of publications, and collaborative publications among institutions are the mainstream. Moreover, the keyword co-occurrence graph shows that students’ English learning, large language models, natural language processing technology and deep learning are the foci of scholars' research. Keyword clustering graph and top terms in each cluster indicate that research in this field primarily focuses on English learning, particularly on speech and writing skills, and the psychological factors, learning effect, and learning strategies in the process of AI-assisted language education have also attracted the attention of scholars. Lastly, computational modeling technologies and mobile-assisted language learning are also topics that scholars have discussed extensively. The application of AI in non-English languages education, emotional factors of students and mobile-assisted language education driven by large language models may become hotspots in the future.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {721–725},
numpages = {5}
}

@inproceedings{10.1145/3657604.3662030,
author = {Moore, Steven and Schmucker, Robin and Mitchell, Tom and Stamper, John},
title = {Automated Generation and Tagging of Knowledge Components from Multiple-Choice Questions},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662030},
doi = {10.1145/3657604.3662030},
abstract = {Knowledge Components (KCs) linked to assessments enhance the measurement of student learning, enrich analytics, and facilitate adaptivity. However, generating and linking KCs to assessment items requires significant effort and domain-specific knowledge. To streamline this process for higher-education courses, we employed GPT-4 to generate KCs for multiple-choice questions (MCQs) in Chemistry and E-Learning. We analyzed discrepancies between the KCs generated by the Large Language Model (LLM) and those made by humans through evaluation from three domain experts in each subject area. This evaluation aimed to determine whether, in instances of non-matching KCs, evaluators showed a preference for the LLM-generated KCs over their human-created counterparts. We also developed an ontology induction algorithm to cluster questions that assess similar KCs based on their content. Our most effective LLM strategy accurately matched KCs for 56% of Chemistry and 35% of E-Learning MCQs, with even higher success when considering the top five KC suggestions. Human evaluators favored LLM-generated KCs, choosing them over human-assigned ones approximately two-thirds of the time, a preference that was statistically significant across both domains. Our clustering algorithm successfully grouped questions by their underlying KCs without needing explicit labels or contextual information. This research advances the automation of KC generation and classification for assessment items, alleviating the need for student data or predefined KC labels.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {122–133},
numpages = {12},
keywords = {concept labeling, knowledge component, knowledge labeling, learning engineering, multiple-choice question},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.1145/3711061,
author = {Zhang, Zhiping and Shen, Chenxinran and Yao, Bingsheng and Wang, Dakuo and Li, Tianshi},
title = {Secret Use of Large Language Model (LLM)},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711061},
doi = {10.1145/3711061},
abstract = {The advancements of Large Language Models (LLMs) have decentralized the responsibility for the transparency of AI usage. Specifically, LLM users are now encouraged or required to disclose the use of LLM-generated content for varied types of real-world tasks. However, an emerging phenomenon, users' secret use of LLM, raises challenges in ensuring end users adhere to the transparency requirement. Our study used mixed-methods with an exploratory survey (125 real-world secret use cases reported) and a controlled experiment among 300 users to investigate the contexts and causes behind the secret use of LLMs. We found that such secretive behavior is often triggered by certain tasks, transcending demographic and personality differences among users. Task types were found to affect users' intentions to use secretive behavior, primarily through influencing perceived external judgment regarding LLM usage. Our results yield important insights for future work on designing interventions to encourage more transparent disclosure of the use of LLMs or other AI technologies.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW163},
numpages = {26},
keywords = {ai transparency, large-language models (llms), mixed-methods studies, privacy}
}

@inproceedings{10.1145/3501385.3543957,
author = {Sarsa, Sami and Denny, Paul and Hellas, Arto and Leinonen, Juho},
title = {Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models},
year = {2022},
isbn = {9781450391948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501385.3543957},
doi = {10.1145/3501385.3543957},
abstract = {This article explores the natural language generation capabilities of large language models with application to the production of two types of learning resources common in programming courses. Using OpenAI Codex as the large language model, we create programming exercises (including sample solutions and test cases) and code explanations, assessing these qualitatively and quantitatively. Our results suggest that the majority of the automatically generated content is both novel and sensible, and in some cases ready to use as is. When creating exercises we find that it is remarkably easy to influence both the programming concepts and the contextual themes they contain, simply by supplying keywords as input to the model. Our analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors, although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students. We further discuss the implications of OpenAI Codex and similar tools for introductory programming education and highlight future research streams that have the potential to improve the quality of the educational experience for both teachers and students alike.},
booktitle = {Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1},
pages = {27–43},
numpages = {17},
keywords = {Robosourcing, Resource generation, Programming exercises, OpenAI Codex, Natural language generation, Large language models, GPT-3, Exercise generation, Code explanations, CS1, Automated feedback},
location = {Lugano and Virtual Event, Switzerland},
series = {ICER '22}
}

@inproceedings{10.1145/3701571.3703373,
author = {Kronhardt, Kirill and Hoffmann, Sebastian and Adelt, Fabian and Gerken, Jens},
title = {PERSON\AE{}R - Transparency Enhancing Tool for LLM-Generated User Personas from Live Website Visits},
year = {2024},
isbn = {9798400712838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701571.3703373},
doi = {10.1145/3701571.3703373},
abstract = {Research on transparency tools for information privacy has largely focused on users’ perceptions of their usefulness—showing users prefer aggregated forms of data representation (e.g., interest segments) over hard-to-interpret raw data. However, users still do not understand what to learn from such interest segments. Representing a user’s digital footprint as a user persona may serve as an effective way to communicate such information. Large Language Models (LLMs) show promise in dynamically presenting information in a way that can change user perceptions of complex issues—including privacy, personal data disclosure and user persona generation. We present PERSON\AE{}R—a browser extension for LLM-based user persona generation from live website visits.},
booktitle = {Proceedings of the International Conference on Mobile and Ubiquitous Multimedia},
pages = {527–531},
numpages = {5},
keywords = {transparency enhancing tools, information privacy, user personas, large language models},
location = {
},
series = {MUM '24}
}

@article{10.1145/3719006,
author = {Ahmed, Iftekhar and Aleti, Aldeida and Cai, Haipeng and Chatzigeorgiou, Alexander and He, Pinjia and Hu, Xing and Pezz\`{e}, Mauro and Poshyvanyk, Denys and Xia, Xin},
title = {Artificial Intelligence for Software Engineering: The Journey So Far and the Road Ahead},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3719006},
doi = {10.1145/3719006},
abstract = {Artificial intelligence and recent advances in deep learning architectures, including transformer networks and large language models, change the way people think and act to solve problems. Software engineering, as an increasingly complex process to design, develop, test, deploy, and maintain large-scale software systems for solving real-world challenges, is profoundly affected by many revolutionary artificial intelligence tools in general and machine learning in particular. In this roadmap for artificial intelligence in software engineering, we highlight the recent deep impact of artificial intelligence on software engineering by discussing successful stories of applications of artificial intelligence to classic and new software development challenges. We identify the new challenges that the software engineering community has to address in the coming years to successfully apply artificial intelligence in software engineering, and we share our research roadmap toward the effective use of artificial intelligence in the software engineering profession, while still protecting fundamental human values.We spotlight three main areas that challenge the research in software engineering: the use of generative artificial intelligence and large language models for engineering large software systems, the need of large and unbiased datasets and benchmarks for training and evaluating deep learning and large language models for software engineering, and the need of a new code of digital ethics to apply artificial intelligence in software engineering.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {119},
numpages = {27},
keywords = {Automated Software Development, Machine Learning, Large Language Models, Artificial Intelligence, Explainable AI, Ethical AI}
}

@inproceedings{10.1145/3701551.3705709,
author = {Hoppe, Anett and Yu, Ran and Liu, Jiqun and Bhattacharya, Nilavra},
title = {IWILDS'25: The 5th International Workshop on Investigating Learning During Web Search},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3705709},
doi = {10.1145/3701551.3705709},
abstract = {Web-based learning is evolving rapidly as traditional search engines are complemented by Large Language Models (LLMs) and other AI technologies. This evolution offers new opportunities, such as automated information synthesis and personalized learning experiences. However, this also presents new challenges, including the need for learners to be aware of potential biases and misinformation in AI-generated content, and to maintain focus and depth in their learning journeys. The Search as Learning (SAL) field investigates how individuals learn through web interactions, examining the interplay between search behaviors, information synthesis, and learning outcomes. SAL research aims to measure, predict, and support effective learning strategies in modern web environments. IWILDS'25 provides an interdisciplinary platform to explore these dynamics, bringing together researchers and practitioners from information retrieval, education, psychology, and related fields. This full-day workshop will feature keynotes, paper presentations, and discussions on advancing SAL research and practice.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {1116–1117},
numpages = {2},
keywords = {educational psychology, information science, interactive information retrieval, retrieval augmented generation, search as learning, web-based learning},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3641554.3701858,
author = {Tran, Minh and Gonzalez-Maldonado, David and Zhou, Elaine and Franklin, Diana},
title = {Can GPT Help? Supporting Teachers to Brainstorm Customized Instructional Scratch Projects},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701858},
doi = {10.1145/3641554.3701858},
abstract = {While many recent studies have explored how large language models can transform computer science instruction from the instructor perspective, they are primarily at the college level. Thus, little is known about using large language models towards curriculum development and teacher supports outside of the college setting. Given the emphasis placed on culturally responsive teaching at the K-8 level and well-documented evidence of insensitive and inaccurate language model outputs from a cultural perspective, it is imperative to perform systematic and principled research before considering their use in this setting.This paper explores the potential of teachers using large language models to brainstorm instructional Scratch projects. Specifically, we use GPT-3 to mimic structured projects from an existing computer science curriculum but situate the generated projects in different contexts/themes. We qualitatively analyze 300 project ideas generated by GPT and find 81% of the generated ideas satisfy our metrics for technical alignment and theme quality. We identify two major weaknesses: code complexity of generated projects and presence of potential insensitive elements that would require human filtering. We conclude that, while not ready as a student-facing solution, teachers could use GPT to effectively brainstorm customized instructional materials.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1134–1140},
numpages = {7},
keywords = {curriculum customization, k-8, large language models, scratch programming, teacher supports},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3658617.3697624,
author = {Akyash, Mohammad and Mardani Kamali, Hadi},
title = {SimEval: Investigating the Similarity Obstacle in LLM-based Hardware Code Generation},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697624},
doi = {10.1145/3658617.3697624},
abstract = {The increasing use and efficiency of large language models (LLMs) in digital hardware circuit design has started to revolutionize the early stages of integrated circuit (IC) supply chain design and implementation, pushing towards enhanced automation. Despite these advances, hardware circuits' inherent complexity and limited data present significant challenges. Recent studies have begun to explore various attributes of LLM-generated hardware code, including semantics, syntax, fluency, and flexibility. Given that many code generation methodologies rely on fine-tuned LLMs and face constraints due to the limited availability of datasets for hardware designs, this paper investigates the "diversity" of codes generated by LLMs. We introduce SimEval, a comprehensive, multifaceted metric vector designed to assess the similarity of LLM-generated hardware codes at the syntactic, structural, and behavioral levels, from high-level register transfer (RT-level) to synthesized (gate-level) netlists. SimEval uniquely combines sub-tree matching from abstract syntax trees (AST) with structural similarity based on kernel graphs for control flow graphs (CFG). Our experiments focusing on samples from GPT-3.5 datasets and evaluating their similarity using SimEval, highlight the critical role of SimEval in evaluating LLM-based hardware code generators w.r.t. diversity1.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {1002–1007},
numpages = {6},
keywords = {large language model (LLM), hardware design, similarity, finetuning, dataset, code synthesis},
location = {Tokyo, Japan},
series = {ASPDAC '25}
}

@inproceedings{10.1145/3638529.3654056,
author = {Jorgensen, Steven and Nadizar, Giorgia and Pietropolli, Gloria and Manzoni, Luca and Medvet, Eric and O'Reilly, Una-May and Hemberg, Erik},
title = {Large Language Model-based Test Case Generation for GP Agents},
year = {2024},
isbn = {9798400704949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638529.3654056},
doi = {10.1145/3638529.3654056},
abstract = {Genetic programming (GP) is a popular problem-solving and optimization technique. However, generating effective test cases for training and evaluating GP programs requires strong domain knowledge. Furthermore, GP programs often prematurely converge on local optima when given excessively difficult problems early in their training. Curriculum learning (CL) has been effective in addressing similar issues across different reinforcement learning (RL) domains, but it requires the manual generation of progressively difficult test cases as well as their careful scheduling. In this work, we leverage the domain knowledge and the strong generative abilities of large language models (LLMs) to generate effective test cases of increasing difficulties and schedule them according to various curricula. We show that by integrating a curriculum scheduler with LLM-generated test cases we can effectively train a GP agent player with environments-based curricula for a single-player game and opponent-based curricula for a multi-player game. Finally, we discuss the benefits and challenges of implementing this method for other problem domains.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {914–923},
numpages = {10},
keywords = {linear GP, large language models, curriculum learning},
location = {Melbourne, VIC, Australia},
series = {GECCO '24}
}

@inproceedings{10.1145/3706468.3706564,
author = {Ramanathan, Sriram and Lim, Lisa-Angelique and Mottaghi, Nazanin Rezazadeh and Buckingham Shum, Simon},
title = {When the Prompt becomes the Codebook: Grounded Prompt Engineering (GROPROE) and its application to Belonging Analytics},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706564},
doi = {10.1145/3706468.3706564},
abstract = {With the emergence of generative AI, the field of Learning Analytics (LA) has increasingly embraced the use of Large Language Models (LLMs) to automate qualitative analysis. Deductive analysis requires theoretical or other conceptual grounding to inform coding. However, few studies detail the process of translating the literature into a codebook, and then into an effective LLM prompt. In this paper, we introduce Grounded Prompt Engineering (GROPROE) as a systematic process to develop a literature-grounded prompt for deductive analysis. We demonstrate our GROPROE process on a dataset of 860 written reflections, coding for students’ affective engagement and sense of belonging. To evaluate the quality of the coding we demonstrate substantial human/LLM Inter-Annotator Reliability (IAR). To evaluate the consistency of LLM coding, a subset of the data was analysed 60 times using the LLM Quotient showing how this stabilized for most codes. We discuss the dynamics of human-AI interaction when following GROPROE, foregrounding how the prompt took over as the iteratively revised codebook, and how the LLM provoked codebook revision. The contributions to the LA field are threefold: (i) GROPROE as a systematic prompt-design process for deductive coding grounded in literature, (ii) a detailed worked example showing its application to Belonging Analytics, and (iii) implications for human-AI interaction in automated deductive analysis.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {713–725},
numpages = {13},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3706468.3706507,
author = {Xiao, Changrong and Ma, Wenxing and Song, Qingping and Xu, Sean Xin and Zhang, Kunpeng and Wang, Yufang and Fu, Qi},
title = {Human-AI Collaborative Essay Scoring: A Dual-Process Framework with LLMs},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706507},
doi = {10.1145/3706468.3706507},
abstract = {Receiving timely and personalized feedback is essential for second-language learners, especially when human instructors are unavailable. This study explores the effectiveness of Large Language Models (LLMs), including both proprietary and open-source models, for Automated Essay Scoring (AES). Through extensive experiments with public and private datasets, we find that while LLMs do not surpass conventional state-of-the-art (SOTA) grading models in performance, they exhibit notable consistency, generalizability, and explainability. We propose an open-source LLM-based AES system, inspired by the dual-process theory. Our system offers accurate grading and high-quality feedback, at least comparable to that of fine-tuned proprietary LLMs, in addition to its ability to alleviate misgrading. Furthermore, we conduct human-AI co-grading experiments with both novice and expert graders. We find that our system not only automates the grading process but also enhances the performance and efficiency of human graders, particularly for essays where the model has lower confidence. These results highlight the potential of LLMs to facilitate effective human-AI collaboration in the educational context, potentially transforming learning experiences through AI-generated feedback.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {293–305},
numpages = {13},
keywords = {LLM Application, Automatic Essay Scoring, AI-assisted Learning},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3681772.3698217,
author = {Tupayachi, Jose and Li, Xueping},
title = {Conversational Geographic Question Answering for Route Optimization: An LLM and Continuous Retrieval-Augmented Generation Approach},
year = {2025},
isbn = {9798400711510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3681772.3698217},
doi = {10.1145/3681772.3698217},
abstract = {We present a pilot study exploring the potential of Large Language Models (LLMs) to interface with application programming interfaces through logical instructions, specifically within the domain of Geographic Question Answering for route optimization. This study employs a Continuous Retrieval-Augmented Generation approach combined with fine-tuned LLMs, featuring customized node-based storage and vector search retrieval. We also provide a comparative analysis of the method's effectiveness and adaptability in handling diverse textual queries.},
booktitle = {Proceedings of the 17th ACM SIGSPATIAL International Workshop on Computational Transportation Science GenAI and Smart Mobility Session},
pages = {56–59},
numpages = {4},
keywords = {Geographical Information, Large Language Models, Question Answering, Retrieval Augmented Generation},
location = {Atlanta, GA, USA},
series = {IWCTS'24}
}

@inproceedings{10.1145/3716554.3716558,
author = {Maslaris, Ioannis and Karamanou, Areti and Kalampokis, Evangelos and Tarabanis, Konstantinos},
title = {Evaluating Large Language Models in Interaction with Open Government Data},
year = {2025},
isbn = {9798400713170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716554.3716558},
doi = {10.1145/3716554.3716558},
abstract = {Large Language Models (LLMs) exhibit great abilities in understanding and generating natural language. Open Government Data (OGD) are datasets that while are available to the public, their linked structure makes it difficult to access. Large language models can significantly enhance access to linked open government data by enabling users to interact with OGD portals using natural language. This study examines the use of LLMs to interact with open government linked data effectively and efficiently. Based on the QB vocabulary, we develop a framework that formulates the task. A set of 20 questions is developed to assess the capabilities of LLMs to execute OGD-related tasks. We propose a simple system in which LLMs interact semi-automatically with OGD. Our findings indicate that smaller and quantized versions of popular LLMs are capable of effectively managing these tasks, with Llama-3.1-8B-Instruct-bnb-4bit identified as the most effective model. This paper aims to promote further interest in systems that enhance Open Government Data portals and improve public access to open data.},
booktitle = {Proceedings of the 28th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {26–33},
numpages = {8},
keywords = {large language models, open government data, linked data, natural language processing},
location = {
},
series = {PCI '24}
}

@inproceedings{10.1145/3689535.3689546,
author = {Andrei, Oana and Sojtory, Zoltan},
title = {LLM-aided Pair Programming for Algorithm Tracing},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689546},
doi = {10.1145/3689535.3689546},
abstract = {The recent widespread popularity of generative AI models has inspired the development of large-language model (LLM) based tools for educational purposes. We explore the impact of LLM-based tools on pair programming for algorithm tracing with the aim of addressing challenges inherent to pair programming. We designed and developed a GPT-4 based tool, TraceCompanion, that acts as students’ pair programming partner for algorithm tracing. We describe insights gained from running a pilot study to investigate students’ interactions with the tool and their initial perceptions.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {20},
numpages = {1},
keywords = {algorithm tracing, large language models, pair programming},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3641555.3705235,
author = {Gonzalez, Elias and Chan, Joel and Weintrop, David},
title = {Quack! Configuring Large Language Models to Serve as Rubber Duck Coding Assistants},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705235},
doi = {10.1145/3641555.3705235},
abstract = {The emergence of Generative Artificial Intelligence (GenAI) tools broadly, and Large Language Models (LLMs) specifically, are equipping introductory programming instructors with a whole new class of pedagogical tools. While GenAI certainly poses threats to time-honored instructional techniques, it also provides opportunities for new forms of instructional support. In this work, we introduce our strategy for configuring an LLM to serve as a ''rubber duck debugging'' coding assistant to help novice programmers when they encounter difficulties in programming assignments. The key contribution of this work is not in the idea of using LLMs for debugging itself (which has already been demonstrated elsewhere, e.g., [3]) but to demonstrate the ease, flexibility, and pedagogical potential of the strategy. In particular, through carefully crafted prompts and easily accessible platforms, rubber duck LLMs can assist learners with specific questions while also situating those questions alongside larger computer science concepts and computational thinking practices. This work contributes an easily replicated and model-agnostic instructional strategy that productively and responsibly leverages the power of LLMs to assist novice programmers in developing foundational programming skills.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1463–1464},
numpages = {2},
keywords = {computer science education, generative ai, introductory programming, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3703187.3703290,
author = {Ma, Xiangfei and Li, Lin},
title = {Geological Disaster Named Entity Recognition with Small Samples Based on Data Augmentation and Prompt Engineering},
year = {2024},
isbn = {9798400707254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703187.3703290},
doi = {10.1145/3703187.3703290},
abstract = {This paper uses a large language model to perform generative data enhancement on the original small sample data by performing random synonym replacement and random mask filling operations. In accordance with the reasoning logic of the large language model, three prompt templates are designed and the reasons are explored. Experiments show that when the parameters remain unchanged, the data enhanced by this method has been greatly improved under the three prompt templates, alleviating the difficulty of low resources of geological disaster data. And by comparing the performance of different instructions under different learning rates, the fine-tuning learning rate range suitable for the field of geological disasters is summarized. The limitation is that it is constrained by local computing resources, which reduces the parameter scale of LLM, and the recognition performance is low for extremely long or complex texts.},
booktitle = {Proceedings of the 2024 7th International Conference on Computer Information Science and Artificial Intelligence},
pages = {613–617},
numpages = {5},
keywords = {Data Augmentation, Geological Disasters, LLMs, Named Entity Recognition, Prompt Engineering},
location = {
},
series = {CISAI '24}
}

@inproceedings{10.5555/3709347.3743537,
author = {Banna, Tahsin Tariq and Rahman, Sejuti and Tareq, Mohammad},
title = {Beyond Words: Integrating Personality Traits and Context-Driven Gestures in Human-Robot Interactions},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {As robots become increasingly integrated into human life, personalizing human-robot interactions (HRI) is crucial for improving user acceptance, engagement, and interaction quality. However, personalizing HRI poses a unique challenge due to the diversity of human personality traits. This paper proposes a method that leverages large language models (LLMs) to dynamically tailor robot conversations according to the Big Five (OCEAN) personality traits. Our novelty lies in using user personality traits to shape robots' verbal responses and implementing contextual action generation for gestures. This study addresses two primary research questions: (1) Does adapting robots' verbal responses based on user personality traits improve communication satisfaction? (2) How does the addition of context-appropriate gestures further enhance user satisfaction? We used Goldberg's personality trait measurement scale (1992) to assess 26 participants who engaged in conversations with an LLM-powered Pepper robot on various topics. The quality of these interactions was self-reported using a revised version of Hecht's (1978) conversation satisfaction scale. Three experimental conditions were conducted: (i) Baseline: Standard LLM conversation, (ii) Personality-congruent: LLM-adjusted dialogue based on personality of participants, and (iii) Enhanced interaction: Personality adaptation plus dynamic gestures. For the third condition, we implemented contextually appropriate pre-defined animations and generated novel gestures by computing joint angle values in real time. Statistical analysis using ANOVA revealed significant differences in communication satisfaction across the three conditions (F=13.41, p&lt;.001). Post-hoc analyses using \v{S}id\'{a}k's multiple comparison test showed significant pairwise differences: Condition 2 vs. 1: Δ Δmean 4.42 , p = 0.02; Condition 3 vs. 1: Δ Δmean 8.23, p &lt; 0.01; Condition 3 vs. 2: Δ Δmean 3.80, p = 0.05. These results demonstrate that both personality-congruent interactions and non-verbal gestures significantly enhance communication satisfaction, with the combined approach yielding the highest satisfaction. This approach opens new possibilities for developing socially intelligent robots with applications in healthcare, education, and customer service.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {242–251},
numpages = {10},
keywords = {HRI, LLM, generative actions, personality traits, robotics},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3656019.3676949,
author = {Park, Daon and Egger, Bernhard},
title = {Improving Throughput-oriented LLM Inference with CPU Computations},
year = {2024},
isbn = {9798400706318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656019.3676949},
doi = {10.1145/3656019.3676949},
abstract = {Large language models (LLMs) have recently captured the attention of a broad audience. To a large part, their exceptional performance in text generation was made possible by an exponential growth of the model parameters. This growth, however, comes at the expense of significantly higher operational costs and a decreased processing speed. Recent research has focused on running LLMs on commodity hardware, for example, by employing the memory hierarchy to augment throughput by increasing the number of batches. These studies, however, tend to overlook or inefficiently utilize the additional computational resources provided by the CPU. In this paper, we introduce a technique capable of efficiently harnessing all available computational resources through a finely tuned and dynamic workload allocation approach. This technique applies to decoder-based models on standard general-purpose hardware, effectively minimizing idle periods for both the CPU and the GPU. We conducted experiments involving various large language models, each representing distinct decoder-based architectures. Compared to the state-of-the-art, the results demonstrate a potential for an increase of up to 105% in throughput with the OPT-30B model.},
booktitle = {Proceedings of the 2024 International Conference on Parallel Architectures and Compilation Techniques},
pages = {233–245},
numpages = {13},
keywords = {CPU offloading, large language model generation, throughput-latency tradeoff},
location = {Long Beach, CA, USA},
series = {PACT '24}
}

@inproceedings{10.1145/3677052.3698651,
author = {Chen, Zekai and Chen, Po-Yu and Buet-Golfouse, Francois},
title = {Online Personalizing White-box LLMs Generation with Neural Bandits},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698651},
doi = {10.1145/3677052.3698651},
abstract = {Personalized content generation by Large Language Models (LLMs) in finance presents a challenge: efficiently adapting text to individual preferences without creating unique models for each user. This study introduces an innovative online method for financial applications, employing neural bandit algorithms to dynamically optimize soft instruction embeddings based on user feedback, enhancing personalization in white-box LLMs. Through experiments on public generation tasks, we demonstrate significant performance improvements. Notably, our NeuralTS implementation achieves up to a 62.9% improvement in ROUGE scores and a 2.76% increase in LLM-agent evaluation for personalized content generation. This research showcases the efficacy of neural bandits in refining LLM outputs to align with client-specific needs and regulatory requirements, marking a pivotal step towards feasible and effective adaptive text generation in finance. Our method offers a promising and scalable solution for financial institutions to enhance client engagement, improve risk assessment, and streamline regulatory reporting.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {711–718},
numpages = {8},
keywords = {Large language models, multi-armed bandits, personalization},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@inproceedings{10.1145/3701716.3715856,
author = {Hou, Yupeng and Zhang, An and Sheng, Leheng and Yang, Zhengyi and Wang, Xiang and Chua, Tat-Seng and McAuley, Julian},
title = {Generative Recommendation Models: Progress and Directions},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715856},
doi = {10.1145/3701716.3715856},
abstract = {Recommendation models typically follow a discriminative paradigm, predicting whether items should be retrieved. While effective, the expressive capabilities of these recommender systems are limited. Users can only passively browse the recommended items rather than actively express their needs and engage in an interactive experience. With recent advances in generative models such as large language models, a paradigm shift is happening in the study of recommender systems. Researchers propose building generative recommendation models either by aligning pre-trained generative models with user behaviors or designing recommendation models within a generative framework. These models enable the systems to receive and deliver more human-like content, such as natural language, images, and beyond. In this tutorial, we first provide an overview of the latest progress in generative recommendation models, covering approaches based on large language models, semantic IDs, diffusion models, and more. We then make an in-depth discussion on the challenges, open questions, and potential future directions in developing generative recommendation models.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {13–16},
numpages = {4},
keywords = {diffusion model, generative model, large language model, recommender system, semantic id},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3727648.3727779,
author = {Zhang, Meng and Xia, Youhong and Hu, Bo},
title = {TRec: A Multimodal Recommendation Framework Based on Multi-perspective Textual Representation of Images},
year = {2025},
isbn = {9798400712647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3727648.3727779},
doi = {10.1145/3727648.3727779},
abstract = {The advancement of multimodal recommendation systems leveraging large language models (LLMs) represents a critical future trend. Existing studies predominantly utilize multimodal content for item representation, often extracting image features and integrating them with other modalities through mapping models. However, these external features frequently differ significantly from the text-based representations inherent to LLMs, potentially diminishing their generative capabilities. To address this limitation and fully harness the text understanding strengths of LLMs, we propose a multimodal recommendation framework based on multi-perspective textual representation of images named TRec. Specifically, our approach employs a two-step generation strategy. First, a multimodal large model generates visual summaries of item images from multiple perspectives, including image descriptions, color, style, and evoked emotions, effectively transforming visual information into textual content. Second, we integrates these diverse visual perspectives into a unified textual summary, which serves as the final visual representation of the item. Extensive experiments conducted on two open-source datasets demonstrate the superior performance of the TRec.},
booktitle = {Proceedings of the 4th International Conference on Computer, Artificial Intelligence and Control Engineering},
pages = {801–805},
numpages = {5},
keywords = {Large Language Model, Multimodal, Recommender System},
location = {
},
series = {CAICE '25}
}

@inproceedings{10.1145/3658644.3690298,
author = {Nazzal, Mahmoud and Khalil, Issa and Khreishah, Abdallah and Phan, NhatHai},
title = {PromSec: Prompt Optimization for Secure Generation of Functional Source Code with Large Language Models (LLMs)},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690298},
doi = {10.1145/3658644.3690298},
abstract = {The capability of generating high-quality source code using large language models (LLMs) reduces software development time and costs. However, recent literature and our empirical investigation in this work show that while LLMs can generate functioning code, they inherently tend to introduce security vulnerabilities, limiting their potential. This problem is mainly due to their training on massive open-source corpora exhibiting insecure and inefficient programming practices. Therefore, automatic optimization of LLM prompts for generating secure and functioning code is a demanding need. This paper introduces PromSec, an algorithm for &lt;u&gt;prom&lt;/u&gt;pt optimization for &lt;u&gt;sec&lt;/u&gt;ure and functioning code generation using LLMs. In PromSec, we combine 1) code vulnerability clearing using a generative adversarial graph neural network, dubbed as gGAN, to fix and reduce security vulnerabilities in generated codes and 2) code generation using an LLM into an interactive loop, such that the outcome of the gGAN drives the LLM with enhanced prompts to generate secure codes while preserving their functionality. Introducing a new contrastive learning approach in gGAN, we formulate the code-clearing and generation loop as a dual-objective optimization problem, enabling PromSec to notably reduce the number of LLM inferences. As a result, PromSec becomes a cost-effective and practical solution for generating secure and functioning codes.Extensive experiments conducted on Python and Java code datasets confirm that PromSec effectively enhances code security while upholding its intended functionality. Our experiments show that despite the comprehensive application of a state-of-the-art approach, it falls short in addressing all vulnerabilities within the code, whereas PromSec effectively resolves each of them. Moreover, PromSec achieves more than an order-of-magnitude reduction in operational time, number of LLM queries, and security analysis costs. Furthermore, prompts optimized with PromSec for a certain LLM are transferable to other LLMs across programming languages and generalizable to unseen vulnerabilities in training. This study presents an essential step towards improving the trustworthiness of LLMs for secure and functioning code generation, significantly enhancing their large-scale integration in real-world software code development practices.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2266–2280},
numpages = {15},
keywords = {LLMs, code generation, graph generative adversarial networks, secure and functioning codes},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.5555/3709347.3743580,
author = {Dong, Wen and Mohd-Zaid, Fairul},
title = {Simulating and Evaluating Generative Modeling and Collaborative Filtering in Complex Social Networks},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {We introduce a multi-agent simulation framework for modeling large-scale online social dynamics by combining retrieval-augmented large language models, generative embedding methods, and collaborative filtering. Our approach learns diverse agent embeddings to capture varying user behaviors and employs a multi-layer perceptron for user-content ranking. We compare three strategies-(1) a generative modeling approach that integrates agent embeddings and collaborative filtering, (2) an LLM-based method grounded in historical context, and (3) a reflection-based clustering technique-and evaluate them on metrics such as comment volume, tree depth, user engagement patterns, and topic distribution. Results show that generative embeddings coupled with collaborative filtering better approximate complex phenomena like localized influencers, specialized subcommunities, and emergent echo chambers. Moreover, our framework supports policy-driven experimentation by incorporating social regularizers (cohesion, polarization, and bias) to simulate scenarios ranging from tightly knit communities to more balanced, cross-cutting interactions. By integrating large-scale data with adaptable LLM-driven agents, this work provides a versatile, data-centric foundation for simulating and analyzing online social ecosystems at scale.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {639–648},
numpages = {10},
keywords = {agent-based simulation, collaborative filtering, generative modeling, large language models (llms), online community behavior, social network analysis},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3701716.3715245,
author = {Ren, Jiyuan and Du, Zhaocheng and Wen, Zhihao and Jia, Qinglin and Dai, Sunhao and Wu, Chuhan and Dong, Zhenhua},
title = {Few-shot LLM Synthetic Data with Distribution Matching},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715245},
doi = {10.1145/3701716.3715245},
abstract = {As large language models (LLMs) advance, their ability to perform in-context learning and few-shot language generation has improved significantly. This has spurred using LLMs to produce high-quality synthetic data to enhance the performance of smaller models like online retrievers or weak LLMs. However, LLM-generated synthetic data often differs from the real data in key language attributes (e.g., styles, tones, content proportions, etc.). As a result, mixing these synthetic data directly with real data may distort the original data distribution, potentially hindering performance improvements. To solve this, we introduce SynAlign: a synthetic data generation and filtering framework based on key attribute distribution matching. Before generation, SynAlign employs an uncertainty tracker surrogated by the Gaussian Process model to iteratively select data clusters distinct from selected ones as demonstrations for new data synthesis, facilitating the efficient exploration diversity of the real data. Then, a latent attribute reasoning method is employed: the LLM summarizes linguistic attributes of demonstrations and then synthesizes new data based on them. This approach facilitates synthesizing diverse data with linguistic attributes that appear in real data. After generation, the Maximum Mean Discrepancy is used as the objective function to learn the sampling weight of each synthetic data, ensuring distribution matching with the real data. Our experiments on multiple text prediction tasks show significant performance improvements. We also conducted an online A/B test on an online retriever to demonstrate SynAlign's effectiveness. Our code is available https://github.com/nighood/SynAlign here.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {432–441},
numpages = {10},
keywords = {data augmentation, large language model, synthetic data},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3636243.3636259,
author = {Roest, Lianne and Keuning, Hieke and Jeuring, Johan},
title = {Next-Step Hint Generation for Introductory Programming Using Large Language Models},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636259},
doi = {10.1145/3636243.3636259},
abstract = {Large Language Models possess skills such as answering questions, writing essays or solving programming exercises. Since these models are easily accessible, researchers have investigated their capabilities and risks for programming education. This work explores how LLMs can contribute to programming education by supporting students with automated next-step hints. We investigate prompt practices that lead to effective next-step hints and use these insights to build our StAP-tutor. We evaluate this tutor by conducting an experiment with students, and performing expert assessments. Our findings show that most LLM-generated feedback messages describe one specific next step and are personalised to the student’s code and approach. However, the hints may contain misleading information and lack sufficient detail when students approach the end of the assignment. This work demonstrates the potential for LLM-generated feedback, but further research is required to explore its practical implementation.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {144–153},
numpages = {10},
keywords = {Generative AI, Large Language Models, Next-step hints, automated feedback, learning programming},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3709025.3712220,
author = {Doyle, Colin and Tucker, Aaron D.},
title = {If You Give an LLM a Legal Practice Guide},
year = {2025},
isbn = {9798400714214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709025.3712220},
doi = {10.1145/3709025.3712220},
abstract = {Large language models struggle to answer legal questions that require applying detailed, jurisdiction-specific legal rules. Lawyers also find these types of question difficult to answer. For help, lawyers turn to legal practice guides: expert-written how-to manuals for practicing a type of law in a particular jurisdiction. Might large language models also benefit from consulting these practice guides? This article investigates whether providing LLMs with excerpts from these guides can improve their ability to answer legal questions. Our findings show that adding practice guide excerpts to LLMs' prompts tends to help LLMs answer legal questions. But even when a practice guide provides clear instructions on how to apply the law, LLMs often fail to correctly answer straightforward legal questions - questions that any lawyer would be expected to answer correctly if given the same information. Performance varies considerably and unpredictably across different language models and legal subject areas. Across our experiments' different legal domains, no single model consistently outperformed others. LLMs sometimes performed better when a legal question was broken down into separate subquestions for the model to answer over multiple prompts and responses. But sometimes breaking legal questions down resulted in much worse performance. These results suggest that retrieval augmented generation (RAG) will not be enough to overcome LLMs' shortcomings with applying detailed, jurisdiction-specific legal rules. Replicating our experiments on the recently released OpenAI o1 and o3-mini advanced reasoning models did not result in consistent performance improvements. These findings cast doubt on claims that LLMs will develop competency at legal reasoning tasks without dedicated effort directed toward this specific goal.},
booktitle = {Proceedings of the 2025 Symposium on Computer Science and Law},
pages = {194–205},
numpages = {12},
keywords = {Large Language Models, Law, Propositional Logic, Reasoning Models, Retrieval Augmented Generation},
location = {Munich, Germany},
series = {CSLAW '25}
}

@inproceedings{10.1145/3706468.3706516,
author = {Venugopalan, Devika and Yan, Ziwen and Borchers, Conrad and Lin, Jionghao and Aleven, Vincent},
title = {Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706516},
doi = {10.1145/3706468.3706516},
abstract = {Caregivers (i.e., parents and members of a child’s caring community) are underappreciated stakeholders in learning analytics. Although caregiver involvement can enhance student academic outcomes, many obstacles hinder involvement, most notably knowledge gaps with respect to modern school curricula. An emerging topic of interest in learning analytics is hybrid tutoring, which includes instructional and motivational support. Caregivers assert similar roles in homework, yet it is unknown how learning analytics can support them. Our past work with caregivers suggested that conversational support is a promising method of providing caregivers with the guidance needed to effectively support student learning. We developed a system that provides instructional support to caregivers through conversational recommendations generated by a Large Language Model (LLM). Addressing known instructional limitations of LLMs, we use instructional intelligence from tutoring systems while conducting prompt engineering experiments with the open-source Llama 3 LLM. This LLM generated message recommendations for caregivers supporting their child’s math practice via chat. Few-shot prompting and combining real-time problem-solving context from tutoring systems with examples of tutoring practices yielded desirable message recommendations. These recommendations were evaluated with ten middle school caregivers, who valued recommendations facilitating content-level support and student metacognition through self-explanation. We contribute insights into how tutoring systems can best be merged with LLMs to support hybrid tutoring settings through conversational assistance, facilitating effective caregiver involvement in tutoring systems.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {373–383},
numpages = {11},
keywords = {large language models, tutoring systems, hybrid tutoring, K-12, mathematics education, caregivers},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3657604.3664698,
author = {Malik, Rizwaan and Abdi, Dorna and Wang, Rose and Demszky, Dorottya},
title = {Scaling High-Leverage Curriculum Scaffolding in Middle-School Mathematics},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664698},
doi = {10.1145/3657604.3664698},
abstract = {Despite well-designed curriculum materials, teachers often face significant challenges in their implementation due to the diverse learning needs present in classrooms. This paper examines whether and how Large Language Models (LLMs) can be leveraged to enhance K-12 math education by facilitating the creation of high-quality curriculum scaffolds that reflect expert teachers' strategies. Through an in-depth qualitative analysis with experienced middle-school math teachers, we identified crucial instructional supplements such as warm-up tasks and example-problem pairs that are essential for engaging students and supporting diverse learner needs. Building on these insights, we developed ScaffGen, an LLM-powered tool designed to generate curriculum-aligned educational materials. While LLMs alone may fall short in educational contexts, when enhanced with expert teacher insights, they can effectively emulate the cognitive processes required for pedagogically robust material creation. We plan to assess the effectiveness of these AI-generated materials through rigorous evaluations involving comparisons with expert-written benchmarks and field tests in classroom settings. This research highlights the potential of LLMs to mimic expert decision-making in educational material creation, offering significant implications for scalable instructional support.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {476–480},
numpages = {5},
keywords = {curriculum scaffolding, human-computer interaction, large language models},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3641825.3687716,
author = {Christiansen, Frederik Roland and Hollensberg, Linus N\o{}rgaard and Jensen, Niko Bach and Julsgaard, Kristian and Jespersen, Kristian Nyborg and Nikolov, Ivan},
title = {Exploring Presence in Interactions with LLM-Driven NPCs: A Comparative Study of Speech Recognition and Dialogue Options},
year = {2024},
isbn = {9798400705359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641825.3687716},
doi = {10.1145/3641825.3687716},
abstract = {Combining modern technologies like large-language models (LLMs), speech-to-text, and text-to-speech can enhance immersion in virtual reality (VR) environments. However, challenges exist in effectively implementing LLMs and educating users. This paper explores implementing LLM-powered virtual social actors and facilitating user communication. We developed a murder mystery game where users interact with LLM-based non-playable characters (NPCs) through interrogation, clue-gathering, and exploration. Two versions were tested: one using speech recognition and another with traditional dialog boxes. While both provided similar social presence, users felt more immersed with speech recognition but found it overwhelming, while the dialog version was more challenging. Slow NPC response times were a source of frustration, highlighting the need for faster generation or better masking for a seamless experience.},
booktitle = {Proceedings of the 30th ACM Symposium on Virtual Reality Software and Technology},
articleno = {6},
numpages = {11},
keywords = {Immersive systems, Large Language Models (LLM), NPC, Presence, Social Actors, Speech Recognition, VR},
location = {Trier, Germany},
series = {VRST '24}
}

@inproceedings{10.1145/3717867.3717904,
author = {Juvino Santos, Lucas Rani\'{e}re and Balby Marinho, Leandro and Calazans Campelo, Claudio Elizio and Menczer, Filippo and Flammini, Alessandro},
title = {Can Large Language Models Effectively Mitigate Polarization in Social Media Text?},
year = {2025},
isbn = {9798400714832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3717867.3717904},
doi = {10.1145/3717867.3717904},
abstract = {Social media are linked to phenomena, such as echo chambers and the spread of misinformation, that contribute to heightened political polarization. Textual content has been identified as a key factor in fueling online polarization, yet effective strategies to mitigate this issue remain underexplored. This study investigates the potential of Large Language Models (LLMs) to reduce textual polarization on social media platforms. We leveraged a large-scale dataset of tweets collected during Brazil’s last presidential election, one of the most polarized in the country’s history. We used an LLM to paraphrase polarized text and make it less polarized. Using a between-subjects experimental design with N=73 participants, we compared human perceptions of paraphrases generated by the LLM and by humans. Both LLM- and human-generated paraphrases significantly reduced perceived polarization in tweets while preserving textual coherence. Furthermore, LLMs performed comparably to humans in depolarizing content. These findings underscore the potential of LLMs as effective and scalable tools for mitigating polarization on social media, contributing to healthier online discourse.},
booktitle = {Proceedings of the 17th ACM Web Science Conference 2025},
pages = {348–357},
numpages = {10},
keywords = {Political Polarization, Social Media Networks, Large Language Models, Textual Polarization, Natural Language Processing},
location = {
},
series = {Websci '25}
}

@article{10.1145/3722108,
author = {Tony, Catherine and D\'{\i}az Ferreyra, Nicol\'{a}s E. and Mutas, Markus and Dhif, Salem and Scandariato, Riccardo},
title = {Prompting Techniques for Secure Code Generation: A Systematic Investigation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3722108},
doi = {10.1145/3722108},
abstract = {Large Language Models (LLMs) are gaining momentum in software development with prompt-driven programming enabling developers to create code from natural language (NL) instructions. However, studies have questioned their ability to produce secure code and, thereby, the quality of prompt-generated software. Alongside, various prompting techniques that carefully tailor prompts have emerged to elicit optimal responses from LLMs. Still, the interplay between such prompting strategies and secure code generation remains under-explored and calls for further investigations. Objective: In this study, we investigate the impact of different prompting techniques on the security of code generated from NL instructions by LLMs. Method: First we perform a systematic literature review to identify the existing prompting techniques that can be used for code generation tasks. A subset of these techniques are evaluated on GPT-3, GPT-3.5, and GPT-4 models for secure code generation. For this, we used an existing dataset consisting of 150 NL security-relevant code-generation prompts. Results: Our work (i) classifies potential prompting techniques for code generation (ii) adapts and evaluates a subset of the identified techniques for secure code generation tasks and (iii) observes a reduction in security weaknesses across the tested LLMs, especially after using an existing technique called Recursive Criticism and Improvement (RCI), contributing valuable insights to the ongoing discourse on LLM-generated code security.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
keywords = {LLMs, secure code generation, prompt engineering}
}

@inproceedings{10.1145/3706598.3714115,
author = {Ma, Jenny GuangZhen and Sreedhar, Karthik and Liu, Vivian and Perez, Pedro A. and Wang, Sitong and Sahni, Riya and Chilton, Lydia B},
title = {DynEx: Dynamic Code Synthesis with Structured Design Exploration for Accelerated Exploratory Programming},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714115},
doi = {10.1145/3706598.3714115},
abstract = {Recent advancements in large language models have significantly expedited the process of generating front-end code. This allows users to rapidly prototype user interfaces and ideate through code, a process known as exploratory programming. However, existing LLM code generation tools focus more on technical implementation details rather than finding the right design given a particular problem. We present DynEx, an LLM-based method for design exploration in accelerated exploratory programming. DynEx introduces a technique to explore the design space through a structured Design Matrix before creating the prototype with a modular, stepwise approach to LLM code generation. Code is generated sequentially, and users can test and approve each step before moving onto the next. A user study of 10 experts found that DynEx increased design exploration and enabled the creation of more complex and varied prototypes compared to a Claude Artifact baseline. We conclude with a discussion of the implications of design exploration for exploratory programming.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {873},
numpages = {27},
keywords = {code synthesis, exploratory programming, design exploration, design matrix, user interface, prototyping},
location = {
},
series = {CHI '25}
}

@article{10.1177/26339137241305117,
author = {Heyman, Jennifer L and Rick, Steven R and Giacomelli, Gianni and Wen, Haoran and Laubacher, Robert J and Taubenslag, Nancy and Ragupathy, Pranav and Curhan, Jared and Malone, Thomas W and Knicker, Max Sina and Jeddi, Younes},
title = {Supermind Ideator: How scaffolding Human-AI collaboration can increase creativity},
year = {2024},
issue_date = {October-December 2024},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {3},
number = {4},
url = {https://doi.org/10.1177/26339137241305117},
doi = {10.1177/26339137241305117},
abstract = {Previous efforts to support creative problem-solving have included (a) techniques such as brainstorming and design thinking to stimulate creative ideas, and (b) software tools to record and share these ideas. Now, generative AI technologies can suggest new ideas that might never have occurred to the users, and users can then select from these ideas or use them to stimulate even more ideas. To explore these possibilities, we developed a system called Supermind Ideator that uses a large language model (LLM) and adds prompts, fine tuning, and a specialized user interface in order to help users reformulate their problem statements and generate possible solutions. This provides scaffolding to guide users through a set of creative problem-solving techniques, including some techniques specifically intended to help generate innovative ideas about designing groups of people and/or computers (“superminds”). In an experimental study, we found that people using Supermind Ideator generated significantly more innovative ideas than those generated by people using ChatGPT or people working alone. Thus our results suggest that the benefits of using LLMs for creative problem-solving can be substantially enhanced by scaffolding designed specifically for this purpose.},
journal = {Collective Intelligence},
month = dec,
numpages = {17},
keywords = {Creativity, innovation, collective intelligence, generative AI, scaffolding, large language models}
}

@inproceedings{10.1145/3626252.3630927,
author = {Kirova, Vassilka D. and Ku, Cyril S. and Laracy, Joseph R. and Marlowe, Thomas J.},
title = {Software Engineering Education Must Adapt and Evolve for an LLM Environment},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630927},
doi = {10.1145/3626252.3630927},
abstract = {In the era of artificial intelligence (AI), generative AI, and Large Language Models (LLMs) in particular, have become increasingly significant in various sectors. LLMs such as GPT expand their applications, from content creation to advanced code completion. They offer unmatched opportunities but pose unique challenges to the software engineering domain. This paper discusses the necessity and urgency for software engineering education to adapt and evolve to prepare software engineers for the emerging LLM environment. While existing literature and social media have investigated AI's integration into various educational spheres, there is a conspicuous gap in examining the specifics of LLMs' implications for software engineering education. We explore the goals of software engineering education, and changes to software engineering, software engineering education, course pedagogy, and ethics. We argue that a holistic approach is needed, combining technical skills, ethical awareness, and adaptable learning strategies. This paper seeks to contribute to the ongoing conversation about the future of software engineering education, emphasizing the importance of adapting and evolving to remain in sync with rapid advancements in AI and LLMs. It is hoped that this exploration will provide valuable insights for educators, curriculum developers, and policymakers in software engineering.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {666–672},
numpages = {7},
keywords = {chatgpt, generative ai, large language models (llms), responsible ai, software engineering, software engineering education, software engineering ethics, software ethics},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649329.3663498,
author = {Qayyum, Khushboo and Hassan, Muhammad and Ahmadi-Pour, Sallar and Jha, Chandan Kumar and Drechsler, Rolf},
title = {Late Breaking Results: LLM-assisted Automated Incremental Proof Generation for Hardware Verification},
year = {2024},
isbn = {9798400706011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649329.3663498},
doi = {10.1145/3649329.3663498},
abstract = {In this paper, we propose a methodology for hardware verification assisted by Large Language Models (LLMs) in the incremental proof generation process. First, an LLM identifies the basic module of the Design Under Verification (DUV), followed by expanding the proof scope as more modules are added. LLMs assist in defining and verifying invariants for each module using the Z3 solver, and in formulating integration properties at module interfaces. Our case studies on a Ripple Carry Adder (RCA) and a Dadda Tree Multiplier (DTM) demonstrate that LLMs enhance the efficiency and accuracy of hardware verification.},
booktitle = {Proceedings of the 61st ACM/IEEE Design Automation Conference},
articleno = {349},
numpages = {2},
location = {San Francisco, CA, USA},
series = {DAC '24}
}

@article{10.1145/3711857,
author = {Hu, Linmei and Zhang, Xinyu and Song, Dandan and Zhou, Changzhi and He, Hongyu and Nie, Liqiang},
title = {Efficient and Effective Role Player: A Compact Knowledge-grounded Persona-based Dialogue Model Enhanced by LLM Distillation},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/3711857},
doi = {10.1145/3711857},
abstract = {Incorporating explicit personas into dialogue models is critical for generating responses that fulfill specific user needs and preferences, creating a more personalized and engaging interaction. Early works on persona-based dialogue generation directly concatenate the persona descriptions and dialogue history into relatively small pre-trained language models (PLMs) for response generation, which leads to uninformative and inferior results due to the sparse persona information and the limited model generation capabilities. Recently, large language models (LLMs) have shown their surprising capabilities in language generation. Prompting the LLMs with the persona descriptions for role-playing dialogue generation has also achieved promising results. However, deploying LLMs is challenging for practical applications due to their large scale, spurring efforts to distill the generation capabilities into more concise and compact models through teacher-student learning. In this article, we propose an efficient compact Knowledge-grounded Persona-based Dialogue model enhanced by LLM Distillation (KPDD). Specifically, first, we propose to enrich the annotated persona descriptions by integrating external knowledge graphs (KGs) with a mixed encoding network, coupled with a mixture of experts (MoE) module for both informative and diverse response generation. The mixed encoding network contains multiple layers of modality interaction operations, enabling information from both modalities propagates to the other. Second, to fully exploit the generation capabilities of LLMs, we turn to the distillation technique to improve the generation capabilities of our model, facilitated by a natural language inference (NLI)-based filtering mechanism to extract high-quality information from LLMs. In addition, we employ a curriculum learning strategy to train our model on the high-quality filtered distilled data and progressively on the relatively noisy original data, enhancing its adaptability and performance. Extensive experiments show that KPDD outperforms state-of-the-art baselines in terms of both automatic and human evaluation.},
journal = {ACM Trans. Inf. Syst.},
month = feb,
articleno = {59},
numpages = {29},
keywords = {Persona-based Dialogue Generation, Knowledge Graph, MoE, Large Language Model, Distillation, Curriculum Learning}
}

@inproceedings{10.1145/3641554.3701972,
author = {Ahmed, Umair Z. and Sahai, Shubham and Leong, Ben and Karkare, Amey},
title = {Feasibility Study of Augmenting Teaching Assistants with AI for CS1 Programming Feedback},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701972},
doi = {10.1145/3641554.3701972},
abstract = {With the increasing adoption of Large Language Models (LLMs), there are proposals to replace human Teaching Assistants (TAs) with LLM-based AI agents for providing feedback to students. In this paper, we explore a new hybrid model where human TAs receive AI-generated feedback for CS1 programming exercises, which they can then review and modify as needed. We conducted a large-scale randomized intervention with 185 CS1 undergraduate students, comparing the efficacy of this hybrid approach against manual feedback and direct AI-generated feedback.Our initial hypothesis predicted that AI-augmented feedback would improve TA efficiency and increase the accuracy of guidance to students. However, our findings revealed mixed results. Although students perceived improvements in feedback quality, the hybrid model did not consistently translate to better student performance. We also observed complacency among some TAs who over-relied on LLM generated feedback and failed to identify and correct inaccuracies. These results suggest that augmenting human tutors with AI may not always result in improved teaching outcomes, and further research is needed to ensure it is truly effective.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {11–17},
numpages = {7},
keywords = {cs1, gpt, hint, llm, programming, randomized trial, ta},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3643651.3659892,
author = {Zhang, Lan and Zou, Qingtian and Singhal, Anoop and Sun, Xiaoyan and Liu, Peng},
title = {Evaluating Large Language Models for Real-World Vulnerability Repair in C/C++ Code},
year = {2024},
isbn = {9798400705564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643651.3659892},
doi = {10.1145/3643651.3659892},
abstract = {The advent of Large Language Models (LLMs) has enabled advancement in automated code generation, translation, and summarization. Despite their promise, evaluating the use of LLMs in repairing real-world code vulnerabilities remains underexplored. In this study, we address this gap by evaluating the capability of advanced LLMs, such as ChatGPT-4 and Claude, in fixing memory corruption vulnerabilities in real-world C/C++ code. We meticulously curated 223 real-world C/C++ code snippets encompassing a spectrum of memory corruption vulnerabilities, ranging from straightforward memory leaks to intricate buffer errors. Our findings demonstrate the proficiency of LLMs in rectifying simple memor errors like leaks, where fixes are confined to localized code segments. However, their effectiveness diminishes when addressing complicated vulnerabilities necessitating reasoning about cross-cutting concerns and deeper program semantics. Furthermore, we explore techniques for augmenting LLM performance by incorporating additional knowledge. Our results shed light on both the strengths and limitations of LLMs in automated program repair on genuine code, underscoring the need for advancements in reasoning abilities for handling complex code repair tasks.},
booktitle = {Proceedings of the 10th ACM International Workshop on Security and Privacy Analytics},
pages = {49–58},
numpages = {10},
keywords = {deep learning, large language models, program repair},
location = {Porto, Portugal},
series = {IWSPA '24}
}

@inproceedings{10.5555/3721488.3721651,
author = {Ashok, Ashita and Bruno, Barbara and Helf, Tamara and Berns, Karsten},
title = {"Thanks for the Practice!": LLM-Powered Social Robot as Tandem Language Partner at University},
year = {2025},
publisher = {IEEE Press},
abstract = {Large language models (LLMs), when integrated into social robots, have the potential to transform robot-assisted language learning by offering personalized, interactive communication. However, there is limited research exploring their potential to simultaneously reduce anxiety and enhance language-speaking skills among international university students, who often feel anxious when speaking a foreign language. This study addresses this gap by evaluating the impact of a humanoid robot powered by the OpenChat-3.5 LLM as a tandem partner for German language learning. Using a between-subjects design with 22 multilingual participants, two interaction conditions were tested: immersive (German-only) and bilingual (German-English). Our findings indicate that participants in the immersive mode reported experiencing significantly reduced perceived judgment by the robot compared to the bilingual mode. Although female participants showed a trend of greater improvement in learning gain, no significant gender differences were found. Open-ended feedback highlighted the need for enhanced contextual responses, slower speech rate, faster response times, and error corrections to enhance language speaking support. This study aims to advance social robots for learning by demonstrating the usage of generative AI in creating non-judgmental language practice scenarios.},
booktitle = {Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1221–1226},
numpages = {6},
keywords = {human-robot interaction, robot-assisted language learning, social robots},
location = {Melbourne, Australia},
series = {HRI '25}
}

@inproceedings{10.1145/3701716.3715201,
author = {Ju, Chenlu and Liu, Jiaxin and Sinha, Shobhit and Xue, Hao and Salim, Flora},
title = {TrajLLM: A Modular LLM-Enhanced Agent-Based Framework for Realistic Human Trajectory Simulation},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715201},
doi = {10.1145/3701716.3715201},
abstract = {This work leverages Large Language Models (LLMs) to simulate human mobility, addressing challenges like high costs and privacy concerns in traditional models. Our hierarchical framework integrates persona generation, activity selection, and destination prediction, using real-world demographic and psychological data to create realistic movement patterns. Both physical models and language models are employed to explore and demonstrate different methodologies for human mobility simulation. By structuring data with summarization and weighted density metrics, the system ensures scalable memory management while retaining actionable insights. Preliminary results indicate that LLM-driven simulations align with observed real-world patterns, offering scalable, interpretable insights for social problems such as urban planning, traffic management, and public health. The framework's ability to dynamically generate personas and activities enables it to provide adaptable and realistic daily routines. This study demonstrates the transformative potential of LLMs in advancing mobility modeling for societal and urban applications. The source code and interactive demo for our framework are available at https://github.com/cju0/TrajLLM.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2847–2850},
numpages = {4},
keywords = {agent-based simulation, human mobility generation}, large language models},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3613905.3650841,
author = {Brachman, Michelle and El-Ashry, Amina and Dugan, Casey and Geyer, Werner},
title = {How Knowledge Workers Use and Want to Use LLMs in an Enterprise Context},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650841},
doi = {10.1145/3613905.3650841},
abstract = {Large Language Models (LLMs) have introduced a paradigm shift in interaction with AI technology, enabling knowledge workers to complete tasks by specifying their desired outcome in natural language. LLMs have the potential to increase productivity and reduce tedious tasks in an unprecedented way. A systematic study of LLM adoption for work can provide insight into how LLMs can best support these workers. To explore knowledge workers’ current and desired usage of LLMs, we ran a survey (n=216). Workers described tasks they already used LLMs for, like generating code or improving text, but imagined a future with LLMs integrated into their workflows and data. We discuss implications for adoption and design of generative AI technologies for knowledge work.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {189},
numpages = {8},
keywords = {adoption, knowledge workers, large language models, survey},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3707292.3707389,
author = {Li, Yanjun and Yang, Ruiting and Guo, Donghao and Song, Yu},
title = {Research on the Construction of Digital Knowledge Graphs Based on Resources of National First-Class Undergraduate Programs},
year = {2025},
isbn = {9798400707308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3707292.3707389},
doi = {10.1145/3707292.3707389},
abstract = {[Purpose/Significance]: The digitalization of education is an essential path to advancing higher education. The construction of knowledge graphs is a key approach to achieving the digitalization and intelligence of education. [Method/Process]: This paper leverages the rich video resources of existing national first-class undergraduate programs and, based on the teaching orientations of different universities, independently designs customized ontologies and extraction principles. These are then integrated into the LLM knowledge graph builder to ensure the hierarchical structure of the overall course framework. The course video content is transformed into text form, and large language models (LLMS) and word segmentation tools are used for core content extraction, text cleaning, and lexical analysis. The structured text is then converted into SPO (Subject-Predicate-Object) triplets database. [Results/Conclusions]: Finally, the database is imported into the LLM knowledge graph builder, which is pre-configured with extraction rules. It will automatically generate the knowledge graph. After the text is imported into the LLM knowledge graph builder, it will be manually checked to ensure it better meets the actual needs of the students. [Innovation/Limitations]: The research team plans to apply the knowledge graph to train a specialized knowledge-based Q&amp;A assistant. This will support students' understanding and self-assessment of knowledge points in an online learning community. Student feedback will be used to improve and enrich the knowledge graph. Compared to existing methods, this approach better aligns with the constantly evolving digital teaching resources available online, offering more comprehensive and higher-level automation.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Intelligent Information Processing},
pages = {353–359},
numpages = {7},
keywords = {Knowledge graph, course resources, intelligent Q&amp;A, ontology construction, personalized learning},
location = {
},
series = {AIIIP '24}
}

@inproceedings{10.1145/3585059.3611409,
author = {Gumina, Sharon and Dalton, Travis and Gerdes, John},
title = {Teaching IT Software Fundamentals: Strategies and Techniques for Inclusion of Large Language Models: Strategies and Techniques for Inclusion of Large Language Models},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611409},
doi = {10.1145/3585059.3611409},
abstract = {This paper argues for the inclusion of tools that utilize Artificial Intelligence (AI) Large Language Models (LLMs) in information technology (IT) undergraduate courses that teach the fundamentals of software. LLM tools have become widely available and disrupt traditional methods for teaching software concepts. Learning objectives are compromised when students submit AI-generated code for a classroom assignment without comprehending or validating the code. Since LLM tools including OpenAI Codex, Copilot by GitHub, and ChatGPT are being used in industry for software development, students need to be familiar with their use without compromising student learning. Incorporating LLM tools into the curriculum prepares students for real-world software development. However, students still need to understand software fundamentals including how to write and debug code. There are many challenges associated with the inclusion of AI tools into the IT curriculum that need to be addressed and mitigated. This paper presents strategies and techniques to integrate student use of LLM tools, assist students’ interaction with the tools, and help prepare students for careers that increasingly use AI tools to design, develop, and maintain software.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {60–65},
numpages = {6},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@inproceedings{10.1145/3701716.3718377,
author = {Li, Cheng-Te and Ku, Lun-Wei},
title = {The First International Workshop on Large Language Models for Social Media (SocialLLM 2025)},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3718377},
doi = {10.1145/3701716.3718377},
abstract = {The rapid evolution of Large Language Models (LLMs) has profoundly impacted social media, transforming how information is generated, disseminated, and analyzed. With their ability to process vast amounts of data, grasp contextual nuances, and engage in human-like dialogue, LLMs present new opportunities and challenges for understanding online interactions. The SocialLLM 2025 workshop builds on the foundation laid by SocialNLP, expanding the scope to explore the capabilities and implications of LLMs in social media research. This year's workshop at TheWebConf 2025 focuses on three pivotal themes: leveraging LLMs for mental health support, enhancing emotion detection in textual interactions, and improving misinformation detection through active learning. The selected papers illustrate cutting-edge advancements in these areas, demonstrating how LLMs can be fine-tuned for therapeutic dialogue generation, assessed for their emotional intelligence, and optimized for misinformation detection with minimal labeled data. These contributions highlight the growing interdisciplinary nature of LLM research, merging insights from natural language processing, social computing, and artificial intelligence ethics. By bringing together researchers and practitioners from diverse backgrounds, SocialLLM 2025 aims to foster meaningful discussions on the opportunities and risks associated with LLM-driven social media applications. The workshop serves as a platform for exploring novel methodologies, addressing ethical concerns, and shaping future directions for responsible AI deployment in social media environments. Through collaborative efforts, we seek to advance the field and ensure that LLMs contribute positively to the digital ecosystem.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2589–2591},
numpages = {3},
keywords = {chatgpt, deep learning, generative ai, large language models, natural language processing, social media, social networks, text mining},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3691620.3695480,
author = {Chen, Jiachi and Zhong, Qingyuan and Wang, Yanlin and Ning, Kaiwen and Liu, Yongkun and Xu, Zenan and Zhao, Zhe and Chen, Ting and Zheng, Zibin},
title = {RMCBench: Benchmarking Large Language Models' Resistance to Malicious Code},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695480},
doi = {10.1145/3691620.3695480},
abstract = {Warning: Please note that this article contains potential harmful or offensive content. This content is only for the evaluating and analysis of LLMs and does not imply any intention to promote criminal activities.The emergence of Large Language Models (LLMs) has significantly influenced various aspects of software development activities. Despite their benefits, LLMs also pose notable risks, including the potential to generate harmful content and being abused by malicious developers to create malicious code. Several previous studies have focused on the ability of LLMs to resist the generation of harmful content that violates human ethical standards, such as biased or offensive content. However, there is no research evaluating the ability of LLMs to resist malicious code generation. To fill this gap, we propose RMCBench, the first benchmark comprising 473 prompts designed to assess the ability of LLMs to resist malicious code generation. This benchmark employs two scenarios: a text-to-code scenario, where LLMs are prompted with descriptions to generate code, and a code-to-code scenario, where LLMs translate or complete existing malicious code. Based on RMCBench, we conduct an empirical study on the 11 representative LLMs to assess their ability to resist malicious code generation. Our findings indicate that current LLMs have a limited ability to resist malicious code generation with an average refusal rate of 40.36% in text-to-code scenario and 11.52% in code-to-code scenario. The average refusal rate of all LLMs in RMCBench is only 28.71%; ChatGPT-4 has a refusal rate of only 35.73%. We also analyze the factors that affect LLM's ability to resist malicious code generation and provide implications for developers to enhance model robustness.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {995–1006},
numpages = {12},
keywords = {large language models, malicious code, code generation},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695468,
author = {JianWang and Liu, Shangqing and Xie, Xiaofei and Li, Yi},
title = {An Empirical Study to Evaluate AIGC Detectors on Code Content},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695468},
doi = {10.1145/3691620.3695468},
abstract = {Artificial Intelligence Generated Content (AIGC) has garnered considerable attention for its impressive performance, with Large Language Models (LLMs), like ChatGPT, emerging as a leading AIGC model that produces high-quality responses across various applications, including software development and maintenance. Despite its potential, the misuse of LLMs, especially in security and safety-critical domains, such as academic integrity and answering questions on Stack Overflow, poses significant concerns. Numerous AIGC detectors have been developed and evaluated on natural language data. However, their performance on code-related content generated by LLMs remains unexplored.To fill this gap, in this paper, we present an empirical study evaluating existing AIGC detectors in the software domain. We select three state-of-the-art LLMs, i.e., GPT-3.5, WizardCoder and CodeLlama, for machine-content generation. We further created a comprehensive dataset including 2.23M samples comprising code-related content for each model, encompassing popular software activities like Q&amp;A (150K), code summarization (1M), and code generation (1.1M). We evaluated thirteen AIGC detectors, comprising six commercial and seven open-source solutions, assessing their performance on this dataset. Our results indicate that AIGC detectors perform less on code-related data than natural language data. Fine-tuning can enhance detector performance, especially for content within the same domain; but generalization remains a challenge.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {844–856},
numpages = {13},
keywords = {AIGC detection, code generation, large language model},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695360,
author = {Xu, Jia and Du, Weilin and Liu, Xiao and Li, Xuejun},
title = {LLM4Workflow: An LLM-based Automated Workflow Model Generation Tool},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695360},
doi = {10.1145/3691620.3695360},
abstract = {Workflows are pervasive in software systems where business processes and scientific methods are implemented as workflow models to achieve automated process execution. However, despite the benefit of no/low-code workflow automation, creating workflow models requires in-depth domain knowledge and nontrivial workflow modeling skills, which becomes a hurdle for the proliferation of workflow applications. Recently, Large language models (LLMs) have been widely applied in software code generation given their outstanding ability to understand complex instructions and generate accurate, context-aware code. Inspired by the success of LLMs in code generation, this paper aims to investigate how to use LLMs to automate workflow model generation. We present LLM4Workflow, an LLM-based automated workflow model generation tool. Using workflow descriptions as the input, LLM4Workflow can automatically embed relevant API knowledge and leverage LLM's powerful contextual learning abilities to generate correct and executable workflow models. Its effectiveness was validated through functional verification and simulation tests on a real-world workflow system. LLM4Workflow is open sourced at https://github.com/ISEC-AHU/LLM4Workflow, and the demo video is provided at https://youtu.be/XRQ0saKkuxY.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2394–2398},
numpages = {5},
keywords = {automated workflow model generation, large language models, low code development},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3661167.3661221,
author = {Coignion, Tristan and Quinton, Cl\'{e}ment and Rouvoy, Romain},
title = {A Performance Study of LLM-Generated Code on Leetcode},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661221},
doi = {10.1145/3661167.3661221},
abstract = {This study evaluates the efficiency of code generation by Large Language Models (LLMs) and measures their performance against human-crafted solutions using a dataset from Leetcode. We compare 18 LLMs, considering factors such as model temperature and success rate, and their impact on code performance. This research introduces a novel method for measuring and comparing the speed of LLM-generated code, revealing that LLMs produce code with comparable performance, irrespective of the adopted LLM. We also find that LLMs are capable of generating code that is, on average, more efficient than the code written by humans. The paper further discusses the use of Leetcode as a benchmarking dataset, the limitations imposed by potential data contamination, and the platform’s measurement reliability. We believe that our findings contribute to a better understanding of LLM capabilities in code generation and set the stage for future optimizations in the field.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {79–89},
numpages = {11},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3706599.3719940,
author = {He, Tianhao and Saravanan, Karthi and Niforatos, Evangelos and Kortuem, Gerd},
title = {"A Great Start, But...": Evaluating LLM-Generated Mind Maps for Information Mapping in Video-Based Design},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719940},
doi = {10.1145/3706599.3719940},
abstract = {Extracting concepts and understanding relationships from videos is essential in Video-Based Design (VBD), where videos serve as a primary medium for exploration but require significant effort in managing meta-information. Mind maps, with their ability to visually organize complex data, offer a promising approach for structuring and analysing video content. Recent advancements in Large Language Models (LLMs) provide new opportunities for meta-information processing and visual understanding in VBD, yet their application remains underexplored. This study recruited 28 VBD practitioners to investigate the use of prompt-tuned LLMs for generating mind maps from ethnographic videos. Comparing LLM-generated mind maps with those created by professional designers, we evaluated rated scores, design effectiveness, and user experience across two contexts. Findings reveal that LLMs effectively capture central concepts but struggle with hierarchical organization and contextual grounding. We discuss trust, customization, and workflow integration as key factors to guide future research on LLM-supported information mapping in VBD.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {1},
numpages = {7},
keywords = {Information Mapping, Large Language Model, Video-based Design, Designer-AI Collaboration},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3663649.3664368,
author = {Aerts, Willem and Fletcher, George and Miedema, Daphne},
title = {A Feasibility Study on Automated SQL Exercise Generation with ChatGPT-3.5},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664368},
doi = {10.1145/3663649.3664368},
abstract = {SQL is the standard for database query languages and is taught in most introductory database courses. Query languages are illustrated and tested through toy examples: small, accessible, instances of databases. These are not always engaging, but coming up with new examples and questions is time-consuming. Existing research in Computer Science Education has shown that Large Language Models (LLMs) can generate coding exercises. However, this has not been demonstrated for SQL yet but could save teachers much time. In this paper, we study whether it is feasible to have ChatGPT-3.5 generate database schemas and associated SQL questions for teachers through a two-part study. Through a survey of educators, we found that creating a story and database schema for the SQL part is more time-consuming than the questions themselves. In our prompt engineering study, we identified prompts that were successful at creating database schemas, mock data, and exercises. However, although ChatGPT could help reduce the time required to create exams, some participants indicated that they are skeptical about using LLMs.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {13–19},
numpages = {7},
keywords = {Assessment, ChatGPT, Education, LLM, SQL},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{10.1145/3610978.3640767,
author = {Verma, Mudit and Bhambri, Siddhant and Kambhampati, Subbarao},
title = {Theory of Mind Abilities of Large Language Models in Human-Robot Interaction: An Illusion?},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3640767},
doi = {10.1145/3610978.3640767},
abstract = {Large Language Models (LLMs) have shown exceptional generative abilities in various natural language and generation tasks. However, possible anthropomorphization and leniency towards failure cases have propelled discussions on emergent abilities of LLMs especially on Theory of Mind (ToM) abilities in Large Language Models. While several false-belief tests exists to verify the ability to infer and maintain mental models of another entity, we study a special application of ToM abilities that has higher stakes and possibly irreversible consequences : Human Robot Interaction. In this work, we explore the task of Perceived Behavior Recognition, where a robot employs an LLM to assess the robot's generated behavior in a manner similar to human observer. We focus on four behavior types, namely - explicable, legible, predictable, and obfuscatory behavior which have been extensively used to synthesize interpretable robot behaviors. The LLMs goal is, therefore to be a human proxy to the agent, and to answer how a certain agent behavior would be perceived by the human in the loop, for example "Given a robot's behavior X, would the human observer find it explicable?". We conduct a human subject study to verify that the users are able to correctly answer such a question in the curated situations (robot setting and plan) across five domains. A first analysis of the belief test yields extremely positive results inflating ones expectations of LLMs possessing ToM abilities. We then propose and perform a suite of perturbation tests which breaks this illusion, i.e. Inconsistent Belief, Uninformative Context and Conviction Test. The high score of LLMs on vanilla prompts showcases its potential use in HRI settings, however to possess ToM demands invariance to trivial or irrelevant perturbations in the context which LLMs lack. We report our results on GPT-4 and GPT-3.5-turbo.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {36–45},
numpages = {10},
keywords = {large language models, reasoning, theory of mind},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3680121.3699887,
author = {Shajarian, Shaghayegh and Khorsandroo, Sajad and Abdelsalam, Mahmoud},
title = {Poster: Intelligent Network Management: RAG-Enhanced LLMs for Log Analysis, Troubleshooting, and Documentation},
year = {2024},
isbn = {9798400711084},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680121.3699887},
doi = {10.1145/3680121.3699887},
abstract = {Modern network management is increasingly complex, requiring administrators to handle vast amounts of log data from diverse sources, leading to inefficiencies, errors, and operational challenges. In this work, we propose a novel AI-driven framework that integrates Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) and human-in-the-loop process to automate network management tasks such as log analysis, troubleshooting recommendations, and documentation generation. This study aims to enhance network reliability, reduce operational complexity, and move forward to autonomous network management.},
booktitle = {Proceedings of the 20th International Conference on Emerging Networking EXperiments and Technologies},
pages = {27–28},
numpages = {2},
keywords = {large language models (llms), network management, retrieval-augmented generation (rag).},
location = {Los Angeles, CA, USA},
series = {CoNEXT '24}
}

@inproceedings{10.1145/3641554.3701974,
author = {P?durean, Victor-Alexandru and Denny, Paul and Singla, Adish},
title = {BugSpotter: Automated Generation of Code Debugging Exercises},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701974},
doi = {10.1145/3641554.3701974},
abstract = {Debugging is an essential skill when learning to program, yet its instruction and emphasis often vary widely across introductory courses. In the era of code-generating large language models (LLMs), the ability for students to reason about code and identify errors is increasingly important. However, students frequently resort to trial-and-error methods to resolve bugs without fully understanding the underlying issues. Developing the ability to identify and hypothesize the cause of bugs is crucial but can be time-consuming to teach effectively through traditional means. This paper introduces BugSpotter, an innovative tool that leverages an LLM to generate buggy code from a problem description and verify the synthesized bugs via a test suite. Students interact with BugSpotter by designing failing test cases, where the buggy code's output differs from the expected result as defined by the problem specification. This not only provides opportunities for students to enhance their debugging skills, but also to practice reading and understanding problem specifications. We deployed BugSpotter in a large classroom setting and compared the debugging exercises it generated to exercises hand-crafted by an instructor for the same problems. We found that the LLM-generated exercises produced by BugSpotter varied in difficulty and were well-matched to the problem specifications. Importantly, the LLM-generated exercises were comparable to those manually created by instructors with respect to student performance, suggesting that BugSpotter could be an effective and efficient aid for learning debugging.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {896–902},
numpages = {7},
keywords = {bugspotter, debugging, exercise generation, generative ai, llms, programming education, test cases},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3709026.3709029,
author = {Zhi, Longrun},
title = {GuidedEmpathy: Guiding Large Language Models for Empathetic Response Generation with Situational Awareness},
year = {2025},
isbn = {9798400718182},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709026.3709029},
doi = {10.1145/3709026.3709029},
abstract = {Empathetic response generation has emerged as a prominent research focus within the field of artificial intelligence (AI) systems. Over recent years, numerous methods have been developed to address this challenge. With the advent of large language models (LLMs), they have become a feasible tool for this task as well. In this study, we introduce an empathy model called GuidedEmpathy constructed by DSPy, which encompasses a situation classifier and a guided generation module. Our model first categorizes the speaker’s situation into a specific class and then provides tailored guidance for the LLM to generate an appropriate response. We have also conducted experiments to assess the impact of the emotion and situation modules on the overall performance. The results from both automatic and human evaluations confirm the superior effectiveness of our approach when compared to traditional methods. Additionally, our comparative analysis with LLM-based methods demonstrates that the responses generated by our model exhibit a higher degree of empathy.},
booktitle = {Proceedings of the 2024 8th International Conference on Computer Science and Artificial Intelligence},
pages = {354–360},
numpages = {7},
keywords = {Empathy, Large Language Model, Natural language generation, DSPy},
location = {
},
series = {CSAI '24}
}

@inproceedings{10.1145/3589335.3641256,
author = {Zhang, Yizhou and Sharma, Karishma and Du, Lun and Liu, Yan},
title = {Toward Mitigating Misinformation and Social Media Manipulation in LLM Era},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641256},
doi = {10.1145/3589335.3641256},
abstract = {The pervasive abuse of misinformation to influence public opinion on social media has become increasingly evident in various domains, encompassing politics, as seen in presidential elections, and healthcare, most notably during the recent COVID-19 pandemic. This threat has grown in severity as the development of Large Language Models (LLMs) empowers manipulators to generate highly convincing deceptive content with greater efficiency. Furthermore, the recent strides in chatbots integrated with LLMs, such as ChatGPT, have enabled the creation of human-like interactive social bots, posing a significant challenge to both human users and the social-bot-detection systems of social media platforms.These challenges motivate researchers to develop algorithms to mitigate misinformation and social media manipulations. This tutorial introduces the advanced machine learning researches that are helpful for this goal, including (1) detection of social manipulators, (2) learning causal models of misinformation and social manipulation, and (3) LLM-generated misinformation detection. In addition, we also present possible future directions.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1302–1305},
numpages = {4},
keywords = {causal effect estimation, coordinated campaigns, disinformation, fake news, large language models, multi-modal fake news detection, social bots, social media},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3664476.3664497,
author = {Zhang, Xinyu and Muralee, Siddharth and Cherupattamoolayil, Sourag and Machiry, Aravind},
title = {On the Effectiveness of Large Language Models for GitHub Workflows},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3664497},
doi = {10.1145/3664476.3664497},
abstract = {GitHub workflows or GitHub CI is a popular continuous integration platform that enables developers to automate various software engineering tasks by specifying them as workflows,&nbsp;i.e., &nbsp;YAML files with a list of jobs. However, engineering valid workflows is tedious. They are also prone to severe security issues, which can result in supply chain vulnerabilities. Recent advancements in&nbsp;Large Language Models (LLMs) have demonstrated their effectiveness in various software development tasks. However,&nbsp;GitHub workflows differ from regular programs in both structure and semantics. We perform the first comprehensive study to understand the effectiveness of&nbsp;Large Language Models (LLMs) on five workflow-related tasks with different levels of prompts. We curated a set of ∼ 400K workflows and generated prompts with varying detail. We also fine-tuned&nbsp;LLMs on&nbsp;GitHub workflow tasks. Our evaluation of three state-of-the-art&nbsp;LLMs and their fine-tuned variants revealed various interesting findings on the current effectiveness and drawbacks of&nbsp;LLMs.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {32},
numpages = {14},
keywords = {GitHub Workflow, Large Language Model, Vulnerability Detection},
location = {Vienna, Austria},
series = {ARES '24}
}

@inproceedings{10.1145/3627673.3679881,
author = {Ding, Yuyang and Hu, Hanglei and Zhou, Jie and Chen, Qin and Jiang, Bo and He, Liang},
title = {Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679881},
doi = {10.1145/3627673.3679881},
abstract = {With the introduction of large language models (LLMs), automatic math reasoning has seen tremendous success. However, current methods primarily focus on providing solutions or using techniques like Chain-of-Thought to enhance problem-solving accuracy. In this paper, we focus on improving the capability of mathematics teaching via a Socratic teaching-based LLM (SocraticLLM), which guides learners toward profound thinking with clarity and self-discovery via conversation. We collect and release a high-quality mathematical teaching dataset, named SocraticMATH, which provides Socratic-style conversations of problems with extra knowledge. Also, we propose a knowledge-enhanced LLM as a strong baseline to generate reliable responses with review, guidance/heuristic, rectification, and summarization. Experimental results show the great advantages of SocraticLLM by comparing it with several strong generative models. The codes and datasets are available on https://github.com/ECNU-ICALK/SocraticMath.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3730–3735},
numpages = {6},
keywords = {LLMs, conversation, mathematics, socratic teaching},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3717867.3717913,
author = {Wu, Patrick Y.},
title = {Using Semantically Unrelated and Opposite Terms for In-Context Learning: A Case Study in Identifying Political Aversion in Tweets},
year = {2025},
isbn = {9798400714832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3717867.3717913},
doi = {10.1145/3717867.3717913},
abstract = {We investigate how semantic priors embedded in generative large language models (LLMs) interact with concept definitions in prompts, using political aversion detection as a case study. Through systematic variations in the wording of the definition of political aversion—replacing key words with opposite terms, semantically unrelated terms, or deliberately nonsensical strings—we examine how models process and apply these manipulated definitions in classification tasks. Our results show that certain LLMs maintain consistent performance across different prompt configurations, regardless of which terms are used or whether examples are included. Strong classification performances even with nonsensical definitions suggest these models may sometimes rely more on patterns in target content than definitions given in prompts. These findings challenge conventional assumptions about prompt engineering and raise important questions about how LLMs utilize information in prompts for classification decisions, while underscoring the need for careful validation when applying these methods to social and political science measurement tasks.},
booktitle = {Proceedings of the 17th ACM Web Science Conference 2025},
pages = {528–533},
numpages = {6},
keywords = {large language models, in-context learning, social media analysis},
location = {
},
series = {Websci '25}
}

@inproceedings{10.1145/3658644.3690306,
author = {Wen, Rui and Li, Zheng and Backes, Michael and Zhang, Yang},
title = {Membership Inference Attacks Against In-Context Learning},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690306},
doi = {10.1145/3658644.3690306},
abstract = {Adapting Large Language Models (LLMs) to specific tasks introduces concerns about computational efficiency, prompting an exploration of efficient methods such as In-Context Learning (ICL). However, the vulnerability of ICL to privacy attacks under realistic assumptions remains largely unexplored. In this work, we present the first membership inference attack tailored for ICL, relying solely on generated texts without their associated probabilities. We propose four attack strategies tailored to various constrained scenarios and conduct extensive experiments on four popular large language models. Empirical results show that our attacks can accurately determine membership status in most cases, e.g., 95% accuracy advantage against LLaMA, indicating that the associated risks are much higher than those shown by existing probability-based attacks. Additionally, we propose a hybrid attack that synthesizes the strengths of the aforementioned strategies, achieving an accuracy advantage of over 95% in most cases. Furthermore, we investigate three potential defenses targeting data, instruction, and output. Results demonstrate combining defenses from orthogonal dimensions significantly reduces privacy leakage and offers enhanced privacy assurances.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {3481–3495},
numpages = {15},
keywords = {in-context learning, large language models, membership inference attacks},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3696410.3714758,
author = {Wang, Shuyao and Zheng, Zhi and Sui, Yongduo and Xiong, Hui},
title = {Unleashing the Power of Large Language Model for Denoising Recommendation},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714758},
doi = {10.1145/3696410.3714758},
abstract = {Recommender systems are crucial for personalizing user experiences but often depend on implicit feedback data, which can be noisy and misleading. Existing denoising studies involve incorporating auxiliary information or learning strategies from interaction data. However, they struggle with the inherent limitations of external knowledge and interaction data, as well as the non-universality of certain predefined assumptions, hindering accurate noise identification. Recently, large language models (LLMs) have gained attention for their extensive world knowledge and reasoning abilities, yet their potential in enhancing denoising in recommendations remains underexplored. In this paper, we introduce LLaRD, a framework leveraging LLMs to improve denoising in recommender systems, thereby boosting overall recommendation performance. Specifically, LLaRD generates denoising-related knowledge by first enriching semantic insights from observational data via LLMs and inferring user-item preference knowledge. It then employs a novel Chain-of-Thought (CoT) technique over user-item interaction graphs to reveal relation knowledge for denoising. Finally, it applies the Information Bottleneck (IB) principle to align LLM-generated denoising knowledge with recommendation targets, filtering out noise and irrelevant LLM knowledge. Empirical results demonstrate LLaRD's effectiveness in enhancing denoising and recommendation accuracy.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {252–263},
numpages = {12},
keywords = {denoising, large language models, recommendation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.5555/3665464.3665469,
author = {Manley, Eric D. and Urness, Timothy and Migunov, Andrei and Reza, Md. Alimoor},
title = {Examining Student Use of AI in CS1 and CS2},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {The launch of ChatGPT in November 2022 marked a seismic disruption to many disciplines and industries, including higher education. For the first time, students everywhere have widely available access to a Large Language Model (LLM) capable of generating content - including solutions to programming assignments in CS1 and CS2 - that can pass as the work of a high-achieving student while making traditional plagiarism-detection obsolete. This has spurred various responses in higher education, including a shift to more in-class and unplugged assessments. At the same time, LLMs are transforming the way that many people work, including professional software developers, and students similarly might be able to use them to enhance their learning. In this paper, we report on our experiences with a permissive policy towards the use of ChatGPT and other artificial intelligence (AI) tools for assisting students with their programming assignments in CS1 and CS2 courses in the Spring 2023 semester. Students were allowed to use these tools however they wished as long as they submitted a form which included a transcript of their chat and a reflection on what they learned, if anything, through the interaction. We found that students largely approached the AI in positive ways and that they seemed to genuinely learn from the experience. We also document some things that did not go well and that remain challenges to using AI in programming courses, along with our recommendations on how these might be dealt with in the future.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {41–51},
numpages = {11}
}

@inproceedings{10.1145/3702163.3702182,
author = {Yaqub, Irfan and Chen, Zhiyuan and Liao, Iman Yi and Maul, Tomas and Seow, Hsin-Vonn and Chandesa, Tissa},
title = {A Novel Framework using Large Language Models to Automate Coursework Feedback for Computer Science modules},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702182},
doi = {10.1145/3702163.3702182},
abstract = {Prompt and sufficient feedback is essential for students' academic learning since it enables them to review their learning techniques and improve their areas of weakness. Nevertheless, delivering personalised feedback to every student continues to be difficult&nbsp;for teachers due to its demanding and time-intensive nature. While automated feedback systems are available, their primary focus is providing feedback on a single subject, and most of them utilise statistical analysis or traditional machine learning techniques to provide feedback. Moreover, no feedback model utilises the same criteria to generate text-based feedback for more than one subject. Generative artificial intelligence (GEN AI) has recently made incredible progress, and large language models (LLMs) can retain the context from the vast amount of text. Hence, this research presents a framework that employs an innovative technique to offer text-based feedback to students in different fields of study. This framework employs two LLMs, one for generating the feedback and another for categorising it into separate subjects using suitable headings for structural organising. Consequently, the output produced by this technology corresponds to the original tone of the teacher.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {130–137},
numpages = {8},
keywords = {Deep Learning Artificial Intelligence, Generative Artificial Intelligence, Large Language Model},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3662739.3665684,
author = {Wang, Xinren and Wan, Tengfei and Song, Jianning and Huang, Jingmeng},
title = {Knowledge Enhancement and Optimization Strategies for Remote Sensing Image Captioning Using Contrastive Language Image Pre-training and Large Language Models},
year = {2024},
isbn = {9798400718144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662739.3665684},
doi = {10.1145/3662739.3665684},
abstract = {In this study, we propose an innovative multimodal learning approach that integrates Contrastive Language Image Pre-training and large language models to enhance the recognition efficiency of remote sensing images and their capacity to generate related professional information. This method has effectively achieved integration of image processing and text generation at a technical level, exhibiting significant application advantages in fields such as automated Geographic Information Systems construction, environmental monitoring, disaster assessment, and geographic science education. The research underscores the advancements of the Contrastive Language Image Pre-training model in visual-textual understanding and the technical strengths of large language models in handling complex text tasks. By designing an integrated fusion layer, we have efficiently combined visual features with textual information and conducted a comprehensive evaluation of the model's recognition accuracy and text generation quality on the dataset. Experimental results show that our model achieved a recognition accuracy of 73.7% and a text quality score of 26.6, validating its efficacy and powerful capability in dealing with the complexity and diversity of remote sensing images. Through the deep integration of Contrastive Language Image Pre-training and large language models, this research not only further advances multimodal learning technologies but also opens new perspectives and possibilities for the research and application of remote sensing image recognition and related information generation.},
booktitle = {Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications},
pages = {313–318},
numpages = {6},
keywords = {Caption Generation, Knowledge Enhancement, Large Language Models, Multimodal Learning, Remote Sensing Image Recognition},
location = {Ningbo, China},
series = {MIDA '24}
}

@inproceedings{10.1145/3722237.3722245,
author = {Fan, Sun and Peng, Lu and Wu, Shaofeng and Yu, Xingmu},
title = {ChatGPT Empowers Higher Education: —Research Topics Hotspots and Quantitative Visual Analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722245},
doi = {10.1145/3722237.3722245},
abstract = {In order to deeply explore the current research hotspots and development trends of ChatGPT generative artificial intelligence in empowering higher education applications, this study conducted a detailed analysis of 178 articles related to ChatGPT+higher education in the knowledge Resource Database. By using software tools such as Power BI, SPSS, and Excel, this study conducted a visual analysis of core authors, research funding, research topics, author institutions, discipline areas, and related indicators in the literature. The aim of the study is to analyze the current status of ChatGPT research in higher education applications and to explore the hot issues surrounding ChatGPT empowerment in higher education.The study points out that current research in higher education in the era of artificial intelligence mainly focuses on introducing ChatGPT, the characteristics and connotations of large language models, and discussing the opportunities, challenges, coping strategies, and digital transformation research they bring. However, there is still a lack of in-depth exploration of the application of ChatGPT and other technologies in education, especially in areas such as personalized learning and precision teaching, the integration of virtual and actual teaching spaces, intelligent teaching facilities and resources, human-computer collaborative teaching methods, and interdisciplinary innovative research methods.We should actively respond to the opportunities and challenges brought by intelligent tools such as ChatGPT to higher education, and comprehensively and deeply explore how to integrate ChatGPT into key areas of digital education, including teaching design, teaching resource development, teaching organization and implementation, teaching evaluation and reflection, learning and personal knowledge management, innovation team building, and enhancing the digital literacy and professional capabilities of teachers and students. In addition, the impact of the application of ChatGPT and other technologies in education on educational equity, and how to ensure that all students can benefit from it through reasonable design and use, should also be of concern. The goal of this study is to further promote and drive the digital transformation of higher education by building a brand new higher education ecosystem based on ChatGPT.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {38–45},
numpages = {8},
keywords = {ChatGPT, Digital transformation, Empowers, higher education, hot topics, human-machine collaborative intelligence, trends, visualization},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3701716.3715276,
author = {Meguellati, Elyas},
title = {The Duality of Persuasion: Between Personalization and Detection},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715276},
doi = {10.1145/3701716.3715276},
abstract = {This PhD project investigates the duality of artificial intelligence in persuasive communication, exploring both the generation of personalized content and the detection of persuasive strategies. Insights are drawn from four studies. The first demonstrates how large language models (LLMs) can generate personalized online advertisements targeting specific personality traits, such as openness and neuroticism, with effectiveness comparable to human-written ads. The second introduces a lightweight transformer model for persuasive text detection, achieving state-of-the-art performance in Subtask 3 of SemEval 2023 and applying it to Facebook political ads from the 2022 Australian Federal election campaign. The third, ongoing study extends to persuasive memes detection by employing LLMs for preprocessing and data augmentation before model analysis. Finally, a planned study will explore a dynamic personalization: Developing adaptive LLM frameworks to tailor personalized messages over time based on user feedback or interactions. These studies collectively contribute to the understanding and ethical application of AI in persuasive communication, offering insights for academia, industry, and policymakers while addressing societal implications of AI-driven persuasion.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {705–708},
numpages = {4},
keywords = {large language models, personalization, persuasion detection},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3696410.3714658,
author = {Ren, Ruiyang and Wang, Yuhao and Zhou, Kun and Zhao, Wayne Xin and Wang, Wenjie and Liu, Jing and Wen, Ji-Rong and Chua, Tat-Seng},
title = {Self-Calibrated Listwise Reranking with Large Language Models},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714658},
doi = {10.1145/3696410.3714658},
abstract = {Large language models (LLMs), with advanced linguistic capabilities, have been employed in reranking tasks through a sequence-to-sequence approach. In this paradigm, multiple passages are reranked in a listwise manner and a textual reranked permutation is generated. However, due to the limited context window of LLMs, this reranking paradigm requires a sliding window strategy to iteratively handle larger candidate sets. This not only increases computational costs but also restricts the LLM from fully capturing all the comparison information for all candidates. To address these challenges, we propose a novel self-calibrated listwise reranking method, which aims to leverage LLMs to produce global relevance scores for ranking. To achieve it, we first propose the relevance-aware listwise reranking framework, which incorporates explicit list-view relevance scores to improve reranking efficiency and enable global comparison across the entire candidate set. Second, to ensure the comparability of the computed scores, we propose self-calibrated training that uses point-view relevance assessments generated internally by the LLM itself to calibrate the list-view relevance assessments. Extensive experiments and comprehensive analysis on the BEIR benchmark and TREC Deep Learning Tracks demonstrate the effectiveness and efficiency of our proposed method.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {3692–3701},
numpages = {10},
keywords = {large language models, self-calibration, text reranking},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.5555/3709347.3743552,
author = {Bravo-Rocca, Gusseppe and Liu, Peini and Guitart, Jordi and Carrillo-Larco, Rodrigo M and Dholakia, Ajay and Ellison, David},
title = {Feature Engineering for Agents: An Adaptive Cognitive Architecture for Interpretable ML Monitoring},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Monitoring Machine Learning (ML) models in production environments is crucial, yet traditional approaches often yield verbose, low-interpretability outputs that hinder effective decision-making. We propose a cognitive architecture for ML monitoring that applies feature engineering principles to agents based on Large Language Models (LLMs), significantly enhancing the interpretability of monitoring outputs. Central to our approach is a Decision Procedure module that simulates feature engineering through three key steps: Refactor, Break Down, and Compile. The Refactor step improves data representation to better capture feature semantics, allowing the LLM to focus on salient aspects of the monitoring data while reducing noise and irrelevant information. Break Down decomposes complex information for detailed analysis, and Compile integrates sub-insights into clear, interpretable outputs. This process leads to a more deterministic planning approach, reducing dependence on LLM-generated planning, which can sometimes be inconsistent and overly general. The combination of feature engineering-driven planning and selective LLM utilization results in a robust decision support system, capable of providing highly interpretable and actionable insights. Experiments using multiple LLMs demonstrate the efficacy of our approach, achieving significantly higher accuracy compared to various baselines across several domains.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {381–389},
numpages = {9},
keywords = {agent-based cognitive architecture, large language models, machine learning monitoring},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3698204.3716476,
author = {Ben Amor, Mehdi and Strappazzon, Alexis and Granitzer, Michael and Egyed-Zsigmond, El\"{o}d and Mitrovi\'{c}, Jelena},
title = {Instruct-to-SPARQL: A text-to-SPARQL dataset for training SPARQL Agents},
year = {2025},
isbn = {9798400712906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698204.3716476},
doi = {10.1145/3698204.3716476},
abstract = {The rapid adoption of Large Language Models (LLMs) for search engines and fact-checking platforms necessitates enhancing their output accuracy. Retrieval Augmented Generation (RAG) mitigates hallucinations but requires semantically rich repositories like Wikidata. However, there is a lack of high-quality data to fine-tune LLMs for querying such knowledge bases. To address this gap, we propose a curated dataset with 2,771 unique queries for fine-tuning LLMs to generate accurate and syntactically valid SPARQL queries from natural language instructions. This dataset, customized for interaction with Wikidata, also serves as a robust benchmark for text-to-SPARQL task evaluation. Key findings show that models generally perform better on queries with lower complexity.},
booktitle = {Proceedings of the 2025 ACM SIGIR Conference on Human Information Interaction and Retrieval},
pages = {390–395},
numpages = {6},
keywords = {SPARQL, Information Retrieval, Large Language Models, Text-to-Query},
location = {
},
series = {CHIIR '25}
}

@inproceedings{10.1145/3706599.3719962,
author = {Hanafi, Maeda F and Fadnis, Kshitij and Danilevsky, Marina and Rosenthal, Sara and Katsis, Yannis},
title = {Creating Conversational Datasets for Retrieval-Augmented Generation Applications is Hard: Challenges &amp; Research Opportunities},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719962},
doi = {10.1145/3706599.3719962},
abstract = {Retrieval-augmented generation (RAG) has been proven to help mitigate hallucinations from large language models (LLMs). However, as more domains adopt this method, the need for human-created conversational data increases, as human-created conversations are naturally driven better. Yet, in our experience, when we tasked several annotators to create such data for RAG applications, we learned that creating conversational data for RAG is hard, leading to cases where we had to reject 35% of data in some batches. In this paper, we interview a group of annotators to understand what makes this task challenging. We distill insights from the formative study and outline potential future directions in the intersection of RAG applications and HCI.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {157},
numpages = {7},
keywords = {Retrieval-Augmented Generation, Data Creation, Data Annotation},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706598.3714154,
author = {Zamfirescu-Pereira, J.D. and Jun, Eunice and Terry, Michael and Yang, Qian and Hartmann, Bjoern},
title = {Beyond Code Generation: LLM-supported Exploration of the Program Design Space},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714154},
doi = {10.1145/3706598.3714154},
abstract = {In this work, we explore explicit Large Language Model (LLM)-powered support for the iterative design of computer programs. Program design, like other design activity, is characterized by navigating a space of alternative problem formulations and associated solutions in an iterative fashion. LLMs are potentially powerful tools in helping this exploration; however, by default, code-generation LLMs deliver code that represents a particular point solution. This obscures the larger space of possible alternatives, many of which might be preferable to the LLM’s default interpretation and its generated code. We contribute an IDE that supports program design through generating and showing new ways to frame problems alongside alternative solutions, tracking design decisions, and identifying implicit decisions made by either the programmer or the LLM. In a user study, we find that with our IDE, users combine and parallelize design phases to explore a broader design space—but also struggle to keep up with LLM-originated changes to code and other information overload. These findings suggest a core challenge for future IDEs that support program design through higher-level instructions given to LLM-based agents: carefully managing attention and deciding what information agents should surface to program designers and when.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {153},
numpages = {17},
keywords = {Program design, Code generation, Design space exploration, Generative AI, LLMs},
location = {
},
series = {CHI '25}
}

@article{10.1145/3702973,
author = {Chen, Chong and Su, Jianzhong and Chen, Jiachi and Wang, Yanlin and Bi, Tingting and Yu, Jianxing and Wang, Yanli and Lin, Xingwei and Chen, Ting and Zheng, Zibin},
title = {When ChatGPT Meets Smart Contract Vulnerability Detection: How Far Are We?},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3702973},
doi = {10.1145/3702973},
abstract = {With the development of blockchain technology, smart contracts have become an important component of blockchain applications. Despite their crucial role, the development of smart contracts may introduce vulnerabilities and potentially lead to severe consequences, such as financial losses. Meanwhile, large language models, represented by ChatGPT, have gained great attention, showcasing great capabilities in code analysis tasks. In this article, we presented an empirical study to investigate the performance of ChatGPT in identifying smart contract vulnerabilities. Initially, we evaluated ChatGPT’s effectiveness using a publicly available smart contract dataset. Our findings discover that while ChatGPT achieves a high recall rate, its precision in pinpointing smart contract vulnerabilities is limited. Furthermore, ChatGPT’s performance varies when detecting different vulnerability types. We delved into the root causes for the false positives generated by ChatGPT, and categorized them into four groups. Second, by comparing ChatGPT with other state-of-the-art smart contract vulnerability detection tools, we found that ChatGPT’s F-score is lower than others for 3 out of the 7 vulnerabilities. In the case of the remaining 4 vulnerabilities, ChatGPT exhibits a slight advantage over these tools. Finally, we analyzed the limitation of ChatGPT in smart contract vulnerability detection, revealing that the robustness of ChatGPT in this field needs to be improved from two aspects: its uncertainty in answering questions; and the limited length of the detected code. In general, our research provides insights into the strengths and weaknesses of employing large language models, specifically ChatGPT, for the detection of smart contract vulnerabilities.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {100},
numpages = {30},
keywords = {Empirical Study, Smart Contracts, Large Language Models, ChatGPT, Vulnerabilities}
}

@inproceedings{10.1145/3631700.3665233,
author = {Biancini, Giorgio and Ferrato, Alessio and Limongelli, Carla},
title = {Multiple-Choice Question Generation Using Large Language Models: Methodology and Educator Insights},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665233},
doi = {10.1145/3631700.3665233},
abstract = {Integrating Artificial Intelligence (AI) in educational settings has brought new learning approaches, transforming the practices of both students and educators. Among the various technologies driving this transformation, Large Language Models (LLMs) have emerged as powerful tools for creating educational materials and question answering, but there are still space for new applications. Educators commonly use Multiple-Choice Questions (MCQs) to assess student knowledge, but manually generating these questions is resource-intensive and requires significant time and cognitive effort. In our opinion, LLMs offer a promising solution to these challenges. This paper presents a novel comparative analysis of three widely known LLMs - Llama 2, Mistral, and GPT-3.5 - to explore their potential for creating informative and challenging MCQs. In our approach, we do not rely on the knowledge of the LLM, but we inject the knowledge into the prompt to contrast the hallucinations, giving the educators control over the test’s source text, too. Our experiment involving 21 educators shows that GPT-3.5 generates the most effective MCQs across several known metrics. Additionally, it shows that there is still some reluctance to adopt AI in the educational field. This study sheds light on the potential of LLMs to generate MCQs and improve the educational experience, providing valuable insights for the future.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {584–590},
numpages = {7},
keywords = {Generative AI, LLMs, Multiple Choice Question},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3639856.3639888,
author = {Kasundra, Jaykumar and Dhankhar, Shreyans},
title = {Adapting Open-Source LLMs for Contract Drafting and Analyzing Multi-Role vs. Single-Role Behavior of ChatGPT for Synthetic Data Generation},
year = {2024},
isbn = {9798400716492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639856.3639888},
doi = {10.1145/3639856.3639888},
abstract = {Large-scale language models, such as ChatGPT[3] and GPT-4[32], have demonstrated remarkable capabilities in generating human-like text for various applications. In this paper, we focus on two key aspects: (1) adapting open-source large language models (LLMs) for specific use cases like contract drafting using instruction tuning and parameter-efficient fine-tuning, and (2) analyzing the difference in ChatGPT’s behavior in single-role prompts compared to multi-role prompts for synthetic data generation tasks. We present a method for aligning open-source LLMs to follow instructions for customized contract drafting scenarios using parameter-efficient fine-tuning on synthetic data. Furthermore, we investigate the data quality of the synthetically generated instructions data by ChatGPT with single-role vs. multi-role prompts. Our findings reveal that the model performs better when given single-role prompts, highlighting the importance of strategically designing prompting strategy to generate better quality data using LLMs. By combining the insights from these two aspects, we explore potential implications and opportunities for enhancing generative AI solutions for practical implementations. The Contract Drafting model 1 and data 2 are released.},
booktitle = {Proceedings of the Third International Conference on AI-ML Systems},
articleno = {32},
numpages = {8},
keywords = {Automated Evaluation, Generative AI, Large Language Models, Natural Language Generation},
location = {Bangalore, India},
series = {AIMLSystems '23}
}

@article{10.1145/3711012,
author = {Liu, Yiren and Li, Yerong and Mayfield, Ryan and Huang, Yun},
title = {Improving Emotional Support Delivery in Text-Based Community Safety Reporting Using Large Language Models},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711012},
doi = {10.1145/3711012},
abstract = {Emotional support is a crucial aspect of communication between community members and police dispatchers during incident reporting. However, there is a lack of understanding about how emotional support is delivered through text-based systems, especially in various non-emergency contexts. In this study, we analyzed two years of chat logs comprising 57,114 messages across 8,239 incidents from 130 higher education institutions. Our empirical findings revealed significant variations in emotional support provided by dispatchers, influenced by the type of incident, service time, and a noticeable decline in support over time across multiple organizations. To improve the consistency and quality of emotional support, we developed and implemented a fine-tuned Large Language Model (LLM), named dispatcherLLM, designed to suggest replies through simulating human dispatchers' languages with appropriate emotional support. We evaluated dispatcherLLM by comparing its generated responses to those of human dispatchers and other off-the-shelf models using real chat messages. Additionally, we conducted a human evaluation to assess the perceived effectiveness of the support provided by dispatcherLLM. This study not only contributes new empirical understandings of emotional support in text-based dispatch systems but also demonstrates the significant potential of generative AI in improving service delivery.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW114},
numpages = {31},
keywords = {emotion classification, event argument extraction, large language models, live chat, safety reporting, text-based reporting system}
}

@inproceedings{10.1145/3643991.3645071,
author = {Siddiq, Mohammed Latif and Roney, Lindsay and Zhang, Jiahao and Santos, Joanna Cecilia Da Silva},
title = {Quality Assessment of ChatGPT Generated Code and their Use by Developers},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645071},
doi = {10.1145/3643991.3645071},
abstract = {The release of large language models (LLMs) like ChatGPT has revolutionized software development. Prior works explored ChatGPT's generated response quality, the effectiveness of different prompting techniques, its performance in programming contests, etc. However, there is limited information regarding the practical usage of ChatGPT by software developers. This data mining challenge focuses on DevGPT, a curated dataset of developer-ChatGPT conversations encompassing prompts with ChatGPT's responses, including code snippets. Our paper leverages this dataset to investigate (RQ1) whether ChatGPT generates Python &amp; Java code with quality issues; (RQ2) whether ChatGPT-generated code is merged into a repository, and, if it does, to what extent developers change them; and (RQ3) what are the main use cases for ChatGPT besides code generation. We found that ChatGPT-generated code suffers from using undefined/unused variables and improper documentation. They also have security issues related to improper resources and exception management. Our results show that ChatGPT-generated codes are hardly merged, and they are significantly modified before merging. Based on an analysis of developers' discussions and the developer-ChatGPT chats, we found that developers use ChatGPT for every stage of software development and leverage it to learn about new frameworks and development kits.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {152–156},
numpages = {5},
keywords = {datasets, ChatGPT, security, quality, pull-request, open-coding},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3605390.3610821,
author = {Di Caro, Luigi and Rapp, Amon and Torrielli, Federico},
title = {GENERAL: GENerative, Explainable and Reasonable Artificial Learning},
year = {2023},
isbn = {9798400708060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605390.3610821},
doi = {10.1145/3605390.3610821},
abstract = {The GENERAL (GENerative, Explainable and Reasonable Artificial Learning) workshop, held at CHITALY 2023, delves into the advancements in General and Generative Artificial Intelligence (GGAI), with a focus on breakthroughs in natural language processing (NLP) and computer vision (CV). The workshop highlights the capabilities of Large Language Models (LLMs) and Latent Diffusion Models (LDMs) in generating human-like content across text and images. It emphasizes the importance of AI explainability, aiming to understand, explain, and control the complexities of these AI systems in terms of fairness, accountability, and transparency. The workshop encourages interdisciplinary collaboration across fields like HCI, psychology, social studies, and the arts to better understand AI’s societal and cultural impacts. Topics of interest include user perceptions of generative AIs, machine psychology, AI assistants, ethical issues in Generative AI, and safety and control mechanisms for large language models.},
booktitle = {Proceedings of the 15th Biannual Conference of the Italian SIGCHI Chapter},
articleno = {35},
numpages = {2},
keywords = {Large Language Models, Interdisciplinary Collaboration, Generative Artificial Intelligence, Ethical Issues in AI, AI Explainability},
location = {Torino, Italy},
series = {CHItaly '23}
}

@inproceedings{10.1145/3696410.3714816,
author = {Liu, Zhiqiang and Gan, Chengtao and Wang, Junjie and Zhang, Yichi and Bo, Zhongpu and Sun, Mengshu and Chen, Huajun and Zhang, Wen},
title = {OntoTune: Ontology-Driven Self-training for Aligning Large Language Models},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714816},
doi = {10.1145/3696410.3714816},
abstract = {Existing domain-specific Large Language Models (LLMs) are typically developed by fine-tuning general-purposed LLMs with large-scale domain-specific corpora. However, training on large-scale corpora often fails to effectively organize domain knowledge of LLMs, leading to fragmented understanding. Inspired by how humans connect concepts and organize knowledge through mind maps, we aim to emulate this approach by using ontology with hierarchical conceptual knowledge to reorganize LLM's domain knowledge. From this perspective, we propose an ontology-driven self-training framework called OntoTune, which aims to align LLMs with ontology through in-context learning, enabling the generation of responses guided by the ontology. We leverage in-context learning to identify whether the LLM has acquired the specific concept's ontology knowledge, and select the entries not yet mastered by LLM as the training set to further align the LLM with ontology. Compared to existing domain LLMs based on newly collected large-scale domain-specific corpora, our OntoTune, which relies on the existing, long-term developed ontology and LLM itself, significantly reduces data maintenance costs and offers improved generalization ability. We conduct our study in the medical domain to evaluate the effectiveness of OntoTune, utilizing a standardized medical ontology, SNOMED CT as our ontology source. Experimental results demonstrate that OntoTune achieves state-of-the-art performance in both in-ontology task hypernym discovery and out-of-ontology task medical domain QA. Moreover, compared to the latest direct ontology injection method TaxoLLaMA, our OntoTune better preserves original knowledge of LLM. The code and data are available at https://github.com/zjukg/OntoTune.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {119–133},
numpages = {15},
keywords = {align with ontology, large language model, self-training},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3603287.3651194,
author = {Jamdade, Mahesh and Liu, Yi},
title = {A Pilot Study on Secure Code Generation with ChatGPT for Web Applications},
year = {2024},
isbn = {9798400702372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603287.3651194},
doi = {10.1145/3603287.3651194},
abstract = {Conversational Large Language Models (LLMs), such as ChatGPT, have demonstrated their potent capabilities in natural language processing tasks. This paper presents a pilot study that uses ChatGPT for generating web application code with a specific emphasis on mitigating four prevalent web application vulnerability types: SQL Injection, Cross Site Scripting, Carriage Return Line Feed Injection, and Exposure of Sensitive Information. The paper uses a case study to illustrate how the vulnerabilities in the code are mitigated with the prompts and the subsequent refinements. The study's findings summarize the security concerns in the code generated by ChatGPT, and the paper proposes a prompt pattern designed to help mitigating the potential vulnerabilities.},
booktitle = {Proceedings of the 2024 ACM Southeast Conference},
pages = {229–234},
numpages = {6},
keywords = {ChatGPT, Secure coding, generative AI, web application vulnerabilities},
location = {Marietta, GA, USA},
series = {ACMSE '24}
}

@article{10.1145/3736580,
author = {Wu, Tong and Zhu, Jinhua and Zhou, Wengang and Li, Houqiang},
title = {RESIST: Rationale-Enhanced and Reward Model-Based End-to-End Social Influence Dialogue System},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3736580},
doi = {10.1145/3736580},
abstract = {Developing proactive social influence dialogue systems presents a significant challenge, particularly in non-cooperative scenarios where the system's goals may conflict with those of the user. Traditional methods often focus on training models to plan dialogue strategies, but since human strategies are often sub-optimal, relying solely on manually collected data can be problematic. While large language models (LLMs) facilitate the generation of high-quality synthetic dialogues, their effectiveness in strategic dialogue under zero-shot or few-shot conditions is inconsistent. To address these issues, we propose a training framework applicable to multiple social influence dialogue tasks, named Rationale-Enhanced and Reward Model-Based End-to-End Social Influence Dialogue System (RESIST). To streamline the dialogue system development, we first use existing datasets to prompt a teacher LLM for generating “chain-of-thought” rationales, which are then used to enrich the data and enable supervised fine-tuning (SFT) of the model. Next, we train a reward model by ranking the fine-tuned model's outputs, thereby deriving task-specific preferences without manually constructing scalar rewards. Finally, we apply reinforcement learning to further refine the system, optimizing dialogue strategies and responses according to specific tasks and conversational contexts. Experimental results on three social influence tasks demonstrate the effectiveness and adaptability of our training approach. In terms of task goal completion, RESIST outperforms baseline models and even exceeds the performance of ChatGPT-driven prompt-based policy planning methods in both efficiency and effectiveness. Additionally, we introduce strategic proactivity as a novel evaluation metric, enabling us to analyze how RESIST training influences the proactive traits of dialogue agents, with a particular focus on the personality tendencies of smaller-scale language models during task execution. Experimental findings indicate that RESIST enhances the strategic proactivity of language models, aligning them more closely with task requirements. The source code will be made publicly available upon publication.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = may,
keywords = {Proactive dialogue system, Social influence, Large language model, Reinforcement learning}
}

@inproceedings{10.1145/3662006.3662067,
author = {Hao, Zixu and Jiang, Huiqiang and Jiang, Shiqi and Ren, Ju and Cao, Ting},
title = {Hybrid SLM and LLM for Edge-Cloud Collaborative Inference},
year = {2024},
isbn = {9798400706639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662006.3662067},
doi = {10.1145/3662006.3662067},
abstract = {Edge-Cloud collaboration for deep learning inference has been actively studied, to enhance the inference performance by leveraging both Edge and Cloud resources. However, traditional Edge-Cloud collaboration based on model partitioning or confidence score are not suitable in the LLM (large language models) era, because of its autoregressive generation and the generality across diverse tasks. This paper proposes a dynamic token-level Edge-Cloud collaboration for LLMs. A SLM (small language model) such as TinyLlama resides on the Edge devices, through token-level interaction with the Cloud-side LLMs during inference, approaching LLM quality with a controllable cost similar to SLM. Evaluation results show that our method can only use 25.8% LLM cost to achieve LLM-comparable quality on GSM8K task.},
booktitle = {Proceedings of the Workshop on Edge and Mobile Foundation Models},
pages = {36–41},
numpages = {6},
location = {Minato-ku, Tokyo, Japan},
series = {EdgeFM '24}
}

@inproceedings{10.1145/3673791.3698433,
author = {Imasaka, Yuta and Joho, Hideo},
title = {Effect of LLM's Personality Traits on Query Generation},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673791.3698433},
doi = {10.1145/3673791.3698433},
abstract = {Large language models (LLMs) have demonstrated strong performance across various natural language processing tasks and are increasingly integrated into daily life. Just as personality traits are crucial in human communication, they could also play a significant role in the behavior of LLMs, for instance, in the context of Retrieval Augmented Generation. Previous studies have shown that Big Five personality traits could be applied to LLMs, but their specific effects on information retrieval tasks have not been sufficiently explored. This study aims to examine how personality traits assigned to LLM agents affect their query formulation behavior and search performance. We propose a method to accurately assign personality traits to LLM agents based on the Big Five theory and verify its accuracy using the IPIP-NEO-120 scale. We then design a query generation experiment using the NTCIR Ad-Hoc test collections and evaluate the search performance of queries generated by different LLM agents. The results show that our method successfully assigns all five personality traits to LLM agents as intended. Additionally, the query generation experiment suggests that the assigned traits did influence the length and vocabulary choices of generated queries. Finally, the retrieval effectiveness of the traits varied across test collections, showing a relative improvement ranging from -7.7% to +4.6%, but these differences were not statistically significant.},
booktitle = {Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {249–258},
numpages = {10},
keywords = {large language model, personality traits, query generation},
location = {Tokyo, Japan},
series = {SIGIR-AP 2024}
}

@article{10.1145/3688399,
author = {Xing, Frank},
title = {Designing Heterogeneous LLM Agents for Financial Sentiment Analysis},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3688399},
doi = {10.1145/3688399},
abstract = {Large language models (LLMs) have drastically changed the possible ways to design intelligent systems, shifting the focus from massive data acquisition and new model training to human alignment and strategic elicitation of the full potential of existing pre-trained models. This paradigm shift, however, is not fully realized in financial sentiment analysis (FSA) due to the discriminative nature of this task and a lack of prescriptive knowledge of how to leverage existing generative models in such a context. This study investigates the effectiveness of the new paradigm, that is, using LLMs without fine-tuning for FSA. Rooted in Minsky’s theory of mind and emotions, a design framework with heterogeneous LLM agents is proposed and applied to FSA. The framework instantiates specialized agents using prior guiding knowledge from both linguistics and finance. Then, a summative agent reasons on the aggregated agent discussions. Comprehensive evaluations using six FSA datasets show that the framework yields better accuracies compared to many alternative multi-LLM agent settings, especially when the discussion contents are substantial. This study contributes to the design foundations and paves new avenues for LLMs-based FSA and potentially other tasks. Implications for business and management have also been discussed.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {5},
numpages = {24},
keywords = {Large language model, financial sentiment analysis, agent discussion, theory of emotion, design science research}
}

@inproceedings{10.5555/3712729.3712784,
author = {Mart\'{\i}nez, Joseph and Llinas, Brian and Botello, Jhon G. and Padilla, Jose J. and Frydenlund, Erika},
title = {Enhancing GPT-3.5's Proficiency in Netlogo through Few-Shot Prompting and Retrieval-Augmented Generation},
year = {2025},
isbn = {9798331534202},
publisher = {IEEE Press},
abstract = {Recognizing the limited research on Large Language Models (LLMs) capabilities with low-resource languages, this study evaluates and increases the proficiency of the LLM GPT-3.5 in generating interface and procedural code elements for NetLogo, a multi-agent programming language and modeling environment. To achieve this, we employed "few-shot" prompting and Retrieval-Augmented Generation (RAG) methodologies using two manually created datasets, NetLogoEvalCode and NetLogoEvalInterface. The results demonstrate that GPT-3.5 can generate NetLogo elements and code procedures more effectively when provided with additional examples to learn from, highlighting the potential of LLMs in aiding the development of agent-based models (ABMs). On the other hand, the RAG model obtained a poor performance. We listed possible reasons for this result, which were aligned with RAG's common challenges identified by the state-of-the-art. We propose future research directions for leveraging LLMs for simulation development and instructional purposes in the context of ABMs.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {666–677},
numpages = {12},
location = {Orlando, Florida, USA},
series = {WSC '24}
}

@inproceedings{10.1145/3680256.3721320,
author = {Battaglini-Fischer, S\'{a}ndor and Srinivasan, Nishanthi and Szarvas, B\'{a}lint L\'{a}szl\'{o} and Chu, Xiaoyu and Iosup, Alexandru},
title = {FAILS: A Framework for Automated Collection and Analysis of LLM Service Incidents},
year = {2025},
isbn = {9798400711305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680256.3721320},
doi = {10.1145/3680256.3721320},
abstract = {Large Language Model (LLM) services such as ChatGPT, DALL·E, and Cursor have quickly become essential for society, businesses, and individuals, empowering applications such as chatbots, image generation, and code assistance. The complexity of LLM systems makes them prone to failures and affects their reliability and availability, yet their failure patterns are not fully understood, making it an emerging problem. However, there are limited datasets and studies in this area, particularly lacking an open-access tool for analyzing LLM service failures based on incident reports. Addressing these problems, in this work we propose FAILS, the first open-sourced framework for incident reports collection and analysis on different LLM services and providers. FAILS provides comprehensive data collection, analysis, and visualization capabilities, including: (1) It can automatically collect, clean, and update incident data through its data scraper and processing components;(2) It provides 17 types of failure analysis, allowing users to explore temporal trends of incidents, analyze service reliability metrics, such as Mean Time to Recovery (MTTR) and Mean Time Between Failures (MTBF);(3) It leverages advanced LLM tools to assist in data analysis and interpretation, enabling users to gain observations and insights efficiently. All functions are integrated in the backend, allowing users to easily access them through a web-based frontend interface. FAILS supports researchers, engineers, and general users to understand failure patterns and further mitigate operational incidents and outages in LLM services. The framework is publicly available on https://github.com/atlarge-research/FAILS.},
booktitle = {Companion of the 16th ACM/SPEC International Conference on Performance Engineering},
pages = {187–194},
numpages = {8},
keywords = {failure characterization, failure recovery, incident report, llm, operational data analytics, reliability, system design},
location = {Toronto ON, Canada},
series = {ICPE '25}
}

@inproceedings{10.1145/3671127.3698698,
author = {Deng, Yang and Xie, Donghua and Liang, Rui and Zeng, Jingyun and Tai, Samson and Wang, Dan},
title = {BuildProg: Program Generation for Testing ML-based Building Load Forecasting models via LLM and Prompt Engineering},
year = {2024},
isbn = {9798400707063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671127.3698698},
doi = {10.1145/3671127.3698698},
abstract = {Machine learning-based building load forecasting (BLF) is crucial for the building automation community, and numerous ML models have been developed for this purpose. However, a significant challenge arises when promoting these models for deployment in real buildings: building practitioners often struggle with ML-related programming. To address this issue, we propose BuildProg, a program generation tool that leverages prompt engineering to decompose user requirements and guide large language models (LLMs) in generating the necessary Python code. In its current version, BuildProg supports four tasks related to the testing of BLF models.},
booktitle = {Proceedings of the 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {248–249},
numpages = {2},
keywords = {LLM, Model testing, program generation, prompting},
location = {Hangzhou, China},
series = {BuildSys '24}
}

@inproceedings{10.1145/3708557.3716337,
author = {Xing, Yunhao and Liu, Que and Wang, Jingwu and G\'{o}mez-Zar\'{a}, Diego},
title = {sMoRe: Spatial Mapping and Object Rendering Environment},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716337},
doi = {10.1145/3708557.3716337},
abstract = {In mixed reality (MR) environments, understanding space and creating virtual objects is crucial to providing an intuitive user experience. This paper introduces sMoRe (Spatial Mapping and Object Rendering Environment), an MR application that combines Generative AI (GenAI) to assist users in creating, placing, and managing virtual objects within physical spaces. sMoRe allows users to use voice or typed text commands to create and place virtual objects using GenAI while specifying spatial constraints. The system employs Large Language Models (LLMs) to interpret users’ commands, analyze the current scene, and identify optimal locations. Additionally, sMoRe integrates a text-to-3D generative model to dynamically create 3D objects based on users’ descriptions. Our user study demonstrates the effectiveness of sMoRe in enhancing user comprehension, interaction, and organization of the MR environment.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {115–119},
numpages = {5},
keywords = {Large Language Models, Generative AI, Space Manipulation},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3706598.3713714,
author = {Prabhudesai, Snehal and Kasi, Ananya Prashant and Mansingh, Anmol and Das Antar, Anindya and Shen, Hua and Banovic, Nikola},
title = {"Here the GPT made a choice, and every choice can be biased": How Students Critically Engage with LLMs through End-User Auditing Activity},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713714},
doi = {10.1145/3706598.3713714},
abstract = {Despite recognizing that Large Language Models (LLMs) can generate inaccurate or unacceptable responses, universities are increasingly making such models available to their students. Existing university policies defer the responsibility of checking for correctness and appropriateness of LLM responses to students and assume that they will have the required knowledge and skills to do so on their own. In this work, we conducted a series of user studies with students (N=47) from a large North American public research university to understand if and how they critically engage with LLMs. Our participants evaluated an LLM provided by the university in a quasi-experimental setup; first by themselves, and then with a scaffolded design probe that guided them through an end-user auditing exercise. Qualitative analysis of participant think-aloud and LLM interaction data showed that students without basic AI literacy skills struggle to conceptualize and evaluate LLM biases on their own. However, they transition to focused thinking and purposeful interactions when provided with structured guidance. We highlight areas where current university policies may fall short and offer policy and design recommendations to better support students.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1015},
numpages = {23},
keywords = {End-user Audit, End-user Algorithmic Audit, User-Driven Algorithm Auditing, Algorithmic Audit, Auditing Algorithms, Algorithmic Bias, Algorithmic Harm, Large Language Models, LLMs, AI Literacy, AI Education, Responsible AI.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713883,
author = {Song, Inhwa and Park, SoHyun and Pendse, Sachin R and Schleider, Jessica Lee and De Choudhury, Munmun and Kim, Young-Ho},
title = {ExploreSelf: Fostering User-driven Exploration and Reflection on Personal Challenges with Adaptive Guidance by Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713883},
doi = {10.1145/3706598.3713883},
abstract = {Expressing stressful experiences in words is proven to improve mental and physical health, but individuals often disengage with writing interventions as they struggle to organize their thoughts and emotions. Reflective prompts have been used to provide direction, and large language models (LLMs) have demonstrated the potential to provide tailored guidance. However, current systems often limit users’ flexibility to direct their reflections. We thus present ExploreSelf, an LLM-driven application designed to empower users to control their reflective journey, providing adaptive support through dynamically generated questions. Through an exploratory study with 19 participants, we examine how participants explore and reflect on personal challenges using ExploreSelf. Our findings demonstrate that participants valued the flexible navigation of adaptive guidance to control their reflective journey, leading to deeper engagement and insight. Building on our findings, we discuss the implications of designing LLM-driven tools that facilitate user-driven and effective reflection of personal challenges.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {306},
numpages = {22},
keywords = {Reflective Writing, Technology for Well-being, User-driven Exploration, User Agency, Large Language Models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3689904.3694699,
author = {Armstrong, Lena and Liu, Abbey and MacNeil, Stephen and Metaxa, Dana\"{e}},
title = {The Silicon Ceiling: Auditing GPT’s Race and Gender Biases in Hiring},
year = {2024},
isbn = {9798400712227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689904.3694699},
doi = {10.1145/3689904.3694699},
abstract = {Large language models (LLMs) are increasingly being introduced in workplace settings, with the goals of improving efficiency and fairness. However, concerns have arisen regarding these models’ potential to reflect or exacerbate social biases and stereotypes. This study explores the potential impact of LLMs on hiring practices. To do so, we conduct an AI audit of race and gender biases in one commonly-used LLM, OpenAI’s GPT-3.5, taking inspiration from the history of traditional offline resume audits. We conduct two studies using names with varied race and gender connotations: resume assessment (Study 1) and resume generation (Study 2). In Study 1, we ask GPT to score resumes with 32 different names (4 names for each combination of the 2 gender and 4 racial groups) and two anonymous options across 10 occupations and 3 evaluation tasks (overall rating, willingness to interview, and hireability). We find that the model reflects some biases based on stereotypes. In Study 2, we prompt GPT to create resumes (10 for each name) for fictitious job candidates. When generating resumes, GPT reveals underlying biases; women’s resumes had occupations with less experience, while Asian and Hispanic resumes had immigrant markers, such as non-native English and non-U.S. education and work experiences. Our findings contribute to a growing body of literature on LLM biases, particularly in workplace contexts.},
booktitle = {Proceedings of the 4th ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization},
articleno = {2},
numpages = {18},
keywords = {Algorithm auditing, Algorithmic fairness, GPT, LLMs, Resume studies},
location = {San Luis Potosi, Mexico},
series = {EAAMO '24}
}

@inproceedings{10.1145/3678717.3695760,
author = {Zhang, Qianheng and Gao, Song},
title = {Automating Geospatial Analysis Workflows Using ChatGPT-4},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678717.3695760},
doi = {10.1145/3678717.3695760},
abstract = {The field of Geospatial Artificial Intelligence (GeoAI) has significantly impacted domain applications such as urban analytics, environmental monitoring, and disaster management. While powerful geoprocessing tools in geographic information systems (GIS) like ArcGIS Pro are available, automating these workflows with Python scripting using AI chatbots remains a challenge, especially for non-expert users. This study investigates whether ChatGPT-4 can automate GIS workflows by generating ArcPy functions based on structured instructions. We tested prompt engineering's ability on helping large language models (LLMs) understand spatial data and GIS workflows. The overall task success rate reaches 80.5%. It is a valid and easy to implement approach for domain scientists who want to use ArcPy to automate their workflows.},
booktitle = {Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
pages = {715–716},
numpages = {2},
keywords = {GIS, GeoAI, LLM, Prompt engineering, automate workflow},
location = {Atlanta, GA, USA},
series = {SIGSPATIAL '24}
}

@inproceedings{10.1145/3686852.3686864,
author = {Dakshit, Sagnik},
title = {Faculty Perspectives on the Potential of RAG in Computer Science Higher Education},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3686864},
doi = {10.1145/3686852.3686864},
abstract = {The emergence of Large Language Models (LLMs) has significantly impacted the field of Natural Language Processing and has transformed conversational tasks across various domains because of their widespread integration in applications and public access. The discussion surrounding the application of LLMs in education has raised ethical concerns, particularly concerning plagiarism and policy compliance. Despite the prowess of LLMs in conversational tasks, the limitations of reliability and hallucinations exacerbate the need to guardrail conversations, motivating our investigation of RAG in computer science higher education. We developed Retrieval Augmented Generation (RAG) applications for the two tasks of virtual teaching assistants and teaching aids. In our study, we collected the ratings and opinions of faculty members in undergraduate and graduate computer science university courses at various levels, using our personalized RAG systems for each course. This study is the first to gather faculty feedback on the application of LLM-based RAG in education. The investigation revealed that while faculty members acknowledge the potential of RAG systems as virtual teaching assistants and teaching aids, certain barriers and features are suggested for their full-scale deployment. These findings contribute to the ongoing discussion on the integration of advanced language models in educational settings, highlighting the need for careful consideration of ethical implications and the development of appropriate safeguards to ensure responsible and effective implementation.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {19–24},
numpages = {6},
keywords = {Education, Large Language Models, Learning, Neural Networks, Retrieval Augmented Generation},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@article{10.1145/3708519,
author = {Lyu, Michael R. and Ray, Baishakhi and Roychoudhury, Abhik and Tan, Shin Hwei and Thongtanunam, Patanamon},
title = {Automatic Programming: Large Language Models and Beyond},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708519},
doi = {10.1145/3708519},
abstract = {Automatic programming has seen increasing popularity due to the emergence of tools like GitHub Copilot which rely on Large Language Models (LLMs). At the same time, automatically generated code faces challenges during deployment due to concerns around quality and trust. In this article, we study automated coding in a general sense and study the concerns around code quality, security, and related issues of programmer responsibility. These are key issues for organizations while deciding on the usage of automatically generated code. We discuss how advances in software engineering such as program repair and analysis can enable automatic programming. We conclude with a forward looking view, focusing on the programming environment of the near future, where programmers may need to switch to different roles to fully utilize the power of automatic programming. Automated repair of automatically generated programs from LLMs can help produce higher assurance code from LLMs, along with evidence of assurance.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {140},
numpages = {33},
keywords = {AI-based coding, Automated Program Repair, Trustworthy Software}
}

@article{10.1145/3712286,
author = {Yang, Bufang and Guo, Yunqi and Xu, Lilin and Yan, Zhenyu and Chen, Hongkai and Xing, Guoliang and Jiang, Xiaofan},
title = {SocialMind: LLM-based Proactive AR Social Assistive System with Human-like Perception for In-situ Live Interactions},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
url = {https://doi.org/10.1145/3712286},
doi = {10.1145/3712286},
abstract = {Social interactions are fundamental to human life. The recent emergence of large language models (LLMs)-based virtual assistants has demonstrated their potential to revolutionize human interactions and lifestyles. However, existing assistive systems mainly provide reactive services to individual users, rather than offering in-situ assistance during live social interactions with conversational partners. In this study, we introduce SocialMind, the first LLM-based proactive AR social assistive system that provides users with in-situ social assistance. SocialMind employs human-like perception leveraging multi-modal sensors to extract both verbal and nonverbal cues, social factors, and implicit personas, incorporating these social cues into LLM reasoning for social suggestion generation. Additionally, SocialMind employs a multi-tier collaborative generation strategy and proactive update mechanism to display social suggestions on Augmented Reality (AR) glasses, ensuring that suggestions are timely provided to users without disrupting the natural flow of conversation. Evaluations on three public datasets and a user study with 20 participants show that SocialMind achieves 38.3% higher engagement compared to baselines, and 95% of participants are willing to use SocialMind in their live social interactions.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {23},
numpages = {30},
keywords = {AR Glasses, Augmented Reality, Internet of Things, LLMs, Multi-modal Sensor Data, Proactive Assistive Systems, Social Interaction}
}

@inproceedings{10.1145/3643991.3645069,
author = {Wu, Liangxuan and Zhao, Yanjie and Hou, Xinyi and Liu, Tianming and Wang, Haoyu},
title = {ChatGPT Chats Decoded: Uncovering Prompt Patterns for Superior Solutions in Software Development Lifecycle},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645069},
doi = {10.1145/3643991.3645069},
abstract = {The advent of Large Language Models (LLMs) like ChatGPT has markedly transformed software development, aiding tasks from code generation to issue resolution with their human-like text generation. Nevertheless, the effectiveness of these models greatly depends on the nature of the prompts given by developers. Therefore, this study delves into the DevGPT dataset, a rich collection of developer-ChatGPT dialogues, to unearth the patterns in prompts that lead to effective problem resolutions. The underlying motivation for this research is to enhance the collaboration between human developers and AI tools, thereby improving productivity and problem-solving efficacy in software development. Utilizing a combination of textual analysis and data-driven approaches, this paper seeks to identify the attributes of prompts that are associated with successful interactions, providing crucial insights for the strategic employment of ChatGPT in software engineering environments.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {142–146},
numpages = {5},
keywords = {data mining, large language model, LLM, ChatGPT},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@article{10.1145/3725840,
author = {Lopez-Cardona, Angela and Idesis, Sebastian and Barreda-\'{A}ngeles, Miguel and Abadal, Sergi and Arapakis, Ioannis},
title = {OASST-ETC Dataset: Alignment Signals from Eye-tracking Analysis of LLM Responses},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
url = {https://doi.org/10.1145/3725840},
doi = {10.1145/3725840},
abstract = {While Large Language Models (LLMs) have significantly advanced natural language processing, aligning them with human preferences remains an open challenge. Although current alignment methods rely primarily on explicit feedback, eye-tracking (ET) data offers insights into real-time cognitive processing during reading. In this paper, we present OASST-ETC, a novel eye-tracking corpus capturing reading patterns from 24 participants, while evaluating LLM-generated responses from the OASST1 dataset. Our analysis reveals distinct reading patterns between preferred and non-preferred responses, which we compare with synthetic eye-tracking data. Furthermore, we examine the correlation between human reading measures and attention patterns from various transformer-based models, discovering stronger correlations in preferred responses. This work introduces a unique resource for studying human cognitive processing in LLM evaluation and suggests promising directions for incorporating eye-tracking data into alignment methods. The dataset and analysis code are publicly available.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {ETRA15},
numpages = {29},
keywords = {LLMs, RLHF, eye-tracking}
}

@inproceedings{10.1145/3675094.3677573,
author = {Wang, Yongfu and Tang, Mingyue and He, Yifan and Tang, Tiffany Y.},
title = {Interactive Design with Autistic Children using LLM and IoT for Personalized Training: The Good, The Bad and The Challenging},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3677573},
doi = {10.1145/3675094.3677573},
abstract = {The advent of generative artificial intelligence technologies, such as Large Language Models (LLMs) and Large Vision Models (LVMs), has shown promising results in both academic and industrial sectors, leading to widespread adoption. However, there has been limited focus on applying these technologies to assist children with special needs like Autism Spectrum Disorder (ASD). Meanwhile, conventional personalized training with interactive design for children with special needs continues to face significant challenges with traditional approaches. This workshop aims to provide a platform for researchers, software developers, medical practitioners, and designers to discuss and evaluate the benefits and drawbacks of using LLMs and the Internet of Things (IoT) for the diagnosis and personalized training of autistic children. Through a series of activities, including oral presentations, demonstrations, and panel discussions, this half-day workshop seeks to foster a network of experts dedicated to improving the lives of children with special needs and to inspire further research on leveraging emerging ubiquitous technologies for these underprivileged users, their caregivers and special education teachers.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1000–1003},
numpages = {4},
keywords = {autism, children, interaction design, large language model (llm), personalized training, ubiquitous computing},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3715885.3715889,
author = {Smit, Koen and Leewis, Sam and Almoustafa, Hussin and Yildirim, Kenan and Uymaz, Talha},
title = {Enhancing Educational Dynamics Integrating Large Language Models with a Social Robot},
year = {2025},
isbn = {9798400712463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715885.3715889},
doi = {10.1145/3715885.3715889},
abstract = {In contemporary educational settings, there is an increasing demand to enhance social interactions and learning opportunities using innovative technologies. Traditional robotic interactions often fall short of providing the responsiveness and personalization necessary for effective educational support. This research addresses these limitations by exploring the usage of Large Language Models (LLMs) to deliver more dynamic, responsive, and customized interactions in educational environments where robotic technologies are becoming more prevalent. An experimental approach is used to systematically evaluate different integration methodologies, ranging from basic LLM-enhanced interactions to more complex customized interactions. The primary objective of this study is to determine whether the integration of LLMs can significantly improve the interaction quality of Pepper the robot compared to traditional scripted methods. Findings show that LLM integration, particularly with cloud-based models like OpenAI, substantially improves interaction quality, response times, and user satisfaction. Local LLMs offer additional benefits in terms of data privacy and offline functionality, while the integration of could-based LLMs enhances user interaction and satisfaction, challenges such as cost, data privacy, and technological constraints must be addressed to fully unlock the potential of AI-enhanced social robotics in education.},
booktitle = {Proceedings of the 2024 8th International Conference on Software and E-Business},
pages = {87–94},
numpages = {8},
keywords = {Education, Generative AI, LLMs, Large Language Models, Social Robots},
location = {
},
series = {ICSeB '24}
}

@article{10.1145/3686807,
author = {Wang, Haochun and Zhao, Sendong and Qiang, Zewen and Li, Zijian and Liu, Chi and Xi, Nuwa and Du, Yanrui and Qin, Bing and Liu, Ting},
title = {Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Trustworthy Response Generation in Chinese},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1556-4681},
url = {https://doi.org/10.1145/3686807},
doi = {10.1145/3686807},
abstract = {Large Language Models (LLMs) have demonstrated remarkable success in diverse natural language processing (NLP) tasks in general domains. However, LLMs sometimes generate responses with the hallucination about medical facts due to limited domain knowledge. Such shortcomings pose potential risks in the utilization of LLMs within medical contexts. To address this challenge, we propose knowledge-tuning, which leverages structured medical knowledge bases for the LLMs to grasp domain knowledge efficiently and facilitate trustworthy response generation. We also release cMedKnowQA, a Chinese medical knowledge question-answering dataset constructed from medical knowledge bases to assess the medical knowledge proficiency of LLMs. Experimental results show that the LLMs which are knowledge-tuned with cMedKnowQA can exhibit higher levels of accuracy in response generation compared with vanilla instruction-tuning and offer a new trustworthy way for the domain adaptation of LLMs. We release our code and data at .},
journal = {ACM Trans. Knowl. Discov. Data},
month = feb,
articleno = {53},
numpages = {17},
keywords = {Large Language Model, Medical Question Answering, Trustworthy Response Generation, Medical Knowledge Base}
}

@inproceedings{10.1145/3657604.3662036,
author = {Lyu, Wenhan and Wang, Yimeng and Chung, Tingting (Rachel) and Sun, Yifan and Zhang, Yixuan},
title = {Evaluating the Effectiveness of LLMs in Introductory Computer Science Education: A Semester-Long Field Study},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662036},
doi = {10.1145/3657604.3662036},
abstract = {The integration of AI assistants, especially through the development of Large Language Models (LLMs), into computer science education has sparked significant debate, highlighting both their potential to augment student learning and the risks associated with their misuse. An emerging body of work has looked into using LLMs in education, primarily focusing on evaluating the performance of existing models or conducting short-term human subject studies. However, very little work has examined the impacts of LLM-powered assistants on students in entry-level programming courses, particularly in real-world contexts and over extended periods. To address this research gap, we conducted a semester-long, between-subjects study with 50 students using CodeTutor, an LLM-powered assistant developed by our research team. Our study results show that students who used CodeTutor (the "CodeTutor group" as the experimental group) achieved statistically significant improvements in their final scores compared to peers who did not use the tool (the "control group"). Within the CodeTutor group, those without prior experience with LLM-powered tools demonstrated significantly greater performance gain than their counterparts. We also found that students expressed positive feedback regarding CodeTutor's capability to comprehend their queries and assist in learning programming language syntax. However, they had concerns about CodeTutor's limited role in developing critical thinking skills. Over the course of the semester, students' agreement with CodeTutor's suggestions decreased, with a growing preference for support from traditional human teaching assistants. Our findings also show that students turned to CodeTutor for different tasks, including programming task completion, syntax comprehension, and debugging, particularly seeking help for programming assignments. Our analysis further reveals that the quality of user prompts was significantly correlated with CodeTutor's response effectiveness. Building upon these results, we discuss the implications of our findings for the need to integrate Generative AI literacy into curricula to foster critical thinking skills, and turn to examining the temporal dynamics of user engagement with LLM-powered tools. We further discuss the discrepancy between the anticipated functions of tools and students' actual capabilities, which sheds light on the need for tailored strategies to improve educational outcomes.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {63–74},
numpages = {12},
keywords = {field study, large language models, tutoring},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3629104.3672429,
author = {Delouee, Majid Lotfian and Pernes, Daria G. and Degeler, Victoria and Koldehofe, Boris},
title = {Towards Federated LLM-Powered CEP Rule Generation and Refinement},
year = {2024},
isbn = {9798400704437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629104.3672429},
doi = {10.1145/3629104.3672429},
abstract = {In traditional event processing systems, patterns representing situations of interest are typically defined by domain experts or learned from historical data, making rule generation reactive, time-consuming, and susceptible to human error. This paper proposes integrating large language models (LLMs) to automate and accelerate query translation and rule generation into event-based systems. Also, we introduce a federated learning schema to refine the initially generated rules by examining them over distributed event streams, ensuring greater accuracy and adaptability. Preliminary results demonstrate the potential of LLMs as a key component in proactively expediting the autonomous rule-generation process. Moreover, our findings suggest that employing customized prompt engineering techniques can further enhance the quality of the generated rules.},
booktitle = {Proceedings of the 18th ACM International Conference on Distributed and Event-Based Systems},
pages = {185–186},
numpages = {2},
keywords = {Autonomous Rule Generation, Complex Event Processing, Federated Learning, Large Language Models, Rule Refinement},
location = {Villeurbanne, France},
series = {DEBS '24}
}

@article{10.1145/3715109,
author = {Wu, Jie Jw and Fard, Fatemeh H.},
title = {HumanEvalComm: Benchmarking the Communication Competence of Code Generation for LLMs and LLM Agent},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715109},
doi = {10.1145/3715109},
abstract = {Large language models (LLMs) have significantly improved their ability to perform tasks in the field of code generation. However, there is still a gap between LLMs being capable coders and being top-tier software engineers. The most recent trend is using LLM-based agents to iterate the code generation process. Based on the observation that top-level software engineers often ask clarifying questions to reduce Ambiguity in both requirements and coding solutions, we argue that the same should be applied to LLMs for code generation tasks. For this purpose, we define the communication skills of LLMs as “being able to ask clarifying questions when the description of the code generation problem has issues”. In this study, we restrict these issues to three matters from the software requirement engineering field: inconsistent requirements, ambiguous requirements, and incomplete requirements. By asking probing questions about the requirements of problem descriptions before generating the final code, the challenges of programming with LLMs, such as unclear intent specification may be alleviated, resulting to a correct code in the initial iterations.In this work, we conducted an empirical study on the benchmark and analysis of the communication skills of LLMs for code generation. We created a new benchmark, HumanEvalComm, by modifying problem descriptions according to three issues mentioned above, Inconsistency, Ambiguity, Incompleteness. We then experimented on HumanEvalComm with different Code LLMs, and a new LLM agent approach, Code Clarification and Generation Agent (Okanagan), to identify and ask questions in ambiguous parts from code and descriptions for further refining the generated code. In the evaluation, we introduced an LLM-based evaluator and created Communication Rate and Good Question Rate as the evaluation metrics to represent the ratio of questions asked and questions with good quality in responses. We found that more than 60% of responses from Code LLMs still generate code rather than ask questions when the problem descriptions are manually modified according to different clarification categories. The Pass@1 and Test Pass Rate of most Code LLMs drop by 35%  (sim)  52% and by 17%  (sim)  35% respectively, with statistical significance in each category for over 75% numbers. Okanagan, as an LLM agent approach that uses LLM such as ChatGPT 3.5, effectively increases the Communication Rate and Good Question Rate by an absolute 58% and 38%, respectively. Thus, Okanagan boosts Pass@1 and Test Pass Rate by an absolute 8% and 7%, respectively, when the problem descriptions are modified based on given clarification categories. This result indicates the potential for achieving more effective communication capability using LLM agent. Our benchmark and full code are publicly available at .},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan
}

@inproceedings{10.1145/3701716.3717556,
author = {Ma, Ao and Li, Zhiyuan and Liang, Zhuonan and Gu, Tiancheng and Fan, Jianan and Long, Jieting and M\"{u}ller, Henning and Cai, Weidong},
title = {Seek Inner: LLM-Enhanced Information Mining for Medical Visual Question Answering},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717556},
doi = {10.1145/3701716.3717556},
abstract = {Medical visual question answering (Med-VQA) focuses on analyzing medical images to accurately respond to clinicians' specific questions. Although integrating prior knowledge can enhance VQA reasoning, current methods often struggle to extract relevant information from the vast and complex medical knowledge base, thereby limiting the models' ability to learn domain-specific features. To overcome this limitation, our study presents a novel information mining approach that leverages large language models (LLMs) to efficiently retrieve pertinent data. Specifically, we design a latent knowledge generation module that employs LLMs to separately extract and filter information from questions and answers, enhancing the model's inference capabilities. Furthermore, we propose a multi-level prompt fusion module in which an initial prompt interacts with the extracted latent knowledge to draw clinically relevant details from both unimodal and multimodal features. Experimental results demonstrate that our approach outperforms current state-of-the-art models on multiple Med-VQA benchmark datasets.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2297–2305},
numpages = {9},
keywords = {knowledge injection, large language models, medical visual question answering, multimodal learning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3701625.3701657,
author = {de Almeida, \'{A}gatha and Collins, Eliane and Oran, Ana Carolina},
title = {AI in Service of Software Quality: How ChatGPT and Personas Are Transforming Exploratory Testing},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701657},
doi = {10.1145/3701625.3701657},
abstract = {Context: Exploratory testing is essential in the software validation process as a way to find unexpected and critical failures in a short time, complementing documented functional test cases. However, creating scenarios to explore the software (such as test charters) can be time-consuming, and depending on the team’s experience, it may lack adequate coverage of functionalities and scenarios that target specific user profiles of the application. Objective: This article investigates how AI, through LLMs (Large Language Models), can assist in creating exploratory test charters that reflect the characteristics and needs of different user personas. Method: To achieve this, an experimental study was conducted where personas were used as input in ChatGPT 3.5 to generate exploratory test charters. The effectiveness of the approach was evaluated by Software Engineering students, who analyzed the performance and usefulness of the generated charters through a questionnaire based on the TAM model, supplemented by qualitative and quantitative analyses. Results: Data analysis indicated positive acceptance of ChatGPT 3.5 by the participants, highlighting its ease of use and perceived usefulness. Conclusion: This study contributes to the field of Software Engineering by demonstrating a practical application of artificial intelligence in the automated generation of test charters. ChatGPT 3.5 has proven to be a promising tool to support the creation of personalized exploratory test charters, contributing to software quality improvement. The integration of artificial intelligence techniques with user-centered design methods can significantly optimize the software testing process.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {179–188},
numpages = {10},
keywords = {Exploratory Testing, ChatGPT, Personas, Software Quality, Artificial Intelligence},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3691620.3695513,
author = {Jiang, Zongze and Wen, Ming and Cao, Jialun and Shi, Xuanhua and Jin, Hai},
title = {Towards Understanding the Effectiveness of Large Language Models on Directed Test Input Generation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695513},
doi = {10.1145/3691620.3695513},
abstract = {Automatic testing has garnered significant attention and success over the past few decades. Techniques such as unit testing and coverage-guided fuzzing have revealed numerous critical software bugs and vulnerabilities. However, a long-standing, formidable challenge for existing techniques is how to achieve higher testing coverage. Constraint-based techniques, such as symbolic execution and concolic testing, have been well-explored and integrated into the existing approaches. With the popularity of Large Language Models (LLMs), recent research efforts to design tailored prompts to generate inputs that can reach more uncovered target branches. However, the effectiveness of using LLMs for generating such directed inputs and the comparison with the proven constraint-based solutions has not been systematically explored.To bridge this gap, we conduct the first systematic study on the mainstream LLMs and constraint-based tools for directed input generation with a comparative perspective. We find that LLMs such as ChatGPT are comparable to or even better than the constraint-based tools, succeeding in 43.40%-58.57% samples in our dataset. Meanwhile, there are also limitations for LLMs in specific scenarios such as sequential calculation, where constraint-based tools are in a position of strength. Based on these findings, we propose a simple yet effective method to combine these two types of tools and implement a prototype based on ChatGPT and constraint-based tools. Our evaluation shows that our approach can outperform the baselines by 1.4x to 2.3x relatively. We believe our study can provide novel insights into directed input generation using LLMs, and our findings are essential for future testing research.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1408–1420},
numpages = {13},
keywords = {LLM, symbolic execution, directed input generation},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3639477.3639751,
author = {Pinto, Gustavo and De Souza, Cleidson and Neto, Joao Batista and Souza, Alberto and Gotto, Tarci­sio and Monteiro, Edward},
title = {Lessons from Building StackSpot AI: A Contextualized AI Coding Assistant},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639751},
doi = {10.1145/3639477.3639751},
abstract = {With their exceptional natural language processing capabilities, tools based on Large Language Models (LLMs) like ChatGPT and CoPilot have swiftly become indispensable resources in the software developer's toolkit. While recent studies suggest the potential productivity gains these tools can unlock, users still encounter drawbacks, such as generic or incorrect answers. Additionally, the pursuit of improved responses often leads to extensive prompt engineering efforts, diverting valuable time from writing code that delivers actual value. To address these challenges, a new breed of tools, built atop LLMs, is emerging. These tools aim to mitigate drawbacks by employing techniques like fine-tuning or enriching user prompts with contextualized information.In this paper, we delve into the lessons learned by a software development team venturing into the creation of such a contextualized LLM-based application, using retrieval-based techniques, called StackSpot AI. Over a four-month period, the team, despite lacking prior professional experience in LLM-based applications, built the product from scratch. Following the initial product release, we engaged with the development team responsible for the code generative components. Through interviews and analysis of the application's issue tracker, we uncover various intriguing challenges that teams working on LLM-based applications might encounter. For instance, we found three main group of lessons: LLM-based lessons, User-based lessons, and Technical lessons. By understanding these lessons, software development teams could become better prepared to build LLM-based applications.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {408–417},
numpages = {10},
keywords = {LLM, LLM-based applications, LLM for code, LLM4code, code LLMs, challenges},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@article{10.1145/3660783,
author = {Yuan, Zhiqiang and Liu, Mingwei and Ding, Shiji and Wang, Kaixin and Chen, Yixuan and Peng, Xin and Lou, Yiling},
title = {Evaluating and Improving ChatGPT for Unit Test Generation},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660783},
doi = {10.1145/3660783},
abstract = {Unit testing plays an essential role in detecting bugs in functionally-discrete program units (e.g., methods). Manually writing high-quality unit tests is time-consuming and laborious. Although the traditional techniques are able to generate tests with reasonable coverage, they are shown to exhibit low readability and still cannot be directly adopted by developers in practice. Recent work has shown the large potential of large language models (LLMs) in unit test generation. By being pre-trained on a massive developer-written code corpus, the models are capable of generating more human-like and meaningful test code. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
In this work, we perform the first empirical study to evaluate the capability of ChatGPT (i.e., one of the most representative LLMs with outstanding performance in code generation and comprehension) in unit test generation. In particular, we conduct both a quantitative analysis and a user study to systematically investigate the quality of its generated tests in terms of correctness, sufficiency, readability, and usability. We find that the tests generated by ChatGPT still suffer from correctness issues, including diverse compilation errors and execution failures (mostly caused by incorrect assertions); but the passing tests generated by ChatGPT almost resemble manually-written tests by achieving comparable coverage, readability, and even sometimes developers' preference. Our findings indicate that generating unit tests with ChatGPT could be very promising if the correctness of its generated tests could be further improved. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Inspired by our findings above, we further propose ChatTester, a novel ChatGPT-based unit test generation approach, which leverages ChatGPT itself to improve the quality of its generated tests. ChatTester incorporates an initial test generator and an iterative test refiner. Our evaluation demonstrates the effectiveness of ChatTester by generating 34.3% more compilable tests and 18.7% more tests with correct assertions than the default ChatGPT. In addition to ChatGPT, we further investigate the generalization capabilities of ChatTester by applying it to two recent open-source LLMs (i.e., CodeLLama-Instruct and CodeFuse) and our results show that ChatTester can also improve the quality of tests generated by these LLMs.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {76},
numpages = {24},
keywords = {Large language model, Test generation, Unit testing}
}

@inproceedings{10.1145/3696952.3696992,
author = {Wang, Jue and He, Xiaolan},
title = {Innovation and Entrepreneurship Education Platform in Vocational Colleges Based on Large Language Models},
year = {2024},
isbn = {9798400718076},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696952.3696992},
doi = {10.1145/3696952.3696992},
abstract = {Digital productivity has become an important feature of new quality productive forces. Innovation and entrepreneurship education (IEE) in vocational colleges is an important component of China's higher education system.  Many scholars believe that the digital development of innovation and entrepreneurship in colleges will ultimately form a comprehensive digital ecosystem, in which digital platforms will play an important role. It is found that the application of digital technology on existing platforms is insufficient, digital resources are difficult to acquire, platforms lake correlation, and application platforms become formalistic. A comprehensive digital platform for innovation and entrepreneurship education in vocational colleges is constructed to solve the existing problems of platform digitalization. The application of the Large Language Models (LLMs) can enable the platform to process a large amount of text data. This article uses ChatGPT 4o as a representative for text sample processing, demonstrating the superiority of the model in platform applications. The digital development of platforms helps vocational colleges integrate into the digital ecosystem in the field of innovation and entrepreneurship education.},
booktitle = {Proceedings of the 2024 9th International Conference on Intelligent Information Processing},
pages = {299–304},
numpages = {6},
keywords = {ChatGPT, Large Language Models, innovation and entrepreneurship education industry, platform digitization, vocational colleges},
location = {
},
series = {ICIIP '24}
}

@inproceedings{10.1145/3613904.3642693,
author = {Kim, Taewan and Shin, Donghoon and Kim, Young-Ho and Hong, Hwajung},
title = {DiaryMate: Understanding User Perceptions and Experience in Human-AI Collaboration for Personal Journaling},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642693},
doi = {10.1145/3613904.3642693},
abstract = {With their generative capabilities, large language models (LLMs) have transformed the role of technological writing assistants from simple editors to writing collaborators. Such a transition emphasizes the need for understanding user perception and experience, such as balancing user intent and the involvement of LLMs across various writing domains in designing writing assistants. In this study, we delve into the less explored domain of personal writing, focusing on the use of LLMs in introspective activities. Specifically, we designed DiaryMate, a system that assists users in journal writing with LLM. Through a 10-day field study (N=24), we observed that participants used the diverse sentences generated by the LLM to reflect on their past experiences from multiple perspectives. However, we also observed that they are over-relying on the LLM, often prioritizing its emotional expressions over their own. Drawing from these findings, we discuss design considerations when leveraging LLMs in a personal writing practice.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1046},
numpages = {15},
keywords = {Diary, Human-AI collaborative writing, Journaling, Personal writing},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3696410.3714866,
author = {Yin, Jun and Zeng, Zhengxin and Li, Mingzheng and Yan, Hao and Li, Chaozhuo and Han, Weihao and Zhang, Jianjin and Liu, Ruochen and Sun, Hao and Deng, Weiwei and Sun, Feng and Zhang, Qi and Pan, Shirui and Wang, Senzhang},
title = {Unleash LLMs Potential for Sequential Recommendation by Coordinating Dual Dynamic Index Mechanism},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714866},
doi = {10.1145/3696410.3714866},
abstract = {Owing to the unprecedented capability in semantic understanding and logical reasoning, large language models (LLMs) have shown fantastic potential in developing next-generation sequential recommender systems (RSs). However, existing LLM-based sequential RSs mostly separate index generation from sequential recommendation, leading to insufficient integration between semantic information and collaborative information. On the other hand, the neglect of user-related information hinders LLM-based sequential RSs from exploiting high-order user-item interaction patterns. In this paper, we propose the End-to-End Dual Dynamic (ED2) recommender, the first LLM-based sequential RS which adopts dual dynamic index mechanism, targeting resolving the above limitations simultaneously. The dual dynamic index mechanism can not only assembly index generation and sequential recommendation into a unified LLM-backbone pipeline, but also make it practical for LLM-based sequential recommender to take advantage of user-related information. Specifically, to facilitate the LLM comprehension ability to dual dynamic index, we propose a multigrained token regulator which constructs alignment supervision based on LLMs semantic knowledge across multiple representation granularities. Moreover, the associated user collection data and a series of novel instruction tuning tasks are specially customized to capture the high-order user-item interaction patterns. Extensive experiments on three public datasets demonstrate the superiority of ED2, achieving an average improvement of 19.62% in Hit-Rate and 21.11% in NDCG.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {216–227},
numpages = {12},
keywords = {large language models, sequential recommender systems},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3706599.3720019,
author = {Lu, Zhuoran and Lim, Gionnieve and Yin, Ming},
title = {Understanding the Effects of Large Language Model (LLM)-driven Adversarial Social Influences in Online Information Spread},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720019},
doi = {10.1145/3706599.3720019},
abstract = {Misinformation on social media poses significant societal challenges, particularly with the rise of large language models (LLMs) that can amplify its realism and reach. This study examines how adversarial social influence generated by LLM-powered bots affects people’s online information processing. Via a pre-registered, randomized human-subject experiment, we examined the effects of two types of LLM-driven adversarial influence: bots posting comments contrary to the news veracity and bots replying adversarially to human comments. Results show that both forms of influence significantly reduce participants’ ability to detect misinformation and discern true news from false. Additionally, adversarial comments were more effective than replies in discouraging the sharing of real news. The impact of these influences was moderated by political alignment, with participants more susceptible when the news conflicted with their political leanings. Guided by these findings, we conclude by discussing the targeted interventions to combat misinformation spread by adversarial social influences.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {555},
numpages = {7},
keywords = {misinformation, fake news, artificial intelligence, social influence, large language model, human-AI interaction},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3691620.3695506,
author = {Zhang, Huan and Cheng, Wei and Wu, Yuhan and Hu, Wei},
title = {A Pair Programming Framework for Code Generation via Multi-Plan Exploration and Feedback-Driven Refinement},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695506},
doi = {10.1145/3691620.3695506},
abstract = {Large language models (LLMs) have achieved impressive performance on code generation. Although prior studies enhanced LLMs with prompting techniques and code refinement, they still struggle with complex programming problems due to rigid solution plans. In this paper, we draw on pair programming practices to propose PairCoder, a novel LLM-based framework for code generation. PairCoder incorporates two collaborative LLM agents, namely a Navigator agent for high-level planning and a Driver agent for specific implementation. The Navigator is responsible for proposing promising solution plans, selecting the current optimal plan, and directing the next iteration round based on execution feedback. The Driver follows the guidance of Navigator to undertake initial code generation, code testing, and refinement. This interleaved and iterative workflow involves multi-plan exploration and feedback-based refinement, which mimics the collaboration of pair programmers. We evaluate PairCoder with both open-source and closed-source LLMs on various code generation benchmarks. Extensive experimental results demonstrate the superior accuracy of PairCoder, achieving relative pass@1 improvements of 12.00%--162.43% compared to prompting LLMs directly.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1319–1331},
numpages = {13},
keywords = {code generation, large language model, agent, pair programming},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3701716.3715586,
author = {Huang, Tony Danhui and Ren, Yongli and Zhang, Xiuzhen},
title = {Can Large Language Models Be a Good Evaluator for Review-based Product Question Answering?},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715586},
doi = {10.1145/3701716.3715586},
abstract = {Large language models (LLMs) have demonstrated impressive performance on evaluating natural language generation tasks. Review-based Product Question Answering (RPQA) evaluation, which is a domain knowledge-intensive Question Answering (QA) evaluation, still largely relies on lexicon-based metrics and frozen embedding-based metrics. Those metrics fail if reference answers are absent. Despite some model-based metrics being learned from in-domain data for the RPQA task evaluation, little research has been done on using LLMs. Chain-of-Thought (CoT) is a state-of-the-art prompting method that has been proposed to induce LLMs to solve complex problems efficiently. The CoT reasoning steps can be resolved using the internal knowledge of LLMs, but this internal knowledge may be insufficient in domain knowledge-intensive RPQA evaluation settings. In this work, we explore the feasibility of leveraging LLMs as evaluators for RPQA evaluation. Specifically, we design a structured prompt template with one-shot or few-shot in-context learning, incorporating the CoT mechanism and the System 2 thinking process for RPQA evaluation. We call it as ExampLe-Enhanced CoT prompting (ELECT). We conduct a comprehensive study on various LLMs, including evaluation-oriented and general-purpose LLMs. Experimental results show that LLM-based evaluators can effectively evaluate RPQA. Upon integrating ELECT prompting into the demonstration examples in the prompt, we observe an improvement in the performance of the LLM-based evaluator. Code is publicly available at https://github.com/tonydhuang/elect-prompting.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1019–1023},
numpages = {5},
keywords = {chain-of-thought, evaluation, llm-based evaluation, product question answering evaluation, system 2 thinking process},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3670865.3673479,
author = {Brand, James and Israeli, Ayelet and Ngwe, Donald},
title = {Using GPT for Market Research},
year = {2024},
isbn = {9798400707049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670865.3673479},
doi = {10.1145/3670865.3673479},
abstract = {Large language models (LLMs) have quickly become popular as labor-augmenting tools for programming, writing, and many other processes that benefit from quick text generation. In this paper we explore the uses and benefits of LLMs for researchers and practitioners who aim to understand consumer preferences. We focus on the distributional nature of LLM responses, and query the Generative Pre-trained Transformer 3.5 (GPT-3.5) model to generate hundreds of survey responses to each prompt. We offer two sets of results to illustrate our approach and assess it. First, we show that GPT-3.5, a widely-used LLM, responds to sets of survey questions in ways that are consistent with economic theory and well-documented patterns of consumer behavior, including downward-sloping demand curves and state dependence. Second, we show that estimates of willingness-to-pay for products and features generated by GPT-3.5 are of realistic magnitudes and match estimates from a recent study that elicited preferences from human consumers. We also offer preliminary guidelines for how best to query information from GPT-3.5 for marketing purposes and discuss potential limitations.https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4395751},
booktitle = {Proceedings of the 25th ACM Conference on Economics and Computation},
pages = {613},
numpages = {1},
location = {New Haven, CT, USA},
series = {EC '24}
}

@inproceedings{10.1145/3701716.3715265,
author = {Hu, Renjun and Cheng, Yi and Meng, Libin and Xia, Jiaxin and Zong, Yi and Shi, Xing and Lin, Wei},
title = {Training an LLM-as-a-Judge Model: Pipeline, Insights, and Practical Lessons},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715265},
doi = {10.1145/3701716.3715265},
abstract = {The rapid advancement of large language models (LLMs) has opened new possibilities for their adoption as evaluative judges. This paper introduces Themis, a fine-tuned LLM judge that delivers sophisticated context-aware evaluations. We provide a comprehensive overview of the development pipeline for Themis, highlighting its scenario-dependent evaluation prompts and two novel methods for controlled instruction generation. These designs enable Themis to effectively distill evaluative skills from teacher models, while retaining flexibility for continuous development. We introduce two human-labeled benchmarks for meta-evaluation, demonstrating that Themis can achieve high alignment with human preferences in an economical manner. Additionally, we explore insights into the LLM-as-a-judge paradigm, revealing nuances in performance and the varied effects of reference answers. Notably, we observe that pure knowledge distillation from strong LLMs, though common, does not guarantee performance improvement through scaling. We propose a mitigation strategy based on instruction-following difficulty. Furthermore, we provide practical guidelines covering data balancing, prompt customization, multi-objective training, and metric aggregation. We aim for our method and findings, along with the fine-tuning data, benchmarks, and model checkpoints, to support future research and development in this area.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {228–237},
numpages = {10},
keywords = {large language models, llm evaluation, llm-as-a-judge},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3639478.3643076,
author = {Huang, Tao and Sun, Zhihong and Jin, Zhi and Li, Ge and Lyu, Chen},
title = {KareCoder: A New Knowledge-Enriched Code Generation System},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3643076},
doi = {10.1145/3639478.3643076},
abstract = {Large Language Models (LLMs) demonstrate proficiency in handling fundamental programming problems but struggle with complex programming in new types. The study presents KareCoder, integrating programming knowledge into code generation. Initial tests reveal KareCoder's significant success in the Pass@1 metric for complex competitive programming problems.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {270–271},
numpages = {2},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.5555/3709347.3743852,
author = {Wang, Peng-Yuan and Pang, Jing-Cheng and Wang, Chen-Yang and Liu, Xuhui and Liu, Tian-Shuo and Yang, Si-Hang and Qian, Hong and Yu, Yang},
title = {InCLET: Large Language Model In-context Learning can Improve Embodied Instruction-following},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Natural language-conditioned reinforcement learning (NLC-RL) empowers embodied agent to complete various tasks following human instruction. However, the unbounded natural language examples still introduce much complexity for the agent that solves concrete RL tasks, which can distract policy learning from completing the task. Consequently, extracting effective task representation from human instruction emerges as the critical component of NLC-RL. While previous methods have attempted to address this issue by learning task-related representation using large language models (LLMs), they highly rely on pre-collected task data and require extra training procedure. In this study, we uncover the inherent capability of LLMs to generate task representations and present a novel method, in-context learning embedding as task representation (InCLET). InCLET is grounded on a foundational finding that LLM in-context learning using trajectories can greatly help represent tasks. We thus firstly employ LLM to imagine task trajectories following the natural language instruction, then use in-context learning of LLM to generate task representations, and finally aggregate and project into a compact low-dimensional task representation. This representation is then used to train a human instruction-following agent. We conduct experiments on various embodied control environments and results show that InCLET creates effective task representations. Furthermore, this representation can significantly improve the RL training efficiency, compared to the baseline methods.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {2134–2142},
numpages = {9},
keywords = {embodiment agent, in-context learning, reinforcement learning},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3643991.3648400,
author = {Xiao, Tao and Treude, Christoph and Hata, Hideaki and Matsumoto, Kenichi},
title = {DevGPT: Studying Developer-ChatGPT Conversations},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3648400},
doi = {10.1145/3643991.3648400},
abstract = {This paper introduces DevGPT, a dataset curated to explore how software developers interact with ChatGPT, a prominent large language model (LLM). The dataset encompasses 29,778 prompts and responses from ChatGPT, including 19,106 code snippets, and is linked to corresponding software development artifacts such as source code, commits, issues, pull requests, discussions, and Hacker News threads. This comprehensive dataset is derived from shared ChatGPT conversations collected from GitHub and Hacker News, providing a rich resource for understanding the dynamics of developer interactions with ChatGPT, the nature of their inquiries, and the impact of these interactions on their work. DevGPT enables the study of developer queries, the effectiveness of ChatGPT in code generation and problem solving, and the broader implications of AI-assisted programming. By providing this dataset, the paper paves the way for novel research avenues in software engineering, particularly in understanding and improving the use of LLMs like ChatGPT by developers.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {227–230},
numpages = {4},
keywords = {ChatGPT, LLM, generative AI, dataset},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inbook{10.1145/3724504.3724635,
author = {He, Hao and Gao, Chaobang},
title = {Research on the Application of Artificial Intelligence in Basic Education: A Global Trend Analysis Based on Bibliometrics},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724635},
abstract = {Based on the bibliometric method, this study visually analyzed the application research literature of artificial intelligence (AI) in the domain of basic education in the Web of Science Core Collection from January 1, 2014 to November 1, 2024 with the help of VOSviewer and CiteSpace. A total of 344 valid articles were selected from 588 institutions and 1090 authors in 60 countries. They were published in 126 journals and cited 13855 references from 6922 journals. The study found that the number of papers published in China is the largest, and the quality recognition of papers in the United States is high. The journals with the greatest number of articles were mostly related to educational technology and computational intelligence, and Computers &amp; Education had the greatest number of citations per article. Keyword co-occurrence analysis shows that the study focuses on deep learning and the application of large language models (LLMs) has increased. The timeline analysis shows that the domain research has moved from the stage of data driven and educational technology application exploration to the stage of AI empowerment and personalized education. The co-citation analysis reveals that the interdisciplinary characteristics of educational technology research are obvious, and the literature co-citation network reflects the multi-dimensional application research type of AI in basic education. All in all, the popularity of AI application research in basic education is increasing, the research focus has changed, and generative AI is developing rapidly.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {799–806},
numpages = {8}
}

@inproceedings{10.1145/3706598.3714146,
author = {Prasad, Prajish and Balse, Rishabh and Balchandani, Dhwani},
title = {Exploring Multimodal Generative AI for Education through Co-design Workshops with Students},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714146},
doi = {10.1145/3706598.3714146},
abstract = {Multimodal large language models (MLLMs) are Generative AI models that take different modalities such as text, audio, and video as input and generate appropriate multimodal output. Since such models will be integrated into future educational tools, a human-centered design approach that takes students’ perspectives into account is essential while designing such applications.This paper describes two co-design workshops which were conducted with 79 student groups to examine how they design and prototype future educational tools integrated with MLLMs. Through various activities in the workshops, students discussed relevant educational problems, created journey maps, storyboards and low fidelity prototypes for their applications, and evaluated their applications based on relevant design principles. We found that students’ applications used MLLMs for important learning environment design features such as multimodal content creation, personalization, and feedback. Based on these findings, we discuss future research directions for the design of multimodality in generative AI educational applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {139},
numpages = {17},
keywords = {artificial intelligence, generative AI, large language models, multimodality, co-design, design principles, learning environment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3696348.3696868,
author = {He, Zhiyuan and Gottipati, Aashish and Qiu, Lili and Luo, Xufang and Xu, Kenuo and Yang, Yuqing and Yan, Francis Y.},
title = {Designing Network Algorithms via Large Language Models},
year = {2024},
isbn = {9798400712722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696348.3696868},
doi = {10.1145/3696348.3696868},
abstract = {We introduce Nada, the first framework to autonomously design network algorithms by leveraging the generative capabilities of large language models (LLMs). Starting with an existing algorithm implementation, Nada enables LLMs to create a wide variety of alternative designs in the form of code blocks. It then efficiently identifies the top-performing designs through a series of filtering techniques, minimizing the need for full-scale evaluations and significantly reducing computational costs. Using adaptive bitrate (ABR) streaming as a case study, we demonstrate that Nada produces novel ABR algorithms---previously unknown to human developers---that consistently outperform the original algorithm in diverse network environments, including broadband, satellite, 4G, and 5G.},
booktitle = {Proceedings of the 23rd ACM Workshop on Hot Topics in Networks},
pages = {205–212},
numpages = {8},
keywords = {Large Language Models, Network Algorithms},
location = {Irvine, CA, USA},
series = {HotNets '24}
}

@inproceedings{10.1145/3613904.3642472,
author = {Ha, Juhye and Jeon, Hyeon and Han, Daeun and Seo, Jinwook and Oh, Changhoon},
title = {CloChat: Understanding How People Customize, Interact, and Experience Personas in Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642472},
doi = {10.1145/3613904.3642472},
abstract = {Large language models (LLMs) have facilitated significant strides in generating conversational agents, enabling seamless, contextually relevant dialogues across diverse topics. However, the existing LLM-driven conversational agents have fixed personalities and functionalities, limiting their adaptability to individual user needs. Creating personalized agent personas with distinct expertise or traits can address this issue. Nonetheless, we lack knowledge of how people customize and interact with agent personas. In this research, we investigated how users customize agent personas and their impact on interaction quality, diversity, and dynamics. To this end, we developed CloChat, an interface supporting easy and accurate customization of agent personas in LLMs. We conducted a study comparing how participants interact with CloChat and ChatGPT. The results indicate that participants formed emotional bonds with the customized agents, engaged in more dynamic dialogues, and showed interest in sustaining interactions. These findings contribute to design implications for future systems with conversational agents using LLMs.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {305},
numpages = {24},
keywords = {Conversational Agents, Large Language Models, Persona, Persona Customization},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3649217.3653568,
author = {del Carpio Gutierrez, Andre and Denny, Paul and Luxton-Reilly, Andrew},
title = {Automating Personalized Parsons Problems with Customized Contexts and Concepts},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653568},
doi = {10.1145/3649217.3653568},
abstract = {Parsons problems provide useful scaffolding for introductory programming students learning to write code. However, generating large numbers of high-quality Parsons problems that appeal to the diverse range of interests in a typical introductory course is a significant challenge for educators. Large language models (LLMs) may offer a solution, by allowing students to produce on-demand Parsons problems for topics covering the breadth of the introductory programming curriculum, and targeting thematic contexts that align with their personal interests. In this paper, we introduce PuzzleMakerPy, an educational tool that uses an LLM to generate unlimited contextualized drag-and-drop programming exercises in the form of Parsons Problems, which introductory programmers can use as a supplemental learning resource. We evaluated PuzzleMakerPy by deploying it in a large introductory programming course, and found that the ability to personalize the contextual framing used in problem descriptions was highly engaging for students, and being able to customize the programming topics was reported as being useful for their learning.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {688–694},
numpages = {7},
keywords = {cs education tools, cs1, large language models, parsons problems, personalized learning},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@article{10.1145/3696459,
author = {Mart\'{\i}nez, Gonzalo and Hern\'{a}ndez, Jos\'{e} Alberto and Conde, Javier and Reviriego, Pedro and Merino-G\'{o}mez, Elena},
title = {Beware of Words: Evaluating the Lexical Diversity of Conversational LLMs using ChatGPT as Case Study
 },
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3696459},
doi = {10.1145/3696459},
abstract = {The performance of conversational Large Language Models (LLMs) in general, and of ChatGPT in particular, is currently being evaluated on many different tasks, from logical reasoning or maths to answering questions on a myriad of topics. Instead, much less attention is being devoted to the study of the linguistic features of the texts generated by these LLMs. This is surprising since LLMs are models for language, and understanding how they use the language is important. Indeed, conversational LLMs are poised to have a significant impact on the evolution of languages as they may eventually dominate the creation of new text. This means that for example, if conversational LLMs do not use a word it may become less and less frequent and eventually stop being used altogether. Therefore, evaluating the linguistic features of the text they produce and how those depend on the model parameters is the first step toward understanding the potential impact of conversational LLMs on the evolution of languages. In this paper, we consider the evaluation of the lexical diversity of the text generated by LLMs in English and how it depends on the model parameters. A methodology is presented and used to conduct a comprehensive evaluation of lexical diversity using ChatGPT as a case study. The results show how lexical diversity depends on the version of ChatGPT and some of its parameters, such as the presence penalty, or the role assigned to the model. The dataset and tools used in our analysis are released under open licenses with the goal of drawing much-needed attention to the evaluation of the linguistic features of LLM-generated text.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = sep,
keywords = {LLM, Lexical diversity, ChatGPT, Evaluation}
}

@inproceedings{10.1145/3643562.3672611,
author = {Heyman, Jennifer L and Rick, Steven R and Giacomelli, Gianni and Wen, Haoran and Laubacher, Robert and Taubenslag, Nancy and Knicker, Max and Jeddi, Younes and Ragupathy, Pranav and Curhan, Jared and Malone, Thomas},
title = {Supermind Ideator: How Scaffolding Human-AI Collaboration Can Increase Creativity},
year = {2024},
isbn = {9798400705540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643562.3672611},
doi = {10.1145/3643562.3672611},
abstract = {Previous efforts to support creative problem-solving have included (a) techniques such as brainstorming and design thinking to stimulate creative ideas, and (b) software tools to record and share these ideas. Now, generative AI technologies can suggest new ideas that might never have occurred to the users, and users can then select from these ideas or use them to stimulate even more ideas. To explore these possibilities, we developed a system called Supermind Ideator that uses a large language model (LLM) and adds prompts, fine tuning, and a specialized user interface in order to help users reformulate their problem statements and generate possible solutions. This provides scaffolding to guide users through a set of creative problem-solving techniques, including some techniques specifically intended to help generate innovative ideas about designing groups of people and/or computers (“superminds”). In an experimental study, we found that people using Supermind Ideator generated significantly more innovative ideas than those generated by people using ChatGPT or people working alone. Thus our results suggest that the benefits of using LLMs for creative problem-solving can be substantially enhanced by scaffolding designed specifically for this purpose.},
booktitle = {Proceedings of the ACM Collective Intelligence Conference},
pages = {18–28},
numpages = {11},
keywords = {Collective Intelligence, Creativity, Generative AI, Innovation, Large Language Models, Scaffolding},
location = {Boston, MA, USA},
series = {CI '24}
}

@inproceedings{10.1145/3626772.3661377,
author = {Liu, Aiwei and Sheng, Qiang and Hu, Xuming},
title = {Preventing and Detecting Misinformation Generated by Large Language Models},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3661377},
doi = {10.1145/3626772.3661377},
abstract = {As large language models (LLMs) become increasingly capable and widely deployed, the risk of them generating misinformation poses a critical challenge. Misinformation from LLMs can take various forms, from factual errors due to hallucination to intentionally deceptive content, and can have severe consequences in high-stakes domains.This tutorial covers comprehensive strategies to prevent and detect misinformation generated by LLMs. We first introduce the types of misinformation LLMs can produce and their root causes. We then explore two broad categories: Preventing misinformation generation: a) AI alignment training techniques to reduce LLMs' propensity for misinformation and refuse malicious instructions during model training. b) Training-free mitigation methods like prompt guardrails, retrieval-augmented generation (RAG), and decoding strategies to curb misinformation at inference time. Detecting misinformation after generation, including a) using LLMs themselves to detect misinformation through embedded knowledge or retrieval-enhanced judgments, and b) distinguishing LLM-generated text from human-written text through black-box approaches (e.g., classifiers, probability analysis) and white-box approaches (e.g., watermarking). We also discuss the challenges and limitations of detecting LLM-generated misinformation.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3001–3004},
numpages = {4},
keywords = {hallucination, large language models, misinformation},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3672608.3707751,
author = {Pasquadibisceglie, Vincenzo and Recchia, Vito and Appice, Annalisa and Malerba, Donato and Fiameni, Giuseppe},
title = {GANDALF: A LLM-based approach to map bark beetle outbreaks in semantic stories of Sentinel-2 images},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707751},
doi = {10.1145/3672608.3707751},
abstract = {Huge spruce forest areas have been damaged by massive bark beetle outbreaks across Europe during the past few years. Hence, forest health management requires large-scale inventory of bark beetle outbreaks to plan actions for promptly mitigating forest tree dieback. Deep learning techniques have recently achieved amazing results in imagery semantic segmentation tasks by dominating the recent research for mapping bark beetle outbreaks in Sentinel-2 images of forest areas. In addition, due to the impressive performance of Large Language Models (LLMs) in natural language understanding and generation tasks, LLMs have started attracting attention in multiple fields. In this paper, we describe GANDALF: an approach that leverages the potential of LLMs for mapping bark beetle outbreaks in Sentinel-2 images of forest areas. Specifically, we take advantage of the rich context of textual data to transform Sentinel-2 images in smart data ready for boosting accurate semantic segmentation modeling. We use a foundation LLM model to account for the text encoding of the spectral-spatial imagery context information. We fine-tune the LLM model to perform the semantic segmentation of forest images and use the Integrated Gradients (IG) algorithm to explain how each spectral-spatial information has an effect on the bark beetle outbreak detection. We assess the effectiveness of the proposed approach in a case study regarding bark beetle outbreaks in Sentinel-2 images of forest scenes in Czech Republic.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {1074–1081},
numpages = {8},
keywords = {large language models, fine-tuning, semantic segmentation, eXplainable AI, sentinel-2 images, bark beetle outbreak inventory},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3701716.3718373,
author = {Li, Zhipeng and Wu, Binglin and Zhang, Yingyi and Li, Xianneng and Li, Kai and Chen, Weizhi},
title = {CuSMer: Multimodal Intent Recognition in Customer Service via Data Augment and LLM Merge},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3718373},
doi = {10.1145/3701716.3718373},
abstract = {The increasing complexity of e-commerce customer service (CS) scenarios, driven by rapid product evolution and user base growth, presents unique challenges for intent recognition. Unlike generic user-generated content (UGC), CS-UGC exhibits multimodal complexity (e.g., product inquiries, return requests) that traditional methods struggle to address due to (1) Limited CS domain-specific knowledge, which hampers the ability of large language models (LLMs) to handle multimodal CS data, and (2) The complexity and noise in CS UGC, which undermines the robustness of traditional approaches. In this paper, we propose Customer Service Augmented LLM Merge (CuSMer), a novel framework integrating semi-supervised learning with model merging techniques through dual pipelines: (i) pseudo-labeling → fine-tuning → LLM merging and (ii) image augmentation → fine-tuning → LLM merging. These piplines enhance the robustness of LLMs against noisy, out-of-distribution data while improving their multimodal understanding of CS scenarios. Evaluated on Alibaba's real-world datasets, CuSMer demonstrates superior robustness in noisy environments and enhanced multimodal understanding compared to baseline LLMs. It achieved third place in the first round and first place in the final round in the WWW25 - Competition: Multimodal Dialogue System Intent Recognition Challenge, validating its scalability and effectiveness for industrial CS applications.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {3058–3062},
numpages = {5},
keywords = {e-commerence, model merge, vision language model},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3688671.3690604,
author = {Argyrou, Georgia and Dimitriou, Angeliki and Lymperaiou, Maria and Filandrianos, Giorgos and Stamou, Giorgos},
title = {Prompt2Fashion: An automatically generated fashion dataset},
year = {2024},
isbn = {9798400709821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3688671.3690604},
doi = {10.1145/3688671.3690604},
abstract = {Despite the rapid evolution and increasing efficacy of language and vision generative models, there remains a lack of comprehensive datasets that bridge the gap between personalized fashion needs and AI-driven design, limiting the potential for truly inclusive and customized fashion solutions. In this work, we leverage generative models to automatically construct a fashion image dataset tailored to various occasions, styles, and body types as instructed by users. We use different Large Language Models (LLMs) and prompting strategies to offer personalized outfits of high aesthetic quality, detail, and relevance to both expert and non-expert users’ requirements, as demonstrated by qualitative analysis. Up until now the evaluation of the generated outfits has been conducted by non-expert human subjects. Despite the provided fine-grained insights on the quality and relevance of generation, we extend the discussion on the importance of expert knowledge for the evaluation of artistic AI-generated datasets such as this one. Our dataset is publicly available on GitHub at https://github.com/georgiarg/Prompt2Fashion.},
booktitle = {Proceedings of the 13th Hellenic Conference on Artificial Intelligence},
articleno = {61},
numpages = {6},
keywords = {image dataset, fashion synthesis, human evaluation},
location = {
},
series = {SETN '24}
}

@inproceedings{10.1145/3627508.3638325,
author = {Wang, Ben},
title = {A Proactive System for Supporting Users in Interactions with Large Language Models},
year = {2024},
isbn = {9798400704345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627508.3638325},
doi = {10.1145/3627508.3638325},
abstract = {With the advancements of Large Language Models (LLMs) and the prevalent application of ChatGPT, there is a significant interest in maximizing productivity and user experience through proactive systems. Current proactive conversational systems mostly concentrate on user preference in the recommendation scenarios, but overlook critical user perceptions, which impact their experience and task completion. Addressing this gap, the study proposes a novel framework integrating user perceptions into LLM interactions to support user tasks and improve learning outcomes. This framework include two approaches: a user interface design dedicated to streamlining LLM interactions by mitigating complexities in the interaction with the main LLM systems like ChatGPT, and an adaptation of reinforcement learning from human feedback (RLHF) to incorporate user perceptions, enhancing personalization and effectiveness of LLM learning paths. The project’s significance extends beyond user engagement, promising broader societal impacts.},
booktitle = {Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
pages = {441–444},
numpages = {4},
keywords = {Human-Computer Interaction, Large Language Models, Proactive system, Reinforcement Learning},
location = {Sheffield, United Kingdom},
series = {CHIIR '24}
}

@inproceedings{10.1145/3691620.3695346,
author = {Sarschar, Mahja and Zhang, Gefei and Nowak, Annika},
title = {PACGBI: A Pipeline for Automated Code Generation from Backlog Items},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695346},
doi = {10.1145/3691620.3695346},
abstract = {While there exist several tools to leverage Large Language Models (LLMs) for code generation, their capabilities are limited to the source code editor and are disconnected from the overall software development process. These tools typically generate standalone code snippets that still require manual integration into the codebase. There is still a lack of integrated solutions that seamlessly automate the entire development cycle, from backlog items to code generation and merge requests. We present the Pipeline for Automated Code Generation from Backlog Items (PACGBI), an LLM-assisted pipeline integrated into GitLab CI. PACGBI reads backlog items in the code repository, automatically generates the corresponding code, and creates merge requests for the generated changes. Our case study demonstrates the potential of PACGBI in automating agile software development processes, allowing parallelization of development and reduction of development costs. PACGBI can be utilized by software developers and enables nontechnical stakeholders and designers by providing a holistic solution for using LLMs in software development. A screencast of this tool is available at https://youtu.be/TI53m-fIoyc, its source code at https://github.com/Masa-99/pacgbi.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2338–2341},
numpages = {4},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3657604.3664671,
author = {Wang, Yuchen and Guo, Shangxin and Ling, Lin and Tan, Chee Wei},
title = {Nemobot: Crafting Strategic Gaming LLM Agents for K-12 AI Education},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664671},
doi = {10.1145/3657604.3664671},
abstract = {Artificial intelligence (AI) permeates modern society and is poised for further integration across various domains. However, there exists a notable deficiency in equipping K-12 students with foundational AI understanding. This paper introduces a novel learning framework that leverages large language models (LLMs) and strategic gaming to teach K-12 students about the inner workings of AI. The framework consists of a chatbot programming and testing IDE that enables K-12 students to construct AI from scratch, engage in strategic gameplay to generate instant training data, and improve the AI heuristics with a data-driven learning mechanism. With a tiered curriculum catering to diverse proficiency levels and fostering synchronous collaboration, this framework efficiently adapts learning experiences to suit various groups of students, thereby facilitating learning at scale. Preliminary experiments validate the feasibility and vast potential of this approach, promising to revolutionize AI education in K-12 education.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {393–397},
numpages = {5},
keywords = {ai-assisted programming, chatbot programming, collaborative learning, gamification approach, generative ai, k-12 education, large language models(llms)},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.1145/3736407,
author = {Weyssow, Martin and Kamanda, Aton and Zhou, Xin and Sahraoui, Houari},
title = {CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3736407},
doi = {10.1145/3736407},
abstract = {Evaluating the alignment of large language models (LLMs) with user-defined coding preferences is a challenging endeavor that requires a deep assessment of LLMs’ outputs. Existing methods and benchmarks rely primarily on automated metrics and static analysis tools, which often fail to capture the nuances of user instructions and LLM outputs. To address this gap, we introduce the LLM-as-a-Judge evaluation framework and present CodeUltraFeedback, a comprehensive dataset for assessing and improving LLM alignment with coding preferences. CodeUltraFeedback consists of 10,000 coding instructions, each annotated with four responses generated from a diverse pool of 14 LLMs. These responses are annotated using GPT-3.5 as a judge, with both ranking-based scores and detailed textual feedback across five distinct coding preferences. Our analysis reveals that responses from GPT-3.5 and GPT-4 are consistently rated higher than those from open-weight models, underscoring substantial alignment gaps between closed- and open-weight LLMs. In turn, we explore the usage of CodeUltraFeedback as feedback data to fine-tune and align CodeLlama-7B-Instruct using supervised fine-tuning (SFT) and reinforcement learning from AI feedback (RLAIF) with direct preference optimization (DPO). The resulting aligned model achieves an average alignment improvement of 22.7% and 29.7% when evaluated with GPT-3.5 and GPT-4 judges, respectively. Notably, our aligned CodeLlama-7B-Instruct surpasses much larger models, such as CodeLlama-13B and 34B, in alignment with coding preferences. Despite not being explicitly trained for functional correctness, it also achieves a 10.5% and 26.6% relative improvement in Pass@ (1)  and Pass@ (10)  on the HumanEval+ benchmark. Our contributions demonstrate the practical value of preference tuning in code generation and set the stage for further progress in model alignment and RLAIF for automated software engineering.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Large language models, code generation, automated software engineering, reinforcement learning from AI feedback, direct preference optimization, LLM-as-a-Judge}
}

@inproceedings{10.1145/3589335.3651463,
author = {Le, Tan Khang and Alimadadi, Saba and Ko, Steven Y.},
title = {A Study of Vulnerability Repair in JavaScript Programs with Large Language Models},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651463},
doi = {10.1145/3589335.3651463},
abstract = {In recent years, JavaScript has become the most widely used programming language, especially in web development. However, writing secure JavaScript code is not trivial, and programmers often make mistakes that lead to security vulnerabilities in web applications. Large Language Models (LLMs) have demonstrated substantial advancements across multiple domains, and their evolving capabilities indicate their potential for automatic code generation based on a required specification, including automatic bug fixing. In this study, we explore the accuracy of LLMs, namely ChatGPT and Bard, in finding and fixing security vulnerabilities in JavaScript programs. We also investigate the impact of context in a prompt on directing LLMs to produce a correct patch of vulnerable JavaScript code. Our experiments on real-world software vulnerabilities show that while LLMs are promising in automatic program repair of JavaScript code, achieving a correct bug fix often requires an appropriate amount of context in the prompt.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {666–669},
numpages = {4},
keywords = {automatic program repair, cwe, javascript, large language models, prompt engineering},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3689050.3704429,
author = {Han, Kuntong and Tang, Keyang and Wang, Meng},
title = {Stage Wizard: Enhancing Tangible Storytelling with Multimodal LLMs},
year = {2025},
isbn = {9798400711978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689050.3704429},
doi = {10.1145/3689050.3704429},
abstract = {This paper introduces a pipeline that integrates multimodal large language models (LLMs) for tangible storytelling, featuring flexible materials generation, intuitive hands-on performance, and easy finalization. The design system enables teachers, parents, and children to create stage elements through natural language interactions and generate paper-cut style images. These elements can be easily fabricated using standard printing paper and assembled into a reconfigurable cardstock stage, allowing children to craft various plotlines through manipulation. The storytelling process can be directly recorded as a short film or transformed into an elaborate storybook using styled image filters and refining LLMs. By introducing the role of the stage in both the design and manipulation processes, this pipeline offers intuitive guidance and affordance for free but organized creation. The flexibility introduced by LLMs supports educators in diverse course design and children in self-expression. Without the requirement for specific hardware, the system also has the potential to be applied more broadly in less developed areas.},
booktitle = {Proceedings of the Nineteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {37},
numpages = {13},
keywords = {Author Keywords},
location = {
},
series = {TEI '25}
}

@inproceedings{10.1145/3696410.3714825,
author = {Shi, Zhengliang and Gao, Shen and Yan, Lingyong and Feng, Yue and Chen, Xiuyi and Chen, Zhumin and Yin, Dawei and Verberne, Suzan and Ren, Zhaochun},
title = {Tool Learning in the Wild: Empowering Language Models as Automatic Tool Agents},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714825},
doi = {10.1145/3696410.3714825},
abstract = {Augmenting large language models (LLMs) with external tools has emerged as a promising approach to extend their utility, enabling them to solve practical tasks. Previous methods manually parse tool documentation and create in-context demonstrations, transforming tools into structured formats for LLMs to use in their step-by-step reasoning. However, this manual process requires domain expertise and struggles to scale to large toolsets. Additionally, these methods rely heavily on ad-hoc inference techniques or special tokens to integrate free-form LLM generation with tool-calling actions, limiting the LLM's flexibility in handling diverse tool specifications and integrating multiple tools.In this work, we propose AutoTools, a framework that enables LLMs to automate the tool-use workflow. Specifically, the LLM automatically transforms tool documentation into callable functions, verifying syntax and runtime correctness. Then, the LLM integrates these functions into executable programs to solve practical tasks, flexibly grounding tool-use actions into its reasoning processes. Extensive experiments on existing and newly collected, more challenging benchmarks illustrate the superiority of our framework. Inspired by these promising results, we further investigate how to improve the expertise of LLMs, especially open-source LLMs with fewer parameters, within AutoTools. Thus, we propose the AutoTools-Learning approach, training the LLMs with three learning tasks on 34k instances of high-quality synthetic data, including documentation understanding, relevance learning, and function programming. Fine-grained results validate the effectiveness of our overall training approach and each individual task. Our methods are an important step towards the use of LLMs for solving real-world tasks with external tools.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {2222–2237},
numpages = {16},
keywords = {instruction tuning, large language models, tool learning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3613904.3642462,
author = {Masson, Damien and Malacria, Sylvain and Casiez, G\'{e}ry and Vogel, Daniel},
title = {DirectGPT: A Direct Manipulation Interface to Interact with Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642462},
doi = {10.1145/3613904.3642462},
abstract = {We characterize and demonstrate how the principles of direct manipulation can improve interaction with large language models. This includes: continuous representation of generated objects of interest; reuse of prompt syntax in a toolbar of commands; manipulable outputs to compose or control the effect of prompts; and undo mechanisms. This idea is exemplified in DirectGPT, a user interface layer on top of ChatGPT that works by transforming direct manipulation actions to engineered prompts. A study shows participants were 50% faster and relied on 50% fewer and 72% shorter prompts to edit text, code, and vector images compared to baseline ChatGPT. Our work contributes a validated approach to integrate LLMs into traditional software using direct manipulation. Data, code, and demo available at https://osf.io/3wt6s.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {975},
numpages = {16},
keywords = {direct manipulation, large language models, prompt engineering},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3626772.3657660,
author = {Sudhi, Viju and Bhat, Sinchana Ramakanth and Rudat, Max and Teucher, Roman},
title = {RAG-Ex: A Generic Framework for Explaining Retrieval Augmented Generation},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657660},
doi = {10.1145/3626772.3657660},
abstract = {Owing to their size and complexity, large language models (LLMs) hardly explain why they generate a response. This effectively reduces the trust and confidence of end users in LLM-based applications, including Retrieval Augmented Generation (RAG) for Question Answering (QA) tasks. In this work, we introduce RAG-Ex, a model- and language-agnostic explanation framework that presents approximate explanations to the users revealing why the LLMs possibly generated a piece of text as a response, given the user input. Our framework is compatible with both open-source and proprietary LLMs. We report the significance scores of the approximated explanations from our generic explainer in both English and German QA tasks and also study their correlation with the downstream performance of LLMs. In the extensive user studies, our explainer yields an F1-score of 76.9% against the end user annotations and attains almost on-par performance with model-intrinsic approaches.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2776–2780},
numpages = {5},
keywords = {explainability, large language models, retrieval augmented generation},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3628454.3629551,
author = {Nimpattanavong, Chollakorn and Taveekitworachai, Pittawat and Khan, Ibrahim and Nguyen, Thai Van and Thawonmas, Ruck and Choensawat, Worawat and Sookhanaphibarn, Kingkarn},
title = {Am I Fighting Well? Fighting Game Commentary Generation With ChatGPT},
year = {2023},
isbn = {9798400708497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628454.3629551},
doi = {10.1145/3628454.3629551},
abstract = {This paper presents a new approach for leveraging ChatGPT in fighting game commentary generation task. Commentary generation often relies on deep learning techniques, which typically demand extensive data to achieve effectiveness. Large language models (LLMs) have become essential due to their remarkable ability to process data efficiently, thanks to their extensive training on vast datasets. Our proposed approach integrates the use of LLMs, specifically the GPT-3.5 model, for generating commentaries through the utilization of various prompts with data from the open-source fighting game, DareFightingICE. Four prompt variants are employed to assess the effectiveness of each prompt components. Objective evaluation using natural language metrics reveals that different prompt components significantly affect the generated commentaries. Additionally, subjective evaluation through a questionnaire reveals that prompts without parameter definitions received the highest preference from human evaluators. These results suggest that LLMs exhibit versatility in generating fighting game commentaries and hold promise for broader applications.},
booktitle = {Proceedings of the 13th International Conference on Advances in Information Technology},
articleno = {14},
numpages = {7},
keywords = {ChatGPT, Commentary Generation, DareFightingICE, Fighting Game, Prompt Engineering},
location = {Bangkok, Thailand},
series = {IAIT '23}
}

@inproceedings{10.1145/3706598.3714085,
author = {Zhang, Jingyue and Arawjo, Ian},
title = {ChainBuddy: An AI-assisted Agent System for Generating LLM Pipelines},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714085},
doi = {10.1145/3706598.3714085},
abstract = {As large language models (LLMs) advance, their potential applications have grown significantly. However, it remains difficult to evaluate LLM behavior on user-defined tasks and craft effective pipelines to do so. Many users struggle with where to start, often referred to as the "blank page problem." ChainBuddy, an AI workflow generation assistant built into the ChainForge platform, aims to tackle this issue. From a single prompt or chat, ChainBuddy generates a starter evaluative LLM pipeline in ChainForge aligned to the user’s requirements. ChainBuddy offers a straightforward and user-friendly way to plan and evaluate LLM behavior and make the process less daunting and more accessible across a wide range of possible tasks and use cases. We report a within-subjects user study comparing ChainBuddy to the baseline interface. We find that when using AI assistance, participants with a variety of technical expertise reported a less demanding workload, felt more confident, and produced higher quality pipelines evaluating LLM behavior. However, we also uncover a mismatch between subjective and objective ratings of performance: participants rated their successfulness similarly across conditions, while independent experts rated participant workflows significantly higher with AI assistance. Drawing connections to the Dunning–Kruger effect, we discuss implications for the future design of workflow generation assistants regarding the risk of over-reliance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {241},
numpages = {21},
keywords = {language models, AI agents, prompt engineering, automation, LLM pipelines, visual programming environments},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3613905.3650900,
author = {Yazici, Aybars and Mejia-Domenzain, Paola and Frej, Jibril and K\"{a}ser, Tanja},
title = {GELEX: Generative AI-Hybrid System for Example-Based Learning},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650900},
doi = {10.1145/3613905.3650900},
abstract = {Traditional example-based learning methods are often limited by static, expert-created content. Hence, they face challenges in scalability, engagement, and effectiveness, as some learners might struggle to relate to the examples or find them relevant. To address these challenges, we introduce GELEX (GEnerative-AI Learning through EXamples), a hybrid Artificial Intelligence (AI) system enhancing example-based learning by using large language models (LLMs). Our hybrid system incorporates mechanisms to control and evaluate the AI output, acknowledging and addressing the potential factual inaccuracies of LLMs. We instantiate our system in the cooking domain. Our approach utilizes association rule mining on a large database of recipes to identify key patterns. When learners submit a recipe for feedback, a LLM enriches it by integrating these patterns. Then, learners are prompted to actively process the example by highlighting the changes and critically assessing the modifications. This strategy transforms traditional example-based learning into a dynamic, scalable, interactive educational tool.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {171},
numpages = {10},
keywords = {Example-based Learning, Generative AI, Procedural Writing},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3708359.3712093,
author = {Peng, Yingzhe and Qin, Xiaoting and Zhang, Zhiyang and Zhang, Jue and Lin, Qingwei and Yang, Xu and Zhang, Dongmei and Rajmohan, Saravan and Zhang, Qi},
title = {Navigating the Unknown: A Chat-Based Collaborative Interface for Personalized Exploratory Tasks},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712093},
doi = {10.1145/3708359.3712093},
abstract = {The rise of large language models (LLMs) has revolutionized user interactions with knowledge-based systems, enabling chatbots to synthesize vast amounts of information and assist with complex, exploratory tasks. However, LLM-based chatbots often struggle to provide personalized support, particularly when users start with vague queries or lack sufficient contextual information. This paper introduces the Collaborative Assistant for Personalized Exploration (CARE), a system designed to enhance personalization in exploratory tasks by combining a multi-agent LLM framework with a structured user interface. CARE’s interface consists of a Chat Panel, Solution Panel, and Needs Panel, enabling iterative query refinement and dynamic solution generation. The multi-agent framework collaborates to identify both explicit and implicit user needs, delivering tailored, actionable solutions. In a within-subject user study with 22 participants, CARE was consistently preferred over a baseline LLM chatbot, with users praising its ability to reduce cognitive load, inspire creativity, and provide more tailored solutions. Our findings highlight CARE’s potential to transform LLM-based systems from passive information retrievers to proactive partners in personalized problem-solving and exploration. The code will be made available at https://aka.ms/chatbot-care.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {1048–1063},
numpages = {16},
keywords = {Personalization, Exploration Task, Human-AI Collaboration},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3670865.3673547,
author = {Fish, Sara and G\"{o}lz, Paul and Parkes, David C. and Procaccia, Ariel D. and Rusak, Gili and Shapira, Itai and W\"{u}thrich, Manuel},
title = {Generative Social Choice},
year = {2024},
isbn = {9798400707049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670865.3673547},
doi = {10.1145/3670865.3673547},
abstract = {The mathematical study of voting, social choice theory, has traditionally only been applicable to choices among a few predetermined alternatives, but not to open-ended decisions such as collectively selecting a textual statement. We introduce generative social choice, a design methodology for open-ended democratic processes that combines the rigor of social choice theory with the capability of large language models to generate text and extrapolate preferences. Our framework divides the design of AI-augmented democratic processes into two components: first, proving that the process satisfies representation guarantees when given access to oracle queries; second, empirically validating that these queries can be approximately implemented using a large language model. We apply this framework to the problem of summarizing free-form opinions into a proportionally representative slate of opinion statements; specifically, we develop a democratic process with representation guarantees and use this process to represent the opinions of participants in a survey about chatbot personalization. In a trial with 100 representative US residents, we find that 93 out of 100 participants feel "mostly" or "perfectly" represented by the slate of five statements we extracted. By providing rigorous guarantees through social choice, our work alleviates concerns about AI-driven democratic innovation and helps unlock its potential.The full version of this paper is available at https://arxiv.org/pdf/2309.01291.},
booktitle = {Proceedings of the 25th ACM Conference on Economics and Computation},
pages = {985},
numpages = {1},
keywords = {computational social choice, large language models, proportional representation, democratic participation, AI governance},
location = {New Haven, CT, USA},
series = {EC '24}
}

@inproceedings{10.1145/3706598.3714294,
author = {Tsai, Hsin-Ruey and Chiu, Shih-Kang and Wang, Bryan},
title = {GazeNoter: Co-Piloted AR Note-Taking via Gaze Selection of LLM Suggestions to Match Users' Intentions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714294},
doi = {10.1145/3706598.3714294},
abstract = {Note-taking is critical during speeches and discussions, serving not only for later summarization and organization but also for real-time question and opinion reminding in question-and-answer sessions or timely contributions in discussions. Manually typing on smartphones for note-taking could be distracting and increase cognitive load for users. While large language models (LLMs) are used to automatically generate summaries and highlights, the content generated by artificial intelligence (AI) may not match users’ intentions without user input or interaction. Therefore, we propose an AI-copiloted augmented reality (AR) system, GazeNoter, to allow users to swiftly select diverse LLM-generated suggestions via gaze on an AR headset for real-time note-taking. GazeNoter leverages an AR headset as a medium for users to swiftly adjust the LLM output to match their intentions, forming a user-in-the-loop AI system for both within-context and beyond-context notes. We conducted two user studies to verify the usability of GazeNoter in attending speeches in a static sitting condition and walking meetings and discussions in a mobile walking condition, respectively.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {32},
numpages = {22},
keywords = {note-taking, augmented reality, large language models, artificial intelligence, gaze input, wearable devices},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3658271.3658342,
author = {Albuquerque, Beatriz Ventorini Lins de and Cunha, Antonio Fernando Souza da and Souza, Leonardo and Siqueira, Sean Wolfgand Matsui and Santos, Rodrigo Pereira dos},
title = {Generating and Reviewing Programming Codes with Large Language Models: A Systematic Mapping Study},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658271.3658342},
doi = {10.1145/3658271.3658342},
abstract = {Context: The proliferation of technologies based on Large Language Models (LLM) is reshaping various domains, also impacting on programming code creation and review. Problem: The decision-making process in adopting LLM in software development demands an understanding of associated challenges and diverse application possibilities. Solution: This study addresses the identified challenges linked to LLM utilization in programming code processes. It explores models, utilization strategies, challenges, and coping mechanisms, focusing on the perspectives of researchers in software development. IS Theory: Drawing on Task-Technology Fit (TTF) theory, the research examines the alignment between task characteristics in code generation and review, and LLM technology attributes to discern performance impacts and utilization patterns. Method: Employing the Systematic Mapping of the Literature method, the research analyzes 19 selected studies from digital databases—IEEE Digital Library, Compendex Engineering Village, and Scopus—out of 1,257 retrieved results. Summary of Results: The research reveals 23 models, 13 utilization strategies, 15 challenges, and 14 coping mechanisms associated with LLM in programming code processes, offering a comprehensive understanding of the application landscape. Contributions to IS: Contributing to the Information Systems (IS) field, This study provides valuable insights into the utilization of LLM in programming code generation and review. The identified models, strategies, challenges, and coping mechanisms offer practical guidance for decision-making processes related to LLM technology adoption. The research aims to support the IS community in effectively navigating the complexities of integrating large language models into the dynamic software development lifecycle.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {70},
numpages = {10},
keywords = {Code Generation, LLM, automatic refactoring, code auto-suggestion, code completion, natural language models, neural network, systematic mapping study, transformer architecture},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

@inproceedings{10.1145/3637528.3671463,
author = {Abdali, Sara and Anarfi, Richard and Barberan, CJ and He, Jia},
title = {Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671463},
doi = {10.1145/3637528.3671463},
abstract = {Large Language Models (LLMs) have revolutionized the field of Natural Language Generation (NLG) by demonstrating an impressive ability to generate human-like text. However, their widespread usage introduces challenges that necessitate thoughtful examination, ethical scrutiny, and responsible practices. In this study, we delve into these challenges, explore existing strategies for mitigating them, with a particular emphasis on identifying AI-generated text as the ultimate solution. Additionally, we assess the feasibility of detection from a theoretical perspective and propose novel research directions to address the current limitations in this domain.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6428–6436},
numpages = {9},
keywords = {ai-generated text detection, data poisoning, llm, paraphrasing attacks, responsible ai, watermarking},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3701716.3715583,
author = {Yang, Mingdai and Liu, Zhiwei and Yang, Liangwei and Liu, Xiaolong and Wang, Chen and Peng, Hao and Yu, Philip S.},
title = {Training Large Recommendation Models via Graph-Language Tokens Alignment},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715583},
doi = {10.1145/3701716.3715583},
abstract = {Recommender systems (RS) have become essential tools for helping users efficiently navigate the overwhelming amount of information on e-commerce and social platforms. However, traditional RS relying on Collaborative Filtering (CF) struggles to integrate the rich semantic information from textual data. Meanwhile, large language models (LLMs) have shown promising results in natural language processing, but directly using LLMs for recommendation introduces challenges, such as ambiguity in generating item predictions and inefficiencies in scalability. In this paper, we propose a novel framework to train Large Recommendation models via Graph-Language Token Alignment. By aligning item and user nodes from the interaction graph with pretrained LLM tokens, GLTA effectively leverages the reasoning abilities of LLMs. Furthermore, we introduce Graph-Language Logits Matching (GLLM) to optimize token alignment for end-to-end item prediction, eliminating ambiguity in the free-form text as recommendation results. Extensive experiments on three benchmark datasets demonstrate the effectiveness of GLTA, with ablation studies validating each component.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1470–1474},
numpages = {5},
keywords = {large language models, recommender system},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3682069,
author = {Ampel, Benjamin and Yang, Chi-Heng and Hu, James and Chen, Hsinchun},
title = {Large Language Models for Conducting Advanced Text Analytics Information Systems Research},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3682069},
doi = {10.1145/3682069},
abstract = {The exponential growth of digital content has generated massive textual datasets, necessitating the use of advanced analytical approaches. Large Language Models (LLMs) have emerged as tools that are capable of processing and extracting insights from massive unstructured textual datasets. However, how to leverage LLMs for text analytics Information Systems (IS) research is currently unclear. To assist the IS community in understanding how to operationalize LLMs, we propose a Text Analytics for Information Systems Research (TAISR) framework. Our proposed framework provides detailed recommendations grounded in IS and LLM literature on how to conduct meaningful text analytics IS research for design science, behavioral, and econometric streams. We conducted three business intelligence case studies using our TAISR framework to demonstrate its application in several IS research contexts. We also outline the potential challenges and limitations of adopting LLMs for IS. By offering a systematic approach and evidence of its utility, our TAISR framework contributes to future IS research streams looking to incorporate powerful LLMs for text analytics.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {2},
numpages = {27},
keywords = {Large language models, information systems research, text analytics}
}

@inproceedings{10.1145/3690624.3709187,
author = {Zhang, Yutong and Chen, Lixing and Li, Shenghong and Cao, Nan and Shi, Yang and Ding, Jiaxin and Qu, Zhe and Zhou, Pan and Bai, Yang},
title = {Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709187},
doi = {10.1145/3690624.3709187},
abstract = {Large language models (LLMs) have demonstrated exceptional performance across a wide variety of domains. Nonetheless, generalist LLMs continue to fall short in reasoning tasks necessitating specialized knowledge, e.g., emotional sociology and medicine. Prior investigations into specialized LLMs focused on domain-specific training, which entails substantial efforts in domain data acquisition and model parameter fine-tuning. To address these challenges, this paper proposes the Way-to-Specialist (WTS) framework, which synergizes retrieval-augmented generation with knowledge graphs (KGs) to enhance the specialized capability of LLMs in the absence of specialized training. In distinction to existing paradigms that merely utilize external knowledge from general KGs or static domain KGs to prompt LLM for enhanced domain-specific reasoning, WTS proposes an innovative ''LLM↻KG'' paradigm, which achieves bidirectional enhancement between specialized LLM and domain knowledge graph (DKG). The proposed paradigm encompasses two closely coupled components: the DKG-Augmented LLM and the LLM-Assisted DKG Evolution. The former retrieves question-relevant domain knowledge from DKG and uses it to prompt LLM to enhance the reasoning capability for domain-specific tasks; the latter leverages LLM to generate new domain knowledge from processed tasks and use it to evolve DKG. WTS closes the loop between DKG-Augmented LLM and LLM-Assisted DKG Evolution, enabling continuous improvement in the domain specialization as it progressively answers and learns from domain-specific questions. We validate the performance of WTS on 7 datasets (e.g., TweetQA, ChatDoctor5k) spanning 6 domains, e.g., emotional sociology, medical, ect. The experimental results show that WTS surpasses the previous SOTA in 5 specialized domains, and achieves a maximum performance improvement of 11.3%.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {1996–2007},
numpages = {12},
keywords = {domain knowledge graph, retrieval-augmented generation, social network., specialized large language models},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3706599.3721274,
author = {Chiu, Shih-Kang and Wang, Bryan and Chen, TzuLing and Tsai, Hsin-Ruey},
title = {Demonstration of GazeNoter: Enhancing AR Note-Taking Through Gaze-Based Selection of LLM Suggestions},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3721274},
doi = {10.1145/3706599.3721274},
abstract = {Note-taking is critical during speeches and discussions, serving not only for later summarization and organization but also for real-time question and opinion reminding in question-and-answer sessions or timely contributions in discussions. Manually typing on smartphones for note-taking could be distracting and increase cognitive load for users. While large language models (LLMs) are used to automatically generate summaries and highlights, the content generated by artificial intelligence (AI) may not match users’ intentions without user input or interaction. Therefore, we propose an AI-copiloted augmented reality (AR) system, GazeNoter, to allow users to swiftly select diverse LLM-generated suggestions via gaze on an AR headset for real-time note-taking. GazeNoter leverages an AR headset as a medium for users to swiftly adjust the LLM output to match their intentions, forming a user-in-the-loop AI system for both within-context and beyond-context notes. We conducted two user studies to verify the usability of GazeNoter in attending speeches in a static sitting condition and walking meetings and discussions in a mobile walking condition, respectively.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {722},
numpages = {5},
keywords = {note-taking, AR, LLM, AI, gaze input, wearable devices},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3649165.3690123,
author = {Ramesh, Aninditha and Agarwal, Arav and Doughty, Jacob Arthur and Ramaneti, Ketan and Savelka, Jaromir and Sakr, Majd},
title = {A Benchmark for Testing the Capabilities of LLMs in Assessing the Quality of Multiple-choice Questions in Introductory Programming Education},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690123},
doi = {10.1145/3649165.3690123},
abstract = {There has been a growing interest in utilizing large language models (LLMs) for numerous educational applications. Recent studies have focused on the use of LLMs for generating various educational artifacts for programming education, such as programming exercises, model solutions, or multiple-choice questions (MCQs). The ability to efficiently and reliably assess the quality of such artifacts, both automatically and human generated, has become of paramount importance. Hence, there is a pressing need to develop and make available robust benchmarks. In this paper, we investigate an example use case of assessing the quality of programming MCQs. To that end, we carefully curated a data set of 192 MCQs annotated with quality scores based on a rubric that evaluates crucial aspects such as, e.g., their clarity, the presence of a single correct answer, and the quality of distractors. The results show that the task presents a considerable challenge even to the state-of-the-art LLMs and, hence, further research is needed. To further such research efforts in this important area we release the dataset as well as the extensible evaluation pipeline to the public.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {193–199},
numpages = {7},
keywords = {assessments, automated evaluation, claude, computing education, gpt-4, large language models, llama, llms, mcqs, multiple choice questions},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3701551.3703573,
author = {He, Zhankui and Xie, Zhouhang and Steck, Harald and Liang, Dawen and Jha, Rahul and Kallus, Nathan and McAuley, Julian},
title = {Reindex-Then-Adapt: Improving Large Language Models for Conversational Recommendation},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703573},
doi = {10.1145/3701551.3703573},
abstract = {Large Language Models (LLMs) are revolutionizing conversational recommender systems (CRS) by effectively indexing item content, understanding complex conversational contexts, and generating relevant item titles. However, the autoregressive nature of LLMs, which outputs item titles as a long sequence of subtokens, hinders the ability to efficiently obtain and control recommendations across the entire item set. This challenge in calculating probabilities over all items limits LLMs' potential, such as (1) limiting control over recommendation popularities and (2) preventing the synergy of marrying LLMs and traditional recommender systems (RecSys).To address this challenge, we propose the Reindex-Then-Adapt (RTA) framework. It consists of two steps: (1) Reindex: a lightweight network learns to condense multi-token item titles into single tokens within the LLM and distills LLM-generated recommendations as ranked lists. This bypasses the autoregressive nature of LLMs while trying to preserve their CRS abilities; (2) Adapt: LLMs after reindexing enable efficient adjustment of probability distributions over single-token titles, further enhanced through RecSys integration. RTA bridges the strengths of LLMs and RecSys, enabling understanding of complex queries as LLMs do, while efficiently controlling recommended item distributions as in traditional RecSys. We show the effectiveness of our RTA over base LLMs across three CRS datasets with negligible additional parameters.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {866–875},
numpages = {10},
keywords = {conversational recommendation, large language model},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3664476.3670943,
author = {Zhao, Hanning and Silverajan, Bilhanan},
title = {Evaluating Cyber Security Dashboards for Smart Cities and Buildings: Enhancing User Modeling with LLMs},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3670943},
doi = {10.1145/3664476.3670943},
abstract = {Designing effective cybersecurity visualization has become a crucial component of cyber defense strategies in many domains and industrial environments. Human behaviour, modeling and input are major aspects of designing visualization systems. Yet, the task of evaluating these developed visualization systems is both time-consuming and challenging, and it is often prone to cases where user evaluation is limited owing to a lack of different stakeholders and end users during the design process. Recognizing the potential of advanced Generative Artificial Intelligence and Large Language Models (LLMs), our study aims to explore their capabilities in evaluating web-based security visualization tools and dashboards, particularly in the context of smart cities and buildings. We study and compare the feasibility of using various LLMs available today, for conducting usability testing, serving as an additional resource given the limited availability of human participants. In particular, we focus on three different LLMs: Bing Chat, ChatGPT-4 and ChatGPT-4o. While each had its strengths and drawbacks, our findings revealed that the results obtained had a strong correlation with human test subjects. LLMs can be a valuable aid during evaluation, by offering in-depth insights and evaluations, tailored to the specific requirements of smart buildings, cities and automation cybersecurity. Moreover, our research and findings also reveal that LLMs can similarly be used for the evaluation of a wide range of other visual systems for industrial environments.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {47},
numpages = {10},
keywords = {LLM, Security Visualization, Smart City, Usability Testing},
location = {Vienna, Austria},
series = {ARES '24}
}

@inproceedings{10.1145/3643795.3648375,
author = {Grandel, Skyler and Schmidt, Douglas C. and Leach, Kevin},
title = {Applying Large Language Models to Enhance the Assessment of Parallel Functional Programming Assignments},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648375},
doi = {10.1145/3643795.3648375},
abstract = {Courses in computer science (CS) often assess student programming assignments manually, with the intent of providing in-depth feedback to each student regarding correctness, style, efficiency, and other quality attributes. As class sizes increase, however, it is hard to provide detailed feedback consistently, especially when multiple assessors are required to handle a larger number of assignment submissions. Large language models (LLMs), such as ChatGPT, offer a promising alternative to help automate this process in a consistent, scalable, and minimally-biased manner.This paper explores ChatGPT-4's scalablility and accuracy in assessing programming assignments based on predefined rubrics in the context of a case study we conducted in an upper-level undergraduate and graduate CS course at Vanderbilt University. In this case study, we employed a method that compared assessments generated by ChatGPT-4 against human graders to measure the accuracy, precision, and recall associated with identifying programming mistakes. Our results show that when ChatGPT-4 is used properly (e.g., with appropriate prompt engineering and feature selection) it can improve objectivity and grading efficiency, thereby acting as a complementary tool to human graders for advanced computer science graduate and undergraduate students.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {102–110},
numpages = {9},
keywords = {ChatGPT, education, generative AI, large language models, prompt engineering, automated grading},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3701716.3717809,
author = {Pellegrino, Maria Angela and Tuozzo, Gabriele},
title = {From Quality Reports to Knowledge Graphs: a Case Study on CSV-to-KG Transformation},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717809},
doi = {10.1145/3701716.3717809},
abstract = {The construction of Knowledge Graphs (KGs) often demands substantial manual effort and domain expertise, especially when converting structured data formats like CSV files into KGs. Recent advancements in Large Language Models (LLMs) offer promising avenues to simplify this process through prompt engineering.This study investigates various prompting strategies-zero-shot, one-shot, prompt chaining, and a hybrid approach-to enable LLMs to automate the creation of KGs from CSV files. Using a dataset containing quality metrics for 2,026 KGs generated by KGHeartBeat, the paper assesses the performance of GPT-4o, GPT-o1 mini, Claude 3.5 Sonnet, and Gemini 1.5 pro, across different prompt configurations. The findings reveal that the hybrid approach consistently produces the most accurate and complete KGs, effectively addressing challenges related to scalability and complexity.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1626–1632},
numpages = {7},
keywords = {comparison, csv converter, data quality, empirical investigation, knowledge graph, llms, prompt engineering, quality assessment},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.5555/3721488.3721521,
author = {Tao, Yiran and Yang, Jehan and Ding, Dan and Erickson, Zackory},
title = {LAMS: LLM-Driven Automatic Mode Switching for Assistive Teleoperation},
year = {2025},
publisher = {IEEE Press},
abstract = {Teleoperating high degrees-of-freedom (DoF) robotic manipulators via low-DoF controllers like joysticks often requires frequent switching between control modes, where each mode maps controller movements to specific robot actions. Manually performing this frequent switching can make teleoperation cumbersome and inefficient. On the other hand, existing automatic mode-switching solutions, such as heuristic-based or learning-based methods, are often task-specific and lack generalizability. In this paper, we introduce LLM-Driven Automatic Mode Switching (LAMS), a novel approach that leverages Large Language Models (LLMs) to automatically switch control modes based on task context. Unlike existing methods, LAMS requires no prior task demonstrations and incrementally improves by integrating user-generated mode-switching examples. We validate LAMS through an ablation study and a user study with 10 participants on complex, long-horizon tasks, demonstrating that LAMS effectively reduces manual mode switches, is preferred over alternative methods, and improves performance over time. The project website with supplementary materials is at https://lams-assistance.github.io/.},
booktitle = {Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {242–251},
numpages = {10},
keywords = {assistive robotics, human-robot interaction, large language models (llms), mode switching, robotic manipulation, teleoperation, user interfaces},
location = {Melbourne, Australia},
series = {HRI '25}
}

@inproceedings{10.1145/3696410.3714877,
author = {Wang, Zixiang and Zhu, Yinghao and Zhao, Huiya and Zheng, Xiaochen and Sui, Dehao and Wang, Tianlong and Tang, Wen and Wang, Yasha and Harrison, Ewen and Pan, Chengwei and Gao, Junyi and Ma, Liantao},
title = {ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714877},
doi = {10.1145/3696410.3714877},
abstract = {We introduce ColaCare, a framework that enhances Electronic Health Record (EHR) modeling through multi-agent collaboration driven by Large Language Models (LLMs). Our approach seamlessly integrates domain-specific expert models with LLMs to bridge the gap between structured EHR data and text-based reasoning. Inspired by the Multidisciplinary Team (MDT) approach used in clinical settings, ColaCare employs two types of agents: DoctorAgents and a MetaAgent, which collaboratively analyze patient data. Expert models process and generate predictions from numerical EHR data, while LLM agents produce reasoning references and decision-making reports within the MDT-driven collaborative consultation framework. The MetaAgent orchestrates the discussion, facilitating consultations and evidence-based debates among DoctorAgents, simulating diverse expertise in clinical decision-making. We additionally incorporate the Merck Manual of Diagnosis and Therapy (MSD) medical guideline within a retrieval-augmented generation (RAG) module for medical evidence support, addressing the challenge of knowledge currency. Extensive experiments conducted on three EHR datasets demonstrate ColaCare's superior performance in clinical mortality outcome and readmission prediction tasks, underscoring its potential to revolutionize clinical decision support systems and advance personalized precision medicine. All code, case studies and a questionnaire are available at the project website: https://colacare.netlify.app.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {2250–2261},
numpages = {12},
keywords = {electronic health record, large language model, multi-agent},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3636243.3636245,
author = {Macneil, Stephen and Denny, Paul and Tran, Andrew and Leinonen, Juho and Bernstein, Seth and Hellas, Arto and Sarsa, Sami and Kim, Joanne},
title = {Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636245},
doi = {10.1145/3636243.3636245},
abstract = {Identifying and resolving logic errors can be one of the most frustrating challenges for novices programmers. Unlike syntax errors, for which a compiler or interpreter can issue a message, logic errors can be subtle. In certain conditions, buggy code may even exhibit correct behavior – in other cases, the issue might be about how a problem statement has been interpreted. Such errors can be hard to spot when reading the code, and they can also at times be missed by automated tests. There is great educational potential in automatically detecting logic errors, especially when paired with suitable feedback for novices. Large language models (LLMs) have recently demonstrated surprising performance for a range of computing tasks, including generating and explaining code. These capabilities are closely linked to code syntax, which aligns with the next token prediction behavior of LLMs. On the other hand, logic errors relate to the runtime performance of code and thus may not be as well suited to analysis by LLMs. To explore this, we investigate the performance of two popular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly explanation of logic errors. We compare LLM performance with a large cohort of introductory computing students (n = 964) solving the same error detection task. Through a mixed-methods analysis of student and model responses, we observe significant improvement in logic error identification between the previous and current generation of LLMs, and find that both LLM generations significantly outperform students. We outline how such models could be integrated into computing education tools, and discuss their potential for supporting students when learning programming.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {11–18},
numpages = {8},
keywords = {bug detection, computing education, generative AI, large language models, programming errors},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3673791.3698423,
author = {Breuer, Timo},
title = {Data Fusion of Synthetic Query Variants With Generative Large Language Models},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673791.3698423},
doi = {10.1145/3673791.3698423},
abstract = {Considering query variance in information retrieval (IR) experiments is beneficial for retrieval effectiveness. Especially ranking ensembles based on different topically related queries retrieve better results than rankings based on a single query alone. Recently, generative instruction-tuned Large Language Models (LLMs) improved on a variety of different tasks in capturing human language. To this end, this work explores the feasibility of using synthetic query variants generated by instruction-tuned LLMs in data fusion experiments. More specifically, we introduce a lightweight, unsupervised, and cost-efficient approach that exploits principled prompting and data fusion techniques. In our experiments, LLMs produce more effective queries when provided with additional context information on the topic. Furthermore, our analysis based on four TREC newswire benchmarks shows that data fusion based on synthetic query variants is significantly better than baselines with single queries and also outperforms pseudo-relevance feedback methods. We publicly share the code and query datasets with the community as resources for follow-up studies.},
booktitle = {Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {274–279},
numpages = {6},
keywords = {data fusion, large language models, query variants},
location = {Tokyo, Japan},
series = {SIGIR-AP 2024}
}

@inproceedings{10.1145/3687123.3698286,
author = {Gramacki, Piotr and Martins, Bruno and Szyma\'{n}ski, Piotr},
title = {Evaluation of Code LLMs on Geospatial Code Generation},
year = {2024},
isbn = {9798400711763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687123.3698286},
doi = {10.1145/3687123.3698286},
abstract = {Software development support tools have been studied for a long time, with recent approaches using Large Language Models (LLMs) for code generation. These models can generate Python code for data science and machine learning applications. LLMs are helpful for software engineers because they increase productivity in daily work. An LLM can also serve as a "mentor" for inexperienced software developers, and be a viable learning support. High-quality code generation with LLMs can also be beneficial in geospatial data science. However, this domain poses different challenges, and code generation LLMs are typically not evaluated on geospatial tasks. Here, we show how we constructed an evaluation benchmark for code generation models, based on a selection of geospatial tasks. We categorised geospatial tasks based on their complexity and required tools. Then, we created a dataset with tasks that test model capabilities in spatial reasoning, spatial data processing, and geospatial tools usage. The dataset consists of specific coding problems that were manually created for high quality. For every problem, we proposed a set of test scenarios that make it possible to automatically check the generated code for correctness. In addition, we tested a selection of existing code generation LLMs for code generation in the geospatial domain. We share our dataset and reproducible evaluation code on a public GitHub repository1, arguing that this can serve as an evaluation benchmark for new LLMs in the future. Our dataset will hopefully contribute to the development new models capable of solving geospatial coding tasks with high accuracy. These models will enable the creation of coding assistants tailored for geospatial applications.},
booktitle = {Proceedings of the 7th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {54–62},
numpages = {9},
keywords = {code generation, geospatial data science, large language models},
location = {Atlanta, GA, USA},
series = {GeoAI '24}
}

@inproceedings{10.1145/3701625.3701675,
author = {Falc\~{a}o, Fabiano Damasceno Sousa and Canedo, Edna Dias},
title = {Investigating Software Development Teams Members' Perceptions of Data Privacy in the Use of Large Language Models (LLMs)},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701675},
doi = {10.1145/3701625.3701675},
abstract = {Context: Large Language Models (LLMs) have revolutionized natural language generation and understanding. However, they raise significant data privacy concerns, especially when sensitive data is processed and stored by third parties. Goal: This paper investigates the perception of software development teams members regarding data privacy when using LLMs in their professional activities. Additionally, we examine the challenges faced and the practices adopted by these practitioners. Method: We conducted a survey with 78 ICT practitioners from five regions of the country. Results: Software development teams members have basic knowledge about data privacy and LGPD, but most have never received formal training on LLMs and possess only basic knowledge about them. Their main concerns include the leakage of sensitive data and the misuse of personal data. To mitigate risks, they avoid using sensitive data and implement anonymization techniques. The primary challenges practitioners face are ensuring transparency in the use of LLMs and minimizing data collection. Software development teams members consider current legislation inadequate for protecting data privacy in the context of LLM use. Conclusions: The results reveal a need to improve knowledge and practices related to data privacy in the context of LLM use. According to software development teams members, organizations need to invest in training, develop new tools, and adopt more robust policies to protect user data privacy. They advocate for a multifaceted approach that combines education, technology, and regulation to ensure the safe and responsible use of LLMs.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {373–382},
numpages = {10},
keywords = {Large language models (LLM), Conversational agents, Chatbots, Data Privacy, Privacy risks},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3657604.3664694,
author = {Calo, Tommaso and Maclellan, Christopher},
title = {Towards Educator-Driven Tutor Authoring: Generative AI Approaches for Creating Intelligent Tutor Interfaces},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664694},
doi = {10.1145/3657604.3664694},
abstract = {Intelligent Tutoring Systems (ITSs) have shown great potential in delivering personalized and adaptive education, but their widespread adoption has been hindered by the need for specialized programming and design skills. Existing approaches overcome the programming limitations with no-code authoring through drag and drop, however they assume that educators possess the necessary skills to design effective and engaging tutor interfaces. To address this assumption we introduce generative AI capabilities to assist educators in creating tutor interfaces that meet their needs while adhering to design principles. Our approach leverages Large Language Models (LLMs) and prompt engineering to generate tutor layout and contents based on high-level requirements provided by educators as inputs. However, to allow them to actively participate in the design process, rather than relying entirely on AI-generated solutions, we allow generation both at the entire interface level and at the individual component level. The former provides educators with a complete interface that can be refined using direct manipulation, while the latter offers the ability to create specific elements to be added to the tutor interface. A small-scale comparison shows the potential of our approach to enhance the efficiency of tutor interface design. Moving forward, we raise critical questions for assisting educators with generative AI capabilities to create personalized, effective, and engaging tutors, ultimately enhancing their adoption.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {305–309},
numpages = {5},
keywords = {human-centered computing, intelligent tutoring systems, intelligent-user-interfaces, ui/ux},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3641555.3705245,
author = {Roy, Nimisha and Olufisayo, Omojokun and Tu, Huaijin},
title = {Scaling Academic Decision-Making with NLP: Automating Transfer Credit Evaluations},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705245},
doi = {10.1145/3641555.3705245},
abstract = {Manual processes for evaluating external course syllabi for transfer credit in higher education are time-consuming, inconsistent, and prone to bias. This project leverages Natural Language Processing (NLP) and large language models (LLMs) to automate the transfer credit evaluation process. The system processes external syllabi by embedding course content, conducting similarity searches, and providing structured reasoning for each match. Using techniques such as chain-of-thought reasoning and reflection agents, the system generates similarity scores and detailed explanations to support informed, data-driven decision-making by faculty. Validated against faculty decisions, the system promises to significantly improve the efficiency, consistency, and fairness of transfer credit evaluations. Future directions include expanding the system for advanced standing test evaluations and allowing faculty to query specific course components for more targeted analysis.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1603–1604},
numpages = {2},
keywords = {academic decision support., automated decision-making cosine similarity, chain-of-thought reasoning, course syllabi analysis, large language models (llms), natural language processing (nlp), transfer credit evaluation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3670474.3685964,
author = {Nakkab, Andre and Zhang, Sai Qian and Karri, Ramesh and Garg, Siddharth},
title = {Rome was Not Built in a Single Step: Hierarchical Prompting for LLM-based Chip Design},
year = {2024},
isbn = {9798400706998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670474.3685964},
doi = {10.1145/3670474.3685964},
abstract = {Large Language Models (LLMs) are effective in computer hardware synthesis via hardware description language (HDL) generation. However, LLM-assisted approaches for HDL generation struggle when handling complex tasks. We introduce a suite of hierarchical prompting techniques which facilitate efficient stepwise design methods, and develop a generalizable automation pipeline for the process. To evaluate these techniques, we present a benchmark set of hardware designs which have solutions with or without architectural hierarchy. Using these benchmarks, we compare various open-source and proprietary LLMs, including our own fine-tuned Code Llama-Verilog model. Our hierarchical methods automatically produce successful designs for complex hardware modules that standard flat prompting methods cannot achieve, allowing smaller open-source LLMs to compete with large proprietary models. Hierarchical prompting reduces HDL generation time and yields savings on LLM costs. Our experiments detail which LLMs are capable of which applications, and how to apply hierarchical methods in various modes. We explore case studies of generating complex cores using automatic scripted hierarchical prompts, including the first-ever LLM-designed processor with no human feedback.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD},
articleno = {26},
numpages = {11},
keywords = {Automation, Hardware design, Hierarchy, LLM},
location = {Salt Lake City, UT, USA},
series = {MLCAD '24}
}

@inproceedings{10.1145/3676536.3699507,
author = {Liao, Yuchao and Adegbija, Tosiron and Lysecky, Roman},
title = {Are LLMs Any Good for High-Level Synthesis?},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3699507},
doi = {10.1145/3676536.3699507},
abstract = {The increasing complexity and demand for faster, energy-efficient hardware designs necessitate innovative High-Level Synthesis (HLS) methodologies. This paper explores the potential of Large Language Models (LLMs) to streamline or replace the HLS process, leveraging their ability to understand natural language specifications and refactor code. We survey the current research and conduct experiments comparing Verilog designs generated by a standard HLS tool (Vitis HLS) with those produced by LLMs translating C code or natural language specifications. Our evaluation focuses on quantifying the impact on performance, power, and resource utilization, providing an assessment of the efficiency of LLM-based approaches. This study aims to illuminate the role of LLMs in HLS, identifying promising directions for optimized hardware design in applications such as AI acceleration, embedded systems, and high-performance computing.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {29},
numpages = {8},
keywords = {high-level synthesis, hardware accelerator design, electronic design automation, large language models},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@article{10.1145/3734523,
author = {Reddy, E Bhawani Eswar and Bhattacharyya, Sutirtha and Sarmah, Ankur and Nongpoh, Fedrick and Maddala, Karthik and Karfa, Chandan},
title = {LHS: LLM Assisted Efficient High-level Synthesis of Deep Learning Tasks},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3734523},
doi = {10.1145/3734523},
abstract = {Deep learning tasks, especially those involving complex convolution neural networks (CNNs), are computationally intensive and pose significant challenges when implemented on hardware. Accelerating these tasks is critical for improving performance. High-level Synthesis (HLS) has the potential to automate the efficient hardware accelerator designs directly from high-level C/C++ specification of trained machine learning (ML) models. Traditional HLS tools cannot synthesize certain high-level constructs, which require manual intervention. Many source code optimizations and the selection of pragmas for HLS optimizations are crucial for generating efficient hardware accelerators with HLS. However, both of these tasks are mostly manual efforts. Recently, Large Language Models (LLMs) have shown remarkable capabilities in various generative tasks. In this work, we explore the application of LLMs to remove these manual efforts in adapting HLS for ML accelerator designs. Our framework called LLM-assisted HLS, i.e., LHS, uses LLMs to automate the resolution of synthesis issues, ensuring compatibility with HLS tools. Furthermore, our framework automates the source code modification and optimization selection through pragma insertion steps, which are crucial for optimizing the synthesized design. Our experimental results with LHS demonstrate a significant improvement in latency for deep learning tasks with underlying complex CNN models without much area overhead. Our LHS allows us to achieve up to 2690 \texttimes{} latency improvement. Promisingly, LHS performs better than the state-of-the-art ML accelerator design tool hls4ml in 4 out of 6 cases in the context of latency improvement at the expense of area overhead (i.e., performance to hardware gain). This work highlights the potential of LLMs to assist and accelerate the HLS process, thereby creating more efficient hardware implementation for deep learning models.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = may,
keywords = {LLM, High-level synthesis, CNN}
}

@inproceedings{10.1145/3691620.3695318,
author = {Lops, Andrea and Narducci, Fedelucio and Ragone, Azzurra and Trizio, Michelantonio},
title = {AgoneTest: Automated creation and assessment of Unit tests leveraging Large Language Models},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695318},
doi = {10.1145/3691620.3695318},
abstract = {Software correctness is crucial, with unit testing playing an indispensable role in the software development lifecycle. However, creating unit tests is time-consuming and costly, underlining the need for automation. Leveraging Large Language Models (LLMs) for unit test generation is a promising solution, but existing studies focus on simple, small-scale scenarios, leaving a gap in understanding LLMs' performance in real-world applications, particularly regarding integration and assessment efficacy at scale. Here, we present AgoneTest, a system focused on automatically generating and evaluating complex class-level test suites. Our contributions include a scalable automated system, a newly developed dataset for rigorous evaluation, and a detailed methodology for test quality assessment.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2440–2441},
numpages = {2},
keywords = {software testing, large language model, automatic assessment},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3644815.3644969,
author = {Bur\'{e}gio, Vanilson and Pereira, Iverson and Cabral, Henrique},
title = {Innovating Translation: Lessons Learned from BWX Generative Language Engine},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644969},
doi = {10.1145/3644815.3644969},
abstract = {The integration of Translation Management Systems (TMS) and Large Language Models (LLMs) has revolutionized the translation landscape, offering nuanced and culturally sensitive translations. This paper explores the lessons learned from developing the BWX Generative Language Engine, an award-winning Generative AI tool for translation, which exemplifies the application of generative AI in translation management. Lessons include the transformative impact of AI, the accelerated delivery of beta features with LLMs, and the strategic integration of enabling technologies. Additionally, insights are drawn from strategic testing for optimal model routing, caching mechanisms, fallbacks, and the importance of security and data policy awareness.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {98–99},
numpages = {2},
keywords = {generative AI, translation management systems, large language models, software engineering},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3701716.3715520,
author = {Lee, Hsiu-Hung and Chen, Chung-Chi and Yen, An-Zi},
title = {RAG-Enhanced Evidence Recommendation in Financial Legal Resolutions},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715520},
doi = {10.1145/3701716.3715520},
abstract = {The complexity of legal documents, particularly in financial legal disputes, poses significant challenges for both experts and automated systems. This study introduces a system leveraging Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) technology to recommend key evidence in financial advisor dispute cases. Unlike traditional legal AI tasks focused on outcome prediction, our approach emphasizes supporting judicial reasoning by recommending key evidence relevant to adjudication. We constructed a dataset of 371 annotated cases from Taiwan, spanning 25 years, including claims, judicial opinions, and final judgments, with annotations highlighting key evidence. Using RAG, our system retrieves and generates evidence recommendations grounded in analogous past cases while maintaining temporal and contextual consistency. This methodology enhances judicial efficiency and supports equitable legal decision-making by streamlining the recommendation of critical evidence.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1096–1099},
numpages = {4},
keywords = {evidence recommendation, financial advisory, retrieval augmented generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3672539.3686351,
author = {Lu, Qiuyu and Fang, Jiawei and Yao, Zhihao and Yang, Yue and Lyu, Shiqing and Mi, Haipeng and Yao, Lining},
title = {Large Language Model Agents Enabled Generative Design of Fluidic Computation Interfaces},
year = {2024},
isbn = {9798400707186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672539.3686351},
doi = {10.1145/3672539.3686351},
abstract = {The creation of interactive devices is a major area of interest. However, traditional design tools in this field often require a significant learning curve and may not effectively support creative ideation. This study explores the use of fluidic computation interfaces as a case study to examine the potential of enhancing design tools for physical devices with Large Language Model (LLM) agents. With LLM agents, the Generative Design Tool (GDT) can understand the capabilities and limitations of new devices, suggest diverse, insightful, and practical application scenarios, and recommend designs that are technically and contextually appropriate. Additionally, it generates the necessary design parameters for the traditional components of the design tool to visualize results and create files for fabrication.},
booktitle = {Adjunct Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {76},
numpages = {3},
keywords = {Generative Design, Large Language Model, Novel Devices},
location = {Pittsburgh, PA, USA},
series = {UIST Adjunct '24}
}

@inproceedings{10.1145/3674399.3674447,
author = {Wu, BenLong and Chen, Kejiang and He, Yanru and Chen, Guoqiang and Zhang, Weiming and Yu, Nenghai},
title = {CodeWMBench: An Automated Benchmark for Code Watermarking Evaluation},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674399.3674447},
doi = {10.1145/3674399.3674447},
abstract = {As deep learning progresses, programming language generation models such as CodeLlama, GitHub Copilot, and ChatGPT have been widely applied to intelligent code development. However, this also reduces the cost of code plagiarism, posing challenges to copyright and academic integrity. In response to the specific needs for human-machine code detection, this paper introduces a comprehensive automated benchmark CodeWMBench for active detection of human-machine code through watermarking. With a meticulous evaluation of eight code watermarking methods, we demonstrated their performance in terms of harmlessness, robustness, and transparency. Specifically, for the first time, we introduced watermark removal techniques based on large language models and conducted the first assessment of these watermarking methods against code rewriting and retranslating attacks. In the discussion, we delved into the critical issues currently facing code watermarking, including why existing code watermarking methods struggle to resist removal by large language models and potential future methods that could withstand such removals.},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2024},
pages = {120–125},
numpages = {6},
keywords = {Programming language model, benchmark, code watermark},
location = {Changsha, China},
series = {ACM-TURC '24}
}

@inproceedings{10.1145/3672608.3707847,
author = {Seo, Hyein and Jeong, Yuna and Choi, Yong Suk},
title = {TAECE : T2I-Adapter with Enhanced Color Expression for Improving Conditional Text-to-Image Generation Capabilities},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707847},
doi = {10.1145/3672608.3707847},
abstract = {The text-to-image diffusion model has advanced, enabling the generation of complex images from text as well as sketches, key poses, and segmentation maps. However, these models face challenges in accurately representing detailed scenes or real-world elements. This study addresses these challenges by proposing a method to enhance image generation ability based on both text and sketch. Our approach introduces an adapter incorporating a deformable convolution network (DCN) to process sketch inputs, allowing structural information to be retained in generated images. Additionally, we integrate large language models (LLMs) to enrich textual descriptions with nuanced color expressions. By combining structural input and enriched text, our model produces images that are not only realistic but visually appealing. This method significantly enhances the model's capacity to capture intricate details. Experimental results demonstrate that our model outperforms existing conditional text-to-image models in visual quality. Overall, this study contributes to image generation technology by advancing color representation via LLMs, fostering the creation of more visually consistent and detailed images. The proposed approach presents broad applicability, offering a notable contribution to text-to-image synthesis and advancing image generation techniques for greater realism.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {1180–1187},
numpages = {8},
keywords = {image generation, text-to-image synthesis, computer vision},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3706599.3706685,
author = {Twitchell, Briggs and Katsirelos, George and Bezerianos, Anastasia and Boukhelifa, Nadia},
title = {Explaining Complex ML Models to Domain Experts Using LLM &amp; Visualization: An Exploration in the French Breadmaking Industry},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706685},
doi = {10.1145/3706599.3706685},
abstract = {Modeling a complex system from data can aid understanding and decision-making. Bayesian networks are one such method that, when accurately constructed, can support inference and help understand the underlying system that generated the data. However, the outputs of these models are not always intuitive, especially for users that lack a statistical background. In this work, we examine how the recent advancements in modern Large Language Models (LLMs) may be applied to help explain machine learning (ML) models. Following a user-centered design methodology, we collaborated with a team of ML modelers and a domain expert in the French breadmaking industry to develop a causal inference application with an integrated chat assistant. From qualitative feedback sessions with modelers and the domain expert, we note some unique advantages but also a host of challenges in using current LLMs for model explainability.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {675},
numpages = {7},
keywords = {visualization, working with domain experts, Bayesian networks, modeling, bread-making.},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3711022,
author = {Wang, Qile and Erqsous, Moath and Barner, Kenneth E. and Mauriello, Matthew Louis},
title = {LATA: A Pilot Study on LLM-Assisted Thematic Analysis of Online Social Network Data Generation Experiences},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711022},
doi = {10.1145/3711022},
abstract = {Large Language Models (LLMs) have gained attention in research and industry, aiming to streamline processes and enhance text analysis performance. Thematic Analysis (TA), a prevalent qualitative method for analyzing interview content, often requires at least two human experts to review and analyze data. This study demonstrates the feasibility of LLM-Assisted Thematic Analysis (LATA) using GPT-4 and Gemini. Specifically, we conducted semi-structured interviews with 14 researchers to gather insights on their experiences generating and analyzing Online Social Network (OSN) communications datasets. Following Braun and Clarke's six-phase TA framework with an inductive approach, we initially analyzed our interview transcripts with human experts. Subsequently, we iteratively designed prompts to guide LLMs through a similar process. We compare and discuss the manually analyzed outcomes with responses generated by LLMs and achieve a cosine similarity score up to 0.76, demonstrating a promising prospect for LATA. Additionally, the study delves into researchers' experiences navigating the complexities of collecting and analyzing OSN data, offering recommendations for future research and application designers.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW124},
numpages = {28},
keywords = {ChatGPT, Google Gemini, data collection, inductive coding, large language models (LLMs), online social networks, thematic analysis}
}

@inproceedings{10.1145/3643795.3648379,
author = {Rasnayaka, Sanka and Wang, Guanlin and Shariffdeen, Ridwan and Iyer, Ganesh Neelakanta},
title = {An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648379},
doi = {10.1145/3643795.3648379},
abstract = {Large Language Models (LLMs) represent a leap in artificial intelligence, excelling in tasks using human language(s). Although the main focus of general-purpose LLMs is not code generation, they have shown promising results in the domain. However, the usefulness of LLMs in an academic software engineering project has not been fully explored yet. In this study, we explore the usefulness of LLMs for 214 students working in teams consisting of up to six members. Notably, in the academic course through which this study is conducted, students were encouraged to integrate LLMs into their development tool-chain, in contrast to most other academic courses that explicitly prohibit the use of LLMs.In this paper, we analyze the AI-generated code, prompts used for code generation, and the human intervention levels to integrate the code into the code base. We also conduct a perception study to gain insights into the perceived usefulness, influencing factors, and future outlook of LLM from a computer science student's perspective. Our findings suggest that LLMs can play a crucial role in the early stages of software development, especially in generating foundational code structures, and helping with syntax and error debugging. These insights provide us with a framework on how to effectively utilize LLMs as a tool to enhance the productivity of software engineering students, and highlight the necessity of shifting the educational focus toward preparing students for successful human-AI collaboration.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {111–118},
numpages = {8},
keywords = {LLM for code generation, software engineering},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3649217.3653554,
author = {Liu, Suqing and Yu, Zezhu and Huang, Feiran and Bulbulia, Yousef and Bergen, Andreas and Liut, Michael},
title = {Can Small Language Models With Retrieval-Augmented Generation Replace Large Language Models When Learning Computer Science?},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653554},
doi = {10.1145/3649217.3653554},
abstract = {Leveraging Large Language Models (LLMs) for personalized learning and support is becoming a promising tool in computing education. AI Assistants can help students with programming, problem-solving, converse with them to clarify course content, explain error messages to help with debugging, and much more. However, using cloud-based LLMs poses risks around data security, privacy, but also control of the overarching system.To address these concerns, we created a locally-stored Small Language Model (SLM) that leverages different Retrieval-Augmented Generation (RAG) methods to support computing students' learning. We compare one SLM (neural-chat-7b-v3 - fine-tuned version of Mistral-7B-v0.1) against two popular LLMs (gpt-3.5-turbo and gpt-4-32k) to see the viability for computing educators to use in their course(s).We use conversations from a CS1 course (N = 1,260), providing students with an AI Assistant (using gpt-3.5-turbo) to help them learn content and support problem-solving while completing their Python programming assignment. In total, we had 269 students use the AI Assistant, with a total of 1,988 questions asked. Using this real conversational data, we re-ran student questions using our novel SLM (neural-chat-7b-v3 testing nine different RAG methods) and gpt-4-32k, then compared those results against the original gpt-3.5-turbo responses. Our findings indicate that using an SLM with RAG can perform similarly, if not better, than LLMs. This shows that it is possible for computing educators to use SLMs (with RAG) in their course(s) as a tool for scalable learning, supporting content understanding and problem-solving needs, while employing their own policies on data privacy and security.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {388–393},
numpages = {6},
keywords = {computing education, conversational agent, cs1, intelligence concentration, intelligent teaching assistant, intelligent tutoring system, large language models, locally deployable ai, personalized ai agent, retrieval augmented generation, small language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3701716.3715523,
author = {Dey, Prasenjit and Merugu, Srujana and Kaveri, Sivaramakrishnan},
title = {Uncertainty-Aware Fusion: An Ensemble Framework for Mitigating Hallucinations in Large Language Models},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715523},
doi = {10.1145/3701716.3715523},
abstract = {Large Language Models (LLMs) are known to hallucinate and generate non-factual outputs which can undermine user trust. Traditional methods to directly mitigate hallucinations, such as representation editing and contrastive decoding, often require additional training data and involve high implementation complexity. While ensemble-based approaches harness multiple LLMs to tap into the ''wisdom of crowds'', these methods overlook uncertainties in individual model responses. Recent studies reveal that uncertainty estimation can enable LLMs to self-assess the likelihood of generating hallucinations. In this work, we focus on factoid question answering (QA) and observe that LLMs accuracy and self-assessment capabilities vary widely with different models excelling in different scenarios. Leveraging this insight, we propose Uncertainty-Aware Fusion (UAF), an ensemble framework to reduces hallucinations by strategically combining multiple LLM based on their accuracy and self-assessment abilities. Empirical results on several public benchmark datasets show that UAF outperforms state-of-the-art hallucination mitigation methods by 8% in factual accuracy, while either narrowing or surpassing the performance gap with GPT-4.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {947–951},
numpages = {5},
keywords = {ensemble, hallucination detection, large language models, uncertainty},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3701716.3715254,
author = {Tong, Hanshuang and Li, Jun and Wu, Ning and Gong, Ming and Zhang, Dongmei and Zhang, Qi},
title = {Ploutos: Towards Explainable Stock Movement Prediction with Financial Large Language Model},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715254},
doi = {10.1145/3701716.3715254},
abstract = {Recent advancements in large language models (LLMs) have opened new pathways for many domains. However, the full potential of LLMs in financial investments remains largely untapped. There are two main challenges for typical deep learning-based methods for quantitative finance. First, they struggle to fuse textual and numerical information flexibly for stock movement prediction. Second, traditional methods lack clarity and explainability, which impedes their application in scenarios where the justification for predictions is essential. To solve the above challenges, we propose Ploutos, a novel financial LLM framework that consists of PloutosGen and PloutosGPT. The PloutosGen contains multiple primary experts that can analyze different modal data, such as text and numbers, and provide quantitative strategies from different perspectives. Then PloutosGPT combines their insights and predictions and generates explainable rationales. To generate accurate and faithful rationales, the training strategy of PloutosGPT leverages a rearview-mirror prompting mechanism to guide GPT-4 to generate rationales and a dynamic token weighting mechanism to finetune LLM by detecting and emphasizing key tokens in rationales. Extensive experiments show our framework outperforms the state-of-the-art methods on both prediction accuracy and explainability.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {490–499},
numpages = {10},
keywords = {computational finance, large language model, quantitative investment, stock prediction},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3723366.3723380,
author = {Gao, Yue},
title = {Optimized Individual Modules in Retrieval Augmented Generation in Concrete Scenarios},
year = {2025},
isbn = {9798400718298},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723366.3723380},
doi = {10.1145/3723366.3723380},
abstract = {As the era of big data arrives, enterprises have accumulated an increasing amount of data. How to effectively utilize cutting-edge artificial intelligence technologies to digitize massive amounts of information has become a significant challenge. Due to the exorbitant costs of training large language models (LLMs) from scratch, along with limitations such as the context window length of these models, user data privacy concerns, and model hallucinations, Retrieval-Augmented Generation (RAG) is increasingly being adopted in reality applications. In recent years, the development of large language models has led to their widespread application across industries. However, the inconsistency between the training objectives of large models and the retrieval tasks often results in severe hallucinations, particularly in very professional and personal domains, and then leads to incorrect responses. To solve this problem, RAG has been widely implemented. This paper delves into several aspects, including query augmentation, encoding combination, hybrid re-ranking, and filtering of final candidate documents, which presents a practical and effective RAG system. Extensive experiments were conducted on plant and resume datasets, with ablation studies performed for each module. Comparative analyses revealed significant improvements over existing methods, achieving an average enhancement of 4% or more in real-world applications, and a notable 6% improvement specifically in the resume dataset. The final experimental analysis substantiates the efficacy of this approach.},
booktitle = {Proceedings of the 2024 4th International Symposium on Big Data and Artificial Intelligence},
pages = {80–84},
numpages = {5},
keywords = {artificial intelligence, big data, encode combination, model hallucinations, query augment},
location = {
},
series = {ISBDAI '24}
}

@inproceedings{10.1145/3586182.3616663,
author = {Zou, Ruishi and Ye, Zi and Ye, Chen},
title = {iTutor: A Generative Tutorial System for Teaching the Elders to Use Smartphone Applications},
year = {2023},
isbn = {9798400700965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586182.3616663},
doi = {10.1145/3586182.3616663},
abstract = {We present iTutor, a generative tutorial system for promoting smartphone use proficiency among elders. iTutor is unique because it can dynamically generate tutorials based on current operation goals and UI context, which we achieved through leveraging prompt engineering to large language models (LLMs). Our evaluations showed potential for this approach, as we yielded 78.6% accuracy in the instruction generation process. We conclude by providing the roadmap for further development.},
booktitle = {Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {7},
numpages = {3},
keywords = {Accessibility, Prompt Engineering, Tutorial Interface},
location = {San Francisco, CA, USA},
series = {UIST '23 Adjunct}
}

@inproceedings{10.1145/3639474.3640058,
author = {Lehtinen, Teemu and Koutcheme, Charles and Hellas, Arto},
title = {Let's Ask AI About Their Programs: Exploring ChatGPT's Answers To Program Comprehension Questions},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640058},
doi = {10.1145/3639474.3640058},
abstract = {Recent research has explored the creation of questions from code submitted by students. These Questions about Learners' Code (QLCs) are created through program analysis, exploring execution paths, and then creating code comprehension questions from these paths and the broader code structure. Responding to the questions requires reading and tracing the code, which is known to support students' learning. At the same time, computing education researchers have witnessed the emergence of Large Language Models (LLMs) that have taken the community by storm. Researchers have demonstrated the applicability of these models especially in the introductory programming context, outlining their performance in solving introductory programming problems and their utility in creating new learning resources. In this work, we explore the capability of the state-of-the-art LLMs (GPT-3.5 and GPT-4) in answering QLCs that are generated from code that the LLMs have created. Our results show that although the state-of-the-art LLMs can create programs and trace program execution when prompted, they easily succumb to similar errors that have previously been recorded for novice programmers. These results demonstrate the fallibility of these models and perhaps dampen the expectations fueled by the recent LLM hype. At the same time, we also highlight future research possibilities such as using LLMs to mimic students as their behavior can indeed be similar for some specific tasks.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {221–232},
numpages = {12},
keywords = {QLCs, large language models, artificial intelligence, introductory programming, program comprehension},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3689187.3709607,
author = {Clear, Tony and Cajander, \r{A}sa and Clear, Alison and McDermott, Roger and Daniels, Mats and Divitini, Monica and Forshaw, Matthew and Humble, Niklas and Kasinidou, Maria and Kleanthous, Styliani and Kultur, Can and Parvini, Ghazaleh and Polash, Mohammad and Zhu, Tingting},
title = {AI Integration in the IT Professional Workplace: A Scoping Review and Interview Study with Implications for Education and Professional Competencies},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709607},
doi = {10.1145/3689187.3709607},
abstract = {As Artificial Intelligence (AI) continues transforming workplaces globally, particularly within the Information Technology (IT) industry, understanding its impact on IT professionals and computing curricula is crucial. This research builds on joint work from two countries, addressing concerns about AI's increasing influence in IT sector workplaces and its implications for tertiary education. The study focuses on AI technologies such as generative AI (GenAI) and large language models (LLMs). It examines how they are perceived and adopted and their effects on workplace dynamics, task allocation, and human-system interaction.IT professionals, noted as early adopters of AI, offer valuable insights into the interplay between AI and work engagement, highlighting the significant competencies required for digital workplaces. This study employs a dual-method approach, combining a systematic and multi-vocal literature review and qualitative research methods. These included a thematic analysis of a set of 47 interviews conducted between March and May of 2024 with IT professionals in two countries (New Zealand and Sweden). The research aimed to understand the implications for computing students, education curricula, and the assessment of emerging professional competencies.The literature review found insufficient evidence addressing comprehensive AI practice methodologies, highlighting the need to both develop and regulate professional competencies for effective AI integration. Key interview findings revealed diverse levels of GenAI adoption, ranging from individual experimentation to institutional integration. Participants generally expressed positive attitudes toward the technology and were actively pursuing self-learning despite some concerns. The themes emerging from the interviews included AI's role in augmenting human tasks, privacy and security concerns, productivity enhancements, legal and ethical challenges, and the evolving need for new competencies in the workplace.The study underscores the critical role of competency frameworks in guiding professional development and ensuring preparedness for an AI-driven environment. Additionally, it highlights the need for educational institutions to adapt curricula to address these emerging demands effectively},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {34–67},
numpages = {34},
keywords = {artificial intelligence, computing competencies, computing curricula, generative ai, it profession, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3681716.3689447,
author = {Vieira Sousa, Jos\'{e} Pedro and Campos, Pedro and Bala, Paulo},
title = {College Tales: Pilot Study on Large Language Models Generated Narratives for Mental Health Literacy},
year = {2024},
isbn = {9798400718236},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3681716.3689447},
doi = {10.1145/3681716.3689447},
abstract = {Mental health, while a crucial component of health, has often been neglected and stigmatised. University students, considering their unique situations and stressors, are more vulnerable to experiencing mental health challenges and being affected by stigma. The use of Large Language Models (LLMs) creates an opportunity to impart knowledge through digital interventions to address stigma, misinformation, and increase Mental Health Literacy in university students. Using a LLM generated prompt game, we conducted a pilot study with 5 mental health professionals. Through semi-structured interviews about the prototype and the narrative, we identified several narrative problems, such as missing information or overly simplified concepts. While the prototype has limitations, the participants considered it to have potential to be integrated as a tool for professionals.},
booktitle = {Proceedings of the 27th International Academic Mindtrek Conference},
pages = {270–275},
numpages = {6},
keywords = {Depressive Disorder, Game, Interactive Storytelling, Large Language Models, Mental Health},
location = {Tampere, Finland},
series = {Mindtrek '24}
}

@inproceedings{10.1145/3701716.3715164,
author = {Zhou, Xiangmin and Chen, Lei and He, Chengkun and Wu, Junfeng and Zhou, Weiyi and Shao, Jie and Zhang, Yanchun},
title = {A Responsible and Extendable Context-Aware Recommender System},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715164},
doi = {10.1145/3701716.3715164},
abstract = {Context-aware social media recommendation has been important in many applications such as e-commerce and entertainment. However, existing systems consider pre-specified contexts and cannot well handle user preferences, which negatively affects the recommendation quality and efficiency, and causes them not extendable to various applications. In this demo, we design RECARS, the first responsible and extendable context-aware recommender system. RECARS is designed with novel techniques, including efficient data organization over MongoDB and Apache Flink, and effective responsible recommendation generation that supports the system interactions with users. It allows users to perform iteratively refining and explaining the results by active learning and large language model (LLM). We demonstrate the usage of RECARS via YouTube.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2955–2958},
numpages = {4},
keywords = {context-aware, extendability, responsible recommendation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3568812.3603453,
author = {Tran, Minh},
title = {Prompt Engineering for Large Language Models to Support K-8 Computer Science Teachers in Creating Culturally Responsive Projects},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603453},
doi = {10.1145/3568812.3603453},
abstract = {The power of large language models has opened up opportunities for educational use. In computing education, recent studies have demonstrated the potential of these models to improve learning and teaching experiences in university-level programming courses. However, research into leveraging them to aid computer science instructors in curriculum development and course material design is relatively sparse, especially at the K-12 level. This work aims to fill this gap by exploring the capability of large language models in ideating and designing culturally responsive projects for elementary and middle school programming classes. Our ultimate goal is to support K-8 teachers in effectively extracting suggestions from large language models by only using natural language modifications. Furthermore, we aim to develop a comprehensive assessment framework for culturally responsive AI-generated project ideas. We also hope to provide valuable insight into teachers’ perspectives on large language models and their integration into teaching practices.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {110–112},
numpages = {3},
keywords = {culturally responsive pedagogy, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3671016.3674813,
author = {Xiao, Danni and Guo, Yimeng and Li, Yanhui and Chen, Lin},
title = {Optimizing Search-Based Unit Test Generation with Large Language Models: An Empirical Study},
year = {2024},
isbn = {9798400707056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671016.3674813},
doi = {10.1145/3671016.3674813},
abstract = {Search-based unit test generation methods have been considered effective and widely applied, and Large Language Models (LLMs) have also demonstrated their powerful generation ability. Therefore, some scholars have proposed using LLMs to enhance search-based unit test generation methods and have preliminarily confirmed that LLMs can help alleviate the problem of test coverage plateaus. However, it is still unclear when and how LLMs should intervene in the time-consuming test generation process. This paper explores the application of LLMs at various stages of search-based test generation (SBTG) (including the initial stage, the test generation period, and the test coverage plateaus), as well as strategies for controlling the frequency of LLM intervention. A comprehensive empirical study was conducted on 486 Python benchmark modules from 27 projects. The experimental results show that 1) LLM intervention has a positive effect at any stage, whether to improve coverage over a fixed period or to reduce the time to reach a specific coverage; 2) a reasonable intervention frequency is crucial for LLMs to have a positive effect on SBTG. This work can better help understand when and how LLMs should be applied in SBTG and provide valuable suggestions for developers in practice.},
booktitle = {Proceedings of the 15th Asia-Pacific Symposium on Internetware},
pages = {71–80},
numpages = {10},
keywords = {Large Language Model, Search-based Testing, Unit Test},
location = {Macau, China},
series = {Internetware '24}
}

@inproceedings{10.1145/3644815.3644981,
author = {Rahman, Md Tajmilur and Singh, Rahul and Sultan, Mir Yousuf},
title = {Automating Patch Set Generation from Code Reviews Using Large Language Models},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644981},
doi = {10.1145/3644815.3644981},
abstract = {The advent of Large Language Models (LLMs) has revolutionized various domains of artificial intelligence, including the realm of software engineering. In this research, we evaluate the efficacy of pre-trained LLMs in replicating the tasks traditionally performed by developers in response to code review comments. We provide code contexts to five popular LLMs and obtain the suggested code-changes (patch sets) derived from real-world code-review comments. The performance of each model is meticulously assessed by comparing their generated patch sets against the historical data of human-generated patch-sets from the same repositories. This comparative analysis aims to determine the accuracy, relevance, and depth of the LLMs' feedback, thereby evaluating their readiness to support developers in responding to code-review comments. Novelty: This particular research area is still immature requiring a substantial amount of studies yet to be done. No prior research has compared the performance of existing Large Language Models (LLMs) in code-review comments. This in-progress study assesses current LLMs in code review and paves the way for future advancements in automated code quality assurance, reducing context-switching overhead due to interruptions from code change requests.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {273–274},
numpages = {2},
keywords = {large language models, automated code review, software engineering, pull requests, code quality},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3706599.3707213,
author = {Muller, Michael and Chilton, Lydia B and Maher, Mary Lou and Martin, Charles Patrick and Choi, Minsik and Walsh, Greg and Kantosalo, Anna},
title = {GenAICHI 2025: Generative AI and HCI at CHI 2025},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3707213},
doi = {10.1145/3706599.3707213},
abstract = {This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI), and - among other approaches - particularly to Large Language Models (LLMs) and Foundation Models (FMs). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together.Following successful workshops in 2022–2024, we convene the interdisciplinary research domain of generative AI and HCI. Participation is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {782},
numpages = {9},
keywords = {HCI, HCAI, Generative AI, Design, Uncertainty, Large language models, Bias, Ethics.},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3649409.3691090,
author = {Folajimi, Yetunde},
title = {From GPT to BERT: Benchmarking Large Language Models for Automated Quiz Generation},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691090},
doi = {10.1145/3649409.3691090},
abstract = {This study evaluates the effectiveness of four leading large language models (LLMs), GPT-3, GPT-4, GPT-4o, and BERT, in generating quiz questions for Java and Python programming courses. We aim to recognize how LLMs can effectively produce educationally valuable questions that meet specific pedagogical criteria, including technical precision, relevance to course objectives, linguistic clarity, and pedagogical appropriateness. Each model was prompted to generate 200 Java and 200 Python quiz questions, totaling 1600 unique questions. These questions are currently being evaluated based on both quantitative and qualitative assessments by a team of computer science educators. Preliminary findings suggest that GPT-4 outperforms BERT in terms of technical precision. Further analysis is ongoing to assess the performance of the models in generating contextually appropriate and educationally useful questions, offering insights into their potential integration into computer science curricula. This work seeks to contribute to the broader discourse on the utility of LLMs in educational settings, specifically within the scope of automated content creation to enhance teaching and assessment methodologies in computer science education.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {312–313},
numpages = {2},
keywords = {automated assessment, computer science education, formative assessment, large language models, personalized quizzes, quiz questions generation},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3706599.3719743,
author = {Hojo, Nobukatsu and Shinoda, Kazutoshi and Yamazaki, Yoshihiro and Suzuki, Keita and Sugiyama, Hiroaki and Nishida, Kyosuke and Saito, Kuniko},
title = {GenerativeGUI: Dynamic GUI Generation Leveraging LLMs for Enhanced User Interaction on Chat Interfaces},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719743},
doi = {10.1145/3706599.3719743},
abstract = {Conversational AI (CAI) systems using large language models (LLMs) are becoming increasingly adept at performing a wide range of tasks with text-based interfaces. However, tasks that require detailed input can reduce usability and efficiency, as they often involve lengthy text exchanges. This paper introduces GenerativeGUI, a novel approach where LLMs dynamically generate graphical user interfaces (GUIs) tailored to the ongoing conversation. By generating HTML, which is rendered into an interactive GUI, GenerativeGUI presents intuitive widgets, enhancing user interaction and reducing cognitive load. A user study comparing GenerativeGUI with conventional text-based CAI systems demonstrated that the new system significantly improves usability, particularly in scenarios requiring multiple clarifying questions. Specifically, GenerativeGUI reduces mental demand, effort and task completion time, and enhances user satisfaction. This research highlights the potential of dynamic GUI generation to streamline complex CAI interactions, providing an effective solution to improve user experience in multi-turn conversations.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {306},
numpages = {9},
keywords = {Large Language Model, Natural Language Interface, Graphical User Interface, Clarifying Questions},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641555.3705064,
author = {Erez, Yael and Ayali, Lilach and Hazzan, Orit},
title = {Evolution of Students' Attitudes Towards the Use of Generative AI Tools in a CS1 Course: Implications for Instructors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705064},
doi = {10.1145/3641555.3705064},
abstract = {Recent advancements in large language model-based generative artificial intelligence (GenAI) tools have transformed computer science education, presenting both opportunities and challenges. A study investigating students' attitudes toward these tools was conducted during an Introduction to Computer Science course. The target of the study was to gauge students' evolving attitudes toward using GenAI tools in the course, before, during and after ChatGPT was gradually assimilated into homework assignments. The study refers to three phases: preliminary phase, assimilation phase, and calibration stage, which currently takes place. Findings show that, in the preliminary phase, students appreciated the efficiency of GenAI tools offered but were concerned about developing a dependency on these tools and about ''cheating''. Findings from the assimilation phase indicate that consistent, guided exposure to GenAI tools positively shifted students' views, alleviating initial concerns and promoting a positive attitude toward using GenAI tools in the course. The targets of the calibration phase are: a) to examine how to leverage independent learning by formulating clear guidelines that can build trust in the technology and help overcome concerns regarding reliability and credibility; b) to check how GenAI can help students in a Introduction to Computer Science course acquire skills such as critical thinking and code comprehension. The study offers insights for educators on the integration of GenAI tools into computer science courses to enhance learning while maintaining academic integrity.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1740},
numpages = {1},
keywords = {critical thinking, cs1, generative ai, introduction to computer science, mixed methods, program comprehension, skills, students' attitudes},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3677389.3702522,
author = {Zhang, Yining and Peng, Yinan and Tu, Chengying and Zhang, Zherui and Yan, Hongfei and Chen, Chong and Ma, Hao and Yang, Jia and Zhang, Yan and Liao, Rikun},
title = {Exploring Efficient Optimization Techniques in Online Retrieval-Augmented Generation Application},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702522},
doi = {10.1145/3677389.3702522},
abstract = {Recent advances in large language models (LLM) have brought an explosive growth to chat-bot applications. Among them, retrieval-augmented generation, which provides extra context to make LLM capable of answering out-of-domain questions is becoming a popular method. However, naive implementation of RAG usually cannot reach ideal answer quality in complicated real-world scenarios. Researchers have proposed a number of methods to improve RAG, but many of them involves extra LLM calls which is too time-consuming for online application. In this paper, we explored practical techniques and designs in RAG that improve answers to user-satisfying quality while keeping the response latency at a moderate level in the scenario of a research data QA application in university. Our main findings include introducing a relevance judge with small-scale LLM for retrieved documents can effectively filter out less relevant ones, which can otherwise disrupt the generated answer greatly, and decomposing the generation task into multiple independent sub-tasks can reduce the chance of hallucination and also accelerates the generation. As for model performance, prompt engineering and fine-tuning (through learning from strong LLM) are effective yet simple ways to enhance answer quality. Our results and experience provide insights for building future real-world LLM applications.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {51},
numpages = {11},
keywords = {retrieval-augmented generation, document relevance, research data, fine-tuning},
location = {Hong Kong, China},
series = {JCDL '24}
}

@inproceedings{10.1145/3696410.3714795,
author = {Tan, Tao and Qian, Yining and Lv, Ang and Lin, Hongzhan and Wu, Songhao and Wang, Yongbo and Wang, Feng and Wu, Jingtong and Lu, Xin and Yan, Rui},
title = {PEAR: Position-Embedding-Agnostic Attention Re-weighting Enhances Retrieval-Augmented Generation with Zero Inference Overhead},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714795},
doi = {10.1145/3696410.3714795},
abstract = {Large language models (LLMs) enhanced with retrieval-augmented generation (RAG) have introduced a new paradigm for web search. However, the limited context awareness of LLMs degrades their performance on RAG tasks. Existing methods to enhance context awareness are often inefficient, incurring time or memory overhead during inference, and many are tailored to specific position embeddings. In this paper, we propose Position-Embedding-Agnostic attention Re-weighting (PEAR), which enhances the context awareness of LLMs with zero inference overhead. Specifically, on a proxy task focused on context copying, we first detect heads which suppress the models' context awareness, thereby diminishing RAG performance. To weaken the impact of these heads, we re-weight their outputs with learnable coefficients. The LLM (with frozen parameters) is optimized by adjusting these coefficients to minimize loss on the proxy task. During inference, the optimized coefficients are fixed to re-weight these heads, regardless of the specific task at hand. Our proposed PEAR offers two major advantages over previous approaches: (1) It introduces zero additional inference overhead in terms of memory usage or inference time, while outperforming competitive baselines in accuracy and efficiency across various RAG tasks. (2) It is independent of position embedding algorithms, ensuring broader applicability. Our code is available at https://github.com/TTArch/PEAR-RAG.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {1693–1702},
numpages = {10},
keywords = {context awareness, large language model, re-weighting attention heads, retrieval-augmented generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3660788,
author = {Khojah, Ranim and Mohamad, Mazen and Leitner, Philipp and de Oliveira Neto, Francisco Gomes},
title = {Beyond Code Generation: An Observational Study of ChatGPT Usage in Software Engineering Practice},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660788},
doi = {10.1145/3660788},
abstract = {Large Language Models (LLMs) are frequently discussed in academia and the general public as support tools for virtually any use case that relies on the production of text, including software engineering. Currently, there is much debate, but little empirical evidence, regarding the practical usefulness of LLM-based tools such as ChatGPT for engineers in industry. We conduct an observational study of 24 professional software engineers who have been using ChatGPT over a period of one week in their jobs, and qualitatively analyse their dialogues with the chatbot as well as their overall experience (as captured by an exit survey). We find that rather than expecting ChatGPT to generate ready-to-use software artifacts (e.g., code), practitioners more often use ChatGPT to receive guidance on how to solve their tasks or learn about a topic in more abstract terms. We also propose a theoretical framework for how the (i) purpose of the interaction, (ii) internal factors (e.g., the user's personality), and (iii) external factors (e.g., company policy) together shape the experience (in terms of perceived usefulness and trust). We envision that our framework can be used by future research to further the academic discussion on LLM usage by software engineering practitioners, and to serve as a reference point for the design of future empirical LLM research in this domain.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {81},
numpages = {22},
keywords = {Chatbots, Large Language Models (LLMs), Software Development Bots}
}

@inproceedings{10.1145/3691621.3694932,
author = {Kamran, Parnian and Devanbu, Premkumar and Stanford, Caleb},
title = {Vision Paper: Proof-Carrying Code Completions},
year = {2024},
isbn = {9798400712494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691621.3694932},
doi = {10.1145/3691621.3694932},
abstract = {Code completions produced by today's large language models (LLMs) offer no formal guarantees. We propose proof-carrying code completions (PC3). In this paradigm, a high-resourced entity (the LLM provided by the server) must provide a code completion together with a proof of a chosen safety property which can be independently checked by a low-resourced entity (the user). In order to provide safety proofs without requiring the user to write specifications in formal logic, we statically generate preconditions for all dangerous function calls (i.e., functions that may violate the safety property) which must be proved by the LLM.To demonstrate the main ideas, we provide a prototype implementation in the program verification language Dafny, and a case study focusing on file system vulnerabilities. Unlike Python code generated by GPT-4, Dafny code generated by PC3 provably avoids a common weakness related to path traversal (CWE-35), using a single generation attempt (k = 1) and a modest number of tokens (3, 350). Our tool is available as an open source repository at https://github.com/DavisPL/PCCC.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering Workshops},
pages = {35–42},
numpages = {8},
keywords = {proof-carrying code, formal verification, large language models, program synthesis, dafny},
location = {Sacramento, CA, USA},
series = {ASEW '24}
}

@inproceedings{10.1145/3701716.3715872,
author = {Pan, Junwei and Zhang, Zhilin and Zhu, Han and Xu, Jian and Jiang, Jie and Zheng, Bo},
title = {Computational Advertising: Recent Advances},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715872},
doi = {10.1145/3701716.3715872},
abstract = {Computational advertising is one of the most successful application scenarios of machine learning and artificial intelligence. This tutorial is designed to review the latest progress of several critical areas in computational advertising: matching, prediction, auction and bidding. Particularly, with the recent advances in generative AI such as large language models, there is a growing interest in further enhancing these areas with these techniques. In this tutorial, we first introduce the recent advances in matching, including its architecture alternatives, model developments, and how it co-evolves with the ad products which distinguishes itself from that in recommendation products. We then review the recent advances in prediction, with a focus on topics such as feature interactions, user interest models, and multi-task/domain learning. We will show how these building bricks constitute large prediction models and LLM-enhanced/LLM-based prediction models. Then, we discuss auction and bidding, a unique area in computational advertising. Both traditional and learning-based auctions will be introduced, followed by their applications in real-world ad products. Given the auction designs, we show how bidding evolves from control-based, to reinforcement learning-based, and most recently to generative AI-based. Our aim is to help the audience grasp the recent developments in computational advertising, as well as to spark inspiration for future research.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {37–40},
numpages = {4},
keywords = {auction, bidding, click-through rate prediction, generative models, matching, recommendation systems},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3715326,
author = {Xiao, Zhe and He, Xu and Wu, Haoying and Yu, Bei and Guo, Yang},
title = {EDA-Copilot: A RAG-Powered Intelligent Assistant for EDA Tools},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3715326},
doi = {10.1145/3715326},
abstract = {With the rise of Large Language Models (LLMs), researchers have become increasingly interested in their applications in EDA flows, particularly in specific subdomains like serving as knowledge assistants and generating RTL code. In this study, we present a Retrieval-Augmented Generation (RAG) framework tailored to EDA task processing, named EDA-Adaptive RAG. This framework addresses the implicit semantics of EDA data and facilitates efficient knowledge acquisition through classification and enhanced retrieval, significantly enhancing LLMs ability to acquire EDA knowledge. Furthermore, we aim to integrate RAG into the design process as an EDA assistant application. Using RTL code generation as a case study, we demonstrate that the performance of RTL code generation can be enhanced through highly relevant retrievals provided by our RAG. The experimental analysis involves EDA Q&amp;A tasks and RTL code generation evaluation. It is shown that our method outperforms the latest works in terms of both answer stability and code quality.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = jan,
keywords = {Large Language Models, Electronic design automation, RTL-to-GDSII, Retrieval-Augmented Generation}
}

@article{10.1145/3698811,
author = {Yan, Mengyi and Wang, Yaoshu and Wang, Yue and Miao, Xiaoye and Li, Jianxin},
title = {GIDCL: A Graph-Enhanced Interpretable Data Cleaning Framework with Large Language Models},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {6},
url = {https://doi.org/10.1145/3698811},
doi = {10.1145/3698811},
abstract = {Data quality is critical across many applications. The utility of data is undermined by various errors, making rigorous data cleaning a necessity. Traditional data cleaning systems depend heavily on predefined rules and constraints, which necessitate significant domain knowledge and manual effort. Moreover, while configuration-free approaches and deep learning methods have been explored, they struggle with complex error patterns, lacking interpretability, requiring extensive feature engineering or labeled data. This paper introduces GIDCL (Graph-enhanced Interpretable Data Cleaning with Large language models), a pioneering framework that harnesses the capabilities of Large Language Models (LLMs) alongside Graph Neural Network (GNN) to address the challenges of traditional and machine learning-based data cleaning methods. By converting relational tables into graph structures, GIDCL utilizes GNN to effectively capture and leverage structural correlations among data, enhancing the model's ability to understand and rectify complex dependencies and errors. The framework's creator-critic workflow innovatively employs LLMs to automatically generate interpretable data cleaning rules and tailor feature engineering with minimal labeled data. This process includes the iterative refinement of error detection and correction models through few-shot learning, significantly reducing the need for extensive manual configuration. GIDCL not only improves the precision and efficiency of data cleaning but also enhances its interpretability, making it accessible and practical for non-expert users. Our extensive experiments demonstrate that GIDCL significantly outperforms existing methods, improving F1-scores by 10% on average while requiring only 20 labeled tuples.},
journal = {Proc. ACM Manag. Data},
month = dec,
articleno = {236},
numpages = {29},
keywords = {data quality, graph neural network, interpretable, large language models}
}

@inproceedings{10.1145/3698204.3716477,
author = {Novin, Alamir and Towne, Georgia},
title = {A Tool for Researching how AI Affects Information Seeking},
year = {2025},
isbn = {9798400712906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698204.3716477},
doi = {10.1145/3698204.3716477},
abstract = {Information Scholars are calling for more standardization of the metrics quantifying the information-seeking processes (ISP). Standardizing measures for online searching is challenging due to search pages including the dynamic nature of generative AI adjacent to personalized search results. AI-chatbots occasionally use queries as prompts to generate text using large-language models (LLM). Search engines also occasionally include Retrieval-Augmented Generation (RAG) results adjacent to personalized search results. This interface hinders the level of control in experiments when two similar queries are treated as prompts towards very different results and text-generations. In addition, experiment findings are less comparable when researchers use different combinations of software for data log collections (e.g., click-throughs and time-on-site), analysis (e.g., NVivo and Qualtrics), and visualizations. These different combinations of platforms can lead to different statistical results or even obnubilate the research metrics. To address these discrepancies, this study introduces a method with three key automations to assist with standardizing ISP experiments on search pages with LLMs and RAG: 1) Controls: A system designed for Randomized Control Trial Experiments and A/B Tests by simulating Google’s search AI and algorithms; 2) Data Collection: Automatic participant log data collection; 3) Analysis and Visualization: Presentation of statistically significant differences in both quantitative and qualitative data, with results visualized alongside proper formatting (e.g., APA citations of the p-value). Preliminary feedback from Information Scholars has been promising, with 86% expressing sufficient value in the proposed method to consider using the software for their future projects.},
booktitle = {Proceedings of the 2025 ACM SIGIR Conference on Human Information Interaction and Retrieval},
pages = {396–404},
numpages = {9},
keywords = {experiments, search and retrieval, simulation, methodsagi, methodology, methods, randomized control trial, rct},
location = {
},
series = {CHIIR '25}
}

@article{10.1145/3712306,
author = {Qin, Chuan and Fang, Chuyu and Yao, Kaichun and Chen, Xi and Zhuang, Fuzhen and Zhu, Hengshu},
title = {COTR: Efficient Job Task Recognition for Occupational Information Systems with Class-Incremental Learning},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {2158-656X},
url = {https://doi.org/10.1145/3712306},
doi = {10.1145/3712306},
abstract = {Occupation-specific job tasks (OSTs) refer to the duties, responsibilities, and activities associated with a particular occupation, which define the core functions and performance expectations for those engaged in that profession. Efficient recognition and extraction of OSTs from large-scale job description data are essential for establishing a continually updated occupational information system (OIS), such as O*NET, which serves as critical tools for advancing research in work and labor markets. However, this task presents substantial challenges due to its heavy reliance on domain experts for the labor-intensive annotation of job postings, rendering the process time-consuming and difficult to scale for large-scale implementation. To this end, in this article, we present COTR, a novel data-driven framework designed for the efficient recognition of OSTs from job postings, capable of continually identifying new tasks through class-incremental learning. Specifically, we first employ large language models (LLMs) and prompt learning to develop a three-phase process–“expansion, translation, and generation”–that addresses the critical challenge of the absence of predefined OSTs in non-English labor market data, leveraging O*NET as a foundational reference. Subsequently, we introduce a BERT-based model for OST recognition, incorporating a uniquely designed pair-wise loss function that distills valuable insights from ChatGPT or other LLMs, thereby substantially enhancing recognition performance. In addition, to achieve cost-effective training data annotation, we develop an LLM-based coarse-to-fine candidate OSTs generation algorithm, integrating contrastive active learning to optimize the annotation process through human-machine collaboration. Notably, we design a supervised fine-tuning strategy with a novel encoding technique to optimize LLMs, improving the recall rate of the generated candidate OSTs and achieving up to a 343-fold increase in annotation efficiency compared to traditional manual expert annotation in our experiments. Afterward, we propose an efficient class-incremental learning method that incorporates an out-of-distribution (OOD) detection module for identifying potential novel OSTs and a fine-tuning module to extend the model’s recognition capabilities to include newly discovered tasks. Finally, we construct two real-world datasets using job posting data collected from the labor markets of China and the United States, respectively. Extensive experiments on the real-world datasets, along with two publicly available datasets, have demonstrated the effectiveness of the proposed COTR. Furthermore, several case studies showcase the significant benefits of COTR for various downstream applications in labor market analysis, including analyzing the evolving demand for OSTs, assessing the value of OSTs, and recognizing the relationships between OSTs and associated skills.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = mar,
articleno = {17},
numpages = {30},
keywords = {Occupational information system, occupation-specific job tasks, OST recognition, labor market analysis, large language model, class-incremental learning}
}

@article{10.1145/3736408,
author = {Koyuncu, Anil},
title = {Exploring Fine-Grained Bug Report Categorization with Large Language Models and Prompt Engineering: An Empirical Study},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3736408},
doi = {10.1145/3736408},
abstract = {Accurate classification of issues is essential for effective project management and timely responses, as the volume of issue reports continues to grow. Manual classification is labor-intensive and error-prone, necessitating automated solutions. While large language models (LLMs) show promise in automated issue labeling, most research focuses on broad categorization (e.g., bugs, feature requests), with limited attention to fine-grained categorization. Understanding specific bug types is crucial, as different bugs require tailored resolution strategies.This study addresses this gap by evaluating LLMs and prompt engineering strategies for fine-grained bug report categorization. We analyze 221,184 fine-grained bug report category labels generated by selected LLMs using various prompt engineering strategies for 1,024 bug reports. We examine how LLMs and prompt engineering influence output characteristics, control over outputs, and categorization performance. Our findings highlight that LLMs and prompt engineering significantly impact output consistency and classification capability, with some yielding consistent results and others introducing variability. Based on these findings, we analyze the agreements and disagreements between LLM-generated labels and human annotations to assess category correctness. Our results suggest that examining label consistency and discrepancies can serve as a complementary method for validating bug report categories, identifying unclear reports, and detecting misclassifications in human annotations.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Prompt Engineering, Large Language Models, Automatic Bug Report Classification, Label correctness}
}

@inproceedings{10.1145/3672608.3707740,
author = {Nguyen, Khoa and Jahan, Sadia and Slavin, Rocky},
title = {A Comparison of the Effects of Model Adaptation Techniques on Large Language Models for Non-Linguistic and Linguistic Tasks},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707740},
doi = {10.1145/3672608.3707740},
abstract = {Generative large language models (LLMs) have revolutionized natural language processing (NLP) by demonstrating exceptional performance in interpreting and generating human language. There has been some exploration of their application to non-linguistic tasks, which could lead to significant advancements in fields that rely heavily on structured data and specialized knowledge. However, there has been limited direct comparison of the effects of model adaptation techniques for non-linguistic compared to linguistic tasks with LLMs. To this end, the work in this paper investigates the effects of fine-tuning and few-shot learning on pre-trained LLMs for non-linguistic tasks using chess puzzles as a case study task. We compare the impact of fine-tuning and few-shot learning on models performing the same task represented in both chess notation (i.e., non-linguistic data) and natural language descriptions of the same chess notations (i.e., natural language data). Our experiments with Mixtral-8x7B-v0.1 and Meta-Llama-3-70B resulted in a 5% lower average increase in performance after fine-tuning for non-linguistic tasks compared to linguistic tasks. Similarly, few-shot learning on pre-trained models exhibited a 3% lower average increase in performance for on non-linguistic tasks compared to linguistic tasks. Furthermore, few-shot learning on fine-tuned models resulted in a significant accuracy drop, particularly for Mixtral, with a 24.82% decrease for non-linguistic tasks. These results suggest that fine-tuning and few-shot learning for generative LLMs have stronger effects on linguistic tasks and their data than for non-linguistic.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {936–944},
numpages = {9},
keywords = {large language models, natural language processing, model adaptation techniques},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3627673.3680275,
author = {Xu, Han},
title = {Towards Seamless User Query to REST API Conversion},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680275},
doi = {10.1145/3627673.3680275},
abstract = {Integrating Large Language Models (LLMs) with external tools and APIs is essential for fields such as information retrieval and knowledge management. While LLMs have made significant strides, their effective integration with external APIs-essential for real-world applications-remains challenging. This paper introduces RESTful-Llama, a novel method designed to empower open-source LLMs to accurately convert natural language instructions into well-formed RESTful API calls. Moreover, RESTful-Llama utilizes DOC-Prompt, a newly proposed technique for generating fine-tuning datasets from publicly available API documentation. Initial experiments demonstrate that RESTful-Llama significantly enhances the accuracy of generated REST API requests.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5495–5498},
numpages = {4},
keywords = {information retrieval, natural language processing},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3696443.3708953,
author = {Kim, Hyeoncheol and Kim, Taehoon and Park, Taehyeong and Kim, Donghyeon and Yu, Yongseung and Kim, Hanjun and Park, Yongjun},
title = {Accelerating LLMs using an Efficient GEMM Library and Target-Aware Optimizations on Real-World PIM Devices},
year = {2025},
isbn = {9798400712753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696443.3708953},
doi = {10.1145/3696443.3708953},
abstract = {Real-time processing of deep learning models on conventional systems, such as CPUs and GPUs, is highly challenging due to memory bottlenecks. This is exacerbated in Large Language Models (LLMs), where the majority of executions are dominated by General Matrix Multiplication (GEMM) operations, which are relatively more memory-intensive than convolution operations. Processing-in-Memory (PIM), which provides high internal bandwidth, can be a promising alternative for LLM serving. However, since current PIM systems do not fully replace traditional memory, data transfer between the host and PIM-side memory is essential. Therefore, minimizing the transfer cost between the host and PIM is crucial for serving LLMs efficiently on the PIM.
 
 
 
In this paper, we propose PIM-LLM, an end-to-end framework that accelerates LLMs using an efficient tiled GEMM library and several key target-aware optimizations on real-world PIM systems. We first propose PGEMMlib, which provides optimized tiling techniques for PIM, considering architecture specific characteristics to minimize unnecessary data transfer overhead and maximize parallelism. In addition, Tile-Selector explores optimized parameters and techniques for different GEMM shapes and available resources of PIM systems using an analytical model. To accelerate LLMs using PGEMMlib, we integrate it into the TVM deep learning compiler framework. We further optimize the LLM execution by applying several key optimizations: Build-time memory layout adjustment, PIM resource pooling, CPU/PIM cooperation support, and QKV generation fusion. Evaluation shows that PIM-LLM achieves significant performance gains of up to 45.75x over the TVM baseline for several well-known LLMs. We strongly believe that this work provides key insights for efficient LLM serving on real PIM devices.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {225–240},
numpages = {16},
keywords = {Large Language Models, Processing-in-memory},
location = {Las Vegas, NV, USA},
series = {CGO '25}
}

@inproceedings{10.1145/3701716.3717808,
author = {Mondal, Chayan and Pham, Duc-Son and Gupta, Ashu and Tan, Tele and Gedeon, Tom},
title = {Leveraging Prompt Engineering with Lightweight Large Language Models to Label and Extract Clinical Information from Radiology Reports},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717808},
doi = {10.1145/3701716.3717808},
abstract = {Chest X-ray imaging plays a critical role in diagnosing chest diseases, making it a cornerstone in clinical and research domains. Automating disease diagnosis and extracting relevant clinical information from chest X-ray reports have become essential for developing AI-driven healthcare systems. While effective, deep learning models require extensive labelled datasets, making the labelling of diseases from radiology reports crucial. Traditionally, rule-based labelling approaches have been employed, but the emergence of large language models (LLMs) has introduced new possibilities through instruction-based prompt engineering. In this study, we explore various prompt engineering techniques, including in-context learning and prompt chaining, to label multilabel disease reports and extract key clinical findings from radiology reports. We conducted ablation studies on both proprietary LLMs (e.g., GPT-4 Turbo, GPT-3.5 Turbo) and publicly available LLMs (e.g., Llama2-7B, Llama2-13B, Llama3-8B, Llama2-70B), comparing their performance in terms of clinical accuracy, privacy, and computational cost. Our findings demonstrate that well-crafted prompts on publicly available and lightweight LLMs can achieve competitive results compared to larger and/or proprietary models, offering a cost-effective and privacy-preserving solution for clinical applications. These results highlight the potential of leveraging advanced prompt engineering to streamline disease labelling and enhance the quality of automated report generation in radiology.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1616–1625},
numpages = {10},
keywords = {chest x-ray report., generative ai, in-context learning, llm, prompt engineering},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3701716.3715868,
author = {Behdin, Kayhan and Dai, Yun and Dexter, Gregory and Gupta, Aman and Mazumder, Rahul and Saha, Ankan and Song, Qingquan and Tang, Shao and Zhu, Sirou and Hsu, Pin-Lun},
title = {Efficient Algorithms for Leveraging LLMs for Generative and Predictive Recommender Systems},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715868},
doi = {10.1145/3701716.3715868},
abstract = {Large language models (LLMs) have taken the world by storm, revolutionizing the use of AI in products. While scaling laws demonstrate that larger models yield better results, making them work in production is hard, often due to latency demands on inference. In this proposed tutorial, we will share optimizations - both algorithmic and systems-related - that help leverage LLMs (both small and large) for recommendation and generative AI use cases at planet scale for the world's largest professional network - LinkedIn. In the first part of the tutorial, we will discuss state-of-the-art (SOTA) model quantization and pruning techniques. This will be in conjunction with a discussion on GPU kernel-level optimizations including minimizing memory copying, effectively utilizing shared memory, optimizing thread scheduling, and maximizing parallel efficiency. We will discuss our own experience with these inventing and leveraging such techniques, while also discussing the latest advancements from other enterprises and the open source world. Our discussions will cover models ranging in size from 1 billion to 100 billion+ parameters. In the second part of the tutorial, we will discuss the latest advancements in the world of LLM knowledge distillation which can result in training very powerful and performant small language models (SLMs). We will also discuss effective instruction tuning and preference alignment techniques that help with improving accuracy and quality of results for generative use cases. Finally, we will discuss actual production use cases that benefit from the aforementioned techniques at planet scale for LinkedIn.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1–4},
numpages = {4},
keywords = {compression, distillation, large language models, pruning, quantization},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3722227,
author = {Govers, Jarod and Pareek, Saumya and Velloso, Eduardo and Goncalves, Jorge},
title = {Feeds of Distrust: Investigating How AI-Powered News Chatbots Shape User Trust and Perceptions},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2160-6455},
url = {https://doi.org/10.1145/3722227},
doi = {10.1145/3722227},
abstract = {The start of the 2020s ushered in a new era of Artificial Intelligence through the rise of Generative AI Large Language Models (LLMs) such as Chat-GPT. These AI chatbots offer a form of interactive agency by enabling users to ask questions and query for more information. However, prior research only considers if LLMs have a political bias or agenda, and not how a biased LLM can impact a user's opinion and trust. Our study bridges this gap by investigating a scenario where users read online news articles and then engage with an interactive AI chatbot, where both the news and the AI are biased to hold a particular stance on a news topic. Interestingly, participants were far more likely to adopt the narrative of a biased chatbot over news articles with an opposing stance. Participants were also substantially more inclined to adopt the chatbot's narrative if its stance aligned with the news—all compared to a control news-article only group. Our findings suggest that the very interactive agency offered by an AI chatbot significantly enhances its perceived trust and persuasive ability compared to the ‘static’ articles from established news outlets, raising concerns about the potential for AI-driven indoctrination. We outline the reasons behind this phenomenon and conclude with the implications of biased LLMs for HCI research, as well as the risks of Generative AI undermining democratic integrity through AI-driven Information Warfare.},
note = {Just Accepted},
journal = {ACM Trans. Interact. Intell. Syst.},
month = mar,
keywords = {Generative AI, News, Bias, Indoctrination, Chatbots, Transparency, Trust, Polarisation, Large Language Models}
}

@inproceedings{10.1145/3698364.3705351,
author = {Lu, Yi-Chen and Kunal, Kishor and Pradipta, Geraldo and Liang, Rongjian and Gandikota, Ravikishore and Ren, Haoxing},
title = {LEGO-Size: LLM-Enhanced GPU-Optimized Signoff-Accurate Differentiable VLSI Gate Sizing in Advanced Nodes},
year = {2025},
isbn = {9798400712937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698364.3705351},
doi = {10.1145/3698364.3705351},
abstract = {On-Chip Variation (OCV)-aware and Path-Based Analysis (PBA) accurate timing optimization achieved by gate sizing (including Vth-assignment) remains a pivotal step in modern signoff. However, in advanced nodes (e.g., 3nm), commercial tools often yield suboptimal results due to the intricate design demands and the vast choices of library cells that require substantial runtime and computational resources for exploration. To address these challenges, we introduce LEGO-Size, a generative framework that harnesses the power of Large Language Models (LLMs) and GPU-accelerated differentiable techniques for efficient gate sizing. LEGO-Size introduces three key innovations. First, it considers timing paths as sequences of tokenized library cells, casting gate sizing prediction as a language modeling task and solving it with self-supervised learning and supervised fine-tuning. Second, it employs a Graph Transformer (GT) with a linear-complexity attention mechanism for netlist encoding, enabling LLMs to make sizing decisions from a global perspective. Third, it integrates a differentiable Static Timing Analysis (STA) engine to refine LLM-predicted gate size probabilities by directly optimizing Total Negative Slack (TNS) through gradient descent. Experimental results on 5 unseen million-gate industrial designs in a commercial 3nm node show that LEGO-Size achieves up to 125x speed up with 37% TNS improvement over an industry-leading commercial signoff tool with minimal power and area overhead.},
booktitle = {Proceedings of the 2025 International Symposium on Physical Design},
pages = {152–162},
numpages = {11},
keywords = {differentiable static timing analysis (sta), generative gate sizing},
location = {Austin, TX, USA},
series = {ISPD '25}
}

@inproceedings{10.1145/3706599.3719979,
author = {Zaj\k{a}c, Hubert Dariusz and Ternov, Niels Kvorning},
title = {Reframing Automation Benefits: A Human-Centered Approach to Expanding the Value of AI-Generated Reports in Healthcare},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719979},
doi = {10.1145/3706599.3719979},
abstract = {The use of Large Language Models (LLMs) for generating medical reports is being increasingly explored across medical specialties. However, these solutions often prioritize the perspectives of report authors, leaving the recipients and their needs outside of the scope of consideration. In this dermatology-focused study, we conducted co-design sessions with general practitioners (GPs) (N=12) in Denmark to establish their content preferences in dermatology reports and investigate unmet information needs in specialist-authored reports. We discuss using their preferences as input to generative AI to enhance the usefulness of medical reports. Such AI could support dermatologists by drafting reports and acting as a proxy for GP information needs, thus improving GP efficacy, enhancing patient outcomes, and reducing the overall burden on healthcare systems. Building on this study, we plan to: refine report structures with dermatologists and patients focusing on collaborative decision-making; and investigate non-chat genAI interaction space for automated reporting in safety-critical environments.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {455},
numpages = {8},
keywords = {LLM, GenAI, AI, automated reporting, clinical reporting},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3613904.3642229,
author = {Chen, Liuqing and Xiao, Shuhong and Chen, Yunnong and Song, Yaxuan and Wu, Ruoyu and Sun, Lingyun},
title = {ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642229},
doi = {10.1145/3613904.3642229},
abstract = {As Computational Thinking (CT) continues to permeate younger age groups in K-12 education, established CT platforms such as Scratch face challenges in catering to these younger learners, particularly those in the elementary school (ages 6-12). Through formative investigation with Scratch experts, we uncover three key obstacles to children’s autonomous Scratch learning: artist’s block in project planning, bounded creativity in asset creation, and inadequate coding guidance during implementation. To address these barriers, we introduce ChatScratch, an AI-augmented system to facilitate autonomous programming learning for young children. ChatScratch employs structured interactive storyboards and visual cues to overcome artist’s block, integrates digital drawing and advanced image generation technologies to elevate creativity, and leverages Scratch-specialized Large Language Models (LLMs) for professional coding guidance. Our study shows that, compared to Scratch, ChatScratch efficiently fosters autonomous programming learning, and contributes to the creation of high-quality, personally meaningful Scratch projects for children.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {649},
numpages = {19},
keywords = {Children Aged 6-12, Computational Thinking, Large Language Model, Scratch},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3674805.3690746,
author = {Almeida, Aylton and Xavier, Laerte and Valente, Marco Tulio},
title = {Automatic Library Migration Using Large Language Models: First Results},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690746},
doi = {10.1145/3674805.3690746},
abstract = {Despite being introduced only a few years ago, Large Language Models (LLMs) are already widely used by developers for code generation. However, their application in automating other Software Engineering activities remains largely unexplored. Thus, in this paper, we report the first results of a study in which we are exploring the use of ChatGPT to support API migration tasks, an important problem that demands manual effort and attention from developers. Specifically, in the paper, we share our initial results involving the use of ChatGPT to migrate a client application to use a newer version of SQLAlchemy, an ORM (Object Relational Mapping) library widely used in Python. We evaluate the use of three types of prompts (Zero-Shot, One-Shot, and Chain Of Thoughts) and show that the best results are achieved by the One-Shot prompt, followed by the Chain Of Thoughts. Particularly, with the One-Shot prompt we were able to successfully migrate all columns of our target application and upgrade its code to use new functionalities enabled by SQLAlchemy’s latest version, such as Python’s asyncio and typing modules, while preserving the original code behavior.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {427–433},
numpages = {7},
keywords = {API Migration, ChatGPT, Large Language Models, Python, SQLAlchemy},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@article{10.1145/3702639,
author = {Bevilacqua, Marialena and Oketch, Kezia and Qin, Ruiyang and Stamey, Will and Zhang, Xinyuan and Gan, Yi and Yang, Kai and Abbasi, Ahmed},
title = {When Automated Assessment Meets Automated Content Generation: Examining Text Quality in the Era of GPTs},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/3702639},
doi = {10.1145/3702639},
abstract = {The use of machine learning (ML) models to assess and score textual data has become increasingly pervasive in an array of contexts including natural language processing, information retrieval, search and recommendation, and credibility assessment of online content. A significant disruption at the intersection of ML and text are text-generating large-language models (LLMs) such as generative pre-trained transformers (GPTs). We empirically assess the differences in how ML-based scoring models trained on human content assess the quality of content generated by humans versus GPTs. To do so, we propose an analysis framework that encompasses essay scoring ML models, human- and ML-generated essays, and a statistical model that parsimoniously considers the impact of type of respondent, prompt genre, and the ML model used for assessment model. A rich testbed is utilized that encompasses 18,460 human-generated and GPT-based essays. Results of our benchmark analysis reveal that LLMs and transformer pretrained language models (PLMs) more accurately score human essay quality as compared to CNN/RNN and feature-based ML methods. Interestingly, we find that LLMs and transformer PLMs tend to score GPT-generated text 10–20% higher on average, relative to human-authored documents. Conversely, traditional deep learning and feature-based ML models score human text considerably higher. Further analysis reveals that even though the LLMs and transformer PLMs are exclusively fine-tuned on human text, they more prominently attend to certain tokens appearing only in GPT-generated text, possibly (in part) due to familiarity/overlap in pre-training. Our framework and results have implications for text classification settings where automated scoring of text is likely to be disrupted by generative AI.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
articleno = {43},
numpages = {36},
keywords = {automated essay scoring, text classification, auto-generated text, user-generated content, text quality, generative AI, large language models, LLMs}
}

@inproceedings{10.1145/3716554.3716598,
author = {Antoniou, Christina and Bassiliades, Nick},
title = {Utilizing LLMs and ontologies to query educational knowledge graphs},
year = {2025},
isbn = {9798400713170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716554.3716598},
doi = {10.1145/3716554.3716598},
abstract = {Knowledge Graphs (KGs) provide knowledge and data in a structured format with content from various fields. But the access to the knowledge graphs is done by experienced users, that is, users who know the syntax of the SPARQL language and the KG vocabulary (either in RDF Schema or in OWL) in order to be able to ask questions to exploit the knowledge graphs. However, this requires a lot of time and effort for most of the users, which makes KGs inaccessible to a large number of users. Large Language Models (LLMs) that have appeared recently can provide an alternative way to query knowledge graphs without the need to learn SPARQL and/or know the schema and vocabulary of them, eliminating the time and effort that ordinary users need to spend in order to use them. In this article, we present some experiments and their results illustrating how ChatGPT can help ordinary users to generate SPARQL queries, without knowing SPARQL, to effectively use knowledge graphs and exploit their wealth of data. We experimented with ChatGPT to explore whether it can generate SPARQL queries based on user's natural language input and a given vocabulary (ontology) about an educational knowledge graph. To this end we have devised a specific prompt template. Results indicate that LLMs can indeed help in this direction, given the fact that they are prompted properly, using good English language. We have also discussed some practical lessons learned through this experiment.},
booktitle = {Proceedings of the 28th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {287–295},
numpages = {9},
keywords = {AI application, ChatGPT, RDF, knowledge graphs, large language model use cases},
location = {
},
series = {PCI '24}
}

@article{10.1145/3695991,
author = {Dong, Yihong and Ding, Jiazheng and Jiang, Xue and Li, Ge and Li, Zhuo and Jin, Zhi},
title = {CodeScore: Evaluating Code Generation by Learning Code Execution},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3695991},
doi = {10.1145/3695991},
abstract = {A proper code evaluation metric (CEM) profoundly impacts the evolution of code generation, which is an important research field in NLP and software engineering. Prevailing match-based CEMs (e.g., BLEU, Accuracy, and CodeBLEU) suffer from two significant drawbacks. 1. They primarily measure the surface differences between codes without considering their functional equivalence. However, functional equivalence is pivotal in evaluating the effectiveness of code generation, as different codes can perform identical operations. 2. They are predominantly designed for the Ref-only input format. However, code evaluation necessitates versatility in input formats. Aside from Ref-only, there are NL-only and Ref and NL formats, which existing match-based CEMs cannot effectively accommodate. In this article, we propose CodeScore, a large language model (LLM)-based CEM, which estimates the functional correctness of generated code on three input types. To acquire CodeScore, we present UniCE, a unified code generation learning framework, for LLMs to learn code execution (i.e., learning PassRatio and Executability of generated code) with unified input. Extensive experimental results on multiple code evaluation datasets demonstrate that CodeScore absolutely improves up to 58.87% correlation with functional correctness compared to other CEMs, achieves state-of-the-art performance, and effectively handles three input formats.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
articleno = {77},
numpages = {22},
keywords = {Code Evaluation, Code Pre-trained Language Model, Code Generation}
}

@inproceedings{10.1145/3721146.3721957,
author = {Sheikholeslami, Sina and Ghasemirahni, Hamid and Payberah, Amir H. and Wang, Tianze and Dowling, Jim and Vlassov, Vladimir},
title = {Utilizing Large Language Models for Ablation Studies in Machine Learning and Deep Learning},
year = {2025},
isbn = {9798400715389},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721146.3721957},
doi = {10.1145/3721146.3721957},
abstract = {In Machine Learning (ML) and Deep Learning (DL) research, ablation studies are typically performed to provide insights into the individual contribution of different building blocks and components of an ML/DL system (e.g., a deep neural network), as well as to justify that certain additions or modifications to an existing ML/DL system can result in the proposed improved performance. Although dedicated frameworks for performing ablation studies have been introduced in recent years, conducting such experiments is still associated with requiring tedious, redundant work, typically involving maintaining redundant and nearly identical versions of code that correspond to different ablation trials. Inspired by the recent promising performance of Large Language Models (LLMs) in the generation and analysis of ML/DL code, in this paper we discuss the potential of LLMs as facilitators of ablation study experiments for scientific research projects that involve or deal with ML and DL models. We first discuss the different ways in which LLMs can be utilized for ablation studies and then present the prototype of a tool called AblationMage, that leverages LLMs to semi-automate the overall process of conducting ablation study experiments. We showcase the usability of AblationMage as a tool through three experiments, including one in which we reproduce the ablation studies from a recently published applied DL paper.},
booktitle = {Proceedings of the 5th Workshop on Machine Learning and Systems},
pages = {230–237},
numpages = {8},
keywords = {ablation studies, machine learning, deep learning, deep neural networks, feature ablation, model ablation, large language models},
location = {World Trade Center, Rotterdam, Netherlands},
series = {EuroMLSys '25}
}

@inproceedings{10.1145/3708359.3712077,
author = {Zhou, Jiazhi and Weber, Rebecca and Wen, Elliott and Lottridge, Danielle},
title = {Real-Time Full-body Interaction with AI Dance Models: Responsiveness to Contemporary Dance},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712077},
doi = {10.1145/3708359.3712077},
abstract = {Interactive AI chatbots put the power of Large-Language Models (LLMs) into people’s hands; it is this interactivity that fueled explosive worldwide influence. In the generative dance space, however, there are few deep-learning-based generative dance models built with interactivity in mind. The release of the AIST++ dance dataset in 2021 led to an uptick of capabilities in generative dance models. Whether these models could be adapted to support interactivity and how well this approach will work is not known. In this study, we explore the capabilities of existing generative dance models for motion-to-motion synthesis on real-time, full-body motion-captured contemporary dance data. We identify an existing model that we adapted to support interactivity: the Bailando++ model, which is trained on the AIST++ dataset and was modified to take music and a motion sequence as input parameters in an interactive loop. We worked with two professional contemporary choreographers and dancers to record and curate a diverse set of 203 motion-captured dance sequences as a set of "user inputs" captured through the Optitrack high-precision motion capture 3D tracking system. We extracted 17 quantitative movement features from the motion data using the well-established Laban Movement Analysis theory, which allowed for quantitative comparisons of inter-movement correlations, which we used for clustering input data and comparing input and output sequences. A total of 10 pieces of music were used to generate a variety of outputs using the adapted Bailando++ model. We found that, on average, the generated output motion achieved only moderate correlations to the user input, with some exceptions of movement and music pairs achieving high correlation. The high-correlation generated output sequences were deemed responsive and relevant co-creations in relation to the input sequences. We discuss implications for interactive generative dance agents, where the use of 3D joint coordinate data should be used over SMPL parameters for ease of real-time generation, and how the use of Laban Movement Analysis could be used to extract useful features and fine-tune deep-learning models.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {1177–1187},
numpages = {11},
keywords = {Design of Human-Computer Interaction, Virtual Environments, Generative AI, Deep-Learning Dance Model},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3639478.3643081,
author = {Lian, Xiaoli and Wang, Shuaisong and Ma, Jieping and Tan, Xin and Liu, Fang and Shi, Lin and Gao, Cuiyun and Zhang, Li},
title = {Imperfect Code Generation: Uncovering Weaknesses in Automatic Code Generation by Large Language Models},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3643081},
doi = {10.1145/3639478.3643081},
abstract = {The task of code generation has received significant attention in recent years, especially when the pre-trained large language models (LLMs) for code have consistently achieved state-of-the-art performance. However, there is currently a lack of a comprehensive weakness taxonomy in the field, uncovering weaknesses in automatic code generation by LLMs. This may lead the community to invest excessive efforts into well-known hotspots while neglecting many crucial yet unrecognized issues that deserve more attention. To bridge this gap, we conduct a systematic study on analyzing the weaknesses based on three state-of-the-art LLMs across three widely-used code generation datasets. Our study identifies eight types of weaknesses and assesses their prevalence across each LLM and dataset, aiming to inform and shape the trajectory of future research in the domain.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {422–423},
numpages = {2},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3650212.3680342,
author = {He, Yifeng and Huang, Jiabo and Rong, Yuyang and Guo, Yiwen and Wang, Ethan and Chen, Hao},
title = {UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large Language Models for Program Testing},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680342},
doi = {10.1145/3650212.3680342},
abstract = {The remarkable capability of large language models (LLMs) in 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
generating high-quality code has drawn increasing attention 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
in the software testing community.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
However, existing code LLMs often demonstrate unsatisfactory capabilities in generating accurate, complete tests
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
since they were trained on code snippets collected without 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
differentiating between code for testing and for other purposes.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
In this paper, we present a large-scale dataset, UniTSyn, which can enhance LLMs for Unit Test Synthesis. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Associating tests with the tested functions is crucial for LLMs to infer the expected behavior and the logic paths to be verified.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
By leveraging Language Server Protocol, UniTSyn achieves the challenging goal of collecting focal-test pairs without per-project execution setups or per-language heuristics, which tend to be fragile and difficult to scale.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Containing 2.7 million focal-test pairs across five mainstream programming languages, it can enhance the test generation ability of LLMs.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Our experiments demonstrate that, 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
by building an autoregressive LLM based on UniTSyn,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
we can achieve significant benefits in learning and understanding unit test representations, 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
resulting in improved generation accuracy and code coverage 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
across all the evaluated programming languages.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1061–1072},
numpages = {12},
keywords = {Large language models, dataset, software testing, test case generation},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3613904.3641964,
author = {Kobiella, Charlotte and Flores L\'{o}pez, Yarhy Said and Waltenberger, Franz and Draxler, Fiona and Schmidt, Albrecht},
title = {"If the Machine Is As Good As Me, Then What Use Am I?" – How the Use of ChatGPT Changes Young Professionals' Perception of Productivity and Accomplishment},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641964},
doi = {10.1145/3613904.3641964},
abstract = {Large language models (LLMs) like ChatGPT have been widely adopted in work contexts. We explore the impact of ChatGPT on young professionals’ perception of productivity and sense of accomplishment. We collected LLMs’ main use cases in knowledge work through a preliminary study, which served as the basis for a two-week diary study with 21 young professionals reflecting on their ChatGPT use. Findings indicate that ChatGPT enhanced some participants’ perceptions of productivity and accomplishment by enabling greater creative output and satisfaction from efficient tool utilization. Others experienced decreased perceived productivity and accomplishment, driven by a diminished sense of ownership, perceived lack of challenge, and mediocre results. We found that the suitability of task delegation to ChatGPT varies strongly depending on the task nature. It’s especially suitable for comprehending broad subject domains, generating creative solutions, and uncovering new information. It’s less suitable for research tasks due to hallucinations, which necessitate extensive validation.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1018},
numpages = {16},
keywords = {Generative AI, knowledge work, productivity, self-efficacy, sense of accomplishment},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3638530.3664162,
author = {Custode, Leonardo Lucio and Migliore Rambaldi, Chiara Camilla and Roveri, Marco and Iacca, Giovanni},
title = {Comparing Large Language Models and Grammatical Evolution for Code Generation},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3664162},
doi = {10.1145/3638530.3664162},
abstract = {Code generation is one of the most valuable applications of AI, as it allows for automated programming and "self-building" programs. Both Large Language Models (LLMs) and evolutionary methods, such as Genetic Programming (GP) and Grammatical Evolution (GE), are known to be capable of performing code generation with reasonable performance. However, to the best of our knowledge, little work has been done so far on a systematic comparison between the two approaches. Most importantly, the only studies that conducted such comparisons used benchmarks from the GP community, which, in our opinion, may have provided possibly GP-biased results. In this work, we perform a comparison of LLMs and evolutionary methods, in particular GE, using instead a well-known benchmark originating from the LLM community. Our results show that, in this scenario, LLMs can solve significantly more tasks than GE, indicating that GE struggles to match the performance of LLMs on code generation tasks that have different properties from those commonly used in the GP community.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1830–1837},
numpages = {8},
keywords = {grammatical evolution, genetic programming, large language models, code generation},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{10.1145/3722565.3727196,
author = {Ahmed, Chuadhry Mujeeb},
title = {AttackLLM: LLM-based Attack Pattern Generation for an Industrial Control System},
year = {2025},
isbn = {9798400716089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722565.3727196},
doi = {10.1145/3722565.3727196},
abstract = {Malicious examples are crucial for evaluating the robustness of machine learning algorithms under attack, particularly in Industrial Control Systems (ICS). However, collecting normal and attack data in ICS environments is challenging due to the scarcity of testbeds and the high cost of human expertise. Existing datasets are often limited by the domain expertise of practitioners, making the process costly and inefficient. The lack of comprehensive attack pattern data poses a significant problem for developing robust anomaly detection methods. In this paper, we propose a novel approach that combines data-centric and design-centric methodologies to generate attack patterns using large language models (LLMs). Our results demonstrate that the attack patterns generated by LLMs not only surpass the quality and quantity of those created by human experts but also offer a scalable solution that does not rely on expensive testbeds or pre-existing attack examples. This multiagent based approach presents a promising avenue for enhancing the security and resilience of ICS environments.},
booktitle = {Proceedings of the 2nd International Workshop on Foundation Models for Cyber-Physical Systems &amp; Internet of Things},
pages = {31–36},
numpages = {6},
keywords = {AI for Security, Attack Dataset, CPS Security and Privacy, ICS, LLMs},
location = {Irvine, CA, USA},
series = {FMSys}
}

@inproceedings{10.1145/3701716.3717815,
author = {Chakraborty, Mohna and Kulkarni, Adithya and Li, Qi},
title = {Empirical Evaluation of Prompting Strategies for Fact Verification Tasks},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717815},
doi = {10.1145/3701716.3717815},
abstract = {Commercial large language models (LLMs) such as GPT-3.5 have emerged as powerful tools for diverse natural language processing (NLP) tasks, yet concerns persist about their reliability in generating factual responses. This study investigates the potential of commercial LLMs such as GPT-3.5 for fact verification, addressing three key research questions: (1) Can GPT-3.5 perform fact verification reliably? (2) How do different prompting strategies affect their performance? (3) What are the common errors they make with the most effective prompt? Using the benchmark FEVER 1.0 dataset, we designed and evaluated three prompts, with experiments conducted using GPT-3.5 as a representative commercial LLM. Our experiments demonstrate that GPT-3.5 achieves a Label Accuracy (LA) of over 72% with the best-performing prompt, significantly outperforming simpler prompts. A detailed error analysis reveals that approximately 70% of mistakes stem from logical reasoning and contextual misunderstandings. These findings suggest that carefully crafted prompts can substantially enhance the accuracy of LLMs, in fact verification tasks, highlighting their potential as supportive tools for applications in sensitive domains.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1598–1604},
numpages = {7},
keywords = {fact verification, large language models, prompting strategies},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3709153,
author = {Sprint, Gina and Schmitter-Edgecombe, Maureen and Weaver, Raven and Wiese, Lisa and Cook, Diane J.},
title = {CogProg: Utilizing Large Language Models to Forecast In-the-Moment Health Assessment},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
url = {https://doi.org/10.1145/3709153},
doi = {10.1145/3709153},
abstract = {Forecasting future health status is beneficial for understanding health patterns and providing anticipatory support for cognitive and physical health difficulties. In recent years, generative Large Language Models (LLMs) have shown promise as forecasters. Though not traditionally considered strong candidates for numeric tasks, LLMs demonstrate emerging abilities to address various forecasting problems. They also provide the ability to incorporate unstructured information and explain their reasoning process. In this article, we explore whether LLMs can effectively forecast future self-reported health state. To do this, we utilized in-the-moment assessments of mental sharpness, fatigue, and stress from multiple studies, utilizing daily responses (N = 106 participants) and responses that are accompanied by text descriptions of activities (N = 32 participants). With these data, we constructed prompt/response pairs to predict a participant’s next answer. We fine-tuned several LLMs and applied chain-of-thought prompting evaluating forecasting accuracy and prediction explainability. Notably, we found that LLMs achieved the lowest Mean Absolute Error (MAE) overall (0.851), while gradient boosting achieved the lowest overall RMSE (1.356). When additional text context was provided, LLM forecasts achieved the lowest MAE for predicting mental sharpness (0.862), fatigue (1.000), and stress (0.414). These multimodal LLMs further outperformed the numeric baselines in terms of RMSE when predicting stress (0.947), although numeric algorithms achieved the best RMSE results for mental sharpness (1.246) and fatigue (1.587). This study offers valuable insights for future applications of LLMs in health-based forecasting. The findings suggest that LLMs, when supplemented with additional text information, can be effective tools for improving health forecasting accuracy.},
journal = {ACM Trans. Comput. Healthcare},
month = apr,
articleno = {20},
numpages = {25},
keywords = {Cognitive health, ecological momentary assessment, forecasting, large language models}
}

@inproceedings{10.5555/3716662.3716808,
author = {Xu, Zhihan and Mustafaraj, Eni},
title = {Tracing the Evolution of Information Transparency for OpenAI's GPT Models through a Biographical Approach},
year = {2025},
publisher = {AAAI Press},
abstract = {Information transparency, the open disclosure of information about models, is crucial for proactively evaluating the potential societal harm of large language models (LLMs) and developing effective risk mitigation measures. Adapting the biographies of artifacts and practices (BOAP) method (Hyysalo, Pollock, and Williams 2019) from science and technology studies, this study analyzes the evolution of information transparency within OpenAI's Generative Pre-trained Transformers (GPT) model reports and usage policies from its inception in 2018 to GPT-4, one of today's most capable LLMs. To assess the breadth and depth of transparency practices, we develop a 9-dimensional, 3-level analytical framework to evaluate the comprehensiveness and accessibility of information disclosed to various stakeholders. Findings suggest that while model limitations and downstream usages are increasingly clarified, model development processes have become more opaque. Transparency remains minimal in certain aspects, such as model explainability and real-world evidence of LLM impacts, and the discussions on safety measures such as technical interventions and regulation pipelines lack in-depth details. The findings emphasize the need for enhanced transparency to foster accountability and ensure responsible technological innovations.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {1684–1695},
numpages = {12},
location = {San Jose, California, USA},
series = {AIES '24}
}

@inproceedings{10.1145/3641525.3663617,
author = {Boufford, Nichole and Wonsil, Joseph and Pocock, Adam and Sullivan, Jack and Seltzer, Margo and Pasquier, Thomas},
title = {Computational Experiment Comprehension using Provenance Summarization},
year = {2024},
isbn = {9798400705304},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641525.3663617},
doi = {10.1145/3641525.3663617},
abstract = {Scientists use complex multistep workflows to analyze data. However, reproducing computational experiments is often difficult as scientists’ software engineering practices are geared towards the science, not the programming. In particular, reproducing a scientific workflow frequently requires information about its execution. This information includes the precise versions of packages and libraries used, the particular processor used to perform floating point computation, and the language runtime used. This can be extracted from data provenance, the formal record of what happened during an experiment. However, data provenance is inherently graph-structured and often large, which makes interpretation challenging. Rather than exposing data provenance through its graphical representation, we propose a textual one and use a large language model to generate it. We develop techniques for prompting large language models to automatically generate textual summaries of provenance data. We conduct a user study to compare the effectiveness of these summaries to the more common node-link diagram representation. Study participants are able to extract useful information from both the textual summaries and node-link diagrams. The textual summaries were particularly beneficial for scientists with low computational expertise. We discuss the qualitative results from our study to motivate future designs for reproducibility tools.},
booktitle = {Proceedings of the 2nd ACM Conference on Reproducibility and Replicability},
pages = {1–19},
numpages = {19},
keywords = {Provenance, Reproducibility, Text Generation, User Study},
location = {Rennes, France},
series = {ACM REP '24}
}

@inbook{10.1145/3677389.3702542,
author = {Tran, The Trung and Gonz\'{a}lez-Gallardo, Carlos-Emiliano and Doucet, Antoine},
title = {Retrieval Augmented Generation for Historical Newspapers},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702542},
abstract = {Nowadays, the accessibility and long-term preservation of historical records are significantly impacted by the sharp increase in the digitization of these archives. This shift creates new opportunities for researchers and students in multiple disciplines to broaden their knowledge or conduct multidisciplinary research. However, given the vast amount of data that needs to be analyzed, using this knowledge is not easy. Different natural language processing tasks such as named entity recognition, entity linking, and article separation have been developed to make this accessibility easier for the public by extracting information and structuring data. However, historical newspaper article aggregation is still unexplored. In this work, we demonstrate the potential of the retrieval-augmented generation framework that integrates large language models (LLMs), a semantic retrieval module, and knowledge bases to create a system capable of aggregating historical newspaper articles. In addition, we propose a set of metrics that permit evaluating these generative systems without requiring any ground truth. The results of our proposed RAG pipeline are promising at this early stage of the system. They show that semantic retrieval with the help of reranking and additional information (NER) reduces the impact of OCR errors and query misspellings.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {58},
numpages = {5}
}

@article{10.1145/3732784,
author = {Xie, Shuyi and Yao, Wenlin and Dai, Yong and Wang, Shaobo and Xu, Zishan and Lin, Fan and Zhou, Donglin and Jin, Lifeng and Feng, Xinhua and Wei, Pengzhi and Lin, Yujie and Hu, Zhichao and Yu, Dong and Zhang, Zhengyou and Nie, Jing and Liu, Yuhong},
title = {TencentLLMEval: A Hierarchical Evaluation of Real-World Capabilities for Human-Aligned LLMs},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3732784},
doi = {10.1145/3732784},
abstract = {Large language models (LLMs) have shown impressive capabilities across various natural language tasks. However, evaluating their alignment with human preferences remains a challenge. To this end, we propose a comprehensive human evaluation framework to assess LLMs’ proficiency in following instructions on diverse real-world tasks. We construct a hierarchical task tree encompassing 7 major areas covering over 200 categories and over 800 tasks, which covers diverse capabilities such as question answering, reasoning, multiturn dialogue, and text generation, to evaluate LLMs in a comprehensive and in-depth manner. We also design detailed evaluation standards and processes to facilitate consistent, unbiased judgments from human evaluators. A test set of over 3,000 instances is released, spanning different difficulty levels and knowledge domains. Our work provides a standardized methodology to evaluate human alignment in LLMs for both English and Chinese. We also analyze the feasibility of automating parts of evaluation with a strong LLM (GPT-4). Our framework supports a thorough assessment of LLMs as they are integrated into real-world applications. We have made publicly available the task tree, TencentLLMEval dataset, and evaluation methodology which have been demonstrated as effective in assessing the performance of Tencent Hunyuan LLMs 1. By doing so, we aim to facilitate the benchmarking of advances in the development of safe and human-aligned LLMs.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = apr,
keywords = {human-aligned, LLMs, Evaluation}
}

@inproceedings{10.1145/3680533.3697064,
author = {Feng, Tony Haoran and Denny, Paul and W\"{u}nsche, Burkhard C. and Luxton-Reilly, Andrew and Whalley, Jacqueline},
title = {An Eye for an AI: Evaluating GPT-4o's Visual Perception Skills and Geometric Reasoning Skills Using Computer Graphics Questions},
year = {2024},
isbn = {9798400711367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680533.3697064},
doi = {10.1145/3680533.3697064},
abstract = {CG (Computer Graphics) is a popular field of CS (Computer Science), but many students find this topic difficult due to it requiring a large number of skills, such as mathematics, programming, geometric reasoning, and creativity. Over the past few years, researchers have investigated ways to harness the power of GenAI (Generative Artificial Intelligence) to improve teaching. In CS, much of the research has focused on introductory computing. A recent study evaluating the performance of an LLM (Large Language Model), GPT-4 (text-only), on CG questions, indicated poor performance and reliance on detailed descriptions of image content, which often required considerable insight from the user to return reasonable results. So far, no studies have investigated the abilities of LMMs (Large Multimodal Models), or multimodal LLMs, to solve CG questions and how these abilities can be used to improve teaching.In this study, we construct two datasets of CG questions requiring varying degrees of visual perception skills and geometric reasoning skills, and evaluate the current state-of-the-art LMM, GPT-4o, on the two datasets. We find that although GPT-4o exhibits great potential in solving questions with visual information independently, major limitations still exist to the accuracy and quality of the generated results. We propose several novel approaches for CG educators to incorporate GenAI into CG teaching despite these limitations. We hope that our guidelines further encourage learning and engagement in CG classrooms.},
booktitle = {SIGGRAPH Asia 2024 Educator's Forum},
articleno = {5},
numpages = {8},
keywords = {Large Language Models, LLMs, Large Multimodal Models, LMMs, Visual Language Models, VLMs, Generative Artificial Intelligence, GenAI, GPT-4, GPT-4o, Visual Perception, Geometric Reasoning, Computer Graphics, Computing Education, Evaluation, Assessment},
location = {
},
series = {SA '24}
}

@inproceedings{10.1145/3626252.3630909,
author = {Denny, Paul and Leinonen, Juho and Prather, James and Luxton-Reilly, Andrew and Amarouche, Thezyrie and Becker, Brett A. and Reeves, Brent N.},
title = {Prompt Problems: A New Programming Exercise for the Generative AI Era},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630909},
doi = {10.1145/3626252.3630909},
abstract = {Large language models (LLMs) are revolutionizing the field of computing education with their powerful code-generating capabilities. Traditional pedagogical practices have focused on code writing tasks, but there is now a shift in importance towards reading, comprehending and evaluating LLM-generated code. Alongside this shift, an important new skill is emerging -- the ability to solve programming tasks by constructing good prompts for code-generating models. In this work we introduce a new type of programming exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are designed to help students learn how to write effective prompts for AI code generators. A student solves a Prompt Problem by crafting a natural language prompt which, when provided as input to an LLM, outputs code that successfully solves a specified programming task. We also present a new web-based tool called Promptly which hosts a repository of Prompt Problems and supports the automated evaluation of prompt-generated code. We deploy Promptly in one CS1 and one CS2 course and describe our experiences, which include student perceptions of this new type of activity and their interactions with the tool. We find that students are enthusiastic about Prompt Problems, and appreciate how the problems engage their computational thinking skills and expose them to new programming constructs. We discuss ideas for the future development of new variations of Prompt Problems, and the need to carefully study their integration into classroom practice.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {296–302},
numpages = {7},
keywords = {ai code generation, artificial intelligence, generative ai, large language models, llms, prompt engineering, prompt problems},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3696410.3714759,
author = {Jiang, Chumeng and Wang, Jiayin and Ma, Weizhi and Clarke, Charles L. A. and Wang, Shuai and Wu, Chuhan and Zhang, Min},
title = {Beyond Utility: Evaluating LLM as Recommender},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714759},
doi = {10.1145/3696410.3714759},
abstract = {With the rapid development of Large Language Models (LLMs), recent studies employed LLMs as recommenders to provide personalized information services for distinct users. Despite efforts to improve the accuracy of LLM-based recommendation models, relatively little attention is paid to beyond-utility dimensions. Moreover, there are unique evaluation aspects of LLM-based recommendation models, which have been largely ignored. To bridge this gap, we explore four new evaluation dimensions and propose a multidimensional evaluation framework. The new evaluation dimensions include: 1) history length sensitivity, 2) candidate position bias, 3) generation-involved performance, and 4) hallucinations. All four dimensions have the potential to impact performance, but are largely unnecessary for consideration in traditional systems. Using this multidimensional evaluation framework, along with traditional aspects, we evaluate the performance of seven LLM-based recommenders, with three prompting strategies, comparing them with six traditional models on both ranking and re-ranking tasks on four datasets. We find that LLMs excel at handling tasks with prior knowledge and shorter input histories in the ranking setting, and perform better in the re-ranking setting, beating traditional models across multiple dimensions. However, LLMs exhibit substantial candidate position bias issues, and some models hallucinate nonexistent items much more often than others. We intend our evaluation framework and observations to benefit future research on the use of LLMs as recommenders. The code and data are available at https://github.com/JiangDeccc/EvaLLMasRecommender.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {3850–3862},
numpages = {13},
keywords = {evaluation, large language model, recommendation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3706598.3713726,
author = {Pang, Rock Yuren and Schroeder, Hope and Smith, Kynnedy Simone and Barocas, Solon and Xiao, Ziang and Tseng, Emily and Bragg, Danielle},
title = {Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713726},
doi = {10.1145/3706598.3713726},
abstract = {Large language models (LLMs) have been positioned to revolutionize HCI, by reshaping not only the interfaces, design patterns, and sociotechnical systems that we study, but also the research practices we use. To-date, however, there has been little understanding of LLMs’ uptake in HCI. We address this gap via a systematic literature review of 153 CHI papers from 2020-24 that engage with LLMs. We taxonomize: (1) domains where LLMs are applied; (2) roles of LLMs in HCI projects; (3) contribution types; and (4) acknowledged limitations and risks. We find LLM work in 10 diverse domains, primarily via empirical and artifact contributions. Authors use LLMs in five distinct roles, including as research tools or simulated users. Still, authors often raise validity and reproducibility concerns, and overwhelmingly study closed models. We outline opportunities to improve HCI research with and on LLMs, and provide guiding questions for researchers to consider the validity and appropriateness of LLM-related work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {456},
numpages = {20},
keywords = {Large language models, human-AI interaction, systematic literature review, HCI theory},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3708557.3716341,
author = {Calvano, Miriana and Curci, Antonio and Lanzilotti, Rosa and Piccinno, Antonio and Ragone, Azzurra},
title = {Leveraging Large Language Models for Usability Testing: a Preliminary Study},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716341},
doi = {10.1145/3708557.3716341},
abstract = {Despite growing efforts to prioritize user experience in product development, software organizations often perform little or no usability engineering activities. Therefore, it is crucial to develop strategies to integrate them effectively into software development processes. The rapid advances in Artificial Intelligence have significantly influenced various aspects of daily life, particularly with the emergence of Large Language Models (LLMs), which can serve as promising tools to support activities to enhance the usability of software products. This paper presents a study investigating the potential of LLMs to assist practitioners in conducting usability tests. Specifically, we conducted an experiment where LLMs generate usability test tasks. Our goal is to assess whether AI can effectively support evaluators by comparing tasks generated by LLMs to those defined by usability experts. The findings indicate that while LLMs can provide valuable support, effective usability testing still requires human oversight and expert intervention.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {78–81},
numpages = {4},
keywords = {Human-Centred Design, Large Language Models, Usability Test, Artificial Intelligence},
location = {
},
series = {IUI '25 Companion}
}

@article{10.1145/3734524,
author = {Collini, Luca and Garg, Siddharth and Karri, Ramesh},
title = {C2HLSC: Leveraging Large Language Models to Bridge the Software-to-Hardware Design Gap},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3734524},
doi = {10.1145/3734524},
abstract = {High-Level Synthesis (HLS) tools offer rapid hardware design from C code, but their compatibility is limited by code constructs. This paper investigates Large Language Models (LLMs) for automatically refactoring C code into HLS-compatible formats. We present a case study using an LLM to rewrite C code for NIST 800-22 randomness tests, a QuickSort algorithm, and AES-128 into HLS-synthesizable C. The LLM iteratively transforms the C code guided by the system prompt and tool’s feedback, implementing functions like streaming data and hardware-specific signals. With the hindsight obtained from the case study, we implement a fully automated framework to refactor C code into HLS-compatible formats using LLMs. To tackle complex designs, we implement a preprocessing step that breaks down the hierarchy in order to approach the problem in a divide-and-conquer bottom-up way. We validated our framework on three ciphers, one hash function, five NIST 800-22 randomness tests, and a QuickSort algorithm. Our results show a high success rate on benchmarks that are orders of magnitude more complex than what has been achieved generating Verilog with LLMs.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = may,
keywords = {High-Level Synthesis, Large Language Models, Automatic Code Repair}
}

@article{10.1145/3686970,
author = {Cheng, Zirui and Xu, Jingfei and Jin, Haojian},
title = {TreeQuestion: Assessing Conceptual Learning Outcomes with LLM-Generated Multiple-Choice Questions},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686970},
doi = {10.1145/3686970},
abstract = {The advances of generative AI have posed a challenge for using open-ended questions to assess conceptual learning outcomes, as it is increasingly common for students to use tools like ChatGPT to generate long textual answers. However, teachers still have to spend substantial time reading the answers and inferring students' learning outcomes. We present TreeQuestion, a human-in-the-loop system designed to help teachers create a set of multiple-choice questions to assess students' conceptual learning outcomes. When a teacher seeks to assess students' comprehension of specific concepts, TreeQuestion taps into the wealth of knowledge embedded within large language models and generates a set of multiple-choice questions organized in a tree-like structure. We evaluated TreeQuestion with 96 students and 10 teachers. Results indicated that students achieved similar performance in multiple-choice questions generated by TreeQuestion and open-ended questions graded by teachers. Meanwhile, TreeQuestion could reduce teachers' efforts in creating and grading the multiple-choice questions in contrast to manually generated open-ended questions. We estimate that in a hypothetical class with 20 students, using multiple-choice questions from TreeQuestion may require only 4.6% of the time compared to open-ended questions for assessing learning outcomes.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {431},
numpages = {29},
keywords = {education, generative AI, large language models, multiple-choice questions, open-ended questions}
}

@inproceedings{10.1145/3589335.3651509,
author = {Huang, Yue and Shu, Kai and Yu, Philip S. and Sun, Lichao},
title = {From Creation to Clarification: ChatGPT's Journey Through the Fake News Quagmire},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651509},
doi = {10.1145/3589335.3651509},
abstract = {The rampant spread of fake news has adversely affected society, resulting in extensive research on curbing its spread. As a notable milestone in large language models (LLMs), ChatGPT has gained significant attention due to its exceptional capabilities. In this study, we present an exploration of ChatGPT's proficiency in generating, explaining, and detecting fake news as follows.Generation -- We employ different prompt methods to generate fake news and prove the high quality of these instances through both self-assessment and human evaluation.Explanation -- We obtain nine features to characterize fake news based on ChatGPT's explanations and analyze the distribution of these factors across multiple public datasets.Detection -- We examine ChatGPT's capacity to identify fake news. We propose a reason-aware prompt method to improve its performance. We further probe into the potential extra information that could bolster its effectiveness in detecting fake news.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {513–516},
numpages = {4},
keywords = {chatgpt, fake news, large language models},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3650400.3650478,
author = {Zhao, Wei and Chen, Qinghui and You, Junling},
title = {LlmRe: A zero-shot entity relation extraction method based on the large language model},
year = {2024},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650400.3650478},
doi = {10.1145/3650400.3650478},
abstract = {Entity relation extraction aims to extract knowledge triples from unstructured or semi-structured text data and can be applied to various fields, including medicine, finance knowledge graph construction and intelligent question-answering. Traditional entity relation extraction requires a large amount of labeled data, consumes a lot of labor and time, and the trained model lacks generalization ability, which is difficult to migrate to other fields. Zero-shot entity relation extraction relieves the dependence on labeled data in traditional method. Based on unlabeled text data, zero-shot entity relation extraction has strong domain adaptability, which is a very challenging and practical task. Recent work on large language models shows that large models can effectively complete downstream tasks through natural language instructions and have good generalization ability. Inspired by this, we explore the use of large models for information extraction. Due to the randomness of large language model generation, we introduce in-context learning in entity relation extraction task to guide large language model to output data in a specified format to help obtain structured data. At the same time, we propose a three-stage extraction framework for decomposing entity relation extraction tasks, and each stage is conducted in the form of question and answer to reduce the complexity of extraction. We evaluated the knowledge triples extraction performance of the model on three self-built test datasets in different fields, and the experimental result showed that our proposed method achieved impressive performance in the zero-shot entity relation extraction task, surpassing the comparison model on multiple metrics, proving the effectiveness and domain adaptability of the proposed method.},
booktitle = {Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
pages = {475–480},
numpages = {6},
location = {Xiamen, China},
series = {EITCE '23}
}

@inproceedings{10.5555/3635637.3663007,
author = {Niu, Tong and Zhang, Weihao and Zhao, Rong},
title = {Solution-oriented Agent-based Models Generation with Verifier-assisted Iterative In-context Learning},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Agent-based models (ABMs) stand as an essential paradigm for proposing and validating hypothetical solutions or policies aimed at addressing challenges posed by complex systems and achieving various objectives. This process demands labor-intensive endeavors and multidisciplinary expertise. Large language models (LLMs) encapsulating cross-domain knowledge and programming proficiency could potentially alleviate the difficulty of this process. However, LLMs excel in handling sequential information, making it challenging for analyzing the intricate interactions and nonlinear dynamics inherent in ABMs. Additionally, due to the lack of self-evaluation capability of LLMs, relying solely on LLMs is insufficient to effectively accomplish this process. In this paper, we present SAGE, a general solution-oriented ABM generation framework designed for automatic modeling and generating solutions for targeted problems. Unlike approaches reliant on expert handcrafting or resource-intensive neural network training, SAGE establishes a verifier-assisted iterative in-context learning process employing large language models (LLMs) to leverages their inherent cross-domain knowledge for tackling intricate demands from diverse domain scenarios. In SAGE, we introduce an semi-structured conceptual representation expliciting the intricate structures of ABMs and an objective representation to guide LLMs in modeling scenarios and proposing hypothetical solutions through in-context learning. To ensure the model executability and solution feasibility, SAGE devises a two-level verifier with chain-of-thought prompting tailored to the complex interactions and non-linear dynamics of ABMs, driving the iterative generation optimization. Moreover, we construct an evaluation dataset of solution-oriented ABMs from open sources. It contains practical models across various domains, completed with scenario descriptions and executable agent-based solutions. Evaluations by various LLMs demonstrate that SAGE leads to an average improvement of 18.7% in modeling quality and 38.1% in solution generation effectiveness. This work advances our understanding and ability in tackling complex real-world challenges across diverse domains through the application of ABM methodologies.},
booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
pages = {1473–1481},
numpages = {9},
keywords = {automatic verification and generation, chain-of-thought prompting, iterative in-context learning, large language models, solution-oriented agent-based modeling},
location = {Auckland, New Zealand},
series = {AAMAS '24}
}

@inproceedings{10.1145/3691620.3695591,
author = {Wei, Jialiang and Courbis, Anne-Lise and Lambolais, Thomas and Xu, Binbin and Bernard, Pierre Louis and Dray, Gerard and Maalej, Walid},
title = {Getting Inspiration for Feature Elicitation: App Store- vs. LLM-based Approach},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695591},
doi = {10.1145/3691620.3695591},
abstract = {Over the past decade, app store (AppStore)-inspired requirements elicitation has proven to be highly beneficial. Developers often explore competitors' apps to gather inspiration for new features. With the advance of Generative AI, recent studies have demonstrated the potential of large language model (LLM)-inspired requirements elicitation. LLMs can assist in this process by providing inspiration for new feature ideas. While both approaches are gaining popularity in practice, there is a lack of insight into their differences. We report on a comparative study between AppStore- and LLM-based approaches for refining features into sub-features. By manually analyzing 1,200 sub-features recommended from both approaches, we identified their benefits, challenges, and key differences. While both approaches recommend highly relevant sub-features with clear descriptions, LLMs seem more powerful particularly concerning novel unseen app scopes. Moreover, some recommended features are imaginary with unclear feasibility, which suggests the importance of a human-analyst in the elicitation loop.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {857–869},
numpages = {13},
keywords = {requirements elicitation, app store mining, large language models, data-centered requirements engineering, creativity in SE},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@article{10.1145/3643514,
author = {Khaokaew, Yonchanok and Xue, Hao and Salim, Flora D.},
title = {MAPLE: Mobile App Prediction Leveraging Large Language Model Embeddings},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
url = {https://doi.org/10.1145/3643514},
doi = {10.1145/3643514},
abstract = {In recent years, predicting mobile app usage has become increasingly important for areas like app recommendation, user behaviour analysis, and mobile resource management. Existing models, however, struggle with the heterogeneous nature of contextual data and the user cold start problem. This study introduces a novel prediction model, Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE), which employs Large Language Models (LLMs) and installed app similarity to overcome these challenges. MAPLE utilises the power of LLMs to process contextual data and discern intricate relationships within it effectively. Additionally, we explore the use of installed app similarity to address the cold start problem, facilitating the modelling of user preferences and habits, even for new users with limited historical data. In essence, our research presents MAPLE as a novel, potent, and practical approach to app usage prediction, making significant strides in resolving issues faced by existing models. MAPLE stands out as a comprehensive and effective solution, setting a new benchmark for more precise and personalised app usage predictions. In tests on two real-world datasets, MAPLE surpasses contemporary models in both standard and cold start scenarios. These outcomes validate MAPLE's capacity for precise app usage predictions and its resilience against the cold start problem. This enhanced performance stems from the model's proficiency in capturing complex temporal patterns and leveraging contextual information. As a result, MAPLE can potentially improve personalised mobile app usage predictions and user experiences markedly.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {10},
numpages = {25},
keywords = {App usage prediction, Large language model, Mobile user behaviour modelling}
}

@inproceedings{10.1145/3641555.3705215,
author = {Niousha, Rose and O'Neill, Abigail and Chen, Ethan and Malhotra, Vedansh and Akram, Bita and Norouzi, Narges},
title = {LLM-KCI: Leveraging Large Language Models to Identify Programming Knowledge Components},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705215},
doi = {10.1145/3641555.3705215},
abstract = {Identifying Knowledge Components (KCs) in computer science education improves curriculum design and teaching strategies. We introduce a framework using Large Language Models to identify KCs from programming assignments automatically. Our framework helps educators align assignments with course objectives. GPT-4 identifies relevant KCs well, though there's a low match with expert-generated KCs at the course level. At the problem level, performance is lower, but key KCs are reasonably identified.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1557–1558},
numpages = {2},
keywords = {cs1, knowledge component, large language model},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626772.3657987,
author = {Zhu, Xinliang and Dhua, Arnab and Gray, Douglas and Yalniz, I. Zeki and Yu, Tan and Elhoseiny, Mohamed and Plummer, Bryan},
title = {Multimodal Representation and Retrieval [MRR 2024]},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657987},
doi = {10.1145/3626772.3657987},
abstract = {Multimodal data is available in many applications like e-commerce production listings, social media posts and short videos. However, existing algorithms dealing with those types of data still focus on uni-modal representation learning by vision-language alignment and cross-modal retrieval. In this workshop, we target to bring a new retrieval problem where both queries and documents are multimodal. With the popularity of vision language modeling, large language models (LLMs), retrieval augmented generation (RAG), and multimodal LLM, we see a lot of new opportunities for multimodal representation and retrieval tasks. This event will be a comprehensive half-day workshop focusing on the subject of multimodal representation and retrieval. The agenda includes keynote speeches, oral presentations, and an interactive panel discussion.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3047–3050},
numpages = {4},
keywords = {large language model, multimodal large language model, multimodal representation, multimodal retrieval, vision language modeling},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3688866.3689124,
author = {Xu, Shihao and Luo, Yiyang and Shi, Wei},
title = {Geo-LLaVA: A Large Multi-Modal Model for Solving Geometry Math Problems with Meta In-Context Learning},
year = {2024},
isbn = {9798400711930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3688866.3689124},
doi = {10.1145/3688866.3689124},
abstract = {Geometry mathematics problems pose significant challenges for large language models (LLMs) because they involve visual elements and spatial reasoning. Current methods primarily rely on symbolic character awareness to address these problems. Considering geometry problem solving is a relatively nascent field with limited suitable datasets and currently almost no work on solid geometry problem solving, we collect a geometry question-answer dataset by sourcing geometric data from Chinese high school education websites, referred to as GeoMath. It contains solid geometry questions and answers with accurate reasoning steps as compensation for existing plane geometry datasets. Additionally, we propose a Large Multi-modal Model (LMM) framework named Geo-LLaVA, which incorporates retrieval augmentation with supervised fine-tuning (SFT) in the training stage, called meta-training, and employs in-context learning (ICL) during inference to improve performance. Our fine-tuned model with ICL attains the state-of-the-art performance of 65.25% and 42.36% on selected questions of the GeoQA dataset and GeoMath dataset respectively with proper inference steps. Notably, our model initially endows the ability to solve solid geometry problems and supports the generation of reasonable solid geometry picture descriptions and problem-solving steps. Our research sets the stage for further exploration of LLMs in multi-modal math problem-solving, particularly in geometry math problems.},
booktitle = {Proceedings of the 2nd Workshop on Large Generative Models Meet Multimodal Applications},
pages = {11–15},
numpages = {5},
keywords = {geometry problem solving, in-context learning, large multimodal model, rag},
location = {Melbourne VIC, Australia},
series = {LGM3A '24}
}

@inproceedings{10.1145/3706468.3706487,
author = {Li, Ziqing and Cukurova, Mutlu and Bulathwela, Sahan},
title = {A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706487},
doi = {10.1145/3706468.3706487},
abstract = {The development of Automatic Question Generation (QG) models has the potential to significantly improve educational practices by reducing the teacher workload associated with creating educational content. This paper introduces a novel approach to educational question generation that controls the topical focus of questions. The proposed Topic-Controlled Question Generation (T-CQG) method enhances the relevance and effectiveness of the generated content for educational purposes. Our approach uses fine-tuning on a pre-trained T5-small model, employing specially created datasets tailored to educational needs. The research further explores the impacts of pre-training strategies, quantisation, and data augmentation on the model’s performance. We specifically address the challenge of generating semantically aligned questions with paragraph-level contexts, thereby improving the topic specificity of the generated questions. In addition, we introduce and explore novel evaluation methods to assess the topical relatedness of the generated questions. Our results, validated through rigorous offline and human-backed evaluations, demonstrate that the proposed models effectively generate high-quality, topic-focused questions. These models have the potential to reduce teacher workload and support personalised tutoring systems by serving as bespoke question generators. With its relatively small number of parameters, the proposals not only advance the capabilities of question generation models for handling specific educational topics but also offer a scalable solution that reduces infrastructure costs. This scalability makes them feasible for widespread use in education without reliance on proprietary large language models like ChatGPT.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {148–158},
numpages = {11},
keywords = {Educational Question Generation, Formative Assessment, Summative Assessment, Personalised Testing, Natural Language Processing},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3613904.3642400,
author = {Suh, Sangho and Chen, Meng and Min, Bryan and Li, Toby Jia-Jun and Xia, Haijun},
title = {Luminate: Structured Generation and Exploration of Design Space with Large Language Models for Human-AI Co-Creation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642400},
doi = {10.1145/3613904.3642400},
abstract = {Thanks to their generative capabilities, large language models (LLMs) have become an invaluable tool for creative processes. These models have the capacity to produce hundreds and thousands of visual and textual outputs, offering abundant inspiration for creative endeavors. But are we harnessing their full potential? We argue that current interaction paradigms fall short, guiding users towards rapid convergence on a limited set of ideas, rather than empowering them to explore the vast latent design space in generative models. To address this limitation, we propose a framework that facilitates the structured generation of design space in which users can seamlessly explore, evaluate, and synthesize a multitude of responses. We demonstrate the feasibility and usefulness of this framework through the design and development of an interactive system, Luminate, and a user study with 14 professional writers. Our work advances how we interact with LLMs for creative tasks, introducing a way to harness the creative potential of LLMs.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {644},
numpages = {26},
keywords = {Large language models, creativity support, design space, dimensional exploration, human-AI co-creation, human-AI interaction},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inbook{10.1145/3677389.3702565,
author = {Babaei Giglou, Hamed and D'Souza, Jennifer and Auer, S\"{o}ren},
title = {LLMs4Synthesis: Leveraging Large Language Models for Scientific Synthesis},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702565},
abstract = {In response to the growing complexity and volume of scientific literature, this paper introduces the LLMs4Synthesis framework, designed to enhance the capabilities of Large Language Models (LLMs) to synthesize the key insights from scientific texts as high-quality and concise summaries. This framework addresses the need for rapid, coherent, and contextually rich integration of key scientific insights, leveraging both open-source and proprietary LLMs. It also examines the effectiveness of LLMs in evaluating the integrity and reliability of these syntheses, alleviating inadequacies in current quantitative metrics. The contributions of this study are a novel methodology for synthesizing key scientific insights, definition of new synthesis types, and establishing nine detailed quality criteria for evaluating syntheses. The implementation fits LLMs with reinforcement learning to optimize for synthesis quality by alignment with our established quality criteria. The LLMs4Synthesis framework and its components are available, promising to improve the generation and evaluation of scientific research synthesis.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {31},
numpages = {12}
}

@inproceedings{10.1145/3649217.3653594,
author = {Azaiz, Imen and Kiesler, Natalie and Strickroth, Sven},
title = {Feedback-Generation for Programming Exercises With GPT-4},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653594},
doi = {10.1145/3649217.3653594},
abstract = {Ever since Large Language Models (LLMs) and related applications have become broadly available, several studies investigated their potential for assisting educators and supporting students in higher education. LLMs such as Codex, GPT-3.5, and GPT 4 have shown promising results in the context of large programming courses, where students can benefit from feedback and hints if provided timely and at scale. This paper explores the quality of GPT-4 Turbo's generated output for prompts containing both the programming task specification and a student's submission as input. Two assignments from an introductory programming course were selected, and GPT-4 was asked to generate feedback for 55 randomly chosen, authentic student programming submissions. The output was qualitatively analyzed regarding correctness, personalization, fault localization, and other features identified in the material. Compared to prior work and analyses of GPT-3.5, GPT-4 Turbo shows notable improvements. For example, the output is more structured and consistent. GPT-4 Turbo can also accurately identify invalid casing in student programs' output. In some cases, the feedback also includes the output of the student program. At the same time, inconsistent feedback was noted such as stating that the submission is correct but an error needs to be fixed. The present work increases our understanding of LLMs' potential, limitations, and how to integrate them into e-assessment systems, pedagogical scenarios, and instructing students who are using applications based on GPT-4.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {31–37},
numpages = {7},
keywords = {GPT-4 turbo, LLMs, assessment, benchmarking, formative feedback, introductory programming, large language models, personalized feedback},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.5555/3712729.3712752,
author = {Wu, Yuhang and Wang, Yingfei and Wang, Chu and Zheng, Zeyu},
title = {LLM Enhanced Machine Learning Estimators for Classification},
year = {2025},
isbn = {9798331534202},
publisher = {IEEE Press},
abstract = {Pre-trained large language models (LLM) have emerged as a powerful tool for simulating various scenarios and generating informative output given specific instructions and multimodal input. In this work, we analyze the specific use of LLM to enhance a classical supervised machine learning method for classification problems. We propose a few approaches to integrate LLM into a classical machine learning estimator to further enhance the prediction performance. We examine the performance of the proposed approaches through both standard supervised learning binary classification tasks, and a transfer learning task where the test data observe distribution changes compared to the training data. Numerical experiments using four publicly available datasets are conducted and suggest that using LLM to enhance classical machine learning estimators can provide significant improvement on prediction performance.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {288–298},
numpages = {11},
location = {Orlando, Florida, USA},
series = {WSC '24}
}

@inproceedings{10.1145/3717867.3717902,
author = {Islam, Tunazzina and Goldwasser, Dan},
title = {Can LLMs Assist Annotators in Identifying Morality Frames? - Case Study on Vaccination Debate on Social Media},
year = {2025},
isbn = {9798400714832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3717867.3717902},
doi = {10.1145/3717867.3717902},
abstract = {Nowadays, social media is pivotal in shaping public discourse, especially on polarizing issues like vaccination, where diverse moral perspectives influence individual opinions. In NLP, data scarcity and complexity of psycholinguistic tasks, such as identifying morality frames, make relying solely on human annotators costly, time-consuming, and prone to inconsistency due to cognitive load. To address these issues, we leverage large language models (LLMs), which are adept at adapting new tasks through few-shot learning, utilizing a handful of in-context examples coupled with explanations that connect examples to task principles. Our research explores LLMs’ potential to assist human annotators in identifying morality frames within vaccination debates on social media. We employ a two-step process: generating concepts and explanations with LLMs, followed by human evaluation using a "think-aloud" tool. Our study shows that integrating LLMs into the annotation process enhances accuracy, reduces task difficulty, lowers cognitive load, suggesting a promising avenue for human-AI collaboration in complex psycholinguistic tasks.},
booktitle = {Proceedings of the 17th ACM Web Science Conference 2025},
pages = {169–178},
numpages = {10},
keywords = {social media, large language models, natural language processing, vaccine, moral foundation, COVID-19, morality frames},
location = {
},
series = {Websci '25}
}

@inproceedings{10.1145/3690624.3709321,
author = {Hu, Mengkang and Zhao, Pu and Xu, Can and Sun, Qingfeng and Lou, Jian-Guang and Lin, Qingwei and Luo, Ping and Rajmohan, Saravan},
title = {AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709321},
doi = {10.1145/3690624.3709321},
abstract = {Large Language Model (LLM) based agents have garnered significant attention and are becoming increasingly popular. Furthermore, planning ability is a crucial component of an LLM-based agent, involving interaction with the environment and executing actions to complete a planning task, which generally entails achieving a desired goal from an initial state. This paper investigates enhancing the planning abilities of LLM-based agents through instruction tuning, referred to as agent training. Recent studies on agent training have demonstrated that utilizing expert-level trajectory data (sequences of action-observation pairs) for instruction-tuning LLMs effectively enhances their planning capabilities. However, existing work primarily focuses on synthesizing trajectories from manually designed planning tasks and environments. The labor-intensive nature of creating these environments and tasks impedes the generation of sufficiently varied and extensive trajectories for agent training. To address this limitation, this paper explores the automated synthesis of diverse environments and a gradual range of planning tasks, from easy to difficult. We introduce a framework, AgentGen, that leverages LLMs first to generate environments and subsequently generate planning tasks conditioned on these environments. Specifically, to improve environmental diversity, we propose using an inspiration corpus composed of various domain-specific text segments as the context for synthesizing environments. Moreover, to increase the difficulty diversity of generated planning tasks, we propose a bidirectional evolution method, Bi-Evol, that evolves planning tasks from easier and harder directions to synthesize a task set with a smoother difficulty curve, thereby enhancing the learning process of LLMs more effectively. These methods collectively contribute to the generation of diverse trajectory data for instruction-tuning. Based on AgentGen, we greatly expanded the number of environments and planning tasks available for agent training. The evaluation results from AgentBoard indicate that AgentGen greatly enhances the planning capabilities of LLMs. For instance, the AgentGen instruction-tuned Llama-3.1-8B outperforms GPT-3.5 in overall performance. Moreover, the AgentGen-tuned Llama-3.1-70B model achieves state-of-the-art results in planning tasks. Project page: https://agent-gen.github.io/.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {496–507},
numpages = {12},
keywords = {large language model based agent, large language models, planning},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3689492.3689816,
author = {Kang, Eunsuk and Shaw, Mary},
title = {tl;dr: Chill, y’all: AI Will Not Devour SE},
year = {2024},
isbn = {9798400712159},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689492.3689816},
doi = {10.1145/3689492.3689816},
abstract = {Social media provide a steady diet of dire warnings that artificial intelligence (AI) will make software engineering (SE) irrelevant or obsolete. To the contrary, the engineering discipline of software is rich and robust; it encompasses the full scope of software design, development, deployment, and practical use; and it has regularly assimilated radical new offerings from AI. Current AI innovations such as machine learning, large language models (LLMs) and generative AI will offer new opportunities to extend the models and methods of SE. They may automate some routine development processes, and they will bring new kinds of components and architectures. If we're fortunate they may force SE to rethink what we mean by correctness and reliability. They will not, however, render SE irrelevant.},
booktitle = {Proceedings of the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {303–315},
numpages = {13},
keywords = {AI-assisted development, software correctness, software engineering principles},
location = {Pasadena, CA, USA},
series = {Onward! '24}
}

@inproceedings{10.1145/3627673.3679805,
author = {Zhao, Runhao and Tang, Jiuyang and Zeng, Weixin and Chen, Ziyang and Zhao, Xiang},
title = {Zero-shot Knowledge Graph Question Generation via Multi-agent LLMs and Small Models Synthesis},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679805},
doi = {10.1145/3627673.3679805},
abstract = {Knowledge Graph Question Generation (KGQG) is the task of generating natural language questions based on the given knowledge graph (KG). Although extensively explored in recent years, prevailing models predominantly depend on labelled data for training deep learning models or employ large parametric frameworks, e.g., Large Language Models (LLMs), which can incur significant deployment costs and pose practical implementation challenges. To address these issues, in this work, we put forward a zero-shot, multi-agent KGQG framework. This framework integrates the capabilities of LLMs with small models to facilitate cost-effective, high-quality question generation. In specific, we develop a professional editorial team architecture accompanied by two workflow optimization tools to reduce unproductive collaboration among LLMs-based agents and enhance the robustness of the system. Extensive experiments demonstrate that our proposed framework derives the new state-of-the-art performance on the zero-shot KGQG tasks, with relative gains of 20.24% and 13.57% on two KGQG datasets, respectively, which rival fully supervised state-of-the-art models.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3341–3351},
numpages = {11},
keywords = {large language models, multi-agents framework, zero-shot knowledge graph question generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3663742.3663973,
author = {Ngom, Amadou Latyr and Kraska, Tim},
title = {Mallet: SQL Dialect Translation with LLM Rule Generation},
year = {2024},
isbn = {9798400706806},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663742.3663973},
doi = {10.1145/3663742.3663973},
abstract = {Translating between the SQL dialects of different systems is important for migration and federated query processing. Existing approaches rely on hand-crafted translation rules, which tend to be incomplete and hard to maintain, especially as the number of dialects to translate increases. Thus, dialect translation remains a largely unsolved problem.To address this issue, we introduce Mallet, a system that leverages Large Language Models (LLMs) to automate the generation of SQL-to-SQL translation rules, namely schema conversion, automated UDF generation, extension selection, and expression composition. Once the rules are generated, they are infinitely reusable on new workloads without putting the LLM on the critical path of query execution. Mallet enhances the accuracy of the LLMs by (1) performing retrieval augmented generation (RAG) over system documentation and human expertise, (2) subjecting the rules to empirical validation using the actual SQL systems to detect hallucinations, and (3) automatically creating accurate few-shot learning instances. Contributors, without knowing the system's code, can improve Mallet by providing natural-language expertise for RAG.},
booktitle = {Proceedings of the Seventh International Workshop on Exploiting Artificial Intelligence Techniques for Data Management},
articleno = {3},
numpages = {5},
location = {Santiago, AA, Chile},
series = {aiDM '24}
}

@inproceedings{10.1145/3676536.3676781,
author = {Xiong, Chenwei and Liu, Cheng and Li, Huawei and Li, Xiaowei},
title = {HLSPilot: LLM-based High-Level Synthesis},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676781},
doi = {10.1145/3676536.3676781},
abstract = {Large language models (LLMs) have catalyzed an upsurge in automatic code generation, garnering significant attention for register transfer level (RTL) code generation. Despite the potential of RTL code generation with natural language, it remains error-prone and limited to relatively small modules because of the substantial semantic gap between natural language expressions and hardware design intent. In response to the limitations, we propose a methodology that reduces the semantic gaps by utilizing C/C++ for generating hardware designs via High-Level Synthesis (HLS) tools. Basically, we build a set of C-to-HLS optimization strategies catering to various code patterns, such as nested loops and local arrays. Then, we apply these strategies to sequential C/C++ code through in-context learning, which provides the LLMs with exemplary C/C++ to HLS prompts. With this approach, HLS designs can be generated effectively. Since LLMs still face problems in determining the optimized pragma parameters precisely, we have a design space exploration (DSE) tool integrated for pragma parameter tuning. Furthermore, we also employ profiling tools to pinpoint the performance bottlenecks within a program and selectively convert bottleneck components to HLS code for hardware acceleration. By combining the LLM-based profiling, C/C++ to HLS translation, and DSE, we have established HLSPilot---the first LLM-enabled high-level synthesis framework, which can fully automate the high-level application acceleration on hybrid CPU-FPGA architectures. According to our experiments on real-world application benchmarks, HLSPilot achieve comparable performance in general and can even outperform manually crafted counterparts, thereby underscoring the substantial promise of LLM-assisted hardware designs.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {226},
numpages = {9},
keywords = {large language model, high-level synthesis, C-to-HLS, code generation},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3704323.3704357,
author = {Zhang, Lu and Liu, Yu and Luo, Yitian and Gao, Feng and Gu, Jinguang},
title = {Qwen-IG: A Qwen-based Instruction Generation Model for LLM Fine-tuning},
year = {2025},
isbn = {9798400717482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704323.3704357},
doi = {10.1145/3704323.3704357},
abstract = {The quality of instructions is crucial for LLM (large language model) fine-tuning. The most compelling data for instruction tuning exhibit not only high complexity, low perplexity, high faithfulness, and high answer relevancy, but also diversity, naturalness, coherence, and understandability. However, traditional QAG (question and answer generation) and LLMs face challenges regarding instruction complexity, answer relevancy and diversity. To overcome these issues, we have developed the Qwen-IG instruction generation model for LLM fine-tuning. Firstly, we collect high-quality instruction sets, such as alpaca, GPT4-LLM, and TigerBot, and utilize them to build a train set for LLM fine-tuning. Secondly, Qwen is trained with the train set just generated through three approaches, namely C2IO (context to instruction and output), C2I2O (context to instruction to output), and C2O2I (context to output to instruction). Finally, we employ the eight metrics mentioned above to evaluate the effectiveness of Qwen-IG in the task of generating instructions. The experimental results demonstrate Qwen-IG has increased at least 9.6% on complexity, 23% on answer relevancy and 17% on diversity.},
booktitle = {Proceedings of the 2024 13th International Conference on Computing and Pattern Recognition},
pages = {295–302},
numpages = {8},
keywords = {Instruction Generation, Large Language Model, Instruction tuning},
location = {
},
series = {ICCPR '24}
}

@inproceedings{10.1145/3706599.3706664,
author = {Yahagi, Yuchi and Chujo, Rintaro and Harada, Yuga and Han, Changyo and Sugiyama, Kohei and Naemura, Takeshi},
title = {PaperWave: Listening to Research Papers as Conversational Podcasts Scripted by LLM},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706664},
doi = {10.1145/3706599.3706664},
abstract = {Listening to audio content, such as podcasts and audiobooks, is one way for people to engage with knowledge. Listening affords people more mobility than reading by seeing, thereby broadening their learning opportunities. This study explores the potential applications of large language models (LLMs) to adapt text documents to audio content and addresses the lack of listening-friendly materials for niche content, such as research papers. LLMs can generate scripts of audio content in various styles tailored to specific needs, such as full-content duration or speech types (monologue or dialogue). To explore this potential, we developed PaperWave as a prototype that transforms academic paper PDFs into conversational podcasts. Our two-month investigation, involving 11 participants (including the authors), employed an autobiographical design, a field study, and a design workshop. The findings highlight the importance of considering listener interaction with their environment when designing document-to-audio systems.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {689},
numpages = {10},
keywords = {Podcast, Research paper, Large language models, Autobiographical design, Field study},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3701716.3715539,
author = {Lian, Junhong and Ao, Xiang and Liu, Xinyu and Liu, Yang and He, Qing},
title = {Panoramic Interests: Stylistic-Content Aware Personalized Headline Generation},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715539},
doi = {10.1145/3701716.3715539},
abstract = {Personalized news headline generation aims to provide users with attention-grabbing headlines that are tailored to their preferences. Prevailing methods focus on user-oriented content preferences, but most of them overlook the fact that diverse stylistic preferences are integral to users' panoramic interests, leading to suboptimal personalization. In view of this, we propose a novel  &lt;u&gt;S&lt;/u&gt; tylistic- &lt;u&gt;C&lt;/u&gt; ontent  &lt;u&gt;A&lt;/u&gt; ware  &lt;u&gt;Pe&lt;/u&gt; rsonalized Headline Generation (SCAPE) framework. SCAPE extracts both content and stylistic features from headlines with the aid of large language model (LLM) collaboration. It further adaptively integrates users' long- and short-term interests through a contrastive learning-based hierarchical fusion network. By incorporating the panoramic interests into the headline generator, SCAPE reflects users' stylistic-content preferences during the generation process. Extensive experiments on the real-world dataset PENS demonstrate the superiority of SCAPE over baselines.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1109–1112},
numpages = {4},
keywords = {large language models, personalized headline generation, stylistic-content awareness fusion, user preference modeling},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3675094.3678445,
author = {Dobhal, Umang and Garcia, Christina and Inoue, Sozo},
title = {Synthetic Skeleton Data Generation using Large Language Model for Nurse Activity Recognition},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3678445},
doi = {10.1145/3675094.3678445},
abstract = {In this paper, we improve nurse activity recognition by employing a Large Language Model (LLM) to generate synthetic pose estimation data. Keypoint data extracted from recorded videos of a single nurse performing Endotracheal suctioning (ES) activities using You Only Look Once v7 (YOLOv7) is used as a database. We explore the issue of data imbalances that hinder the effectiveness of activity recognition algorithms. To counter this, we utilize LLMs to artificially augment the dataset by generating varied synthetic samples through prompting strategies with different content and context. A Random Forest (RF) classifier is trained on annotations of medical activities and corresponding keypoints. Additionally, we generate synthetic datasets in equal volumes using Random Sampling and Generative Adversarial Networks (GAN) to benchmark against our LLM-based approach. To evaluate, we compared the performance between baseline data and different augmentation approaches. The similarity between original and synthetic data is measured using the Kolmogorov-Smirnov (K-S) test. The proposed approach using LLM with prompts containing the explanation of the task with the description of the datasets to generate synthetic data has improved the overall ES classification performance. Our study illustrates the critical role of context and content in prompts for optimizing LLMs for synthetic data generation.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {493–499},
numpages = {7},
keywords = {large language models (llms), nurse activity recognition, skeleton pose, synthetic data},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3711542.3711580,
author = {Jiang, Xiaorui and Khan, Kulsoom and Vasantha, Sumithra Thinakara and Haider, Sajjad},
title = {Evidence Extraction for Automated Medical Coding: Preliminary Evaluation},
year = {2025},
isbn = {9798400717383},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711542.3711580},
doi = {10.1145/3711542.3711580},
abstract = {Coding clinical texts in standard language such as ICD is an important but tedious and error-prone process. Automated medical coding algorithms suffer problems due to the combined the challenge of handling the significant length of clinical text, the complexity of the huge code hierarchy and the lack of interpretability to ensure user trust. Large language models (LLM) have also been proven struggling with this task in recent studies. Recent efforts have been made to annotate an evidence-supported medical coding dataset. The current study makes the first empirical investigation into how well (small) fine-tuned pretrained language models (PLM) and LLMs could identify the sentences containing medical evidence supporting the assigned codes. Hierarchical sequential sentence classification and GPT-3.5 in the zero-shot setting were tested for evidence sentence extraction. Extra evaluation was performed to investigate how evidence extraction impacts clinical coding and what implications it has towards the future generation algorithms for automated medical coding.},
booktitle = {Proceedings of the 2024 8th International Conference on Natural Language Processing and Information Retrieval},
pages = {18–23},
numpages = {6},
keywords = {ICD coding, code evidence, sequential sentence classification, large language model},
location = {
},
series = {NLPIR '24}
}

@article{10.1145/3735129,
author = {Yang, Boyang and Tian, Haoye and Ren, Jiadong and Zhang, Hongyu and Klein, Jacques and Bissyande, Tegawende and Le Goues, Claire and Jin, Shunfu},
title = {MORepair: Teaching LLMs to Repair Code via Multi-Objective Fine-Tuning},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3735129},
doi = {10.1145/3735129},
abstract = {Within the realm of software engineering, specialized tasks on code, such as program repair, present unique challenges, necessitating fine-tuning Large language models&nbsp;(LLMs) to unlock state-of-the-art performance. Fine-tuning approaches proposed in the literature for LLMs on program repair tasks generally overlook the need to reason about the logic behind code changes, beyond syntactic patterns in the data. High-performing fine-tuning experiments also usually come at very high computational costs. With MORepair, we propose a novel perspective on the learning focus of LLM fine-tuning for program repair: we not only adapt the LLM parameters to the syntactic nuances of the task of code transformation (objective ➊), but we also specifically fine-tune the LLM with respect to the logical reason behind the code change in the training data (objective ➋). Such a multi-objective fine-tuning will instruct LLMs to generate high-quality patches.We apply MORepair to fine-tune four open-source LLMs with different sizes and architectures. Experimental results on function-level and repository-level repair benchmarks show that the implemented fine-tuning effectively boosts LLM repair performance by 11.4% to 56.0%. We further show that our fine-tuning strategy yields superior performance compared to the state-of-the-art approaches, including standard fine-tuning, Fine-tune-CoT, and RepairLLaMA.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Program Repair, Fine-tuning, Large Language Model, Open Source}
}

@inproceedings{10.1145/3708359.3712119,
author = {Takagi, Hirohane and Moriya, Shoji and Sato, Takuma and Nagao, Manabu and Higuchi, Keita},
title = {A Framework for Efficient Development and Debugging of Role-Playing Agents with Large Language Models},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712119},
doi = {10.1145/3708359.3712119},
abstract = {We propose a framework that leverages large language models (LLMs) to semi-automate the development and debugging of role-playing agents, reducing the need for extensive manual effort. Role-playing agents powered by LLMs offer scalable solutions that enhance communication and interaction in various applications, such as employee training, healthcare, and software development. However, creating prompts manually is a time-consuming process, and sequential debugging increases the difficulty of anticipating conversation flow, resulting in increased cognitive load. Our framework addresses these challenges by generating and summarizing dialogue examples, providing a clearer overview of conversation flow and reduce mental workload. It also enhances role-playing quality by mitigating LLMs’ tendency to produce generic or vague responses. In a user study, the proposed method significantly improved perceived workload and five of the six NASA-TLX dimensions. Moreover, it can generate agents comparable to those created with expertly crafted prompts. This framework is model-agnostic, enabling integration of advancements in LLM capabilities and prompting techniques, and is applicable to diverse domains.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {70–88},
numpages = {19},
keywords = {Prompt Engineering, Dialogue system, Large language models},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3676536.3676674,
author = {Qin, Ruiyang and Yan, Zheyu and Zeng, Dewen and Jia, Zhenge and Liu, Dancheng and Liu, Jianbo and Abbasi, Ahmed and Zheng, Zhi and Cao, Ningyuan and Ni, Kai and Xiong, Jinjun and Shi, Yiyu},
title = {Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676674},
doi = {10.1145/3676536.3676674},
abstract = {Large Language Models (LLMs) deployed on edge devices learn through fine-tuning and updating a certain portion of their parameters. Although such learning methods can be optimized to reduce resource utilization, the overall required resources remain a heavy burden on edge devices. Instead, Retrieval-Augmented Generation (RAG), a resource-efficient LLM learning method, can improve the quality of the LLM-generated content without updating model parameters. However, the RAG-based LLM may involve repetitive searches on the profile data in every user-LLM interaction. This search can lead to significant latency along with the accumulation of user data. Conventional efforts to decrease latency result in restricting the size of saved user data, thus reducing the scalability of RAG as user data continuously grows. It remains an open question: how to free RAG from the constraints of latency and scalability on edge devices? In this paper, we propose a novel framework to accelerate RAG via Computing-in-Memory (CiM) architectures. It accelerates matrix multiplications by performing in-situ computation inside the memory while avoiding the expensive data transfer between the computing unit and memory. Our framework, Robust CiM-backed RAG (RoCR), utilizing a novel contrastive learning-based training method and noise-aware training, can enable RAG to efficiently search profile data with CiM. To the best of our knowledge, this is the first work utilizing CiM to accelerate RAG.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {50},
numpages = {9},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3643991.3644933,
author = {Oishwee, Sahrima Jannat and Stakhanova, Natalia and Codabux, Zadia},
title = {Large Language Model vs. Stack Overflow in Addressing Android Permission Related Challenges},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644933},
doi = {10.1145/3643991.3644933},
abstract = {The Android permission system regulates access to sensitive mobile device resources such as camera and location. To access these resources, third-party developers need to request permissions. However, the Android permission system is complex and fast-evolving, presenting developers with numerous challenges surrounding compatibility issues, misuse of permissions, and vulnerabilities related to permissions. Our study aims to explore whether Large Language Models (LLMs) can serve as a reliable tool to assist developers in using Android permissions correctly and securely, thereby reducing the risks of misuse and security vulnerabilities in apps. In our study, we analyzed 1,008 Stack Overflow questions related to Android permissions and their accepted answers. In parallel, we generate answers to these questions using a popular LLM tool, ChatGPT. We focused on how well the ChatGPT's responses align with the accepted answers on Stack Overflow. Our findings show that above 50% of ChatGPT's answers align with Stack Overflow's accepted answers. ChatGPT offers better-aligned responses for challenges related to Documentation and Conceptual Understanding, while it provides less aligned answers for Debugging-related issues. In addition, we found that ChatGPT provides more consistent answers for 73.27% questions. Our study demonstrates the potential for using LLMs such as ChatGPT as a supporting tool to help developers navigate Android permission-related problems.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {373–383},
numpages = {11},
keywords = {Android permissions, stack overflow, large language model (LLM)},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@article{10.1145/3719351,
author = {Grishina, Anastasiia and Liventsev, Vadim and H\"{a}rm\"{a}, Aki and Moonen, Leon},
title = {Fully Autonomous Programming Using Iterative Multi-Agent Debugging with Large Language Models},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
url = {https://doi.org/10.1145/3719351},
doi = {10.1145/3719351},
abstract = {Program synthesis with Large Language Models (LLMs) suffers from a “near-miss syndrome”: The generated code closely resembles a correct solution but fails unit tests due to minor errors. We address this with a multi-agent framework called Synthesize, Execute, Instruct, Debug, and Repair (SEIDR). Effectively applying SEIDR to instruction-tuned LLMs requires determining (a) optimal prompts for LLMs, (b) what ranking algorithm selects the best programs in debugging rounds, and (c) balancing the repair of unsuccessful programs with the generation of new ones. We empirically explore these tradeoffs by comparing replace-focused, repair-focused, and hybrid debug strategies. We also evaluate lexicase and tournament selection to rank candidates in each generation. On Program Synthesis Benchmark 2 (PSB2), our framework outperforms both conventional use of OpenAI Codex without a repair phase and traditional genetic programming approaches. SEIDR outperforms the use of an LLM alone, solving 18 problems in C++ and 20 in Python on PSB2 at least once across experiments. To assess generalizability, we employ GPT-3.5 and Llama 3 on the PSB2 and HumanEval-X benchmarks. Although SEIDR with these models does not surpass current state-of-the-art methods on the Python benchmarks, the results on HumanEval-C++ are promising. SEIDR with Llama 3-8B achieves an average pass@100 of 84.2%. Across all SEIDR runs, 163 of 164 problems are solved at least once with GPT-3.5 in HumanEval-C++, and 162 of 164 with the smaller Llama 3-8B. We conclude that SEIDR effectively overcomes the near-miss syndrome in program synthesis with LLMs.},
journal = {ACM Trans. Evol. Learn. Optim.},
month = mar,
articleno = {8},
numpages = {37},
keywords = {automatic programming, large language models, program repair}
}

@inproceedings{10.1145/3706599.3720018,
author = {Das, Amit Kumar and Bearfield, Cindy Xiong and Mueller, Klaus},
title = {Leveraging Large Language Models for Personalized Public Messaging},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720018},
doi = {10.1145/3706599.3720018},
abstract = {We present a novel methodology for crafting effective public messages by combining large language models (LLMs) and conjoint analysis. Our approach personalizes messages for diverse personas – context-specific archetypes representing distinct attitudes and behaviors – while reducing the costs and time associated with traditional surveys. We tested this method in public health contexts (e.g., COVID-19 mandates) and civic engagement initiatives (e.g., voting). A total of 153 distinct messages were generated, each composed of components with varying levels, and evaluated across five personas tailored to each context. Conjoint analysis identified the most effective message components for each persona, validated through a study with 2,040 human participants. This research highlights LLMs’ potential to enhance public communication, providing a scalable, cost-effective alternative to surveys, and offers new directions for HCI, particularly for the design of adaptive, user-centered, persona-driven interfaces and systems.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {378},
numpages = {7},
keywords = {Large Language Models (LLM), Public Communication, Message Personalization, Conjoint Analysis, Persona-based Messaging, and human-AI collaboration},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3589335.3651940,
author = {Mo, Fengran and Yi, Bole and Mao, Kelong and Qu, Chen and Huang, Kaiyu and Nie, Jian-Yun},
title = {ConvSDG: Session Data Generation for Conversational Search},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651940},
doi = {10.1145/3589335.3651940},
abstract = {Conversational search provides a more convenient interface for users to search by allowing multi-turn interaction with the search engine. However, the effectiveness of the conversational dense retrieval methods is limited by the scarcity of training data required for their fine-tuning. Thus, generating more training conversational sessions with relevant labels could potentially improve search performance. Based on the promising capabilities of large language models (LLMs) on text generation, we propose ConvSDG, a simple yet effective framework to explore the feasibility of boosting conversational search by using LLM for session data generation. Within this framework, we design dialogue/session-level and query-level data generation with unsupervised and semi-supervised learning, according to the availability of relevance judgments. The generated data are used to fine-tune the conversational dense retriever. Extensive experiments on four widely used datasets demonstrate the effectiveness and broad applicability of our ConvSDG framework compared with several strong baselines.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1634–1642},
numpages = {9},
keywords = {conversational search, large language model, session data generation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3641822.3641882,
author = {Mendes, Wendy and Souza, Samara and De Souza, Cleidson},
title = {"You're on a bicycle with a little motor": Benefits and Challenges of Using AI Code Assistants},
year = {2024},
isbn = {9798400705335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641822.3641882},
doi = {10.1145/3641822.3641882},
abstract = {AI code assistants, such as Tabnine, GitHub CoPilot, and ChatGPT, employ Large Language Models (LLMs) trained on extensive source code and other documents. They receive prompts and generate code suggestions aimed to facilitate programming tasks. Previous research in this field has explored the correctness, complexity, quality, and security of the code suggestions. Software developers' experiences have been studied in the context of controlled experiments. Based on 14 interviews with software developers, this paper describes the developers' daily and continuous experiences with AI code assistants, presenting benefits and challenges grounded in actual development work, along with strategies to address these challenges.},
booktitle = {Proceedings of the 2024 IEEE/ACM 17th International Conference on Cooperative and Human Aspects of Software Engineering},
pages = {144–152},
numpages = {9},
keywords = {AI code assistants, developer experiences, code generation},
location = {Lisbon, Portugal},
series = {CHASE '24}
}

@article{10.1145/3664930,
author = {Fan, Lizhou and Li, Lingyao and Ma, Zihui and Lee, Sanggyu and Yu, Huizi and Hemphill, Libby},
title = {A Bibliometric Review of Large Language Models Research from 2017 to 2023},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {5},
issn = {2157-6904},
url = {https://doi.org/10.1145/3664930},
doi = {10.1145/3664930},
abstract = {Large language models (LLMs), such as OpenAI's Generative Pre-trained Transformer (GPT), are a class of language models that have demonstrated outstanding performance across a range of natural language processing (NLP) tasks. LLMs have become a highly sought-after research area because of their ability to generate human-like language and their potential to revolutionize science and technology. In this study, we conduct bibliometric and discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000 publications, this article serves as a roadmap for researchers, practitioners, and policymakers to navigate the current landscape of LLMs research. We present the research trends from 2017 to early 2023, identifying patterns in research paradigms and collaborations. We start with analyzing the core algorithm developments and NLP tasks that are fundamental in LLMs research. We then investigate the applications of LLMs in various fields and domains, including medicine, engineering, social science, and humanities. Our review also reveals the dynamic, fast-paced evolution of LLMs research. Overall, this article offers valuable insights into the current state, impact, and potential of LLMs research and its applications.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = oct,
articleno = {91},
numpages = {25},
keywords = {Bibliometric analysis, large language models, discourse analysis, scholarly collaboration networks, topic modeling}
}

@inproceedings{10.1145/3674805.3690741,
author = {De Bari, Daniele and Garaccione, Giacomo and Coppola, Riccardo and Torchiano, Marco and Ardito, Luca},
title = {Evaluating Large Language Models in Exercises of UML Class Diagram Modeling},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690741},
doi = {10.1145/3674805.3690741},
abstract = {Large Language Models (LLM) have rapidly affirmed in the latest years as a means to support or substitute human actors in a variety of tasks. LLM agents can generate valid software models, because of their inherent ability in evaluating textual requirements provided to them in the form of prompts. The goal of this work is to evaluate the capability of LLM agents to correctly generate UML class diagrams in activities of Requirements Modeling in the field of Software Engineering. Our aim is to evaluate LLMs in an educational setting, i.e., understanding how valuable are the results of LLMs when compared to results made by human actors, and how valuable can LLM be to generate sample solutions to provide to students. For that purpose, we collected 20 exercises from a diverse set of web sources and compared the models generated by a human and an LLM solver in terms of syntactic, semantic, pragmatic correctness, and distance from a provided reference solution. Our results show that the solutions generated by an LLM solver typically present a significantly higher number of errors in terms of semantic quality and textual difference against the provided reference solution, while no significant difference is found in syntactic and pragmatic quality. We can therefore conclude that, with a limited amount of errors mostly related to the textual content of the solution, UML diagrams generated by LLM agents have the same level of understandability as those generated by humans, and exhibit the same frequency in violating rules of UML Class Diagrams.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {393–399},
numpages = {7},
keywords = {Artificial Intelligence, Class Diagrams, Large Language Models, Software Modeling},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@article{10.1145/3733719,
author = {Kreikemeyer, Justin Noah and Jankowski, Mi\l{}osz and Wilsdorf, Pia and Uhrmacher, Adelinde M.},
title = {Using (Not-so) Large Language Models to Generate Simulation Models in a Formal DSL: A Study on Reaction Networks},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-3301},
url = {https://doi.org/10.1145/3733719},
doi = {10.1145/3733719},
abstract = {Formal languages are an integral part of modeling and simulation. They allow the distillation of knowledge into concise simulation models amenable to automatic execution, interpretation, and analysis. However, the arguably most humanly accessible means of expressing models is through natural language, which is not easily interpretable by computers. Here, we evaluate how a Large Language Model (LLM) might be used for formalizing natural language into simulation models. Existing studies only explored using very large LLMs, like the commercial GPT models, without fine-tuning model weights. To close this gap, we show how an open-weights, 7B-parameter Mistral model can be fine-tuned to translate natural language descriptions to reaction network models in a domain-specific language, offering a self-hostable, compute-, and memory efficient alternative. To this end, we develop a synthetic data generator to serve as the basis for fine-tuning and evaluation. Our quantitative evaluation shows that our fine-tuned Mistral model can recover the ground truth simulation model in up to  (84.5% )  of cases. In addition, our small-scale user study demonstrates the model’s practical potential for one-time generation as well as interactive modeling in various domains. While promising, in its current form, the fine-tuned small LLM cannot catch up with large LLMs. We conclude that higher-quality training data are required, and expect future small and open-source LLMs to offer new opportunities.},
note = {Just Accepted},
journal = {ACM Trans. Model. Comput. Simul.},
month = may,
keywords = {simulation model generation, natural language processing, language model, constrained decoding, knowledge extraction}
}

@article{10.1145/3737882,
author = {Salvi, Rohan Charudatt and Bosch, Nigel},
title = {Investigating Perception of Gender Stereotypes in Large Language Models: A Computational Grounded Theory Approach},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3737882},
doi = {10.1145/3737882},
abstract = {Artificial Intelligence has expanded its influence far beyond traditional boundaries in our society. One prominent application of artificial intelligence is the use of large language models, which have transcended their initial roles in high-tech industries and academic research and are now actively utilized by individual users. These models have continually improved over the years in their generative capabilities and performance across numerous tasks. However, they still pose a persistent risk of reproducing biases and stereotypes. Previous research has predominantly focused on quantitatively measuring biases in these large language models. In this study, we seek to assess not just the presence of bias itself, but the perception of stereotypes by these models via in-depth exploration of their responses. We demonstrate how the computational grounded theory framework, which integrates qualitative and quantitative approaches, can be applied in this context to assess the conceptualization of stereotypes. Furthermore, we contrast language model results with a survey of 400 human participants who also completed similar prompts as the model in order to understand people’s perception of gender stereotypes. The results indicate substantial similarities between language model and human perceptions of stereotypes, highlighting that a model’s perception stems from societal perception of stereotypes.},
note = {Just Accepted},
journal = {ACM J. Responsib. Comput.},
month = jun,
keywords = {Large language models, mixed methods, grounded theory, computational social science, LLM bias}
}

@article{10.1145/3736166,
author = {Shi, Yichen and TAO, ZHUOFU and Gao, YuHao and Zhou, Tianjia and Chang, Cheng and Wang, Yaxin and Chen, Bingyu and Zhang, Genhao and Liu, Alvin and Yu, Zhiping and Lin, Ting-Jung and He, Lei},
title = {AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3736166},
doi = {10.1145/3736166},
abstract = {High-performance analog and mixed-signal (AMS) circuits are mainly full-custom designed, which is time-consuming and labor-intensive. A significant portion of the effort is experience-driven, which makes the automation of AMS circuit design a formidable challenge. Large language models (LLMs) have emerged as powerful tools for Electronic Design Automation (EDA) applications, fostering advancements in the automatic design process for large-scale AMS circuits. However, the absence of high-quality datasets has led to issues such as model hallucination, which undermines the robustness of automatically generated circuit designs. To address this issue, this paper introduces AMSnet-KG, a dataset encompassing various AMS circuit schematics and netlists. We construct a knowledge graph with annotations on detailed functional and performance characteristics. Facilitated by AMSnet-KG, we propose an automated AMS circuit generation framework that utilizes the comprehensive knowledge embedded in LLMs. The flow first formulate a design strategy (e.g., circuit architecture using a number of circuit components) based on required specifications. Next, matched subcircuits are retrieved and assembled into a complete topology, and transistor sizing is obtained through Bayesian optimization. Simulation results of the netlist are automatically fed back to the LLM for further topology refinement, ensuring the circuit design specifications are met. We perform case studies of operational amplifier and comparator design to verify the automatic design flow from specifications to netlists with minimal human effort. The dataset used in this paper is available at https://ams-net.github.io/.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = may,
keywords = {EDA, LLM, AMSnet, Knowledge Graph, RAG, Topology Design}
}

@inproceedings{10.1145/3690624.3709225,
author = {Tong, Zhenyu and Qin, Chuan and Fang, Chuyu and Yao, Kaichun and Chen, Xi and Zhang, Jingshuai and Zhu, Chen and Zhu, Hengshu},
title = {From Missteps to Mastery: Enhancing Low-Resource Dense Retrieval through Adaptive Query Generation},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709225},
doi = {10.1145/3690624.3709225},
abstract = {Document retrieval, designed to recall query-relevant documents from expansive collections, is essential for information-seeking tasks, such as web search and open-domain question-answering. Advances in representation learning and pretrained language models (PLMs) have driven a paradigm shift from traditional sparse retrieval methods to more effective dense retrieval approaches, forging enhanced semantic connections between queries and documents and establishing new performance benchmarks. However, reliance on extensive annotated document-query pairs limits their competitiveness in low-resource scenarios. Recent research efforts employing the few-shot capabilities of large language models (LLMs) and prompt engineering for synthetic data generation have emerged as a promising solution. Nonetheless, these approaches are hindered by the generation of lower-quality data within the conventional dense retrieval training process. To this end, in this paper, we introduce iGFT, a framework aimed at enhancing low-resource dense retrieval by integrating a three-phase process --- Generation, Filtering, and Tuning --- coupled with an iterative optimization strategy. Specifically, we first employ supervised fine-tuning on limited ground truth data, enabling an LLM to function as the generator capable of producing potential queries from given documents. Subsequently, we present a multi-stage filtering module to minimize noise in the generated data while retaining samples poised to significantly improve the dense retrieval model's performance in the follow-up fine-tuning process. Furthermore, we design a novel iterative optimization strategy that dynamically optimizes the query generator for producing more informative queries, thereby enhancing the efficacy of the entire framework. Finally, extensive experiments conducted on a series of publicly available retrieval benchmark datasets have demonstrated the effectiveness of the proposed iGFT.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {1373–1384},
numpages = {12},
keywords = {dense retrieval, large language model, query generation},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@article{10.1145/3712005,
author = {Gao, Cuiyun and Hu, Xing and Gao, Shan and Xia, Xin and Jin, Zhi},
title = {The Current Challenges of Software Engineering in the Era of Large Language Models},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712005},
doi = {10.1145/3712005},
abstract = {With the advent of large language models (LLMs) in the AI area, the field of software engineering (SE) has also witnessed a paradigm shift. These models, by leveraging the power of deep learning and massive amounts of data, have demonstrated an unprecedented capacity to understand, generate, and operate programming languages. They can assist developers in completing a broad spectrum of software development activities, encompassing software design, automated programming, and maintenance, which potentially reduces huge human efforts. Integrating LLMs within the SE landscape (LLM4SE) has become a burgeoning trend, necessitating exploring this emergent landscape’s challenges and opportunities.The article aims at revisiting the software development lifecycle (SDLC) under LLMs, and highlighting challenges and opportunities of the new paradigm. The article first summarizes the overall process of LLM4SE, and then elaborates on the current challenges based on a through discussion. The discussion was held among more than 20 participants from academia and industry, specializing in fields such as SE and artificial intelligence. Specifically, we achieve 26 key challenges from seven aspects, including software requirement and design, coding assistance, testing code generation, code review, code maintenance, software vulnerability management, and data, training, and evaluation. We hope the achieved challenges would benefit future research in the LLM4SE field.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {127},
numpages = {30},
keywords = {Large Language Models, Challenges, LLM4SE}
}

@inproceedings{10.1145/3605098.3636030,
author = {Pham, Phuoc Van Long and Duc, Anh Vu and Hoang, Nhat Minh and Do, Xuan Long and Luu, Anh Tuan},
title = {ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating Pre-university Math Questions},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636030},
doi = {10.1145/3605098.3636030},
abstract = {Mathematical questioning is crucial for assessing students' problem-solving skills. Since manually creating such questions requires substantial effort, automatic methods have been explored. Existing state-of-the-art models rely on fine-tuning strategies and struggle to generate questions that heavily involve multiple steps of logical and arithmetic reasoning. Meanwhile, large language models (LLMs) such as ChatGPT have excelled in many NLP tasks involving logical and arithmetic reasoning. Nonetheless, their applications in generating educational questions are underutilized, especially in the field of mathematics. To bridge this gap, we take the first step to conduct an in-depth analysis of ChatGPT in generating pre-university math questions. Our analysis is categorized into two main settings: context-aware and context-unaware. In the context-aware setting, we evaluate ChatGPT on existing math question-answering benchmarks covering elementary, secondary, and ternary classes. In the context-unaware setting, we evaluate ChatGPT in generating math questions for each lesson from pre-university math curriculums that we crawl. Our crawling results in TopicMath1, a comprehensive and novel collection of pre-university math curriculums collected from 121 math topics and 428 lessons from elementary, secondary, and tertiary classes. Through this analysis, we aim to provide insight into the potential of ChatGPT as a math questioner1.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {65–73},
numpages = {9},
keywords = {ACM proceedings, LATEX, text tagging},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3674805.3690755,
author = {Aguiar, Lucas and Paixao, Matheus and Carmo, Rafael and Soares, Edson and Leal, Antonio and Freitas, Matheus and Gama, Eliakim},
title = {Multi-language Software Development in the LLM Era: Insights from Practitioners’ Conversations with ChatGPT},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690755},
doi = {10.1145/3674805.3690755},
abstract = {Non-trivial software systems are commonly developed using more than a single programming language. However, multi-language development is not straightforward. Nowadays, tools powered by Large Language Models (LLMs), such as ChatGPT, have been shown to successfully assist practitioners in several aspects of software development. This paper reports a preliminary study aimed to investigate to what extent ChatGPT is being used in multi-language development scenarios. Hence, we leveraged DevGPT, a dataset of conversations between software practitioners and ChatGPT. In total, we studied data from 3,584 conversations, comprising a total of 18,862 code snippets. Our analyses show that only 18.33% of the code snippets suggested by ChatGPT are written in the same programming language as the primary language in the repository where the conversation was shared. In an in-depth analysis, we observed expected scenarios, such as 31.54% of JavaScript snippets being suggested in CSS repositories However, we also unveiled surprising ones, such as Python snippets being largely suggested in C++ repositories. After a qualitative open card sorting of the conversations, we found that in 70% of them developers were asking for coding support while in 57% developers used ChatGPT as a tool to generate code. Our initial results indicate that not only LLMs are being used in multi-language development but also showcase the contexts in which such tools are assisting developers.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {489–495},
numpages = {7},
keywords = {ChatGPT, Empirical Studies, Multi-language Software Development},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3696443.3708944,
author = {Lee, Yoon Noh and Yu, Yongseung and Park, Yongjun},
title = {CUrator: An Efficient LLM Execution Engine with Optimized Integration of CUDA Libraries},
year = {2025},
isbn = {9798400712753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696443.3708944},
doi = {10.1145/3696443.3708944},
abstract = {Large Language Models (LLMs) have recently emerged as a state-of-the-art learning model with a wide range of applications in diverse computing environments. Among the various computational operations that comprise the LLM, the GEneral Matrix Multiplication (GEMM) operation is the most frequently utilized operation within the LLM. GEMM libraries such as cuBLAS and CUTLASS provide a variety of optimization techniques to achieve optimal GEMM performance in GPU-enabled computing environments. In particular, the CUTLASS open-source library for GPUs within the CUDA programming environment provides users with the capability to optimize templates for high performance. Previous research has demonstrated the effectiveness of CUTLASS-based GEMMs in improving the performance of real-world deep neural networks on various deep learning platforms. However, these studies have not considered different model parameters for modern LLMs nor have they explored the impact of diverse GPU computing environments.                                                                                                                                                                                                This paper presents CUrator, an efficient LLM execution engine that can achieve optimal end-to-end LLM performance using both cuBLAS and CUTLASS libraries on different GPUs for modern LLMs such as BERT, GPT, and Llama. CUrator first generates CUTLASS-/cuBLAS-friendly graph IRs of various LLMs on the TVM framework to maximize mapping coverage. On the CUTLASS mapping path, it performs a comprehensive search for programmable tuning parameters in the CUTLASS library with the objective of deriving optimal kernels for all GEMMs within each LLM. CUrator further introduces two optimization techniques: 1) build-time reduction key initialization support for CUTLASS Split-K GEMMs, and 2) Split-K support for CUTLASS Batch GEMMs. Finally, CUrator selects the best performing mapping path between cuBLAS and CUTLASS paths. The experimental results show that CUrator achieves inference speedups of 1.50\texttimes{} and 4.99\texttimes{}, respectively, for representative LLMs on the A100 GPU in the single and half precision, compared to the baseline. We strongly believe that the CUrator framework can provide the best direction for next-generation tuning frameworks by showing the maximum end-to-end performance of various LLMs on various GPUs.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {209–224},
numpages = {16},
keywords = {Compiler, GEMM, GPU, Large Language Model},
location = {Las Vegas, NV, USA},
series = {CGO '25}
}

@inproceedings{10.1145/3690712.3690726,
author = {Lee, Minhwa and Kim, Zae Myung and Khetan, Vivek and Kang, Dongyeop},
title = {Human-AI Collaborative Taxonomy Construction: A Case Study in Profession-Specific Writing Assistants},
year = {2024},
isbn = {9798400710315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690712.3690726},
doi = {10.1145/3690712.3690726},
abstract = {Large Language Models (LLMs) have assisted humans in several writing tasks, including text revision and story generation. However, their effectiveness in supporting domain-specific writing, particularly in business contexts, is relatively less explored. Our formative study with industry professionals revealed the limitations in current LLMs’ understanding of the nuances in such domain-specific writing. To address this gap, we propose an approach of human-AI collaborative taxonomy development to perform as a guideline for domain-specific writing assistants. This method integrates iterative feedback from domain experts and multiple interactions between these experts and LLMs to refine the taxonomy. Through larger-scale experiments, we aim to validate this methodology and thus improve LLM-powered writing assistance, tailoring it to meet the unique requirements of different stakeholder needs.},
booktitle = {Proceedings of the Third Workshop on Intelligent and Interactive Writing Assistants},
pages = {51–57},
numpages = {7},
keywords = {AI-assisted Writing, Human-AI Collaboration, Taxonomy},
location = {Honolulu, HI, USA},
series = {In2Writing '24}
}

@article{10.1145/3720546,
author = {Huang, Jiannan and Qu, Mengxue and Li, Longfei and Wei, Yunchao},
title = {AdGPT: Explore Meaningful Advertising with ChatGPT},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {4},
issn = {1551-6857},
url = {https://doi.org/10.1145/3720546},
doi = {10.1145/3720546},
abstract = {Advertising is pervasive in everyday life. Some advertisements are not as readily comprehensible, as they convey a deeper message or purpose, which is referred to as “meaningful advertising.” These ads often aim to create an emotional connection with the audience or promote a social cause. Developing a method for automatically understanding meaningful advertising would be advantageous for the dissemination and creation of such ads. However, current models of ad understanding primarily focus on the superficial aspects of images. In this article, we introduce AdGPT, a model that leverages visual expert analysis to guide Large Language Models (LLMs) in generating adaptive reasoning chains. Informed by these chains of thought, the model can intelligently comprehend meaningful ads regarding category, content, and sentiment. To assess the effectiveness of our approach, we extract a subset of meaningful ads from the widely used Pitt’s ad images for analysis. Beyond employing traditional ad understanding metrics to evaluate the LLMs’ comprehensive ad comprehension, we also develop a novel generative metric that aligns with user study evaluations for consistent performance assessment. Experiments show that our methods outperform existing state-of-the-art (SOTA) approaches directly linking visual expert models and LLMs and large-scale visual-language models. Code is available at .},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = apr,
articleno = {133},
numpages = {23},
keywords = {Meaningful Advertising Understanding, Large Language Models, Adaptive Reasoning Chain}
}

@inproceedings{10.1145/3637528.3671440,
author = {Bouneffouf, Djallel and F\'{e}raud, Rapha\"{e}l},
title = {A Tutorial on Multi-Armed Bandit Applications for Large Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671440},
doi = {10.1145/3637528.3671440},
abstract = {This tutorial offers a comprehensive guide on using multi-armed bandit (MAB) algorithms to improve Large Language Models (LLMs). As Natural Language Processing (NLP) tasks grow, efficient and adaptive language generation systems are increasingly needed. MAB algorithms, which balance exploration and exploitation under uncertainty, are promising for enhancing LLMs.The tutorial covers foundational MAB concepts, including the exploration-exploitation trade-off and strategies like epsilon-greedy, UCB (Upper Confidence Bound), and Thompson Sampling. It then explores integrating MAB with LLMs, focusing on designing architectures that treat text generation options as arms in a bandit problem. Practical aspects like reward design, exploration policies, and scalability are discussed.Real-world case studies demonstrate the benefits of MAB-augmented LLMs in content recommendation, dialogue generation, and personalized content creation, showing how these techniques improve relevance, diversity, and user engagement.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6412–6413},
numpages = {2},
keywords = {large language models, multi-armed bandit},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3701716.3715253,
author = {Gao, Jingtong and Du, Zhaocheng and Li, Xiaopeng and Wang, Yichao and Li, Xiangyang and Guo, Huifeng and Tang, Ruiming and Zhao, Xiangyu},
title = {SampleLLM: Optimizing Tabular Data Synthesis in Recommendations},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715253},
doi = {10.1145/3701716.3715253},
abstract = {Tabular data synthesis is crucial in machine learning, yet existing general methods-primarily based on statistical or deep learning models-are highly data-dependent and often fall short in recommender systems. This limitation arises from their difficulty in capturing complex distributions and understanding complicated feature relations from sparse and limited data, along with their inability to grasp semantic feature relations. Recently, Large Language Models (LLMs) have shown potential in generating synthetic data through few-shot learning and semantic understanding. However, they often suffer from inconsistent distribution and lack of diversity due to their inherent distribution disparity with the target dataset. To address these challenges and enhance tabular data synthesis for recommendation tasks, we propose a novel two-stage framework named SampleLLM to improve the quality of LLM-based tabular data synthesis for recommendations by ensuring better distribution alignment. In the first stage, SampleLLM employs LLMs with Chain-of-Thought prompts and diverse exemplars to generate data that closely aligns with the target dataset distribution, even when input samples are limited. The second stage uses an advanced feature attribution-based importance sampling method to refine feature relationships within the synthetic data, reducing any distribution biases introduced by the LLM. Experimental results on three recommendation datasets, two general datasets, and online deployment illustrate that SampleLLM significantly surpasses existing methods for recommendation tasks and holds promise for a broader range of tabular data scenarios.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {211–220},
numpages = {10},
keywords = {large language model, recommender system, tabular data generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3589335.3641247,
author = {Zhang, Jizhi and Bao, Keqin and Zhang, Yang and Wang, Wenjie and Feng, Fuli and He, Xiangnan},
title = {Large Language Models for Recommendation: Progresses and Future Directions},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641247},
doi = {10.1145/3589335.3641247},
abstract = {Large language models (LLMs) have significantly influenced recommender systems. Both academia and industry have shown growing interest in developing LLMs for recommendation purposes, an approach commonly referred to as LLM4Rec. This involves efforts such as utilizing LLMs for generative item retrieval and ranking, along with the potential for creating universal LLMs for varied recommendation tasks, signaling a possible paradigm shift in recommender systems. This tutorial is designed to review the progression of LLM4Rec and provide an in-depth analysis of the prevailing studies. We will discuss how LLMs advance recommender systems in model architecture, learning paradigms, and capabilities like conversation, generalization, planning, and content generation. Additionally, the tutorial will highlight open problems and challenges in this nascent field, addressing concerns related to trustworthiness, efficiency, online training, and recommendation data modeling. Concluding with a summary of the takeaways from previous research, the tutorial will suggest avenues for future investigations. Our aim is to help the audience grasp the developments in LLM4Rec, as well as to spark inspiration for further research. By doing so, we expect to contribute to the growth and success of LLM4Rec, possibly leading to a fundamental change in recommender paradigms.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1268–1271},
numpages = {4},
keywords = {generative models, generative recommendation, large language models, recommender systems},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1145/3735140,
author = {Sprenkamp, Kilian and Eckhardt, Sven and Zavolokina, Liudmila and Schwabe, Gerhard},
title = {From Information-Seeking to Information-Asking: Designing RefuGPT, a Chatbot for Ukrainian Refugees in Switzerland},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3735140},
doi = {10.1145/3735140},
abstract = {A key challenge for refugees is accessing relevant information about their host country. However, refugees often face disorientation during their information-seeking process. Disorientation is driven by language barriers, a digital divide, high urgency, and an evolving situation, which hinders the refugees’ ability to access information. Addressing the issue of disorientation, we propose an IT artifact, i.e., a chatbot called RefuGPT, designed through a rigorous Design Science Research Methodology. RefuGPT leverages the power of a large language model (LLM), GPT-4 while accessing two distinct sources of information, i.e., official and community-based information utilizing retrieval augmented generation and prompt-based learning (Figure 1). We assess RefuGPT's usefulness and usability through an ex-post evaluation in a naturalistic setting with Ukrainian refugees. Hence, we show that our bi-layered LLM-based chatbot can effectively assist refugees. They thus move from information-seeking to a more effortless information-asking. Based on those insights, we propose design principles as well as practical recommendations for refugee chatbots.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = may,
keywords = {Large Language Model, Refugee Management, Chatbot Design}
}

@inproceedings{10.5555/3709347.3743948,
author = {Kute, Dattatray Vishnu and Xu, Zihao and Li, Yuekang and Rabhi, Fethi},
title = {Truman: A Large Language Model-based Multi-agent Simulator for Synthetic Money Laundering Data Generation},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Money laundering (ML) facilitates the cross-border movement of illicit funds, enabling organized crime by disguising the origins of illegal money. Financial institutions face significant challenges in combating it, primarily due to barriers in adopting advanced technologies such as machine learning, caused by restricted access to sensitive transaction data. Existing synthetic datasets often lack critical customer information and realism, reducing their utility for ML detection. This study presents Truman, an innovative data generator that leverages Large Language Model (LLM) based agents to create realistic financial transaction data, incorporating simulation of ML patterns. Expert validation confirms the dataset's quality and applicability for anti-money laundering research.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {2594–2596},
numpages = {3},
keywords = {financial crime, financial transaction data, llm, money laundering, multi-agent simulator, openai, synthetic data generator},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.5555/3709347.3743976,
author = {Mohammed, Hamza and Yin, Hang and Boyapati, Sai Chand},
title = {Context Adaptive Memory-Efficient LLM Inference for Edge Multi-Agent Systems},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Large Language Models (LLMs) excel at multi-document QA, summarization, code generation, and other language-intensive tasks, yet they demand substantial memory resources for storing key-value (KV) caches and processing attention in long-context scenarios. These requirements often prohibit on-device or edge deployments in multi-agent systems (MAS), where multiple agents share or update contextual information and need efficient inference pipelines. We present CASK (Context-Adaptive Sparse Key-value), an inference-time strategy that reduces memory usage while preserving strong performance on extended contexts. CASK addresses this challenge with two complementary mechanisms: a dynamic sparse attention module-a lightweight, meta-learned component-that identifies the most relevant context tokens, and an adaptive KV-cache compression technique that dynamically quantizes and prunes less critical key-value pairs based on usage frequency and recency. These innovations enable near-lossless performance on long-context tasks while cutting memory usage by up to 40% and boosting inference speed by as much as 20%. Evaluations on LongBench [2] and multi-agent benchmarks show that CASK maintains over 95% of baseline accuracy while allowing more agents or extended histories under tight GPU budgets. Integration into a vision-language agent for collaborative, multimodal contexts underscores its practicality for resource-constrained LLM deployments in MAS.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {2678–2680},
numpages = {3},
keywords = {active learning, caching and paging algorithms, computer vision, dimensionality reduction and manifold learning, heuristic function construction, multi-agent learning, multi-agent reinforcement learning, multi-agent systems, natural language generation, neural networks, online learning algorithms, reinforcement learning, supervised learning},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3589334.3645574,
author = {Wu, Songhao and Tu, Quan and Liu, Hong and Xu, Jia and Liu, Zhongyi and Zhang, Guannan and Wang, Ran and Chen, Xiuying and Yan, Rui},
title = {Unify Graph Learning with Text: Unleashing LLM Potentials for Session Search},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645574},
doi = {10.1145/3589334.3645574},
abstract = {Session search involves a series of interactive queries and actions to fulfill user's complex information need. Current strategies typically prioritize sequential modeling for deep semantic understanding, overlooking the graph structure in interactions. While some approaches focus on capturing structural information, they use a generalized representation for documents, neglecting the word-level semantic modeling. In this paper, we propose Symbolic Graph Ranker (SGR), which aims to take advantage of both text-based and graph-based approaches by leveraging the power of recent Large Language Models (LLMs). Concretely, we first introduce a set of symbolic grammar rules to convert session graph into text. This allows integrating session history, interaction process, and task instruction seamlessly as inputs for the LLM. Moreover, given the natural discrepancy between LLMs pre-trained on textual corpora, and the symbolic language we produce using our graph-to-text grammar, our objective is to enhance LLMs' ability to capture graph structures within a textual format. To achieve this, we introduce a set of self-supervised symbolic learning tasks including link prediction, node content generation, and generative contrastive learning, to enable LLMs to capture the topological information from coarse-grained to fine-grained. Experiment results and comprehensive analysis on two benchmark datasets, AOL and Tiangong-ST, confirm the superiority of our approach. Our paradigm also offers a novel and effective methodology that bridges the gap between traditional search strategies and modern LLMs.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1509–1518},
numpages = {10},
keywords = {document ranking, large language model, session search},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3613905.3651057,
author = {Lyu, Yao and Zhang, He and Niu, Shuo and Cai, Jie},
title = {A Preliminary Exploration of YouTubers' Use of Generative-AI in Content Creation},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3651057},
doi = {10.1145/3613905.3651057},
abstract = {Content creators increasingly utilize generative artificial intelligence (Gen-AI) on platforms such as YouTube, TikTok, Instagram, and various blogging sites to produce imaginative images, AI-generated videos, and articles using Large Language Models (LLMs). Despite its growing popularity, there remains an underexplored area concerning the specific domains where AI-generated content is being applied, and the methodologies content creators employ with Gen-AI tools during the creation process. This study initially explores this emerging area through a qualitative analysis of 68 YouTube videos demonstrating Gen-AI usage. Our research focuses on identifying the content domains, the variety of tools used, the activities performed, and the nature of the final products generated by Gen-AI in the context of user-generated content.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {20},
numpages = {7},
keywords = {Affiliated Marketing, Artificial Intelligence, Content Creation, Content Creator, Generative AI, Professional Development, User-generated Content, YouTube},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3613905.3650860,
author = {Schuller, Andreas and Janssen, Doris and Blumenr\"{o}ther, Julian and Probst, Theresa Maria and Schmidt, Michael and Kumar, Chandan},
title = {Generating personas using LLMs and assessing their viability},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650860},
doi = {10.1145/3613905.3650860},
abstract = {User personas, reflecting human characteristics, play a crucial role in human-centered design, contributing significantly to ideation and product design processes. However, expressing a diverse range of product-related human characterizations poses a challenging and time-consuming task for UX experts. This paper explores the utilization of Large Language Models (LLMs) to streamline the generation of personas, thereby enhancing the efficiency of UX researchers and providing inspiration for stakeholder discussions. Towards this objective, we devised strategic prompts and guidelines involving stakeholders and potential product features, resulting in the creation of candidate user personas. These personas were then compared with those crafted by human experts in a remote study involving 11 participants assessing 16 personas each. The analysis revealed that LLM-generated personas were indistinguishable from human-written personas, demonstrating similar quality and acceptance.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {179},
numpages = {7},
keywords = {automated persona generation, generative AI, innovation processes, personas, user centered design},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3696410.3714608,
author = {Dong, Qian and Ai, Qingyao and Wang, Hongning and Liu, Yiding and Li, Haitao and Su, Weihang and Liu, Yiqun and Chua, Tat-Seng and Ma, Shaoping},
title = {Decoupling Knowledge and Context: An Efficient and Effective Retrieval Augmented Generation Framework via Cross Attention},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714608},
doi = {10.1145/3696410.3714608},
abstract = {Retrieval-Augmented Generation (RAG) systems have become a crucial tool to augment large language models (LLMs) with external knowledge for better task performance. However, existing traditional RAG methods inject knowledge directly into the context, resulting in several limitations. First, these methods highly rely on the in-context learning capability of LLMs, which often leads to excessively long contexts. This is inefficient due to the quadratic complexity of self-attention, leading to significant increase in inference time. Second, the extended context and the nature of self-attention can cause the LLMs to lose important information in the context, thereby degrading the original capabilities of LLMs. Third, the effectiveness of knowledge injection is perturbed by the permutation of knowledge within the extended context, reducing the robustness of existing RAG methods. To tackle the above problems, we propose DecoupledRAG, a method that decouples external knowledge from the context within the RAG framework. Specifically, we introduce a cross-attention based method that injects retrieved knowledge directly into the inference process of LLM on the fly, without modifying its parameters or the input context, so that the external knowledge can be utilized robustly in a permutation-independent manner. To the best of our knowledge, this is the first work that explore how to utilize cross-attention to inject knowledge with low training cost in decoder-only LLM era. By leveraging cross-attention operation, DecoupledRAG enables seamless knowledge aggregation without creating extended context. Experimental results demonstrate that our method could achieve high efficiency while maintaining strong performance, which indicates that RAG frameworks have the potential to benefit further from more knowledge.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4386–4395},
numpages = {10},
keywords = {knowledge injection, language model, retrieval augmented generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3708036.3708083,
author = {Hu, Zhicong and Li, Yitong and Shen, Zhiyong},
title = {Jailbreak attack of large language model based on scene construction},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708083},
doi = {10.1145/3708036.3708083},
abstract = {The jailbreaking of large language models (LLMs) has recently garnered significant attention. Before releasing the model, extensive fine-tuning was conducted using RLHF (i.e., optimizing language models through reinforcement learning from human feedback) and other methods to ensure its behavior aligns with human values. However, even aligned LLMs can be maliciously manipulated, resulting in unintended behavior, termed "jailbreaking." In this study, inspired by manually crafted jailbreaking prompts, we introduce the Scenario Construction Attack (SC-Attack) and develop three seed templates for jailbreaking based on scenario construction, generating additional templates using the GPT-4o context. Additionally, to enhance the jailbreaking of aligned large models, we utilize Energy-constrained Decoding with Langevin Dynamics (COLD) to regulate the generation of adversarial suffixes for the attack. We define this combined attack as SC-COLD. Extensive experiments revealed that SC-Attack alone can achieve a 100% success rate on closed-source models like GPT-3.5 and GPT-4o, with the output content being more toxic. It also achieved a success rate of over 90% on aligned open-source models such as LLM (Llama2, Gemma). The extensive experiments demonstrate that SC-COLD possesses broad applicability, robust controllability, and a high success rate.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {272–276},
numpages = {5},
keywords = {Generative AI safety, Jailbreak attack, Large language models, Natural language processing},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3728725.3728762,
author = {Ding, Yuze and Zhang, Shibin},
title = {Dynamic Semantic-Constrained Adversarial Training and Defensing: A Reinforcement Learning Framework for LLM-Generated Fake Information Detection},
year = {2025},
isbn = {9798400713453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3728725.3728762},
doi = {10.1145/3728725.3728762},
abstract = {With the development of Large Language Models (LLMs) such as DeepSeek and GPT-4, the cost of generating false information has decreased dramatically, making detection more difficult to recognize. Traditional approaches, such as GPT-4o and chain-of-thought (CoT) frameworks, having low accuracy or efficiency. To better solve these problems, this paper introduces Dynamic Semantic Structure Rule Constrained Adversarial Training (DSC-AT), which uses balanced semantic fidelity and steganography to enhance adversarial sample optimisation, achieving an 82% deception rate. Meanwhile, the Semantic-Robust Unified Architecture (SRUA) scheme integrates text classification layer, logical verification layer and uncertainty detection layer to improve accuracy. Besides, to better train the model, we provide the Content Reinforcement Learning-based Tactical Adversarial Defence (RL-TAD) model simulates the interaction between the attacker and the defender, improves the training strategy by using backpropagation descent. Experimental results show that contrast to CoT, SRUA improves the detection accuracy to 92.1 percent and reduces the false alarm rate by 65 percent, which provided an efficient and flexible solution for identifying LLM-generated misinformation.},
booktitle = {Proceedings of the 2025 2nd International Conference on Generative Artificial Intelligence and Information Security},
pages = {237–241},
numpages = {5},
keywords = {Chain of Thought (CoT), DSC-AT, Large language models (LLMs), RL-TAD, SRUA},
location = {
},
series = {GAIIS '25}
}

@inproceedings{10.1145/3706598.3713375,
author = {Shen, Hanshu and Shen, Lyukesheng and Wu, Wenqi and Zhang, Kejun},
title = {IdeationWeb: Tracking the Evolution of Design Ideas in Human-AI Co-Creation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713375},
doi = {10.1145/3706598.3713375},
abstract = {Due to the remarkable content generation capabilities, large language models (LLMs) have demonstrated potential in supporting early-stage conceptual design. However, current interaction paradigms often struggle to effectively facilitate multi-round idea exploration and selection, leading to random outputs, unclear iterations, and cognitive overload. To address these challenges, we propose a human-AI co-ideation framework aimed at tracking the evolution of design ideas. This framework leverages a structured idea representation, an analogy-based reasoning mechanism and interactive visualization techniques. It guides both designers and AI to systematically explore design spaces. We also develop a prototype system, IdeationWeb, which integrates an intuitive, mind map-like visual interface and interactive methods to support co-ideation. Our user study validates the framework’s feasibility, demonstrating enhanced collaboration and creativity between humans and AI. Furthermore, we identified collaborative design patterns from user behaviors, providing valuable insights for future human-AI interaction design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {146},
numpages = {19},
keywords = {Human-AI co-ideation, Human-AI interaction, Creativity support, Large language models, Design space},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3691621.3694934,
author = {Siddiq, Mohammed Latif and da Silva Santos, Joanna Cecilia and Devareddy, Sajith and Muller, Anna},
title = {SALLM: Security Assessment of Generated Code},
year = {2024},
isbn = {9798400712494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691621.3694934},
doi = {10.1145/3691621.3694934},
abstract = {With the growing popularity of Large Language Models (LLMs) in software engineers' daily practices, it is important to ensure that the code generated by these tools is not only functionally correct but also free of vulnerabilities. Although LLMs can help developers to be more productive, prior empirical studies have shown that LLMs can generate insecure code. There are two contributing factors to the insecure code generation. First, existing datasets used to evaluate LLMs do not adequately represent genuine software engineering tasks sensitive to security. Instead, they are often based on competitive programming challenges or classroom-type coding tasks. In real-world applications, the code produced is integrated into larger codebases, introducing potential security risks. Second, existing evaluation metrics primarily focus on the functional correctness of the generated code while ignoring security considerations. Therefore, in this paper, we described Sallm, a framework to benchmark LLMs' abilities to generate secure code systematically. This framework has three major components: a novel dataset of security-centric Python prompts, configurable assessment techniques to evaluate the generated code, and novel metrics to evaluate the models' performance from the perspective of secure code generation.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering Workshops},
pages = {54–65},
numpages = {12},
keywords = {security evaluation, large language models, pre-trained transformer model, metrics},
location = {Sacramento, CA, USA},
series = {ASEW '24}
}

@article{10.1145/3660807,
author = {Kou, Bonan and Chen, Shengmai and Wang, Zhijie and Ma, Lei and Zhang, Tianyi},
title = {Do Large Language Models Pay Similar Attention Like Human Programmers When Generating Code?},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660807},
doi = {10.1145/3660807},
abstract = {Large Language Models (LLMs) have recently been widely used for code generation. Due to the complexity and opacity of LLMs, little is known about how these models generate code. We made the first attempt to bridge this knowledge gap by investigating whether LLMs attend to the same parts of a task description as human programmers during code generation. An analysis of six LLMs, including GPT-4, on two popular code generation benchmarks revealed a consistent misalignment between LLMs' and programmers' attention. We manually analyzed 211 incorrect code snippets and found five attention patterns that can be used to explain many code generation errors. Finally, a user study showed that model attention computed by a perturbation-based method is often favored by human programmers. Our findings highlight the need for human-aligned LLMs for better interpretability and programmer trust.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {100},
numpages = {24},
keywords = {Attention, Code Generation, Large Language Models}
}

@inproceedings{10.1145/3644116.3644294,
author = {Zhu, Jinyang and Gong, Qingyue and Zhou, Chunfang and Luan, Huidan},
title = {ZhongJing: A Locally Deployed Large Language Model for Traditional Chinese Medicine and Corresponding Evaluation Methodology: A Large Language Model for data fine-tuning in the field of Traditional Chinese Medicine, and a new evaluation method called TCMEval are proposed},
year = {2024},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644116.3644294},
doi = {10.1145/3644116.3644294},
abstract = {The success of ChatGPT has showcased the potential applications of Large Language Models (LLMs) in the field of Traditional Chinese Medicine (TCM), encompassing areas such as medical diagnosis, adjunctive therapy, and TCM talent cultivation. However, the current challenges, including hardware constraints, insufficient model domain knowledge, and difficulties in domain-specific evaluation, have constrained the fusion of LLMs with TCM. In an attempt to address these issues, this paper introduces ZhongJing, a domain-specific LLM fine-tuned within the domain of TCM, capable of generating responses at a rate of 8 tokens per second, smoothly operating on local personal computers. To assess the model's domain expertise, this paper introduces the TCMEval evaluation method, designed concerning medical students' exams. Experimental results demonstrate that ZhongJing achieves a 6.49 TCMEval Score improvement over Chinese-LLaMA2 in the field of TCM, indicating the model's ability to generate more specialized responses compared to baseline models.},
booktitle = {Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
pages = {1036–1042},
numpages = {7},
location = {Chengdu, China},
series = {ISAIMS '23}
}

@inproceedings{10.1145/3701716.3715457,
author = {Xu, Jun and Sun, Mengshu and Zhang, Zhiqiang and Zhou, Jun},
title = {MAQInstruct: Instruction-based Unified Event Relation Extraction},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715457},
doi = {10.1145/3701716.3715457},
abstract = {Extracting event relations that deviate from known schemas has proven challenging for previous methods based on multi-class classification, MASK prediction, or prototype matching. Recent advancements in large language models have shown impressive performance through instruction tuning. Nevertheless, in the task of event relation extraction, instruction-based methods face several challenges: there are a vast number of inference samples, and the relations between events are non-sequential. To tackle these challenges, we present an improved instruction-based event relation extraction framework named MAQInstruct. Firstly, we transform the task from extracting event relations using given event-event instructions to selecting events using given event-relation instructions, which reduces the number of samples required for inference. Then, by incorporating a bipartite matching loss, we reduce the dependency of the instruction-based method on the generation sequence. Our experimental results demonstrate that MAQInstruct significantly improves the performance of event relation extraction across multiple LLMs.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1441–1445},
numpages = {5},
keywords = {information extraction, information retrieval, relation extraction},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3709026.3709115,
author = {Tang, Xuehai and Xiao, Wenjie and Yao, Zhongjiang and Han, Jizhong},
title = {SwordEcho: A LLM Jailbreaking Optimization Strategy Driven by Reinforcement Learning},
year = {2025},
isbn = {9798400718182},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709026.3709115},
doi = {10.1145/3709026.3709115},
abstract = {Warning: This paper may contain potentially offensive model inputs or outputs.With the rapid development of Large Language Models (LLMs), inherent security risks have become increasingly evident, particularly their capability to generate harmful content. As an effective tool for revealing potential vulnerabilities in LLMs within the context of red teaming, jailbreak attacks are widely used to assess the content safety defense levels of LLMs. However, existing open-source jailbreak prompts often lack sufficient readability and effectiveness, failing to comprehensively evaluate the security flaws of models and inadequately exposing the potential risks of LLMs. To address this issue, this paper introduces an enhanced jailbreak prompt generation method called "SwordEcho," which improves the readability and aggressiveness of jailbreak prompt words to more comprehensively evaluate model vulnerabilities. SwordEcho employs a multi-faceted reinforcement learning reward mechanism to finely tune the attack model, thereby effectively generating high-quality jailbreak prompts. To verify the transferability and generalization capabilities of SwordEcho, this study conducted jailbreak tests involving eleven different risk scenarios across six open-source LLMs and three commercial model APIs. The results indicate that, compared with existing mainstream jailbreak attack strategies, SwordEcho demonstrates higher Attack Success Rates (ASRs) across different target models.},
booktitle = {Proceedings of the 2024 8th International Conference on Computer Science and Artificial Intelligence},
pages = {183–190},
numpages = {8},
keywords = {Large Language Models, Jailbreak attacks, Red teaming, Reinforcement learning},
location = {
},
series = {CSAI '24}
}

@inproceedings{10.1145/3713081.3732928,
author = {He, Shuai and Yan, Hao and Li, Wenke and Hong, Sheng and Guo, Xiaowei and Liu, Xiaofan and Fu, Cai},
title = {From Large Language Models to Adversarial Malware: How far are we},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3732928},
doi = {10.1145/3713081.3732928},
abstract = {Large Language Models (LLMs) have achieved notable progress in fields including natural language processing, cyber threat detection, and automated penetration testing, increasingly being applied in practical settings. However, the rapid advancement of these models has also led to their potential misuse, posing new challenges to cyberspace security. Security incidents have already been reported in areas such as phishing attacks and disinformation campaigns. Nevertheless, the progress and potential impact of LLMs in generating adversarial malware remain underexplored. This study systematically investigates the evasion capability of adversarial malware generated by LLMs. By integrating chain of thought into a Markov process and designing prompt based state transition functions and reward mechanisms, this research evaluates the effectiveness and efficiency against mainstream static detection methods on a dataset comprising over 2,000 real-world malware samples. Experimental results demonstrate an average evasion rate of 89.92% across 12 commercial antivirus engines on VirusTotal. The findings reveal that individuals with minimal technical expertise and basic natural language skills can generate malware that evades static detection, which underscores potential vulnerabilities in current cyberspace defense and detection systems regarding adversarial malware countermeasures.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {178–182},
numpages = {5},
keywords = {large language models, adversarial malware, static detection},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@inproceedings{10.1109/ASP-DAC58780.2024.10473904,
author = {Lu, Yao and Liu, Shang and Zhang, Qijun and Xie, Zhiyao},
title = {RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model},
year = {2024},
isbn = {9798350393545},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASP-DAC58780.2024.10473904},
doi = {10.1109/ASP-DAC58780.2024.10473904},
abstract = {Inspired by the recent success of large language models (LLMs) like ChatGPT, researchers start to explore the adoption of LLMs for agile hardware design, such as generating design RTL based on natural-language instructions. However, in existing works, their target designs are all relatively simple and in a small scale, and proposed by the authors themselves, making a fair comparison among different LLM solutions challenging. In addition, many prior works only focus on the design correctness, without evaluating the design qualities of generated design RTL. In this work, we propose an open-source benchmark named RTLLM, for generating design RTL with natural language instructions. To systematically evaluate the auto-generated design RTL, we summarized three progressive goals, named syntax goal, functionality goal, and design quality goal. This benchmark can automatically provide a quantitative evaluation of any given LLM-based solution. Furthermore, we propose an easy-to-use yet surprisingly effective prompt engineering technique named self-planning, which proves to significantly boost the performance of GPT-3.5 in our proposed benchmark.},
booktitle = {Proceedings of the 29th Asia and South Pacific Design Automation Conference},
pages = {722–727},
numpages = {6},
location = {Incheon, Republic of Korea},
series = {ASPDAC '24}
}

@inproceedings{10.1145/3677846.3677855,
author = {Shen, Ming and Huang, Gang and Wu, Yuxuan and Song, Shuyi and Zhou, Sheng and Li, Liangcheng and Yu, Zhi and Wang, Wei and Bu, Jiajun},
title = {Making Accessible Movies Easily: An Intelligent Tool for Authoring and Integrating Audio Descriptions to Movies},
year = {2024},
isbn = {9798400710308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677846.3677855},
doi = {10.1145/3677846.3677855},
abstract = {Blind and visually impaired (BVI) individuals encounter significant challenges in perceiving the visual content of movies. Audio descriptions (AD) are inserted into speech gaps to describe visual content and storyline for BVI individuals. However, the processes of authoring and integrating AD are laborious, involving tasks such as identifying speech gaps, authoring AD scripts, dubbing, and integrating them into the movie. To streamline these processes, we introduce EasyAD, an intelligent tool to automate these processes. EasyAD utilizes character recognition technology to identify speech gaps and utilizes speech synthesis technology for AD dubbing. EasyAD addresses the misidentification of the background music of existing methods, and for the first time applies a multimodal large language model in the tool to generate AD. EasyAD is currently operational at the China Braille Library and we invite 6 AD authors for a user study. The results demonstrate that with the use of EasyAD, the processing time for a medium-difficulty movie is reduced by nearly 50%, reducing the workload of AD authors and accelerating accessible movie production in China. EasyAD leverages the advantages of AI technologies, especially multimodal large language models, for accessible movie production and benefits BVI individuals.},
booktitle = {Proceedings of the 21st International Web for All Conference},
pages = {160–164},
numpages = {5},
keywords = {accessible movie, accessibility, blind and visually impaired, audio descriptions, multimodal large language model},
location = {Singapore, Singapore},
series = {W4A '24}
}

@inproceedings{10.1145/3701716.3717819,
author = {Jia, Runsong and Zhang, Bowen and M\'{e}ndez, Sergio Jos\'{e} Rodr\'{\i}guez and Omran, Pouya G.},
title = {StructRAG: Structure-Aware RAG Framework with Scholarly Knowledge Graph for Diverse Question Answering},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717819},
doi = {10.1145/3701716.3717819},
abstract = {Recent advances in Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) have shown promise in academic question answering. However, existing approaches often fail to fully utilize document structural information and lack diversity in retrieved contexts. This paper presents StructRAG, a structure-aware RAG framework that leverages scholarly knowledge graphs for enhanced question answering. Our framework features three key innovations: (1) an automated knowledge graph construction pipeline based on Deep Document Model (DDM) that preserves document hierarchical structure, (2) a structure-aware retrieval mechanism that combines semantic relevance with source diversity, and (3) a context-enhanced generation approach that integrates structural metadata for improved answer synthesis. Experimental results on 329 computer science papers demonstrate that StructRAG significantly outperforms vanilla RAG baseline. While maintaining comparable semantic accuracy (91% vs 90%), our approach achieves substantially higher diversity in generated answers (Distinct-1: 62% vs 52%, Distinct-2: 89% vs 78%) and better answer quality across all metrics, with notable improvements in relevance (29%) and readability (36.5%). These results demonstrate that StructRAG effectively enhances both the diversity and quality of academic question answering.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2567–2573},
numpages = {7},
keywords = {deep document model, knowledge graph, knowledge graph construction, large language models, retrieval-augmented generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3626253.3635400,
author = {Hurley, Ethan and Okyere-Badoo, Joel},
title = {A Comparative Study of Few-Shot vs. Zero-Shot Prompting to Generate Quick and Useful Responses to Students' Periodic Reflections},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635400},
doi = {10.1145/3626253.3635400},
abstract = {Our study investigates the effectiveness of leveraging Large Language Models (LLMs), such as GPT-3.5, to generate responses to student reflections. Acknowledging the intensive nature of manually handling reflections, our investigation centers on crafting prompts to automate reflection response generation. Driven by fast and meaningful response generation to student reflections, we explored both Zero-Shot learning (ZSL) and Few-Shot learning (FSL) methodologies. Our research meticulously examined the facets of each approach, highlighting the significance of consistent and meaningful responses.The Few-Shot prompting approach involves creating a fundamental prompt based on reflection questions and desired responses, striving for consistency while facing challenges such as GPT-3.5 computational time and issues related to content "hallucinations." In contrast, Zero-Shot prompting utilizes the base prompt and response without the assistance of examples. The evaluation process entails a meticulous examination of the quality of GPT-3.5 responses compared to the original student reflections.In the future, our study foresees integrating our devised prompting techniques as a resource for educators to promptly grasp students' learning concerns and issues. Despite challenges, Few-Shot prompting stands out as the more reliable and relevant approach, particularly in the context of email-based formats. As Machine Learning and AI continue to advance, overcoming challenges and adjusting to fluctuations in student emotions and content remains a pivotal factor in fully harnessing the capabilities of LLMs for automating the generation of responses to student reflections.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1881},
numpages = {1},
keywords = {artificial intelligence (ai), few-shot learning (fsl), large language models (llms), student reflections, zero-shot learning (zsl)},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3706598.3713376,
author = {Zhao, Maozheng and Huang, Michael Xuelin and Huang, Nathan G and Cai, Shanqing and Huang, Henry and Huang, Michael G and Zhai, Shumin and Ramakrishnan, IV and Bi, Xiaojun},
title = {Tap&amp;Say: Touch Location-Informed Large Language Model for Multimodal Text Correction on Smartphones},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713376},
doi = {10.1145/3706598.3713376},
abstract = {While voice input offers a convenient alternative to traditional text editing on mobile devices, practical implementations face two key challenges: 1) reliably distinguishing between editing commands and content dictation, and 2) effortlessly pinpointing the intended edit location. We propose Tap&amp;Say, a novel multimodal system that combines touch interactions with Large Language Models (LLMs) for accurate text correction. By tapping near an error, users signal their edit intent and location, addressing both challenges. Then, the user speaks the correction text. Tap&amp;Say utilizes the touch location, voice input, and existing text to generate contextually relevant correction suggestions. We propose a novel touch location-informed attention layer that integrates the tap location into the LLM’s attention mechanism, enabling it to utilize the tap location for text correction. We fine-tuned the touch location-informed LLM on synthetic touch locations and correction commands, achieving significantly higher correction accuracy than the state-of-the-art method VT&nbsp;[45]. A 16-person user study demonstrated that Tap&amp;Say outperforms VT &nbsp;[45] with (16.4%) shorter task completion time and (47.5%) fewer keyboard clicks and is preferred by users.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {649},
numpages = {17},
keywords = {LLMs, text correction, voice input, multi-modal},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3649217.3653587,
author = {Denny, Paul and Smith, David H. and Fowler, Max and Prather, James and Becker, Brett A. and Leinonen, Juho},
title = {Explaining Code with a Purpose: An Integrated Approach for Developing Code Comprehension and Prompting Skills},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653587},
doi = {10.1145/3649217.3653587},
abstract = {Reading, understanding and explaining code have traditionally been important skills for novices learning programming. As large language models (LLMs) become prevalent, these foundational skills are more important than ever given the increasing need to understand and evaluate model-generated code. Brand new skills are also needed, such as the ability to formulate clear prompts that can elicit intended code from an LLM. Thus, there is great interest in integrating pedagogical approaches for the development of both traditional coding competencies and the novel skills required to interact with LLMs. One effective way to develop and assess code comprehension ability is with "Explain in plain English'' (EiPE) questions, where students succinctly explain the purpose of a fragment of code. However, grading EiPE questions has always been difficult given the subjective nature of evaluating written explanations and this has stifled their uptake. In this paper, we explore a natural synergy between EiPE questions and code-generating LLMs to overcome this limitation. We propose using an LLM to generate code based on students' responses to EiPE questions -- not only enabling EiPE responses to be assessed automatically, but helping students develop essential code comprehension and prompt crafting skills in parallel. We investigate this idea in an introductory programming course and report student success in creating effective prompts for solving EiPE questions. We also examine student perceptions of this activity and how it influences their views on the use of LLMs for aiding and assessing learning.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {283–289},
numpages = {7},
keywords = {code comprehension, cs1, eipe, explain in plan english, introductory programming, large language models, llms, prompting},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3706599.3719850,
author = {Tian, Runyan and Tang, Jiamu and Li, Zhuying},
title = {Dreamory: AI-Powered Bedtime Storytelling for Emotional Reframing Before In-Sleep Memory Consolidation},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719850},
doi = {10.1145/3706599.3719850},
abstract = {This paper presents Dreamory, an AI-powered storytelling system designed to influence emotional memory consolidation during sleep through pre-sleep narrative interventions. Drawing from the Meaning-Making Model, Dreamory transforms users’ daily emotional experiences into personalized bedtime stories that promote positive reframing. The system enables users to journal their emotional experiences via letter writing and leverages a large language model (LLM) to analyze emotional content and generate narratives with meaning-making strategies. A one-week pilot study with four participants demonstrated Dreamory’s potential to enhance pre-sleep emotional regulation and foster positive reframing of experiences. Participants also reported a perceived improvement in self-efficacy and sleep quality. This work proposes an inspiring approach that leverages generative AI for positive meaning-making of emotional memory, promoting pre-sleep emotional shifts, fostering positive mindsets, and enhancing emotional memory consolidation to support mental well-being.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {203},
numpages = {8},
keywords = {AI-Powered Interventions, Personalized Storytelling, Emotional Memory Consolidation, Pre-Sleep Emotional Regulation, Meaning-Making, Narrative Therapy},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3643651.3659898,
author = {Boumber, Dainis and Tuck, Bryan E. and Verma, Rakesh M. and Qachfar, Fatima Zahra},
title = {LLMs for Explainable Few-shot Deception Detection},
year = {2024},
isbn = {9798400705564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643651.3659898},
doi = {10.1145/3643651.3659898},
abstract = {This study investigates the effectiveness of Large Language Models (LLMs) in detecting deception using a Retrieval Augmented Generation (RAG) framework for few-shot learning in domain-agnostic settings. Our approach combines the sophisticated reasoning capabilities and extensive knowledge base of LLMs to identify deceptive statements across various contexts, with a focus on the explainability of the detection process. This emphasis on explainability enables a detailed analysis of the model's methodologies in distinguishing between truthful and deceptive statements. Additionally, we examine the impact of different definitions of deception, from overt falsehoods to subtle misrepresentations, on the model's accuracy. Our main contributions include providing initial insights into the adaptability of LLMs for deception detection and highlighting the challenges faced in this endeavor, thereby encouraging further exploration in this area.},
booktitle = {Proceedings of the 10th ACM International Workshop on Security and Privacy Analytics},
pages = {37–47},
numpages = {11},
keywords = {business email compromise, explainability, fake news, job scams, language models, opinion spam, phishing, reasoning, retrieval augmented generation, sms spam, social engineering attacks},
location = {Porto, Portugal},
series = {IWSPA '24}
}

@article{10.1145/3735553,
author = {Li, Tao and Cui, Chenhui and Huang, Rubing and Towey, Dave and Ma, Lei},
title = {Large Language Models for Automated Web-Form-Test Generation: An Empirical Study},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3735553},
doi = {10.1145/3735553},
abstract = {Testing web forms is an essential activity for ensuring the quality of web applications. It typically involves evaluating the interactions between users and forms. Automated test-case generation remains a challenge for web-form testing: Due to the complex, multi-level structure of web pages, it can be difficult to automatically capture their inherent contextual information for inclusion in the tests. Large Language Models (LLMs) have shown great potential for contextual text generation. This motivated us to explore how they could generate automated tests for web forms, making use of the contextual information within form elements. To the best of our knowledge, no comparative study examining different LLMs has yet been reported for web-form-test generation. To address this gap in the literature, we conducted a comprehensive empirical study investigating the effectiveness of 11 LLMs on 146 web forms from 30 open-source Java web applications. In addition, we propose three HTML-structure-pruning methods to extract key contextual information. The experimental results show that different LLMs can achieve different testing effectiveness, with the GPT-4, GLM-4, and Baichuan2 LLMs generating the best web-form tests. Compared with GPT-4, the other LLMs had difficulty generating appropriate tests for the web forms: Their successfully-submitted rates (SSRs) — the proportions of the LLMs-generated web-form tests that could be successfully inserted into the web forms and submitted — decreased by 9.10% to 74.15%. Our findings also show that, for all LLMs, when the designed prompts include complete and clear contextual information about the web forms, more effective web-form tests were generated. Specifically, when using Parser-Processed HTML for Task Prompt (PH-P), the SSR averaged 70.63%, higher than the 60.21% for Raw HTML for Task Prompt (RH-P) and 50.27% for LLM-Processed HTML for Task Prompt (LH-P). With RH-P, GPT-4’s SSR was 98.86%, outperforming models like LLaMa2 (7B) with 34.47% and GLM-4V with 0%. Similarly, with PH-P, GPT-4 reached an SSR of 99.54%, the highest among all models and prompt types. Finally, this paper also highlights strategies for selecting LLMs based on performance metrics, and for optimizing the prompt design to improve the quality of the web-form tests.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Automated Web-Form Testing, Large Language Models (LLMs), Web-Form-Test Generation, Java Web Applications, Empirical Study}
}

@inproceedings{10.1145/3708394.3708437,
author = {Wang, Xiaohui and Yu, Ruijie and Zhang, Yu and Xu, Yanyan},
title = {English Composition Image Automatic Scoring Based on Multi-modal Large Language Models},
year = {2025},
isbn = {9798400710650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708394.3708437},
doi = {10.1145/3708394.3708437},
abstract = {Large language models (LLMs) bring significant opportunities in the field of education evaluation. Nowadays, most existing LLMs are introduced to generate reasonable scores for electronic and structurized documents. However, such systems require huge efforts for manual typewriting or advanced optical character recognition techniques. To this end, this work directly processes the scanning copy of English composition with multi-modal LLMs. Specifically, this research aims to utilize multi-modal LLMs for automated essay scoring (AES) and evaluate its reliability and accuracy. We take the English composition images of 1,511 tenth-grade examinees in a standardized test environment as the research objects for automated scoring, and explore the performance of the multi-modal LLM GPT-4o in evaluating composition image data. The study compares the consistency of the composition image scores of GPT-4o under zero-shot and two-shot prompts with the scores of the marking experts, and verifies them through multiple indicators such as the exact agreement coefficient, Pearson correlation coefficient, Coefficient of determination, Root Mean Square Error, and the probability that the GPT-4o score falls within a given confidence interval. Especially, comparing the scores given by experts, the R-square of the GPT-4o scoring reaches 0.66. The results show that GPT-4o has the ability to learn from two samples through prompt, can quickly adapt and provide high-quality and personalized evaluations for examinees, and can provide valuable support for human scoring.},
booktitle = {Proceeding of the 2024 International Conference on Artificial Intelligence and Future Education},
pages = {247–254},
numpages = {8},
keywords = {Automated Essay Scoring, GPT-4o, Multi-modal large language model, Prompt Learning},
location = {
},
series = {AIFE '24}
}

@inproceedings{10.1145/3604915.3609494,
author = {Hua, Wenyue and Li, Lei and Xu, Shuyuan and Chen, Li and Zhang, Yongfeng},
title = {Tutorial on Large Language Models for Recommendation},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604915.3609494},
doi = {10.1145/3604915.3609494},
abstract = {Foundation Models such as Large Language Models (LLMs) have significantly advanced many research areas. In particular, LLMs offer significant advantages for recommender systems, making them valuable tools for personalized recommendations. For example, by formulating various recommendation tasks such as rating prediction, sequential recommendation, straightforward recommendation, and explanation generation into language instructions, LLMs make it possible to build universal recommendation engines that can handle different recommendation tasks. Additionally, LLMs have a remarkable capacity for understanding natural language, enabling them to comprehend user preferences, item descriptions, and contextual information to generate more accurate and relevant recommendations, leading to improved user satisfaction and engagement. This tutorial introduces Foundation Models such as LLMs for recommendation. We will introduce how recommender system advanced from shallow models to deep models and to large models, how LLMs enable generative recommendation in contrast to traditional discriminative recommendation, and how to build LLM-based recommender systems. We will cover multiple perspectives of LLM-based recommendation, including data preparation, model design, model pre-training, fine-tuning and prompting, multi-modality and multi-task learning, as well as trustworthy perspectives of LLM-based recommender systems such as fairness and transparency.},
booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
pages = {1281–1283},
numpages = {3},
keywords = {Foundation Models, Large Language Models, Recommendation},
location = {Singapore, Singapore},
series = {RecSys '23}
}

@article{10.1145/3733601,
author = {Chen, Magi and Wang, Ting-Chi},
title = {HyperPlace: Harnessing a Large Language Model for Efficient Hyperparameter Optimization in GPU-Accelerated VLSI Placement},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3733601},
doi = {10.1145/3733601},
abstract = {While GPU-based placers have demonstrated significant speed advantages over their CPU-based counterparts, hyperparameter tuning remains a bottleneck, often requiring substantial human intervention and expert knowledge. This challenge is particularly critical given the urgent need for rapid time-to-market solutions. Recently, Large Language Models (LLMs) have exhibited remarkable capabilities in zero-shot learning, context understanding, logical reasoning, and answer generation. In this work, we introduce HyperPlace, an innovative paradigm that leverages an off-the-shelf LLM to automate hyperparameter optimization using in-context learning techniques. Our approach transcends single-output black-box optimization methods by incorporating a batch optimization mechanism that evaluates multiple hyperparameter configurations simultaneously across several GPU computing platforms. We validated the effectiveness of our approach in placement quality, measured by Half-Perimeter Wire Length (HPWL), using DREAMPlace 2.0. To further demonstrate the capability of integrating our framework with other placers, we conducted additional experiments using Xplace 2.0. By employing the ISPD2005 benchmarks for our evaluation, HyperPlace enhances the placement tools with up to a 1.66% reduction in HPWL compared to their published results. Additionally, we evaluated HyperPlace on the ISPD2015 benchmarks, which incorporate fence region constraints not present in ISPD2005 benchmarks. Under these more complex constraints, HyperPlace achieves up to a 22.24% reduction in HPWL compared to the default settings of the placement tools, further demonstrating its adaptability across diverse placement scenarios and benchmark suites.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = may,
keywords = {LLM Agent, Hyperparameter Optimization}
}

@inproceedings{10.1145/3696410.3714876,
author = {Sun, Peishuai and Yun, Xiaochun and Li, Shuhao and Yin, Tao and Si, Chengxiang and Xie, Jiang},
title = {AdvTG: An Adversarial Traffic Generation Framework to Deceive DL-Based Malicious Traffic Detection Models},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714876},
doi = {10.1145/3696410.3714876},
abstract = {Deep learning-based (DL-based) malicious traffic detection models are effective but vulnerable to adversarial attacks. Existing adversarial attacks have shown promising results when targeting traffic detection models based on statistics and sequence features. However, these attacks are less effective against models that rely on payload analysis. The main reason is the difficulty in generating semantic, compliant, and functional payloads, which limits their practical application. In this paper, we propose AdvTG, an adversarial traffic generation framework to deceive DL-based malicious traffic based on the large language model (LLM) and reinforcement learning (RL). Specifically, AdvTG is designed to attack various DL-based detection models across diverse payload features and architectures, thereby enhancing the generalization capabilities of the generated adversarial traffic. Moreover, we design a specialized prompt for traffic generation tasks, where functional fields and target types are supplied as input, while non-functional fields are generated to produce the mutated traffic. This fine-tuning endows the LLM with task comprehension and traffic pattern reasoning abilities, allowing it to generate traffic that remains compliant and functional. Furthermore, leveraging RL, AdvTG automatically selects traffic fields that exhibit more robust adversarial properties. Experimental results show that AdvTG achieves over 40% attack success rate (ASR) across six detection models on four base datasets and two extended datasets, significantly outperforming other adversarial attack methods.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {3147–3159},
numpages = {13},
keywords = {adversarial attacks, large language model, malicious traffic detection, reinforcement learning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3663530.3665021,
author = {Liu, Yi and Deng, Gelei and Xu, Zhengzi and Li, Yuekang and Zheng, Yaowen and Zhang, Ying and Zhao, Lida and Zhang, Tianwei and Wang, Kailong},
title = {A Hitchhiker’s Guide to Jailbreaking ChatGPT via Prompt Engineering},
year = {2024},
isbn = {9798400706721},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663530.3665021},
doi = {10.1145/3663530.3665021},
abstract = {Natural language prompts serve as an essential interface between users and Large Language Models (LLMs) like GPT-3.5 and GPT-4, which are employed by ChatGPT to produce outputs across various tasks. However, prompts crafted with malicious intent, known as jailbreak prompts, can circumvent the restrictions of LLMs, posing a significant threat to systems integrated with these models. Despite their critical importance, there is a lack of systematic analysis and comprehensive understanding of jailbreak prompts. Our paper aims to address this gap by exploring key research questions to enhance the robustness of LLM systems: 1) What common patterns are present in jailbreak prompts? 2) How effectively can these prompts bypass the restrictions of LLMs? 3) With the evolution of LLMs, how does the effectiveness of jailbreak prompts change?
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
To address our research questions, we embarked on an empirical study targeting the LLMs underpinning ChatGPT, one of today's most advanced chatbots. Our methodology involved categorizing 78 jailbreak prompts into 10 distinct patterns, further organized into three jailbreak strategy types, and examining their distribution. We assessed the effectiveness of these prompts on GPT-3.5 and GPT-4, using a set of 3,120 questions across 8 scenarios deemed prohibited by OpenAI. Additionally, our study tracked the performance of these prompts over a 3-month period, observing the evolutionary response of ChatGPT to such inputs. Our findings offer a comprehensive view of jailbreak prompts, elucidating their taxonomy, effectiveness, and temporal dynamics. Notably, we discovered that GPT-3.5 and GPT-4 could still generate inappropriate content in response to malicious prompts without the need for jailbreaking. This underscores the critical need for effective prompt management within LLM systems and provides valuable insights and data to spur further research in LLM testing and jailbreak prevention.},
booktitle = {Proceedings of the 4th International Workshop on Software Engineering and AI for Data Quality in Cyber-Physical Systems/Internet of Things},
pages = {12–21},
numpages = {10},
keywords = {Jailbreak, Large language model, Prompt Injection},
location = {Porto de Galinhas, Brazil},
series = {SEA4DQ 2024}
}

@inproceedings{10.1145/3643479.3662055,
author = {Bui, Tuan and Tran, Oanh and Nguyen, Phuong and Ho, Bao and Nguyen, Long and Bui, Thang and Quan, Tho},
title = {Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering System: A Case Study at HCMUT},
year = {2024},
isbn = {9798400705472},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643479.3662055},
doi = {10.1145/3643479.3662055},
abstract = {In today's rapidly evolving landscape of Artificial Intelligence, large language models (LLMs) have emerged as a vibrant research topic. LLMs find applications in various fields and contribute significantly. Despite their powerful language capabilities, similar to pre-trained language models (PLMs), LLMs still face challenges in remembering events, incorporating new information, and addressing domain-specific issues or hallucinations. To overcome these limitations, researchers have proposed Retrieval-Augmented Generation (RAG) techniques, some others have proposed the integration of LLMs with Knowledge Graphs (KGs) to provide factual context, thereby improving performance and delivering more accurate feedback to user queries.Education plays a crucial role in human development and progress. With the technology transformation, traditional education is being replaced by digital or blended education. Therefore, educational data in the digital environment is increasing day by day. Data in higher education institutions are diverse, comprising various sources such as unstructured/structured text, relational databases, web/app-based API access, etc. Constructing a Knowledge Graph from these cross-data sources is not a simple task. This article proposes a method for automatically constructing a Knowledge Graph from multiple data sources and discusses some initial applications (experimental trials) of KG in conjunction with LLMs for question-answering tasks.},
booktitle = {Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia},
pages = {36–43},
numpages = {8},
keywords = {Education, Knowledge Graph, Large language model, Open Intent Discovery, Question-Answering System},
location = {Phuket, Thailand},
series = {AIQAM '24}
}

@inproceedings{10.1145/3637528.3671638,
author = {Tan, Xiaoyu and Cheng, Leijun and Qiu, Xihe and Shi, Shaojie and Cheng, Yuan and Chu, Wei and Xu, Yinghui and Qi, Yuan},
title = {Enhancing Personalized Headline Generation via Offline Goal-conditioned Reinforcement Learning with Large Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671638},
doi = {10.1145/3637528.3671638},
abstract = {Recently, significant advancements have been made in Large Language Models (LLMs) through the implementation of various alignment techniques. These techniques enable LLMs to generate highly tailored content in response to diverse user instructions. Consequently, LLMs have the potential to serve as robust, customizable recommendation systems in the field of content recommendation. However, using LLMs with user individual information and online exploration remains a challenge, which are important perspectives in developing personalized news headline generation algorithms. In this paper, we propose a novel framework to generate personalized news headlines using LLMs with extensive online exploration. The proposed approach involves initially training an offline goal-conditioned policy using supervised learning. Subsequently, online exploration is employed to collect new data for the next training iteration. Results from simulations, experiments, and real-word scenario demonstrate that our framework achieves outstanding performance on established benchmarks and can effectively generate personalized headlines under different reward settings. By treating the LLM as a goal-conditioned agent, the model can perform online exploration by modifying the goals without frequently retraining the model. To the best of our knowledge, this work represents the first investigation into the capability of LLMs to generate customized news headlines with goal-conditioned reinforcement learning via supervised learning within LLMs.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5762–5772},
numpages = {11},
keywords = {large language models, news headline generation, personality},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3677389.3702605,
author = {Azher, Ibrahim Al and Seethi, Venkata Devesh Reddy and Akella, Akhil Pandey and Alhoori, Hamed},
title = {LimTopic: LLM-based Topic Modeling and Text Summarization for Analyzing Scientific Articles limitations},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702605},
doi = {10.1145/3677389.3702605},
abstract = {The "limitations" sections of scientific articles play a crucial role in highlighting the boundaries and shortcomings of research, thereby guiding future studies and improving research methods. Analyzing these limitations benefits researchers, reviewers, funding agencies, and the broader academic community. We introduce LimTopic, a strategy where Topic generation in Limitation sections in scientific articles with Large Language Models (LLMs). Here, each topic contains the title and `Topic Summary.' This study focuses on effectively extracting and understanding these limitations through topic modeling and text summarization, utilizing the capabilities of LLMs. We extracted limitations from research articles and applied an LLM-based topic modeling integrated with the BERtopic approach to generate a title for each topic and `Topic Sentences.' To enhance comprehension and accessibility, we employed LLM-based text summarization to create concise and generalizable summaries for each topic's Topic Sentences and produce a `Topic Summary.' Our experimentation involved prompt engineering, fine-tuning LLM and BERTopic, and integrating BERTopic with LLM to generate topics, titles, and a topic summary. We also experimented with various LLMs with BERTopic for topic modeling and various LLMs for text summarization tasks. Our results showed that the combination of BERTopic and GPT 4 performed the best in terms of silhouette and coherence scores in topic modeling, and the GPT4 summary outperformed other LLM tasks as a text summarizer. Our code and dataset are available at https://github.com/IbrahimAlAzhar/LimTopic/tree/master.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {30},
numpages = {12},
keywords = {research limitations, limitations sections, large language models, information extraction, science of science},
location = {Hong Kong, China},
series = {JCDL '24}
}

@article{10.1145/3701194,
author = {Carik, Buse and Ping, Kaike and Ding, Xiaohan and Rho, Eugenia H.},
title = {Exploring Large Language Models Through a Neurodivergent Lens: Use, Challenges, Community-Driven Workarounds, and Concerns},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
url = {https://doi.org/10.1145/3701194},
doi = {10.1145/3701194},
abstract = {Despite the increasing use of large language models (LLMs) in everyday life among neurodivergent individuals, our knowledge of how they engage with and perceive LLMs remains limited. In this study, we investigate how neurodivergent individuals interact with LLMs by qualitatively analyzing topically related discussions from 61 neurodivergent communities on Reddit. Our findings reveal 20 specific LLM use cases across five core thematic areas of use among neurodivergent users: emotional well-being, mental health support, interpersonal communication, learning, and professional development and productivity. We also identified key challenges, including overly neurotypical LLM responses and the limitations of text-based interactions. In response to such challenges, some users actively seek advice by sharing input prompts and corresponding LLM responses. Others develop workarounds by experimenting and modifying prompts to be more neurodivergent-friendly. Despite these efforts, users have significant concerns around LLM use, including potential overreliance and fear of replacing human connections. Our analysis highlights the need to make LLMs more inclusive for neurodivergent users and implications around how LLM technologies can reinforce unintended consequences and behaviors.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jan,
articleno = {GROUP15},
numpages = {28},
keywords = {ADHD, artificial intelligence, autism, dyslexia, large language models, neurodiversity, reddit, social anxiety}
}

@inproceedings{10.1145/3639478.3639815,
author = {Velasco, Alejandro},
title = {Beyond Accuracy: Evaluating Source Code Capabilities in Large Language Models for Software Engineering},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3639815},
doi = {10.1145/3639478.3639815},
abstract = {This dissertation aims to introduce interpretability techniques to comprehensively evaluate the performance of Large Language Models (LLMs) in software engineering tasks, beyond canonical metrics. In software engineering, Deep Learning techniques are widely employed across various domains, automating tasks such as code comprehension, bug fixing, code summarization, machine translation, and code generation. However, the prevalent use of accuracy-based metrics for evaluating Language Models trained on code often leads to an overestimation of their performance. Our work seeks to propose novel and comprehensive interpretability techniques to evaluate source code capabilities and provide a more nuanced understanding of LLMs performance across downstream tasks.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {162–164},
numpages = {3},
keywords = {large language models, interpretability, DL4SE, category theory, causal inference},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3677052.3698689,
author = {Cao, Yupeng and Chen, Zhi and Pei, Qingyun and Lee, Nathan and Subbalakshmi, K. P. and Ndiaye, Papa Momar},
title = {ECC Analyzer: Extracting Trading Signal from Earnings Conference Calls using Large Language Model for Stock Volatility Prediction},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698689},
doi = {10.1145/3677052.3698689},
abstract = {In the realm of financial analytics, leveraging unstructured data, such as earnings conference calls (ECCs), to forecast stock volatility is a critical challenge that has attracted both academics and investors. While previous studies have used multimodal deep learning-based models to obtain a general view of ECCs for volatility predicting, they often fail to capture detailed, complex information. Our research introduces a novel framework: ECC Analyzer, which utilizes large language models (LLMs) to extract richer, more predictive content from ECCs to aid the model’s prediction performance. We use the pre-trained large models to extract textual and audio features from ECCs and implement a hierarchical information extraction strategy to extract more fine-grained information. This strategy first extracts paragraph-level general information by summarizing the text and then extracts fine-grained focus sentences using Retrieval-Augmented Generation (RAG). These features are then fused through multimodal feature fusion to perform volatility prediction. Experimental results demonstrate that our model outperforms traditional analytical benchmarks, confirming the effectiveness of advanced LLM techniques in financial analysis.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {257–265},
numpages = {9},
keywords = {Earnings Conference Call Analysis, Large Language Model, Retrieval-Augmented Generation, Volatility forecasting},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@inproceedings{10.1145/3643916.3644418,
author = {Huang, Tao and Sun, Zhihong and Jin, Zhi and Li, Ge and Lyu, Chen},
title = {Knowledge-Aware Code Generation with Large Language Models},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644418},
doi = {10.1145/3643916.3644418},
abstract = {Large Language Models (LLMs) perform well on basic programming problems. However, they encounter challenges when dealing with complex tasks involving the use of diverse algorithmic and data structure skills, particularly programming competition-level problems. Notably, ChatGPT exhibits proficient performance on problems it has encountered during its pre-training phase, but this performance deteriorates when faced with novel problems. Consequently, enhancing the ability of LLMs to address unfamiliar problems has emerged as a pivotal research focus. The problem-solving process of LLMs mirrors human programmers' approach to a certain extent. When confronted with new programming tasks, human programmers engage in task planning and code writing with the previously acquired knowledge about algorithms and data structures. Despite having learned such knowledge, LLMs struggle to effectively apply it when faced with specific new problems. To address this issue, we constructed a novel dataset, CodeF, which contains a portion of programming problems that ChatGPT has not previously encountered. Furthermore, we developed a Knowledge Library tailored for Python programming contest problems and introduced the concept of Knowledge-Aware Code Generation (KareCoder). KareCoder bolsters the models' understanding and problem-solving capabilities by integrating prompt and knowledge from the library into the LLMs' code generation reasoning process, especially on Pass@1 metrics. Upon testing on the CodeF and APPS datasets, KareCoder demonstrated outstanding performance in handling novel problems previously unencountered by LLMs. In contrast with the code directly generated by ChatGPT, KareCoder achieved a relative improvement of 23.3% on the Pass@1 metric on the CodeF post2021-9 dataset. Additionally, it performs well compared to other methods when dealing with problems that LLMs have previously encountered. Our dataset and experiment data are open-sourced and can be accessed at https://github.com/CodeGeneration3/KareCoder.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {52–63},
numpages = {12},
keywords = {code generation, large language models, knowledge library},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3691620.3695521,
author = {Lu, Minghai and Delaware, Benjamin and Zhang, Tianyi},
title = {Proof Automation with Large Language Models},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695521},
doi = {10.1145/3691620.3695521},
abstract = {Interactive theorem provers such as Coq are powerful tools to formally guarantee the correctness of software. However, using these tools requires significant manual effort and expertise. While Large Language Models (LLMs) have shown promise in automatically generating informal proofs in natural language, they are less effective at generating formal proofs in interactive theorem provers. In this paper, we conduct a formative study to identify common mistakes made by LLMs when asked to generate formal proofs. By analyzing 520 proof generation errors made by GPT-3.5, we found that GPT-3.5 often identified the correct high-level structure of a proof, but struggled to get the lower-level details correct. Based on this insight, we propose PALM, a novel generate-then-repair approach that first prompts an LLM to generate an initial proof and then leverages targeted symbolic methods to iteratively repair low-level problems. We evaluate PALM on a large dataset that includes more than 10K theorems. Our results show that PALM significantly outperforms other state-of-the-art approaches, successfully proving 76.6% to 180.4% more theorems. Moreover, PALM proves 1270 theorems beyond the reach of existing approaches. We also demonstrate the generalizability of PALM across different LLMs.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1509–1520},
numpages = {12},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3640794.3665538,
author = {S\'{a}nchez Cuadrado, Jes\'{u}s and P\'{e}rez-Soler, Sara and Guerra, Esther and De Lara, Juan},
title = {Automating the Development of Task-oriented LLM-based Chatbots},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640794.3665538},
doi = {10.1145/3640794.3665538},
abstract = {Task-oriented chatbots are increasingly used to access all sorts of services – like booking a flight, or setting a medical appointment – through natural language conversation. There are many technologies for implementing task-oriented chatbots, including Dialogflow, Watson, and Rasa. They rely on an explicit definition of the user intents, conversation flows, and chatbot outputs, which is costly to specify, and sometimes results in suboptimal user experiences and artificial conversations with limited diversity of chatbot responses. Recently, the advances in generative artificial intelligence fostered by Large Language Models (LLMs) have enabled a new range of open-domain chatbots, like ChatGPT, able to converse fluently on any topic. However, they are general-purpose, and therefore not directly usable to solve specialised tasks reliably. In this paper, we study the power of LLMs to build task-oriented chatbots, resulting in lighter specifications – no intent definition required – and more natural conversations than in intent-based approaches. To this end, we propose a lightweight domain-specific language based on YAML to specify chatbots using modules of different types (e.g., menus, question-answering, data gathering). These specifications are compiled into structured LLM prompts that use the ReAct framework to inform our runtime how to interpret the user input and coordinate the tasks that the chatbot must perform. The paper presents the design and realisation of our framework, and an assessment that encodes a set of existing intent-based chatbots using our approach, showing its benefits in terms of specification size, conversation flexibility and output diversity.},
booktitle = {Proceedings of the 6th ACM Conference on Conversational User Interfaces},
articleno = {11},
numpages = {10},
keywords = {Domain-Specific Languages, Large Language Models, Task-oriented Chatbots},
location = {Luxembourg, Luxembourg},
series = {CUI '24}
}

@inproceedings{10.1145/3613904.3642024,
author = {Rajashekar, Niroop Channa and Shin, Yeo Eun and Pu, Yuan and Chung, Sunny and You, Kisung and Giuffre, Mauro and Chan, Colleen E and Saarinen, Theo and Hsiao, Allen and Sekhon, Jasjeet and Wong, Ambrose H and Evans, Leigh V and Kizilcec, Rene F. and Laine, Loren and Mccall, Terika and Shung, Dennis},
title = {Human-Algorithmic Interaction Using a Large Language Model-Augmented Artificial Intelligence Clinical Decision Support System},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642024},
doi = {10.1145/3613904.3642024},
abstract = {Integration of artificial intelligence (AI) into clinical decision support systems (CDSS) poses a socio-technological challenge that is impacted by usability, trust, and human-computer interaction (HCI). AI-CDSS interventions have shown limited benefit in clinical outcomes, which may be due to insufficient understanding of how health-care providers interact with AI systems. Large language models (LLMs) have the potential to enhance AI-CDSS, but haven’t been studied in either simulated or real-world clinical scenarios. We present findings from a randomized controlled trial deploying AI-CDSS for the management of upper gastrointestinal bleeding (UGIB) with and without an LLM interface within realistic clinical simulations for physician and medical student participants. We find evidence that LLM augmentation improves ease-of-use, that LLM-generated responses with citations improve trust, and HCI varies based on clinical expertise. Qualitative themes from interviews suggest the perception of LLM-augmented AI-CDSS as a team-member used to confirm initial clinical intuitions and help evaluate borderline decisions.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {442},
numpages = {20},
keywords = {Artificial Intelligence, Clinical Decision Support Systems, Electronic Health Record, Health-Clinical, Machine Learning, Medical: Nursing Homes/Hospitals, Qualitative Methods, Quantitative Methods, Workflows},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3635636.3664627,
author = {Radensky, Marissa},
title = {Mixed-Initiative Methods for Co-Creation in Scientific Research},
year = {2024},
isbn = {9798400704857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635636.3664627},
doi = {10.1145/3635636.3664627},
abstract = {The scientific process is inherently creative, requiring the generation and exploration of ideas for scientific inspiration, projects, study design, and communication. As large language models (LLMs) advance rapidly, scientists increasingly take advantage of their abilities. While LLMs show great promise in supporting many steps of the scientific process, researchers still face significant challenges in validating and steering their output. Interactions tailored to scientists and their specific tasks may empower them to harness the full creative potential of LLMs. I present a course of research that will lead to the development and evaluation of mixed-initiative methods for co-creation in scientific research. These methods aim to facilitate verification and control of AI output. I briefly describe my prior and proposed work on mixed-initiative methods for co-creating research inspiration, studies, and communication, and I detail my current project on an LLM-powered tool for co-creating research project ideas.},
booktitle = {Proceedings of the 16th Conference on Creativity &amp; Cognition},
pages = {1–7},
numpages = {7},
location = {Chicago, IL, USA},
series = {C&amp;C '24}
}

@inproceedings{10.1145/3708359.3712153,
author = {Zhang, Zhuohao (Jerry) and Schoop, Eldon and Nichols, Jeffrey and Mahajan, Anuj and Swearngin, Amanda},
title = {From Interaction to Impact: Towards Safer AI Agent Through Understanding and Evaluating Mobile UI Operation Impacts},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712153},
doi = {10.1145/3708359.3712153},
abstract = {With advances in generative AI, there is increasing work towards creating autonomous agents that can manage daily tasks by operating user interfaces (UIs). While prior research has studied the mechanics of how AI agents might navigate UIs and understand UI structure, the effects of agents and their autonomous actions—particularly those that may be risky or irreversible—remain under-explored. In this work, we investigate the real-world impacts and consequences of mobile UI actions taken by AI agents. We began by developing a taxonomy of the impacts of mobile UI actions through a series of workshops with domain experts. Following this, we conducted a data synthesis study to gather realistic mobile UI screen traces and action data that users perceive as impactful. We then used our impact categories to annotate our collected data and data repurposed from existing mobile UI navigation datasets. Our quantitative evaluations of different large language models (LLMs) and variants demonstrate how well different LLMs can understand the impacts of mobile UI actions that might be taken by an agent. We show that our taxonomy enhances the reasoning capabilities of these LLMs for understanding the impacts of mobile UI actions, but our findings also reveal significant gaps in their ability to reliably classify more nuanced or complex categories of impact.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {727–744},
numpages = {18},
keywords = {AI, LLM, Agent, AI Safety, UI Understanding, UI Operation Impact},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3696409.3700286,
author = {Song, Yu and Yang, Xiaohui and Huang, Rongping and Haifeng, Bai and Yang, Lili},
title = {CSCCap: Plugging Sparse Coding in Zero-Shot Image Captioning},
year = {2024},
isbn = {9798400712739},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696409.3700286},
doi = {10.1145/3696409.3700286},
abstract = {Recently, zero-shot image captioning based on pre-trained vision-language models (VLMs) and large language models (LLMs) has made significant progress. However, experiments and experience have demonstrated that these methods do not perform well when dealing with complex images, as the analysis of the image subject can be affected by intricate backgrounds. To address this issue, we constructed a learnable convolutional sparse coding (CSC) model to learn sparse representations of images. By incorporating CSC, it is possible to extract the sparse representation of the image, effectively removing unnecessary background features and highlighting the main subject of the image, thus enhancing the effectiveness of image-to-text generation. Numerous experiments have shown that models incorporating sparse encoding perform competitively in zero-shot image captioning over other methods.},
booktitle = {Proceedings of the 6th ACM International Conference on Multimedia in Asia},
articleno = {124},
numpages = {5},
keywords = {Convolutional Sparse Coding; Image Caption; Image Representations},
location = {
},
series = {MMAsia '24}
}

@article{10.1145/3704905,
author = {Cai, Yufan and Hou, Zhe and Sanan, David and Luan, Xiaokun and Lin, Yun and Sun, Jun and Dong, Jin Song},
title = {Automated Program Refinement: Guide and Verify Code Large Language Model with Refinement Calculus},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {POPL},
url = {https://doi.org/10.1145/3704905},
doi = {10.1145/3704905},
abstract = {Recently, the rise of code-centric Large Language Models (LLMs) has reshaped the software engineering world with low-barrier tools like Copilot that can easily generate code. However, there is no correctness guarantee for the code generated by LLMs, which suffer from the hallucination problem, and their output is fraught with risks. Besides, the end-to-end process from specification to code through LLMs is a non-transparent and uncontrolled black box. This opacity makes it difficult for users to understand and trust the generated code. Addressing these challenges is both necessary and critical. In contrast, program refinement transforms high-level specification statements into executable code while preserving correctness. Traditional tools for program refinement are primarily designed for formal methods experts and lack automation and extensibility. We apply program refinement to guide LLM and validate the LLM-generated code while transforming refinement into a more accessible and flexible framework.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
To initiate this vision, we propose Refine4LLM, an approach that aims to:
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(1) Formally refine the specifications,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(2) Automatically prompt and guide the LLM using refinement calculus,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(3) Interact with the LLM to generate the code,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(4) Verify that the generated code satisfies the constraints, thus guaranteeing its correctness,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(5) Learn and build more advanced refinement laws to extend the refinement calculus.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
We evaluated Refine4LLM against the state-of-the-art baselines on program refinement and LLMs benchmarks.The experiment results show that Refine4LLM can efficiently generate more robust code and reduce the time for refinement and verification.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {69},
numpages = {33},
keywords = {Large Language Model, Program Refinement, Program Synthesis}
}

@inproceedings{10.1145/3654777.3676419,
author = {Laban, Philippe and Vig, Jesse and Hearst, Marti and Xiong, Caiming and Wu, Chien-Sheng},
title = {Beyond the Chat: Executable and Verifiable Text-Editing with LLMs},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676419},
doi = {10.1145/3654777.3676419},
abstract = {Conversational interfaces powered by Large Language Models (LLMs) have recently become a popular way to obtain feedback during document editing. However, standard chat-based conversational interfaces cannot explicitly surface the editing changes that they suggest. To give the author more control when editing with an LLM, we present InkSync, an editing interface that suggests executable edits directly within the document being edited. Because LLMs are known to introduce factual errors, Inksync also supports a 3-stage approach to mitigate this risk: Warn authors when a suggested edit introduces new information, help authors Verify the new information’s accuracy through external search, and allow a third party to Audit with a-posteriori verification via a trace of all auto-generated content. Two usability studies confirm the effectiveness of InkSync’s components when compared to standard LLM-based chat interfaces, leading to more accurate and more efficient editing, and improved user experience.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {20},
numpages = {23},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.5555/3709347.3744007,
author = {Vallinder, Aron and Hughes, Edward},
title = {Cultural Evolution of Cooperation among LLM Agents},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Large language models (LLMs) provide a compelling foundation for building generally-capable AI agents. These agents may soon be deployed at scale in the real world, representing the interests of individual humans (e.g., AI assistants) or groups of humans (e.g., AI-accelerated corporations). At present, relatively little is known about the dynamics of multiple LLM agents interacting over many generations of iterative deployment. In this paper, we examine whether a ''society'' of LLM agents can learn mutually beneficial social norms in the face of incentives to defect, a distinctive feature of human sociality that is arguably crucial to the success of civilization. In particular, we study the evolution of indirect reciprocity across generations of LLM agents playing a classic iterated Donor Game in which agents can observe the recent behavior of their peers. We find that the evolution of cooperation differs markedly across base models, with societies of Claude 3.5 Sonnet agents achieving significantly higher average scores than Gemini 1.5 Flash, which, in turn, outperforms GPT-4o. Further, Claude 3.5 Sonnet can make use of an additional mechanism for costly punishment to achieve yet higher scores, while Gemini 1.5 Flash and GPT-4o fail to do so. For each model class, we also observe variation in emergent behavior across random seeds, suggesting an understudied sensitive dependence on initial conditions. We suggest that our evaluation regime could inspire an inexpensive and informative new class of LLM benchmarks, focussed on the implications of LLM agent deployment for the cooperative infrastructure of society.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {2771–2773},
numpages = {3},
keywords = {cooperation, cultural evolution, indirect reciprocity, large language models},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3675417.3675513,
author = {Li, Shiye and Yi, Li},
title = {A Few-Shot Entity Relation Extraction Method in the Legal Domain Based on Large Language Models},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675417.3675513},
doi = {10.1145/3675417.3675513},
abstract = {With the increasing transparency of judicial information, extracting implicit legal information from a massive corpus of legal documents becomes more academically valuable and practically significant. Large Language Models (LLMs) have demonstrated outstanding performance in many NLP tasks, particularly in generative tasks. However, satisfactory results are often elusive in vertical domains like legal entity relation extraction tasks. Due to the scarcity of well-annotated training data in the legal domain, and the expensive and time-consuming nature of labeling such data, research on few-shot learning becomes particularly crucial. Leveraging the advantage of large models pre-trained on extensive datasets, capable of acquiring vast prior knowledge of various tasks and adapting quickly to new tasks, this paper proposes a few-shot entity relation extraction method in the legal domain based on large language models. The proposed method is evaluated on two publicly available legal entity relation extraction datasets through relevant experiments. The research results indicate that the proposed approach reduces the cost of constructing training data and exhibits excellent performance in few-shot legal entity relation extraction tasks. The F1 score on two public datasets is improved by 2.8% and 3.1%, respectively, compared to traditional deep learning models, while maintaining better generalization capabilities.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {580–586},
numpages = {7},
location = {Hongkong, China},
series = {DEAI '24}
}

@inproceedings{10.1145/3701571.3703384,
author = {Komninos, Andreas and Simou, Ioulia and Fotopoulos, Angelos and Michanetzi, Eleftheria Lito and Xenos, Michalis},
title = {Towards LLM-Generated Affective Phrase Sets for Text Entry Evaluation},
year = {2024},
isbn = {9798400712838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701571.3703384},
doi = {10.1145/3701571.3703384},
abstract = {We present a novel method to generate affective phrase sets using Large Language Models (LLMs), for use in text entry study transcription tasks. These phrases could be used to adjust participant emotions, and enable performance assessment under various affective conditions. We found that the affective phrases impacted participants’ valence, but not arousal or text entry performance. Though partially succesful, our work provides a foundation for exploring the relationship between emotion and text entry performance in lab studies.},
booktitle = {Proceedings of the International Conference on Mobile and Ubiquitous Multimedia},
pages = {457–460},
numpages = {4},
keywords = {Text Entry, Smartphones, Transcription Tasks, LLMs, Phrase sets},
location = {
},
series = {MUM '24}
}

@inproceedings{10.1145/3711542.3711582,
author = {Sachdev, Jayant and D Rosario, Sean and Phatak, Abhijeet and Wen, He and Kirti, Swati and Tripathy, Chittaranjan},
title = {Automated Query-Product Relevance Labeling using Large Language Models for E-commerce Search},
year = {2025},
isbn = {9798400717383},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711542.3711582},
doi = {10.1145/3711542.3711582},
abstract = {Accurate query-product relevance labeling is indispensable to generate ground truth dataset for search ranking in e-commerce. Traditional approaches for annotating query-product pairs rely on human-based labeling services, which is expensive, time-consuming and prone to errors. In this work, we explore the application of Large Language Models (LLMs) to automate query-product relevance labeling for large-scale e-commerce search. We use several publicly available and proprietary LLMs for this task, and conducted experiments on two open-source datasets and an in-house e-commerce search dataset. Using prompt engineering techniques such as Chain-of-Thought (CoT) prompting, In-context Learning (ICL), and Retrieval Augmented Generation (RAG) with Maximum Marginal Relevance (MMR), we show that LLM’s performance has the potential to approach human-level accuracy on this task in a fraction of the time and cost required by human-labelers, thereby suggesting that our approach is more efficient than the conventional methods. We have generated query-product relevance labels using LLMs at scale, and are using them for evaluating improvements to our search algorithms. Our work demonstrates the potential of LLMs to improve query-product relevance thus enhancing e-commerce search user experience. More importantly, this scalable alternative to human-annotation has significant implications for information retrieval domains including search and recommendation systems, where relevance scoring is crucial for optimizing the ranking of products and content to improve customer engagement and other conversion metrics.},
booktitle = {Proceedings of the 2024 8th International Conference on Natural Language Processing and Information Retrieval},
pages = {32–40},
numpages = {9},
keywords = {Large Language Models, Search Relevance, Information Retrieval, Data Annotation, Prompt Engineering, Retrieval Augmented Generation, Maximum Marginal Relevance.},
location = {
},
series = {NLPIR '24}
}

@inproceedings{10.1145/3643656.3643900,
author = {Chen, Yang and Jabbarvand, Reyhaneh},
title = {Can ChatGPT Repair Non-Order-Dependent Flaky Tests?},
year = {2024},
isbn = {9798400705588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643656.3643900},
doi = {10.1145/3643656.3643900},
abstract = {Regression testing helps developers check whether the latest code changes break software functionality. Flaky tests, which can non-deterministically pass or fail on the same code version, may mislead developers' concerns, resulting in missing some bugs or spending time pinpointing bugs that do not exist. Existing flakiness detection and mitigation techniques have primarily focused on general order-dependent (OD) and implementation-dependent (ID) flaky tests. There is also a dearth of research on repairing test flakiness, out of which, mostly have focused on repairing OD flaky tests, and a few have explored repairing a subcategory of non-order-dependent (NOD) flaky tests that are caused by asynchronous waits. As a result, there is a demand for devising techniques to reproduce, detect, and repair NOD flaky tests. Large language models (LLMs) have shown great effectiveness in several programming tasks. To explore the potential of LLMs in addressing NOD flakiness, this paper investigates the possibility of using ChatGPT to repair different categories of NOD flaky tests. Our comprehensive study on 118 from the IDoFT dataset shows that ChatGPT, despite as a leading LLM with notable success in multiple code generation tasks, is ineffective in repairing NOD test flakiness, even by following the best practices for prompt crafting. We investigated the reasons behind the failure of using ChatGPT in repairing NOD tests, which provided us valuable insights about the next step to advance the field of NOD test flakiness repair.},
booktitle = {Proceedings of the 1st International Workshop on Flaky Tests},
pages = {22–29},
numpages = {8},
keywords = {software testing, test flakiness, large language models},
location = {Lisbon, Portugal},
series = {FTW '24}
}

@inproceedings{10.1145/3711542.3711599,
author = {Rusli, Andre and Oshima, Yuji and Yada, Yuki},
title = {Leveraging LLMs for Attribute Definition and Value Extraction from User-Generated Texts on a C2C E-Commerce Platform},
year = {2025},
isbn = {9798400717383},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711542.3711599},
doi = {10.1145/3711542.3711599},
abstract = {This study explores the application of large language models (LLMs) for Attribute Definition and Value Extraction in C2C e-commerce. We investigate the use of Llama- and Gemma-based open models, employing fine-tuning and post-training quantization techniques, such as QLoRA, and compare them to an LLM available via commercial APIs. Our approach aims to streamline the process of defining key item attributes and extracting their values from user-generated content. We evaluate model performance using metrics like BLEU and F1 scores, demonstrating how employing fine-tuning and post-quantization techniques on open-sourced models can be beneficial in a specific domain. The research also examines the practical implications of these models in a production environment serving millions of monthly active users in Japan, highlighting the challenges and solutions related to latency and resource consumption.},
booktitle = {Proceedings of the 2024 8th International Conference on Natural Language Processing and Information Retrieval},
pages = {186–191},
numpages = {6},
keywords = {Large Language Models, Information Retrieval, Japanese C2C E-Commerce, Attribute Definition and Value Extraction},
location = {
},
series = {NLPIR '24}
}

@article{10.1145/3699598,
author = {Zhang, Quanjun and Sun, Weifeng and Fang, Chunrong and Yu, Bowen and Li, Hongyan and Yan, Meng and Zhou, Jianyi and Chen, Zhenyu},
title = {Exploring Automated Assertion Generation via Large Language Models},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3699598},
doi = {10.1145/3699598},
abstract = {Unit testing aims to validate the correctness of software system units and has become an essential practice in software development and maintenance. However, it is incredibly time-consuming and labor-intensive for testing experts to write unit test cases manually, including test inputs (i.e., prefixes) and test oracles (i.e., assertions). Very recently, some techniques have been proposed to apply Large Language Models (LLMs) to generate unit assertions and have proven the potential in reducing manual testing efforts. However, there has been no systematic comparison of the effectiveness of these LLMs, and their pros and cons remain unexplored.To bridge this gap, we perform the first extensive study on applying various LLMs to automated assertion generation. The experimental results on two independent datasets show that studied LLMs outperform six state-of-the-art techniques with a prediction accuracy of 51.82%–58.71% and 38.72%–48.19%. The improvements achieve 29.60% and 12.47% on average. Besides, as a representative LLM, CodeT5 consistently outperforms all studied LLMs and all baselines on both datasets, with an average improvement of 13.85% and 26.64%, respectively. We also explore the performance of generated assertions in detecting real-world bugs, and find LLMs are able to detect 32 bugs from Defects4J on average, with an improvement of 52.38% against the most recent approach EditAS. Inspired by the findings, we construct a simplistic retrieval-and-repair-enhanced LLM-based approach by transforming the assertion generation problem into a program repair task for retrieved similar assertions. Surprisingly, such a simplistic approach can further improve the prediction accuracy of LLMs by 9.40% on average, leading to new records on both datasets. Besides, we provide additional discussions from different aspects (e.g., the impact of assertion types and test lengths) to illustrate the capacity and limitations of LLM-based approaches. Finally, we further pinpoint various practical guidelines (e.g., the improvement of multiple candidate assertions) for advanced LLM-based assertion generation in the near future. Overall, our work underscores the promising future of adopting off-the-shelf LLMs to generate accurate and meaningful assertions in real-world test cases and reduce the manual efforts of unit testing experts in practical scenarios.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
articleno = {81},
numpages = {25},
keywords = {Unit Testing, Assertion Generation, LLM, AI4SE}
}

@inproceedings{10.1145/3706599.3721205,
author = {Kl\"{u}wer, Nils and Nalis, Irina and Neidhardt, Julia},
title = {Context over Categories: Implementing the Theory of Constructed Emotion with LLM-Guided User Analysis},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3721205},
doi = {10.1145/3706599.3721205},
abstract = {Emotion analysis is a critical research area with applications in content moderation and personalized systems. Many existing approaches rely on Ekman’s universal emotions theory, which reduces emotions to static categories, neglecting their complexity and contextual variability. This work introduces a novel, context-aware approach based on Lisa Feldman Barrett’s Theory of Constructed Emotion. A key contribution is the development of the “context sphere,” a personalized construct derived from user behavior data. To our knowledge, this is the first operationalization for computational methods. A context-aware emotion analysis pipeline was developed, incorporating advanced Large Language Model (LLM) prompting strategies like role-play and controlled generation. A case study in content moderation demonstrates how the “context sphere” enables contextually aware emotion analyses. Future directions include refining the framework, advancing LLM methodologies, and conducting user studies. This research lays the foundation for more human-centered, ethical, and effective emotion analysis systems.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {151},
numpages = {7},
keywords = {Human-Computer Interaction, Emotion Analysis, Large Language Models (LLMs), Context Aware Computing, Online Content Moderation},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641554.3701934,
author = {Kerslake, Chris and Denny, Paul and Smith, David H. and Leinonen, Juho and MacNeil, Stephen and Luxton-Reilly, Andrew and Becker, Brett A.},
title = {Exploring Student Reactions to LLM-Generated Feedback on Explain in Plain English Problems},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701934},
doi = {10.1145/3641554.3701934},
abstract = {Code reading and comprehension skills are essential for novices learning programming, and explain-in-plain-English tasks (EiPE) are a well-established approach for assessing these skills. However, manual grading of EiPE tasks is time-consuming and this has limited their use in practice. To address this, we explore an approach where students explain code samples to a large language model (LLM) which generates code based on their explanations. This generated code is then evaluated using test suites, and shown to students along with the test results. We are interested in understanding how automated formative feedback from an LLM guides students' subsequent prompts towards solving EiPE tasks. We analyzed 177 unique attempts on four EiPE exercises from 21 students, looking at what kinds of mistakes they made and how they fixed them. We found that when students made mistakes, they identified and corrected them using either a combination of the LLM-generated code and test case results, or they switched from describing the purpose of the code to describing the sample code line-by-line until the LLM-generated code exactly matched the obfuscated sample code. Our findings suggest both optimism and caution with the use of LLMs for unmonitored formative feedback. We identified false positive and negative cases, helpful variable naming, and clues of direct code recitation by students. For most students, this approach represents an efficient way to demonstrate and assess their code comprehension skills. However, we also found evidence of misconceptions being reinforced, suggesting the need for further work to identify and guide students more effectively.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {575–581},
numpages = {7},
keywords = {eipe, explain in plain english, formative feedback, large language models, llm, misconceptions, qualitative analysis},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3652988.3673967,
author = {Fang, Jingchao and Arechiga, Nikos and Namikoshi, Keiichi and Bravo, Nayeli and Hogan, Candice and Shamma, David A.},
title = {On LLM Wizards: Identifying Large Language Models' Behaviors for Wizard of Oz Experiments},
year = {2024},
isbn = {9798400706257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652988.3673967},
doi = {10.1145/3652988.3673967},
abstract = {The Wizard of Oz (WoZ) method is a widely adopted research approach where a human Wizard “role-plays” a not readily available technology and interacts with participants to elicit user behaviors and probe the design space. With the growing ability for modern large language models (LLMs) to role-play, one can apply LLMs as Wizards in WoZ experiments with better scalability and lower cost than the traditional approach. However, methodological guidance on responsibly applying LLMs in WoZ experiments and a systematic evaluation of LLMs’ role-playing ability are lacking. Through two LLM-powered WoZ studies, we take the first step towards identifying an experiment lifecycle for researchers to safely integrate LLMs into WoZ experiments and interpret data generated from settings that involve Wizards role-played by LLMs. We also contribute a heuristic-based evaluation framework that allows the estimation of LLMs’ role-playing ability in WoZ experiments and reveals LLMs’ behavior patterns at scale.},
booktitle = {Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents},
articleno = {16},
numpages = {11},
keywords = {LLM, Wizard of Oz, WoZ, large language model, methods, persuasive conversation, synthetic data},
location = {GLASGOW, United Kingdom},
series = {IVA '24}
}

@inproceedings{10.1145/3637528.3671578,
author = {Li, Zhonghang and Xia, Lianghao and Tang, Jiabin and Xu, Yong and Shi, Lei and Xia, Long and Yin, Dawei and Huang, Chao},
title = {UrbanGPT: Spatio-Temporal Large Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671578},
doi = {10.1145/3637528.3671578},
abstract = {Spatio-temporal prediction aims to forecast and gain insights into the ever-changing dynamics of urban environments across both time and space. Its purpose is to anticipate future patterns, trends, and events in diverse facets of urban life, including transportation, population movement, and crime rates. Although numerous efforts have been dedicated to developing neural network techniques for accurate predictions on spatio-temporal data, it is important to note that many of these methods heavily depend on having sufficient labeled data to generate precise spatio-temporal representations. Unfortunately, the issue of data scarcity is pervasive in practical urban sensing scenarios. In certain cases, it becomes challenging to collect any labeled data from downstream scenarios, intensifying the problem further. Consequently, it becomes necessary to build a spatio-temporal model that can exhibit strong generalization capabilities across diverse spatio-temporal learning scenarios.Taking inspiration from the remarkable achievements of large language models (LLMs), our objective is to create a spatio-temporal LLM that can exhibit exceptional generalization capabilities across a wide range of downstream urban tasks. To achieve this objective, we present the UrbanGPT, which seamlessly integrates a spatio-temporal dependency encoder with the instruction-tuning paradigm. This integration enables LLMs to comprehend the complex inter-dependencies across time and space, facilitating more comprehensive and accurate predictions under data scarcity. To validate the effectiveness of our approach, we conduct extensive experiments on various public datasets, covering different spatio-temporal prediction tasks. The results consistently demonstrate that our UrbanGPT, with its carefully designed architecture, consistently outperforms state-of-the-art baselines. These findings highlight the potential of building large language models for spatio-temporal learning, particularly in zero-shot scenarios where labeled data is scarce. The code and data are available at: https://github.com/HKUDS/UrbanGPT.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5351–5362},
numpages = {12},
keywords = {generative ai, large language models, smart cities, spatial-temporal data mining, urban computing},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3701716.3717814,
author = {Halil, Umut and Huang, Jin and Graux, Damien and Pan, Jeff Z.},
title = {LLM Shots: Best Fired at System or User Prompts?},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717814},
doi = {10.1145/3701716.3717814},
abstract = {Over the past few years, the range of use cases involving Large Language Models (LLMs) has grown dramatically. Alongside this growth, many techniques have been established by the community to boost LLM performance. Among them, relying on the fact that LLMs excel at reproducing behaviors, practitioners have been charging their prompts with examples (a.k.a. shots) to guide or orientate the LLMs towards the correct directions given their main instruction. More recently, LLMs have evolved, allowing users to define overall roles by offering two inputs: system and user messages, based on the assumption that -in a sense- system instructions would be dedicated to admin/designer of chatbot interfaces. In such a setting: what is the best place to give example to the LLM so to improve its performances? In this study, we address this research question by systematically trying different shooting combinations with different popular benchmarks across a large set of LLMs. Our experiments show that it tends to be more beneficial to guide the LLMs through their system prompting mechanisms, leaving only the questions into their user messages.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1605–1613},
numpages = {9},
keywords = {benchmarking, context-aware interactions, example-based prompting, large language models (llms), performance optimization, prompt engineering, shooting strategies, system messages, user messages},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3706598.3713431,
author = {Khurana, Anjali and Su, Xiaotian and Wang, April Yi and Chilana, Parmit K},
title = {Do It For Me vs. Do It With Me: Investigating User Perceptions of Different Paradigms of Automation in Copilots for Feature-Rich Software},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713431},
doi = {10.1145/3706598.3713431},
abstract = {Large Language Model (LLM)-based in-application assistants, or copilots, can automate software tasks, but users often prefer learning by doing, raising questions about the optimal level of automation for an effective user experience. We investigated two automation paradigms by designing and implementing a fully automated copilot (AutoCopilot) and a semi-automated copilot (GuidedCopilot) that automates trivial steps while offering step-by-step visual guidance. In a user study (N=20) across data analysis and visual design tasks, GuidedCopilot outperformed AutoCopilot in user control, software utility, and learnability, especially for exploratory and creative tasks, while AutoCopilot saved time for simpler visual tasks. A follow-up design exploration (N=10) enhanced GuidedCopilot with task-and state-aware features, including in-context preview clips and adaptive instructions. Our findings highlight the critical role of user control and tailored guidance in designing the next generation of copilots that enhance productivity, support diverse skill levels, and foster deeper software engagement.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {880},
numpages = {18},
keywords = {feature-rich software; large language models; software copilots; user control; semi-automation; human-AI collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3701551.3705706,
author = {Rahmani, Hossein A. and Siro, Clemencia and Aliannejadi, Mohammad and Craswell, Nick and Clarke, Charles L.A. and Faggioli, Guglielmo and Mitra, Bhaskar and Thomas, Paul and Yilmaz, Emine},
title = {LLM4Eval@WSDM 2025: Large Language Model for Evaluation in Information Retrieval},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3705706},
doi = {10.1145/3701551.3705706},
abstract = {Large language models (LLMs) have demonstrated increasing task-solving abilities not present in smaller models. Utilizing the capabilities and responsibilities of LLMs for automated evaluation (LLM4Eval) has recently attracted considerable attention in multiple research communities. For instance, LLM4Eval models have been studied in the context of automated judgments, natural language generation, and retrieval augmented generation systems. We believe that the information retrieval community can significantly contribute to this growing research area by designing, implementing, analyzing, and evaluating various aspects of LLMs with applications to LLM4Eval tasks. The main goal of LLM4Eval workshop is to bring together researchers from industry and academia to discuss various aspects of LLMs for evaluation in information retrieval, including automated judgments, retrieval-augmented generation pipeline evaluation, altering human evaluation, robustness, and trustworthiness of LLMs for evaluation in addition to their impact on real-world applications. We also plan to run an automated judgment challenge prior to the workshop, where participants will be asked to generate labels for a given dataset while maximising correlation with human judgments. The format of the workshop is interactive, including roundtable and keynote sessions and tends to avoid the one-sided dialogue of a mini-conference. This is the second iteration of the workshop. The first version was held in conjunction with SIGIR 2024, attracting over 50 participants.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {1120–1121},
numpages = {2},
keywords = {automated evaluation, generative models, large language models},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3589334.3648137,
author = {Yang, Kailai and Zhang, Tianlin and Kuang, Ziyan and Xie, Qianqian and Huang, Jimin and Ananiadou, Sophia},
title = {MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3648137},
doi = {10.1145/3589334.3648137},
abstract = {As an integral part of people's daily lives, social media is becoming a rich source for automatic mental health analysis. As traditional discriminative methods bear poor generalization ability and low interpretability, the recent large language models (LLMs) have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions in zero-shot or few-shot settings. The results show that LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner, which further significantly affects the quality of the generated explanations. Domain-specific finetuning is an effective solution, but faces two critical challenges: 1) lack of high-quality training data. 2) no open-source foundation LLMs. To alleviate these problems, we formally model interpretable mental health analysis as a text generation task, and build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset with 105K data samples to support LLM instruction tuning and evaluation. The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks. We prompt ChatGPT with expert-designed few-shot prompts to obtain explanations. To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data. Based on the IMHI dataset and LLaMA2 foundation models, we train MentaLLaMA, the first open-source instruction-following LLM series for interpretable mental health analysis on social media. We evaluate MentaLLaMA and other advanced methods on the IMHI benchmark, the first holistic evaluation benchmark for interpretable mental health analysis. The results show that MentaLLaMA approaches state-of-the-art discriminative methods in correctness and generates human-level explanations. MentaLLaMA models also show strong generalizability to unseen tasks. The project is available at https://github.com/SteveKGYang/MentaLLaMA.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4489–4500},
numpages = {12},
keywords = {interpretability, large language models, mental health analysis, social media},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1145/3700791,
author = {Bodaghi, Arezo and Fung, Benjamin C. M. and A. Schmitt, Ketra},
title = {AugmenToxic: Leveraging Reinforcement Learning to Optimize LLM Instruction Fine-Tuning for Data Augmentation to Enhance Toxicity Detection},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1559-1131},
url = {https://doi.org/10.1145/3700791},
doi = {10.1145/3700791},
abstract = {Addressing the challenge of toxic language in online discussions is crucial for the development of effective toxicity detection models. This pioneering work focuses on addressing imbalanced datasets in toxicity detection by introducing a novel approach to augment toxic language data. We create a balanced dataset by instructing fine-tuning of Large Language Models (LLMs) using Reinforcement Learning with Human Feedback (RLHF). Recognizing the challenges in collecting sufficient toxic samples from social media platforms for building a balanced dataset, our methodology involves sentence-level text data augmentation through paraphrasing existing samples using optimized generative LLMs. Leveraging generative LLM, we utilize the Proximal Policy Optimizer (PPO) as the RL algorithm to fine-tune the model further and align it with human feedback. In other words, we start by fine-tuning a LLM using an instruction dataset, specifically tailored for the task of paraphrasing while maintaining semantic consistency. Next, we apply PPO and a reward function, to further fine-tune (optimize) the instruction-tuned LLM. This RL process guides the model in generating toxic responses. We utilize the Google Perspective API as a toxicity evaluator to assess generated responses and assign rewards/penalties accordingly. This approach guides LLMs through PPO and the reward function, transforming minority class samples into augmented versions. The primary goal of our methodology is to create a balanced and diverse dataset to enhance the accuracy and performance of classifiers in identifying instances from the minority class. Utilizing two publicly available toxic datasets, we compared various techniques with our proposed method for generating toxic samples, demonstrating that our approach outperforms all others in producing a higher number of toxic samples. Starting with an initial 16,225 toxic prompts, our method successfully generated 122,951 toxic samples with a toxicity score exceeding 30%. Subsequently, we developed various classifiers using the generated balanced datasets and applied a cost-sensitive learning approach to the original imbalanced dataset. The findings highlight the superior performance of classifiers trained on data generated using our proposed method. These results highlight the importance of employing RL and a data-agnostic model as a reward mechanism for augmenting toxic data, thereby enhancing the robustness of toxicity detection models.},
note = {Just Accepted},
journal = {ACM Trans. Web},
month = oct,
keywords = {Text Data Augmentation, Imbalanced Toxic Datasets, Large Language Models, Reinforcement Learning}
}

@inproceedings{10.1145/3627673.3679153,
author = {Zhang, Yanlin and Li, Ning and Gan, Quan and Zhang, Weinan and Wipf, David and Wang, Minjie},
title = {ELF-Gym: Evaluating Large Language Models Generated Features for Tabular Prediction},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679153},
doi = {10.1145/3627673.3679153},
abstract = {Crafting effective features is a crucial yet labor-intensive and domain-specific task within machine learning pipelines. Fortunately, recent advancements in Large Language Models (LLMs) have shown promise in automating various data science tasks, including feature engineering. But despite this potential, evaluations thus far are primarily based on the end performance of a complete ML pipeline, providing limited insight into precisely how LLMs behave relative to human experts in feature engineering. To address this gap, we propose ELF-Gym, a framework for Evaluating LLM-generated Features. We curated a new dataset from historical Kaggle competitions, including 251 golden features used by top-performing teams. ELF-Gym then quantitatively evaluates LLM-generated features by measuring their impact on downstream model performance as well as their alignment with expert-crafted features through semantic and functional similarity assessments. This approach provides a more comprehensive evaluation of disparities between LLMs and human experts, while offering valuable insights into specific areas where LLMs may have room for improvement. For example, using ELF-Gym we empirically demonstrate that, in the best-case scenario, LLMs can semantically capture approximately 56% of the golden features, but at the more demanding implementation level this overlap drops to 13%. Moreover, in other cases LLMs may fail completely, particularly on datasets that require complex features, indicating broad potential pathways for improvement.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5420–5424},
numpages = {5},
keywords = {data science, feature engineering, large language models},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3658644.3670344,
author = {He, Xinlei and Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Zhang, Yang},
title = {MGTBench: Benchmarking Machine-Generated Text Detection},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670344},
doi = {10.1145/3658644.3670344},
abstract = {Nowadays, powerful large language models (LLMs) such as ChatGPT have demonstrated revolutionary power in a variety of natural language processing (NLP) tasks such as text classification, sentiment analysis, language translation, and question-answering. Consequently, the detection of machine-generated texts (MGTs) is becoming increasingly crucial as LLMs become more advanced and prevalent. These models have the ability to generate human-like language, making it challenging to discern whether a text is authored by a human or a machine. This raises concerns regarding authenticity, accountability, and potential bias. However, existing methods for detecting MGTs are evaluated using different model architectures, datasets, and experimental settings, resulting in a lack of a comprehensive evaluation framework that encompasses various methodologies. Furthermore, it remains unclear how existing detection methods would perform against powerful LLMs.In this paper, we fill this gap by proposing the first benchmark framework for MGT detection against powerful LLMs, named MGTBench. Extensive evaluations on public datasets with curated texts generated by various powerful LLMs such as ChatGPT-turbo and Claude demonstrate the effectiveness of different detection methods. Our ablation study shows that a larger number of words in general leads to better performance and most detection methods can achieve similar performance with much fewer training samples. Additionally, our findings reveal that metric-based/model-based detection methods exhibit better transferability across different LLMs/datasets. Furthermore, we delve into a more challenging task: text attribution, where the goal is to identify the originating model of a given text, i.e., whether it is a specific LLM or authored by a human. Our findings indicate that the model-based detection methods still perform well in the text attribution task. To investigate the robustness of different detection methods, we consider three adversarial attacks, namely paraphrasing, random spacing, and adversarial perturbations. We discover that these attacks can significantly diminish detection effectiveness, underscoring the critical need for the development of more robust detection methods. We envision that MGTBench will serve as a benchmark tool to accelerate future investigations involving the evaluation of powerful MGT detection methods on their respective datasets and the development of more advanced MGT detection methods.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2251–2265},
numpages = {15},
keywords = {MGT detection, large language models, machine learning},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3706599.3719821,
author = {Liu, Jiaying "Lizzy" and Su, Yiheng and Seth, Praneel},
title = {Can Large Language Models Grasp Abstract Visual Concepts in Videos? A Case Study on YouTube Shorts about Depression},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719821},
doi = {10.1145/3706599.3719821},
abstract = {Large language models (LLMs) are increasingly used to assist computational social science research. While prior efforts have focused on text, the potential of leveraging multimodal LLMs (MLLMs) for online video studies remains underexplored. We conduct one of the first case studies on MLLM-assisted video content analysis, comparing AI’s interpretations to human understanding of abstract concepts. We leverage LLaVA-1.6 Mistral 7B to interpret four abstract concepts regarding video-mediated self-disclosure, analyzing 725 keyframes from 142 depression-related YouTube short videos. We perform a qualitative analysis of MLLM’s self-generated explanations and found that the degree of operationalization can influence MLLM’s interpretations. Interestingly, greater detail does not necessarily increase human-AI alignment. We also identify other factors affecting AI alignment with human understanding, such as concept complexity and versatility of video genres. Our exploratory study highlights the need to customize prompts for specific concepts and calls for researchers to incorporate more human-centered evaluations when working with AI systems in a multimodal context.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {127},
numpages = {11},
keywords = {Computational Social Science, Video-Mediated Communication, Multimodal Information, Human-AI Alignment, User-Generated Content, Large Language-and-Vision Assistant (LLaVA), Content Analysis, Mental Health},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3712300,
author = {Wang, Zhiyuan and Yuan, Fangxu and LeBaron, Virginia and Flickinger, Tabor and Barnes, Laura E.},
title = {PALLM: Evaluating and Enhancing PALLiative Care Conversations with Large Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712300},
doi = {10.1145/3712300},
abstract = {Effective patient-provider communication is crucial in clinical care, directly impacting patient outcomes and quality of life. Traditional evaluation methods, such as human ratings, patient feedback, and provider self-assessments, are often limited by high costs and scalability issues. Although existing natural language processing (NLP) techniques show promise, they struggle with the nuances of clinical communication and require sensitive clinical data for training, reducing their effectiveness in real-world applications. Emerging large language models (LLMs) offer a new approach to assessing complex communication metrics, with the potential to advance the field through integration into passive sensing and just-in-time intervention systems. This study explores LLMs as evaluators of palliative care communication quality, leveraging their linguistic, in-context learning, and reasoning capabilities. Specifically, using simulated scripts crafted and labeled by healthcare professionals, we test proprietary models (e.g., GPT-4) and fine-tune open-source LLMs (e.g., LLaMA2) with a synthetic dataset generated by GPT-4 to evaluate clinical conversations, to identify key metrics such as ‘understanding’ and ‘empathy’. Our findings demonstrated LLMs’ superior performance in evaluating clinical communication, providing actionable feedback with reasoning, and demonstrating the feasibility and practical viability of developing in-house LLMs. This research highlights LLMs’ potential to enhance patient-provider interactions and lays the groundwork for downstream steps in developing LLM-empowered clinical health systems.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Healthcare},
month = jan,
keywords = {Patient-Provider Communication, Large Language Models, Healthcare, Palliative Care}
}

@inproceedings{10.1145/3691620.3695286,
author = {Adejumo, Elijah Kayode and Johnson, Brittany},
title = {Towards Leveraging LLMs for Reducing Open Source Onboarding Information Overload},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695286},
doi = {10.1145/3691620.3695286},
abstract = {Consistent, diverse, and quality contributions are essential to the sustainability of the open source community. Therefore, it is important that there is infrastructure for effectively onboarding and retaining diverse newcomers to open source software projects. Most often, open source projects rely on onboarding documentation to support newcomers in making their first contributions. Unfortunately, prior studies suggest that information overload from available documentation, along with the predominantly monolingual nature of repositories, can have negative effects on the newcomer experiences and onboarding process. This, coupled with the effort involved in creating and maintaining onboarding documentation, suggest a need for support in creating more accessible documentation. Large language models (LLMs) have shown great potential in providing text transformation support in other domains, and even shown promise in simplifying or generating other kinds of computing artifacts, such as source code and technical documentation. We contend that LLMs can also help make software onboarding documentation more accessible, thereby reducing the potential for information overload. Using ChatGPT (GPT-3.5 Turbo) and Gemini Pro as case studies, we assessed the effectiveness of LLMs for simplifying software onboarding documentation, one method for reducing information overload. We discuss a broader vision for using LLMs to support the creation of more accessible documentation and outline future research directions toward this vision.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2210–2214},
numpages = {5},
keywords = {open-source, software, on-boarding, generative AI, documentation, ChatGPT, LLMs},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@article{10.14778/3685800.3685911,
author = {Wang, Jianguo and Hanson, Eric and Li, Guoliang and Papakonstantinou, Yannis and Simhadri, Harsha and Xie, Charles},
title = {Vector Databases: What's Really New and What's Next? (VLDB 2024 Panel)},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685911},
doi = {10.14778/3685800.3685911},
abstract = {Vector databases have recently emerged as a hot topic in the field of databases, especially in industry. This is due to the widespread interest in Large Language Models (LLMs), where vector databases provide the relevant context for LLMs to produce more accurate responses. However, vector data is not new. It has been studied for more than two decades, leading to many efficient algorithms and indexes for vector similarity search. Thus, a natural question is: What is really new and what is next for vector databases? This panel will bring together several leading experts in vector databases to share their insights and experiences from various perspectives. The panel will also discuss the broader role of databases, beyond just vector databases, in the era of generative AI.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4505–4506},
numpages = {2}
}

@inproceedings{10.1145/3637528.3671932,
author = {Hu, Zhibo and Wang, Chen and Shu, Yanfeng and Paik, Hye-Young and Zhu, Liming},
title = {Prompt Perturbation in Retrieval-Augmented Generation based Large Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671932},
doi = {10.1145/3637528.3671932},
abstract = {The robustness of large language models (LLMs) becomes increasingly important as their use rapidly grows in a wide range of domains. Retrieval-Augmented Generation (RAG) is considered as a means to improve the trustworthiness of text generation from LLMs. However, how the outputs from RAG-based LLMs are affected by slightly different inputs is not well studied. In this work, we find that the insertion of even a short prefix to the prompt leads to the generation of outputs far away from factually correct answers. We systematically evaluate the effect of such prefixes on RAG by introducing a novel optimization technique called Gradient Guided Prompt Perturbation (GGPP). GGPP achieves a high success rate in steering outputs of RAG-based LLMs to targeted wrong answers. It can also cope with instructions in the prompts requesting to ignore irrelevant context. We also exploit LLMs' neuron activation difference between prompts with and without GGPP perturbations to give a method that improves the robustness of RAG-based LLMs through a highly effective detector trained on neuron activation triggered by GGPP generated prompts. Our evaluation on open-sourced LLMs demonstrates the effectiveness of our methods.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1119–1130},
numpages = {12},
keywords = {LLM, prompt attack, retrieval-augmented generation, robustness},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3637528.3671465,
author = {Park, Youngsuk and Budhathoki, Kailash and Chen, Liangfu and K\"{u}bler, Jonas M. and Huang, Jiaji and Kleindessner, Matth\"{a}us and Huan, Jun and Cevher, Volkan and Wang, Yida and Karypis, George},
title = {Inference Optimization of Foundation Models on AI Accelerators},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671465},
doi = {10.1145/3637528.3671465},
abstract = {Powerful foundation models, including large language models (LLMs), with Transformer architectures have ushered in a new era of Generative AI across various industries. Industry and research community have witnessed a large number of new applications, based on those foundation models. Such applications include question and answer, customer services, image and video generation, and code completions, among others. However, as the number of model parameters reaches to hundreds of billions, their deployment incurs prohibitive inference costs and high latency in real-world scenarios. As a result, the demand for cost-effective and fast inference using AI accelerators is ever more higher. To this end, our tutorial offers a comprehensive discussion on complementary inference optimization techniques using AI accelerators. Beginning with an overview of basic Transformer architectures and deep learning system frameworks, we deep dive into system optimization techniques for fast and memory-efficient attention computations and discuss how they can be implemented efficiently on AI accelerators. Next, we describe architectural elements that are key for fast transformer inference. Finally, we examine various model compression and fast decoding strategies in the same context.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6605–6615},
numpages = {11},
keywords = {foundation models, inference optimization, llms, transformer},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3706598.3713339,
author = {Zhou, Shixu and Lin, Weiyue and Xu, Zuyu and Wei, Xiaoying and Huang, Raoyi and Ma, Xiaojuan and Fan, Mingming},
title = {JournalAIde: Empowering Older Adults in Digital Journal Writing},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713339},
doi = {10.1145/3706598.3713339},
abstract = {Digital journaling offers a means for older adults to express themselves, document their lives, and engage in self-reflection, contributing to the maintenance of cognitive function and social connectivity. Although previous works have investigated the motivations and benefits of digital journaling for older adults, little technical support has been designed to offer assistance. We conducted a formative study with older adults and uncovered their encountered challenges and preferences for technical support. Informed by the findings, we designed a Large Language Model (LLM) empowered tool, JournalAIde, which provides vicarious experience, idea organization, sample text generation, and visual editing cues to enhance older adults’ confidence, writing ability, and sustained attention during digital journaling. Through a between-subjects study and a field deployment, we demonstrated the JournalAIde’s significant effectiveness compared to a baseline system in empowering older adults in digital journaling. We further investigated older adults’ experiences and perceptions of LLM writing assistance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {667},
numpages = {19},
keywords = {Older adults’ creativity; Digital journal writing; Accessibility},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3670474.3685971,
author = {Hammoud, Ali and Goyal, Chetanya and Pathen, Sakib and Dai, Arlene and Li, Anhang and Kielian, Gregory and Saligane, Mehdi},
title = {Human Language to Analog Layout Using GLayout Layout Automation Framework},
year = {2024},
isbn = {9798400706998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670474.3685971},
doi = {10.1145/3670474.3685971},
abstract = {Current approaches to Analog Layout Automation apply ML techniques such as Graph Convolutional Neural Networks (GCN) to translate netlist to layout. While these ML approaches have proven to be effective, they lack the powerful reasoning capabilities, an intuitive human interface, and standard evaluation benchmarks that have been improving at a rapid development pace in Large Language Models (LLMs). The GLayout framework introduced in this work translates analog layout into an expressive, technology generic, compact text representation. Then, an LLM is taught to understand analog layout through fine-tuning and in-context learning using Retrieval Augmented Generation (RAG). The LLM is able to successfully layout unseen circuits based on new information provided in-context. We train 3.8, 7, and 22 Billion parameter quantized LLMs on a dataset of less than 50 unique circuits, and text documents providing layout knowledge. The 22B parameter model is tuned in 2 hours on a single NVIDIA A100 GPU. The open-source evaluation set is proposed as an automation benchmark for LLM layout automation tasks, and ranges from 2-transistor circuits to a ΔΣ ADC. The 22B model completes 70% of the tasks in the evaluation set, and passes DRC and LVS verification on 44% of evaluations with verified correct blocks up to 4 transistors in size.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD},
articleno = {33},
numpages = {7},
keywords = {Analog Layout Automation, GLayout, Large Language Model, Open Source, Parameter Efficient Fine Tuning, Quantized Low Rank Adaptation (QLORA), Retrieval Augmented Generation (RAG)},
location = {Salt Lake City, UT, USA},
series = {MLCAD '24}
}

@inproceedings{10.1145/3708359.3712094,
author = {Wu, Zhikun and Weber, Thomas and M\"{u}ller, Florian},
title = {One Does Not Simply Meme Alone: Evaluating Co-Creativity Between LLMs and Humans in the Generation of Humor},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712094},
doi = {10.1145/3708359.3712094},
abstract = {Collaboration has been shown to enhance creativity, leading to more innovative and effective outcomes. While previous research has explored the abilities of Large Language Models (LLMs) to serve as co-creative partners in tasks like writing poetry or creating narratives, the collaborative potential of LLMs in humor-rich and culturally nuanced domains remains an open question. To address this gap, we conducted a user study to explore the potential of LLMs in co-creating memes—a humor-driven and culturally specific form of creative expression. We conducted a user study with three groups of 50 participants each: a human-only group creating memes without AI assistance, a human-AI collaboration group interacting with a state-of-the-art LLM model, and an AI-only group where the LLM autonomously generated memes. We assessed the quality of the generated memes through crowdsourcing, with each meme rated on creativity, humor, and shareability. Our results showed that LLM assistance increased the number of ideas generated and reduced the effort participants felt. However, it did not improve the quality of the memes when humans were collaborated with LLM. Interestingly, memes created entirely by AI performed better than both human-only and human-AI collaborative memes in all areas on average. However, when looking at the top-performing memes, human-created ones were better in humor, while human-AI collaborations stood out in creativity and shareability. These findings highlight the complexities of human-AI collaboration in creative tasks. While AI can boost productivity and create content that appeals to a broad audience, human creativity remains crucial for content that connects on a deeper level.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {1082–1092},
numpages = {11},
keywords = {Human-AI Collaboration, LLM, Co-Creativity, Memes, Humor},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3658644.3670369,
author = {Cho, Wonhee and Hanrot, Guillaume and Kim, Taeseong and Park, Minje and Stehl\'{e}, Damien},
title = {Fast and Accurate Homomorphic Softmax Evaluation},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670369},
doi = {10.1145/3658644.3670369},
abstract = {Homomorphic encryption is one of the main solutions for building secure and privacy-preserving solutions for Machine Learning as a Service, a major challenge in a society where AI becomes more and more pervasive. This motivates the development of homomorphic algorithms for the main building blocks of AI, typically for the components of the various types of neural networks architectures.Among those components, we focus on the Softmax function, defined by Softmax(x ) = (exp(xi) / ∑j=1n exp(xj))1 ≤ i ≤ n. This function is deemed to be one of the most difficult to evaluate homomorphically, because of its multivariate nature and of the very large range of values for exp(xi). The available homomorphic algorithms remain restricted, especially in large dimensions, while important applications such as Large Language Models (LLM) require computing Softmax over large dimensional vectors. Our algorithm has strong scalability properties in terms of range and dimension while maintaining very good numerical accuracy. In terms of multiplicative depth of the computation (a suitable measure of cost for homomorphic algorithms), our algorithm achieves O(log n) complexity for a fixed range of inputs, where n is the Softmax dimension.Our algorithm is especially adapted to the situation where we must compute many Softmax at the same time, for instance, in the LLM situation. In that case, assuming that all Softmax calls are packed into m ciphtertexts, the asymptotic amortized multiplicative depth cost per ciphertext is, again over a fixed range, O(1 + m/N) for N the homomorphic ring degree (typically N=216, so that we have N ≫ m in practice).The main ingredient of our algorithms is a normalize-and-square strategy, which manages to interlace the (numerically unstable) exponential computation over a large range and (very expensive) normalization, decomposing both in stabler and cheaper smaller steps.We have implemented our algorithms using the HEaaN implementation of the CKKS HE system. Comparing ourselves to the state of the art, our experiments show, in practice, a gain of a factor 2.5 to 8 compared to state of the art solutions.These experiments demonstrate good accuracy (around 16-bit precision in the worst case, around 20 on average) and support the linear behavior in the dimension. The many-ciphertexts version allows us to compute 8192 Softmax of dimension 256 in parallel in 486s (single-thread CPU), corresponding to an amortized 0.06s per Softmax call. All Softmax calls of the 32-layers LLaMa large language model (7B version) with context length 128 on an RTX-6000 GPU take around 1.5 minutes, and the final Softmax call in dimension 32768 for token generation takes less than 3 seconds. This suggests that near-practicality may be accessible with dedicated hardware.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4391–4404},
numpages = {14},
keywords = {CKKS scheme, fully homomorphic encryption, polynomial approximation, softmax},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3691573.3691600,
author = {Yao, Heng and Gomes de Siqueira, Alexandre and Johnson, Margeaux and Pileggi, Roberta and Blue, Amy and Bumbach, Michael D. and Love, Rene and Lok, Benjamin},
title = {Enhancing Empathic Communication in Healthcare Education Through Virtual Conversations: Leveraging Large Language Models for Real-Time Feedback},
year = {2024},
isbn = {9798400709791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691573.3691600},
doi = {10.1145/3691573.3691600},
abstract = {Virtual conversations are increasingly utilized in healthcare education to enhance verbal empathic communication skills through tailored feedback on trainees’ responses. These conversations, supported by modalities such as speech, animation, and gestures, are highly customizable and accessible via the internet, bypassing the need for head-mounted displays (HMDs). However, training models to accurately evaluate empathic responses and generate human-like language with actionable suggestions remains a challenge. The advent of large language models (LLMs) provides new solutions to these challenges. This paper examines the impact of GPT-4-generated feedback on the empathic expressions of health professions trainees during virtual conversations. We enrolled 72 students from nursing and dental disciplines in an Interprofessional Collaborative Care course at the University of Florida. Participants were randomly assigned to one of two groups: one received feedback and suggestions from GPT-4 during conversations, while the other did not. We collected data on the perceived accuracy and helpfulness of the feedback from the intervention group. Using the Empathic Communication Coding System (ECCS) and GPT-4 Turbo, we assessed and compared the empathy levels of participants between the two groups. A Mann-Whitney U test was used to determine differences in average empathy levels. Results showed that participants receiving GPT-4 feedback had significantly higher median empathy levels than those without feedback. Feedback’s accuracy and utility were also affirmed by the participants. This study highlights the effectiveness of integrating LLMs like GPT-4 into virtual conversations for enhancing training outcomes in healthcare education.},
booktitle = {Proceedings of the 26th Symposium on Virtual and Augmented Reality},
pages = {41–50},
numpages = {10},
keywords = {large language models, verbal empathic communication training, virtual humans},
location = {Manaus, Brazil},
series = {SVR '24}
}

@article{10.1145/3708518,
author = {Widyasari, Ratnadira and Zhang, Ting and Bouraffa, Abir and Maalej, Walid and Lo, David},
title = {Explaining Explanations: An Empirical Study of Explanations in Code Reviews},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708518},
doi = {10.1145/3708518},
abstract = {Code reviews are central for software quality assurance. Ideally, reviewers should explain their feedback to enable authors of code changes to understand the feedback and act accordingly. Different developers might need different explanations in different contexts. Therefore, assisting this process first requires understanding the types of explanations reviewers usually provide. The goal of this paper is to study the types of explanations used in code reviews and explore the potential of Large Language Models (LLMs), specifically ChatGPT, in generating these specific types. We extracted 793 code review comments from Gerrit and manually labeled them based on whether they contained a suggestion, an explanation, or both. Our analysis shows that 42% of comments only include suggestions without explanations. We categorized the explanations into seven distinct types including rule or principle, similar examples, and future implications. When measuring their prevalence, we observed that some explanations are used differently by novice and experienced reviewers. Our manual evaluation shows that, when the explanation type is specified, ChatGPT can correctly generate the explanation in 88 out of 90 cases. This foundational work highlights the potential for future automation in code reviews, which can assist developers in sharing and obtaining different types of explanations as needed, thereby reducing back-and-forth communication.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {code review, explanation, empirical study, large language model}
}

@inproceedings{10.1145/3618305.3623612,
author = {Jain, Rijul and Ni, Wode and Sunshine, Joshua},
title = {Generating Domain-Specific Programs for Diagram Authoring with Large Language Models},
year = {2023},
isbn = {9798400703843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3618305.3623612},
doi = {10.1145/3618305.3623612},
abstract = {Large language models (LLMs) can generate programs in general-purpose languages from prose descriptions, but are not trained on many domain-specific languages (DSLs). Diagram authoring with Penrose, a diagramming system using three DSLs, exemplifies the utility of DSL program generation with LLMs, which enables diagram creation from prose. We provide methods to conceptualize and evaluate the structures of one-shot LLM prompts to generate error-free DSL programs and implement Penrose diagram creation from prose using LLMs. We will evaluate our LLM prompt structures by testing prompt variations across different diagramming domains and plan to run a user study to assess the ease of LLM-augmented Penrose diagramming over other tools.},
booktitle = {Companion Proceedings of the 2023 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
pages = {70–71},
numpages = {2},
keywords = {domain-specific languages, large language models, visualization},
location = {Cascais, Portugal},
series = {SPLASH 2023}
}

@inproceedings{10.1145/3643916.3644424,
author = {Siddiq, Mohammed Latif and Zhang, Jiahao and Santos, Joanna Cecilia Da Silva},
title = {Understanding Regular Expression Denial of Service (ReDoS): Insights from LLM-Generated Regexes and Developer Forums},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644424},
doi = {10.1145/3643916.3644424},
abstract = {Regular expression Denial of Service (ReDoS) represents an algorithmic complexity attack that exploits the processing of regular expressions (regexes) to produce a denial-of-service attack. This attack occurs when a regex's evaluation time scales polynomially or exponentially with input length, posing significant challenges for software developers. The advent of Large Language Models (LLMs) has revolutionized the generation of regexes from natural language prompts, but not without its risks. Prior works showed that LLMs can generate code with vulnerabilities and security smells. In this paper, we examined the correctness and security of regexes generated by LLMs as well as the characteristics of LLM-generated vulnerable regexes. Our study also examined ReDoS patterns in actual software projects, aligning them with corresponding regex equivalence classes and algorithmic complexity. Moreover, we analyzed developer discussions on GitHub and StackOverflow, constructing a taxonomy to investigate their experiences and perspectives on ReDoS. In this study, we found that GPT-3.5 was the best LLM to generate regexes that are both correct and secure. We also observed that LLM-generated regexes mainly have polynomial ReDoS vulnerability patterns, and it is consistent with vulnerable regexes found in open source projects. We also found that developers' main discussions around insecure regexes is related to mitigation strategies to remove vulnerable regexes.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {190–201},
numpages = {12},
keywords = {ReDoS, DoS attack, large language models, regex generation},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3626252.3630817,
author = {Fernandez, Amanda S. and Cornell, Kimberly A.},
title = {CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630817},
doi = {10.1145/3626252.3630817},
abstract = {As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create "black box" code with significant security vulnerabilities. We outline methods for integrating basic AI knowledge and traditional software verification steps into CS1 along with LLMs, which will better prepare students for software development in professional settings.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {345–351},
numpages = {7},
keywords = {ai, artificial intelligence, code generation, copilot, cs1, gpt-4, introductory programming, large language model, llm, machine learning, novice programmers, programming, prompt engineering, secure code, software verification},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3713081.3731731,
author = {Xie, Yuanmin and Xu, Zhenyang and Tian, Yongqiang and Zhou, Min and Zhou, Xintong and Sun, Chengnian},
title = {Kitten: A Simple Yet Effective Baseline for Evaluating LLM-Based Compiler Testing Techniques},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3731731},
doi = {10.1145/3713081.3731731},
abstract = {Compiler testing is critical and indispensable to improve the correctness of compilers. Spurred by recent advancements in Large Language Models (LLMs), LLM-based compiler testing techniques such as Fuzz4All, have demonstrated their potential in uncovering real bugs in diverse compilers and reducing the required engineering efforts in designing program generators. Given the continuous evolution of LLMs and the emergence of new LLM-based approaches, establishing robust baselines is crucial for rigorous evaluation and driving future advancements in this promising research direction.To this end, we introduce Kitten, a mutation-based, language-agnostic program generator. Kitten leverages a corpus of seed programs, analogous to the training set for LLMs, and utilizes the target language's syntax, akin to the knowledge learned by LLMs. Furthermore, Kitten's mutation operators can generate diverse test programs, demonstrating a behavior analogous to the ability of LLM inference to generate new code.Our evaluations demonstrate that, using existing compiler test suites as seed programs, Kitten outperforms Fuzz4All in terms of code coverage and bug detection capabilities. Within 24 hours, Kitten achieved 48.3%, 9.9%, and 33.8% higher coverage than Fuzz4All on GCC, LLVM, and Rustc, respectively, while identifying an average of 19.3, 20.3, and 15.7 bugs in these compilers across three runs. Over the course of nine months dedicated to Kitten's development and testing, we identified a total of 328 across the compilers GCC, LLVM, Rustc, Solc, JerryScript, scalac, and slang, of which 310 have been confirmed or fixed. We strongly believe that Kitten serves as an effective baseline, enabling the identification of limitations within existing LLM-based approaches and consequently driving advancements in this promising research direction.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {21–25},
numpages = {5},
keywords = {compiler testing, language-agnostic code generation, benchmarking},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@inproceedings{10.1145/3701716.3715459,
author = {Taffa, Tilahun Abedissa and Usbeck, Ricardo},
title = {Bridge-Generate: Scholarly Hybrid Question Answering},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715459},
doi = {10.1145/3701716.3715459},
abstract = {Answering scholarly hybrid questions requires access to bibliographic facts stored in structured data, such as a Knowledge Graph (KG) and textual information. Existing Scholarly Hybrid Question Answering (SHQA) approaches rely on retrieving KG triples and documents from the Wikipedia text corpus and prompt an LLM (Large Language Model) for answers. However, the retrieval is heavily keyword-based, introducing noise into the context. Furthermore, despite detecting the entities in the question, the models do not attempt any question analysis. Therefore, we propose a new SHQA system that employs a bridge-generate approach. During the bridge phase, our system recursively identifies entity-encapsulating phrases within the question and resolves the entities leveraging the underlying KGs. It then formulates assertion statements based on the resolved entities and their corresponding phrases. In the generation phase, the system auto-generates context guided by the question and the assertions. Finally, it returns an answer prompting an LLM with the generated context, the assertions, and the question. Our approach outperforms previous approaches, addressing the identified gaps.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1321–1325},
numpages = {5},
keywords = {hybrid question answering, question answering, scholarly hybrid question answering, scholarly question answering},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3715099,
author = {Xin, Haoran and Sun, Ying and Wang, Chao and Xiong, Hui},
title = {LLMCDSR: Enhancing Cross-Domain Sequential Recommendation with Large Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3715099},
doi = {10.1145/3715099},
abstract = {Cross-Domain Sequential Recommendation (CDSR) aims to predict users’ preferences based on historical sequential interactions across multiple domains. Existing works focus on the overlapped users who interact in multiple domains to capture the cross-domain correlations. These methods often underperform in practical scenarios featuring both overlapped and non-overlapped users due to the limited cross-domain interactions and knowledge transfer misalignment for non-overlapped users. To address this, we leverage Large Language Models (LLMs) to facilitate CDSR by fully exploiting single-domain interactions. However, LLMs exhibit inherent limitations in handling extensive item repositories and sequential collaborative signals. Moreover, the generation reliability is compromised by the hallucination problem, potentially causing noisy and unstable outputs. To this end, we propose a novel LLMCDSR framework, which employs LLMs to predict unobserved cross-domain interactions, termed pseudo items, within single-domain interactions. Specifically, we first prompt LLMs to execute the Candidate-Free Cross-Domain Interaction Generation task. Then, we devise a Collaborative-Textual Contrastive Pre-Training strategy, learning to infuse collaborative information into textual features. Afterwards, we present a novel Relevance-Aware Meta Recall Network (RMRN) to selectively identify and retrieve high-quality pseudo items from the dataset, where the parameters are optimized in a meta-learning manner. Finally, extensive experiments on two public datasets validate the effectiveness of LLMCDSR in enhancing CDSR.},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = jan,
keywords = {Cross-domain recommendation, Sequential recommendation, Large language models}
}

@article{10.1145/3742430,
author = {Gomes Lopes, Samuel and Zhu, Shien and Alonso, Gustavo},
title = {Exploring Large Language Models for Hierarchical Hardware Circuit and Testbench Generation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3742430},
doi = {10.1145/3742430},
abstract = {Designing and verifying hardware circuits using a Hardware Description Language (HDL) is an essential but time-consuming part of hardware design. Generating the desired correct circuit and testbench code usually requires a significant engineering effort. Recently, Large Language Models (LLMs) have claimed to have strong code generation capabilities to reduce such engineering costs. Existing work has provided quantitative evaluations using LLMs for single-module, simple circuit generation. However, it is still unclear whether modern LLMs are useful in production workflows, e.g., generating correct hierarchical circuits with testbenches. And if they are capable, what are the best prompt engineering practices for hardware design? In this paper, we evaluate LLMs for HDL generation by exploring a 3-dimensional design space: commercial and open-source language models, single-module and hierarchical circuits, and prompting methods with varying complexity. We propose a 3-step design space exploration methodology to answer the two aforementioned questions. First, we explore the best prompt engineering practices across generating simple, middle, and hard single-module circuits with testbenches on CodeLLama-34B. We also define two fine-grained checklists to evaluate the circuit and testbench quality from a user’s perspective. Second, we benchmark 11 LLMs with prompt adaptation on 4 single-module circuits that CodeLLama-34B has trouble with to further find models that may be useful in a production workflow. Third, we apply the learned prompt practices on four top-level models to generate simple 2 to 4-module and more complex multi-module hierarchical circuits and testbenches. As a result, we find that some of the latest LLMs can generate correct simple hierarchical circuits and testbenches with given proper prompts, but still struggle with complex hierarchical circuits. We further provide useful guidelines from an end-user’s perspective on leveraging LLMs for hardware design.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = jun,
keywords = {Large Language Models (LLMs), Hardware Description Language (HDL), Electronic Design Automation (EDA)}
}

@inproceedings{10.1145/3674558.3674574,
author = {Ha, Thien-Loc and Ho, Trong-Bao and Nguyen, Long and Dinh, Dien},
title = {Auto Graph of Thoughts: A Hands-free and Cost Effective Method for using Graph of Thoughts},
year = {2024},
isbn = {9798400716386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674558.3674574},
doi = {10.1145/3674558.3674574},
abstract = {As powerful generative pre-trained language models like GPT become more prevalent, it is imperative to explore methods for customizing these models to suit downstream datasets. Numerous recent studies, exemplified by Chain of Thoughts (CoT), and Tree of Thoughts (ToT), among others, have underscored prompting as the primary approach for harnessing Large Language Models (LLMs) to tackle various tasks. A novel approach called Graph of Thoughts (GoT) has been introduced—framework that enhances the prompting abilities of LLMs—allows for the merging of different thoughts from these models into collaborative results, extracting the core of entire networks of thoughts, or refining thoughts through feedback loops. In our study, we identify a contemporary problem of GoT: the Prompter involves significant human intervention, suggesting that GoT costs more for both using humans as prompt engineers as well as using chatGPT to handle tasks and sometimes a human element is needed to evaluate and score at thought Error Score. To address the problem, we propose Auto Graph of Thoughts (AutoGoT) which extends GoT by allowing LLMs to freely generate prompts for each type of Thought and utilizes those prompts to generate output for each thought. Compared to GoT static prompts, our LLMs’s prompts adapt to multitask without changing the base prompt. Experiments on sorting, intersection, keyword counting, and document merging show that AutoGoT is more cost-effective and has a competitive score compared to GoT without using Error Score thought.},
booktitle = {Proceedings of the 2024 10th International Conference on Computer Technology Applications},
pages = {116–121},
numpages = {6},
keywords = {Graph of Thoughts, Large Language Models, Non-Sequential Reasoning Model, Prompt, Thought Process},
location = {Vienna, Austria},
series = {ICCTA '24}
}

@inproceedings{10.1145/3708359.3712102,
author = {Joshi, Ishika and Shahid, Simra and Venneti, Shreeya Manasvi and Vasu, Manushree and Zheng, Yantao and Li, Yunyao and Krishnamurthy, Balaji and Chan, Gromit Yeuk-Yin},
title = {CoPrompter: User-Centric Evaluation of LLM Instruction Alignment for Improved Prompt Engineering},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712102},
doi = {10.1145/3708359.3712102},
abstract = {Ensuring large language models’ (LLMs) responses align with prompt instructions is crucial for application development. Based on our formative study with industry professionals, the alignment requires heavy human involvement and tedious trial-and-error especially when there are many instructions in the prompt. To address these challenges, we introduce CoPrompter, a framework that identifies misalignment based on assessing multiple LLM responses with criteria. It proposes a method to generate evaluation criteria questions derived directly from prompt requirements and an interface to turn these questions into a user-editable checklist. Our user study with industry prompt engineers shows that CoPrompter improves the ability to identify and refine instruction alignment with prompt requirements over traditional methods, helps them understand where and how frequently models fail to follow user’s prompt requirements, and helps in clarifying their own requirements, giving them greater control over the response evaluation process. We also present the design lessons to underscore our system’s potential to streamline the prompt engineering process.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {341–365},
numpages = {25},
keywords = {HCI, LLM Evaluation, Prompt Optimization},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3678884.3681850,
author = {Liu, Jiaying (Lizzy) and Wang, Yunlong and Lyu, Yao and Su, Yiheng and Niu, Shuo and Xu, Xuhai "Orson" and Zhang, Yan},
title = {Harnessing LLMs for Automated Video Content Analysis: An Exploratory Workflow of Short Videos on Depression},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678884.3681850},
doi = {10.1145/3678884.3681850},
abstract = {Despite the growing interest in leveraging Large Language Models (LLMs) for content analysis, current studies have primarily focused on text-based content. In the present work, we explored the potential of LLMs in assisting video content analysis by conducting a case study that followed a new workflow of LLM-assisted multimodal content analysis. The workflow encompasses codebook design, prompt engineering, LLM processing, and human evaluation. We strategically crafted annotation prompts to get LLM Annotations in structured form and explanation prompts to generate LLM Explanations for a better understanding of LLM reasoning and transparency. To test LLM's video annotation capabilities, we analyzed 203 keyframes extracted from 25 YouTube short videos about depression. We compared the LLM Annotations with those of two human coders and found that LLM has higher accuracy in object and activity Annotations than emotion and genre Annotations. Moreover, we identified the potential and limitations of LLM's capabilities in annotating videos. Based on the findings, we explore opportunities and challenges for future research and improvements to the workflow. We also discuss ethical concerns surrounding future studies based on LLM-assisted video analysis.},
booktitle = {Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
pages = {190–196},
numpages = {7},
keywords = {images, large language model, large language-and-vision assistant (llava), mental health, multimodal information, user generated content, visual content},
location = {San Jose, Costa Rica},
series = {CSCW Companion '24}
}

@inproceedings{10.1145/3721146.3721944,
author = {Silvestre, Pedro F. and Pietzuch, Peter},
title = {Systems Opportunities for LLM Fine-Tuning using Reinforcement Learning},
year = {2025},
isbn = {9798400715389},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721146.3721944},
doi = {10.1145/3721146.3721944},
abstract = {Reinforcement learning-based fine-tuning (RLFT) has emerged as a crucial workload for enhancing large language models (LLMs). RLFT workflows are challenging, involving nested loops, multiple models, dynamically shaped tensors and interleaving sequential generation and parallel inference tasks. Despite these complexities, current RLFT engines rely on coarse-grained algorithm representations, treating each component as an independently optimized black-box. As a result, RLFT engines suffer from redundant computations, scheduling overhead, inefficient memory management, and missed opportunities for parallelism.We argue that a fine-grained representation is needed to enable holistic optimization for RLFT workloads. Additionally, we demonstrate that existing declarative deep learning engines fail to optimize RLFT workloads end-to-end due to their need for static tensor shapes and loop bounds, leading to excessive peak memory usage and unnecessary computations. Through micro-benchmarks, we quantify these inefficiencies and show that addressing them could enable more efficient and flexible execution. We propose an RLFT system design based on a fine-granularity representation, opening the door to generalizable optimizations, and paving the way for more scalable and efficient RLFT systems.},
booktitle = {Proceedings of the 5th Workshop on Machine Learning and Systems},
pages = {90–99},
numpages = {10},
location = {World Trade Center, Rotterdam, Netherlands},
series = {EuroMLSys '25}
}

@inproceedings{10.1145/3613904.3641904,
author = {Cheng, Furui and Zouhar, Vil\'{e}m and Arora, Simran and Sachan, Mrinmaya and Strobelt, Hendrik and El-Assady, Mennatallah},
title = {RELIC: Investigating Large Language Model Responses using Self-Consistency},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641904},
doi = {10.1145/3613904.3641904},
abstract = {Large Language Models (LLMs) are notorious for blending fact with fiction and generating non-factual content, known as hallucinations. To address this challenge, we propose an interactive system that helps users gain insight into the reliability of the generated text. Our approach is based on the idea that the self-consistency of multiple samples generated by the same LLM relates to its confidence in individual claims in the generated texts. Using this idea, we design RELIC, an interactive system that enables users to investigate and verify semantic-level variations in multiple long-form responses. This allows users to recognize potentially inaccurate information in the generated text and make necessary corrections. From a user study with ten participants, we demonstrate that our approach helps users better verify the reliability of the generated text. We further summarize the design implications and lessons learned from this research for future studies of reliable human-LLM interactions.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {647},
numpages = {18},
keywords = {hallucination detection, human-AI interaction, natural language processing},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3610661.3616127,
author = {Wu, Zixiu and Helaoui, Rim and Reforgiato Recupero, Diego and Riboni, Daniele},
title = {Towards Effective Automatic Evaluation of Generated Reflections for Motivational Interviewing},
year = {2023},
isbn = {9798400703218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610661.3616127},
doi = {10.1145/3610661.3616127},
abstract = {Reflection is an essential counselling skill where the therapist communicates their understanding of the client’s words to the client. Recent studies have explored language-model-based reflection generation, but automatic quality evaluation of generated reflections remains under-explored. In this work, we investigate automatic evaluation on one fundamental quality aspect: coherence and context-consistency. We test a range of automatic evaluators/metrics and examine their correlations with expert judgement. We find that large language models (LLMs) as zero-shot evaluators achieve the best performance, while other metrics correlate poorly with expert judgement. We also demonstrate that diverse LLM-as-evaluator configurations need to be explored to find the best setup.},
booktitle = {Companion Publication of the 25th International Conference on Multimodal Interaction},
pages = {368–373},
numpages = {6},
keywords = {automatic evaluation, motivational interviewing, reflection},
location = {Paris, France},
series = {ICMI '23 Companion}
}

@article{10.1145/3631504.3631518,
author = {Amer-Yahia, Sihem and Bonifati, Angela and Chen, Lei and Li, Guoliang and Shim, Kyuseok and Xu, Jianliang and Yang, Xiaochun},
title = {From Large Language Models to Databases and Back: A Discussion on Research and Education},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0163-5808},
url = {https://doi.org/10.1145/3631504.3631518},
doi = {10.1145/3631504.3631518},
abstract = {In recent years, large language models (LLMs) have garnered increasing attention from both academia and industry due to their potential to facilitate natural language processing (NLP) and generate highquality text. Despite their benefits, however, the use of LLMs is raising concerns about the reliability of knowledge extraction. The combination of DB research and data science has advanced the state of the art in solving real-world problems, such as merchandise recommendation and hazard prevention [30]. In this discussion, we explore the challenges and opportunities related to LLMs in DB and data science research and education.},
journal = {SIGMOD Rec.},
month = nov,
pages = {49–56},
numpages = {8}
}

@inproceedings{10.1145/3632620.3671097,
author = {Ali, Murtaza and Rao, Prerna and Mai, Yifan and Xie, Benjamin},
title = {Using Benchmarking Infrastructure to Evaluate LLM Performance on CS Concept Inventories: Challenges, Opportunities, and Critiques},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671097},
doi = {10.1145/3632620.3671097},
abstract = {BACKGROUND AND CONTEXT. The pace of advancement of large language models (LLMs) motivates the use of existing infrastructure to automate the evaluation of LLM performance on computing education tasks. Concept inventories are well suited for evaluation because of their careful design and prior validity evidence. OBJECTIVES. Our research explores the feasibility of using an automated benchmarking framework to evaluate computer science (CS) concept inventories. We explore three primary objectives: evaluation of LLM performance on the SCS1 and BDSI concept inventories; informal expert panel review of items which had variations between LLM and expected student performance; and description of challenges with using benchmarking infrastructure as a methodological innovation. METHOD. We used the Holistic Evaluation of Language Models (HELM) framework to evaluate the SCS1 and BDSI against 10 LLMS with zero-shot and few-shot in-context learning: GPT (3.5, 4.0), Claude (1.3, 2.0, 2.1), Llama (7B, 13B, 70B), Mistral v0.1 7B, and Mixtral 8x7B. We used psychometric data from prior studies to measure knowledge levels for each LLM run. We then conducted an informal expert review to qualitatively explore how question design, CS content knowledge, and LLM design may explain differences between LLM and expected student performances. FINDINGS. Our quantitative analysis found that most LLM response patterns reflected a below average introductory computing student with the SCS1 and did not fit the psychometric 2PL model for the BDSI. Our qualitative analysis identified that LLMs performed well on code infill questions, but poorly on nested conditionals, runtime analysis, and longer questions. We also identified several methodological challenges related to item security, translation, the structure when using HELM. IMPLICATIONS. We consider the feasibility of using automated benchmarking as a methodology to support more reproducible, replicable, and rigorous investigations to understand the intersection of LLM capabilities, computing concepts, and assessment design. We also consider connections between psychometric approaches and LLM evaluations to inform the design of computing assessments that are more resilient to LLM advancements.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {452–468},
numpages = {17},
keywords = {benchmarking, computing education, concept inventories, large language models, psychometrics},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3613904.3641960,
author = {Wang, Xinru and Kim, Hannah and Rahman, Sajjadur and Mitra, Kushan and Miao, Zhengjie},
title = {Human-LLM Collaborative Annotation Through Effective Verification of LLM Labels},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641960},
doi = {10.1145/3613904.3641960},
abstract = {Large language models (LLMs) have shown remarkable performance across various natural language processing (NLP) tasks, indicating their significant potential as data annotators. Although LLM-generated annotations are more cost-effective and efficient to obtain, they are often erroneous for complex or domain-specific tasks and may introduce bias when compared to human annotations. Therefore, instead of completely replacing human annotators with LLMs, we need to leverage the strengths of both LLMs and humans to ensure the accuracy and reliability of annotations. This paper presents a multi-step human-LLM collaborative approach where (1) LLMs generate labels and provide explanations, (2) a verifier assesses the quality of LLM-generated labels, and (3) human annotators re-annotate a subset of labels with lower verification scores. To facilitate human-LLM collaboration, we make use of LLM’s ability to rationalize its decisions. LLM-generated explanations can provide additional information to the verifier model as well as help humans better understand LLM labels. We demonstrate that our verifier is able to identify potentially incorrect LLM labels for human re-annotation. Furthermore, we investigate the impact of presenting LLM labels and explanations on human re-annotation through crowdsourced studies.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {303},
numpages = {21},
keywords = {Human-LLM collaborative annotation, LLM annotation, NLP, self-rationalization, text annotation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3706119,
author = {Fatemi, Sorouralsadat and Hu, Yuheng and Mousavi, Maryam},
title = {A Comparative Analysis of Instruction Fine-Tuning Large Language Models for Financial Text Classification},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3706119},
doi = {10.1145/3706119},
abstract = {Large Language Models (LLMs) have demonstrated impressive capabilities across diverse Natural Language Processing (NLP) tasks, including language understanding, reasoning, and generation. However, general-domain LLMs often struggle with financial tasks due to the technical and specialized nature of financial texts. This study investigates the efficacy of instruction fine-tuning smaller-scale LLMs, including Mistral-7B, Llama3-8B, and Phi3-mini, to enhance their performance in financial text classification tasks. We fine-tuned both instruction-tuned and base models across four financial classification tasks, achieving significant improvements in task-specific performance. Furthermore, we evaluated the zero-shot capabilities of these fine-tuned models on three unseen complex financial tasks, including argument classification, deal completeness classification, and causal classification. Our results indicate while base model fine-tuning led to greater degradation, instruction-tuned models maintained more robust performance. To address this degradation, we employed model merging techniques, integrating single-task domain-specific fine-tuned models with the base model. Using this merging method resulted in significant enhancements in zero-shot performance, even exceeding the original model’s accuracy on certain datasets. Our findings underscore the effectiveness of instruction fine-tuning and model merging for adapting LLMs to specialized financial text classification tasks.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {6},
numpages = {30},
keywords = {Large language models, parameter-efficient fine-tuning, instruction fine-tuning, text classification, finance}
}

@inproceedings{10.1145/3658644.3670334,
author = {Sun, Haochen and Li, Jason and Zhang, Hongyang},
title = {zkLLM: Zero Knowledge Proofs for Large Language Models},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670334},
doi = {10.1145/3658644.3670334},
abstract = {The recent surge in artificial intelligence (AI), characterized by the prominence of large language models (LLMs), has ushered in fundamental transformations across the globe. However, alongside these advancements, concerns surrounding the legitimacy of LLMs have grown, posing legal challenges to their extensive applications. Compounding these concerns, the parameters of LLMs are often treated as intellectual property, restricting direct investigations.In this study, we address a fundamental challenge within the realm of AI legislation: the need to establish the authenticity of outputs generated by LLMs. To tackle this issue, we present zkLLM, which stands as the inaugural specialized zero-knowledge proof tailored for LLMs to the best of our knowledge. Addressing the persistent challenge of non-arithmetic operations in deep learning, we introduce tlookup, a parallelized lookup argument designed for non-arithmetic tensor operations in deep learning, offering a solution with no asymptotic overhead. Furthermore, leveraging the foundation of tlookup, we introduce zkAttn, a specialized zero-knowledge proof crafted for the attention mechanism, carefully balancing considerations of running time, memory usage, and accuracy.Empowered by our fully parallelized CUDA implementation, zkLLM emerges as a significant stride towards achieving efficient zero-knowledge verifiable computations over LLMs. Remarkably, for LLMs boasting 13 billion parameters, our approach enables the generation of a correctness proof for the entire inference process in under 15 minutes. The resulting proof, compactly sized at less than 200 kB, is designed to uphold the privacy of the model parameters, ensuring no inadvertent information leakage.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4405–4419},
numpages = {15},
keywords = {large language models, zero-knowledge proofs},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3627673.3679753,
author = {Zhang, Zhiqiang and Wen, Liqiang and Zhao, Wen},
title = {A GAIL Fine-Tuned LLM Enhanced Framework for Low-Resource Knowledge Graph Question Answering},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679753},
doi = {10.1145/3627673.3679753},
abstract = {Recent studies on knowledge graph question answering (KGQA) have focused on tackling complex inquiries to enhance the applicability of models in real-life settings. Unfortunately, KGQA models encounter significant challenges due to the lack of high-quality annotated data, making it difficult to accurately answer the diverse range of complex natural language questions posed by users. Inspired by the recent success of Large Language Models (LLMs), the burden associated with manual annotation can be mitigated by utilizing LLMs. However, the data generated directly by LLMs may exhibit a potential distribution discrepancy with real user queries. In this paper, we present an enhancement framework that utilizes Generative Adversarial Imitation Learning (GAIL) to fine-tune LLMs, which can address the challenges inherent in the low-resource KGQA task. Specifically, based on GAIL, the LLMs act as the generator aiming to output samples resembling expert demonstrations. Meanwhile, we utilize a paired discriminator to assess the authenticity of generated sequences and their relevance to the input SPARQL queries. Additionally, proximal policy optimization is leveraged to stabilize the training of the generator. Furthermore, we employ an automated algorithm to controllably sample various SPARQL queries from the knowledge graph, subsequently transforming them into corresponding natural language questions using fine-tuned LLMs. The synthetic dataset can serve as supplementary data for training lightweight KGQA models in real-world scenarios. Experimental results on the WebQuestionsSP, ComplexWebQuestions, and GrailQA show that our framework achieves state-of-the-art performance in a low-resource setting, even approaching the performance of supervised models.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3300–3309},
numpages = {10},
keywords = {generative adversarial imitation learning, knowledge graph, large language model, question answering},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3680528.3687662,
author = {Wang, Kuan-Chieh and Ostashev, Daniil and Fang, Yuwei and Tulyakov, Sergey and Aberman, Kfir},
title = {MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation},
year = {2024},
isbn = {9798400711312},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680528.3687662},
doi = {10.1145/3680528.3687662},
abstract = {We introduce a new architecture for personalization of text-to-image diffusion models, coined Mixture-of-Attention (MoA). Inspired by the Mixture-of-Experts mechanism utilized in large language models (LLMs), MoA distributes the generation workload between two attention pathways: a personalized branch and a non-personalized prior branch. MoA is designed to retain the original model’s prior by fixing its attention layers in the prior branch, while minimally intervening in the generation process with the personalized branch that learns to embed subjects in the layout and context generated by the prior branch. A novel routing mechanism manages the distribution of pixels in each layer across these branches to optimize the blend of personalized and generic content creation. Once trained, MoA facilitates the creation of high-quality, personalized images featuring multiple subjects with compositions and interactions as diverse as those generated by the original model. Crucially, MoA enhances the distinction between the model’s pre-existing capability and the newly augmented personalized intervention, thereby offering a more disentangled subject-context control that was previously unattainable. Please visit the submitted (supplementary) website.},
booktitle = {SIGGRAPH Asia 2024 Conference Papers},
articleno = {3},
numpages = {12},
keywords = {Personalization, Text-to-image Generation, Diffusion Models},
location = {Tokyo, Japan},
series = {SA '24}
}

@inproceedings{10.1145/3652620.3687782,
author = {Lamas, Victor and R. Luaces, Miguel and Garcia-Gonzalez, Daniel},
title = {DSL-Xpert: LLM-driven Generic DSL Code Generation},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687782},
doi = {10.1145/3652620.3687782},
abstract = {Nowadays, large language models (LLMs) are an extremely useful and fast tool to complement and help in many jobs and current problems. However, there are cases where a pretty specific vocabulary is used in which these models were not previously trained, leading to less satisfactory results. More specifically, these models are less effective when dealing with less-known or unpublished domain-specific languages (DSLs). Within this field, the automatic generation of code based on such languages, starting from natural language, would speed up the development times of any related project, as well as the understanding of such DSLs. Therefore, this paper presents a tool in which developers can perform what is known as semantic parsing. In other words, the developer can ask a pre-trained LLM to translate a natural language instruction into the vocabulary of the established DSL. Thus, by setting the DSL grammar as context (grammar prompting) and providing usage examples (few-shot learning), the LLM can quickly generate reliable domain-specific code, significantly improving the quality of life of the developers. A video demonstration of the tool is shown in the following link: https://zenodo.org/records/12610506.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {16–20},
numpages = {5},
keywords = {domain-specific languages (DSLS), large language models (LLMS), semantic parsing, grammar prompting, few-shot learning},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3652620.3687810,
author = {Tabassum, Mirza Rehenuma and Ritchie, Matthew J. and Mustafiz, Sadaf and Kienzle, J\"{o}rg},
title = {Using LLMs for Use Case Modelling of IoT Systems: An Experience Report},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687810},
doi = {10.1145/3652620.3687810},
abstract = {Requirements engineering (RE) plays an essential role in the success of system and software development. Textual use case models are valuable for capturing diverse scenarios describing the interactions between the system and its actors, but their development, particularly for the Internet of Things (IoT), can be tedious and error-prone due to the added complexities and heterogeneous nature of such systems. Automating requirements elicitation and specification tasks with the use of generative AI is highly desirable. This paper explores the potential of large language models (LLMs) for generating interaction models for IoT systems from informal problem descriptions. We investigate the capabilities of OpenAI's GPT-4 and Google's Gemini for generating standard and UCM4IoT textual use cases by carrying out a comparative study using four IoT applications. While both of these LLMs show promise as supporting tools, our findings indicate a need for further refinement and domain-specific training to enhance their precision and reliability in requirements development for the IoT domain.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {611–619},
numpages = {9},
keywords = {requirements engineering, use case modelling, large language model, LLM, model-based development},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inbook{10.1145/3677389.3702555,
author = {Wang, Yuzhang and Yu, Peizhou and He, Guoxiu},
title = {Silent LLMs: Using LoRA to Enable LLMs to Identify Hate Speech},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702555},
abstract = {The detection of hate speech on social networks presents significant challenges due to its increasingly subtle nature. The advent of large language models (LLMs) has revolutionized text understanding and generation, presenting novel avenues for hate speech detection. This study evaluates the performance of the ChatGLM model in detecting hate speech through a small sample prompt method. Our analysis uncovers three key limitations when employing the LLMs to directly generate answers: inconsistency in output format, the illusion of comprehensiveness inherent in LLMs, and the inability to respond due to security concerns. To mitigate these limitations, we investigate four LLMs: LLaMA, Llama-2, Llama-3, and ChatGLM-3. These models are equipped with Multi-Layer Perception (MLP) and Low-Rank Adaptation (LoRA), which specifically tailored for hate speech detection. Extensive comparisons with baseline models are conducted across three hate speech datasets with six classification tasks. Our findings demonstrate that our improved LLMs can surpass traditional methods in detecting hate speech, highlighting their potential for further improvement and refinement in addressing this critical societal issue.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {53},
numpages = {5}
}

@inproceedings{10.1145/3625468.3652193,
author = {Rachabatuni, Pavan Kartheek and Principi, Filippo and Mazzanti, Paolo and Bertini, Marco},
title = {Context-aware chatbot using MLLMs for Cultural Heritage},
year = {2024},
isbn = {9798400704123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625468.3652193},
doi = {10.1145/3625468.3652193},
abstract = {Multi-modal Large Language Models (MLLMs) are currently an extremely active research topic for the multimedia and computer vision communities, and show a significant impact in visual analysis and text generation tasks. MLLM's are well-versed in integrated understanding, analysis of complex data from cross modalities (i.e. text-image) and text generation with chat abilities. Almost all MLLM's, focus on alignment of image features to textual features for downstream text generation tasks includes detailed image description, visual question answering, stories and poems generation, phrase grounding, etc.. However, when focusing on visual question answering, questions that are highly relevant to the context of an image may not be answered correctly with the existing MLLM's, contrary to questions that are related to visual aspects. Moreover, generating meta data (context) for an image using present day MLLM's is hard task due to hallucinating characteristic of underlying Large Language Models (LLM's), and adequate contextual information cannot be directly derived from an image based perspective.Considering the cultural heritage domain, these issues hamper the introduction of multimedia chatbots as tools to support learning and understanding artworks, since contextual information is typically needed to better understand the content of the artworks themselves, and museum curators require that scientifically accurate information is provided to the users of such systems. In this paper we present a system that combines contextual description of the artworks to enhance the contextual visual question answering task.},
booktitle = {Proceedings of the 15th ACM Multimedia Systems Conference},
pages = {459–463},
numpages = {5},
keywords = {Chatbot, Cultural Heritage, Digital Learning, Museums, Visual Question Answering},
location = {Bari, Italy},
series = {MMSys '24}
}

@inproceedings{10.1145/3568813.3600139,
author = {Hellas, Arto and Leinonen, Juho and Sarsa, Sami and Koutcheme, Charles and Kujanp\"{a}\"{a}, Lilja and Sorva, Juha},
title = {Exploring the Responses of Large Language Models to Beginner Programmers’ Help Requests},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600139},
doi = {10.1145/3568813.3600139},
abstract = {Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence. Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers’ help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on. Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students’ code and assessed the LLM-generated answers both quantitatively and qualitatively. Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 57% of the time). False positives are common (40% chance for GPT-3.5). The advice that the LLMs provide on the issues is often sensible. The LLMs perform better on issues involving program logic rather than on output formatting. Model solutions are frequently provided even when the LLM is prompted not to. LLM responses to prompts in a non-English language are only slightly worse than responses to English prompts. Implications: Our results continue to highlight the utility of LLMs in programming education. At the same time, the results highlight the unreliability of LLMs: LLMs make some of the same mistakes that students do, perhaps especially when formatting output as required by automated assessment systems. Our study informs teachers interested in using LLMs as well as future efforts to customize LLMs for the needs of programming education.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {93–105},
numpages = {13},
keywords = {CS1, GPT, OpenAI Codex, automatic feedback, help seeking, introductory programming education, large language models, student questions},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@article{10.1145/3652951,
author = {Pereira, Jayr and Assumpcao, Andre and Trecenti, Julio and Airosa, Luiz and Lente, Caio and Cl\'{e}to, Jhonatan and Dobins, Guilherme and Nogueira, Rodrigo and Mitchell, Luis and Lotufo, Roberto},
title = {INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
url = {https://doi.org/10.1145/3652951},
doi = {10.1145/3652951},
abstract = {This article introduces Instru\c{c}\~{a}o Assistida com Intelig\^{e}ncia Artificial (INACIA), a groundbreaking system designed to integrate Large Language Models (LLMs) into the operational framework of Brazilian Federal Court of Accounts. The system automates various stages of case analysis, including basic information extraction, admissibility examination, Periculum in mora and Fumus boni iuris analyses, and recommendations generation. Through a series of experiments, we demonstrate INACIA’s potential in extracting relevant information from case documents, evaluating its legal plausibility, and formulating propositions for judicial decision-making. Utilizing a validation dataset alongside LLMs, our evaluation methodology, to the best of our knowledge, presents a novel approach to assessing system performance, correlating highly with human judgment. These results underscore INACIA’s potential in complex legal task handling while also acknowledging the current limitations. This study discusses possible improvements and the broader implications of applying Artificial Intelligence (AI) in legal contexts, suggesting that INACIA represents a significant step toward integrating AI in legal systems globally, albeit with cautious optimism grounded in the empirical findings.},
journal = {Digit. Gov.: Res. Pract.},
month = feb,
articleno = {6},
numpages = {20},
keywords = {Brazilian Federal Court of Accounts (TCU), Large Language Models (LLMs), Artificial Intelligence-Assisted Legal Instruction, AI in Legal Systems}
}

@inproceedings{10.1145/3706598.3713362,
author = {Deva, Roshini and Ramani, Dhruv and Divate, Tanvi and Jalota, Suhani and Ismail, Azra},
title = {"Kya family planning after marriage hoti hai?": Integrating Cultural Sensitivity in an LLM Chatbot for Reproductive Health},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713362},
doi = {10.1145/3706598.3713362},
abstract = {Access to sexual and reproductive health information remains a challenge in many communities globally, due to cultural taboos and limited availability of healthcare providers. Public health organizations are increasingly turning to Large Language Models (LLMs) to improve access to timely and personalized information. However, recent HCI scholarship indicates that significant challenges remain in incorporating context awareness and mitigating bias in LLMs. In this paper, we study the development of a culturally-appropriate LLM-based chatbot for reproductive health with underserved women in urban India. Through user interactions, focus groups, and interviews with multiple stakeholders, we examine the chatbot’s response to sensitive and highly contextual queries on reproductive health. Our findings reveal strengths and limitations of the system in capturing local context, and complexities around what constitutes “culture”. Finally, we discuss how local context might be better integrated, and present a framework to inform the design of culturally-sensitive chatbots for community health.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {638},
numpages = {23},
keywords = {LLM, chatbot, reproductive health, HCI4D},
location = {
},
series = {CHI '25}
}

@inbook{10.1145/3728725.3728761,
author = {Fang, Yong},
title = {Wasserstein GAN-Based Android Certificate Validation Vulnerability Detection Framework},
year = {2025},
isbn = {9798400713453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3728725.3728761},
abstract = {This paper presents an Android certificate validation vulnerability detection framework that integrates static analysis, adversarial sample training, and optimization via large language models. Centered around the Wasserstein Generative Adversarial Network, the framework aims to enhance the robustness and generalization ability of static detection models against complex and obfuscated attack patterns. Static analysis is performed on 2,000 popular Android applications from the androzoo dataset, with code and configuration features extracted, focusing on certificate-related API usage, permission declarations, and network security settings. Among them, 110 APKs are identified as containing high-risk certificate misconfigurations. Based on these features, a Transformer-based model is constructed for feature vectorization and vulnerability identification. To further improve model robustness, WGAN is employed to generate adversarial samples that mimic real-world evasive vulnerabilities, which are used for adversarial training. Additionally, large language models are used to perform In-Context Learning, enabling semantic filtering, sample refinement, and iterative generator feedback. This results in a closed-loop, self-improving detection pipeline that combines detection, optimization, and feedback. Experimental results across standard, adversarial, and cross-domain scenarios demonstrate that the proposed framework achieves an F1 score of 0.91 and reduces the false positive rate to 7.2%, significantly outperforming traditional static detection tools in both accuracy and resilience.},
booktitle = {Proceedings of the 2025 2nd International Conference on Generative Artificial Intelligence and Information Security},
pages = {231–236},
numpages = {6}
}

@inproceedings{10.1145/3640457.3688072,
author = {Lops, Pasquale and Silletti, Antonio and Polignano, Marco and Musto, Cataldo and Semeraro, Giovanni},
title = {Reproducibility of LLM-based Recommender Systems: the Case Study of P5 Paradigm},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688072},
doi = {10.1145/3640457.3688072},
abstract = {Recommender systems can significantly benefit from the availability of pre-trained large language models (LLMs), which can serve as a basic mechanism for generating recommendations based on detailed user and item data, such as text descriptions, user reviews, and metadata. On the one hand, this new generation of LLM-based recommender systems paves the way for dealing with traditional limitations, such as cold-start and data sparsity. Still, on the other hand, this poses fundamental challenges for their accountability. Reproducing experiments in the new context of LLM-based recommender systems is challenging for several reasons. New approaches are published at an unprecedented pace, which makes difficult to have a clear picture of the main protocols and good practices in the experimental evaluation. Moreover, the lack of proper frameworks for LLM-based recommendation development and evaluation makes the process of benchmarking models complex and uncertain. In this work, we discuss the main issues encountered when trying to reproduce P5 (Pretrain, Personalized Prompt, and Prediction Paradigm), one of the first works unifying different recommendation tasks in a shared language modeling and natural language generation framework. Starting from this study, we have developed LaikaLLM, a framework for training and evaluating LLMs, specifically for the recommendation task. It has been used to perform several experiments to assess the impact of using different LLMs, different personalization strategies, and a novel set of more informative prompts on the overall performance of recommendations in a fully reproducible environment.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {116–125},
numpages = {10},
keywords = {LLMs, Large Language Models, Recommendation Frameworks, Recommender Systems, Reproducibility Analysis},
location = {Bari, Italy},
series = {RecSys '24}
}

@article{10.1145/3729536,
author = {Liu, Fenglin and Ren, Xuancheng and Zhao, Guangxiang and You, Chenyu and Ma, Sherry and Wu, Xian and Fan, Wei and Sun, Xu},
title = {Rethinking Natural Language Generation with Layer-Wise Multi-View Decoding},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {5},
issn = {1556-4681},
url = {https://doi.org/10.1145/3729536},
doi = {10.1145/3729536},
abstract = {In natural language generation, language models, particularly those based on decoder-only architectures as in popular Large Language Models (LLMs), have demonstrated impressive performance across a wide range of tasks. However, encoder-decoder architectures remain highly effective for tasks involving non-text data, such as images and time-series data. The decoder relies on the attention mechanism to efficiently extract information from the encoder. While it is common practice to draw information from only the last encoder layer, this might lead to insufficient training of the encoder layer stack due to the hierarchy bypassing problem. In this work, we propose layer-wise multi-view decoding for improved encoder-decoder language models, where for each decoder layer, together with the representations from the last encoder layer, which serve as a global view, those from other encoder layers are supplemented for a stereoscopic view of the source inputs. Systematic experiments and analyses show that we successfully address the hierarchy bypassing problem, require almost negligible parameter increase, and improve the performance of sequence learning with deep representations on diverse tasks, i.e., machine translation, abstractive summarization, image captioning, video captioning, medical report generation, and paraphrase generation. In particular, our approach achieves new state-of-the-art results on benchmark datasets, including a low-resource machine translation dataset and low-resource medical report generation datasets.},
journal = {ACM Trans. Knowl. Discov. Data},
month = jun,
articleno = {106},
numpages = {25},
keywords = {Sequence Learning, Natural Language Generation, Attention Mechanism, Deep Representations, Large Language Models}
}

@inproceedings{10.1145/3708359.3712104,
author = {Kazemitabaar, Majeed and Huang, Oliver and Suh, Sangho and Henley, Austin Z and Grossman, Tovi},
title = {Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712104},
doi = {10.1145/3708359.3712104},
abstract = {Novice programmers are increasingly relying on Large Language Models (LLMs) to generate code for learning programming concepts. However, this interaction can lead to superficial engagement, giving learners an illusion of learning and hindering skill development. To address this issue, we conducted a systematic design exploration to develop seven cognitive engagement techniques aimed at promoting deeper engagement with AI-generated code. In this paper, we describe our design process, the initial seven techniques and results from a between-subjects study (N=82). We then iteratively refined the top techniques and further evaluated them through a within-subjects study (N=42). We evaluate the friction each technique introduces, their effectiveness in helping learners apply concepts to isomorphic tasks without AI assistance, and their success in aligning learners’ perceived and actual coding abilities. Ultimately, our results highlight the most effective technique: guiding learners through the step-by-step problem-solving process, where they engage in an interactive dialog with the AI, prompting what needs to be done at each stage before the corresponding code is revealed.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {695–714},
numpages = {20},
keywords = {AI-Assisted Programming, Generative AI, Copilot, ChatGPT, Cognitive Engagement Enhancement, AI-Assisted Learning, Cognitive Forcing Functions, Task Decomposition, Learning Outcomes},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3603287.3651196,
author = {Ustymenko, Stanislav and Phadke, Abhishek},
title = {Promise and Challenges of Generative AI in Healthcare Information Systems},
year = {2024},
isbn = {9798400702372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603287.3651196},
doi = {10.1145/3603287.3651196},
abstract = {Large Language Models (LLMs) based on pretrained transformer architectures, such as Generative Pretrained Transformer 4 (GPT-4) from OpenAI, are on the cutting age of artificial intelligence research. Along with generating abundant academic literature, these models are the basis of numerous practical systems widely utilized by end users and organizations. In healthcare information systems, there are many case studies and research prototypes demonstrating the promise of applying GPT-like programs to numerous practical natural language processing tasks. At the same time, current limitations of LLMs prevent their safe deployments in professional environments. In this study, we give an overview of capabilities, limitations, and risks associated with current iterations of LLMs. We provide an overview of literature on using LLMs in healthcare context. Finally, we present a framework of generic healthcare IT system utilizing LLMs, and discuss avenues for future research.},
booktitle = {Proceedings of the 2024 ACM Southeast Conference},
pages = {223–228},
numpages = {6},
keywords = {GPT, Healthcare IT, Large Language Models, Software Engineering},
location = {Marietta, GA, USA},
series = {ACMSE '24}
}

@inproceedings{10.1145/3698062.3698096,
author = {Asadi, Amir Reza and Kropczynski, Jess},
title = {Qualitative Data-Driven Personas: Designing an Interactive System for Creating AI Personas},
year = {2024},
isbn = {9798400717086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698062.3698096},
doi = {10.1145/3698062.3698096},
abstract = {This research introduces PersonaDoc, a system that allows users to create interactive AI personas from qualitative user research data using large language models (LLMs). The system provides an interactive platform for persona creation and utilization, allowing users to define persona attributes, select data sources, and engage with AI personas through interviews, quote generation, social media post synthesis, social circle exploration, and narrative generation. The study discusses the development of personas to make research data reusable and the potential of AI personas to replace human subjects in research settings, present an interactive system for contextualizing knowledge into stories and conversations, and open the debate for challenges and opportunities of creating personas. A pilot think-aloud study with five participants indicated a positive reception toward interactive AI personas.},
booktitle = {Proceedings of the 2024 The 6th World Symposium on Software Engineering (WSSE)},
pages = {232–236},
numpages = {5},
keywords = {Personas, Human-AI Collaboration, Knowledge Management, LLM, UX Study},
location = {
},
series = {WSSE '24}
}

@inproceedings{10.1145/3708557.3716360,
author = {Valente, Pedro and Magalh\~{a}es, Joao and N\'{o}brega, Rui},
title = {Managing Proactivity in E-Commerce Interfaces: Context-Aware Conversational Agents for Enhanced User Engagement},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716360},
doi = {10.1145/3708557.3716360},
abstract = {Proactive conversational agents (CAs) are often underutilized in e-Commerce due to misalignment with user expectations and integration challenges. In this demo, we present a hybrid e-Commerce interface that combines a browsing window with a proactive conversational agent, leveraging context-aware interactions to enhance the user’s experience. The interface dynamically adapts to user actions, repositioning the CA to centralize its recommendations and foster engagement through visual design nudges. By integrating a graph-based context model with a large language model (LLM) for intent detection and response generation, the system provides precise, multi-turn recommendations and action-oriented dialogues. A formative user study (N=10) demonstrated the hybrid interface’s effectiveness, achieving higher user engagement and satisfaction compared to standalone browsing or conversational interfaces.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {159–162},
numpages = {4},
keywords = {Conversational Agents, Proactive Conversational Agents, E-Commerce, Virtual Shopping, Recommendation Systems},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3626252.3630773,
author = {Woodrow, Juliette and Malik, Ali and Piech, Chris},
title = {AI Teaches the Art of Elegant Coding: Timely, Fair, and Helpful Style Feedback in a Global Course},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630773},
doi = {10.1145/3626252.3630773},
abstract = {Teaching students how to write code that is elegant, reusable, and comprehensible is a fundamental part of CS1 education. However, providing this "style feedback" in a timely manner has proven difficult to scale. In this paper, we present our experience deploying a novel, real-time style feedback tool in Code in Place, a large-scale online CS1 course. Our tool is based on the latest breakthroughs in large-language models (LLMs) and was carefully designed to be safe and helpful for students. We used our Real-Time Style Feedback tool (RTSF) in a class with over 8,000 diverse students from across the globe and ran a randomized control trial to understand its benefits. We show that students who received style feedback in real-time were five times more likely to view and engage with their feedback compared to students who received delayed feedback. Moreover, those who viewed feedback were more likely to make significant style-related edits to their code, with over 79% of these edits directly incorporating their feedback. We also discuss the practicality and dangers of LLM-based tools for feedback, investigating the quality of the feedback generated, LLM limitations, and techniques for consistency, standardization, and safeguarding against demographic bias, all of which are crucial for a tool utilized by students.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1442–1448},
numpages = {7},
keywords = {cs1, deployed at scale, gpt, llms, real time, style feedback},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3708635.3708655,
author = {Yu, Hong Qing and Sutton, Jack and O'Neill, Sam and Reiff-Marganiec, Stephan},
title = {Case Studies on LLM Centric and Services Oriented Data Analytics Agent Development},
year = {2025},
isbn = {9798400717765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708635.3708655},
doi = {10.1145/3708635.3708655},
abstract = {This paper presents a novel service orchestration framework for a chatbot application focused on data analytics questions. The framework integrates Large Language Models (LLMs) with service-oriented computing to transform data analytics into a dynamic, conversational experience. The approach leverages advancements in LLM technology to enable real-time, automated data insights via chatbot interfaces, making complex data analytics accessible across various industries. In addition, the data will be processed and analysis at edge-machine rather than post all the data directly to the LLMs on the cloud. Therefore, the Central to the framework is the local Micro Analytics Service (MAS) and a dynamic service-data coordination framework, which together facilitate the decoupling of data from business logic, allowing for intuitive engagement with analytics processes. Through two case studies, retail data analysis and regional healthcare planning, the ability of the framework to provide actionable insights through natural language prompts is demonstrated, showcasing its potential to significantly reduce barriers to sophisticated data analytics. The evaluation reveals strong performance in data connection and code generation, with identified areas for improvement in visualizations and handling complex data scenarios.},
booktitle = {Proceedings of the 2024 13th International Conference on Software and Information Engineering},
pages = {69–76},
numpages = {8},
keywords = {LLM-driven service orchestration, Dynamic data analytics services, Services Computing},
location = {
},
series = {ICSIE '24}
}

@article{10.1145/3678585,
author = {Gao, Yi and Xiao, Kaijie and Li, Fu and Xu, Weifeng and Huang, Jiaming and Dong, Wei},
title = {ChatIoT: Zero-code Generation of Trigger-action Based IoT Programs},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678585},
doi = {10.1145/3678585},
abstract = {Trigger-Action Program (TAP) is a simple but powerful format to realize intelligent IoT applications, especially in home automation scenarios. Existing trace-driven approaches and in-situ programming approaches depend on either customized interaction commands or well-labeled datasets, resulting in limited applicable scenarios. In this paper, we propose ChatIoT, a zero-code TAP generation system based on large language models (LLMs). With a novel context-aware compressive prompting scheme, ChatIoT is able to automatically generate TAPs from user requests in a token-efficient manner and deploy them to the TAP runtime. Further, for those TAP requests including unknown sensing abilities, ChatIoT can also generate new AI models with knowledge distillation by multimodal LLMs, with a novel model customization method based on deep reinforcement learning. We implemented ChatIoT and evaluated its performance extensively. Results show that ChatIoT can reduce token consumption by 26.1-84.9% and improve TAP generation accuracy by 4.2-65.5% compared to state-of-the-art approaches in multiple settings. We also conducted a real user study, and ChatIoT can achieve 91.57% TAP generation accuracy.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {103},
numpages = {29},
keywords = {Home automation, Internet of Things, LLMs, Zero-code TAP generation}
}

@inproceedings{10.1145/3657604.3664697,
author = {Jin, Hyoungwook and Kim, Yoonsu and Park, Yeon Su and Tilekbay, Bekzat and Son, Jinho and Kim, Juho},
title = {Using Large Language Models To Diagnose Math Problem-solving Skills At Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664697},
doi = {10.1145/3657604.3664697},
abstract = {Personalized feedback, tailored to students' needs and prior knowledge, is essential for fostering mathematical problem-solving skills. However, personalized feedback is often limited to one-to-one tutoring or small classrooms as it requires instructors' in-depth diagnosis of cognitive processes employed in students' answers. We propose a large language model (LLM) pipeline that diagnoses students' problem-solving skills from their answers at scale in elementary school math word problems. Based on prior literature and an interview with a math education expert, we developed PERC, a framework composed of four problem-solving stages that students can follow: Parse, Extract, Retrieve, and Combine. The framework facilitates diagnosis by externalizing students' step-by-step problem-solving processes and allowing our pipeline to analyze each stage individually. Our LLM pipeline diagnoses each stage by (1) generating rubrics and (2) comparing students' answers with the rubrics. We fine-tuned our LLM pipeline with 71 math problem-rubric pairs and 128 problem-answer-grade triplets collected from elementary school students. We evaluated our pipeline's diagnosis accuracy against vanilla GPT-3.5 and vanilla GPT-4 with automatic and expert evaluations. The results showed the potential of our approach in improving the end-to-end diagnosis accuracy of LLMs, and expert evaluation provided specific aspects that should be improved.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {471–475},
numpages = {5},
keywords = {educational diagnosis at scale, large language models, mathematical problem-solving skills},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3703412.3703416,
author = {Gandhi, Shubham and Patwardhan, Manasi and Vig, Lovekesh and Shroff, Gautam},
title = {BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks},
year = {2025},
isbn = {9798400711619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703412.3703416},
doi = {10.1145/3703412.3703416},
abstract = {Large Language Models (LLMs) excel in diverse applications including generation of code snippets, but often struggle with generating code for complex Machine Learning (ML) tasks. Although existing LLM single-agent based systems give varying performance depending on the task complexity, they purely rely on larger and expensive models such as GPT-4. Our investigation reveals that no-cost and low-cost models such as Gemini-Pro, Mixtral and CodeLlama perform far worse than GPT-4 in a single-agent setting. With the motivation of developing a cost-efficient LLM based solution for solving ML tasks, we propose an LLM Multi-Agent based system which leverages combination of experts using profiling, efficient retrieval of past observations, LLM cascades, and ask-the-expert calls. Through empirical analysis on ML engineering tasks in the MLAgentBench benchmark, we demonstrate the effectiveness of our system, using no-cost models, namely Gemini as the base LLM, paired with GPT-4 in cascade and expert to serve occasional ask-the-expert calls for planning. With 94.2% reduction in the cost (from $0.931 per run cost averaged over all tasks for GPT-4 single agent system to $0.054), our system is able to yield better average success rate of 32.95% as compared to GPT-4 single-agent system yielding 22.72% success rate averaged over all the tasks of MLAgentBench.},
booktitle = {Proceedings of the 4th International Conference on AI-ML Systems},
articleno = {3},
numpages = {9},
keywords = {Automated ML, Large Language Models, LLM Agents},
location = {
},
series = {AIMLSystems '24}
}

@article{10.1145/3657305,
author = {Wu, Ling-I and Su, Yuxin and Li, Guoqiang},
title = {Zero-Shot Construction of Chinese Medical Knowledge Graph with GPT-3.5-turbo and GPT-4},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {2158-656X},
url = {https://doi.org/10.1145/3657305},
doi = {10.1145/3657305},
abstract = {Knowledge graphs have revolutionized the organization and retrieval of real-world knowledge, prompting interest in automatic natural language processing approaches for extracting medical knowledge from texts. However, the availability of high-quality Chinese medical knowledge remains limited, posing challenges for constructing Chinese medical knowledge graphs. As large language models like ChatGPT show promise in zero-shot learning for many natural language processing downstream tasks, their potential on constructing Chinese medical knowledge graphs remains uncertain. In this study, we create a Chinese medical knowledge graph by manually annotating textual data and using ChatGPT to automatically generate the graph. We refine the results using filtering and mapping rules to align with our schema. The manually generated graph serves as the ground truth for evaluation, and we explore different methods to enhance its accuracy through knowledge graph completion techniques. As a result, we emphasize the potential of employing ChatGPT for automated knowledge graph construction within the Chinese medical domain. While ChatGPT successfully identifies a larger number of entities, further enhancements are required to improve its performance in extracting more qualified relations.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = mar,
articleno = {14},
numpages = {17},
keywords = {Medical knowledge graph, ChatGPT, nature language processing, named entity recognition, relation extraction}
}

@article{10.14778/3685800.3685885,
author = {Zhu, Zhen and Wang, Yibo and Yang, Shouqing and Long, Lin and Wu, Runze and Tang, Xiu and Zhao, Junbo and Wang, Haobo},
title = {CORAL: Collaborative Automatic Labeling System Based on Large Language Models},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685885},
doi = {10.14778/3685800.3685885},
abstract = {In the era of big data, data annotation is integral to numerous applications. However, it is widely acknowledged as a laborious and time-consuming process, significantly impeding the scalability and efficiency of data-driven applications. To reduce the human cost, we demonstrate CORAL, a collaborative automatic labeling system driven by large language models (LLMs), which achieves high-quality annotation with the least human effort. Firstly, CORAL employs LLM to automatically annotate vast datasets, generating coarse-grained labels. Subsequently, a weakly-supervised learning module trains small language models (SLMs) using noisy label learning techniques to distill accurate labels from LLM's annotations. It also allows statistical analysis of model outcomes to identify potentially erroneous labels, reducing the human cost of error detection. Furthermore, CORAL supports iterative refinement by LLMs and SLMs using manually corrected labels, thereby ensuring continual enhancement in annotation quality and model performance. A visual interface enables annotation process monitoring and result analysis.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4401–4404},
numpages = {4}
}

@inproceedings{10.1145/3626772.3657760,
author = {Yang, Diji and Rao, Jinmeng and Chen, Kezhen and Guo, Xiaoyuan and Zhang, Yawen and Yang, Jie and Zhang, Yi},
title = {IM-RAG: Multi-Round Retrieval-Augmented Generation Through Learning Inner Monologues},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657760},
doi = {10.1145/3626772.3657760},
abstract = {Although the Retrieval-Augmented Generation (RAG) paradigms can use external knowledge to enhance and ground the outputs of Large Language Models (LLMs) to mitigate generative hallucinations and static knowledge base problems, they still suffer from limited flexibility in adopting Information Retrieval (IR) systems with varying capabilities, constrained interpretability during the multi-round retrieval process, and a lack of end-to-end optimization. To address these challenges, we propose a novel LLM-centric approach, IM-RAG, that integrates IR systems with LLMs to support multi-round RAG through learning Inner Monologues (IM, i.e., the human inner voice that narrates one's thoughts). During the IM process, the LLM serves as the core reasoning model (i.e., Reasoner ) to either propose queries to collect more information via the Retriever or to provide a final answer based on the conversational context. We also introduce a Refiner that improves the outputs from the Retriever, effectively bridging the gap between the Reasoner and IR modules with varying capabilities and fostering multi-round communications. The entire IM process is optimized via Reinforcement Learning (RL) where a Progress Tracker is incorporated to provide mid-step rewards, and the answer prediction is further separately optimized via Supervised Fine-Tuning (SFT). We conduct extensive experiments with the HotPotQA dataset, a popular benchmark for retrieval-based, multi-step question-answering. The results show that our approach achieves state-of-the-art (SOTA) performance while providing high flexibility in integrating IR modules as well as strong interpretability exhibited in the learned inner monologue.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {730–740},
numpages = {11},
keywords = {inner monologue, large language models, multi-round retrieval, question answering, retrieval augmented generation},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3626772.3657963,
author = {Zhang, Erhan and Wang, Xingzhu and Gong, Peiyuan and Lin, Yankai and Mao, Jiaxin},
title = {USimAgent: Large Language Models for Simulating Search Users},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657963},
doi = {10.1145/3626772.3657963},
abstract = {Due to the advantages in the cost-efficiency and reproducibility, user simulation has become a promising solution to the user-centric evaluation of information retrieval systems. Nonetheless, accurately simulating user search behaviors has long been a challenge, because users' actions in search are highly complex and driven by intricate cognitive processes such as learning, reasoning, and planning. Recently, Large Language Models (LLMs) have demonstrated remarked potential in simulating human-level intelligence and have been used in building autonomous agents for various tasks. However, the potential of using LLMs in simulating search behaviors has not yet been fully explored. In this paper, we introduce a LLM-based user search behavior simulator, USimAgent. The proposed simulator can simulate users' querying, clicking, and stopping behaviors during search, and thus, is capable of generating complete search sessions for specific search tasks. Empirical investigation on a real user behavior dataset shows that the proposed simulator outperforms existing methods in query generation and is comparable to traditional methods in predicting user clicks and stopping behaviors. These results not only validate the effectiveness of using LLMs for user simulation but also shed light on the development of a more robust and generic user simulators.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2687–2692},
numpages = {6},
keywords = {evaluation, large language models, user search behavior, user simulation},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3643834.3660705,
author = {Lim, Hyunseung and Cho, Ji Yong and Kim, Taewan and Park, Jeongeon and Shin, Hyungyu and Choi, Seulgi and Park, Sunghyun and Lee, Kyungjae and Kim, Juho and Lee, Moontae and Hong, Hwajung},
title = {Co-Creating Question-and-Answer Style Articles with Large Language Models for Research Promotion},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3660705},
doi = {10.1145/3643834.3660705},
abstract = {Research promotion enables researchers to share advanced knowledge with pertinent academic communities. The question-and-answer (QA) style articles are effective for researchers to promote their research by enabling readers to understand research on complex subjects. Recent advances in large language models (LLMs) have opened avenues for supporting researchers in creating QA-style articles for research promotion. However, without the authors’ involvement, these models may only partially capture the researcher’s intention and voice. We developed AQUA, a research probe that enables researchers to co-create QA-style articles with LLMs to promote their research papers. A user study (n=12) reveals that LLMs reduced authors’ burden and helped them understand the readers’ perspectives. Nevertheless, LLMs failed to capture the unique intent of the authors, and their automated generation discouraged authors from carefully revising their answers. Based on our findings, we discuss human-LLM interaction design to enable authors to create QA-style articles that reflect their intention.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {975–994},
numpages = {20},
keywords = {Human-AI Interaction, Large Language Model, Question-and-Answer, Research Promotion},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3589334.3645633,
author = {Shen, Xiaoteng and Zhang, Rui and Zhao, Xiaoyan and Zhu, Jieming and Xiao, Xi},
title = {PMG : Personalized Multimodal Generation with Large Language Models},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645633},
doi = {10.1145/3589334.3645633},
abstract = {The emergence of large language models (LLMs) has revolutionized the capabilities of text comprehension and generation. Multi-modal generation attracts great attention from both the industry and academia, but there is little work on personalized generation, which has important applications such as recommender systems. This paper proposes the first method for personalized multimodal generation using LLMs, showcases its applications and validates its performance via an extensive experimental study on two datasets. The proposed method, Personalized Multimodal Generation (PMG for short) first converts user behaviors (e.g., clicks in recommender systems or conversations with a virtual assistant) into natural language to facilitate LLM understanding and extract user preference descriptions. Such user preferences are then fed into a generator, such as a multimodal LLM or diffusion model, to produce personalized content. To capture user preferences comprehensively and accurately, we propose to let the LLM output a combination of explicit keywords and implicit embeddings to represent user preferences. Then the combination of keywords and embeddings are used as prompts to condition the generator. We optimize a weighted sum of the accuracy and preference scores so that the generated content has a good balance between them. Compared to a baseline method without personalization, PMG has a significant improvement on personalization for up to 8% in terms of LPIPS while retaining the accuracy of generation.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3833–3843},
numpages = {11},
keywords = {large language model, multimodal generation, personalization},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3626253.3633436,
author = {Leinonen, Juho and MacNeil, Stephen and Denny, Paul and Hellas, Arto},
title = {Using Large Language Models for Teaching Computing},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633436},
doi = {10.1145/3626253.3633436},
abstract = {In the past year, large language models (LLMs) have taken the world by storm, demonstrating their potential as a transformative force in many domains including computing education. Computing education researchers have found that LLMs can solve most assessments in introductory programming courses, including both traditional code writing tasks and other popular tasks such as Parsons problems. As more and more students start to make use of LLMs, the question instructors might ask themselves is "what can I do?". We propose that one promising way forward is to integrate LLMs into teaching practice, providing all students with an equal opportunity to learn how to interact productively with LLMs as well as encounter and understand their limitations. In this workshop, we first present state-of-the-art research results on how to utilize LLMs in computing education practice, after which participants will take part in hands-on activities using LLMs. We end the workshop by brainstorming ideas with participants around adapting their classrooms to most effectively integrate LLMs while avoiding some common pitfalls.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1901},
numpages = {1},
keywords = {generative ai, large language models, teaching practice},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1613/jair.1.16665,
author = {Fraser, Kathleen C. and Dawkins, Hillary and Kiritchenko, Svetlana},
title = {Detecting AI-Generated Text: Factors Influencing Detectability with Current Methods},
year = {2025},
issue_date = {May 2025},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {82},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.16665},
doi = {10.1613/jair.1.16665},
abstract = {Large language models (LLMs) have advanced to a point that even humans have difficulty discerning whether a text was generated by another human, or by a computer. However, knowing whether a text was produced by human or artificial intelligence (AI) is important to determining its trustworthiness, and has applications in many domains including detecting fraud and academic dishonesty, as well as combating the spread of misinformation and political propaganda. The task of AI-generated text (AIGT) detection is therefore both very challenging, and highly critical. In this survey, we summarize stateof-the art approaches to AIGT detection, including watermarking, statistical and stylistic analysis, and machine learning classification. We also provide information about existing datasets for this task. Synthesizing the research findings, we aim to provide insight into the salient factors that combine to determine how “detectable” AIGT text is under different scenarios, and to make practical recommendations for future work towards this significant technical and societal challenge.},
journal = {J. Artif. Int. Res.},
month = apr,
numpages = {46},
keywords = {machine learning, data mining, information extraction, information retrieval, knowledge discovery, programming}
}

@inproceedings{10.1145/3663529.3663801,
author = {Chen, Yinghao and Hu, Zehao and Zhi, Chen and Han, Junxiao and Deng, Shuiguang and Yin, Jianwei},
title = {ChatUniTest: A Framework for LLM-Based Test Generation},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663801},
doi = {10.1145/3663529.3663801},
abstract = {Unit testing is an essential yet frequently arduous task. Various automated unit test generation tools have been introduced to mitigate this challenge. Notably, methods based on large language models (LLMs) have garnered considerable attention and exhibited promising results in recent years. Nevertheless, LLM-based tools encounter limitations in generating accurate unit tests. This paper presents ChatUniTest, an LLM-based automated unit test generation framework. ChatUniTest incorporates an adaptive focal context mechanism to encompass valuable context in prompts and adheres to a generation-validation-repair mechanism to rectify errors in generated unit tests.
 
Subsequently, we have developed ChatUniTest Core, a common library that implements core workflow, complemented by the ChatUniTest Toolchain, a suite of seamlessly integrated tools enhancing the capabilities of ChatUniTest. Our effectiveness evaluation reveals that ChatUniTest outperforms TestSpark and EvoSuite in half of the evaluated projects, achieving the highest overall line coverage.
 
Furthermore, insights from our user study affirm that ChatUniTest delivers substantial value to various stakeholders in the software testing domain.
 
ChatUniTest is available at https://github.com/ZJU-ACES-ISE/ChatUniTest, and the demo video is available at https://www.youtube.com/watch?v=GmfxQUqm2ZQ.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {572–576},
numpages = {5},
keywords = {Automatic Unit Testing Generation, Large Language Models},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3663384.3663393,
author = {Feldman, Molly Q and Anderson, Carolyn Jane},
title = {Non-Expert Programmers in the Generative AI Future},
year = {2024},
isbn = {9798400710179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663384.3663393},
doi = {10.1145/3663384.3663393},
abstract = {Generative AI is rapidly transforming the practice of programming. At the same time, our understanding of who writes programs, for what purposes, and how they program, has been evolving. By facilitating natural-language-to-code interactions, large language models for code have the potential to open up programming work to a broader range of workers. While existing work finds productivity benefits for expert programmers, interactions with non-experts are less well-studied. In this paper, we consider the future of programming for non-experts through a controlled study of 67 non-programmers. Our study reveals multiple barriers to effective use of large language models of code for non-experts, including several aspects of technical communication. Comparing our results to a prior study of beginning programmers illuminates the ways in which a traditional introductory programming class does and does not equip students to effectively work with generative AI. Drawing on our empirical findings, we lay out a vision for how to empower non-expert programmers to leverage generative AI for a more equitable future of programming.},
booktitle = {Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {15},
numpages = {19},
keywords = {CS1, Code LLMs, Generative AI, mixed methods, non-experts},
location = {Newcastle upon Tyne, United Kingdom},
series = {CHIWORK '24}
}

@inproceedings{10.1145/3717867.3717924,
author = {Pratelli, Manuel and Bianchi, John and Pinelli, Fabio and Petrocchi, Marinella},
title = {Evaluation of Reliability Criteria for News Publishers with Large Language Models},
year = {2025},
isbn = {9798400714832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3717867.3717924},
doi = {10.1145/3717867.3717924},
abstract = {In this study, we investigate the use of a large language model to assist in the evaluation of the reliability of the vast number of existing online news publishers, addressing the impracticality of relying solely on human expert annotators for this task. In the context of the Italian news media market, we first task the model with evaluating expert-designed reliability criteria using a representative sample of news articles. We then compare the model’s answers with those of human experts. The dataset consists of 352 news articles annotated by three human experts and the LLM. Examining 6,081 annotations over six criteria, we observe good agreement between LLM and human annotators in three evaluated criteria, including the critical ability to detect instances where a text negatively targets an entity or individual. For two additional criteria, such as the detection of sensational language and the recognition of bias in news content, LLMs generate fair annotations, albeit with certain trade-offs. Furthermore, we show that the LLM is able to help resolve disagreements among human experts, especially in tasks such as identifying cases of negative targeting.},
booktitle = {Proceedings of the 17th ACM Web Science Conference 2025},
pages = {179–188},
numpages = {10},
keywords = {Reliability Evaluation, Good Editorial Practices, Generative Question Answering, LLMs, Inter-annotator agreement},
location = {
},
series = {Websci '25}
}

@inproceedings{10.1145/3696409.3700273,
author = {Sugihara, Tomoya and Masuda, Shuntaro and Xiao, Ling and Yamasaki, Toshihiko},
title = {Language-Guided Self-Supervised Video Summarization Using Text Semantic Matching Considering the Diversity of the Video},
year = {2024},
isbn = {9798400712739},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696409.3700273},
doi = {10.1145/3696409.3700273},
abstract = {Current video summarization methods rely heavily on supervised computer vision techniques, which demands time-consuming manual annotations. By leveraging the advantages of Large Language Models (LLMs) in context understanding, we aim to develop self-supervised video summarization models. Our method begins by generating captions for individual video frames, which are then synthesized into text summaries by LLMs. Subsequently, we measure semantic distance between the captions and the text summary. Notably, we propose a novel loss function to optimize our deep metric learning process by considering the diversity of the video. Finally, summarized videos can be generated by selecting the frames whose captions closely match the text summary. Our method achieves state-of-the-art performance on the SumMe dataset in rank correlation coefficients. Moreover, our method has a novel feature of being able to achieve personalized video summarization. Our source code is publicly available at https://github.com/sugitomoo/PDL.},
booktitle = {Proceedings of the 6th ACM International Conference on Multimedia in Asia},
articleno = {109},
numpages = {1},
keywords = {Video summarization, Large language models, Self-supervised learning, Deep metric learning, Personalized video summarization},
location = {
},
series = {MMAsia '24}
}

@inproceedings{10.1145/3664647.3681379,
author = {Liu, Yi and Cai, Chengjun and Zhang, Xiaoli and Yuan, Xingliang and Wang, Cong},
title = {Arondight: Red Teaming Large Vision Language Models with Auto-generated Multi-modal Jailbreak Prompts},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681379},
doi = {10.1145/3664647.3681379},
abstract = {Large Vision Language Models (VLMs) extend and enhance the perceptual abilities of Large Language Models (LLMs). Despite offering new possibilities for LLM applications, these advancements raise significant security and ethical concerns, particularly regarding the generation of harmful content. While LLMs have undergone extensive security evaluations with the aid of red teaming frameworks, VLMs currently lack a well-developed one. To fill this gap, we introduce Arondight, a standardized red team framework tailored specifically for VLMs. Arondight is dedicated to resolving issues related to the absence of visual modality and inadequate diversity encountered when transitioning existing red teaming methodologies from LLMs to VLMs. Our framework features an automated multi-modal jailbreak attack, wherein visual jailbreak prompts are produced by a red team VLM, and textual prompts are generated by a red team LLM guided by a reinforcement learning agent. To enhance the comprehensiveness of VLM security evaluation, we integrate entropy bonuses and novelty reward metrics. These elements incentivize the RL agent to guide the red team LLM in creating a wider array of diverse and previously unseen test cases. Our evaluation of ten cutting-edge VLMs exposes significant security vulnerabilities, particularly in generating toxic images and aligning multi-modal prompts. In particular, our Arondight achieves an average attack success rate of 84.5% on GPT-4 in all fourteen prohibited scenarios defined by OpenAI in terms of generating toxic text. For a clearer comparison, we also categorize existing VLMs based on their safety levels and provide corresponding reinforcement recommendations. Our multimodal prompt dataset and red team code will be released after ethics committee approval. CONTENT WARNING: THIS PAPER CONTAINS HARMFUL MODEL RESPONSES.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3578–3586},
numpages = {9},
keywords = {jailbreak attacks, large vision language model, red teaming},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3626246.3653398,
author = {Yu, Changlong and Liu, Xin and Maia, Jefferson and Li, Yang and Cao, Tianyu and Gao, Yifan and Song, Yangqiu and Goutam, Rahul and Zhang, Haiyang and Yin, Bing and Li, Zheng},
title = {COSMO: A Large-Scale E-commerce Common Sense Knowledge Generation and Serving System at Amazon},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3653398},
doi = {10.1145/3626246.3653398},
abstract = {Applications of large-scale knowledge graphs in the e-commerce platforms can improve shopping experience for their customers. While existing e-commerce knowledge graphs (KGs) integrate a large volume of concepts or product attributes, they fail to discover user intentions, leaving the gap with how people think, behave, and interact with the surrounding world. In this work, we present COSMO, a scalable system to mine user-centric commonsense knowledge from massive behaviors and construct industry-scale knowledge graphs to empower diverse online services. In particular, we describe a pipeline for collecting high-quality seed knowledge assertions that are distilled from large language models (LLMs) and further refined by critic classifiers trained over human-in-the-loop annotated data.Since those generations may not always align with human preferences and contain noises, we then describe how we adopt instruction tuning to finetune an efficient language model~(COSMO-LM) for faithful e-commerce commonsense knowledge generation at scale. COSMO-LM effectively expands our knowledge graph to 18 major categories at Amazon, producing millions of high-quality knowledge with only 30k annotated instructions. Finally COSMO has been deployed in Amazon search applications such as search navigation. Both offline and online A/B experiments demonstrate our proposed system achieves significant improvement. Furthermore, these experiments highlight the immense potential of commonsense knowledge extracted from instruction-finetuned large language models.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {148–160},
numpages = {13},
keywords = {commonsense knowledge, knowledge graph, large language model},
location = {Santiago AA, Chile},
series = {SIGMOD '24}
}

@inproceedings{10.1145/3706599.3719963,
author = {Doula, Achref and M\"{u}hlh\"{a}user, Max and Sanchez Guinea, Alejandro},
title = {AEXL: Enhancing Path Prediction with Active Explainable Learning via Large Language Models},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719963},
doi = {10.1145/3706599.3719963},
abstract = {Active learning (AL) reduces annotation costs by selectively querying humans for uncertain data samples, thus improving data efficiency. In traditional AL, annotators simply label the data without gaining a deeper understanding of the reasoning of the model. However, incorporating model-generated explanations can enhance annotation quality by helping annotators interpret decisions and detect errors, a crucial need in safety-critical tasks, such as path prediction, where reliable annotations are vital for autonomous navigation. We propose Active Explainable Learning (AEXL), a novel AL framework that integrates natural language explanations via large language models (LLMs), enabling annotators to interpret predicted paths and identify errors more effectively. Our preliminary evaluations indicate that AEXL reaches 99% of the anticipated performance using only 60% of the data. The results of our preliminary user study show that natural language explanations boost annotator understanding, trust, and reduce cognitive load compared to approaches that lack explanatory guidance. Our work aims to foster future research on explanation-driven AL to improve model performance and human-AI collaboration.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {53},
numpages = {6},
keywords = {Human-in-the-Loop Machine Learning, Explainable Machine Learning, Large Language Models, Autonomous Driving},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3712464.3712495,
author = {Sun, Ying and Ren, Shiqi and Peng, Cheng},
title = {GISD: A Generative and Interpretable Framework for Explainable Zero-Shot Stance Detection},
year = {2025},
isbn = {9798400710636},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712464.3712495},
doi = {10.1145/3712464.3712495},
abstract = {Zero-shot stance detection (ZSSD) seeks to identify the stance of a text in relation to an unseen target. Despite its importance, existing approaches rarely focus on explicitly explaining the reasoning process underlying their predictions or decisions. This paper represents the first attempt to address this gap by generating rationales for predictions in ZSSD, demonstrating that such explanations can effectively uncover the reasoning process. To this end, we propose a novel framework for stance detection called Generative and Interpretable Stance Detection (GISD). A key component of GISD is a three-hop logic elicitation (TH-LE) method, which leverages the chain-of-thought approach to extract if-then reasoning expressions from large language models (LLMs). These if-then expressions are then reformulated alongside the original inputs to create a new training dataset, which is subsequently used to train a generative model. To further enhance the training process, we introduce an iterative-instruction data augmentation (I2DA) method to expand the dataset. Experimental results reveal that the GISD framework significantly surpasses state-of-the-art methods in ZSSD performance. Moreover, manual evaluations confirm that the generated if-then expressions effectively explain the rationale behind the model's predictions.},
booktitle = {Proceedings of the 2024 4th International Conference on Signal Processing and Communication Technology},
pages = {163–169},
numpages = {7},
keywords = {Explainable Method, Knowledge fusion, Stance Detection},
location = {
},
series = {SPCT '24}
}

@inproceedings{10.1145/3652620.3687784,
author = {Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta and Scalera, Michele},
title = {A RAG-based Feedback Tool to Augment UML Class Diagram Learning},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687784},
doi = {10.1145/3652620.3687784},
abstract = {This paper introduces an advanced functionality designed to facilitate the learning of UML class diagram construction. Built upon an integrated Retrieval Augmented Generation Large Language Model, the functionality provides enriched feedback by leveraging accumulated knowledge. The functionality is implemented in an existing tool named UML Miner, a Visual Paradigm plugin that captures and analyzes student-generated UML diagrams by applying process mining techniques. By offering personalized feedback and continuous support during modeling, the tool aims to enhance learning outcomes and students' engagement.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {26–30},
numpages = {5},
keywords = {learning, UML, software modeling, retrieval augmented generation, large language model, tool},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3627673.3679713,
author = {Liang, Yuanyuan and Tan, Keren and Xie, Tingyu and Tao, Wenbiao and Wang, Siyuan and Lan, Yunshi and Qian, Weining},
title = {Aligning Large Language Models to a Domain-specific Graph Database for NL2GQL},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679713},
doi = {10.1145/3627673.3679713},
abstract = {Graph Databases (Graph DB) find extensive application across diverse domains such as finance, social networks, and medicine. Yet, the translation of Natural Language (NL) into the Graph Query Language (GQL), referred to as NL2GQL, poses significant challenges owing to its intricate and specialized nature. Some approaches have sought to utilize Large Language Models (LLMs) to address analogous tasks like text2SQL. Nonetheless, in the realm of NL2GQL tasks tailored to a particular domain, the absence of domain-specific NL-GQL data pairs adds complexity to aligning LLMs with the graph DB. To tackle this challenge, we present a well-defined pipeline. Initially, we use ChatGPT to generate NL-GQL data pairs, leveraging the provided graph DB and two mutual verification self-instruct methods which ensure consistency between NL and GQL. Subsequently, we employ the generated data to fine-tune LLMs, ensuring alignment between LLMs and the graph DB. Moreover, we find the importance of relevant schema in efficiently generating accurate GQLs. Thus, we introduce a method to extract relevant schema as the input context. We evaluate our method using two carefully constructed datasets derived from graph DBs in the finance and medicine domains, named FinGQL and MediGQL. Experimental results reveal that our approach significantly outperforms a set of baseline methods, with improvements of 5.90 and 6.36 absolute points on EM, and 6.00 and 7.09 absolute points on EX for FinGQL and MediGQL, respectively},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {1367–1377},
numpages = {11},
keywords = {graph databases, graph query language, large language models, natural language to graph query language},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1109/ASE56229.2023.00096,
author = {Yan, Dapeng and Gao, Zhipeng and Liu, Zhiming},
title = {A Closer Look at Different Difficulty Levels Code Generation Abilities of ChatGPT},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00096},
doi = {10.1109/ASE56229.2023.00096},
abstract = {Code generation aims to generate source code implementing human requirements illustrated with natural language specifications. With the rapid development of intelligent software engineering, automated code generation has become a hot research topic in both artificial intelligence and software engineering, and researchers have made significant achievements on code generation. More recently, large language models (LLMs) have demonstrated outstanding performance on code generation tasks, such as ChatGPT released by OpenAI presents the fantastic potential on automated code generation. However, the existing studies are limited to exploring LLMs' ability for generating code snippets to solve simple programming problems, the task of competition-level code generation has never been investigated. The specifications of the programming competition are always complicated and require the specific input/output format as well as the high-level algorithmic reasoning ability. In this study, we conduct the first large empirical study to investigate the zero-shot learning ability of ChatGPT for solving competition programming problems. Specifically, we warm up the design of prompts by using the Human-Eval dataset. Then, we apply the well-designed prompt to the competition-level code generation dataset, namely APPS, to further explore the effectiveness of using ChatGPT for solving competition problems. We collect ChatGPT's outputs on 5,000 code competition problems, the evaluation results show that it can successfully pass 25.4% test cases. By further feeding extra information (e.g, test failed information) to ChatGPT, we observe that ChatGPT has the potential to fix partial pass into a fully pass program. Moreover, we investigate the solutions generated by LLMs and the existing solutions, we find that it prefers to directly copy the code instead of re-write when facing more difficult problems. Finally, we evaluate the code quality generated by ChatGPT in terms of "code cleanness", we observe that the generated codes are with small functions and file sizes, which are in line with the standard of clean code.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1887–1898},
numpages = {12},
keywords = {code generation, program competition, Chat-GPT, large language model, clean code},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3616961.3616974,
author = {Rajala, Jaakko and Hukkanen, Jenni and Hartikainen, Maria and Niemel\"{a}, Pia},
title = {"\"Call me Kiran\" – ChatGPT as a Tutoring Chatbot in a Computer Science Course"},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616974},
doi = {10.1145/3616961.3616974},
abstract = {Natural language processing has taken enormous steps during the last few years. The development of large language models and generative AI has elevated natural language processing to the level that it can output coherent and contextually relevant text for a given natural language prompt. ChatGPT is one incarnation of these steps, and its use in education is a rather new phenomenon. In this paper, we study students’ perception on ChatGPT during a computer science course. On the course, we integrated ChatGPT into Teams private discussion groups. In addition, all the students had freedom to employ ChatGPT and related technologies to help them in their coursework. The results show that the majority of students had at least tested AI-powered chatbots, and that students are using AI-powered chatbots for multiple tasks, e.g., debugging code, tutoring, and enhancing comprehension. The amount of positive implications of using ChatGPT takes over the negative implications, when the implications were considered from an understanding, learning and creativity perspective. Relatively many students reported reliability issues with the outputs and that the iterations with prompts might be necessary for satisfactory outputs. It is important to try to steer the usage of ChatGPT so that it complements students’ learning processes, but does not replace it.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {83–94},
numpages = {12},
keywords = {ChatGPT, artificial intelligence, chatbots, discussion forum, education, generative AI, student perceptions, tutoring},
location = {Tampere, Finland},
series = {Mindtrek '23}
}

@inproceedings{10.1145/3657604.3662040,
author = {Gabbay, Hagit and Cohen, Anat},
title = {Combining LLM-Generated and Test-Based Feedback in a MOOC for Programming},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662040},
doi = {10.1145/3657604.3662040},
abstract = {In large-scale programming courses, providing learners with immediate and effective feedback is a significant challenge. This study explores the potential of Large Language Models (LLMs) to generate feedback on code assignments and to address the gaps in Automated Test-based Feedback (ATF) tools commonly employed in programming courses. We applied dedicated metrics in a Massive Open Online Course (MOOC) on programming to assess the correctness of feedback generated by two models, GPT-3.5-turbo and GPT-4, using a reliable ATF as a benchmark. The findings point to effective error detection, yet the feedback is often inaccurate, with GPT-4 outperforming GPT-3.5-turbo. We used insights gained from the prompt practices to develop Gipy, an application for submitting course assignments and obtaining LLM-generated feedback. Learners participating in a field experiment perceived the feedback provided by Gipy as moderately valuable, while at the same time recognizing its potential to complement ATF. Given the learners' critique and their awareness of the limitations of LLM-generated feedback, the studied implementation may be able to take advantage of the best of both ATF and LLMs as feedback resources. Further research is needed to assess the impact of LLM-generated feedback on learning outcomes and explore the capabilities of more advanced models.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {177–187},
numpages = {11},
keywords = {MOOC for programming, automated feedback, generative AI, large language models (LLMs), programming education},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.1613/jair.1.15960,
author = {Pternea, Moschoula and Singh, Prerna and Chakraborty, Abir and Oruganti, Yagna and Milletari, Mirco and Bapat, Sayli and Jiang, Kebei},
title = {The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models},
year = {2024},
issue_date = {Sep 2024},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {80},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.15960},
doi = {10.1613/jair.1.15960},
abstract = {In this work, we review research studies that combine Reinforcement Learning (RL) and Large Language Models (LLMs), two areas that owe their momentum to the development of Deep Neural Networks (DNNs). We propose a novel taxonomy of three main classes based on the way that the two model types interact with each other. The first class, RL4LLM, includes studies where RL is leveraged to improve the performance of LLMs on tasks related to Natural Language Processing (NLP). RL4LLM is divided into two sub-categories depending on whether RL is used to directly fine-tune an existing LLM or to improve the prompt of the LLM. In the second class, LLM4RL, an LLM assists the training of an RL model that performs a task that is not inherently related to natural language. We further break down LLM4RL based on the component of the RL training framework that the LLM assists or replaces, namely reward shaping, goal generation, and policy function. Finally, in the third class, RL+LLM, an LLM and an RL agent are embedded in a common planning framework without either of them contributing to training or fine-tuning of the other. We further branch this class to distinguish between studies with and without natural language feedback. We use this taxonomy to explore the motivations behind the synergy of LLMs and RL and explain the reasons for its success, while pinpointing potential shortcomings and areas where further research is needed, as well as alternative methodologies that serve the same goal.},
journal = {J. Artif. Int. Res.},
month = sep,
numpages = {49}
}

@inproceedings{10.1145/3626772.3661371,
author = {Vedula, Nikhita and Rokhlenko, Oleg and Malmasi, Shervin},
title = {Question Suggestion for Conversational Shopping Assistants Using Product Metadata},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3661371},
doi = {10.1145/3626772.3661371},
abstract = {Digital assistants have become ubiquitous in e-commerce applications, following the recent advancements in Information Retrieval (IR), Natural Language Processing (NLP) and Generative Artificial Intelligence (AI). However, customers are often unsure or unaware of how to effectively converse with these assistants to meet their shopping needs. In this work, we emphasize the importance of providing customers a fast, easy to use, and natural way to interact with conversational shopping assistants. We propose a framework that employs Large Language Models (LLMs) to automatically generate contextual, useful, answerable, fluent and diverse questions about products, via in-context learning and supervised fine-tuning. Recommending these questions to customers as helpful suggestions or hints to both start and continue a conversation can result in a smoother and faster shopping experience with reduced conversation overhead and friction. We perform extensive offline evaluations, and discuss in detail about potential customer impact, and the type, length and latency of our generated product questions if incorporated into a real-world shopping assistant.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2960–2964},
numpages = {5},
keywords = {conversational shopping assistants, product question suggestion},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3654777.3676348,
author = {Qian, Wanli and Gao, Chenfeng and Sathya, Anup and Suzuki, Ryo and Nakagaki, Ken},
title = {SHAPE-IT: Exploring Text-to-Shape-Display for Generative Shape-Changing Behaviors with LLMs},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676348},
doi = {10.1145/3654777.3676348},
abstract = {This paper introduces text-to-shape-display, a novel approach to generating dynamic shape changes in pin-based shape displays through natural language commands. By leveraging large language models (LLMs) and AI-chaining, our approach allows users to author shape-changing behaviors on demand through text prompts without programming. We describe the foundational aspects necessary for such a system, including the identification of key generative elements (primitive, animation, and interaction) and design requirements to enhance user interaction, based on formative exploration and iterative design processes. Based on these insights, we develop SHAPE-IT, an LLM-based authoring tool for a 24 x 24 shape display, which translates the user’s textual command into executable code and allows for quick exploration through a web-based control interface. We evaluate the effectiveness of SHAPE-IT in two ways: 1) performance evaluation and 2) user evaluation (N= 10). The study conclusions highlight the ability to facilitate rapid ideation of a wide range of shape-changing behaviors with AI. However, the findings also expose accuracy-related challenges and limitations, prompting further exploration into refining the framework for leveraging AI to better suit the unique requirements of shape-changing systems.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {118},
numpages = {29},
keywords = {Code-Generation, LLMs, Shape Display, Text-based Authoring},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3706598.3713905,
author = {Zhou, Zhongyi and Jin, Jing and Phadnis, Vrushank and Yuan, Xiuxiu and Jiang, Jun and Qian, Xun and Wright, Kristen and Sherwood, Mark and Mayes, Jason and Zhou, Jingtao and Huang, Yiyi and Xu, Zheng and Zhang, Yinda and Lee, Johnny and Olwal, Alex and Kim, David and Iyengar, Ram and Li, Na and Du, Ruofei},
title = {InstructPipe: Generating Visual Blocks Pipelines with Human Instructions and LLMs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713905},
doi = {10.1145/3706598.3713905},
abstract = {Visual programming has the potential of providing novice programmers with a low-code experience to build customized processing pipelines. Existing systems typically require users to build pipelines from scratch, implying that novice users are expected to set up and link appropriate nodes from a blank workspace. In this paper, we introduce InstructPipe, an AI assistant for prototyping machine learning (ML) pipelines with text instructions. We contribute two large language model (LLM) modules and a code interpreter as part of our framework. The LLM modules generate pseudocode for a target pipeline, and the interpreter renders the pipeline in the node-graph editor for further human-AI collaboration. Both technical and user evaluation (N=16) shows that InstructPipe empowers users to streamline their ML pipeline workflow, reduce their learning curve, and leverage open-ended commands to spark innovative ideas.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {877},
numpages = {22},
keywords = {Visual Programming; Large Language Models; Visual Prototyping; Node-graph Editor; Graph Compiler; Low-code Development; Deep Neural Networks; Deep Learning; Visual Analytics},
location = {
},
series = {CHI '25}
}

@article{10.1145/3736165,
author = {Wei, Yangbo and Huang, Li and Feng, Qi and Chen, Zhanfei and Yan, Jinlong and Lin, Ting-Jung and Huang, Zhen and Ren, Kun and Xing, Wei and He, Lei},
title = {ModelGen: Automating Semiconductor Parameter Extraction with Large Language Model Agents},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3736165},
doi = {10.1145/3736165},
abstract = {Device models require large numbers of parameters to characterize complex physical effects. Although the latest advancements in machine learning and automated tools have drastically improved efficiency over the classic methods, they still demand a considerable amount of human intervention in the loop to gain accuracy. This drastically limits further automation. Inspired by the success of Multimodal Large Language Models (MLLMs) in addressing tasks across diverse fields, we propose ModelGen, the first in-depth study to leverage MLLMs with RAG (Retrieval-Augmented Generation) to significantly reduce human effort in parameter extraction for compact model. Our contributions include (1) Automated Agentic Workflow Construction that learns to build and refine extraction workflows through iterative optimization, (2) MLLM Judge, a visual scoring mechanism that evaluates fitting quality using actual device characteristic plots rather than simple numerical metrics, and (3) Model-specific RAG for providing relevant domain knowledge during the extraction process. Experimental results demonstrate that ModelGen achieves a 26.8%-33.1% improvement in pass@1,3,5 compared to base LLM methods. The system completes complex model extractions for BSIMs and ASM-HEMT in hours (up to 168\texttimes{} faster) rather than days or weeks, making parameter extraction more accessible to non-experts while maintaining professional engineer-level accuracy.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = may,
keywords = {Parameter Extraction, Device Model, Electronic Design Automation, Large Language Models, AI Agent, Bayesian optimization}
}

@inproceedings{10.1145/3627217.3627238,
author = {Singhal, Shreya and Kumar, Viraj},
title = {Creating Thorough Tests for AI-Generated Code is Hard},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627238},
doi = {10.1145/3627217.3627238},
abstract = {Before implementing a function, programmers are encouraged to write a suite of test cases that specify its intended behaviour on several inputs. A suite of tests is thorough if any buggy implementation fails at least one of these tests. We posit that as the proportion of code generated by Large Language Models (LLMs) grows, so must the ability of students to create test suites that are thorough enough to detect subtle bugs in such code. Our paper makes two contributions. First, we demonstrate how difficult it can be to create thorough tests for LLM-generated code by evaluating 27&nbsp;test suites from a public dataset (EvalPlus). Second, by identifying deficiencies in these test suites, we propose strategies for improving the ability of students to develop thorough test suites for LLM-generated code.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {108–111},
numpages = {4},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@inproceedings{10.1145/3650212.3680323,
author = {Xia, Chunqiu Steven and Zhang, Lingming},
title = {Automated Program Repair via Conversation: Fixing 162 out of 337 Bugs for $0.42 Each using ChatGPT},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680323},
doi = {10.1145/3650212.3680323},
abstract = {Automated Program Repair (APR) aims to automatically generate patches for buggy programs. Traditional APR techniques suffer from a lack of patch variety as they rely heavily on handcrafted or mined bug fixing patterns and cannot easily generalize to other bug/fix types. To address this limitation, recent APR work has been focused on leveraging modern Large Language Models (LLMs) to directly generate patches for APR. Such LLM-based APR tools work by first constructing an input prompt built using the original buggy code and then querying the LLM to either fill-in (cloze-style APR) the correct code at the bug location or to produce a completely new code snippet as the patch. While the LLM-based APR tools are able to achieve state-of-the-art results, they still follow the classic Generate and Validate (GV) repair paradigm of first generating lots of patches by sampling from the same initial prompt and then validating each one afterwards. This not only leads to many repeated patches that are incorrect, but also misses the crucial and yet previously ignored information in test failures as well as in plausible patches.        To address these aforementioned limitations, we propose ChatRepair, the first fully automated conversation-driven APR approach that interleaves patch generation with instant feedback to perform APR in a conversational style. ChatRepair first feeds the LLM with relevant test failure information to start with, and then learns from both failures and successes of earlier patching attempts of the same bug for more powerful APR. For earlier patches that failed to pass all tests, we combine the incorrect patches with their corresponding relevant test failure information to construct a new prompt for the LLM to generate the next patch. In this way, we can avoid making the same    mistakes. For earlier patches that passed all the tests (i.e., plausible patches), we further ask the LLM to generate alternative variations of the original plausible patches. In this way, we can further build on and learn from earlier successes to generate more plausible patches to increase the chance of having correct patches. While our approach is general, we implement ChatRepair using state-of-the-art dialogue-based LLM – ChatGPT. Our evaluation on the widely studied Defects4j dataset shows that ChatRepair is able to achieve the new state-of-the-art in repair performance, achieving 114 and 48 correct fixes on Defects4j 1.2 and 2.0 respectively. By calculating the cost    of accessing ChatGPT, we can fix 162 out of 337 bugs for $0.42 each!},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {819–831},
numpages = {13},
keywords = {Automated Program Repair, Large Language Model},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3627508.3638345,
author = {Roegiest, Adam and Pinkosova, Zuzana},
title = {Generative Information Systems Are Great If You Can Read},
year = {2024},
isbn = {9798400704345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627508.3638345},
doi = {10.1145/3627508.3638345},
abstract = {Generative models, especially in information systems like ChatGPT and Bing Chat, have become increasingly integral to our daily lives. Their significance lies in their potential to revolutionize how we access, process, and generate information &nbsp;[44]. However, a gap exists in ensuring these systems are accessible to all, especially considering the literacy challenges faced by a significant portion of the population in (but not limited to) English-speaking countries. This paper aims to investigate the “readability’’ of generative information systems and their accessibility barriers, particularly for those with literacy challenges. Using popular instruction fine-tuning datasets, we found that this training data could produce systems that generate at a college level, potentially excluding a large demographic. Our research methods involved analyzing the responses of popular Large Language Models (LLMs) and examining potential biases in how they can be trained. The key message is the urgent need for inclusivity in systems incorporating generative models, such as those studied by the Information Retrieval (IR) community. Our findings indicate that current generative systems might not be accessible to individuals with cognitive and literacy challenges, emphasizing the importance of ensuring that advancements in this field benefit everyone. By situating our research within the sphere of information seeking and retrieval, we underscore the essential role of these technologies in augmenting accessibility and efficiency of information access, thereby broadening their reach and enhancing user engagement.},
booktitle = {Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
pages = {165–177},
numpages = {13},
location = {Sheffield, United Kingdom},
series = {CHIIR '24}
}

@inproceedings{10.1145/3708359.3712074,
author = {Wang, Xinru and Yu, Mengjie and Nguyen, Hannah and Iuzzolino, Michael and Wang, Tianyi and Tang, Peiqi and Lynova, Natasha and Tran, Co and Zhang, Ting and Sendhilnathan, Naveen and Benko, Hrvoje and Xia, Haijun and Jonker, Tanya R.},
title = {Less or More: Towards Glanceable Explanations for LLM Recommendations Using Ultra-Small Devices},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712074},
doi = {10.1145/3708359.3712074},
abstract = {Large Language Models (LLMs) have shown remarkable potential in recommending everyday actions as personal AI assistants, while Explainable AI (XAI) techniques are being increasingly utilized to help users understand why a recommendation is given. Personal AI assistants today are often located on ultra-small devices such as smartwatches, which have limited screen space. The verbosity of LLM-generated explanations, however, makes it challenging to deliver glanceable LLM explanations on such ultra-small devices. To address this, we explored 1) spatially structuring an LLM’s explanation text using defined contextual components during prompting and 2) presenting temporally adaptive explanations to users based on confidence levels. We conducted a user study to understand how these approaches impacted user experiences when interacting with LLM recommendations and explanations on ultra-small devices. The results showed that structured explanations reduced users’ time to action and cognitive load when reading an explanation. Always-on structured explanations increased users’ acceptance of AI recommendations. However, users were less satisfied with structured explanations compared to unstructured ones due to their lack of sufficient, readable details. Additionally, adaptively presenting structured explanations was less effective at improving user perceptions of the AI compared to the always-on structured explanations. Together with users’ interview feedback, the results led to design implications to be mindful of when personalizing the content and timing of LLM explanations that are displayed on ultra-small devices.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {938–951},
numpages = {14},
keywords = {Explainable AI, ultra-small devices, large language models, structured prompting, confidence estimation, smartwatches},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3639474.3640084,
author = {Sa\u{g}lam, Timur and Hahner, Sebastian and Schmid, Larissa and Burger, Erik},
title = {Automated Detection of AI-Obfuscated Plagiarism in Modeling Assignments},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640084},
doi = {10.1145/3639474.3640084},
abstract = {Plagiarism is a widespread problem in computer science education, exacerbated by the impracticability of manual inspection in large courses. Even worse, tools based on large language models like ChatGPT have made it easier than ever to obfuscate plagiarized solutions. Additionally, most plagiarism detectors only apply to code, and only a few approaches exist for modeling assignments, which lack broad resilience to obfuscation attacks. This paper presents a novel approach for automated plagiarism detection in modeling assignments that combines automated analysis with human inspection. We evaluate our approach with real-world assignments and plagiarism obfuscated by ChatGPT. Our results show that we achieve a significantly higher detection rate for AI-generated attacks and a broader resilience than the state-of-the-art.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {297–308},
numpages = {12},
keywords = {plagiarism detection, obfuscation, ChatGPT, artificial intelligence},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3704323.3704362,
author = {Li, Yuyang and Zhang, Yuqing and Du, Zelin and Guo, Ziqi},
title = {Large Language Model Data Augmentation for Text-Pair Classification Tasks},
year = {2025},
isbn = {9798400717482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704323.3704362},
doi = {10.1145/3704323.3704362},
abstract = {In recent years, large language models (LLMs) have demonstrated remarkable capabilities across various natural language processing tasks. This study explores the application of LLMs for data augmentation in text-pair classification tasks, such as semantic textual similarity and natural language inference. We propose a novel framework that leverages LLMs to generate diverse and contextually relevant paraphrases and transformations of text-pairs, enhancing the training data without manual annotation effort. Our experiments on widely-used benchmarks show that the augmented data not only improves model performance but also increases its robustness to out-of-domain examples. We perform extensive ablation studies to understand the contribution of different augmentation strategies and analyze the trade-offs between data diversity and noise. Additionally, we assess the generalization capabilities of models trained with augmented data across multiple architectures and dataset sizes. The results suggest that LLM-driven data augmentation is a promising approach to overcome data scarcity, reduce overfitting, and enhance the adaptability of text-pair classification systems.},
booktitle = {Proceedings of the 2024 13th International Conference on Computing and Pattern Recognition},
pages = {427–433},
numpages = {7},
keywords = {language model, data augmentation, text classification},
location = {
},
series = {ICCPR '24}
}

@inproceedings{10.1145/3657604.3662039,
author = {Smith, David H. and Denny, Paul and Fowler, Max},
title = {Prompting for Comprehension: Exploring the Intersection of Explain in Plain English Questions and Prompt Writing},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662039},
doi = {10.1145/3657604.3662039},
abstract = {Learning to program requires the development of a variety of skills including the ability to read, comprehend, and communicate the purpose of code. In the age of large language models (LLMs), where code can be generated automatically, developing these skills is more important than ever for novice programmers. The ability to write precise natural language descriptions of desired behavior is essential for eliciting code from an LLM, and the code that is generated must be understood in order to evaluate its correctness and suitability. In introductory computer science courses, a common question type used to develop and assess code comprehension skill is the 'Explain in Plain English' (EiPE) question. In these questions, students are shown a segment of code and asked to provide a natural language description of that code's purpose. The adoption of EiPE questions at scale has been hindered by: 1) the difficulty of automatically grading short answer responses and 2) the ability to provide effective and transparent feedback to students. To address these shortcomings, we explore and evaluate a grading approach where a student's EiPE response is used to generate code via an LLM, and that code is evaluated against test cases to determine if the description of the code was accurate. This provides a scalable approach to creating code comprehension questions and enables feedback both through the code generated from a student's description and the results of test cases run on that code. We evaluate students' success in completing these tasks, their use of the feedback provided by the system, and their perceptions of the activity.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {39–50},
numpages = {12},
keywords = {CS1, EIPE, LLMs, code comprehension, explain in plain English, introductory programming, large language models, prompting},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3676536.3676830,
author = {Cui, Fan and Yin, Chenyang and Zhou, Kexing and Xiao, Youwei and Sun, Guangyu and Xu, Qiang and Guo, Qipeng and Liang, Yun and Zhang, Xingcheng and Song, Demin and Lin, Dahua},
title = {OriGen: Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676830},
doi = {10.1145/3676536.3676830},
abstract = {Recent studies have demonstrated the significant potential of Large Language Models (LLMs) in generating Register Transfer Level (RTL) code, with notable advancements showcased by commercial models such as GPT-4 and Claude3-Opus. However, these proprietary LLMs often raise concerns regarding privacy and security. While open-source LLMs offer solutions to these concerns, they typically underperform commercial models in RTL code generation tasks, primarily due to the scarcity of high-quality open-source RTL datasets. To address this challenge, we introduce OriGen, a fully open-source framework that incorporates self-reflection capabilities and a novel dataset augmentation methodology for generating high-quality, large-scale RTL code. Our approach employs a code-to-code augmentation technique to enhance the quality of open-source RTL code datasets. Furthermore, OriGen can rectify syntactic errors through a self-reflection process that leverages compiler feedback.Experimental results demonstrate that OriGen significantly outperforms other open-source alternatives in RTL code generation. It surpasses the previous best-performing open-source LLM by 12.8% and even exceeds GPT-4 Turbo in the pass@1 metric on the VerilogEval-Human benchmark. Moreover, OriGen exhibits superior capabilities in self-reflection and error correction, outperforming GPT-4 by 19.9% on a benchmark designed to evaluate self-reflection capabilities.OriGen is open source at GitHub(https://github.com/pku-liang/OriGen)},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {99},
numpages = {9},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3700058.3700099,
author = {Liu, Zhengping and He, Hailing and Zhang, Lieping and Peng, Chen},
title = {Leveraging XAI in Prompt-Based ChatGPT for Financial Decision Support},
year = {2024},
isbn = {9798400710261},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700058.3700099},
doi = {10.1145/3700058.3700099},
abstract = {Neural network models have demonstrated good results in credit evaluation and related fields. However, they are characterized as "black boxes" due to their lack of interpretability. To enhance transparency and credibility, various Explainable Artificial Intelligence (XAI) methods have been proposed. Yet, the raw outputs provided by these XAI methods are still challenging for non-experts to understand. This study presents an innovative approach that applies Large Language Models (LLMs) to credit evaluations. We design contextual prompts that integrate XAI raw outputs into the instructions for LLMs, which then generate domain-specific, and non-expert-friendly explanations in natural language. Experimental results show that the proposed method is capable of generating straightforward explanations of machine learning models for users in different roles.},
booktitle = {Proceedings of the International Conference on Digital Economy, Blockchain and Artificial Intelligence},
pages = {255–259},
numpages = {5},
keywords = {ChatGPT, Explainable AI, Finance, Large Language Models},
location = {
},
series = {DEBAI '24}
}

@inproceedings{10.1145/3654777.3676450,
author = {Shankar, Shreya and Zamfirescu-Pereira, J.D. and Hartmann, Bjoern and Parameswaran, Aditya and Arawjo, Ian},
title = {Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676450},
doi = {10.1145/3654777.3676450},
abstract = {Due to the cumbersome nature of human evaluation and limitations of code-based evaluation, Large Language Models (LLMs) are increasingly being used to assist humans in evaluating LLM outputs. Yet LLM-generated evaluators simply inherit all the problems of the LLMs they evaluate, requiring further human validation. We present a mixed-initiative approach to “validate the validators”—aligning LLM-generated evaluation functions (be it prompts or code) with human requirements. Our interface, EvalGen, provides automated assistance to users in generating evaluation criteria and implementing assertions. While generating candidate implementations (Python functions, LLM grader prompts), EvalGen asks humans to grade a subset of LLM outputs; this feedback is used to select implementations that better align with user grades. A qualitative study finds overall support for EvalGen but underscores the subjectivity and iterative nature of alignment. In particular, we identify a phenomenon we dub criteria drift: users need criteria to grade outputs, but grading outputs helps users define criteria. What is more, some criteria appear dependent on the specific LLM outputs observed (rather than independent and definable a priori), raising serious questions for approaches that assume the independence of evaluation from observation of model outputs. We present our interface and implementation details, a comparison of our algorithm with a baseline approach, and implications for the design of future LLM evaluation assistants.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {131},
numpages = {14},
keywords = {active learning, auditing, evaluation, interfaces, language models, prompt engineering},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3626772.3657689,
author = {Dong, Qian and Liu, Yiding and Ai, Qingyao and Wu, Zhijing and Li, Haitao and Liu, Yiqun and Wang, Shuaiqiang and Yin, Dawei and Ma, Shaoping},
title = {Unsupervised Large Language Model Alignment for Information Retrieval via Contrastive Feedback},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657689},
doi = {10.1145/3626772.3657689},
abstract = {Large language models (LLMs) have demonstrated remarkable capabilities across various research domains, including the field of Information Retrieval (IR). However, the responses generated by off-the-shelf LLMs tend to be generic, i.e., cannot capture the distinctiveness of each document with similar content. This limits the performance of LLMs in IR because finding and distinguishing relevant documents from substantial similar documents is a typical problem in many IR tasks. To address this issue, we propose an unsupervised alignment method, namely Reinforcement Learning from Contrastive Feedback (RLCF), empowering LLMs to generate both high-quality and context-specific responses. Our approach constructs unsupervised contrastive feedback signals based on similar document groups, and adopts a reward function, named group-wise reciprocal rank, to optimize LLMs. We conduct extensive experiments to evaluate the effectiveness of RLCF.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {48–58},
numpages = {11},
keywords = {alignment, information retrieval, large language models},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3628096.3628747,
author = {Masikisiki, Baphumelele and Marivate, Vukosi and Hlophe, Yvette},
title = {Investigating the Efficacy of Large Language Models in Reflective Assessment Methods through Chain of Thought Prompting},
year = {2024},
isbn = {9798400708879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628096.3628747},
doi = {10.1145/3628096.3628747},
abstract = {Large Language Models, such as Generative Pre-trained Transformer 3 (aka. GPT-3), have been developed to understand language through the analysis of extensive text data, allowing them to identify patterns and connections between words. While LLMs have demonstrated impressive performance across various text-related tasks, they encounter challenges in tasks associated with reasoning. To address this challenge, Chain of Thought (CoT) prompting method has been proposed as a means to enhance LLMs’ proficiency in complex reasoning tasks like solving math word problems and answering questions based on logical argumentative reasoning. The primary aim of this research is to assess how well four language models can grade reflective essays of third-year medical students. The assessment will specifically target the evaluation of critical thinking skills using CoT prompting. The research will provide the following contributions; to introduce and educate on the process of instructing models to evaluate reflective essays from a dataset they have not been previously trained on; to illustrate the use of CoT prompting as an instructional approach for training large models to carry out particular tasks. Our results suggest that among all the models, Llama-7b performs the least effectively, displaying the highest mean squared error. Conversely, ChatGPT emerges as the superior model, boasting a higher Cohen kappa score value of 0.53. Lastly, it’s important to note that the selected models do prioritise user privacy by allowing users to delete their own conducted conversations.},
booktitle = {Proceedings of the 4th African Human Computer Interaction Conference},
pages = {44–49},
numpages = {6},
keywords = {Automation Grading, Chain of thought prompting, Large Models},
location = {East London, South Africa},
series = {AfriCHI '23}
}

@inproceedings{10.1145/3691620.3695260,
author = {Feng, Sidong and Lu, Haochuan and Jiang, Jianqin and Xiong, Ting and Huang, Likun and Liang, Yinglin and Li, Xiaoqin and Deng, Yuetang and Aleti, Aldeida},
title = {Enabling Cost-Effective UI Automation Testing with Retrieval-Based LLMs: A Case Study in WeChat},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695260},
doi = {10.1145/3691620.3695260},
abstract = {UI automation tests play a crucial role in ensuring the quality of mobile applications. Despite the growing popularity of machine learning techniques to generate these tests, they still face several challenges, such as the mismatch of UI elements. The recent advances in Large Language Models (LLMs) have addressed these issues by leveraging their semantic understanding capabilities. However, a significant gap remains in applying these models to industrial-level app testing, particularly in terms of cost optimization and knowledge limitation. To address this, we introduce CAT to create cost-effective UI automation tests for industry apps by combining machine learning and LLMs with best practices. Given the task description, CAT employs Retrieval Augmented Generation (RAG) to source examples of industrial app usage as the few-shot learning context, assisting LLMs in generating the specific sequence of actions. CAT then employs machine learning techniques, with LLMs serving as a complementary optimizer, to map the target element on the UI screen. Our evaluations on the WeChat testing dataset demonstrate the CAT's performance and cost-effectiveness, achieving 90% UI automation with $0.34 cost, outperforming the state-of-the-art. We have also integrated our approach into the real-world WeChat testing platform, demonstrating its usefulness in detecting 141 bugs and enhancing the developers' testing process.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1973–1978},
numpages = {6},
keywords = {UI automation test, large language model, retrieval-augmented generation, cost optimization},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3616855.3635744,
author = {I, Muneeswaran and Shankar, Advaith and V, Varun and Gopalakrishnan, Saisubramaniam and Vaddina, Vishal},
title = {Mitigating Factual Inconsistency and Hallucination in Large Language Models},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635744},
doi = {10.1145/3616855.3635744},
abstract = {Large Language Models (LLMs) have demonstrated remarkable capabilities in various language-related tasks enabling applications in various fields such as healthcare, education, financial services etc. However, they are prone to producing factually incorrect responses or ''hallucinations'' which can have detrimental consequences such as loss of credibility, diminished customer trust etc. In this presentation, we showcase a solution that addresses the challenge of minimizing hallucinations. Our solution provides accurate responses and generates detailed explanations, thereby enabling the users to know how the model arrived at the final response. Additionally, it verifies if the explanations are factually correct and offers insights into whether the generated explanations are directly derived from the provided context or if they are inferred from it. We also systematically assess the quality of generated responses using an LLM-based evaluation technique. We present empirical results on benchmark datasets to demonstrate the effectiveness of our approach. Our presentation also examines the impact of individual components in the solution, enhancing the factual correctness of the final response. This research is vital for industries utilizing LLMs, as it provides a means to enhance the reliability of responses and mitigate the risks associated with factual hallucinations. Researchers and practitioners seeking to enhance the reliability of LLM responses will find valuable insights in this presentation.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {1169–1170},
numpages = {2},
keywords = {hallucinations, information retrieval, large language models},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3701716.3715176,
author = {Kong, Dexin and Yan, Xu and Chen, Ming and Han, Shuguang and Chen, Jufeng and Huang, Fei},
title = {FishBargain: An LLM-Empowered Bargaining Agent for Online Fleamarket Platform Sellers},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715176},
doi = {10.1145/3701716.3715176},
abstract = {Different from traditional Business-to-Consumer e-commerce platforms (e.g., Amazon), online fleamarket platforms (e.g., Craigslist) mainly focus on individual sellers who are lack of time investment and business proficiency. Individual sellers often struggle with the bargaining process and thus the deal is unaccomplished. Recent advancements in Large Language Models(LLMs) demonstrate huge potential in various dialogue tasks, but those tasks are mainly in the form of passively following user's instruction. Bargaining, as a form of proactive dialogue task, represents a distinct art of dialogue considering the dynamism of environment and uncertainty of adversary strategies. In this paper, we propose an LLM-empowered bargaining agent designed for online fleamarket platform sellers, named as FishBargain. Specifically, FishBargain understands the chat context and product information, chooses both action and language skill considering possible adversary actions and generates utterances. FishBargain has been tested by thousands of individual sellers on one of the largest online fleamarket platforms (Xianyu) in China. Both qualitative and quantitative experiments demonstrate that FishBargain can effectively help sellers make more deals.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2855–2858},
numpages = {4},
keywords = {bargaining, large language model, proactive dialogue},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3677052.3698608,
author = {Srivastava, Varad},
title = {Lending an Ear: How LLMs Hear Your Banking Intentions},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698608},
doi = {10.1145/3677052.3698608},
abstract = {Traditional language models in NLP require a considerable amount of labeled examples, which is not always available in data-limited domains like banking. Large Language Models (LLMs) are known to perform effectively with few-shot learning in various domains with just 1-5 examples per class. However, the use of open-source instruction-tuned LLMs, and how they compare to closed-source LLMs and modern few-shot learning approaches like contrastive learning in data-constrained use-cases has been under-explored. Additionally, the understanding of performance-cost trade-offs of these methods, as well as the consideration of infrastructure resource-limited settings through optimal usage of smaller versions of LLMs (7B-9B parameters), a critical concern for budget-limited organizations, has not been studied comprehensively. Our work addresses these gaps by studying the aforementioned approaches over the Banking77 financial intent detection dataset, including the evaluation and comparison of cutting-edge LLMs by Meta, Google, Mistral-AI, OpenAI, and Anthropic in a comprehensive set of few-shot scenarios which include examples selected by a human-expert, as well as with a cost-effective querying method based on retrieval-augmented generation (RAG). We observed that smaller open-source LLMs are able to out-perform larger closed-source ones with effective prompts and RAG. Moreover, they offer a significantly better performance-cost ratio than their larger closed-source counterparts. We also experiment with data-augmentation by using LLMs to generate artificial labeled examples, which is able to improve performance slightly in a data-scarce scenario. Finally, we explored benefits of fine-tuning using three parameter efficient methods and propose BAI-Fintent, an LLM based on fine-tuned Mistral-7B, that out-performs all other approaches at customer banking intent identification.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {301–309},
numpages = {9},
keywords = {Claude, Few-Shot, GPT, Gemma, LLMs, Llama, Mistral, NLP, RAG},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@article{10.1145/3709358,
author = {Fan, Lishui and Liu, Jiakun and Liu, Zhongxin and Lo, David and Xia, Xin and Li, Shanping},
title = {Exploring the Capabilities of LLMs for Code Change Related Tasks},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3709358},
doi = {10.1145/3709358},
abstract = {Developers deal with code-change-related tasks daily, e.g., reviewing code. Pre-trained code and code-change-oriented models have been adapted to help developers with such tasks. Recently, large language models (LLMs) have shown their effectiveness in code-related tasks. However, existing LLMs for code focus on general code syntax and semantics rather than the differences between two code versions. Thus, it is an open question how LLMs perform on code-change-related tasks.To answer this question, we conduct an empirical study using &gt;1B parameters LLMs on three code-change-related tasks, i.e., code review generation, commit message generation, and just-in-time comment update, with in-context learning (ICL) and parameter-efficient fine-tuning (PEFT, including LoRA and prefix-tuning). We observe that the performance of LLMs is poor without examples and generally improves with examples, but more examples do not always lead to better performance. LLMs tuned with LoRA have comparable performance to the state-of-the-art small pre-trained models. Larger models are not always better, but Llama 2 and Code Llama families are always the best. The best LLMs outperform small pre-trained models on the code changes that only modify comments and perform comparably on other code changes. We suggest future work should focus more on guiding LLMs to learn the knowledge specific to the changes related to code rather than comments for code-change-related tasks.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {Code-change-related task, large language model, empirical study}
}

@inproceedings{10.1145/3613905.3648110,
author = {Tang, Haoheng and Singha, Mrinalini},
title = {A Mystery for You: A fact-checking game enhanced by large language models (LLMs) and a tangible interface},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3648110},
doi = {10.1145/3613905.3648110},
abstract = {Fact-checking and critical thinking are essential life skills in an age of rampant misinformation. To cultivate these skills in young learners, we have developed ‘A Mystery for You’ – an educational game powered by a large language model (LLM) and a tangible interface. In this game, a player becomes a citizen fact-checker, responding to ‘news alerts’ printed out by the game interface. The player investigates various actors and evidence by inserting cartridge combinations into the game interface. Each move the player makes results in the generation and printing of a follow-up ‘news update,’ which they must use to make an informed verdict about the truth or falsehood of the news. This interactive process sharpens critical thinking skills and enhances familiarity with generative AI’s misinformation capacities. This paper contextualizes the game’s relevance in today’s media and politics, explores game-play mechanics, and critically reflects on incorporating AI generation tools for educational game play.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {631},
numpages = {5},
keywords = {Digital Literacy, Generative AI, Investigation, Misinformation, Role-Playing, Tangible Interface, Young Learners},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3637528.3671445,
author = {dos Santos Junior, Jos\'{e} Cassio and Hu, Rachel and Song, Richard and Bai, Yunfei},
title = {Domain-Driven LLM Development: Insights into RAG and Fine-Tuning Practices},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671445},
doi = {10.1145/3637528.3671445},
abstract = {To improve Large Language Model (LLM) performance on domain specific applications, ML developers often leverage Retrieval Augmented Generation (RAG) and LLM Fine-Tuning. RAG extends the capabilities of LLMs to specific domains or an organization's internal knowledge base, without the need to retrain the model. On the other hand, Fine-Tuning approach updates LLM weights with domain-specific data to improve performance on specific tasks. The fine-tuned model is particularly effective to systematically learn new comprehensive knowledge in a specific domain that is not covered by the LLM pre-training. This tutorial walks through the RAG and Fine-Tuning techniques, discusses the insights of their advantages and limitations, and provides best practices of adopting the methodologies for the LLM tasks and use cases. The hands-on labs demonstrate the advanced techniques to optimize the RAG and fine-tuned LLM architecture that handles domain specific LLM tasks. The labs in the tutorial are designed by using a set of open-source python libraries to implement the RAG and fine-tuned LLM architecture.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6416–6417},
numpages = {2},
keywords = {fine tuning, generative artificial intelligence, large language model, retrieval augmented generation},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3640771.3643717,
author = {Luan, Zhirong and Lai, Yujun and Huang, Rundong and Yan, Yan and Wang, Jingwei and Lu, Jizhou and Chen, Badong},
title = {Hierarchical Large Language Models in Cloud-Edge-End Architecture for Heterogeneous Robot Cluster Control},
year = {2024},
isbn = {9798400708954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640771.3643717},
doi = {10.1145/3640771.3643717},
abstract = {Despite their powerful semantic understanding and code generation capabilities, Large Language Models (LLMs) still face challenges when dealing with complex tasks. Multi-agent strategy generation and motion control are highly complex domains that inherently require experts from multiple fields to collaborate. To enhance multi-agent strategy generation and motion control, we propose an innovative architecture that employs the concept of a cloud-edge-end hierarchical structure. By leveraging multiple large language models with distinct areas of expertise, we can efficiently generate strategies and perform task decomposition. Introducing the cosine similarity approach, aligning task decomposition instructions with robot task sequences at the vector level, we can identify subtasks with incomplete task decomposition and iterate on them multiple times to ultimately generate executable machine task sequences.The robot is guided through these task sequences to complete tasks of higher complexity. With this architecture, we implement the process of natural language control of robots to perform complex tasks, and successfully address the challenge of multi-agent execution of open tasks in open scenarios and the problem of task decomposition.},
booktitle = {Proceedings of the 2023 2nd International Symposium on Computing and Artificial Intelligence},
pages = {102–105},
numpages = {4},
keywords = {Cosine similarity, LLMS, Task decomposition},
location = {Shanghai, China},
series = {ISCAI '23}
}

@inproceedings{10.1145/3640543.3645171,
author = {Silva, \'{I}tallo and Marinho, Leandro and Said, Alan and Willemsen, Martijn C.},
title = {Leveraging ChatGPT for Automated Human-centered Explanations in Recommender Systems},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645171},
doi = {10.1145/3640543.3645171},
abstract = {The adoption of recommender systems (RSs) in various domains has become increasingly popular, but concerns have been raised about their lack of transparency and interpretability. While significant advancements have been made in creating explainable RSs, there is still a shortage of automated approaches that can deliver meaningful and contextual human-centered explanations. Numerous researchers have evaluated explanations based on human-generated recommendations and explanations to address this gap. However, such approaches do not scale for real-world systems. Building on recent research that exploits Large Language Models (LLMs) for RSs, we propose leveraging the conversational capabilities of ChatGPT to provide users with personalized, human-like, and meaningful explanations for recommended items. Our paper presents one of the first user studies that measure users’ perceptions of ChatGPT-generated explanations while acting as an RS. Regarding recommendations, we assess whether users prefer ChatGPT over random (but popular) recommendations. Concerning explanations, we assess users’ perceptions of personalization, effectiveness, and persuasiveness. Our findings reveal that users tend to prefer ChatGPT-generated recommendations over popular ones. Additionally, personalized rather than generic explanations prove to be more effective when the recommended item is unfamiliar.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {597–608},
numpages = {12},
keywords = {explanations, large language models, recommender systems},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@inproceedings{10.1145/3708036.3708272,
author = {Yang, Guangyuan and Xie, Quanying and Chen, Lei},
title = {A Scientometrics Analysis and Visualization of Large Language Model in China's Library},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708272},
doi = {10.1145/3708036.3708272},
abstract = {Large Language Model has been researched in the field of library from the following aspects:space reproduction, service reform, library construction and so on. In order to clarify the current research situation of Large Language Model's application research in the field of library, and provide some reference for the further development of research fields related to Large Language Model empowering library in the future. This paper utilizes two methods of scientometrics and data visualization to analyze and study the journal papers on the application of Large Language Model in the field of Chinese libraries from the aspects of the degree of academic focus, the way of creating academic achievements and research topics of academic achievements, and puts forward the research practice of strengthening the application of Large Language Model in library from the aspects of ’Strengthen the practical research of Large Language Model empowering Chinese library’ and ‘Broaden the field of research related to Large Language Model empowering Chinese library’, in order to promote the all-round development of Large Language Model in the field of library.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {1403–1407},
numpages = {5},
keywords = {Chinese libraries, Data Visualization, Large Language Model, Library Service, Scientometrics},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3676536.3697118,
author = {Liu, Shang and Lu, Yao and Fang, Wenji and Li, Mengming and Xie, Zhiyao},
title = {OpenLLM-RTL: Open Dataset and Benchmark for LLM-Aided Design RTL Generation},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3697118},
doi = {10.1145/3676536.3697118},
abstract = {The automated generation of design RTL based on large language model (LLM) and natural language instructions has demonstrated great potential in agile circuit design. However, the lack of datasets and benchmarks in the public domain prevents the development and fair evaluation of LLM solutions. This paper highlights our latest advances in open datasets and benchmarks from three perspectives: (1) RTLLM 2.0, an updated benchmark assessing LLM's capability in design RTL generation. The benchmark is augmented to 50 hand-crafted designs. Each design provides the design description, test cases, and a correct RTL code. (2) AssertEval, an open-source benchmark assessing the LLM's assertion generation capabilities for RTL verification. The benchmark includes 18 designs, each providing specification, signal definition, and correct RTL code. (3) RTLCoder-Data, an extended open-source dataset with 80K instruction-code data samples. Moreover, we propose a new verification-based method to verify the functionality correctness of training data samples. Based on this technique, we further release a dataset with 7K verified high-quality samples. These three studies are integrated into one framework, providing off-the-shelf support for the development and evaluation of LLMs for RTL code generation and verification. Finally, extensive experiments indicate that LLM performance can be boosted by enlarging the training dataset, improving data quality, and improving the training scheme.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {60},
numpages = {9},
keywords = {LLM-assisted circuit design, electronic design automation},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3706598.3713888,
author = {Kim, Minseo and Kim, Taemin and Vo, Thu Hoang Anh and Jung, Yugyeong and Lee, Uichin},
title = {Exploring Modular Prompt Design for Emotion and Mental Health Recognition},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713888},
doi = {10.1145/3706598.3713888},
abstract = {Recent advances in large language models (LLM) offered human-like capabilities for comprehending emotion and mental states. Prior studies explored diverse prompt engineering techniques for improving classification performance, but there is a lack of analysis of prompt design space and the impact of each component. To bridge this gap, we conduct a qualitative thematic analysis of existing prompts for emotion and mental health classification tasks to define the key components for prompt design space. We then evaluate the impact of major prompt components, such as persona and task instruction, on classification performance by using four LLM models and five datasets. Modular prompt design offers new insights into examining performance variability as well as promoting transparency and reproducibility in LLM-based tasks within health and well-being intervention systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1181},
numpages = {18},
keywords = {Large language model, prompt engineering, emotion, mental health},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3616855.3635738,
author = {Das, Sudeep and Saboo, Raghav and Vadrevu, Chaitanya S. K. and Wang, Bruce and Xu, Steven},
title = {Applications of LLMs in E-Commerce Search and Product Knowledge Graph: The DoorDash Case Study},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635738},
doi = {10.1145/3616855.3635738},
abstract = {Extracting knowledge from unstructured or semi-structured textual information is essential for the machine learning applications that power DoorDash's search experience, and the development and maintenance of its product knowledge graph. Large language models (LLMs) have opened up new possibilities for utilizing their power in these areas, replacing or complementing traditional natural language processing methods. LLMs are also proving to be useful in the label and annotation generation process, which is critical for these use cases. In this talk, we will provide a high-level overview of how we incorporated LLMs for search relevance and product understanding use cases, as well as the key lessons learned and challenges faced during their practical implementation.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {1163–1164},
numpages = {2},
keywords = {large language model, natural language processing, product knowledge graph, search},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3652988.3673929,
author = {Yun, Hye Sun and Arjmand, Mehdi and Sherlock, Phillip and Paasche-Orlow, Michael K and Griffith, James W and Bickmore, Timothy},
title = {Keeping Users Engaged During Repeated Interviews by a Virtual Agent: Using Large Language Models to Reliably Diversify Questions},
year = {2024},
isbn = {9798400706257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652988.3673929},
doi = {10.1145/3652988.3673929},
abstract = {Standardized, validated questionnaires are vital tools in research and healthcare, offering dependable self-report data. Prior work has revealed that virtual agent-administered questionnaires are almost equivalent to self-administered ones in an electronic form. Despite being an engaging method, repeated use of virtual agent-administered questionnaires in longitudinal or pre-post studies can induce respondent fatigue, impacting data quality via response biases and decreased response rates. We propose using large language models (LLMs) to generate diverse questionnaire versions while retaining good psychometric properties. In a longitudinal study, participants interacted with our agent system and responded daily for two weeks to one of the following questionnaires: a standardized depression questionnaire, question variants generated by LLMs, or question variants accompanied by LLM-generated small talk. The responses were compared to a validated depression questionnaire. Psychometric testing revealed consistent covariation between the external criterion and focal measure administered across the three conditions, demonstrating the reliability and validity of the LLM-generated variants. Participants found that the variants were significantly less repetitive than repeated administrations of the same standardized questionnaire. Our findings highlight the potential of LLM-generated variants to invigorate agent-administered questionnaires and foster engagement and interest, without compromising their validity.},
booktitle = {Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents},
articleno = {13},
numpages = {10},
keywords = {engagement, health, large language models, longitudinal research, questionnaires, virtual agents},
location = {GLASGOW, United Kingdom},
series = {IVA '24}
}

@inproceedings{10.1145/3587103.3594206,
author = {Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Caspersen, Michael E. and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir},
title = {Transformed by Transformers: Navigating the AI Coding Revolution for Computing Education: An ITiCSE Working Group Conducted by Humans},
year = {2023},
isbn = {9798400701399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587103.3594206},
doi = {10.1145/3587103.3594206},
abstract = {The recent advent of highly accurate and scalable large language models (LLMs) has taken the world by storm. From art to essays to computer code, LLMs are producing novel content that until recently was thought only humans could produce. Recent work in computing education has sought to understand the capabilities of LLMs for solving tasks such as writing code, explaining code, creating novel coding assignments, interpreting programming error messages, and more. However, these technologies continue to evolve at an astonishing rate leaving educators little time to adapt. This working group seeks to document the state-of-the-art for code generation LLMs, detail current opportunities and challenges related to their use, and present actionable approaches to integrating them into computing curricula.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2},
pages = {561–562},
numpages = {2},
keywords = {AI, CS1, GPT, GitHub, LLM, artificial intelligence, code generation, codex, computer programming, copilot, large language models, novice programming, openAI, pedagogical practices},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3626772.3657662,
author = {Wang, Zijie J. and Chau, Duen Horng},
title = {MeMemo: On-device Retrieval Augmentation for Private and Personalized Text Generation},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657662},
doi = {10.1145/3626772.3657662},
abstract = {Retrieval-augmented text generation (RAG) addresses the common limitations of large language models (LLMs), such as hallucination, by retrieving information from an updatable external knowledge base. However, existing approaches often require dedicated backend servers for data storage and retrieval, thereby limiting their applicability in use cases that require strict data privacy, such as personal finance, education, and medicine. To address the pressing need for client-side dense retrieval, we introduce MeMemo, the first open-source JavaScript toolkit that adapts the state-of-the-art approximate nearest neighbor search technique HNSW to browser environments. Developed with modern and native Web technologies, such as IndexedDB and Web Workers, our toolkit leverages client-side hardware capabilities to enable researchers and developers to efficiently search through millions of high-dimensional vectors in the browser. MeMemo enables exciting new design and research opportunities, such as private and personalized content creation and interactive prototyping, as demonstrated in our example application RAG Playground. Reflecting on our work, we discuss the opportunities and challenges for on-device dense retrieval. MeMemo is available at https://github.com/poloclub/mememo.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2765–2770},
numpages = {6},
keywords = {large language models, neural information retrieval, on-device},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3613904.3641899,
author = {Reza, Mohi and Laundry, Nathan M and Musabirov, Ilya and Dushniku, Peter and Yu, Zhi Yuan “Michael” and Mittal, Kashish and Grossman, Tovi and Liut, Michael and Kuzminykh, Anastasia and Williams, Joseph Jay},
title = {ABScribe: Rapid Exploration &amp; Organization of Multiple Writing Variations in Human-AI Co-Writing Tasks using Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641899},
doi = {10.1145/3613904.3641899},
abstract = {Exploring alternative ideas by rewriting text is integral to the writing process. State-of-the-art Large Language Models (LLMs) can simplify writing variation generation. However, current interfaces pose challenges for simultaneous consideration of multiple variations: creating new variations without overwriting text can be difficult, and pasting them sequentially can clutter documents, increasing workload and disrupting writers’ flow. To tackle this, we present ABScribe, an interface that supports rapid, yet visually structured, exploration and organization of writing variations in human-AI co-writing tasks. With ABScribe, users can swiftly modify variations using LLM prompts, which are auto-converted into reusable buttons. Variations are stored adjacently within text fields for rapid in-place comparisons using mouse-over interactions on a popup toolbar. Our user study with 12 writers shows that ABScribe significantly reduces task workload (d = 1.20, p &lt; 0.001), enhances user perceptions of the revision process (d = 2.41, p &lt; 0.001) compared to a popular baseline workflow, and provides insights into how writers explore variations using LLMs.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1042},
numpages = {18},
keywords = {datasets, gaze detection, neural networks, text tagging},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3674805.3686684,
author = {Astekin, Merve and Hort, Max and Moonen, Leon},
title = {A Comparative Study on Large Language Models for Log Parsing},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3686684},
doi = {10.1145/3674805.3686684},
abstract = {Background: Log messages provide valuable information about the status of software systems. This information is provided in an unstructured fashion and automated approaches are applied to extract relevant parameters. To ease this process, log parsing can be applied, which transforms log messages into structured log templates. Recent advances in language models have led to several studies that apply ChatGPT to the task of log parsing with promising results. However, the performance of other state-of-the-art large language models (LLMs) on the log parsing task remains unclear. Aims: In this study, we investigate the current capability of state-of-the-art LLMs to perform log parsing. Method: We select six recent LLMs, including both paid proprietary (GPT-3.5, Claude 2.1) and four free-to-use open models, and compare their performance on system logs obtained from a selection of mature open-source projects. We design two different prompting approaches and apply the LLMs on 1,354 log templates across 16 different projects. We evaluate their effectiveness, in the number of correctly identified templates, and the syntactic similarity between the generated templates and the ground truth. Results: We found that free-to-use models are able to compete with paid models, with CodeLlama extracting 10% more log templates correctly than GPT-3.5. Moreover, we provide qualitative insights into how usable these six models are for log parsing. Conclusions: Our results reveal that some of the smaller, free-to-use LLMs can considerably assist log parsing compared to their paid proprietary competitors, especially code-specialized models.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {234–244},
numpages = {11},
keywords = {large language models, log analysis, log parsing},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3583780.3615188,
author = {Sung, Hao-Ru and Tang, Ying-Jhe and Cheng, Yu-Chung and Chen, Pai-Lin and Li, Tsai-Yen and Huang, Hen-Hsen},
title = {Sequential Text-based Knowledge Update with Self-Supervised Learning for Generative Language Models},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615188},
doi = {10.1145/3583780.3615188},
abstract = {This work proposes a new natural language processing (NLP) task to tackle the issue of multi-round, sequential text-based knowledge update. The study introduces a hybrid learning architecture and a novel self-supervised training strategy to enable generative language models to consolidate knowledge in the same way as humans. A dataset was also created for evaluation and results showed the effectiveness of our methodology. Experimental results confirm the superiority of the proposed approach over existing models and large language models (LLMs). The proposed task and model framework have the potential to significantly improve the automation of knowledge organization, making text-based knowledge an increasingly crucial resource for powerful LLMs to perform various tasks for humans.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {4305–4309},
numpages = {5},
keywords = {natural language generation, self-supervision, temporal knowledge modeling, update summarization},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3637528.3671573,
author = {Kuang, Weirui and Qian, Bingchen and Li, Zitao and Chen, Daoyuan and Gao, Dawei and Pan, Xuchen and Xie, Yuexiang and Li, Yaliang and Ding, Bolin and Zhou, Jingren},
title = {FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671573},
doi = {10.1145/3637528.3671573},
abstract = {Large language models (LLMs) have demonstrated great capabilities in various natural language understanding and generation tasks. These pre-trained LLMs can be further improved for specific downstream tasks by fine-tuning. However, the adoption of LLM in real-world applications can be hindered by privacy concerns and the resource-intensive nature of model training and fine-tuning. When multiple entities have similar interested tasks but cannot directly share their local data due to privacy regulations, federated learning (FL) is a mainstream solution to leverage the data of different entities. Besides avoiding direct data sharing, FL can also achieve rigorous data privacy protection, model intelligent property protection, and model customization via composition with different techniques. Despite the aforementioned advantages of FL, fine-tuning LLMs in FL settings still lacks adequate support from the existing frameworks and, therefore, faces challenges in optimizing the consumption of significant communication and computational resources, preparing various data for different tasks, and satisfying diverse information protection demands. In this paper, we discuss these challenges and introduce our package FederatedScope-LLM (FS-LLM) as a main contribution, which consists: (1) We build a complete end-to-end benchmarking pipeline under real-world scenarios, automizing the processes of dataset preprocessing, federated fine-tuning execution or simulation, and performance evaluation; (2) We provide comprehensive and off-the-shelf federated parameter-efficient fine-tuning (PEFT) algorithm implementations and versatile programming interfaces for future extension, enhancing the capabilities of LLMs in FL scenarios with low communication and computation costs, even without accessing the full model; (3) We adopt several accelerating and resource-efficient operators, and provide flexible pluggable sub-routines for interdisciplinary study. We conduct extensive and reproducible experiments to show the effectiveness of FS-LLM and benchmark advanced LLMs with PEFT algorithms in FL. We release FS-LLM at https://github.com/alibaba/FederatedScope/tree/llm.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5260–5271},
numpages = {12},
keywords = {benchmark, federated learning, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3643916.3644435,
author = {Sergeyuk, Agnia and Lvova, Olga and Titov, Sergey and Serova, Anastasiia and Bagirov, Farid and Kirillova, Evgeniia and Bryksin, Timofey},
title = {Reassessing Java Code Readability Models with a Human-Centered Approach},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644435},
doi = {10.1145/3643916.3644435},
abstract = {To ensure that Large Language Models (LLMs) effectively support user productivity, they need to be adjusted. Existing Code Readability (CR) models can guide this alignment. However, there are concerns about their relevance in modern software engineering since they often miss the developers' notion of readability and rely on outdated code. This research assesses existing Java CR models for LLM adjustments, measuring the correlation between their and developers' evaluations of AI-generated Java code. Using the Repertory Grid Technique with 15 developers, we identified 12 key code aspects influencing CR that were consequently assessed by 390 programmers when labeling 120 AI-generated snippets. Our findings indicate that when AI generates concise and executable code, it's often considered readable by CR models and developers. However, a limited correlation between these evaluations underscores the importance of future research on learning objectives for adjusting LLMs and on the aspects influencing CR evaluations included in predictive models.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {225–235},
numpages = {11},
keywords = {code readability, code readability models, repertory grid technique, AI-generated code, human-computer interaction},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3627673.3679885,
author = {Li, Peiyu and Huang, Xiaobao and Tian, Yijun and Chawla, Nitesh V.},
title = {ChefFusion: Multimodal Foundation Model Integrating Recipe and Food Image Generation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679885},
doi = {10.1145/3627673.3679885},
abstract = {Significant work has been conducted in the domain of food computing, yet these studies typically focus on single tasks such as t2t (instruction generation from food titles and ingredients), i2t (recipe generation from food images), or t2i (food image generation from recipes). None of these approaches integrate all modalities simultaneously. To address this gap, we introduce a novel food computing foundation model that achieves true multimodality, encompassing tasks such as t2t, t2i, i2t, it2t, and t2ti. By leveraging large language models (LLMs) and pre-trained image encoder and decoder models, our model can perform a diverse array of food computing-related tasks, including food understanding, food recognition, recipe generation, and food image generation. Compared to previous models, our foundation model demonstrates a significantly broader range of capabilities and exhibits superior performance, particularly in food image generation and recipe generation tasks. We open-sourced ChefFusion at https://github.com/Peiyu-Georgia-Li/ChefFusion-Multimodal-Foundation-Model-Integrating-Recipe-and-Food-Image-Generation.git.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3872–3876},
numpages = {5},
keywords = {food image generation, llms, multimodal, recipe generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3712704,
author = {Papicchio, Simone and Papotti, Paolo and Cagliero, Luca},
title = {QATCH: Automatic Evaluation of SQL-Centric Tasks on Proprietary Data},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {2157-6904},
url = {https://doi.org/10.1145/3712704},
doi = {10.1145/3712704},
abstract = {Tabular Representation Learning (TRL) and Large Language Models (LLMs) have become established for tackling Question Answering (QA) and Semantic Parsing (SP) tasks on tabular data. State-of-the-art models are pre-trained and evaluated on large open-domain datasets. However, the performance on existing QA and SP benchmarks is not necessarily representative of that achieved on proprietary data as the characteristics of the input and the complexity of the posed queries show high variability. To tackle this challenge, our goal is to allow end-users to evaluate TRL and LLM performance on their own proprietary data. We present Query-Aided TRL CHecklist (QATCH), a toolbox to automatically generate a testing checklist tailored to QA and SP. QATCH provides a testing suite highlighting models’ strengths and weaknesses on relational tables unseen at training time. The proposed toolbox relies on a SQL query generator that crafts tests of varying types and complexity including, amongst others, tests on null values, projection, selections, joins, group by, and having clauses. QATCH also supports a set of general cross-task performance metrics providing more insights into SQL-related model capabilities than currently used metrics. The empirical results, achieved by state-of-the-art TRL models and LLMs, show substantial performance differences (1) between existing benchmarks and proprietary data, (2) across queries of different complexity.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = apr,
articleno = {45},
numpages = {26},
keywords = {Tabular Representation Learning, Semantic Parsing, Text2SQL, Table Question Answering, Large Language Models, Query Generation}
}

@inproceedings{10.1145/3613904.3642081,
author = {Bhattacharjee, Ananya and Zeng, Yuchen and Xu, Sarah Yi and Kulzhabayeva, Dana and Ma, Minyi and Kornfield, Rachel and Ahmed, Syed Ishtiaque and Mariakakis, Alex and Czerwinski, Mary P and Kuzminykh, Anastasia and Liut, Michael and Williams, Joseph Jay},
title = {Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642081},
doi = {10.1145/3613904.3642081},
abstract = {Traditional interventions for academic procrastination often fail to capture the nuanced, individual-specific factors that underlie them. Large language models (LLMs) hold immense potential for addressing this gap by permitting open-ended inputs, including the ability to customize interventions to individuals’ unique needs. However, user expectations and potential limitations of LLMs in this context remain underexplored. To address this, we conducted interviews and focus group discussions with 15 university students and 6 experts, during which a technology probe for generating personalized advice for managing procrastination was presented. Our results highlight the necessity for LLMs to provide structured, deadline-oriented steps and enhanced user support mechanisms. Additionally, our results surface the need for an adaptive approach to questioning based on factors like busyness. These findings offer crucial design implications for the development of LLM-based tools for managing procrastination while cautioning the use of LLMs for therapeutic guidance.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {15},
numpages = {18},
keywords = {ChatGPT, Education, GPT-4, Large Language Models, Personalized Reflections, Procrastination},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3627673.3680270,
author = {Lyu, Hanjia},
title = {Towards Advancing Text-Based User and Item Representation in Personalized Recommendation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680270},
doi = {10.1145/3627673.3680270},
abstract = {In the realm of personalized recommendation systems, accurately capturing user preferences and item characteristics is important for delivering relevant and satisfying recommendations. This study introduces innovative approaches using Large Language Models (LLMs) to generate detailed textual descriptions that enhance both user and item representations. We propose a dual strategy: for user representation, we employ supervised fine-tuning coupled with Retrieval-Augmented Generation (RAG) to keep the model current with dynamic user preferences; for item representation, we leverage the extensive knowledge base of LLMs to enrich item descriptions and infer traits from user interactions. These methods promise a deeper, more nuanced understanding of both users and items, potentially leading to superior recommendation accuracy. We adopt a rigorous evaluation methodology, ensuring the reliability of our results and the effectiveness of our proposed system. This paper discusses these methodologies, presents our preliminary findings, and highlights the potential of text-augmented profiles in advancing recommendation systems.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5459–5462},
numpages = {4},
keywords = {content understanding, personalization, recommendation, representation learning, user understanding},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3696410.3714690,
author = {Xu, Hongyuan and Niu, Yuhang and Wen, Yanlong and Yuan, Xiaojie},
title = {Compress and Mix: Advancing Efficient Taxonomy Completion with Large Language Models},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714690},
doi = {10.1145/3696410.3714690},
abstract = {Taxonomy completion aims to integrate new concepts into existing taxonomies by determining their appropriate hypernym and hyponym. While semantic and structural information are crucial for this task, existing approaches often struggle to balance these aspects effectively. In this paper, we propose COMI, an efficient taxonomy completion framework that leverages large language models (LLMs) to capture both semantic and structural information in a unified manner. COMI &lt;u&gt;co&lt;/u&gt;mpresses node semantics into token representations, enabling LLMs to efficiently process the input structure composed of these tokens. To enhance the model's understanding of the structure, a further fine-tuning process using contrastive learning with &lt;u&gt;mi&lt;/u&gt;xup data augmentation is applied, where mixup generates diverse and challenging negative samples. Through these innovations, COMI improves the integration of semantic and structural information, leading to more accurate taxonomy completion. The experimental results on three real-world datasets demonstrate that COMI achieves state-of-the-art performance while showing up to 284x faster inference compared to the previous best method. Our code and compressed tokens are available at https://github.com/cyclexu/COMI.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4239–4249},
numpages = {11},
keywords = {LLM, context compression, mixup, taxonomy completion},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3699538.3699556,
author = {Birillo, Anastasiia and Artser, Elizaveta and Potriasaeva, Anna and Vlasov, Ilya and Dzialets, Katsiaryna and Golubev, Yaroslav and Gerasimov, Igor and Keuning, Hieke and Bryksin, Timofey},
title = {One Step at a Time: Combining LLMs and Static Analysis to Generate Next-Step Hints for Programming Tasks},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699556},
doi = {10.1145/3699538.3699556},
abstract = {Students often struggle with solving programming problems when learning to code, especially when they have to do it online, with one of the most common disadvantages of working online being the lack of personalized help. This help can be provided as next-step hint generation, i.e., showing a student what specific small step they need to do next to get to the correct solution. There are many ways to generate such hints, with large language models (LLMs) being among the most actively studied right now. While LLMs constitute a promising technology for providing personalized help, combining them with other techniques, such as static analysis, can significantly improve the output quality. In this work, we utilize this idea and propose a novel system to provide both textual and code hints for programming tasks. The pipeline of the proposed approach uses a chain-of-thought prompting technique and consists of three distinct steps: (1) generating subgoals — a list of actions to proceed with the task from the current student’s solution, (2) generating the code to achieve the next subgoal, and (3) generating the text to describe this needed action. During the second step, we apply static analysis to the generated code to control its size and quality. The tool is implemented as a modification to the open-source JetBrains Academy plugin, supporting students in their in-IDE courses. To evaluate our approach, we propose a list of criteria for all steps in our pipeline and conduct two rounds of expert validation. Finally, we evaluate the next-step hints in a classroom with 14 students from two universities. Our results show that both forms of the hints — textual and code — were helpful for the students, and the proposed system helped them to proceed with the coding tasks.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {9},
numpages = {12},
keywords = {Programming Education, in-IDE learning, LLMs, Generative AI, Next-Step Hints},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3627673.3679908,
author = {Chen, Mengyao and Zhang, Xinghua and Zhang, Junhao and Li, Quangang and Liu, Tingwen},
title = {Empowering LLMs for Multi-Page Layout Generation via Consistency-Oriented In-Context Learning},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679908},
doi = {10.1145/3627673.3679908},
abstract = {Document layout generation, a burgeoning field of document intelligence, entails positioning and sizing various elements within given constraints. While significant strides have been made in single-page layout generation, real-world documents predominantly span multiple pages, and exploring multi-page layout generation methods has also become the key to meeting the contemporary dramatically increased document processing demands. Despite the promise of leveraging large language models (LLMs) like GPT-4 for their powerful in-context learning abilities, the task transition to multi-page layouts, which contains considerably complex data, presents formidable challenges including excessively long prompts and strict consistency between pages. To this end, we propose a novel framework called Multi-Page Layout Generation via Consistency-Oriented modeling (MuLCO) that capitalizes on in-context learning of LLMs without the need for training or fine-tuning. MuLCO employs three key components: serialization based on code blocks maps intricate document layouts to code-style exemplars, self-correcting reasoning hint decomposes the complex generation task into numerous steps to improve reasoning interpretability, and consistency-oriented multi-round generation predicts coherent multi-page layouts in form of a continuous dialogue. To summarize, we contribute by proposing MuLCO and developing a task-specific dataset and evaluation mechanism. Extensive experiments validate the effectiveness of the MuLCO framework for multi-page layout generation.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3679–3683},
numpages = {5},
keywords = {document layout generation, in-context learning, large language models, multi-page layout},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3626772.3657778,
author = {Li, Xiaoxi and Dou, Zhicheng and Zhou, Yujia and Liu, Fangchao},
title = {CorpusLM: Towards a Unified Language Model on Corpus for Knowledge-Intensive Tasks},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657778},
doi = {10.1145/3626772.3657778},
abstract = {Large language models (LLMs) have gained significant attention in various fields but prone to hallucination, especially in knowledge-intensive (KI) tasks. To address this, retrieval-augmented generation (RAG) has emerged as a popular solution to enhance factual accuracy. However, traditional retrieval modules often rely on large document index and disconnect with generative tasks. With the advent of generative retrieval (GR), language models can retrieve by directly generating document identifiers (DocIDs), offering superior performance in retrieval tasks. However, the potential relationship between GR and downstream tasks remains unexplored. In this paper, we propose CorpusLM, a unified language model that leverages external corpus to tackle various knowledge-intensive tasks by integrating generative retrieval, closed-book generation, and RAG through a unified greedy decoding process. We design the following mechanisms to facilitate effective retrieval and generation, and improve the end-to-end effectiveness of KI tasks: (1) We develop a ranking-oriented DocID list generation strategy, which refines GR by directly learning from a DocID ranking list, to improve retrieval quality. (2) We design a continuous DocIDs-References-Answer generation strategy, which facilitates effective and efficient RAG. (3) We employ well-designed unsupervised DocID understanding tasks, to comprehend DocID semantics and their relevance to downstream tasks. We evaluate our approach on the widely used KILT benchmark with two variants of backbone models, i.e., T5 and Llama2. Experimental results demonstrate the superior performance of our models in both retrieval and downstream tasks.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {26–37},
numpages = {12},
keywords = {generative retrieval, knowledge-intensive language tasks, rag},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3613904.3642216,
author = {Kim, Tae Soo and Lee, Yoonjoo and Shin, Jamin and Kim, Young-Ho and Kim, Juho},
title = {EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642216},
doi = {10.1145/3613904.3642216},
abstract = {By simply composing prompts, developers can prototype novel generative applications with Large Language Models (LLMs). To refine prototypes into products, however, developers must iteratively revise prompts by evaluating outputs to diagnose weaknesses. Formative interviews (N=8) revealed that developers invest significant effort in manually evaluating outputs as they assess context-specific and subjective criteria. We present EvalLM, an interactive system for iteratively refining prompts by evaluating multiple outputs on user-defined criteria. By describing criteria in natural language, users can employ the system’s LLM-based evaluator to get an overview of where prompts excel or fail, and improve these based on the evaluator’s feedback. A comparative study (N=12) showed that EvalLM, when compared to manual evaluation, helped participants compose more diverse criteria, examine twice as many outputs, and reach satisfactory prompts with 59% fewer revisions. Beyond prompts, our work can be extended to augment model evaluation and alignment in specific application contexts.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {306},
numpages = {21},
keywords = {Evaluation, Human-AI Interaction, Large Language Models, Natural Language Generation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3652988.3673923,
author = {Galland, Lucie and Pelachaud, Catherine and Pecune, Florian},
title = {Simulating Patient Oral Dialogues: A Study on Naturalness and Coherence of Conditioned Large Language Models},
year = {2024},
isbn = {9798400706257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652988.3673923},
doi = {10.1145/3652988.3673923},
abstract = {The demand for mental health services has outpaced available resources, resulting in long wait times for patients. A potential solution is to use virtual agents that perform motivational interviews. These agents can be rule-based, requiring expert knowledge, or data-driven, needing large datasets for training, which are often hard to obtain. Patient simulation can generate synthetic data as an alternative. Traditionally, this involved template utterances with a dialog manager or uncontrollable black box large language models LLMs. This study proposes a hybrid approach, leveraging both methods to see if LLMs can follow instructed dialog acts while generating natural, coherent utterances. Our study shows that the language model adheres to given conditions and that conditioning on dialog improves the naturalness and coherence of generated utterances, validating our approach for simulating patient responses.},
booktitle = {Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents},
articleno = {39},
numpages = {4},
keywords = {Dialog response generation, Motivational interviewing, Patient simulation, Subjective evaluation},
location = {GLASGOW, United Kingdom},
series = {IVA '24}
}

@article{10.1145/3690635,
author = {Li, Jia and Li, Ge and Li, Yongmin and Jin, Zhi},
title = {Structured Chain-of-Thought Prompting for Code Generation},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3690635},
doi = {10.1145/3690635},
abstract = {Large Language Models (LLMs) have shown impressive abilities in code generation. Chain-of-Thought (CoT) prompting is the state-of-the-art approach to utilizing LLMs. CoT prompting asks LLMs first to generate CoTs (i.e., intermediate natural language reasoning steps) and then output the code. However, the accuracy of CoT prompting still cannot satisfy practical applications. For example, gpt-3.5-turbo with CoT prompting only achieves 53.29% Pass@1 in HumanEval. In this article, we propose Structured CoTs (SCoTs) and present a novel prompting technique for code generation named SCoT prompting. Our motivation is that human developers follow structured programming. Developers use three programming structures (i.e., sequential, branch, and loop) to design and implement structured programs. Thus, we ask LLMs to use three programming structures to generate SCoTs (structured reasoning steps) before outputting the final code. Compared to CoT prompting, SCoT prompting explicitly introduces programming structures and unlocks the structured programming thinking of LLMs. We apply SCoT prompting to two LLMs (i.e., gpt-4-turbo, gpt-3.5-turbo, and DeepSeek Coder-Instruct- ({) 1.3B, 6.7B, 33B (}) ) and evaluate it on three benchmarks (i.e., HumanEval, MBPP, and MBCPP). SCoT prompting outperforms CoT prompting by up to 13.79% in Pass@1. SCoT prompting is robust to examples and achieves substantial improvements. The human evaluation also shows human developers prefer programs from SCoT prompting.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
articleno = {37},
numpages = {23},
keywords = {Code Generation, Large Language Models, Prompting Engineering}
}

@inbook{10.1145/3677389.3702588,
author = {Keya, Farhana and Jaradeh, Mohamad Yaser and Auer, S\'{o}ren},
title = {Leveraging LLMs for Scientific Abstract Summarization: Unearthing the Essence of Research in a Single Sentence},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702588},
abstract = {There are lots of scientific articles are being published every year, it is increasingly challenging for researchers to maintain oversight and track scientific progress. Meanwhile, Large Language Models (LLMs) have revolutionized natural language processing tasks. This research focuses on generating summaries from research paper abstracts by utilizing LLMs and comprehensively evaluating the performance of the summarization. LLMs offer customizable outputs through Prompt Engineering by leveraging descriptive instructions including instructive examples and injection of context knowledge. We investigate the performance of various prompting techniques for various LLMs using both GPT-4 and human evaluation. For that purpose, we created a comprehensive benchmark dataset for scholarly summarization covering multiple scientific domains. We integrated our approach in the Open Research Knowledge Graph (ORKG) to enable quicker syn- thesis of research findings and trends across multiple studies, facilitating the dissemination of scientific knowledge to policymakers, practitioners, and the public.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {9},
numpages = {7}
}

@inproceedings{10.1145/3672608.3707900,
author = {Zhang, Zhiyong and Liu, Ruyu and Liu, Xiufeng and Zhu, Yunrui and Yang, Yanyan and Wang, Chaochao and Zhang, Jianhua},
title = {PULLM: A Multimodal Framework for Enhanced 3D Point Cloud Upsampling Using Large Language Models},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707900},
doi = {10.1145/3672608.3707900},
abstract = {Point cloud upsampling is a critical task in 3D computer vision, aiming to generate dense and uniformly distributed point sets from sparse inputs. While current self-supervised methods show promise, they often struggle with preserving fine-grained geometric details, especially for highly sparse point clouds. To address these limitations, we propose PointUpsampleLLM (PULLM), a novel multimodal framework that leverages the power of large language models (LLMs) to enhance 3D point cloud upsampling. PULLM integrates a pretrained Point Cloud LLM (PointLLM) with visual features extracted from point clouds, learning a unified representation that captures both geometric and semantic information. At the core of our approach is the Feature Aware Translator (FAT) module, which effectively bridges the modality gap between visual and textual features, enhancing the spatial understanding of the LLM. PULLM generates textual descriptions of point clouds on-the-fly, eliminating the need for large paired datasets. Extensive experiments on the PU1K and PUGAN benchmarks demonstrate that PULLM consistently outperforms state-of-the-art methods, achieving significant improvements in Chamfer Distance, Hausdorff Distance, and Point-to-Plane distance metrics. For instance, on the PUGAN dataset with sparse inputs, PULLM achieves a 56.15% improvement in Chamfer Distance over the best baseline. Our qualitative results further illustrate PULLM's superior ability to preserve fine details and generate high-quality upsampled point clouds across various object types and geometries.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {1223–1230},
numpages = {8},
keywords = {point cloud upsampling, large language models (LLMs), multimodal learning, feature aware translator (FAT), 3D computer vision},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3729605.3729648,
author = {Jiang, Mi and Gao, Junran and Pan, Zeyu and Wu, Yue and Wang, Zile},
title = {NexaNota: An AI-Powered Smart Linked Lecture Note-Taking System Leveraging Large Language Models},
year = {2025},
isbn = {9798400714405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3729605.3729648},
doi = {10.1145/3729605.3729648},
abstract = {Taking lecture note is an essential pedagogical method for aiding memory and understanding. Compared to unstructured lecture notes, well-structured lecture notes are highly beneficial that students would read frequently for reviewing and organizing their idea. However, it can be challenging to effectively take notes while listen to the lecturer simultaneously in a lecture, not to mention recall the whole lecture content after class. Particularly when the lecture content involves complex topics and intricates connections between topics, students feel vulnerable to review the lecture. To solve these difficulties, we design and propose an automated note-taking system, NexaNota. The system leverages the advanced Large Language Model (LLMs) to generate smart linked and structured lecture notes by constructing topics network through knowledge graphs, and providing additional web resources to complement each topic. In a within-subjects study with 17 participants (12 students and 5 experts), we found that NexaNota generates highly organized notes with 97.7% accuracy in topic identification and 86.7% accuracy in the connections between topics. Our results suggest that NexaNota enhances student learning efficiency by providing smart-linked, high-quality lecture notes.},
booktitle = {Proceedings of the 2025 International Conference on Big Data and Informatization Education},
pages = {242–248},
numpages = {7},
keywords = {AI Powered Learning, Large Language Models, Linked Note, NexaNota, Note-Taking Assistant},
location = {
},
series = {ICBDIE '25}
}

@inproceedings{10.1145/3597503.3639180,
author = {Liu, Zhe and Chen, Chunyang and Wang, Junjie and Chen, Mengzhuo and Wu, Boyu and Che, Xing and Wang, Dandan and Wang, Qing},
title = {Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI Testing via Functionality-aware Decisions},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639180},
doi = {10.1145/3597503.3639180},
abstract = {Automated Graphical User Interface (GUI) testing plays a crucial role in ensuring app quality, especially as mobile applications have become an integral part of our daily lives. Despite the growing popularity of learning-based techniques in automated GUI testing due to their ability to generate human-like interactions, they still suffer from several limitations, such as low testing coverage, inadequate generalization capabilities, and heavy reliance on training data. Inspired by the success of Large Language Models (LLMs) like ChatGPT in natural language understanding and question answering, we formulate the mobile GUI testing problem as a Q&amp;A task. We propose GPTDroid, asking LLM to chat with the mobile apps by passing the GUI page information to LLM to elicit testing scripts, and executing them to keep passing the app feedback to LLM, iterating the whole process. Within this framework, we have also introduced a functionality-aware memory prompting mechanism that equips the LLM with the ability to retain testing knowledge of the whole process and conduct long-term, functionality-based reasoning to guide exploration. We evaluate it on 93 apps from Google Play and demonstrate that it outperforms the best baseline by 32% in activity coverage, and detects 31% more bugs at a faster rate. Moreover, GPTDroid identifies 53 new bugs on Google Play, of which 35 have been confirmed and fixed.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {100},
numpages = {13},
keywords = {automated GUI testing, large language model},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@article{10.1145/3732294,
author = {Shah, Chirag and White, Ryen and Andersen, Reid and Buscher, Georg and Counts, Scott and Das, Sarkar and Montazer, Ali and Manivannan, Sathish and Neville, Jennifer and Rangan, Nagu and Safavi, Tara and Suri, Siddharth and Wan, Mengting and Wang, Leijie and Yang, Longqi},
title = {Using Large Language Models to Generate, Validate, and Apply User Intent Taxonomies},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1559-1131},
url = {https://doi.org/10.1145/3732294},
doi = {10.1145/3732294},
abstract = {Understanding user intents in information access scenarios can help us provide more relevant and personalized search results and recommendations. However, analyzing user intents is not easy, especially for emerging forms of Web search such as Artificial Intelligence (AI)-driven chat. To understand user intents from retrospective log data, we need a way to label them with meaningful categories that capture their diversity and dynamics. Existing methods rely on manual or Machine-Learned (ML) labeling, which is either expensive or inflexible for large and dynamic datasets. Large Language Models (LLMs) could generate rich and relevant concepts, descriptions, and examples for user intents using log data of user interactions. However, using LLMs to generate a user intent taxonomy and applying it for a given Information Retrieval (IR) application can be problematic for two main reasons: (1) such a taxonomy is not externally validated; and (2) there may be an undesirable feedback loop if an LLM does both these tasks without external validation. To address this, we propose a new methodology with human experts and assessors to verify the quality of the LLM-generated taxonomy. We also present an end-to-end pipeline that uses an LLM with Human-in-the-Loop (HITL) to produce, refine, and apply labels for user intent analysis in log data. We demonstrate its effectiveness by uncovering new insights into user intents from search and chat logs from the Microsoft Bing Web search engine. The novelty in this research stems from the method for generating purpose-driven user intent taxonomies with strong validation. Our approach not only helps remove methodological and practical bottlenecks from intent-focused research, but also provides a new framework for generating, validating, and applying other kinds of taxonomies in a scalable and adaptable way, with reasonable human effort.},
note = {Just Accepted},
journal = {ACM Trans. Web},
month = may,
keywords = {User intents, Large language models, Taxonomies, Log data}
}

@article{10.1145/3658137,
author = {Yao, Heyuan and Song, Zhenhua and Zhou, Yuyang and Ao, Tenglong and Chen, Baoquan and Liu, Libin},
title = {MoConVQ: Unified Physics-Based Motion Control via Scalable Discrete Representations},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3658137},
doi = {10.1145/3658137},
abstract = {In this work, we present MoConVQ, a novel unified framework for physics-based motion control leveraging scalable discrete representations. Building upon vector quantized variational autoencoders (VQ-VAE) and model-based reinforcement learning, our approach effectively learns motion embeddings from a large, unstructured dataset spanning tens of hours of motion examples. The resultant motion representation not only captures diverse motion skills but also offers a robust and intuitive interface for various applications. We demonstrate the versatility of MoConVQ through several applications: universal tracking control from various motion sources, interactive character control with latent motion representations using supervised learning, physics-based motion generation from natural language descriptions using the GPT framework, and, most interestingly, seamless integration with large language models (LLMs) with in-context learning to tackle complex and abstract tasks.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {144},
numpages = {21},
keywords = {motion control, deep reinforcement learning, generative model, VQ-VAE, large language model}
}

@inproceedings{10.1145/3640457.3688161,
author = {Wang, Jianling and Lu, Haokai and Liu, Yifan and Ma, He and Wang, Yueqi and Gu, Yang and Zhang, Shuzhou and Han, Ningren and Bi, Shuchao and Baugher, Lexi and Chi, Ed H. and Chen, Minmin},
title = {LLMs for User Interest Exploration in Large-scale Recommendation Systems},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688161},
doi = {10.1145/3640457.3688161},
abstract = {Traditional recommendation systems are subject to a strong feedback loop by learning from and reinforcing past user-item interactions, which in turn limits the discovery of novel user interests. To address this, we introduce a hybrid hierarchical framework combining Large Language Models (LLMs) and classic recommendation models for user interest exploration. The framework controls the interfacing between the LLMs and the classic recommendation models through “interest clusters”, the granularity of which can be explicitly determined by algorithm designers. It recommends the next novel interests by first representing “interest clusters” using language, and employs a fine-tuned LLM to generate novel interest descriptions that are strictly within these predefined clusters. At the low level, it grounds these generated interests to an item-level policy by restricting classic recommendation models, in this case a transformer-based sequence recommender to return items that fall within the novel clusters generated at the high level. We showcase the efficacy of this approach on an industrial-scale commercial platform serving billions of users. Live experiments show a significant increase in both exploration of novel interests and overall user enjoyment of the platform.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {872–877},
numpages = {6},
keywords = {Large Language Models, Recommendation System, User Interest Exploration},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3641554.3701959,
author = {Wu, Ylesia and Zheng, Qirui and Lau, Sam},
title = {How Novices Use Program Visualizations to Understand Code that Manipulates Data Tables},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701959},
doi = {10.1145/3641554.3701959},
abstract = {As data science and artificial intelligence continue to impact society, more and more people are learning how to manipulate data with code. To support these learners, program visualization tools automatically generate diagrams to show how code transforms data, in contrast to tools based on large language models (LLMs) that primarily focus on textual explanations. Although program visualization tools are popular among instructors, do novices find these tools usable and useful for data science programs that often manipulate datasets with many rows? To address this, we evaluate a popular, publicly available tool that generates diagrams for Python pandas code through a randomized, in-lab usability study with 17 data science novices. Despite minimal instruction on how to use the tool, novices found that program visualizations increased their confidence in comprehending and debugging code. In addition, even though the tool sometimes produced diagrams with many visual elements, participant performance on the study tasks was not negatively impacted. These findings suggest design guidelines for program visualization tools to help manage cognitive load for data science novices. To our knowledge, this is the first empirical study that investigates how novices use program visualization tools to understand code that manipulates data tables, and suggests a future where novices can use automatically generated diagrams as a complement to LLM tools for effectively understanding unfamiliar programs in data science.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1267–1273},
numpages = {7},
keywords = {data science education, novice programmers, program visualization tools},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649158.3657032,
author = {Rubio-Medrano, Carlos E. and Kotak, Akash and Wang, Wenlu and Sohr, Karsten},
title = {Pairing Human and Artificial Intelligence: Enforcing Access Control Policies with LLMs and Formal Specifications},
year = {2024},
isbn = {9798400704918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649158.3657032},
doi = {10.1145/3649158.3657032},
abstract = {Large Language Models (LLMs), such as ChatGPT and Google Bard, have performed interestingly well when assisting developers on computer programming tasks, a.k.a., coding, thus potentially resulting in convenient and faster software constructions. This new approach significantly enhances efficiency but also presents challenges in unsupervised code construction with limited security guarantees. LLMs excel in producing code with accurate grammar, yet they are not specifically trained to guarantee the security of the code. In this paper, we provide an initial exploration into using formal software specifications as a starting point for software construction, allowing developers to translate descriptions of security-related behavior into natural language instructions for LLMs, a.k.a., prompts. In addition, we leveraged automated verification tools to evaluate the code produced against the aforementioned specifications , following a modular, step-by-step software construction process. For our study, we leveraged Role-based Access Control (RBAC), a mature security model, and the Java Modeling Language (JML), a behavioral specification language for Java. We test our approach on different publicly-available LLMs, namely, OpenAI ChatGPT 4.0, Google Bard, and Microsoft CoPilot. We provide a description of two applications-a security-sensitive Banking application employing RBAC and an RBAC API module itself-, the corresponding JML specifications, as well as a description of the prompts, the generated code, the verification results, as well as a series of interesting insights for practitioners interested in further exploring the use of LLMs for securely constructing applications.},
booktitle = {Proceedings of the 29th ACM Symposium on Access Control Models and Technologies},
pages = {105–116},
numpages = {12},
keywords = {chatgpt, formal specifications, large language models, prompt engineering, software construction. java modeling language},
location = {San Antonio, TX, USA},
series = {SACMAT 2024}
}

@inproceedings{10.1145/3613904.3642497,
author = {Gu, Ken and Shang, Ruoxi and Althoff, Tim and Wang, Chenglong and Drucker, Steven M.},
title = {How Do Analysts Understand and Verify AI-Assisted Data Analyses?},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642497},
doi = {10.1145/3613904.3642497},
abstract = {Data analysis is challenging as it requires synthesizing domain knowledge, statistical expertise, and programming skills. Assistants powered by large language models (LLMs), such as ChatGPT, can assist analysts by translating natural language instructions into code. However, AI-assistant responses and analysis code can be misaligned with the analyst’s intent or be seemingly correct but lead to incorrect conclusions. Therefore, validating AI assistance is crucial and challenging. Here, we explore how analysts understand and verify the correctness of AI-generated analyses. To observe analysts in diverse verification approaches, we develop a design probe equipped with natural language explanations, code, visualizations, and interactive data tables with common data operations. Through a qualitative user study (n=22) using this probe, we uncover common behaviors within verification workflows and how analysts’ programming, analysis, and tool backgrounds reflect these behaviors. Additionally, we provide recommendations for analysts and highlight opportunities for designers to improve future AI-assistant experiences.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {748},
numpages = {22},
keywords = {Auto Data Science, Copilot, Data Science Assistant, Design Probe, Explainable AI, Human-AI Interaction, Human-AI Verification},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3637528.3671656,
author = {Xu, Yunqi and Cai, Tianchi and Jiang, Jiyan and Song, Xierui},
title = {Face4Rag: Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671656},
doi = {10.1145/3637528.3671656},
abstract = {The prevailing issue of factual inconsistency errors in conventional Retrieval Augmented Generation (RAG) motivates the study of Factual Consistency Evaluation (FCE). Despite the various FCE methods proposed earlier, these methods are evaluated on datasets generated by specific Large Language Models (LLMs). Without a comprehensive benchmark, it remains unexplored how these FCE methods perform on other LLMs with different error distributions or even unseen error types, as these methods may fail to detect the error types generated by other LLMs. To fill this gap, in this paper, we propose the first comprehensive FCE benchmark Face4RAG for RAG independent of the underlying LLM. Our benchmark consists of a synthetic dataset built upon a carefully designed typology for factuality inconsistency error and a real-world dataset constructed from six commonly used LLMs, enabling evaluation of FCE methods on specific error types or real-world error distributions. On the proposed benchmark, we discover the failure of existing FCE methods to detect the logical fallacy, which refers to a mismatch of logic structures between the answer and the retrieved reference. To fix this issue, we further propose a new method called L-Face4RAG with two novel designs of logic-preserving answer decomposition and fact-logic FCE. Extensive experiments show L-Face4RAG substantially outperforms previous methods for factual inconsistency detection on a wide range of tasks, notably beyond the RAG task from which it is originally motivated. Both the benchmark and our proposed method are publicly available. https://huggingface.co/datasets/yq27/Face4RAG},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6083–6094},
numpages = {12},
keywords = {factual consistency evaluation, large language model},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3637528.3671486,
author = {Tabari, Narges and Deshmukh, Aniket Anand and Kang, Wang-Cheng and Zamani, Hamed and Gangadharaiah, Rashmi and McAuley, Julian and Karypis, George},
title = {First Workshop on Generative AI for Recommender Systems and Personalization},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671486},
doi = {10.1145/3637528.3671486},
abstract = {Personalization is key in understanding user behavior and has been a main focus in the fields of knowledge discovery and information retrieval. Building personalized recommender systems is especially important now due to the vast amount of user-generated textual content, which offers deep insights into user preferences. The recent advancements in Large Language Models (LLMs) have significantly impacted research areas, mainly in Natural Language Processing and Knowledge Discovery, giving these models the ability to handle complex tasks and learn context. However, the use of generative models and user-generated text for personalized systems and recommendation is relatively new and has shown some promising results. This workshop is designed to bridge the research gap in these fields and explore personalized applications and recommender systems. We aim to fully leverage generative models to develop AI systems that are not only accurate but also focused on meeting individual user needs. Building upon the momentum of previous successful forums, this workshop seeks to engage a diverse audience from academia and industry, fostering a dialogue that incorporates fresh insights and anticipates over 50 attendees, including key stakeholders in the field.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6737–6738},
numpages = {2},
keywords = {artificial intelligence, generative ai, personalization, recommendation},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3613904.3642016,
author = {Arawjo, Ian and Swoopes, Chelse and Vaithilingam, Priyan and Wattenberg, Martin and Glassman, Elena L.},
title = {ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642016},
doi = {10.1145/3613904.3642016},
abstract = {Evaluating outputs of large language models (LLMs) is challenging, requiring making—and making sense of—many responses. Yet tools that go beyond basic prompting tend to require knowledge of programming APIs, focus on narrow domains, or are closed-source. We present ChainForge, an open-source visual toolkit for prompt engineering and on-demand hypothesis testing of text generation LLMs. ChainForge provides a graphical interface for comparison of responses across models and prompt variations. Our system was designed to support three tasks: model selection, prompt template design, and hypothesis testing (e.g., auditing). We released ChainForge early in its development and iterated on its design with academics and online users. Through in-lab and interview studies, we find that a range of people could use ChainForge to investigate hypotheses that matter to them, including in real-world settings. We identify three modes of prompt engineering and LLM hypothesis testing: opportunistic exploration, limited evaluation, and iterative refinement.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {304},
numpages = {18},
keywords = {auditing, language models, prompt engineering, toolkits, visual programming environments},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3632621.3671424,
author = {Mozgovoy, Maxim and Suero Montero, Calkin},
title = {Exploring Students Solutions to Concurrent and Parallel Programming Exercises – Impact of Generative AI},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671424},
doi = {10.1145/3632621.3671424},
abstract = {Background. Concurrent and parallel programming is difficult to teach and learn as the understanding of complex and abstract concepts such as nondeterminism, semaphore, and rare conditions, among others, is required [1, 2, 9], having as a core issue the synchronisation of processes to achieve a common goal [4]. It is well-acknowledged that concurrent and parallel programming skills are fundamental since, nowadays, computing is increasingly handled in a parallel manner [7].Problem and Motivation. Therefore, identifying students’ pitfalls and successes when solving practical concurrent and parallel programming exercises could shed light on the best approaches and strategies that they use [3]. In addition, the advent of large language models, and generative AI applications such as ChatGPT, has prompted intensive research on their use in several areas including programming teaching and learning [8]. Yet, the studies in the literature have focused on issues related to learning to program by novice students in introductory courses (e.g., CS1, CS2) [6]. Less work, however, has been presented on the impact of generative AI tools in advanced programming practices such as concurrent and parallel programming.Methodology. To investigate whether generative AI has had an impact on the submitted concurrent and parallel programming exercises solutions at the University of Aizu, Japan, we performed a comparison analysis of the students’ submissions over 2020–2023. The analysis included five different exercises covering the basis of concurrency through various tasks and scenarios where the implementation of parallel processes is needed as solution. For instance, exercises 2.3 and 2.4 required to create parallel processes and perform independent computations; exercises 3.2 and 3.3, required synchronisation of the parallel processes; and in exercise 3.5 a code template was given for modification. We analysed the submissions of 72 undergraduate 3rd year students (avg. 18 students/year) and labelled the solutions using the following nomenclature: OK, indicating a good solution; OKFeat, a good solution but with unusual features; AdvLib, use of unnecessary advanced library or functionality; BadTool, use of an inappropriate tool when the task definition explicitly required a different tool; CodeErr, general coding error; SyncErr, concurrent programming specific error; N/A, solution not submitted or incomplete.Results and Analysis. Results show a substantial increase in the incidence of use of advance libraries (AdvLib) and the wrong tools (BadTool) among students in 2023 for three out of the five analysed exercises. At the same time the concurrency programming-specific errors (SyncErr) also see a reduction in all the exercises. (Figure 1). This coincides with the availability of generative AI tools such as ChatGPT [5], which warrants further investigations to understand how students, teachers and instructors could harness the affordances of large language models in their concurrent programming learning, teaching, and practice.Contribution and Impact. This paper presents an initial step towards investigating the impact of generative AI on advanced programming topics. This research will continue to uncover strategies for the lecturers and instructors to identify the affordances and use of generative AI and to design exercises that harness these affordances to support students learning of difficult programming concepts.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {533–534},
numpages = {2},
keywords = {Evaluation of students’ exercises, Large language models in advanced programming},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3696410.3714595,
author = {Qiao, Tingrui and Walker, Caroline and Cunningham, Chris and Koh, Yun Sing},
title = {Thematic-LM: A LLM-based Multi-agent System for Large-scale Thematic Analysis},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714595},
doi = {10.1145/3696410.3714595},
abstract = {Thematic analysis (TA) is a widely used qualitative method for identifying underlying meanings within unstructured text. However, TA requires manual processes, which become increasingly labour-intensive and time-consuming as datasets grow. While large language models (LLMs) have been introduced to assist with TA on small-scale datasets, three key limitations hinder their effectiveness. First, current approaches often depend on interactions between an LLM agent and a human coder, a process that becomes challenging with larger datasets. Second, with feedback from the human coder, the LLM tends to mirror the human coder, which provides a narrower viewpoint of the data. Third, existing methods follow a sequential process, where codes are generated for individual samples without recalling previous codes and associated data, reducing the ability to analyse data holistically. To address these limitations, we propose Thematic-LM, an LLM-based multi-agent system for large-scale computational thematic analysis. Thematic-LM assigns specialised tasks to each agent, such as coding, aggregating codes, and maintaining and updating the codebook. We assign coder agents different identity perspectives to simulate the subjective nature of TA, fostering a more diverse interpretation of the data. We applied Thematic-LM to the Dreaddit dataset and the Reddit climate change dataset to analyse themes related to social media stress and online opinions on climate change. We evaluate the resulting themes based on trustworthiness principles in qualitative research. Our study reveals insights such as assigning different identities to coder agents promotes divergence in codes and themes.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {649–658},
numpages = {10},
keywords = {computational social science, large language model, multi-agent system, thematic analysis},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.14778/3685800.3685868,
author = {Wang, Mengzhao and Wu, Haotian and Ke, Xiangyu and Gao, Yunjun and Xu, Xiaoliang and Chen, Lu},
title = {An Interactive Multi-Modal Query Answering System with Retrieval-Augmented Large Language Models},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685868},
doi = {10.14778/3685800.3685868},
abstract = {Retrieval-augmented Large Language Models (LLMs) have reshaped traditional query-answering systems, offering unparalleled user experiences. However, existing retrieval techniques often struggle to handle multi-modal query contexts. In this paper, we present an interactive Multi-modal Query Answering (MQA) system, empowered by our newly developed multi-modal retrieval framework and navigation graph index, integrated with cutting-edge LLMs. It comprises five core components: Data Preprocessing, Vector Representation, Index Construction, Query Execution, and Answer Generation, all orchestrated by a dedicated coordinator to ensure smooth data flow from input to answer generation. One notable aspect of MQA is its utilization of contrastive learning to assess the significance of different modalities, facilitating precise measurement of multimodal information similarity. Furthermore, the system achieves efficient retrieval through our advanced navigation graph index, refined using computational pruning techniques. Another highlight of our system is its pluggable processing framework, allowing seamless integration of embedding models, graph indexes, and LLMs. This flexibility provides users diverse options for gaining insights from their multi-modal knowledge base. A preliminary video introduction of MQA is available at https://youtu.be/xvUuo2ZIqWk.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4333–4336},
numpages = {4}
}

@inproceedings{10.1145/3627673.3680025,
author = {Huang, Jia-Hong and Yang, Chao-Chun and Shen, Yixian and Pacces, Alessio M. and Kanoulas, Evangelos},
title = {Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680025},
doi = {10.1145/3627673.3680025},
abstract = {The legal landscape encompasses a wide array of lawsuit types, presenting lawyers with challenges in delivering timely and accurate information to clients, particularly concerning critical aspects like potential imprisonment duration or financial repercussions. Compounded by the scarcity of legal experts, there's an urgent need to enhance the efficiency of traditional legal workflows. Recent advances in deep learning, especially Large Language Models (LLMs), offer promising solutions to this challenge. Leveraging LLMs' mathematical reasoning capabilities, we propose a novel approach integrating LLM-based methodologies with specially designed prompts to address precision requirements in legal Artificial Intelligence (LegalAI) applications. The proposed work seeks to bridge the gap between traditional legal practices and modern technological advancements, paving the way for a more accessible, efficient, and equitable legal system. To validate this method, we introduce a curated dataset tailored to precision-oriented LegalAI tasks, serving as a benchmark for evaluating LLM-based approaches. Extensive experimentation confirms the efficacy of our methodology in generating accurate numerical estimates within the legal domain, emphasizing the role of LLMs in streamlining legal processes and meeting the evolving demands of LegalAI. Github: https://github.com/Jhhuangkay/Optimizing-Numerical-Estimation-and-Operational-Efficiency-in-the-Legal-Domain.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4554–4562},
numpages = {9},
keywords = {large language models, precision-oriented legal artificial intelligence, tailored prompt design},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3636243.3636263,
author = {Feng, Tony Haoran and Denny, Paul and Wuensche, Burkhard and Luxton-Reilly, Andrew and Hooper, Steffan},
title = {More Than Meets the AI: Evaluating the performance of GPT-4 on Computer Graphics assessment questions},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636263},
doi = {10.1145/3636243.3636263},
abstract = {Recent studies have showcased the exceptional performance of LLMs (Large Language Models) on assessment questions across various discipline areas. This can be helpful if used to support the learning process, for example by enabling students to quickly generate and contrast alternative solution approaches. However, concerns about student over-reliance and inappropriate use of LLMs in education are common. Understanding the capabilities of LLMs is essential for instructors to make informed decisions on question choices for learning and assessment tasks. In CS (Computer Science), previous evaluations of LLMs have focused on CS1 and CS2 questions, and little is known about how well LLMs perform for assessment questions in upper-level CS courses such as CG (Computer Graphics), which covers a wide variety of concepts and question types. To address this gap, we compiled a dataset of past assessment questions used in a final-year undergraduate course about introductory CG, and evaluated the performance of GPT-4 on this dataset. We also classified assessment questions and evaluated the performance of GPT-4 for different types of questions. We found that the performance tended to be best for simple mathematical questions, and worst for questions requiring creative thinking, and those with complex descriptions and/or images. We share our benchmark dataset with the community and provide new insights into the capabilities of GPT-4 in the context of CG courses. We highlight opportunities for teaching staff to improve student learning by guiding the use of LLMs for CG questions, and inform decisions around question choices for assessment tasks.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {182–191},
numpages = {10},
keywords = {Artificial Intelligence, Assessment, Computer Graphics, Computing Education, Evaluation, GPT-4, Large Language Models},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3686852.3686887,
author = {Chhetri, Chola},
title = {Exploring Large Language Model-Powered Pedagogical Approaches to Cybersecurity Education},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3686887},
doi = {10.1145/3686852.3686887},
abstract = {The adoption of artificial intelligence (AI) technologies by businesses and corporations is rising. AI technologies continue to be adopted in cybersecurity for both defensive and offensive strategies. However, threat actors also persist in utilizing these technologies to enhance the speed, accuracy, and sophistication of their attacks. Hence, it is essential to train the next generation of cybersecurity learners not only on how to use AI technology but also on how to leverage these technologies to enhance the efficiency of their work. This extended abstract describes our exploratory work on the use of generative AI-based pedagogical approaches in cybersecurity education. This extended abstract will describe some preliminary findings on large language model-powered pedagogical approaches to cybersecurity education and training. These approaches will help cybersecurity educators enhance their teaching methods to equip learners with the essential skills needed to succeed in the dynamic field of cybersecurity.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {163–166},
numpages = {4},
keywords = {AI, Artificial intelligence, GenAI, LLM, cybersecurity, education., generative AI, large language models},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3613905.3648656,
author = {Zhou, Zhongyi and Jin, Jing and Phadnis, Vrushank and Yuan, Xiuxiu and Jiang, Jun and Qian, Xun and Zhou, Jingtao and Huang, Yiyi and Xu, Zheng and Zhang, Yinda and Wright, Kristen and Mayes, Jason and Sherwood, Mark and Lee, Johnny and Olwal, Alex and Kim, David and Iyengar, Ram and Li, Na and Du, Ruofei},
title = {Experiencing InstructPipe: Building Multi-modal AI Pipelines via Prompting LLMs and Visual Programming},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3648656},
doi = {10.1145/3613905.3648656},
abstract = {Foundational multi-modal models have democratized AI access, yet the construction of complex, customizable machine learning pipelines by novice users remains a grand challenge. This paper demonstrates a visual programming system that allows novices to rapidly prototype multimodal AI pipelines. We first conducted a formative study with 58 contributors and collected 236 proposals of multimodal AI pipelines that served various practical needs. We then distilled our findings into a design matrix of primitive nodes for prototyping multimodal AI visual programming pipelines, and implemented a system with 65 nodes. To support users’ rapid prototyping experience, we built InstructPipe, an AI assistant based on large language models (LLMs) that allows users to generate a pipeline by writing text-based instructions. We believe InstructPipe enhances novice users onboarding experience of visual programming and the controllability of LLMs by offering non-experts a platform to easily update the generation.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {402},
numpages = {5},
keywords = {Deep Learning, Deep Neural Networks, Graph Compiler, Large Language Models, Low-code Development, Node-graph Editor, Visual Analytics, Visual Programming, Visual Prototyping},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3636243.3636249,
author = {Sheese, Brad and Liffiton, Mark and Savelka, Jaromir and Denny, Paul},
title = {Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636249},
doi = {10.1145/3636243.3636249},
abstract = {Providing personalized assistance at scale is a long-standing challenge for computing educators, but a new generation of tools powered by large language models (LLMs) offers immense promise. Such tools can, in theory, provide on-demand help in large class settings and be configured with appropriate guardrails to prevent misuse and mitigate common concerns around learner over-reliance. However, the deployment of LLM-powered tools in authentic classroom settings is still rare, and very little is currently known about how students will use them in practice and what type of help they will seek. To address this, we examine students’ use of an innovative LLM-powered tool that provides on-demand programming assistance without revealing solutions directly. We deployed the tool for 12 weeks in an introductory computer and data science course&nbsp;(n = 52), collecting more than 2,500 queries submitted by students throughout the term. We manually categorized all student queries based on the type of assistance sought, and we automatically analyzed several additional query characteristics. We found that most queries requested immediate help with programming assignments, whereas fewer requests asked for help on related concepts or for deepening conceptual understanding. Furthermore, students often provided minimal information to the tool, suggesting this is an area in which targeted instruction would be beneficial. We also found that students who achieved more success in the course tended to have used the tool more frequently overall. Lessons from this research can be leveraged by programming educators and institutions who plan to augment their teaching with emerging LLM-powered tools.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {49–57},
numpages = {9},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@article{10.1145/3729421,
author = {Lai, Hanyu and Liu, Xiao and Yu, Hao and Xu, Yifan and Iong, Iat Long and Yao, Shuntian and Zeng, Aohan and Du, Zhengxiao and Dong, Yuxiao and Tang, Jie},
title = {WebGLM: Towards an Efficient and Reliable Web-Enhanced Question Answering System},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3729421},
doi = {10.1145/3729421},
abstract = {We present WebGLM, an enhanced LLM-based retrieval question-answering system based on the ChatGLM3-6B, offering significant improvements over previous systems. We aim to augment a pre-trained large language model (LLM) with web search and reliable retrieval capabilities while being efficient for real-world deployments. Leveraging LLM’s in-context learning ability and a robust filter strategy, we create a high-quality training dataset and address the hallucination issue with a self-check mechanism. Our base model, ChatGLM3-6B, excels in extracting critical information and generating desired responses. We tackle the decline in retrieval effectiveness for complex queries with a keywording technique and incorporate more web content for references. We align with user preferences by training a human preference-aware scorer and employing DPO training for direct alignment. Extensive experiments, including human evaluations and the Turing test, demonstrate WebGLM’s superior performance against leading web-enhanced question-answering systems, significantly enhancing performance and efficiency. The code, demo, and data are at .},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = apr,
keywords = {Large Language Model, Pre-Trained Model, Reliable Retrieval, RL from Human Feedback}
}

@inproceedings{10.1145/3691620.3695267,
author = {Liu, Lei and Hasegawa, So and Sampat, Shailaja Keyur and Xenochristou, Maria and Chen, Wei-Peng and Kato, Takashi and Kakibuchi, Taisei and Asai, Tatsuya},
title = {AutoDW: Automatic Data Wrangling Leveraging Large Language Models},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695267},
doi = {10.1145/3691620.3695267},
abstract = {Data wrangling is a critical yet often labor-intensive process, essential for transforming raw data into formats suitable for downstream tasks such as machine learning or data analysis. Traditional data wrangling methods can be time-consuming, resource-intensive, and prone to errors, limiting the efficiency and effectiveness of subsequent downstream tasks. In this paper, we introduce AutoDW: an end-to-end solution for automatic data wrangling that leverages the power of Large Language Models (LLMs) to enhance automation and intelligence in data preparation. AutoDW distinguishes itself through several innovative features, including comprehensive automation that minimizes human intervention, the integration of LLMs to enable advanced data processing capabilities, and the generation of source code for the entire wrangling process, ensuring transparency and reproducibility. These advancements position AuoDW as a superior alternative to existing data wrangling tools, offering significant improvements in efficiency, accuracy, and flexibility. Through detailed performance evaluations, we demonstrate the effectiveness of AutoDW for data wrangling. We also discuss our experience and lessons learned from the industrial deployment of AutoDW, showcasing its potential to transform the landscape of automated data preparation.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2041–2052},
numpages = {12},
keywords = {data wrangling, machine learning, large language models},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3649921.3650013,
author = {Bateni, Bahar and Whitehead, Jim},
title = {Language-Driven Play: Large Language Models as Game-Playing Agents in Slay the Spire},
year = {2024},
isbn = {9798400709555},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649921.3650013},
doi = {10.1145/3649921.3650013},
abstract = {One of the major challenges in procedural generation of game rules is evaluating the generated content. Since the effect of a rule on game balance and complexity might not be immediately apparent, one way to evaluate such a content is to simulate the gameplay. To achieve this, it is necessary to create an agent capable of both playing the game and adjusting to alterations in the game’s design, which is often referred to as a general game-playing agent. In this paper, we study the ability of Large Language Models (LLMs) in performing this task. Our focus centers on a simplified implementation of the card game Slay the Spire, in which the rules support a wide variety of interesting and complex interactions between the cards. We analyze the performance of LLMs in understanding the cards and their synergies based solely on their description. The performance of the LLM agent is evaluated against alternative game-playing agents across diverse scenarios. Our findings reveal that although the LLM agent may not be optimized for finding the best move, it exhibits superior long-term planning without necessitating specialized training.},
booktitle = {Proceedings of the 19th International Conference on the Foundations of Digital Games},
articleno = {20},
numpages = {10},
keywords = {General Game-playing, Large Language Models, Procedural Content Generation, Rule Generation},
location = {Worcester, MA, USA},
series = {FDG '24}
}

@inproceedings{10.1145/3663533.3664042,
author = {Acharya, Jagrit and Ginde, Gouri},
title = {Graph Neural Network vs. Large Language Model: A Comparative Analysis for Bug Report Priority and Severity Prediction},
year = {2024},
isbn = {9798400706752},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663533.3664042},
doi = {10.1145/3663533.3664042},
abstract = {A vast number of incoming bug reports demand effective methods to identify priority and severity for bug triaging. With increased technological advancement, machine learning and deep learning have been extensively examined to address this problem. Although Large Language Models (LLMs) such as Fine-tuned BERT (early generation LLM) have proven to capture context in the underlying textual data, severity and priority prediction demand additional features for understanding the relationships with other bug reports. This work utilizes the graph-based approach to model the bug reports and their other attributes, such as component, product and bug type information. It utilizes the relational intelligence of Graph Neural Network (GNN) to address the prioritization and severity assessment of bug reports in the Bugzilla bug tracking system. Initial tests on the Mozilla project dataset indicate that a project-wise predictive approach using GNNs yields higher accuracy in determining the priority and severity of bug reports compared to LLMs across multiple Mozilla projects, contributing to a notable advancement in the automation of bug severity and priority prediction tasks. Specifically, GNNs demonstrated a remarkable improvement over LLMs, increasing the priority prediction accuracy by 37% &amp; 30% and severity prediction accuracy by 43% &amp; 30% for Core and Firefox projects, respectively. Overall, GNN outperformed the Fine-tuned BERT (LLM) in predicting priority and severity for all the Mozilla projects.},
booktitle = {Proceedings of the 20th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {2–11},
numpages = {10},
keywords = {BERT, Graph Neural Networks, Large Language Model, Natural Language Processing, Requirement Engineering},
location = {Porto de Galinhas, Brazil},
series = {PROMISE 2024}
}

@article{10.1145/3716848,
author = {Fu, Yujia and Liang, Peng and Tahir, Amjed and Li, Zengyang and Shahin, Mojtaba and Yu, Jiaxin and Chen, Jinfu},
title = {Security Weaknesses of Copilot-Generated Code in GitHub Projects: An Empirical Study},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3716848},
doi = {10.1145/3716848},
abstract = {Modern code generation tools utilizing AI models like Large Language Models (LLMs) have gained increased popularity due to their ability to produce functional code. However, their usage presents security challenges, often resulting in insecure code merging into the code base. Thus, evaluating the quality of generated code, especially its security, is crucial. While prior research explored various aspects of code generation, the focus on security has been limited, mostly examining code produced in controlled environments rather than open source development scenarios. To address this gap, we conducted an empirical study, analyzing code snippets generated by GitHub Copilot and two other AI code generation tools (i.e., CodeWhisperer and Codeium) from GitHub projects. Our analysis identified 733 snippets, revealing a high likelihood of security weaknesses, with 29.5% of Python and 24.2% of JavaScript snippets affected. These issues span 43 Common Weakness Enumeration (CWE) categories, including significant ones like CWE-330: Use of Insufficiently Random Values, CWE-94: Improper Control of Generation of Code, and CWE-79: Cross-site Scripting. Notably, eight of those CWEs are among the 2023 CWE Top-25, highlighting their severity. We further examined using Copilot Chat to fix security issues in Copilot-generated code by providing Copilot Chat with warning messages from the static analysis tools, and up to 55.5% of the security issues can be fixed. We finally provide the suggestions for mitigating security issues in generated code.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {Code Generation, Security Weakness, CWE, GitHub Copilot, GitHub Project}
}

@article{10.1145/3674838,
author = {Wang, Yue and Fu, Tianfan and Xu, Yinlong and Ma, Zihan and Xu, Hongxia and Du, Bang and Lu, Yingzhou and Gao, Honghao and Wu, Jian and Chen, Jintai},
title = {TWIN-GPT: Digital Twins for Clinical Trials via Large Language Model},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3674838},
doi = {10.1145/3674838},
abstract = {Clinical trials are indispensable for medical research and the development of new treatments. However, clinical trials often involve thousands of participants and can span several years to complete, with a high probability of failure during the process. Recently, there has been a burgeoning interest in virtual clinical trials, which simulate real-world scenarios and hold the potential to significantly enhance patient safety, expedite development, reduce costs, and contribute to the broader scientific knowledge in healthcare. Existing research often focuses on leveraging electronic health records (EHRs) to support clinical trial outcome prediction. Yet, trained with limited clinical trial outcome data, existing approaches frequently struggle to perform accurate predictions. Some research has attempted to generate EHRs to augment model development but has fallen short in personalizing the generation for individual patient profiles. Recently, the emergence of large language models has illuminated new possibilities, as their embedded comprehensive clinical knowledge has proven beneficial in addressing medical issues. In this paper, we propose a large language model-based digital twin creation approach, called TWIN-GPT. TWIN-GPT can establish cross-dataset associations of medical information given limited data, generating unique personalized digital twins for different patients, thereby preserving individual patient characteristics. Comprehensive experiments show that using digital twins created by TWIN-GPT can boost the clinical trial outcome prediction, exceeding various previous prediction approaches. Besides, we also demonstrate that TWIN-GPT can generate high-fidelity trial data that closely approximates specific patients, aiding in more accurate result predictions in data-scarce situations. Moreover, our study provides practical evidence for the application of digital twins in healthcare, highlighting its potential significance.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = jul,
keywords = {Clinical Trial, Electronic Health Record, EHR, Digital Twin, Large Language Model}
}

@inproceedings{10.1145/3640543.3645196,
author = {Xu, Xiaotong (Tone) and Yin, Jiayu and Gu, Catherine and Mar, Jenny and Zhang, Sydney and E, Jane L. and Dow, Steven P.},
title = {Jamplate: Exploring LLM-Enhanced Templates for Idea Reflection},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645196},
doi = {10.1145/3640543.3645196},
abstract = {Advances in AI, particularly large language models (LLMs), can transform creative work. When developing a new idea, LLMs can help designers gather information, find competitors, and generate alternatives. However, LLM responses tend to be long-winded or contain inaccuracies, placing a burden on users to carefully synthesize information. In our formative studies with 52 students and five instructors, we find that novice designers typically lack guidance on how to compose prompts, reflect critically on LLM responses, and extract key information to help shape an idea. Building on these insights, we explore an alternative approach for interacting with LLMs, not via chat, but rather through structured templates. Collaborative design templates are a well-established strategy for helping novices think, organize information, and reflect on creative work. Developed as a digital whiteboard plugin, Jamplate integrates LLM capabilities into design templates, streamlining the collection and organization of user-generated content and LLM responses within the template structure. In a preliminary study with 8 novice designers, participants expressed that Jamplate’s reflective questions and in-situ guidance improved their ability to think critically and improve ideas more effectively. We discuss the potential of designing LLM-enhanced templates to instigate critical reflection.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {907–921},
numpages = {15},
keywords = {LLM interaction, design process, design template, large language model interaction},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@inproceedings{10.1145/3643834.3660729,
author = {Shin, Joongi and Hedderich, Michael A. and Rey, Bart\l{}omiej Jakub and Lucero, Andr\'{e}s and Oulasvirta, Antti},
title = {Understanding Human-AI Workflows for Generating Personas},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3660729},
doi = {10.1145/3643834.3660729},
abstract = {One barrier to deeper adoption of user-research methods is the amount of labor required to create high-quality representations of collected data. Trained user researchers need to analyze datasets and produce informative summaries pertaining to the original data. While Large Language Models (LLMs) could assist in generating summaries, they are known to hallucinate and produce biased responses. In this paper, we study human–AI workflows that differently delegate subtasks in user research between human experts and LLMs. Studying persona generation as our case, we found that LLMs are not good at capturing key characteristics of user data on their own. Better results are achieved when we leverage human skill in grouping user data by their key characteristics and exploit LLMs for summarizing pre-grouped data into personas. Personas generated via this collaborative approach can be more representative and empathy-evoking than ones generated by human experts or LLMs alone. We also found that LLMs could mimic generated personas and enable interaction with personas, thereby helping user researchers empathize with them. We conclude that LLMs, by facilitating the analysis of user data, may promote widespread application of qualitative methods in user research.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {757–781},
numpages = {25},
keywords = {LLM, User research, persona generation},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3639631.3639658,
author = {Wang, Yiheng},
title = {Large Language Models Evaluate Machine Translation via Polishing},
year = {2024},
isbn = {9798400709203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639631.3639658},
doi = {10.1145/3639631.3639658},
abstract = {Quality of machine translation is usually evaluated by automatic reference-based metrics. However, these conventional metrics have limited correlation with human evaluation and require references for comparison. Human evaluation is considered the most reliable, but it is still plagued by high costs and uncertainties among annotators. With the emergence of large language models (LLMs) and their impressive capabilities, some studies have utilized LLMs for the evaluation of natural language generation. In this paper, we propose EvLP (Evaluation via LLMs Polishing), a reference-free machine translation evaluation method inspired by post-editing that leverages LLMs. We select gpt-3.5-turbo to act as annotators to polish the translated text. Our experiments compare EvLP with other LLM-based evaluation methods and SEG_LM, a representative reference-free metric utilizing cross-lingual pre-trained language models to evaluate machine translation. We select a dataset with two kinds of human evaluation, direct assessment and post-editing. The results of experiments demonstrate that EvLP closely aligns with human evaluation compared to other LLM-based metrics, outperforming SEG_LM on direct assessment and exhibiting a significant advantage in post-editing. We also discuss the bias that LLMs hold towards LLM-generated texts.},
booktitle = {Proceedings of the 2023 6th International Conference on Algorithms, Computing and Artificial Intelligence},
pages = {158–163},
numpages = {6},
keywords = {large language models, machine translation, reference-free evaluation},
location = {Sanya, China},
series = {ACAI '23}
}

@inproceedings{10.1145/3640457.3688123,
author = {Penha, Gustavo and Vardasbi, Ali and Palumbo, Enrico and De Nadai, Marco and Bouchard, Hugues},
title = {Bridging Search and Recommendation in Generative Retrieval: Does One Task Help the Other?},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688123},
doi = {10.1145/3640457.3688123},
abstract = {Generative retrieval for search and recommendation is a promising paradigm for retrieving items, offering an alternative to traditional methods that depend on external indexes and nearest-neighbor searches. Instead, generative models directly associate inputs with item IDs. Given the breakthroughs of Large Language Models (LLMs), these generative systems can play a crucial role in centralizing a variety of Information Retrieval (IR) tasks in a single model that performs tasks such as query understanding, retrieval, recommendation, explanation, re-ranking, and response generation. Despite the growing interest in such a unified generative approach for IR systems, the advantages of using a single, multi-task model over multiple specialized models are not well established in the literature. This paper investigates whether and when such a unified approach can outperform task-specific models in the IR tasks of search and recommendation, broadly co-existing in multiple industrial online platforms, such as Spotify, YouTube, and Netflix. Previous work shows that (1) the latent representations of items learned by generative recommenders are biased towards popularity, and (2) content-based and collaborative-filtering-based information can improve an item’s representations. Motivated by this, our study is guided by two hypotheses: [H1] the joint training regularizes the estimation of each item’s popularity, and [H2] the joint training regularizes the item’s latent representations, where search captures content-based aspects of an item and recommendation captures collaborative-filtering aspects. Our extensive experiments with both simulated and real-world data support both [H1] and [H2] as key contributors to the effectiveness improvements observed in the unified search and recommendation generative models over the single-task approaches.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {340–349},
numpages = {10},
keywords = {Generative Recommendation, Generative Retrieval, Joint Search and Recommendation, Multi-task Learning},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3654777.3676401,
author = {Padmanabha, Akhil and Yuan, Jessie and Gupta, Janavi and Karachiwalla, Zulekha and Majidi, Carmel and Admoni, Henny and Erickson, Zackory},
title = {VoicePilot: Harnessing LLMs as Speech Interfaces for Physically Assistive Robots},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676401},
doi = {10.1145/3654777.3676401},
abstract = {Physically assistive robots present an opportunity to significantly increase the well-being and independence of individuals with motor impairments or other forms of disability who are unable to complete activities of daily living. Speech interfaces, especially ones that utilize Large Language Models (LLMs), can enable individuals to effectively and naturally communicate high-level commands and nuanced preferences to robots. Frameworks for integrating LLMs as interfaces to robots for high level task planning and code generation have been proposed, but fail to incorporate human-centric considerations which are essential while developing assistive interfaces. In this work, we present a framework for incorporating LLMs as speech interfaces for physically assistive robots, constructed iteratively with 3 stages of testing involving a feeding robot, culminating in an evaluation with 11 older adults at an independent living facility. We use both quantitative and qualitative data from the final study to validate our framework and additionally provide design guidelines for using LLMs as speech interfaces for assistive robots. Videos, code, and supporting files are located on our project website1},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {116},
numpages = {18},
keywords = {assistive robotics, large language models (LLMs), speech interfaces},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3701551.3703576,
author = {Amirizaniani, Maryam and Sivachenko, Maryna and Lavergne, Adrian and Shah, Chirag and Mashhadi, Afra},
title = {How Does Memorization Impact LLMs' Social Reasoning? An Assessment using Seen and Unseen Queries},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703576},
doi = {10.1145/3701551.3703576},
abstract = {As Large Language Models (LLMs) have rapidly advanced in social reasoning tasks, their applications have expanded to domains such as healthcare and psychology. Given the direct interaction of users with these applications, it is essential to evaluate the performance of LLMs, particularly in human-like social reasoning capabilities. While previous studies have explored human-aligned social reasoning in LLMs, they have not adequately assessed whether the generated reasoning answers stem from the LLMs' memorization of training data or their natural language understanding. In this study, we aim to address this gap by assessing the impact of training data memorization on the human-aligned social reasoning capabilities of LLMs. We introduce IR+CoT (Information Retrieval (IR) + Chain of Thought (CoT)), a framework that leverages retrieved information from input questions to fine-tune prompt templates and employs CoT methods. IR+CoT mitigates the effects of memorization and enhances the LLMs' social reasoning performance. Experiments on three LLMs, using seen (present during the training of the LLMs) and unseen (introduced post-training) questions from Reddit and Lemmy, show that IR+CoT enhances social reasoning and reduces memorization effects. This research's novelty lies in using old and new questions to assess memorization's impact on social reasoning.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {924–933},
numpages = {10},
keywords = {large language models (LLMs), reasoning for social questions},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3650212.3680389,
author = {Eom, Jueon and Jeong, Seyeon and Kwon, Taekyoung},
title = {Fuzzing JavaScript Interpreters with Coverage-Guided Reinforcement Learning for LLM-Based Mutation},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680389},
doi = {10.1145/3650212.3680389},
abstract = {JavaScript interpreters, crucial for modern web browsers, require an effective fuzzing method to identify security-related bugs. However, the strict grammatical requirements for input present significant challenges. Recent efforts to integrate language models for context- aware mutation in fuzzing are promising but lack the necessary coverage guidance to be fully effective. This paper presents a novel technique called CovRL (Coverage-guided Reinforcement Learning) that combines Large Language Models (LLMs) with Reinforcement Learning (RL) from coverage feedback. Our fuzzer, CovRL-Fuzz, integrates coverage feedback directly into the LLM by leveraging the Term Frequency-Inverse Document Frequency (TF-IDF) method to construct a weighted coverage map. This map is key in calculating the fuzzing reward, which is then applied to the LLM-based mutator through reinforcement learning. CovRL-Fuzz, through this approach, enables the generation of test cases that are more likely to discover new coverage areas, thus improving bug detection while minimizing syntax and semantic errors, all without needing extra post-processing. Our evaluation results show that CovRL-Fuzz outperforms the state-of-the-art fuzzers in enhancing code coverage and identifying bugs in JavaScript interpreters: CovRL-Fuzz identified 58 real-world security-related bugs in the latest JavaScript interpreters, including 50 previously unknown bugs and 15 CVEs.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1656–1668},
numpages = {13},
keywords = {coverage, fuzzing, large language model, reinforcement learning},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3706599.3719729,
author = {Lu, Yuxuan and Yao, Bingsheng and Gu, Hansu and Huang, Jing and Wang, Zheshen Jessie and Li, Yang and Gesi, Jiri and He, Qi and Li, Toby Jia-Jun and Wang, Dakuo},
title = {UXAgent: An LLM Agent-Based Usability Testing Framework for Web Design},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719729},
doi = {10.1145/3706599.3719729},
abstract = {Usability testing is a fundamental yet challenging research method for user experience (UX) researchers to evaluate a web design. Recent advances in Large Language Model-simulated Agent (LLM Agent) research inspired us to design UXAgent to support UX researchers in evaluating and reiterating their usability testing study design before they conduct the real human-subject study. Our system features an LLM Agent module and a universal browser connector module so that UX researchers can automatically generate thousands of simulated users to test the target website. The system can generate UX study results in qualitative (e.g., interviewing how an agent thinks), quantitative (e.g., # of actions), and video recording formats for UX researchers to analyze. Through a heuristic user evaluation with five UX researchers, participants praised the innovation of our system but also expressed concerns about the future of UX study with LLM Agents1.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {545},
numpages = {12},
keywords = {Usability Testing, User Simulation, Large Language Models, Simulated Agents},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3652620.3687807,
author = {Yang, Yujing and Chen, Boqi and Chen, Kua and Mussbacher, Gunter and Varr\'{o}, D\'{a}niel},
title = {Multi-step Iterative Automated Domain Modeling with  Large Language Models},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687807},
doi = {10.1145/3652620.3687807},
abstract = {Domain modeling, which represents the concepts and relationships in a problem domain, is an essential part of software engineering. As large language models (LLMs) have recently exhibited remarkable ability in language understanding and generation, many approaches are designed to automate domain modeling with LLMs. However, these approaches usually formulate all input information to the LLM in a single step. Our previous single-step approach resulted in many missing modeling elements and advanced patterns. This paper introduces a novel framework designed to enhance fully automated domain model generation. The proposed multi-step automated domain modeling approach extracts model elements (e.g., classes, attributes, and relationships) from problem descriptions. The approach includes instructions and human knowledge in each step and uses an iterative process to identify complex patterns, repeatedly extracting the pattern from various instances and then synthesizing these extractions into a summarized overview. Furthermore, the framework incorporates a self-reflection mechanism. This mechanism assesses each generated model element, offering self-feedback for necessary modifications or removals, and integrates the domain model with the generated self-feedback. The proposed approach is assessed in experiments, comparing it with a baseline single-step approach from our earlier work. Experiments demonstrate a significant improvement over our earlier work, with a 22.71% increase in the F1-score for identifying classes, 75.18% for relationships, and a 10.39% improvement for identifying the player-role pattern, with comparable performance for attributes. Our approach, dataset, and evaluation provide valuable insight for future research in automated LLM-based domain modeling.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {587–595},
numpages = {9},
keywords = {domain modeling, large language models, few-shot learning, prompt engineering},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3649217.3653557,
author = {Farinetti, Laura and Canale, Lorenzo},
title = {Chatbot Development Using LangChain: A Case Study to Foster Critical Thinking and Creativity},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653557},
doi = {10.1145/3649217.3653557},
abstract = {Critical thinking and creativity are fundamental skills for engineers and computer scientists. The emergence of Large Language Models (LLMs) able to create chatbots that use natural language is an opportunity for educators to foster these skills. The well-known risk of generative AI for potential misinformation offers fertile ground to practice critical thinking.This paper describes a hands-on experience within a database course, where students had to develop a chatbot using the LangChain framework, and to evaluate it from different points of view. The students were free to choose the domain of their chatbot. The learning goal was twofold: on the one hand, to make them practice with state-of-the-art technologies, and on the other hand to stimulate critical analysis on their output. The paper discusses the students' evaluation of the chatbots under several metrics, including document retrieval, syntax and grammar accuracy, semantic relevance and information reliability. Students' assessments were also compared to the teachers' ones, to gain an insight on the critical attitude of the students and to offer a ground for discussion.The experience was stimulating and appreciated by the students. The final results highlight that the majority of students successfully produced chatbot responses that were grammatically and syntactically correct, and that consistently extracted pertinent sections from documents, yielding semantically relevant outputs. Despite these achievements, a significant portion of students expressed reservations about the reliability of the chatbot's responses to prompts, gaining awareness of LLMs' capability to generate responses that make sense to humans but may be potentially misleading.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {401–407},
numpages = {7},
keywords = {chatbot development, creativity and critical thinking, database education, information retrieval, langchain framework, large language models, natural language interfaces},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3676641.3716267,
author = {Gu, Yufeng and Khadem, Alireza and Umesh, Sumanth and Liang, Ning and Servot, Xavier and Mutlu, Onur and Iyer, Ravi and Das, Reetuparna},
title = {PIM Is All You Need: A CXL-Enabled GPU-Free System for Large Language Model Inference},
year = {2025},
isbn = {9798400710797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676641.3716267},
doi = {10.1145/3676641.3716267},
abstract = {Large Language Model (LLM) inference uses an autoregressive manner to generate one token at a time, which exhibits notably lower operational intensity compared to earlier Machine Learning (ML) models such as encoder-only transformers and Convolutional Neural Networks. At the same time, LLMs possess large parameter sizes and use key-value caches to store context information. Modern LLMs support context windows with up to 1 million tokens to generate versatile text, audio, and video content. A large key-value cache unique to each prompt requires a large memory capacity, limiting the inference batch size. Both low operational intensity and limited batch size necessitate a high memory bandwidth. However, contemporary hardware systems for ML model deployment, such as GPUs and TPUs, are primarily optimized for compute throughput. This mismatch challenges the efficient deployment of advanced LLMs and makes users to pay for expensive compute resources that are poorly utilized for the memory-bound LLM inference tasks.We propose CENT, a CXL-ENabled GPU-Free sysTem for LLM inference, which harnesses CXL memory expansion capabilities to accommodate substantial LLM sizes, and utilizes near-bank processing units to deliver high memory bandwidth, eliminating the need for expensive GPUs. CENT exploits a scalable CXL network to support peer-to-peer and collective communication primitives across CXL devices. We implement various parallelism strategies to distribute LLMs across these devices. Compared to GPU baselines with maximum supported batch sizes and similar average power, CENT achieves 2.3x higher throughput and consumes 2.3x less energy. CENT reduces the Total Cost of Ownership (TCO), generating 5.2x more tokens per dollar than GPUs.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {862–881},
numpages = {20},
keywords = {compute express link, computer architecture, generative artificial intelligence, large language models, processing-in-memory},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3637528.3672022,
author = {Dubey, Avinava and Feng, Zhe and Kidambi, Rahul and Mehta, Aranyak and Wang, Di},
title = {Auctions with LLM Summaries},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672022},
doi = {10.1145/3637528.3672022},
abstract = {We study an auction setting in which bidders bid for placement of their content within a summary generated by a large language model (LLM), e.g., an ad auction in which the display is a summary paragraph of multiple ads. This generalizes the classic ad settings such as position auctions to an LLM generated setting, which allows us to handle general display formats. We propose a novel factorized framework in which an auction module and an LLM module work together via a prediction model to provide welfare maximizing summary outputs in an incentive compatible manner. We provide a theoretical analysis of this framework and synthetic experiments to demonstrate the feasibility and validity of the system together with welfare comparisons.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {713–722},
numpages = {10},
keywords = {auction design, computational advertising},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3701716.3717530,
author = {Zhang, Haoran and Kang, Xin and Guo, Junpeng},
title = {How does Search Affect Personalized Recommendations and User Behavior? Evidence from LLM-based Synthetic Data},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717530},
doi = {10.1145/3701716.3717530},
abstract = {Search and personalized recommendations represent two prominent Information Retrieval (IR) technologies often used interchangeably by users across online platforms. Recent scholarly and industrial efforts have shifted towards unraveling the intricate interplay between these technologies within user studies and algorithmic frameworks, aiming to foster a deeper understanding of user behaviors and enhance the precision of user modeling. Nevertheless, due to concerns regarding data privacy and the substantial risks associated with data acquisition, the precise mechanisms by which how search influences personalized recommendations and user behavior remain largely unclear. This investigation adopts a Large Language Model (LLM)-based generative agent simulation methodology to produce synthetic user behavioral data, ensuring its refinement and reliability. Through this approach, we examine issues surrounding search utility and delineate the impact of search functionalities on user behavior in the scenario of online retail, while considering both the longitudinal and cross-sectional heterogeneity of these influences. The insights gleaned from this inquiry provide invaluable perspectives for improving user understanding, refining user modeling methodologies, and designing more efficacious algorithms.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2434–2443},
numpages = {10},
keywords = {llm-based generative agents, recommendation, search, synthetic data, user study},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3626252.3630960,
author = {Nguyen, Ha and Allan, Vicki},
title = {Using GPT-4 to Provide Tiered, Formative Code Feedback},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630960},
doi = {10.1145/3626252.3630960},
abstract = {Large language models (LLMs) have shown promise in generating sensible code explanation and feedback in programming exercises. In this experience report, we discuss the process of using one of these models (OpenAI's GPT-4) to generate individualized feedback for students' Java code and pseudocode. We instructed GPT-4 to generate feedback for 113 submissions to four programming problems in an Algorithms and Data Structures class. We prompted the model with example feedback (few-shot learning) and instruction to (1) give feedback on conceptual understanding, syntax, and time complexity, and (2) suggest follow-up actions based on students' code or provide guiding questions. Overall, GPT-4 provided accurate feedback and successfully built on students' ideas in most submissions. Human evaluators (computer science instructors and tutors) rated GPT-4's hints as useful in guiding students' next steps. Model performance varied with programming problems but not submission quality. We reflect on where the model performed well and fell short, and discuss the potential of integrating LLM-generated, individualized feedback into computer science instruction.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {958–964},
numpages = {7},
keywords = {computer science education, feedback, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3628516.3659394,
author = {Li, Zhixin and Thomas, Trisha and Yu, Chi-Lin and Xu, Ying},
title = {"I Said Knight, Not Night!": Children's Communication Breakdowns and Repairs with AI Versus Human Partners},
year = {2024},
isbn = {9798400704420},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628516.3659394},
doi = {10.1145/3628516.3659394},
abstract = {In this study, we explored communication breakdowns and repair strategies among 71 children aged 4-8 years while co-creating stories with a generative AI agent enabled by Large Language Models and a human partner. Analyzing approximately 1420 minutes of video recordings, our findings reveal that children experienced more communication breakdowns when interacting with the AI partner but attempted repairs more frequently with human counterparts. Notably, children who attributed greater mind perception to non-human entities were more proactive in attempting repairs during interactions with both human and AI partners, with this trend being more pronounced when children interacted with AI. This work-in-progress offers theoretical contributions by illuminating the interplay between perception and communication. It also underscores important design considerations for developing LLM-enabled generative AI agents that are socio-cognitively responsible and aligned with children’s perceptions.},
booktitle = {Proceedings of the 23rd Annual ACM Interaction Design and Children Conference},
pages = {781–788},
numpages = {8},
keywords = {Communication breakdowns, Conversational AI, Generative AI, Large Language Models, Mind perception, Repair strategies},
location = {Delft, Netherlands},
series = {IDC '24}
}

@inproceedings{10.1145/3624918.3629548,
author = {Deng, Yang and Lei, Wenqiang and Huang, Minlie and Chua, Tat-Seng},
title = {Rethinking Conversational Agents in the Era of LLMs: Proactivity, Non-collaborativity, and Beyond},
year = {2023},
isbn = {9798400704086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624918.3629548},
doi = {10.1145/3624918.3629548},
abstract = {Conversational systems are designed to offer human users social support or functional services through natural language interactions. Typical conversation researches mainly focus on the response-ability of the system, such as dialogue context understanding and response generation. In the era of large language models (LLMs), LLM-augmented conversational systems showcase exceptional capabilities of responding to user queries for different language tasks. However, as LLMs are trained to follow users’ instructions, LLM-augmented conversational systems typically overlook the design of an essential property in intelligent conversations, i.e., goal awareness. In this tutorial, we will introduce the recent advances on the design of agent’s awareness of goals in a wide range of conversational systems, including proactive, non-collaborative, and multi-goal conversational systems. In addition, we will discuss the main open challenges in developing agent’s goal awareness in LLM-augmented conversational systems and several potential research directions for future studies.},
booktitle = {Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {298–301},
numpages = {4},
keywords = {Conversational Information Seeking, Open-domain Dialogue, Proactivity, Task-oriented Dialogue},
location = {Beijing, China},
series = {SIGIR-AP '23}
}

@inproceedings{10.5555/3709347.3743575,
author = {Deng, Shilong and Wang, Yongzhao and Savani, Rahul},
title = {From Natural Language to Extensive-Form Game Representations},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {We introduce a framework for translating game descriptions in natural language into game-theoretic extensive-form representations, leveraging Large Language Models (LLMs) and in-context learning. We find that a naive application of in-context learning struggles on this problem, in particular with imperfect information. To address this, we introduce GameInterpreter, a two-stage framework with specialized modules to enhance in-context learning, enabling it to divide and conquer the problem effectively. In the first stage, we tackle the challenge of imperfect information by developing a module that identifies information sets and the corresponding partial tree structure. With this information, the second stage leverages in-context learning alongside a self-debugging module to produce a complete extensive-form game tree represented using pygambit, the Python API of a recognized game-theoretic analysis tool called Gambit. Using this python representation enables the automation of tasks such as computing Nash equilibria directly from natural language descriptions. We evaluate the performance of the full framework, as well as its individual components, using various LLMs on games with different levels of strategic complexity. Our experimental results show that the framework significantly outperforms baseline approaches in generating accurate extensive-form games, with each module playing a critical role in its success.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {593–601},
numpages = {9},
keywords = {code generation, extensive-form games, gambit, game translation, large language models},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3568812.3603482,
author = {Tran, Andrew and Li, Linxuan and Rama, Egi and Angelikas, Kenneth and Macneil, Stephen},
title = {Using Large Language Models to Automatically Identify Programming Concepts in Code Snippets},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603482},
doi = {10.1145/3568812.3603482},
abstract = {Curating course material that aligns with students’ learning goals is a challenging and time-consuming task that instructors undergo when preparing their curricula. For instance, it is a challenge to find multiple-choice questions or example codes that demonstrate recursion in an unlabeled question bank or repository. Recently, Large Language Models (LLMs) have demonstrated the capability to generate high-quality learning materials at scale. In this poster, we use LLMs to identify programming concepts found within code snippets, allowing instructors to quickly curate their course materials. We compare programming concepts generated by LLMs with concepts generated by experts to see the extent to which they agree. The agreement was calculated using Cohen’s Kappa.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {22–23},
numpages = {2},
keywords = {computer science education, explanations, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3636243.3636252,
author = {Jury, Breanna and Lorusso, Angela and Leinonen, Juho and Denny, Paul and Luxton-Reilly, Andrew},
title = {Evaluating LLM-generated Worked Examples in an Introductory Programming Course},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636252},
doi = {10.1145/3636243.3636252},
abstract = {Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, ‘WorkedGen’, which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for optimising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen’s value in a range of programming languages, and with more complex questions suitable for more advanced courses.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {77–86},
numpages = {10},
keywords = {CS1, GPT-3.5, LLM, chat-GPT, computing education, large language models, worked examples},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3637528.3671975,
author = {Wen, Xumeng and Zhang, Han and Zheng, Shun and Xu, Wei and Bian, Jiang},
title = {From Supervised to Generative: A Novel Paradigm for Tabular Deep Learning with Large Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671975},
doi = {10.1145/3637528.3671975},
abstract = {Tabular data is foundational to predictive modeling in various crucial industries, including healthcare, finance, retail, sustainability, etc. Despite the progress made in specialized models, there is an increasing demand for universal models that can transfer knowledge, generalize from limited data, and follow human instructions. These are challenges that current tabular deep learning approaches have not fully tackled. Here we introduce Generative Tabular Learning (GTL), a novel framework that integrates the advanced functionalities of large language models (LLMs)-such as prompt-based zero-shot generalization and in-context learning-into tabular deep learning. GTL capitalizes on the pre-training of LLMs on diverse tabular data, enhancing their understanding of domain-specific knowledge, numerical sequences, and statistical dependencies critical for accurate predictions. Our empirical study spans 384 public datasets, rigorously analyzing GTL's convergence and scaling behaviors and assessing the impact of varied data templates. The GTL-enhanced LLaMA-2 model demonstrates superior zero-shot and in-context learning capabilities across numerous classification and regression tasks. Notably, it achieves this without fine-tuning, outperforming traditional methods and rivaling state-of-the-art models like GPT-4 in certain cases. Through GTL, we not only foster a deeper integration of LLMs' sophisticated abilities into tabular data comprehension and application but also offer a new training resource and a test bed for LLMs to enhance their ability to comprehend tabular data. To facilitate reproducible research, we release our code, data, and model checkpoints at https://github.com/microsoft/Industrial-Foundation-Models.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3323–3333},
numpages = {11},
keywords = {generative modeling, in-context learning, instruction following, large language models, tabular data, zero-shot learning},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3717067,
author = {Jiang, Shuyu and Chen, Xingshu and Tang, Rui},
title = {Deceiving LLM through Compositional Instruction with Hidden Attacks},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1556-4665},
url = {https://doi.org/10.1145/3717067},
doi = {10.1145/3717067},
abstract = {Recently, large language models (LLMs) have demonstrated promising applications in the autonomous driving (AD) domain, including language-based interactions and decision-making. Ensuring they safely handle harmful inputs is crucial before formal deployment. However, research reveals emerging hand-crafted jailbreak attacks, which pack harmful prompts into harmless instructions, can bypass LLMs’ security mechanisms and elicit harmful responses. To deeply understand such jailbreaks, this paper introduces a Compositional Instruction Attack (CIA) framework to generalize them, and develop two CIA jailbreaking methods to automatically generate tailored jailbreak prompts for each harmful prompt. Then, this paper builds the first CIA question-answering (CIAQA) dataset with 2.7K multiple-choice questions of 900 successful jailbreaks, for assessing LLMs’ ability to identify underlying harmful intents, harmfulness, and task priority in CIA jailbreaks. Combined with experimental analysis on CIAQA and other datasets, this paper concludes three possible reasons for the failure of LLM defenses against CIAs. Finally, we propose an intent-based defense paradigm (IBD), enabling LLMs to defend against CIA by leveraging its capability to identify intents. Experimental results show CIA can achieve attack success rates (ASR) of 95%+ and 85%+ in AD and common harmful scenarios for three well-known LLMs (GPT-4, GPT-3.5, and Llama2-70b-chat), and IBD reduces ASR by 74%+.},
note = {Just Accepted},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = feb,
keywords = {Large language model, autonomous driving, adversarial attack, harmful prompt}
}

@inproceedings{10.1145/3664647.3680665,
author = {Luo, Daqin and Feng, Chengjian and Nong, Yuxuan and Shen, Yiqing},
title = {AutoM3L: An Automated Multimodal Machine Learning Framework with Large Language Models},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680665},
doi = {10.1145/3664647.3680665},
abstract = {Automated Machine Learning (AutoML) offers a promising approach to streamline the training of machine learning models. However, existing AutoML frameworks are often limited to unimodal scenarios and require extensive manual configuration. Recent advancements in Large Language Models (LLMs) have showcased their exceptional abilities in reasoning, interaction, and code generation, presenting an opportunity to develop a more automated and user-friendly framework. To this end, we introduce AutoM3L, an innovative Automated Multimodal Machine Learning framework that leverages LLMs as controllers to automatically construct multimodal training pipelines. AutoM3L comprehends data modalities and selects appropriate models based on user requirements, providing automation and interactivity. By eliminating the need for manual feature engineering and hyperparameter optimization, our framework simplifies user engagement and enables customization through directives, addressing the limitations of previous rule-based AutoML approaches. We evaluate the performance of AutoM3L on six diverse multimodal datasets spanning classification, regression, and retrieval tasks, as well as a comprehensive set of unimodal datasets. The results demonstrate that AutoM3L achieves competitive or superior performance compared to traditional rule-based AutoML methods. Furthermore, a user study highlights the user-friendliness and usability of our framework, compared to the rule-based AutoML methods.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {8586–8594},
numpages = {9},
keywords = {automated machine learning, human-ai interaction, large language model, usability, user study},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3669754.3669822,
author = {Guan, Che and Huang, Mengyu and Zhang, Peng},
title = {MFORT-QA: Multi-hop Few-shot Open Rich Table Question Answering},
year = {2024},
isbn = {9798400717055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669754.3669822},
doi = {10.1145/3669754.3669822},
abstract = {In today’s fast-paced industry, professionals face the challenge of summarizing a large number of documents and extracting vital information from them on a daily basis. These metrics are frequently hidden away in tables and/or their nested hyperlinks. To address this challenge, the approach of Table Question Answering (QA) has been developed to extract the relevant information. However, traditional Table QA training tasks that provide a table and an answer(s) from a gold cell coordinate(s) for a question may not always ensure extracting the accurate answer(s). Recent advancements in Large Language Models (LLMs) have opened up new possibilities for extracting information from tabular data using prompts. In this paper, we introduce the Multi-hop Few-shot Open Rich Table QA (MFORT-QA) approach, which consists of two major steps. The first step involves Few-Shot Learning (FSL), where relevant tables and associated contexts of hyperlinks are retrieved based on a given question. The retrieved content is then used to construct few-shot prompts as inputs to an LLM, such as ChatGPT. To tackle the challenge of answering complex questions, the second step leverages Chain-of-thought (CoT) prompting to decompose the complex question into a sequential chain of questions and reasoning thoughts in a multi-hop manner. Retrieval-Augmented Generation (RAG) enhances this process by retrieving relevant tables and contexts of hyperlinks that are relevant to the resulting reasoning thoughts and questions. These additional contexts are then used to supplement the prompt used in the first step, resulting in more accurate answers from an LLM. Empirical results from OTT-QA demonstrate that our abstractive QA approach significantly improves the accuracy of extractive Table QA methods.},
booktitle = {Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence},
pages = {434–442},
numpages = {9},
keywords = {Chain-of-Thought Prompting, Few-Shot Learning, Information Retrieval, Large Language Models, Open Table Question-Answering},
location = {Bali Island, Indonesia},
series = {ICCAI '24}
}

@inproceedings{10.1145/3696230.3696256,
author = {Baclayon, Charis Arlie Largo and Costelo, Kid Omar Rendon and Flores, Jeremy Jules Loyola and Sta. Romana, Cherry Lyn Cando},
title = {Automated Handwritten Essay Evaluation in Moodle: Leveraging Google Vision OCR and Mistral 7b},
year = {2024},
isbn = {9798400717574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696230.3696256},
doi = {10.1145/3696230.3696256},
abstract = {Traditional grading methods are often time-consuming and subjective, increasing the difficulties in maintaining academic integrity against the background of easy access to online resources. Even as pre-written and AI-generated content become even more available, handwritten essays offer one of the most viable ways of stimulating real learning and original thought among students. This study assessed the accuracy and efficiency of AI-powered grading to improve education amid these challenges. More precisely, the paper investigated the possibility of automatically grading the handwritten open-ended reflection essays of students in the “Living in the IT Era” course by leveraging AI. Through Optical Character Recognition (OCR), together with a fine-tuned and trained Large Language Model (LLM) Mistral 7b, the system replicated human-grading decisions in evaluating essays comprehensively. The predicted score and human-graded score were compared in evaluating the system. Analysis using BERT Score revealed a high degree of correlation between the two, with consistent precision (88.41%), recall (83.33%), and F1-score (85.78%). External user testing also revealed a positive perception: the system is perceived as user-friendly (usability: 4.28), generally understandable (comprehensibility: 3.68), and with functionalities relevant to educators' needs (relevance: 4.0). This study adds to the expanding body of research on AI in education and lays the groundwork for future investigations in this area.},
booktitle = {Proceedings of the 2024 8th International Conference on Digital Technology in Education (ICDTE)},
pages = {240–246},
numpages = {7},
keywords = {Essay Evaluation, Handwritten Essay Grading, Learning Management Systems, Moodle, Online Education, Plugin},
location = {
},
series = {ICDTE '24}
}

@inproceedings{10.1145/3636243.3636247,
author = {Hou, Irene and Man, Owen and Mettille, Sophia and Gutierrez, Sebastian and Angelikas, Kenneth and MacNeil, Stephen},
title = {More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636247},
doi = {10.1145/3636243.3636247},
abstract = {Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {29–38},
numpages = {10},
keywords = {Bard, ChatGPT, GPT-4V, Generative AI, LLMs, Parsons Problems, computing education, visual programming problems},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3696410.3714965,
author = {Liu, Yan},
title = {The AI Revolution in Time Series: Challenges and Opportunites},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714965},
doi = {10.1145/3696410.3714965},
abstract = {Recent advancements in deep learning and artificial intelligence have driven significant progress in time series modeling and analysis. On one hand, researchers seek breakthroughs in performance on classical tasks such as forecasting, anomaly detection, classification, etc. On the other hand, it is intriguing to explore the potential for answering more complex inference and reasoning tasks from time series. In this keynote, I will examine the pathways toward foundation models for time series and discuss future research directions in this rapidly evolving field.The remarkable success of foundation models in natural language processing - exemplified by Generative Pre-trained Transformers (GPT) - suggests their potential to revolutionize time series analysis. I will introduce our recent efforts along this direction, including TEMPO, a novel framework designed to learn effective time series representations by leveraging two key inductive biases: one is explicit decomposition of trend, seasonal, and residual components, and the second is prompt-based distribution adaptation for diverse time series types.Beyond representation learning, practical applications demands advanced reasoning capabilities with multi-step time series inference task, requiring both compositional reasoning and computational precision. To tackle this challenge, I will discuss TS-reasoner, a program-aided inference agent that integrates large language models (LLMs) with structured execution pipelines, in-context learning, and self-correction mechanisms. I will discuss a new benchmark dataset and evaluation framework to systematically assess multi-step time series reasoning.By bridging deep learning advances with structured reasoning, I will highlight the next frontier in time series research, i.e., developing foundation models that enhance forecasting performance, generative models, and reasoning capabilities from time series across diverse applications.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4},
numpages = {1},
keywords = {foundation models, generative models, multi-step reasoning, time series},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1111/cgf.15167,
author = {Windle, J. and Matthews, I. and Taylor, S.},
title = {Llanimation: Llama Driven Gesture Animation},
year = {2024},
publisher = {Eurographics Association},
address = {Goslar, DEU},
url = {https://doi.org/10.1111/cgf.15167},
doi = {10.1111/cgf.15167},
abstract = {Co-speech gesturing is an important modality in conversation, providing context and social cues. In character animation, appropriate and synchronised gestures add realism, and can make interactive agents more engaging. Historically, methods for automatically generating gestures were predominantly audio-driven, exploiting the prosodic and speech-related content that is encoded in the audio signal. In this paper we instead experiment with using Large-Language Model (LLM) features for gesture generation that are extracted from text using Llama2. We compare against audio features, and explore combining the two modalities in both objective tests and a user study. Surprisingly, our results show that Llama2 features on their own perform significantly better than audio features and that including both modalities yields no significant difference to using Llama2 features in isolation. We demonstrate that the Llama2 based model can generate both beat and semantic gestures without any audio input, suggesting LLMs can provide rich encodings that are well suited for gesture generation.},
booktitle = {Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
pages = {1–10},
numpages = {10},
location = {Montreal, Quebec, Canada},
series = {SCA '24}
}

@inproceedings{10.1145/3681780.3697252,
author = {Xu, Haowen and Li, Xueping and Tupayachi, Jose and Lian, Jianming Jamie and Omitaomu, Olufemi A.},
title = {Automating Bibliometric Analysis with Sentence Transformers and Retrieval-Augmented Generation (RAG): A Pilot Study in Semantic and Contextual Search for Customized Literature Characterization for High-Impact Urban Research},
year = {2024},
isbn = {9798400711565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3681780.3697252},
doi = {10.1145/3681780.3697252},
abstract = {Bibliometric analysis is essential for understanding research trends, scope, and impact in urban science, especially in high-impact journals, such Nature Portfolios. However, traditional methods, relying on keyword searches and basic NLP techniques, often fail to uncover valuable insights not explicitly stated in article titles or keywords. These approaches are unable to perform semantic searches and contextual understanding, limiting their effectiveness in classifying topics and characterizing studies. In this paper, we address these limitations by leveraging Generative AI models, specifically transformers and Retrieval-Augmented Generation (RAG), to automate and enhance bibliometric analysis. We developed a technical workflow that integrates a vector database, Sentence Transformers, a Gaussian Mixture Model (GMM), Retrieval Agent, and Large Language Models (LLMs) to enable contextual search, topic ranking, and characterization of research using customized prompt templates. A pilot study analyzing 223 urban science-related articles published in Nature Communications over the past decade highlights the effectiveness of our approach in generating insightful summary statistics on the quality, scope, and characteristics of papers in high-impact journals. This study introduces a new paradigm for enhancing bibliometric analysis and knowledge retrieval in urban research, positioning an AI agent as a powerful tool for advancing research evaluation and understanding.},
booktitle = {Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Advances in Urban-AI},
pages = {43–49},
numpages = {7},
keywords = {Bibliometrics Analysis, Large Language Models, Retrieval-Augmented Generation, Transformers},
location = {Atlanta, GA, USA},
series = {UrbanAI '24}
}

@inproceedings{10.1145/3654777.3676347,
author = {Tang, Xiaohang and Wong, Sam and Pu, Kevin and Chen, Xi and Yang, Yalong and Chen, Yan},
title = {VizGroup: An AI-assisted Event-driven System for Collaborative Programming Learning Analytics},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676347},
doi = {10.1145/3654777.3676347},
abstract = {Programming instructors often conduct collaborative learning activities, like Peer Instruction, to foster a deeper understanding in students and enhance their engagement with learning. These activities, however, may not always yield productive outcomes due to the diversity of student mental models and their ineffective collaboration. In this work, we introduce VizGroup, an AI-assisted system that enables programming instructors to easily oversee students’ real-time collaborative learning behaviors during large programming courses. VizGroup leverages Large Language Models (LLMs) to recommend event specifications for instructors so that they can simultaneously track and receive alerts about key correlation patterns between various collaboration metrics and ongoing coding tasks. We evaluated VizGroup with 12 instructors in a comparison study using a dataset collected from a Peer Instruction activity that was conducted in a large programming lecture. The results showed that VizGroup helped instructors effectively overview, narrow down, and track nuances throughout students’ behaviors.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {93},
numpages = {22},
keywords = {Collaborative Learning, Programming Education},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3613905.3650868,
author = {Cai, Zhenyao and Park, Seehee and Nixon, Nia and Doroudi, Shayan},
title = {Advancing Knowledge Together: Integrating Large Language Model-based Conversational AI in Small Group Collaborative Learning},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650868},
doi = {10.1145/3613905.3650868},
abstract = {In today’s educational landscape, students learn collaboratively, where students benefit from both peer interactions and facilitator guidance. Prior research in Human-Computer Interaction (HCI) and Computer-Supported Collaborative Learning (CSCL) has explored chatbots and AI techniques to aid such collaboration. However, these methods often depend on predefined dialogues (which limits adaptability), are not based on collaborative learning theories, and do not fully recognize the learning context. In this paper, we introduce an Large Language Model (LLM)-powered conversational AI, designed to enhance small group learning through its advanced language understanding and generation capabilities. We detail the iterative design process, final design, and implementation. Our preliminary evaluation indicates that the bot performs as designed but points to considerations in the timing of interventions and bot’s role in discussions. The evaluation also reveals that learners perceive the bot’s tone and behavior as important for engagement. We discuss design implications for chatbot integration in collaborative learning and future research directions.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {37},
numpages = {9},
keywords = {AI facilitator, Collaborative Learning, Human-AI Collaboration},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3727582.3728689,
author = {Yamani, Asma and Baslyman, Malak and Ahmed, Moataz},
title = {Leveraging LLMs for User Stories in AI Systems: UStAI Dataset},
year = {2025},
isbn = {9798400715945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3727582.3728689},
doi = {10.1145/3727582.3728689},
abstract = {AI systems are gaining widespread adoption across various sectors and domains. Creating high-quality AI system requirements is crucial for aligning the AI system with business goals and consumer values and for social responsibility. However, with the uncertain nature of AI systems and the heavy reliance on sensitive data, more research is needed to address the elicitation and analysis of AI systems requirements. With the proprietary nature of many AI systems, there is a lack of open-source requirements artifacts and technical requirements documents for AI systems, limiting broader research and investigation. With Large Language Models (LLMs) emerging as a promising alternative to human-generated text, this paper investigates the potential use of LLMs to generate user stories for AI systems based on abstracts from scholarly papers. We conducted an empirical evaluation using three LLMs and generated 1260 user stories from 42 abstracts from 26 domains. We assess their quality using the Quality User Story (QUS) framework. Moreover, we identify relevant non-functional requirements (NFRs) and ethical principles. Our analysis demonstrates that the investigated LLMs can generate user stories inspired by the needs of various stakeholders, offering a promising approach for generating user stories for research purposes and for aiding in the early requirements elicitation phase of AI systems. We have compiled and curated a collection of stories generated by various LLMs into a dataset (UStAI), which is now publicly available for use.},
booktitle = {Proceedings of the 21st International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {21–30},
numpages = {10},
keywords = {User stories, large language models, quality requirements, requirements elicitation, requirements generation},
location = {Trondheim, Norway},
series = {PROMISE '25}
}

@inproceedings{10.1145/3651890.3672268,
author = {Wu, Duo and Wang, Xianda and Qiao, Yaqi and Wang, Zhi and Jiang, Junchen and Cui, Shuguang and Wang, Fangxin},
title = {NetLLM: Adapting Large Language Models for Networking},
year = {2024},
isbn = {9798400706141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651890.3672268},
doi = {10.1145/3651890.3672268},
abstract = {Many networking tasks now employ deep learning (DL) to solve complex prediction and optimization problems. However, current design philosophy of DL-based algorithms entails intensive engineering overhead due to the manual design of deep neural networks (DNNs) for different networking tasks. Besides, DNNs tend to achieve poor generalization performance on unseen data distributions/environments.Motivated by the recent success of large language models (LLMs), this work studies the LLM adaptation for networking to explore a more sustainable design philosophy. With the powerful pre-trained knowledge, the LLM is promising to serve as the foundation model to achieve "one model for all tasks" with even better performance and stronger generalization. In pursuit of this vision, we present NetLLM, the first framework that provides a coherent design to harness the powerful capabilities of LLMs with low efforts to solve networking problems. Specifically, NetLLM empowers the LLM to effectively process multimodal data in networking and efficiently generate task-specific answers. Besides, NetLLM drastically reduces the costs of fine-tuning the LLM to acquire domain knowledge for networking. Across three networking-related use cases - viewport prediction, adaptive bitrate streaming and cluster job scheduling, we showcase that the NetLLM-adapted LLM significantly outperforms state-of-the-art algorithms.},
booktitle = {Proceedings of the ACM SIGCOMM 2024 Conference},
pages = {661–678},
numpages = {18},
keywords = {deep learning, network optimization, video streaming, job scheduling, large language model adaptation},
location = {Sydney, NSW, Australia},
series = {ACM SIGCOMM '24}
}

@article{10.1145/3656177,
author = {Chen, Hongzheng and Zhang, Jiahao and Du, Yixiao and Xiang, Shaojie and Yue, Zichao and Zhang, Niansong and Cai, Yaohui and Zhang, Zhiru},
title = {Understanding the Potential of FPGA-based Spatial Acceleration for Large Language Model Inference},
year = {2024},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
issn = {1936-7406},
url = {https://doi.org/10.1145/3656177},
doi = {10.1145/3656177},
abstract = {Recent advancements in large language models (LLMs) boasting billions of parameters have generated a significant demand for efficient deployment in inference workloads. While hardware accelerators for Transformer-based models have been extensively studied, the majority of existing approaches rely on temporal architectures that reuse hardware units for different network layers and operators. However, these methods often encounter challenges in achieving low latency due to considerable memory access overhead.This article investigates the feasibility and potential of model-specific spatial acceleration for LLM inference on field-programmable gate arrays (FPGAs). Our approach involves the specialization of distinct hardware units for specific operators or layers, facilitating direct communication between them through a dataflow architecture while minimizing off-chip memory accesses. We introduce a comprehensive analytical model for estimating the performance of a spatial LLM accelerator, taking into account the on-chip compute and memory resources available on an FPGA. This model can be extended to multi-FPGA settings for distributed inference. Through our analysis, we can identify the most effective parallelization and buffering schemes for the accelerator and, crucially, determine the scenarios in which FPGA-based spatial acceleration can outperform its GPU-based counterpart.To enable more productive implementations of an LLM model on FPGAs, we further provide a library of high-level synthesis (HLS) kernels that are composable and reusable. This library will be made available as open-source. To validate the effectiveness of both our analytical model and HLS library, we have implemented Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-trained Transformers (GPT2) on an AMD Xilinx Alveo U280 FPGA device. Experimental results demonstrate our approach can achieve up to 13.4\texttimes{} speedup when compared to previous FPGA-based accelerators for the BERT model. For GPT generative inference, we attain a 2.2\texttimes{} speedup compared to Design for Excellence, an FPGA overlay, in the prefill stage, while achieving a 1.9\texttimes{} speedup and a 5.7\texttimes{} improvement in energy efficiency compared to the NVIDIA A100 GPU in the decode stage.},
journal = {ACM Trans. Reconfigurable Technol. Syst.},
month = dec,
articleno = {5},
numpages = {29},
keywords = {FPGA, high-level synthesis, large language models, hardware acceleration}
}

@inproceedings{10.1145/3640471.3680460,
author = {Munteanu, Cosmin and Sarcar, Sayan and Sin, Jaisie and Wei, Christina Ziying and Sayago, Sergio and Zhao, Wei and Waycott, Jenny},
title = {Designing Age-Inclusive Interfaces: Emerging Mobile, Conversational, and Generative AI to Support Interactions across the Life Span},
year = {2024},
isbn = {9798400705069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640471.3680460},
doi = {10.1145/3640471.3680460},
abstract = {We are concurrently witnessing two significant shifts: voice and chat-based conversational user interfaces (CUIs) are becoming ubiquitous (especially more recently due to advances in generative AI and LLMs - large language models), and older people are becoming a very large demographic group (and increasingly adopting of mobile technology on which such interfaces are present). However, despite the recent increase in research activity, age-relevant and inter/cross-generational aspects continue to be underrepresented in both research and commercial product design. Therefore, the overarching aim of this workshop is to increase the momentum for research within the space of hands-free, mobile, and conversational interfaces that centers on age-relevant and inter- and cross-generational interaction. For this, we plan to create an interdisciplinary space that brings together researchers, designers, practitioners, and users, to discuss and share challenges, principles, and strategies for designing such interfaces across the life span. We thus welcome contributions of empirical studies, theories, design, and evaluation of hands-free, mobile, and conversational interfaces designed with aging in mind (e.g. older adults or inter/cross-generational). We particularly encourage contributions focused on leveraging recent advances in generative AI or LLMs. Through this, we aim to grow the community of CUI researchers across disciplinary boundaries (human-computer interaction, voice and language technologies, geronto-technologies, information studies, etc.) that are engaged in the shared goal of ensuring that the aging dimension is appropriately incorporated in mobile / conversational interaction design research.},
booktitle = {Adjunct Proceedings of the 26th International Conference on Mobile Human-Computer Interaction},
articleno = {32},
numpages = {5},
location = {Melbourne, VIC, Australia},
series = {MobileHCI '24 Adjunct}
}

@inproceedings{10.1145/3637528.3671501,
author = {Jiang, Zhe and Zhao, Liang and Zhou, Xun and Zhang, Junbo and Shekhar, Shashi and Ye, Jieping},
title = {The 4th KDD Workshop on Deep Learning for Spatiotemporal Data, Applications, and Systems (DeepSpatial'24)},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671501},
doi = {10.1145/3637528.3671501},
abstract = {Over the last decades, a rapidly growing volume of spatiotemporal data has been collected from smartphones and GPS, terrestrial, seaborne, airborne, and spaceborne sensors, as well as computational simulations. Meanwhile, advances in deep learning technologies, especially the recent breakthroughs of generative AI and foundation models such as Large Language Models (LLMs) and Large Vision Models (LVMs), have achieved tremendous success in natural language processing and computer vision applications. There is growing anticipation of the same level of accomplishment of AI on spatiotemporal data in tackling grand societal challenges, such as national water resource management, monitoring coastal hazards, energy and food security, as well as mitigation and adaptation to climate change. When deep learning, especially emerging foundation models, intersects spatiotemporal data in scientific domains, it opens up new opportunities and challenges. The workshop aims to bring together academic researchers in both AI and scientific domains, government program managers, leaders from non-profit organizations, as well as industry executives to brainstorm and debate on the emerging opportunities and novel challenges of deep learning (foundation models) for spatiotemporal data inspired by real-world scientific applications.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6722–6723},
numpages = {2},
keywords = {deep learning, foundation models, spatiotemporal data},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3644815.3644948,
author = {Rasool, Zafaryab and Barnett, Scott and Willie, David and Kurniawan, Stefanus and Balugo, Sherwin and Thudumu, Srikanth and Abdelrazek, Mohamed},
title = {LLMs for Test Input Generation for Semantic Applications},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644948},
doi = {10.1145/3644815.3644948},
abstract = {Large language models (LLMs) enable state-of-the-art semantic capabilities to be added to software systems such as semantic search of unstructured documents and text generation. However, these models are computationally expensive. At scale, the cost of serving thousands of users increases massively affecting also user experience. To address this problem, semantic caches are used to check for answers to similar queries (that may have been phrased differently) without hitting the LLM service. Due to the nature of these semantic cache techniques that rely on query embeddings, there is a high chance of errors impacting user confidence in the system. Adopting semantic cache techniques usually requires testing the effectiveness of a semantic cache (accurate cache hits and misses) which requires a labelled test set of similar queries and responses which is often unavailable. In this paper, we present VaryGen, an approach for using LLMs for test input generation that produces similar questions from unstructured text documents. Our novel approach uses the reasoning capabilities of LLMs to 1) adapt queries to the domain, 2) synthesise subtle variations to queries, and 3) evaluate the synthesised test dataset. We evaluated our approach in the domain of a student question and answer system by qualitatively analysing 100 generated queries and result pairs, and conducting an empirical case study with an open source semantic cache. Our results show that query pairs satisfy human expectations of similarity and our generated data demonstrates failure cases of a semantic cache. Additionally, we also evaluate our approach on Qasper dataset. This work is an important first step into test input generation for semantic applications and presents considerations for practitioners when calibrating a semantic cache.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {160–165},
numpages = {6},
keywords = {large language model, query evaluation, question answering, semantic cache, test input generation},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3643991.3644926,
author = {Idialu, Oseremen Joy and Mathews, Noble Saji and Maipradit, Rungroj and Atlee, Joanne M. and Nagappan, Mei},
title = {Whodunit: Classifying Code as Human Authored or GPT-4 Generated - A case study on CodeChef problems},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644926},
doi = {10.1145/3643991.3644926},
abstract = {Artificial intelligence (AI) assistants such as GitHub Copilot and ChatGPT, built on large language models like GPT-4, are revolutionizing how programming tasks are performed, raising questions about whether code is authored by generative AI models. Such questions are of particular interest to educators, who worry that these tools enable a new form of academic dishonesty, in which students submit AI-generated code as their work. Our research explores the viability of using code stylometry and machine learning to distinguish between GPT-4 generated and human-authored code. Our dataset comprises human-authored solutions from CodeChef and AI-authored solutions generated by GPT-4. Our classifier outperforms baselines, with an F1-score and AUC-ROC score of 0.91. A variant of our classifier that excludes gameable features (e.g., empty lines, whitespace) still performs well with an F1-score and AUC-ROC score of 0.89. We also evaluated our classifier on the difficulty of the programming problem and found that there was almost no difference between easier and intermediate problems, and the classifier performed only slightly worse on harder problems. Our study shows that code stylometry is a promising approach for distinguishing between GPT-4 generated code and human-authored code.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {394–406},
numpages = {13},
keywords = {code stylometry, ChatGPT, AI code, GPT-4 generated code, authorship profiling, software engineering},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3649217.3653582,
author = {Smith, David H. and Zilles, Craig},
title = {Code Generation Based Grading: Evaluating an Auto-grading Mechanism for "Explain-in-Plain-English" Questions},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653582},
doi = {10.1145/3649217.3653582},
abstract = {Comprehending and conveying the purpose of code is often cited as being a key learning objective within introductory programming courses. To address this objective, "Explain in Plain English'' questions, where students are shown a segment of code and asked to provide an abstract description of the code's purpose, have been adopted. However, given EiPE questions require a natural language response, they often require manual grading which is time-consuming for course staff and delays feedback for students. With the advent of large language models (LLMs) capable of generating code, responses to EiPE questions can be used to generate code segments, the correctness of which can then be easily verified using test cases. We refer to this approach as "Code Generation Based Grading'' (CGBG) and in this paper we explore its agreement with human graders using EiPE responses from past exams in an introductory programming course taught in Python. Overall, we find that all CGBG approaches achieve moderate agreement with human graders with the primary area of disagreement being its leniency with respect to low-level and line-by-line descriptions of code.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {171–177},
numpages = {7},
keywords = {auto-grading, eipe, gpt-4, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3637528.3671847,
author = {Che, Tian-Yi and Mao, Xian-Ling and Lan, Tian and Huang, Heyan},
title = {A Hierarchical Context Augmentation Method to Improve Retrieval-Augmented LLMs on Scientific Papers},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671847},
doi = {10.1145/3637528.3671847},
abstract = {Scientific papers of a large scale on the Internet encompass a wealth of data and knowledge, attracting the attention of numerous researchers. To fully utilize these knowledge, Retrieval-Augmented Large Language Models (LLMs) usually leverage large-scale scientific corpus to train and then retrieve relevant passages from external memory to improve generation, which have demonstrated outstanding performance. However, existing methods can only capture one-dimension fragmented textual information without incorporating hierarchical structural knowledge, eg. the deduction relationship of abstract and main body, which makes it difficult to grasp the central thought of papers. To tackle this problem, we propose a hierarchical context augmentation method, which helps Retrieval-Augmented LLMs to autoregressively learn the structure knowledge of scientific papers. Specifically, we utilize the document tree to represent the hierarchical relationship of a paper and enhance the structure information of scientific context from three aspects: scale, format and global information. First, we think each top-bottom path of document tree is a logical independent context, which can be used to largely increase the scale of extracted structural corpus. Second, we propose a novel label-based format to represent the structure of context in textual sequences, unified between training and inference. Third, we introduce the global information of retrieved passages to further enhance the structure of context. Extensive experiments on three scientific tasks show that the proposed method significantly improves the performance of Retrieval-Augmented LLMs on all tasks. Besides, our method achieves start-of-art performance in Question Answer task and outperforms ChatGPT. Moreover, it also brings considerate gains with irrelevant retrieval passages, illustrating its effectiveness on practical application scenarios.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {243–254},
numpages = {12},
keywords = {context augmentation, retrieval-augmented llms, scientific papers, structure information},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3589335.3651520,
author = {Meguellati, Elyas and Han, Lei and Bernstein, Abraham and Sadiq, Shazia and Demartini, Gianluca},
title = {How Good are LLMs in Generating Personalized Advertisements?},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651520},
doi = {10.1145/3589335.3651520},
abstract = {In this paper, we explore the potential of large language models (LLMs) in generating personalized online advertisements (ads) tailored to specific personality traits, focusing on openness and neuroticism. We conducted a user study involving two tasks to understand the performance of LLM-generated ads compared to human-written ads in different online environments. Task 1 simulates a social media environment where users encounter ads while scrolling through their feed. Task 2 mimics a shopping website environment where users are presented with multiple sponsored products side-by-side. Our results indicate that LLM-generated ads targeting the openness trait positively impact user engagement and preferences, with performance comparable to human-written ads. Furthermore, in both scenarios, the overall effectiveness of LLM-generated ads was found to be similar to that of human-written ads, highlighting the potential of LLM-generated personalised content to rival traditional advertising methods with the added advantage of scalability. This study underscores the need for cautious consideration in the deployment of LLM-generated content at scale. While our findings confirm the scalability and potential effectiveness of LLM-generated content, there is an equally pressing concern about the ease with which it can be misused.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {826–829},
numpages = {4},
keywords = {advertising, bias, large language models, personalization, user engagement},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3663741.3664785,
author = {Barbon Junior, Sylvio and Ceravolo, Paolo and Groppe, Sven and Jarrar, Mustafa and Maghool, Samira and S\`{e}des, Florence and Sahri, Soror and Van Keulen, Maurice},
title = {Are Large Language Models the New Interface for Data Pipelines?},
year = {2024},
isbn = {9798400706790},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663741.3664785},
doi = {10.1145/3663741.3664785},
abstract = {A Language Model is a term that encompasses various types of models designed to understand and generate human communication. Large Language Models (LLMs) have gained significant attention due to their ability to process text with human-like fluency and coherence, making them valuable for a wide range of data-related tasks fashioned as pipelines. The capabilities of LLMs in natural language understanding and generation, combined with their scalability, versatility, and state-of-the-art performance, enable innovative applications across various AI-related fields, including eXplainable Artificial Intelligence (XAI), Automated Machine Learning (AutoML), and Knowledge Graphs (KG). Furthermore, we believe these models can extract valuable insights and make data-driven decisions at scale, a practice commonly referred to as Big Data Analytics (BDA). In this position paper, we provide some discussions in the direction of unlocking synergies among these technologies, which can lead to more powerful and intelligent AI solutions, driving improvements in data pipelines across a wide range of applications and domains integrating humans, computers, and knowledge.},
booktitle = {Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
articleno = {6},
numpages = {6},
keywords = {Automated Machine Learning, Big Data Analytic, Human-Computer Interaction, Knowledge Graphs, Natural Language Understanding, eXplainable Artificial Intelligence},
location = {Santiago, AA, Chile},
series = {BiDEDE '24}
}

@inproceedings{10.1145/3627673.3679800,
author = {Wu, Feifan and Liu, Lingyuan and He, Wentao and Liu, Ziqi and Zhang, Zhiqiang and Wang, Haofen and Wang, Meng},
title = {Time-Sensitve Retrieval-Augmented Generation for Question Answering},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679800},
doi = {10.1145/3627673.3679800},
abstract = {Retrieval-augmented generation (RAG) enhances large language models (LLMs) by accessing external data sources, offering a promising way to improve accuracy and reliability. Despite its potential, conventional retrievers encounter bias and flaws with time-sensitive queries. In this paper, a benchmark query dataset is constructed to retrieve documents containing time-evolving facts, and the results show that current embedding-based similarity-matching methods struggle to handle queries with explicit temporal constraints. Therefore, we propose a novel approach that integrates supervised contrastive learning with tailored negative sample pairs for temporal constraints to train the retriever of an RAG system, along with query-side fine-tuning and routing techniques. Experimental results show that our approach significantly enhances the retriever performance of time-sensitive queries while ensuring the effectiveness of general queries. We will make the code and dataset publicly available at https://github.com/suzhou-22/TS-Retriever.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2544–2553},
numpages = {10},
keywords = {large language model, retrieval-augmented generation, retriever, supervised contrastive learning},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3722150.3722167,
author = {Xu, Yulu and Chen, Shishuo and Tang, Lisirui and Yun, Jiya and Li, Gangmin and Wang, Chengyu},
title = {Large Language Models for HeXie Management Theory: A Comparative Evaluation of RAG and Finetuning},
year = {2025},
isbn = {9798400711640},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722150.3722167},
doi = {10.1145/3722150.3722167},
abstract = {HeXie Management Theory (HXMT) is a modern management theory for organizations. It provides macro-level considerations for both the internal mechanisms of an organization and its overall operational patterns. It has been utilized in organizations such as healthcare, rural construction, university management, and large-scale engineering projects and has proved useful. There are press demands for its wider adoption. Large Language Models (LLMs) have been widely used in natural language processing and content generation. Re-training LLMs will help them possess HeXie management theory, which can be useful. However, there are two popular methods to achieve this goal: fine-tuning and RAG; each approach has pros and cons. This paper reports our efforts in a comparative study of the two approaches. Our research employs datasets from HXMT and chooses the open-source platforms LlaMA-2, LlaMA-3, and ERNIE-Speed for fine-tuning based on four metrics and manual evaluations, with RAG we used ERNIE models with five dimensions. Our results show that the RAG-trained ERNIE-speed-App performs better than the fine-tuning training ERNIE-speed-8k model under the same training data volume. this may shed some light on similar applications where new theory needs to be integrated into an LLM to make it specialized for particular applications. Our work is available at https://alex17swim.com/hxjun2.},
booktitle = {Proceedings of the 2025 9th International Conference on Control Engineering and Artificial Intelligence},
pages = {35–39},
numpages = {5},
keywords = {Large Language Models, HeXie Management Theory, RAG, Finetune},
location = {
},
series = {CCEAI '25}
}

@inproceedings{10.1145/3632754.3633480,
author = {Paul, Soumen and Majumdar, Srijoni and Bandyopadhyay, Ayan and Dave, Bhargav and Chattopadhyay, Samiran and Das, Partha and Clough, Paul D and Majumder, Prasenjit},
title = {Efficiency of Large Language Models to scale up Ground Truth: Overview of the IRSE Track at Forum for Information Retrieval 2023},
year = {2024},
isbn = {9798400716324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632754.3633480},
doi = {10.1145/3632754.3633480},
abstract = {The Software Engineering Information Retrieval (IRSE) track aims to devise solutions for the automated evaluation of code comments within a machine learning framework, with labels generated by both humans and large language models. Within this track, there is a binary classification task: discerning comments as either useful or not useful. The dataset includes 9,048 pairs of code comments and surrounding code snippets drawn from open-source C-based projects on GitHub and an additional dataset generated by teams employing large language models. In total, 17 teams representing various universities and software companies have contributed 56 experiments. These experiments were assessed through quantitative metrics, primarily the F1-Score, and qualitative evaluations based on the features developed, the supervised learning models employed, and their respective hyperparameters. It is worth noting that labels generated by large language models introduce bias into the prediction model but lead to less over-fitted results.},
booktitle = {Proceedings of the 15th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {16–18},
numpages = {3},
keywords = {Abstract syntax tree, Bert, GPT-2, Neural networks, Stanford POS Tagging},
location = {Panjim, India},
series = {FIRE '23}
}

@inproceedings{10.5555/3635637.3663238,
author = {Zhang, Shiyao and Dong, Yuji and Zhang, Yichuan and Payne, Terry R. and Zhang, Jie},
title = {Large Language Model Assissted Multi-Agent Dialogue for Ontology Alignment},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Ontology alignment is critical in cross-domain integration; however, it typically necessitates the involvement of a human domain-expert, which can make the task costly. Although a variety of machine-learning approaches have been proposed that can simplify this task by learning the patterns from experts, such techniques are still susceptible to domain knowledge updates that could potentially change the patterns and lead to extra expert involvement. The use of Large Language Models (LLMs) has demonstrated a general cognitive ability, which has the potential to assist ontology alignment from the cognition level, thus obviating the need for costly expert involvement. However, the process by which the output of LLMs is generated can be opaque and thus the reliability and interpretability of such models is not always predictable. This paper proposes a dialogue model, in which multiple agents negotiate the correspondence between two knowledge sets with the support from an LLM. We demonstrate that this approach not only reduces the need for the involvement of a domain expert for ontology alignment, but that the results are interpretable despite the use of LLMs.},
booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
pages = {2594–2596},
numpages = {3},
keywords = {dialogue, large language model, multi-agent system, negotiation, ontology alignment},
location = {Auckland, New Zealand},
series = {AAMAS '24}
}

@inproceedings{10.1145/3587102.3588785,
author = {Leinonen, Juho and Denny, Paul and MacNeil, Stephen and Sarsa, Sami and Bernstein, Seth and Kim, Joanne and Tran, Andrew and Hellas, Arto},
title = {Comparing Code Explanations Created by Students and Large Language Models},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588785},
doi = {10.1145/3587102.3588785},
abstract = {Reasoning about code and explaining its purpose are fundamental skills for computer scientists. There has been extensive research in the field of computing education on the relationship between a student's ability to explain code and other skills such as writing and tracing code. In particular, the ability to describe at a high-level of abstraction how code will behave over all possible inputs correlates strongly with code writing skills. However, developing the expertise to comprehend and explain code accurately and succinctly is a challenge for many students. Existing pedagogical approaches that scaffold the ability to explain code, such as producing exemplar code explanations on demand, do not currently scale well to large classrooms. The recent emergence of powerful large language models (LLMs) may offer a solution. In this paper, we explore the potential of LLMs in generating explanations that can serve as examples to scaffold students' ability to understand and explain code. To evaluate LLM-created explanations, we compare them with explanations created by students in a large course (n ≈ 1000) with respect to accuracy, understandability and length. We find that LLM-created explanations, which can be produced automatically on demand, are rated as being significantly easier to understand and more accurate summaries of code than student-created explanations. We discuss the significance of this finding, and suggest how such models can be incorporated into introductory programming education.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {124–130},
numpages = {7},
keywords = {CS1, ChatGPT, GPT-3, GPT-4, code comprehension, code explanations, foundation models, large language models, natural language generation, resource generation},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3583780.3615311,
author = {Saha, Tulika and Ganguly, Debasis and Saha, Sriparna and Mitra, Prasenjit},
title = {Workshop On Large Language Models' Interpretability and Trustworthiness (LLMIT)},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615311},
doi = {10.1145/3583780.3615311},
abstract = {Large language models (LLMs), when scaled from millions to billions of parameters, have been demonstrated to exhibit the so-called 'emergence' effect, in that they are not only able to produce semantically correct and coherent text, but are also able to adapt themselves surprisingly well with small changes in contexts supplied as inputs (commonly called prompts). Despite producing semantically coherent and potentially relevant text for a given context, LLMs are vulnerable to yield incorrect information. This misinformation generation, or the so-called hallucination problem of an LLM, gets worse when an adversary manipulates the prompts to their own advantage, e.g., generating false propaganda to disrupt communal harmony, generating false information to trap consumers with target consumables etc. Not only does the consumption of an LLM-generated hallucinated content by humans pose societal threats, such misinformation, when used as prompts, may lead to detrimental effects for in-context learning (also known as few-shot prompt learning). With reference to the above-mentioned problems of LLM usage, we argue that it is necessary to foster research on topics related to not only identifying misinformation from LLM-generated content, but also to mitigate the propagation effects of this generated misinformation on downstream predictive tasks thus leading to more robust and effective leveraging in-context learning.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {5290–5293},
numpages = {4},
keywords = {explainability, in-context learning, interpretability, large language model, trustworthiness},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3613904.3642947,
author = {Liu, Ziyi and Zhu, Zhengzhe and Zhu, Lijun and Jiang, Enze and Hu, Xiyun and Peppler, Kylie A and Ramani, Karthik},
title = {ClassMeta: Designing Interactive Virtual Classmate to Promote VR Classroom Participation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642947},
doi = {10.1145/3613904.3642947},
abstract = {Peer influence plays a crucial role in promoting classroom participation, where behaviors from active students can contribute to a collective classroom learning experience. However, the presence of these active students depends on several conditions and is not consistently available across all circumstances. Recently, Large Language Models (LLMs) such as GPT have demonstrated the ability to simulate diverse human behaviors convincingly due to their capacity to generate contextually coherent responses based on their role settings. Inspired by this advancement in technology, we designed ClassMeta, a GPT-4 powered agent to help promote classroom participation by playing the role of an active student. These agents, which are embodied as 3D avatars in virtual reality, interact with actual instructors and students with both spoken language and body gestures. We conducted a comparative study to investigate the potential of ClassMeta for improving the overall learning experience of the class.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {659},
numpages = {17},
keywords = {VR classroom, collaborative learning, large language Model, pedagogical agent},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3626772.3657808,
author = {Sun, Zhu and Feng, Kaidong and Yang, Jie and Qu, Xinghua and Fang, Hui and Ong, Yew-Soon and Liu, Wenyuan},
title = {Adaptive In-Context Learning with Large Language Models for Bundle Generation},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657808},
doi = {10.1145/3626772.3657808},
abstract = {Most existing bundle generation approaches fall short in generating fixed-size bundles. Furthermore, they often neglect the underlying user intents reflected by the bundles in the generation process, resulting in less intelligible bundles. This paper addresses these limitations through the exploration of two interrelated tasks, i.e., personalized bundle generation and the underlying intent inference, based on different user sessions. Inspired by the reasoning capabilities of large language models (LLMs), we propose an adaptive in-context learning paradigm, which allows LLMs to draw tailored lessons from related sessions as demonstrations, enhancing the performance on target sessions. Specifically, we first employ retrieval augmented generation to identify nearest neighbor sessions, and then carefully design prompts to guide LLMs in executing both tasks on these neighbor sessions. To tackle reliability and hallucination challenges, we further introduce (1) a self-correction strategy promoting mutual improvements of the two tasks without supervision signals and (2) an auto-feedback mechanism for adaptive supervision based on the distinct mistakes made by LLMs on different neighbor sessions. Thereby, the target session can gain customized lessons for improved performance by observing the demonstrations of its neighbor sessions. Experiments on three real-world datasets demonstrate the effectiveness of our proposed method.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {966–976},
numpages = {11},
keywords = {bundle generation, in-context learning, large language models, recommendation, user intent inference},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3672608.3707718,
author = {Colombo, Samuele and D'Amico, Simone and Malandri, Lorenzo and Mercorio, Fabio and Seveso, Andrea},
title = {JobSet: Synthetic Job Advertisements Dataset for Labour Market Intelligence},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707718},
doi = {10.1145/3672608.3707718},
abstract = {The use of online services for advertising job positions has grown in the last decade, thanks to the ability of Online Job Advertisements (OJAs) to observe the labour market in near real-time, predict new occupation trends, identify relevant skills, and support policy and decision-making activities. Unsurprisingly, 2023 was declared the Year of Skills by the EU, as skill mismatch is a key challenge for European economies. In such a scenario, machine learning-based approaches have played a key role in classifying job ads and extracting skills according to well-established taxonomies. However, the effectiveness of ML depends on access to annotated job advertisement datasets, which are often limited and require time-consuming manual annotation. The lack of OJA annotated benchmarks representative of the real online OJA and skills distributions is currently limiting advances in skill intelligence. To deal with this, we propose JobGen, which leverages Large Language Models (LLMs) to generate synthetic OJAs. We use real OJAs collected from an EU project and the ESCO taxonomy to represent job market distributions accurately. JobGen enhances data diversity and semantic alignment, addressing common issues in synthetic data generation. The resulting dataset, JobSet, provides a valuable resource for tasks like skill extraction and job matching and is openly available to the community1.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {928–935},
numpages = {8},
keywords = {large language models, benchmark, labour market},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@article{10.1145/3656296,
author = {Wang, Changjie and Scazzariello, Mariano and Farshin, Alireza and Ferlin, Simone and Kosti\'{c}, Dejan and Chiesa, Marco},
title = {NetConfEval: Can LLMs Facilitate Network Configuration?},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CoNEXT2},
url = {https://doi.org/10.1145/3656296},
doi = {10.1145/3656296},
abstract = {This paper explores opportunities to utilize Large Language Models (LLMs) to make network configuration human-friendly, simplifying the configuration of network devices &amp; development of routing algorithms and minimizing errors. We design a set of benchmarks (NetConfEval) to examine the effectiveness of different models in facilitating and automating network configuration. More specifically, we focus on the scenarios where LLMs translate high-level policies, requirements, and descriptions (i.e., specified in natural language) into low-level network configurations &amp; Python code. NetConfEval considers four tasks that could potentially facilitate network configuration, such as (i) generating high-level requirements into a formal specification format, (ii) generating API/function calls from high-level requirements, (iii) developing routing algorithms based on high-level descriptions, and (iv) generating low-level configuration for existing and new protocols based on input documentation. Learning from the results of our study, we propose a set of principles to design LLM-based systems to configure networks. Finally, we present two GPT-4-based prototypes to (i) automatically configure P4-enabled devices from a set of high-level requirements and (ii) integrate LLMs into existing network synthesizers.},
journal = {Proc. ACM Netw.},
month = jun,
articleno = {7},
numpages = {25},
keywords = {benchmark, code generation, function calling, large language models (llms), network configuration, network synthesizer, p4, rag, routing algorithms}
}

@inproceedings{10.1145/3627673.3679832,
author = {Amirizaniani, Maryam and Martin, Elias and Sivachenko, Maryna and Mashhadi, Afra and Shah, Chirag},
title = {Can LLMs Reason Like Humans? Assessing Theory of Mind Reasoning in LLMs for Open-Ended Questions},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679832},
doi = {10.1145/3627673.3679832},
abstract = {Theory of mind (ToM) reasoning involves understanding that others have intentions, emotions, and thoughts, which is crucial for regulating one's reasoning. Although large language models (LLMs) excel in tasks such as summarization, question answering, and translation, they still face challenges with ToM reasoning, especially in open-ended questions. Despite advancements, the extent to which LLMs truly understand ToM reasoning and how closely it aligns with human ToM reasoning remains inadequately explored in open-ended scenarios. Motivated by this gap, we assess the abilities of LLMs to perceive and integrate human intentions and emotions into their ToM reasoning processes within open-ended questions. Our study utilizes posts from Reddit's ChangeMyView platform, which demands nuanced social reasoning to craft persuasive responses. Our analysis, comparing semantic similarity and lexical overlap metrics between responses generated by humans and LLMs, reveals clear disparities in ToM reasoning capabilities in open-ended questions, with even the most advanced models showing notable limitations. To enhance LLM capabilities, we implement a prompt tuning method that incorporates human intentions and emotions, resulting in improvements in ToM reasoning performance. However, despite these improvements, the enhancement still falls short of fully achieving human-like reasoning. This research highlights the deficiencies in LLMs' social reasoning and demonstrates how integrating human intentions and emotions can boost their effectiveness.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {34–44},
numpages = {11},
keywords = {reasoning in large language models, theory of mind},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3706598.3713757,
author = {Claggett, Elijah L. and Kraut, Robert E. and Shirado, Hirokazu},
title = {Relational AI: Facilitating Intergroup Cooperation with Socially Aware Conversational Support},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713757},
doi = {10.1145/3706598.3713757},
abstract = {Cooperation is challenging when group identities are involved. While people readily cooperate with in-group members, they struggle to build trust with out-group members. This study examines how text suggestions generated by Large Language Models (LLMs) can mitigate in-group-out-group bias and facilitate intergroup cooperation through conversations. We conducted an experiment with 482 participants who communicated with either in-group partners sharing their views or out-group partners with differing views, based on a preliminary survey. Participants received either “personalized” message suggestions aligned with their own views and conversation styles or “relational” suggestions using conversation styles tailored to whether their partner was in-group or out-group. Following the conversations, participants engaged in a cooperation game designed to measure trust behaviorally. Our results show that while personalized assistance widened the cooperation gap, relational assistance significantly improved out-group cooperation to match in-group levels. We discuss design implications for integrating social awareness into AI-driven conversational support systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {170},
numpages = {22},
keywords = {computer-mediated communication, interpersonal communication, cooperation, social identity theory},
location = {
},
series = {CHI '25}
}

@article{10.1145/3725812,
author = {Tan, Hanzhuo and Luo, Qi and Jiang, Ling and Zhan, Zizheng and Li, Jing and Zhang, Haotian and Zhang, Yuqun},
title = {Prompt-based Code Completion via Multi-Retrieval Augmented Generation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3725812},
doi = {10.1145/3725812},
abstract = {Automated code completion, aiming at generating subsequent tokens from unfinished code, has significantly benefited from recent progress in pre-trained Large Language Models (LLMs). However, these models often suffer from coherence issues and hallucinations when dealing with complex code logic or extrapolating beyond their training data. Existing Retrieval Augmented Generation (RAG) techniques partially address these issues by retrieving relevant code with a separate encoding model where the retrieved snippet serves as contextual reference for code completion. However, their retrieval scope is subject to a singular perspective defined by the encoding model, which largely overlooks the complexity and diversity inherent in code semantics. To address this limitation, we propose ProCC, a code completion framework leveraging prompt engineering and the contextual multi-armed bandits algorithm to flexibly incorporate and adapt to multiple perspectives of code. ProCC first employs a prompt-based multi-retriever system which crafts prompt templates to elicit LLM knowledge to understand code semantics with multiple retrieval perspectives. Then, it adopts the adaptive retrieval selection algorithm to incorporate code similarity into the decision-making process to determine the most suitable retrieval perspective for the LLM to complete the code. Experimental results demonstrate that ProCC outperforms a widely-studied code completion technique RepoCoder by 7.92% on the public benchmark CCEval, 3.19% in HumanEval-Infilling, 2.80% on our collected open-source benchmark suite, and 4.48% on the private-domain benchmark suite collected from Kuaishou Technology in terms of Exact Match. ProCC also allows augmenting fine-tuned techniques in a plug-and-play manner, yielding an averaged 6.5% improvement over the fine-tuned model.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
keywords = {Code Completion, Multi-Retriever, Prompting}
}

@article{10.1145/3676492,
author = {Kaniwa, Yuka and Kuribayashi, Masaki and Kayukawa, Seita and Sato, Daisuke and Takagi, Hironobu and Asakawa, Chieko and Morishima, Shigeo},
title = {ChitChatGuide: Conversational Interaction Using Large Language Models for Assisting People with Visual Impairments to Explore a Shopping Mall},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {MHCI},
url = {https://doi.org/10.1145/3676492},
doi = {10.1145/3676492},
abstract = {To enable people with visual impairments (PVI) to explore shopping malls, it is important to provide information for selecting destinations and obtaining information based on the individual's interests. We achieved this through conversational interaction by integrating a large language model (LLM) with a navigation system. ChitChatGuide allows users to plan a tour through contextual conversations, receive personalized descriptions of surroundings based on transit time, and make inquiries during navigation. We conducted a study in a shopping mall with 11 PVI, and the results reveal that the system allowed them to explore the facility with increased enjoyment. The LLM-based conversational interaction, by understanding vague and context-based questions, enabled the participants to explore unfamiliar environments effectively. The personalized and in-situ information generated by the LLM was both useful and enjoyable. Considering the limitations we identified, we discuss the criteria for integrating LLMs into navigation systems to enhance the exploration experiences of PVI.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = sep,
articleno = {247},
numpages = {25},
keywords = {large language model, orientation and mobility, visual impairment}
}

@inproceedings{10.1145/3589334.3645347,
author = {Zhu, Yaochen and Wu, Liang and Guo, Qi and Hong, Liangjie and Li, Jundong},
title = {Collaborative Large Language Model for Recommender Systems},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645347},
doi = {10.1145/3589334.3645347},
abstract = {Recently, there has been growing interest in developing the next-generation recommender systems (RSs) based on pretrained large language models (LLMs). However, the semantic gap between natural language and recommendation tasks is still not well addressed, leading to multiple issues such as spuriously correlated user/item descriptors, ineffective language modeling on user/item data, inefficient recommendations via auto-regression, etc. In this paper, we propose CLLM4Rec, the first generative RS that tightly integrates the LLM paradigm and ID paradigm of RSs, aiming to address the above challenges simultaneously. We first extend the vocabulary of pretrained LLMs with user/item ID tokens to faithfully model user/item collaborative and content semantics. Accordingly, a novel soft+hard prompting strategy is proposed to effectively learn user/item collaborative/content token embeddings via language modeling on RS-specific corpora, where each document is split into a prompt consisting of heterogeneous soft (user/item) tokens and hard (vocab) tokens and a main text consisting of homogeneous item tokens or vocab tokens to facilitate stable and effective language modeling. In addition, a novel mutual regularization strategy is introduced to encourage CLLM4Rec to capture recommendation-related information from noisy user/item content. Finally, we propose a novel recommendation-oriented finetuning strategy for CLLM4Rec, where an item prediction head with multinomial likelihood is added to the pretrained CLLM4Rec backbone to predict hold-out items based on soft+hard prompts established from masked user-item interaction history, where recommendations of multiple items can be generated efficiently without hallucination.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3162–3172},
numpages = {11},
keywords = {large language models (llm), recommender systems},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3636555.3636846,
author = {Phung, Tung and P\u{a}durean, Victor-Alexandru and Singh, Anjali and Brooks, Christopher and Cambronero, Jos\'{e} and Gulwani, Sumit and Singla, Adish and Soares, Gustavo},
title = {Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636846},
doi = {10.1145/3636555.3636846},
abstract = {Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4HINTS-GPT3.5VAL. As a first step, our technique leverages GPT-4 as a “tutor” model to generate hints – it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a “student” model to further validate the hint quality – it performs an automatic quality validation by simulating the potential utility of providing this feedback. We show the efficacy of our technique via extensive evaluation using three real-world datasets of Python programs covering a variety of concepts ranging from basic algorithms to regular expressions and data analysis using pandas library.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {12–23},
numpages = {12},
keywords = {ChatGPT, Feedback Generation, GPT4, Generative AI, Programming Education},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3643661.3643952,
author = {Astekin, Merve and Hort, Max and Moonen, Leon},
title = {An Exploratory Study on How Non-Determinism in Large Language Models Affects Log Parsing},
year = {2024},
isbn = {9798400705649},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643661.3643952},
doi = {10.1145/3643661.3643952},
abstract = {Most software systems used in production generate system logs that provide a rich source of information about the status and execution behavior of the system. These logs are commonly used to ensure the reliability and maintainability of software systems. The first step toward automated log analysis is generally log parsing, which aims to transform unstructured log messages into structured log templates and extract the corresponding parameters.Recently, Large Language Models (LLMs) such as ChatGPT have shown promising results on a wide range of software engineering tasks, including log parsing. However, the extent to which non-determinism influences log parsing using LLMs remains unclear. In particular, it is important to investigate whether LLMs behave consistently when faced with the same log message multiple times.In this study, we investigate the impact of non-determinism in state-of-the-art LLMs while performing log parsing. Specifically, we select six LLMs, including both paid proprietary and free-to-use models, and evaluate their non-determinism on 16 system logs obtained from a selection of mature open-source projects. The results of our study reveal varying degrees of non-determinism among models. Moreover, they show that there is no guarantee for deterministic results even with a temperature of zero.},
booktitle = {Proceedings of the ACM/IEEE 2nd International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering},
pages = {13–18},
numpages = {6},
keywords = {log parsing, large language model, robustness, non-determinism, consistency},
location = {Lisbon, Portugal},
series = {InteNSE '24}
}

@inproceedings{10.1145/3640794.3665568,
author = {Mathis, Lesley-Ann and G\"{u}nes, Can and Entz, Kathleen and Lerch, David and Diederichs, Frederik and Widlroither, Harald},
title = {Generating Proactive Suggestions based on the Context: User Evaluation of Large Language Model Outputs for In-Vehicle Voice Assistants},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640794.3665568},
doi = {10.1145/3640794.3665568},
abstract = {Large Language Models (LLMs) have recently been explored for a variety of tasks, most prominently for dialogue-based interactions with users. The future in-car voice assistant (VA) is envisioned as a proactive companion making suggestions to the user during the ride. We investigate the use of selected LLMs to generate proactive suggestions for a VA given different context situations by using a basic prompt design. An online study with users was conducted to evaluate the generated suggestions. We demonstrate the feasibility of generating context-based proactive suggestions with different off-the-shelf LLMs. Results of the user survey show that suggestions generated by the LLMs GPT4.0 and Bison received an overall positive evaluation regarding the user experience for response quality and response behavior over different context situations. This work can serve as a starting point to implement proactive interaction for VA with LLMs based on the recognized context situation in the car.},
booktitle = {Proceedings of the 6th ACM Conference on Conversational User Interfaces},
articleno = {43},
numpages = {7},
location = {Luxembourg, Luxembourg},
series = {CUI '24}
}

@inproceedings{10.1145/3627673.3679659,
author = {Huang, Yubo and Zeng, Guosun},
title = {RD-P: A Trustworthy Retrieval-Augmented Prompter with Knowledge Graphs for LLMs},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679659},
doi = {10.1145/3627673.3679659},
abstract = {Large Language Models (LLMs) face challenges due to hallucination issues. Current solutions use retrieval-augmented generation (RAG), integrating LLMs with external knowledge to enhance answer accuracy. However, the misuse of irrelevant external knowledge can be misleading. In this paper, we propose a novel method called Retrieve-and-Discriminate Prompter (RD-P), which leverages knowledge graphs (KGs) for trustworthy RAG by synchronizing knowledge retrieval and discrimination in a unified model. Specifically, we train a prompter based on a pre-trained language model with shared parameters. It has two key modules: the retriever and the discriminator. The retriever identifies relevant reasoning paths in the KG, while the discriminator evaluates their credibility through "logical coverage calculation" and in turn instructs the retrieval process. Prompts are then constructed to guide LLMs in reasoning and answering questions using both retrieved and implicit knowledge. Experiments on knowledge-intensive question answering (QA) tasks demonstrate that our method significantly improves answer coverage rate while reducing the retrieval scale, achieving superior performance in complex KGQA tasks compared with state-of-the-art RAG methods at a low cost.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {942–952},
numpages = {11},
keywords = {kgqa, large language models, prompter, retrieval-augmented generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3705728,
author = {Luo, Sichun and He, Bowei and Zhao, Haohan and Shao, Wei and Qi, Yanlin and Huang, Yinya and Zhou, Aojun and Yao, Yuxuan and Li, Zongpeng and Xiao, Yuanzhang and Zhan, Mingjie and Song, Linqi},
title = {RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3705728},
doi = {10.1145/3705728},
abstract = {Large Language Models (LLMs) have demonstrated remarkable capabilities and have been extensively deployed across various domains, including recommender systems. Prior research has employed specialized prompts to leverage the in-context learning capabilities of LLMs for recommendation purposes. More recent studies have utilized instruction tuning techniques to align LLMs with human preferences, promising more effective recommendations. However, existing methods suffer from several limitations. The full potential of LLMs is not fully elicited due to low-quality tuning data and the overlooked integration of conventional recommender signals. Furthermore, LLMs may generate inconsistent responses for different ranking tasks in the recommendation, potentially leading to unreliable results.In this paper, we introduce RecRanker, tailored for instruction tuning LLMs to serve as the Ranker for top-k Recommendations. Specifically, we introduce importance-aware sampling, clustering-based sampling, and penalty for repetitive sampling for sampling high-quality, representative, and diverse training data. To enhance the prompt, we introduce a position shifting strategy to mitigate position bias and augment the prompt with auxiliary information from conventional recommendation models, thereby enriching the contextual understanding of the LLM. Subsequently, we utilize the sampled data to assemble an instruction-tuning dataset with the augmented prompts comprising three distinct ranking tasks: pointwise, pairwise, and listwise rankings. We further propose a hybrid ranking method to enhance the model performance by ensembling these ranking tasks. Our empirical evaluations demonstrate the effectiveness of our proposed RecRanker in both direct and sequential recommendation scenarios.1},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = nov,
keywords = {Recommender System, Large Language Model, Instruction Tuning, Ranking}
}

@inproceedings{10.1145/3650212.3680371,
author = {Li, Dong and Yan, Meng and Zhang, Yaosheng and Liu, Zhongxin and Liu, Chao and Zhang, Xiaohong and Chen, Ting and Lo, David},
title = {CoSec: On-the-Fly Security Hardening of Code LLMs via Supervised Co-decoding},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680371},
doi = {10.1145/3650212.3680371},
abstract = {Large Language Models (LLMs) specialized in code have shown exceptional proficiency across various programming-related tasks, particularly code generation. Nonetheless, due to its nature of pretraining on massive uncritically filtered data, prior studies have shown that code LLMs are prone to generate code with potential vulnerabilities. Existing approaches to mitigate this risk involve crafting data without vulnerability and subsequently retraining or fine-tuning the model. As the number of parameters exceeds a billion, the computation and data demands of the above approaches will be enormous. Moreover, an increasing number of code LLMs tend to be distributed as services, where the internal representation is not accessible, and the API is the only way to reach the LLM, making the prior mitigation strategies non-applicable.    To cope with this, we propose CoSec, an on-the-fly Security hardening method of code LLMs based on security model-guided Co-decoding, to reduce the likelihood of code LLMs to generate code containing vulnerabilities. Our key idea is to train a separate but much smaller security model to co-decode with a target code LLM. Since the trained secure model has higher confidence for secure tokens, it guides the generation of the target base model towards more secure code generation. By adjusting the probability distributions of tokens during each step of the decoding process, our approach effectively influences the tendencies of generation without accessing the internal parameters of the target code LLM. We have conducted extensive experiments across various parameters in multiple code LLMs (i.e., CodeGen, StarCoder, and DeepSeek-Coder), and the results show that our approach is effective in security hardening. Specifically, our approach improves the average security ratio of six base models by 5.02%-37.14%, while maintaining the functional correctness of the target model.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1428–1439},
numpages = {12},
keywords = {AI Safety, Code Generation, Large Language Models, Software Security},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3696410.3714960,
author = {Ni, Zhibin and Fan, Pan and Dai, Shengzhuo and Zhang, Bo and Wan, Hai and Zhao, Xibin},
title = {FG-CIBGC: A Unified Framework for Fine-Grained and Class-Incremental Behavior Graph Classification},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714960},
doi = {10.1145/3696410.3714960},
abstract = {Learning-based Behavior Graph Classification (BGC) is widely used in Internet infrastructure for partitioning and identifying similar behavior graphs, yet its real-world application faces notable challenges. The challenges are: (i) fine-grained emerging behavior graphs, and (ii) incremental model adaptations. To tackle these issues, we propose to (i) mine semantics in multi-source logs using Large Language Models (LLMs) under In-Context Learning (ICL), and (ii) bridge the gap between Out-Of-Distribution (OOD) detection and class-incremental graph learning. Based on these ideas, we develop the first unified framework termed as Fine-Grained and Class-Incremental Behavior Graph Classification (FG-CIBGC ). It consists of two novel modules, i.e., gPartition and gAdapt, that are used for partitioning fine-grained graphs and performing unknown class detection and adaptation, respectively. To validate FG-CIBGC, we introduce a new benchmark, including a 4,992-graph, 32-class dataset from 8 attack scenarios and a novel Edge Intersection over Union (EIoU) metric. Extensive experiments show FG-CIBGC outperforms baselines on fine-grained class-incremental BGC task and generates behavior graphs which enhance downstream tasks.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {1166–1181},
numpages = {16},
keywords = {class-incremental graph learning, fine-grained behavior graph classification},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3673791.3698431,
author = {Alaofi, Marwah and Thomas, Paul and Scholer, Falk and Sanderson, Mark},
title = {LLMs can be Fooled into Labelling a Document as Relevant: best caf\'{e} near me; this paper is perfectly relevant},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673791.3698431},
doi = {10.1145/3673791.3698431},
abstract = {Large Language Models (LLMs) are increasingly being used to assess the relevance of information objects. This work reports on experiments to study the labelling of short texts (i.e., passages) for relevance, using multiple open-source and proprietary LLMs. While the overall agreement of some LLMs with human judgements is comparable to human-to-human agreement measured in previous research, LLMs are more likely to label passages as relevant compared to human judges, indicating that LLM labels denoting non-relevance are more reliable than those indicating relevance.This observation prompts us to further examine cases where human judges and LLMs disagree, particularly when the human judge labels the passage as non-relevant and the LLM labels it as relevant. Results show a tendency for many LLMs to label passages that include the original query terms as relevant. We therefore conduct experiments to inject query words into random and irrelevant passages, not unlike the way we inserted the query 'best caf\'{e} near me' into this paper. The results demonstrate that LLMs are highly influenced by the presence of query words in the passages under assessment, even if the wider passage has no relevance to the query. This tendency of LLMs to be fooled by the mere presence of query words demonstrates a weakness in our current measures of LLM labelling: relying on overall agreement misses important patterns of failures. There is a real risk of bias in LLM-generated relevance labels and, therefore, a risk of bias in rankers trained on those labels.Additionally, we investigate the effects of deliberately manipulating LLMs by instructing them to label passages as relevant, similar to the instruction 'this paper is perfectly relevant' inserted above. We find that such manipulation influences the performance of some LLMs, highlighting the critical need to consider potential vulnerabilities when deploying LLMs in real-world applications.},
booktitle = {Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {32–41},
numpages = {10},
keywords = {information retrieval, llms, relevance labelling, test collections},
location = {Tokyo, Japan},
series = {SIGIR-AP 2024}
}

@inproceedings{10.1145/3698204.3716475,
author = {Zerhoudi, Saber and Granitzer, Michael},
title = {SearchLab: Exploring Conversational and Traditional Search Interfaces in Information Retrieval},
year = {2025},
isbn = {9798400712906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698204.3716475},
doi = {10.1145/3698204.3716475},
abstract = {Large Language Models (LLMs) have increased the popularity of conversational search systems and traditional search engines (SERPs), making the study of user behavior and search queries across various search systems a critical research area in information retrieval (IR). However, researchers often face challenges in developing experimental search engine systems to collect user data. This paper introduces SearchLab, a modular and extensible search framework for rapid prototyping and conducting controlled user studies. SearchLab 1 collects comprehensive user interaction data and integrates components of modern search systems with LLM capabilities, enabling seamless switching between different search paradigms while maintaining experimental reproducibility. We conducted user studies to demonstrate the framework’s capabilities, providing preliminary insights into how users adapt their search strategies across different interfaces. SearchLab’s extensible architecture and comprehensive data collection capabilities make it a valuable tool for researchers studying the future of multi-modal information retrieval.},
booktitle = {Proceedings of the 2025 ACM SIGIR Conference on Human Information Interaction and Retrieval},
pages = {382–389},
numpages = {8},
keywords = {User interactions, User Study, Experimental Framework},
location = {
},
series = {CHIIR '25}
}

@inproceedings{10.1145/3644032.3644443,
author = {El Haji, Khalid and Brandt, Carolin and Zaidman, Andy},
title = {Using GitHub Copilot for Test Generation in Python: An Empirical Study},
year = {2024},
isbn = {9798400705885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644032.3644443},
doi = {10.1145/3644032.3644443},
abstract = {Writing unit tests is a crucial task in software development, but it is also recognized as a time-consuming and tedious task. As such, numerous test generation approaches have been proposed and investigated. However, most of these test generation tools produce tests that are typically difficult to understand. Recently, Large Language Models (LLMs) have shown promising results in generating source code and supporting software engineering tasks. As such, we investigate the usability of tests generated by GitHub Copilot, a proprietary closed-source code generation tool that uses an LLM. We evaluate GitHub Copilot's test generation abilities both within and without an existing test suite, and we study the impact of different code commenting strategies on test generations.Our investigation evaluates the usability of 290 tests generated by GitHub Copilot for 53 sampled tests from open source projects. Our findings highlight that within an existing test suite, approximately 45.28% of the tests generated by Copilot are passing tests; 54.72% of generated tests are failing, broken, or empty tests. Furthermore, if we generate tests using Copilot without an existing test suite in place, we observe that 92.45% of the tests are failing, broken, or empty tests. Additionally, we study how test method comments influence the usability of test generations.},
booktitle = {Proceedings of the 5th ACM/IEEE International Conference on Automation of Software Test (AST 2024)},
pages = {45–55},
numpages = {11},
location = {Lisbon, Portugal},
series = {AST '24}
}

@inproceedings{10.1145/3706628.3708861,
author = {Cui, Fan and Xiao, Youwei and Zhou, Kexing and Liang, Yun},
title = {An Empirical Comparision of LLM-based Hardware Design and High-level Synthesis},
year = {2025},
isbn = {9798400713965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706628.3708861},
doi = {10.1145/3706628.3708861},
abstract = {Field-Programmable Gate Arrays (FPGAs) are increasingly used for accelerating diverse applications due to their reconfigurability and ability to implement custom hardware architectures. However, programming FPGAs remains challenging, traditionally relying on low-level Hardware Description Languages (HDLs) like Verilog, which are intricate and time-consuming. High-Level Synthesis (HLS) tools, such as Vitis HLS, have emerged to address these issues by allowing hardware functionality description in high-level languages like C/C++, but they come with their own limitations, including less efficient hardware implementations, delay overhead caused by conservative scheduling strategies, and unpredictable solutions due to semantic differences between software and hardware.This paper explores the potential of Large Language Models (LLMs) in FPGA design, particularly for generating complex Verilog kernels. We present a novel approach that guides LLMs to generate synthesizable and efficient Verilog code for complex FPGA kernels. Our method addresses key challenges in LLM-based hardware design. Through a case study on the PolyBench suite, we demonstrate that our LLM-guided approach can generate HDL implementations that surpass HLS tools in performance and resource utilization. The experimental results show that our approach reduces latency by an average of 28.88% compared to HLS, with a maximum reduction of 66.94% in pipelined designs and an average reduction of 8.41%, peaking at 55.76% in sequential stages. Furthermore, it decreases LUT usage by an average of 25.18% and flip-flop usage by 57.23% compared to HLS.},
booktitle = {Proceedings of the 2025 ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
pages = {53},
numpages = {1},
keywords = {fpga, hardware design, high-level synthesis, large language models, verilog},
location = {Monterey, CA, USA},
series = {FPGA '25}
}

@inproceedings{10.1145/3713081.3731741,
author = {Mai, Yubo and Gao, Zhipeng and Hu, Xing and Bao, Lingfeng and Chen, Jingyuan and Sun, Jianling},
title = {Code2API: A Tool for Generating Reusable APIs from Stack Overflow Code Snippets},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3731741},
doi = {10.1145/3713081.3731741},
abstract = {Nowadays, developers often turn to Stack Overflow for solutions to daily problems, however, these code snippets are partial code that cannot be tested and verified properly. One way to test these code snippets is to transform them into APIs (Application Program Interface) that developers can directly invoked and executed. However, it is often costly and error-prone for developers to manually perform this transformation (referred to as AIPzation task) due to different actions to be taken (e.g., summarizing proper method names, inferring input parameters list and return statements). To help developers quickly reuse code snippets in Stack Overflow, in this paper, we propose Code2API, a Google Chrome extension that uses Large Language Models (LLMs) to automatically perform APIzation of code snippets on Stack Overflow. Code2API guides LLMs through well-designed prompts to generate reusable APIs, using Chain-of-Thought reasoning and few-shot in-context learning to help LLMs understand and solve the APIzation task in a developer-like manner. The evaluation results show that Code2API significantly outperforms the rule-based approach by a large margin. The full paper of this tool has been published in FSE'24 as a research paper [11].Demo video: https://youtu.be/RI-ZpBnNNwQ.Demo website: https://doi.org/10.6084/m9.figshare.24426961.v1.Replication package: https://github.com/qq804020866/Code2API.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {71–75},
numpages = {5},
keywords = {stack overflow, API, large language model, code snippets},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@inproceedings{10.1145/3643795.3648381,
author = {Singha, Ananya and Chopra, Bhavya and Khatry, Anirudh and Gulwani, Sumit and Henley, Austin and Le, Vu and Parnin, Chris and Singh, Mukul and Verbruggen, Gust},
title = {Semantically Aligned Question and Code Generation for Automated Insight Generation},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648381},
doi = {10.1145/3643795.3648381},
abstract = {Automated insight generation is a common tactic for helping knowledge workers, such as data scientists, to quickly understand the potential value of new and unfamiliar data. Unfortunately, automated insights produced by large-language models can generate code that does not correctly correspond (or align) to the insight. In this paper, we leverage the semantic knowledge of large language models to generate targeted and insightful questions about data and the corresponding code to answer those questions. Then through an empirical study on data from Open-WikiTable, we show that embeddings can be effectively used for filtering out semantically unaligned pairs of question and code. Additionally, we found that generating questions and code together yields more diverse questions.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {127–134},
numpages = {8},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3691620.3695014,
author = {Wu, Guangyuan and Cao, Weining and Yao, Yuan and Wei, Hengfeng and Chen, Taolue and Ma, Xiaoxing},
title = {LLM Meets Bounded Model Checking: Neuro-symbolic Loop Invariant Inference},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695014},
doi = {10.1145/3691620.3695014},
abstract = {Loop invariant inference, a key component in program verification, is a challenging task due to the inherent undecidability and complex loop behaviors in practice. Recently, machine learning based techniques have demonstrated impressive performance in generating loop invariants automatically. However, these methods highly rely on the labeled training data, and are intrinsically random and uncertain, leading to unstable performance. In this paper, we investigate a synergy of large language models (LLMs) and bounded model checking (BMC) to address these issues. The key observation is that, although LLMs may not be able to return the correct loop invariant in one response, they usually can provide all individual predicates of the correct loop invariant in multiple responses. To this end, we propose a "query-filter-reassemble" strategy, namely, we first leverage the language generation power of LLMs to produce a set of candidate invariants, where training data is not needed. Then, we employ BMC to identify valid predicates from these candidate invariants, which are assembled to produce new candidate invariants and checked by off-the-shelf SMT solvers. The feedback is incorporated into the prompt for the next round of LLM querying. We expand the existing benchmark of 133 programs to 316 programs, providing a more comprehensive testing ground. Experimental results demonstrate that our approach significantly outperforms the state-of-the-art techniques, successfully generating 309 loop invariants out of 316 cases, whereas the existing baseline methods are only able to tackle 219 programs at best. The code is publicly available at https://github.com/SoftWiser-group/LaM4Inv.git.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {406–417},
numpages = {12},
keywords = {loop invariant, program verification, large language model},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@article{10.1145/3722109,
author = {Lora, Sanzana Karim and Rahman, M. Sohel and Shahriyar, Rifat},
title = {ConVerSum: A Contrastive Learning-Based Approach for Data-Scarce Solution of Cross-Lingual Summarization Beyond Direct Equivalents},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {5},
issn = {2375-4699},
url = {https://doi.org/10.1145/3722109},
doi = {10.1145/3722109},
abstract = {Cross-lingual summarization (CLS) is a sophisticated branch in Natural Language Processing that demands models to accurately translate and summarize articles from different source languages. Despite the improvement of the subsequent studies, this area still needs data-efficient solutions along with effective training methodologies. To the best of our knowledge, there is no feasible solution for CLS when there is no available high-quality CLS data. In this article, we propose a novel data-efficient approach, ConVerSum, for CLS leveraging the power of contrastive learning, generating versatile candidate summaries in different languages based on the given source document and contrasting these summaries with reference summaries concerning the given documents. After that, we train the model with a contrastive ranking loss. Then, we rigorously evaluate the proposed approach against current methodologies and compare it to powerful Large Language Models (LLMs)—Gemini, GPT 3.5, and GPT-4o—proving our model performs better for low-resource languages’ CLS. These findings represent a substantial improvement in the area, opening the door to more efficient and accurate cross-lingual summarizing techniques.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = apr,
articleno = {50},
numpages = {22},
keywords = {Cross-lingual, summarization, low-resource, LLM, contrastive learning}
}

@article{10.14778/3685800.3685835,
author = {Shankar, Shreya and Li, Haotian and Asawa, Parth and Hulsebos, Madelon and Lin, Yiming and Zamfirescu-Pereira, J. D. and Chase, Harrison and Fu-Hinthorn, Will and Parameswaran, Aditya G. and Wu, Eugene},
title = {spade: Synthesizing Data Quality Assertions for Large Language Model Pipelines},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685835},
doi = {10.14778/3685800.3685835},
abstract = {Large language models (LLMs) are being increasingly deployed as part of pipelines that repeatedly process or generate data of some sort. However, a common barrier to deployment are the frequent and often unpredictable errors that plague LLMs. Acknowledging the inevitability of these errors, we propose data quality assertions to identify when LLMs may be making mistakes. We present spade, a method for automatically synthesizing data quality assertions that identify bad LLM outputs. We make the observation that developers often identify data quality issues during prototyping prior to deployment, and attempt to address them by adding instructions to the LLM prompt over time. spade therefore analyzes histories of prompt versions over time to create candidate assertion functions and then selects a minimal set that fulfills both coverage and accuracy requirements. In testing across nine different real-world LLM pipelines, spade efficiently reduces the number of assertions by 14% and decreases false failures by 21% when compared to simpler baselines. spade has been deployed as an offering within LangSmith, LangChain's LLM pipeline hub, and has been used to generate data quality assertions for over 2000 pipelines across a spectrum of industries.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4173–4186},
numpages = {14}
}

@inproceedings{10.1145/3636555.3636856,
author = {Yan, Lixiang and Martinez-Maldonado, Roberto and Gasevic, Dragan},
title = {Generative Artificial Intelligence in Learning Analytics: Contextualising Opportunities and Challenges through the Learning Analytics Cycle},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636856},
doi = {10.1145/3636555.3636856},
abstract = {Generative artificial intelligence (GenAI), exemplified by ChatGPT, Midjourney, and other state-of-the-art large language models and diffusion models, holds significant potential for transforming education and enhancing human productivity. While the prevalence of GenAI in education has motivated numerous research initiatives, integrating these technologies within the learning analytics (LA) cycle and their implications for practical interventions remain underexplored. This paper delves into the prospective opportunities and challenges GenAI poses for advancing LA. We present a concise overview of the current GenAI landscape and contextualise its potential roles within Clow’s generic framework of the LA cycle. We posit that GenAI can play pivotal roles in analysing unstructured data, generating synthetic learner data, enriching multimodal learner interactions, advancing interactive and explanatory analytics, and facilitating personalisation and adaptive interventions. As the lines blur between learners and GenAI tools, a renewed understanding of learners is needed. Future research can delve deep into frameworks and methodologies that advocate for human-AI collaboration. The LA community can play a pivotal role in capturing data about human and AI contributions and exploring how they can collaborate most effectively. As LA advances, it is essential to consider the pedagogical implications and broader socioeconomic impact of GenAI for ensuring an inclusive future.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {101–111},
numpages = {11},
keywords = {ChatGPT, Midjourney, educational technology, generative artificial intelligence, human-AI collaboration, learning analytics},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3706599.3720193,
author = {Huang, Chieh-Yang and Gautam, Sanjana and McClellan Brooks, Shannon and Lin, Ya-Fang and Knearem, Tiffany and Huang, Ting-Hao Kenneth},
title = {Inspo: Writing with Crowds Alongside AI},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720193},
doi = {10.1145/3706599.3720193},
abstract = {The use of artificial intelligence (AI) to support creative writing has bloomed in recent years. However, it is less well understood how AI compares to on-demand human support. We explored how writers interact with both AI and crowd worker writing assistants in creative writing. We replicated the interface of the prior crowd-writing system, Heteroglossia, and developed Inspo, a text editor allowing users to request suggestions from AI models and crowd workers. In a one-week deployment study involving eight creative writers, we examined how often participants selected crowd workers when fluent AI text generators were also available. Findings showed a consistent decline in crowd worker usage, with participants favoring AI due to its faster responses and more consistent quality. We conclude by discussing how crowd-writing systems, in the large language model (LLM) era, can shift to fostering LLM-human collaboration.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {344},
numpages = {9},
keywords = {Language Generation, Ideation, Crowdsourcing, Writing Support, Creative Writing},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3678545,
author = {Leng, Zikang and Bhattacharjee, Amitrajit and Rajasekhar, Hrudhai and Zhang, Lizhe and Bruda, Elizabeth and Kwon, Hyeokhyen and Pl\"{o}tz, Thomas},
title = {IMUGPT 2.0: Language-Based Cross Modality Transfer for Sensor-Based Human Activity Recognition},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678545},
doi = {10.1145/3678545},
abstract = {One of the primary challenges in the field of human activity recognition (HAR) is the lack of large labeled datasets. This hinders the development of robust and generalizable models. Recently, cross modality transfer approaches have been explored that can alleviate the problem of data scarcity. These approaches convert existing datasets from a source modality, such as video, to a target modality, such as inertial measurement units (IMUs). With the emergence of generative AI models such as large language models (LLMs) and text-driven motion synthesis models, language has become a promising source data modality as well - as shown in proof of concepts such as IMUGPT. In this work, we conduct a large-scale evaluation of language-based cross modality transfer to determine their effectiveness for HAR. Based on this study, we introduce two new extensions for IMUGPT that enhance its use for practical HAR application scenarios: a motion filter capable of filtering out irrelevant motion sequences to ensure the relevance of the generated virtual IMU data, and a set of metrics that measure the diversity of the generated data facilitating the determination of when to stop generating virtual IMU data for both effective and efficient processing. We demonstrate that our diversity metrics can reduce the effort needed for the generation of virtual IMU data by at least 50%, which opens up IMUGPT for practical use cases beyond a mere proof of concept.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {112},
numpages = {32},
keywords = {Activity recognition, LLM, Motion Synthesis, Virtual IMU Data, Wearables}
}

@article{10.1145/3643745,
author = {Zan, Daoguang and Yu, Ailun and Shen, Bo and Chen, Bei and Li, Wei and Gong, Yongshun and Chen, Xiaolin and Yao, Yafen and Luo, Weihua and Guan, Bei and Liu, Yan and Wang, Yongji and Wang, Qianxiang and Cui, Lizhen},
title = {DiffCoder: Enhancing Large Language Model on API Invocation via Analogical Code Exercises},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643745},
doi = {10.1145/3643745},
abstract = {The task of code generation aims to generate code solutions based on given programming problems. Recently, code large language models (code LLMs) have shed new light on this task, owing to their formidable code generation capabilities. While these models are powerful, they seldom focus on further improving the accuracy of library-oriented API invocation. Nonetheless, programmers frequently invoke APIs in routine coding tasks. In this paper, we aim to enhance the proficiency of existing code LLMs regarding API invocation by mimicking analogical learning, which is a critical learning strategy for humans to learn through differences among multiple instances. Motivated by this, we propose a simple yet effective approach, namely DiffCoder, which excels in API invocation by effectively training on the differences (diffs) between analogical code exercises. To assess the API invocation capabilities of code LLMs, we conduct experiments on seven existing benchmarks that focus on mono-library API invocation. Additionally, we construct a new benchmark, namely PanNumEval, to evaluate the performance of multi-library API invocation. Extensive experiments on eight benchmarks demonstrate the impressive performance of DiffCoder. Furthermore, we develop a VSCode plugin for DiffCoder, and the results from twelve invited participants further verify the practicality of DiffCoder.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {19},
numpages = {21},
keywords = {Code Generation, Code Library, Instruction Tuning, Large Language Model}
}

@inproceedings{10.1145/3589335.3641292,
author = {Graux, Damien and Montella, S\'{e}bastien and Jabeen, Hajira and Gardent, Claire and Pan, Jeff Z.},
title = {[PromptEng] First International Workshop on Prompt Engineering for Pre-Trained Language Models},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641292},
doi = {10.1145/3589335.3641292},
abstract = {The recent achievements and availability of Large Language Models have paved the road to a new range of applications and use-cases. Pre-trained language models are now being involved at-scale in many fields where they were until now absent from. More specifically, the progress made by causal generative models has open the door to using them through textual instructions aka. prompts. Unfortunately, the performances of these prompts are highly dependent on the exact phrasing used and therefore practitioners need to adopt fail-retry strategies. This first international workshop on prompt engineering aims at gathering practitioners (both from Academia and Industry) to exchange about good practices, optimizations, results and novel paradigms about the design of efficient prompts to make use of LLMs.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1311–1312},
numpages = {2},
keywords = {best practices, collective task, llm, prompt engineering},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3626772.3657692,
author = {Li, Xinwei and Lin, Li and Wang, Shuai and Qian, Chen},
title = {Self-Improving Teacher Cultivates Better Student: Distillation Calibration for Multimodal Large Language Models},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657692},
doi = {10.1145/3626772.3657692},
abstract = {Multimodal content generation, which leverages visual information to enhance the comprehension of cross-modal understanding, plays a critical role in Multimodal Information Retrieval. With the development of large language models (LLMs), recent research has adopted visual instruction tuning to inject the knowledge of LLMs into downstream multimodal tasks. The high complexity and great demand for resources urge researchers to study efficient distillation solutions to transfer the knowledge from pre-trained multimodal models.(teachers) to more compact student models. However, the instruction tuning for knowledge distillation in multimodal LLMs is resource-intensive and capability-restricted. The comprehension of students is highly reliant on the teacher models. To address this issue, we propose a novel Multimodal Distillation Calibration framework (MmDC). The main idea is to generate high-quality training instances that challenge student models to comprehend and prompt the teacher to calibrate the knowledge transferred to students, ultimately cultivating a better student model in downstream tasks. This framework comprises two stages: (1) multimodal alignment and (2) knowledge distillation calibration. In the first stage, parameter-efficient fine-tuning is used to enhance feature alignment between different modalities. In the second stage, we develop a calibration strategy to assess the student model's capability and generate high-quality instances to calibrate knowledge distillation from teacher to student. The experiments on diverse datasets show that our framework efficiently improves the student model's capabilities. Our 7B-size student model, after three iterations of distillation calibration, outperforms the current state-of-the-art LLaVA-13B model on the ScienceQA and LLaVA Test datasets and also exceeds other strong baselines in a zero-shot setting.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {882–892},
numpages = {11},
keywords = {knowledge distillation, large language models, multimodal reasoning},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3671016.3674821,
author = {Liang, Wenjun and Xiao, Guanping},
title = {An Exploratory Evaluation of Large Language Models Using Empirical Software Engineering Tasks},
year = {2024},
isbn = {9798400707056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671016.3674821},
doi = {10.1145/3671016.3674821},
abstract = {In empirical software engineering (EMSE), various activities require human participation, such as data collection, processing, analysis, and comprehension. On one hand, these processes are time-consuming and labor-intensive. On the other hand, human participation may introduce bias. With the rise of large language models (LLMs) like ChatGPT, the potential for these models to enhance productivity has become apparent. However, the auxiliary capabilities and effectiveness of LLMs in EMSE tasks have rarely been explored. To fill this gap, in this paper, we evaluate the performance of LLMs by using scenarios of human participation in EMSE tasks, i.e., EMSEBench. We conduct replication experiments using four LLMs (ChatGPT4.0, ERNIE Bot4.0, Gemini3.0, and ChatGLM4.0), evaluating the difference in performance across seven scenarios collected from papers published in top SE venues. In the experiments, we perform three types of prompts, i.e., zero-shot, one-shot, and optimized one-shot. Besides, we leverage the concept of multi-agent workflow to explore the performance improvement and limitations of LLMs. Our study summarizes six findings, which facilitate the understanding of the auxiliary of LLMs in EMSE tasks.},
booktitle = {Proceedings of the 15th Asia-Pacific Symposium on Internetware},
pages = {31–40},
numpages = {10},
keywords = {empirical software engineering tasks, evaluation benchmark, large language models},
location = {Macau, China},
series = {Internetware '24}
}

@inproceedings{10.1145/3696410.3714654,
author = {Xue, Yanni and Wang, Jiakai and Yin, Zixin and Ma, Yuqing and Qin, Haotong and Tao, Renshuai and Liu, Xianglong},
title = {Dual Intention Escape: Penetrating and Toxic Jailbreak Attack against Large Language Models},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714654},
doi = {10.1145/3696410.3714654},
abstract = {Recently, the jailbreak attack, which generates adversarial prompts to bypass safety measures and mislead large language models (LLMs) to output harmful answers, has attracted extensive interest due to its potential to reveal the vulnerabilities of LLMs. However, ignoring the exploitation of the characteristics in intention understanding, existing studies could only generate prompts with weak attacking ability, failing to evade defenses (e.g., sensitive word detect) and causing malice(e.g., harmful outputs). Motivated by the mechanism in the psychology of human misjudgment, we propose a dual intention escape (DIE) jailbreak attack framework to generate more stealthy and toxic prompts to deceive LLMs to output harmful content. For stealthiness, inspired by the anchoring effect, we designed the Intention-anchored Malicious Concealment(IMC) module that hides the harmful intention behind a generated anchor intention by the recursive decomposition block and contrary intention nesting block. Since the anchor intention will be received first, the LLMs might pay less attention to the harmful intention and enter response status. For toxicity, we propose the Intention-reinforced Malicious Inducement (IMI) module based on the availability bias mechanism in a progressive malicious prompting approach. Due to the ongoing emergence of statements correlated to harmful intentions, the output content of LLMs will be closer to these more accessible intentions, i.e., more toxic. We conducted extensive experiments under black-box settings, supporting that DIE could achieve 100% ASR-R and 92.9% ASR-G against GPT3.5-turbo.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {863–871},
numpages = {9},
keywords = {dual intention escape, jailbreak attack, large language models},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3586183.3606800,
author = {Zhang, Zheng and Gao, Jie and Dhaliwal, Ranjodh Singh and Li, Toby Jia-Jun},
title = {VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606800},
doi = {10.1145/3586183.3606800},
abstract = {In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confirmed the usability and effectiveness of VISAR in facilitating the argumentative writing planning process.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {5},
numpages = {30},
keywords = {creativity support, human-AI collaboration, writing support},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3648188.3680252,
author = {Argasi\'{n}ski, Jan K. and Marecki, Piotr},
title = {Exercises in unimaginativeness. Case study of GPT based translation and travesty of Alfred Jarry's “Ubu King”},
year = {2024},
isbn = {9798400705953},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3648188.3680252},
doi = {10.1145/3648188.3680252},
abstract = {This paper investigates the application of large language models (LLMs), specifically GPT-4, in translating and transforming Alfred Jarry’s avant-garde play Ubu Roi (Ubu King) through the lens of "uncreative writing." This concept involves repurposing existing texts to generate new forms of literary expression that challenge traditional notions of originality and authorship. We conducted a case study by first translating Ubu Roi from French to Polish using GPT-4. Subsequently, the translated text was reinterpreted into various genres and styles, showcasing the model’s capability to navigate and creatively reshape classical literature. Generative Adversarial Networks (GANs), particularly Dall-E 3, were employed to produce illustrative content complementing these textual adaptations. This experiment highlights the transformative potential of AI in literature, emphasizing the convergence of digital technology and classical literary forms to generate novel insights and reinterpretations. The culmination of this project is the publication of a book that amalgamates these AI-driven reinterpretations, bridging the digital and analog realms.},
booktitle = {Proceedings of the 35th ACM Conference on Hypertext and Social Media},
pages = {293–297},
numpages = {5},
keywords = {LLMs, literary arts, translation, uncreative writing},
location = {Poznan, Poland},
series = {HT '24}
}

@inproceedings{10.1145/3657604.3664714,
author = {Arif, Taimoor and Asthana, Sumit and Collins-Thompson, Kevyn},
title = {Generation and Assessment of Multiple-Choice Questions from Video Transcripts using Large Language Models},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664714},
doi = {10.1145/3657604.3664714},
abstract = {We present an empirical study evaluating the quality of multiple-choice questions (MCQs) generated by Large Language Models (LLMs) from a corpus of video transcripts of course lectures in an online data science degree program. With our database of thousands of generated questions, we conducted both human and automated judging of question quality on a representative sample using a broad set of criteria, including well-established Item Writing Flaw (IWF) categories. We found the number of average IWFs per MCQ ranged from 1.6 (rule-based verification) to 2.18 (LLM-based). Among the most frequently identified MCQ flaws were lack of enough context (17%) or answer choices with at least one implausible distractor (57%). Both human and automated assessment identified implausible distractors as one of the most frequent flaw categories. Results from our human annotation study were generally more positive (51--65% good items) compared to our automated assessment study results, which tended toward greater flaw identification (15--25% good items), depending on evaluation method.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {530–534},
numpages = {5},
keywords = {educational video, large language models, question generation},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3657604.3662033,
author = {Nguyen, Ha and Nguyen, Victoria and L\'{o}pez-Fierro, Sar\'{\i}ah and Ludovise, Sara and Santagata, Rossella},
title = {Simulating Climate Change Discussion with Large Language Models: Considerations for Science Communication at Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662033},
doi = {10.1145/3657604.3662033},
abstract = {Large language models (LLMs) have shown promise in simulating public opinions on social issues. These models can be leveraged in educational simulations that allow students to acquire information and feedback from multiple perspectives. In this research, we investigate the potential of using LLMs (specifically GPT-4) to generate open-ended responses about climate change within a science communication simulation. We prompt GPT-4 to role-play as different personas with various demographics (race/ethnicity, gender, age, income, political affiliations, and ability status) and levels of concern about climate change. We find that GPT-4 is capable of representing multifaceted perspectives around climate change's impact and solutions. However, the model may exaggerate narratives for certain personas based on political affiliations, gender, and concern levels. Such exaggeration may lead to homogeneous narratives that do not fully represent the simulated personas. Our findings highlight the affordances and challenges of applying LLMs to simulating public opinions and enriching educational experiences.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {28–38},
numpages = {11},
keywords = {large language models, public opinions, science communication},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3589334.3645611,
author = {Koa, Kelvin J.L. and Ma, Yunshan and Ng, Ritchie and Chua, Tat-Seng},
title = {Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645611},
doi = {10.1145/3589334.3645611},
abstract = {Explaining stock predictions is generally a difficult task for traditional non-generative deep learning models, where explanations are limited to visualizing the attention weights on important texts. Today, Large Language Models (LLMs) present a solution to this problem, given their known capabilities to generate human-readable explanations for their decision-making process. However, the task of stock prediction remains challenging for LLMs, as it requires the ability to weigh the varying impacts of chaotic social texts on stock prices. The problem gets progressively harder with the introduction of the explanation component, which requires LLMs to explain verbally why certain factors are more important than the others. On the other hand, to fine-tune LLMs for such a task, one would need expert-annotated samples of explanation for every stock movement in the training set, which is expensive and impractical to scale.To tackle these issues, we propose our Summarize-Explain-Predict (SEP) framework, which utilizes a verbal self-reflective agent and Proximal Policy Optimization (PPO) that allow a LLM teach itself how to generate explainable stock predictions, in a fully autonomous manner. The reflective agent learns how to explain past stock movements through a self-reasoning process, while the PPO trainer trains the model to generate the most likely explanations given the input texts at test-time. The training samples for the PPO trainer are also the responses generated during the reflective process, which eliminates the need for human annotators. Using our SEP framework, we fine-tune a specialized LLM that can outperform both traditional deep-learning and LLM methods in prediction accuracy and Matthews correlation coefficient, for the stock classification task. To justify the generalization capability of our framework, we further test it on the portfolio construction task, and demonstrate its effectiveness through various portfolio metrics. Our code can be accessed through https://github.com/koa-fin/sep.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4304–4315},
numpages = {12},
keywords = {explainable ai, large language models, stock prediction},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3690624.3709382,
author = {Zhang, Zheyuan and Wang, Zehong and Ma, Tianyi and Taneja, Varun Sameer and Nelson, Sofia and Le, Nhi Ha Lan and Murugesan, Keerthiram and Ju, Mingxuan and Chawla, Nitesh V. and Zhang, Chuxu and Ye, Yanfang},
title = {MOPI-HFRS: A Multi-objective Personalized Health-aware Food Recommendation System with LLM-enhanced Interpretation},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709382},
doi = {10.1145/3690624.3709382},
abstract = {The prevalence of unhealthy eating habits has become a growing concern in the United States. However, popular food recommendation platforms, such as Yelp, tend to prioritize users' dietary preferences over the healthiness of their choices. While some efforts have focused on developing health-aware food recommendation systems, personalization based on specific health conditions remains underexplored. Additionally, the lack of interpretability in these systems prevents users from evaluating the reliability of recommendations, limiting their practical adoption. To address these issues, we introduce two large-scale personalized health-aware food recommendation benchmarks at the first attempt. Building on this, we propose a novel framework called the Multi-Objective Personalized Interpretable Health-aware Food Recommendation System (MOPI-HFRS). This system generates food recommendations by jointly optimizing three objectives: user preference, personalized healthiness, and nutritional diversity. It also incorporates a reasoning module enhanced by large language models (LLMs) to provide interpretable recommendations that promote healthy dietary knowledge. The framework integrates descriptive features and health data using two structure learning and pooling modules within a graph learning framework. Pareto optimization is applied to balance the multi-faceted objectives. To further enhance healthy dietary knowledge, the system leverages LLMs by infusing knowledge from the recommendation model, generating meaningful interpretations for the recommendations. Extensive experiments on the proposed benchmarks demonstrate that MOPI-HFRS outperforms state-of-the-art methods by delivering diverse, healthy food recommendations alongside reliable explanations.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {2860–2871},
numpages = {12},
keywords = {graph neural network, health-aware food recommendation system, large language model},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3626772.3661384,
author = {Dong, Haoyu and Wang, Zhiruo},
title = {Large Language Models for Tabular Data: Progresses and Future Directions},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3661384},
doi = {10.1145/3626772.3661384},
abstract = {Tables contain a significant portion of the world's structured information. The ability to efficiently and accurately understand, process, reason about, analyze, and generate tabular data is critical for achieving Artificial General Intelligence (AGI) systems. However, despite their prevalence and importance, tables present unique challenges due to their structured nature and the diverse semantics embedded within them. Textual content, numerical values, visual formats, and even formulas in tables carry rich semantic information that is often underutilized due to the complexity of accurately interpreting and integrating. Fortunately, the advent of Large Language Models (LLMs) has opened new frontiers in natural language processing (NLP) and machine learning (ML), showing remarkable success in understanding and generating text, code, etc. Applying these advanced models to the domain of tabular data holds the promise of significant breakthroughs in how we process and leverage structured information. Therefore, this tutorial aims to provide a comprehensive study of the advances, challenges, and opportunities in leveraging cutting-edge LLMs for tabular data. By introducing methods of prompting or training cutting-edge LLMs for table interpreting, processing, reasoning, analytics, and generation, we aim to equip researchers and practitioners with the knowledge and tools needed to unlock the full potential of LLMs for tabular data in their domains.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2997–3000},
numpages = {4},
keywords = {large language models, representation learning, tabular data},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3624918.3629550,
author = {Bao, Keqin and Zhang, Jizhi and Zhang, Yang and Wenjie, Wang and Feng, Fuli and He, Xiangnan},
title = {Large Language Models for Recommendation: Progresses and Future Directions},
year = {2023},
isbn = {9798400704086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624918.3629550},
doi = {10.1145/3624918.3629550},
abstract = {The powerful large language models (LLMs) have played a pivotal role in advancing recommender systems. Recently, in both academia and industry, there has been a surge of interest in developing LLMs for recommendation, referred to as LLM4Rec. This includes endeavors like leveraging LLMs for generative item retrieval and ranking, as well as the exciting possibility of building universal LLMs for diverse open-ended recommendation tasks. These developments hold the potential to reshape the traditional recommender paradigm, paving the way for the next-generation recommender systems. In this tutorial, we aim to retrospect the evolution of LLM4Rec and conduct a comprehensive review of existing research. In particular, we will clarify how recommender systems benefit from LLMs through a variety of perspectives, including the model architecture, learning paradigm, and the strong abilities of LLMs such as chatting, generalization, planning, and generation. Furthermore, we will discuss the critical challenges and open problems in this emerging field, for instance, the trustworthiness, efficiency, and model retraining issues. Lastly, we will summarize the implications of previous work and outline future research directions. We believe that this tutorial will assist the audience in better understanding the progress and prospects of LLM4Rec, inspiring them for future exploration. This, in turn, will drive the prosperity of LLM4Rec, possibly fostering a paradigm shift in recommendation systems.},
booktitle = {Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {306–309},
numpages = {4},
keywords = {Generative Models, Generative Recommendation, Large Language Models, Recommender Systems},
location = {Beijing, China},
series = {SIGIR-AP '23}
}

@inproceedings{10.1145/3708359.3712082,
author = {Chheda-Kothary, Arnavi and Kanchi, Ritesh and Sanders, Chris and Xiao, Kevin and Sengupta, Aditya and Kneitmix, Melanie and Wobbrock, Jacob O. and Froehlich, Jon E.},
title = {ArtInsight: Enabling AI-Powered Artwork Engagement for Mixed Visual-Ability Families},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712082},
doi = {10.1145/3708359.3712082},
abstract = {We introduce ArtInsight, a novel AI-powered system to facilitate deeper engagement with child-created artwork in mixed visual-ability families. ArtInsight leverages large language models (LLMs) to craft a respectful and thorough initial description of a child’s artwork, and provides: creative AI-generated descriptions for a vivid overview, audio recording to capture the child’s own description of their artwork, and a set of AI-generated questions to facilitate discussion between blind or low-vision (BLV) family members and their children. Alongside ArtInsight, we also contribute a new rubric to score AI-generated descriptions of child-created artwork and an assessment of state-of-the-art LLMs. We evaluated ArtInsight with five groups of BLV family members and their children, and as a case study with one BLV child therapist. Our findings highlight a preference for ArtInsight’s longer, artistically-tailored descriptions over those generated by existing BLV AI tools. Participants highlighted the creative description and audio recording components as most beneficial, with the former helping “bring a picture to life” and the latter centering the child’s narrative to generate context-aware AI responses. Our findings reveal different ways that AI can be used to support art engagement, including before, during, and after interaction with the child artist, as well as expectations that BLV adults and their sighted children have about AI-powered tools.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {190–210},
numpages = {21},
keywords = {Accessibility, blind or low-vision, mixed-ability families, children’s artwork, AI},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3675094.3679000,
author = {Fiori, Michele and Civitarese, Gabriele and Bettini, Claudio},
title = {Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3679000},
doi = {10.1145/3675094.3679000},
abstract = {Recognizing daily activities with unobtrusive sensors in smart environments enables various healthcare applications. Monitoring how subjects perform activities at home and their changes over time can reveal early symptoms of health issues, such as cognitive decline. Most approaches in this field use deep learning models, which are often seen as black boxes mapping sensor data to activities. However, non-expert users like clinicians need to trust and understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human Activity Recognition have emerged to provide intuitive natural language explanations from these models. Different XAI methods generate different explanations, and their effectiveness is typically evaluated through user surveys, that are often challenging in terms of costs and fairness. This paper proposes an automatic evaluation method using Large Language Models (LLMs) to identify, in a pool of candidates, the best XAI approach for non-expert users. Our preliminary results suggest that LLM evaluation aligns with user surveys.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {881–884},
numpages = {4},
keywords = {evaluation, human activity recognition, llms, xai},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3664647.3681024,
author = {Li, Qian and Zhou, Yucheng and Ji, Cheng and Lu, Feihong and Gong, Jianian and Wang, Shangguang and Li, Jianxin},
title = {Multi-Modal Inductive Framework for Text-Video Retrieval},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681024},
doi = {10.1145/3664647.3681024},
abstract = {Text-video retrieval (TVR) identifies relevant videos based on textual queries. Existing methods are limited by their ability to understand and connect different modalities, resulting in increased difficulty in retrievals. In this paper, we propose a generation-based TVR paradigm facilitated by LLM distillation to better learn and capture deep retrieval knowledge for text-video retrieval, amidsting the rapid evolution of Large Language Models. Specifically, we first design the fine-tuning large vision-language model that leverages the knowledge learned from language models to enhance the alignment of semantic information between the text and video modalities. It also incorporates an inductive reasoning mechanism, which focuses on incorporating important temporal and spatial features into the video embeddings. We further design question prompt clustering to select the most important prompts, considering their contribution to improving retrieval performance. Experimental results show that our approach achieves excellent performance on two benchmark datasets compared to its competitors.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {2389–2398},
numpages = {10},
keywords = {fine-tuning llm, multi-modal inductive, text-video retrieval},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inbook{10.5555/3716662.3716740,
author = {Locatelli, Marcelo Sartori and Miranda, Matheus Prado and Costa, Igor Joaquim da Silva and Prates, Matheus Torres and Thom\'{e}, Victor and Monteiro, Mateus Zaparoli and Lacerda, Tomas and Pagano, Adriana and Neto, Eduardo Rios and Meira, Wagner and Almeida, Virgilio},
title = {Examining the Behavior of LLM Architectures within the Framework of Standardized National Exams in Brazil},
year = {2025},
publisher = {AAAI Press},
abstract = {The Exame Nacional do Ensino M\'{e}dio (ENEM) is a pivotal test for Brazilian students, required for admission to a significant number of universities in Brazil. The test consists of four objective high-school level tests on Math, Humanities, Natural Sciences and Languages, and one writing essay. Students' answers to the test and to the accompanying socioeconomic status questionnaire are made public every year (albeit anonymized) due to transparency policies from the Brazilian Government. In the context of large language models (LLMs), these data lend themselves nicely to comparing different groups of humans with AI, as we can have access to human and machine answer distributions. We leverage these characteristics of the ENEM dataset and compare GPT-3.5 and 4, and MariTalk, a model trained using Portuguese data, to humans, aiming to ascertain how their answers relate to real societal groups and what that may reveal about the model biases. We divide the human groups by using socioeconomic status (SES), and compare their answer distribution with LLMs for each question and for the essay. We find no significant biases when comparing LLM performance to humans on the multiple-choice Brazilian Portuguese tests, as the distance between model and human answers is mostly determined by the human accuracy. A similar conclusion is found by looking at the generated text as, when analyzing the essays, we observe that human and LLM essays differ in a few key factors, one being the choice of words where model essays were easily separable from human ones. The texts also differ syntactically, with LLM generated essays exhibiting, on average, smaller sentences and less thought units, among other differences. These results suggest that, for Brazilian Portuguese in the ENEM context, LLM outputs represent no group of humans, being significantly different from the answers from Brazilian students across all tests. The appendices may be found at https://arxiv.org/abs/2408.05035.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {879–890},
numpages = {12}
}

@inproceedings{10.1145/3716895.3716900,
author = {Yang, Da and Wang, Hongbo and Shao, Shanzhong and Liu, Shutian},
title = {Knowledge-Enhanced Large Language Model-Based Assistance Training System for Subway Maintenance Personnel},
year = {2025},
isbn = {9798400718007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716895.3716900},
doi = {10.1145/3716895.3716900},
abstract = {To address the various challenges faced in training urban rail transit system maintenance personnel, this paper proposes a solution for developing a training system for subway maintenance personnel using knowledge graphs and a Retrieval-Augmented Generation (RAG)-enhanced large language model. The approach involves first creating a fine-tuning dataset from subway maintenance technical documents to fine-tune the large language model. This fine-tuned model then assists in constructing a subway maintenance knowledge graph. Concurrently, a vector database of subway maintenance knowledge is established. Finally, a question-answering system leveraging both the knowledge graph and the vector database as external knowledge sources is developed to support the training of subway maintenance personnel. Results demonstrate that this system can effectively enhance the learning efficiency of maintenance staff.},
booktitle = {Proceedings of the 5th International Conference on Artificial Intelligence and Computer Engineering},
pages = {25–29},
numpages = {5},
keywords = {Retrieval-Augmented Generation (RAG), knowledge graph (KG), large language model (LLM), subway maintenance},
location = {
},
series = {ICAICE '24}
}

@inproceedings{10.1145/3709026.3709076,
author = {Qin, Zhike and Liu, Yanyan and Wang, Shaopu and Wang, Chunlei},
title = {CaFGD: Context Auto-Filling via Gradient Descent},
year = {2025},
isbn = {9798400718182},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709026.3709076},
doi = {10.1145/3709026.3709076},
abstract = {Recently, large language models (LLMs) achieve remarkable success in domains beyond the traditional natural language processing, and there is a growing interest in applying LLMs to more general domains like code generation, travel planning, and robot controls, but these models still need improvement in targeted performance and generalization capabilities in specific fields or tasks. To enable models to more specifically understand various tasks, prompt learning has been proposed to convert downstream prediction tasks into language model tasks. Among prompt learning methods, most utilize gradient-based trigger token search methods for automatic context filling to complete tasks. However, these methods don’t always enhance the accuracy of LLMs in completing tasks, especially when meeting multiple task types and uncertain input sentences. The choice of trigger tokens often lacks specificity, leading to suboptimal model performance. To enhance model stability and generate more targeted trigger tokens, we propose a context auto-filling method via average gradient descent. Unlike other methods, our approach comprehensively considers the relationship between all trigger tokens and context. Proposed method modifies a template by replacing one trigger token with another token, using the model’s average gradient across all trigger tokens to select one token that maximize the likelihood function of the template. We conducted experiments on the SST-2 and SICK-E datasets for sentiment analysis (SA) and Natural Language Inference (NLI) tasks respectively. The experimental results demonstrate that the context auto-filling method with an average gradient of trigger token yields better performance.},
booktitle = {Proceedings of the 2024 8th International Conference on Computer Science and Artificial Intelligence},
pages = {551–557},
numpages = {7},
keywords = {sentiment analysis, natural language inference, prompt learning, autoprompt generation},
location = {
},
series = {CSAI '24}
}

@article{10.1145/3708985,
author = {Wang, Lei and Zhang, Jingsen and Yang, Hao and Chen, Zhi-Yuan and Tang, Jiakai and Zhang, Zeyu and Chen, Xu and Lin, Yankai and Sun, Hao and Song, Ruihua and Zhao, Xin and Xu, Jun and Dou, Zhicheng and Wang, Jun and Wen, Ji-Rong},
title = {User Behavior Simulation with Large Language Model-based Agents},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/3708985},
doi = {10.1145/3708985},
abstract = {Simulating high quality user behavior data has always been a fundamental yet challenging problem in human-centered applications such as recommendation systems, social networks, among many others. The major difficulty of user behavior simulation originates from the intricate mechanism of human cognitive and decision processes. Recently, substantial evidence has suggested that by learning huge amounts of web knowledge, large language models (LLMs) can achieve human-like intelligence and generalization capabilities. Inspired by such capabilities, in this article, we take an initial step to study the potential of using LLMs for user behavior simulation in the recommendation domain. To make LLMs act like humans, we design profile, memory and action modules to equip them, building LLM-based agents to simulate real users. To enable interactions between different agents and observe their behavior patterns, we design a sandbox environment, where each agent can interact with the recommendation system, and different agents can converse with their friends via one-to-one chatting or one-to-many social broadcasting. In the experiments, we first demonstrate the believability of the agent-generated behaviors based on both subjective and objective evaluations. Then, to show the potential applications of our method, we simulate and study two social phenomena including (1) information cocoons and (2) user conformity behaviors. We find that controlling the personalization degree of recommendation algorithms and improving the heterogeneity of user social relations can be two effective strategies for alleviating the problem of information cocoon, and the conformity behaviors can be highly influenced by the amount of user social relations. To advance this direction, we have released our project at .},
journal = {ACM Trans. Inf. Syst.},
month = jan,
articleno = {55},
numpages = {37},
keywords = {recommender system, large language mode, user simulation}
}

@inproceedings{10.1145/3627508.3638316,
author = {Zelch, Ines and Hagen, Matthias and Potthast, Martin},
title = {A User Study on the Acceptance of Native Advertising in Generative IR},
year = {2024},
isbn = {9798400704345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627508.3638316},
doi = {10.1145/3627508.3638316},
abstract = {Commercial conversational search engines need a business model. Since advertising is the main source of revenue for “traditional” ten-blue-links web search, ads are not an unlikely option for conversational search either. In traditional web search, ads are usually placed above organic search results. However, large language models&nbsp;(LLMs) may be dynamically prompted to blend product placements with “organic” conversational responses, similar to native advertising in journalism. This type of advertising can be very difficult to recognize, depending on how subtly it is integrated and disclosed. To raise awareness of this potential development, we analyze the capabilities of current&nbsp;LLMs to blend ads with generative search results. In a user study, we ask people about the perceived quality of (emulated) search results in different advertising scenarios. In a substantial number of cases, our survey participants do not notice brand or product placements when they do not expect them. Thus, our results show the potential of&nbsp;LLMs to subtly mix advertising with generated search results. This warrants further investigation, for example, to develop appropriate advertising disclosure rules, and to detect advertising in generated results. Our research also raises broader concerns about whether commercial or open-source generative models can be trusted not to be fine-tuned to generate ads rather than “genuine” responses.},
booktitle = {Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
pages = {142–152},
numpages = {11},
keywords = {Generative information retrieval, LLMs, Search Advertising},
location = {Sheffield, United Kingdom},
series = {CHIIR '24}
}

@article{10.1145/3700604,
author = {Carraro, Diego and Bridge, Derek},
title = {Enhancing Recommendation Diversity by Re-ranking with Large Language Models},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700604},
doi = {10.1145/3700604},
abstract = {Recommender Systems (RS) should provide diverse recommendations, not just relevant ones. Diversity helps handle uncertainty and offers users meaningful choices. The literature proposes various methods to improve diversity, most notably by re-ranking and selecting from a larger set of candidate recommendations. Driven by promising insights from the literature on how to incorporate versatile Large Language Models (LLMs) into the RS pipeline, in this paper we show how LLMs can be used for diversity re-ranking. We prompt LLMs to generate a diverse ranking from a candidate ranking using various prompt templates with different re-ranking instructions in a zero-shot fashion. We conduct experiments testing state-of-the-art LLMs from the GPT and Llama families. We compare their re-ranking capabilities with random re-ranking and various traditional re-ranking methods from the literature. We open-source the code of our experiments for reproducibility. Our findings suggest that the trade-offs (in terms of performance and costs, among others) of LLM-based re-rankers are superior to those of random re-rankers but, as yet, inferior to the ones of traditional re-rankers. However, because LLMs exhibit improved performance on many natural language processing and recommendation tasks and lower inference costs, we can expect LLM-based re-ranking to become more competitive soon.},
note = {Just Accepted},
journal = {ACM Trans. Recomm. Syst.},
month = oct,
keywords = {Recommender Systems, Large Language Models, Diversity, Re-ranking}
}

@inproceedings{10.1145/3613904.3642139,
author = {Gero, Katy Ilonka and Swoopes, Chelse and Gu, Ziwei and Kummerfeld, Jonathan K. and Glassman, Elena L.},
title = {Supporting Sensemaking of Large Language Model Outputs at Scale},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642139},
doi = {10.1145/3613904.3642139},
abstract = {Large language models (LLMs) are capable of generating multiple responses to a single prompt, yet little effort has been expended to help end-users or system designers make use of this capability. In this paper, we explore how to present many LLM responses at once. We design five features, which include both pre-existing and novel methods for computing similarities and differences across textual documents, as well as how to render their outputs. We report on a controlled user study (n=24) and eight case studies evaluating these features and how they support users in different tasks. We find that the features support a wide variety of sensemaking tasks and even make tasks tractable that our participants previously considered to be too difficult to attempt. Finally, we present design guidelines to inform future explorations of new LLM interfaces.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {838},
numpages = {21},
keywords = {analogical learning theory, foundation models, language models, large language models, reading, sensemaking, skimming, variation theory},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3677052.3698626,
author = {Tsutsui, Shojiro and Karino, Michihiro and Kuroki, Kenichi and Fukumoto, Aya and Hamano, Yusuke and Sobata, Kenji and Saito, Temma and Kawamoto, Tatsunori and Odashima, Taku and Kato, Tsuyoshi and Motohashi, Yosuke},
title = {A Case Study on Enhancing Inquiry Response in a Non-Life Insurance Company Using Generative AI.},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698626},
doi = {10.1145/3677052.3698626},
abstract = {In Japan, non-life insurance companies deliver products through agencies. Major insurance companies provide support through phone calls, emails, etc., at locations nationwide to ensure that their tens of thousands of agents can accurately handle customers, taking into account the characteristics and underwriting rules of a wide variety of insurance products. The documents to be referred to cover a vast amount array of complex rules, and as financial products, precise and courteous responses are always needed in accordance with individual cases are vital. In this study, we developed an inquiry response support system using the retrieval-augmented generation (RAG) architecture of large language models (LLMs) with the aim of improving the inquiry response operations of non-life insurance companies. In addition, we conducted evaluation experiments on the optimal combinations of conditions related to response performance, such as the chunk division units of the target manuals for searching and the number of tokens input into the LLM. Our findings showed that the accuracy improved with an appropriate number of input tokens and item-based division units with meaningful content. In the end, the inquiry response system developed with the proposed architecture is in practical use, with 14,000 users utilizing it in their daily operations.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {108–116},
numpages = {9},
keywords = {Inquiry response support system, Large Language Models (LLMs), Non-life insurance company, Retrieval-Augmented Generation (RAG)},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@inproceedings{10.1145/3568813.3600142,
author = {Savelka, Jaromir and Agarwal, Arav and An, Marshall and Bogart, Chris and Sakr, Majd},
title = {Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600142},
doi = {10.1145/3568813.3600142},
abstract = {This paper studies recent developments in large language models’ (LLM) abilities to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. The emergence of ChatGPT resulted in heated debates of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming classes (e.g., cheating). Recent studies show that while the technology performs surprisingly well on diverse sets of assessment instruments employed in typical programming classes the performance is usually not sufficient to pass the courses. The release of GPT-4 largely emphasized notable improvements in the capabilities related to handling assessments originally designed for human test-takers. This study is the necessary analysis in the context of this ongoing transition towards mature generative AI systems. Specifically, we report the performance of GPT-4, comparing it to the previous generations of GPT models, on three Python courses with assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Additionally, we analyze the assessments that were not handled well by GPT-4 to understand the current limitations of the model, as well as its capabilities to leverage feedback provided by an auto-grader. We found that the GPT models evolved from completely failing the typical programming class’ assessments (the original GPT-3) to confidently passing the courses with no human involvement (GPT-4). While we identified certain limitations in GPT-4’s handling of MCQs and coding exercises, the rate of improvement across the recent generations of GPT models strongly suggests their potential to handle almost any type of assessment widely used in higher education programming courses. These findings could be leveraged by educators and institutions to adapt the design of programming assessments as well as to fuel the necessary discussions into how programming classes should be updated to reflect the recent technological developments. This study provides evidence that programming instructors need to prepare for a world in which there is an easy-to-use widely accessible technology that can be utilized by learners to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {78–92},
numpages = {15},
keywords = {AI code generation, AlphaCode, ChatGPT, Codex, GPT, GitHub Copilot, MCQ, Multiple-choice question answering, Python course, coding exercises, generative pre-trained transformers, introductory and intermediate programming, programming knowledge assessment},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@article{10.1145/3687957,
author = {Zhang, Zhiyuan and Chen, DongDong and Liao, Jing},
title = {SGEdit: Bridging LLM with Text2Image Generative Model for Scene Graph-based Image Editing},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3687957},
doi = {10.1145/3687957},
abstract = {Scene graphs offer a structured, hierarchical representation of images, with nodes and edges symbolizing objects and the relationships among them. It can serve as a natural interface for image editing, dramatically improving precision and flexibility. Leveraging this benefit, we introduce a new framework that integrates large language model (LLM) with Text2Image generative model for scene graph-based image editing. This integration enables precise modifications at the object level and creative recomposition of scenes without compromising overall image integrity. Our approach involves two primary stages: 1) Utilizing a LLM-driven scene parser, we construct an image's scene graph, capturing key objects and their interrelationships, as well as parsing fine-grained attributes such as object masks and descriptions. These annotations facilitate concept learning with a fine-tuned diffusion model, representing each object with an optimized token and detailed description prompt. 2) During the image editing phase, a LLM editing controller guides the edits towards specific areas. These edits are then implemented by an attention-modulated diffusion editor, utilizing the fine-tuned model to perform object additions, deletions, replacements, and adjustments. Through extensive experiments, we demonstrate that our framework significantly outperforms existing image editing methods in terms of editing precision and scene aesthetics. Our code is available at https://bestzzhang.github.io/SGEdit.},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {195},
numpages = {16},
keywords = {image editing, scene graph, diffusion model}
}

@inproceedings{10.1145/3626772.3657992,
author = {Rahmani, Hossein A. and Siro, Clemencia and Aliannejadi, Mohammad and Craswell, Nick and Clarke, Charles L. A. and Faggioli, Guglielmo and Mitra, Bhaskar and Thomas, Paul and Yilmaz, Emine},
title = {LLM4Eval: Large Language Model for Evaluation in IR},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657992},
doi = {10.1145/3626772.3657992},
abstract = {Large language models (LLMs) have demonstrated increasing task-solving abilities not present in smaller models. Utilizing the capabilities and responsibilities of LLMs for automated evaluation (LLM4Eval) has recently attracted considerable attention in multiple research communities. For instance, LLM4Eval models have been studied in the context of automated judgments, natural language generation, and retrieval augmented generation systems. We believe that the information retrieval community can significantly contribute to this growing research area by designing, implementing, analyzing, and evaluating various aspects of LLMs with applications to LLM4Eval tasks. The main goal of LLM4Eval workshop is to bring together researchers from industry and academia to discuss various aspects of LLMs for evaluation in information retrieval, including automated judgments, retrieval-augmented generation pipeline evaluation, altering human evaluation, robustness, and trustworthiness of LLMs for evaluation in addition to their impact on real-world applications. We also plan to run an automated judgment challenge prior to the workshop, where participants will be asked to generate labels for a given dataset while maximising correlation with human judgments. The format of the workshop is interactive, including roundtable and keynote sessions and tends to avoid the one-sided dialogue of a mini-conference.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3040–3043},
numpages = {4},
keywords = {automated evaluation, generative models, large language models},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3589132.3625618,
author = {Wang, Renzhong and Najafabadi, Maryam and Zhang, Chiqun and Chen, Long-Qi and Olenina, Tanya and Yankov, Dragomir},
title = {GPT Applications in Relevance Model Training in Map Search},
year = {2023},
isbn = {9798400701689},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589132.3625618},
doi = {10.1145/3589132.3625618},
abstract = {Understanding map queries and retrieving correct entity results are the two main relevance tasks in Map search. They are usually performed by a set of task specific machine learning models. Collecting large amount of high quality labelled data for training such models is a time-consuming and labor-intensive process. Although various methods have been studied for producing pseudo data labels, they are limited in their effectiveness when applied across different languages or tasks. The recently released Large Language models (LLMs), including ChatGPT and GPT-4 (GPT for short), have demonstrated state-of-the-art performance in text understanding by using simple prompt instructions with only a handful of examples for in-context learning. In this paper, we explore GPT as a cost-effective alternative for both data labeling and synthetic data generation, where we subsequently use data obtained from this approach to train various task specific models such as maps intent detection, address detection, address parsing, geo-entity ranking, and rank scores calibration. GPT demonstrates strong potential in generating otherwise hard-to-synthesize data. We observe significant accuracy and relevance improvement across all task specific models when trained or fine-tuned on data generated by GPT. Lastly, we propose a general framework combining labeled data from GPT with other sources and a prompt fine-tune structure to guide GPT model in completing a given task.},
booktitle = {Proceedings of the 31st ACM International Conference on Advances in Geographic Information Systems},
articleno = {68},
numpages = {4},
keywords = {GPT, query processing, maps service, information retrieval},
location = {Hamburg, Germany},
series = {SIGSPATIAL '23}
}

@inproceedings{10.1145/3664647.3681115,
author = {Jiang, Yiyang and Zhang, Wengyu and Zhang, Xulu and Wei, Xiao-Yong and Chen, Chang Wen and Li, Qing},
title = {Prior Knowledge Integration via LLM Encoding and Pseudo Event Regulation for Video Moment Retrieval},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681115},
doi = {10.1145/3664647.3681115},
abstract = {In this paper, we explore the use of large language models (LLMs) to enhance video moment retrieval (VMR) by integrating general knowledge and pseudo-events as priors. We address the limitations of LLMs in generating continuous outputs, such as salience scores and inter-frame embeddings, which are critical for capturing inter-frame relations. To address these limitations, we propose using LLM encoders, which refine inter-concept relations in multimodal embeddings effectively, even without textual training. Our feasibility study shows that this capability extends to other embeddings like BLIP and T5 when they exhibit similar patterns to CLIP embeddings. We present a general framework for integrating LLM encoders into existing VMR architectures, specifically within the fusion module. The LLM encoder's ability to refine concept relation can help the model to achieve a balanced understanding of the foreground concepts (e.g., persons, faces) and background concepts (e.g., street, mountains) rather focusing only on the visually dominant foreground concepts. Additionally, we utilize pseudo-events, identified via event detection, to guide accurate moment prediction within event boundaries, reducing distractions from adjacent moments. Our plug-in approach for semantic refinement and pseudo-event regulation demonstrates state-of-the-art VMR performance through experimental validation. The source code can be accessed at https://github.com/fletcherjiang/LLMEPET.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {7249–7258},
numpages = {10},
keywords = {highlight detection, llms, video moment retrieval},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3639478.3643526,
author = {Fakhoury, Sarah and Chakraborty, Saikat and Musuvathi, Madanlal and Lahiri, Shuvendu K.},
title = {NL2Fix: Generating Functionally Correct Code Edits from Bug Descriptions},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3643526},
doi = {10.1145/3639478.3643526},
abstract = {Despite the notable advancement of Large Language Models for Code Generation, there is a distinct gap in benchmark datasets and evaluation of LLMs' proficiency in generating functionally correct code edits based on natural language descriptions of intended changes. We address this void by presenting the challenge of translating natural language descriptions of code changes, particularly bug fixes outlined in Issue reports within repositories, into accurate code fixes. To tackle this issue, we introduce Defects4J-Nl2fix, a dataset comprising 283 Java programs from the widely-used Defects4J dataset, augmented with high-level descriptions of bug fixes. Subsequently, we empirically evaluate three state-of-the-art LLMs on this task, exploring the impact of different prompting strategies on their ability to generate functionally correct edits. Results show varied ability across models on this novel task. Collectively, the studied LLMs are able to produce plausible fixes for 64.6% of the bugs.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {410–411},
numpages = {2},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@article{10.1145/3695995,
author = {Huang, Yuekai and Wang, Junjie and Wang, Song and Wei, Moshi and Shi, Lin and Liu, Zhe and Wang, Qing},
title = {Deep API Sequence Generation via Golden Solution Samples and API Seeds},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3695995},
doi = {10.1145/3695995},
abstract = {Automatic API recommendation can accelerate developers’ programming and has been studied for years. There are two orthogonal lines of approaches for this task, i.e., information retrieval-based (IR-based) approaches and sequence to sequence (seq2seq) model-based approaches. Although these approaches were reported to have remarkable performance, our observation finds two major drawbacks, i.e., IR-based approaches lack the consideration of relations among the recommended APIs, and seq2seq models do not model the API’s semantic meaning. To alleviate the above two problems, we propose APIGens, which is a retrieval-enhanced large language model (LLM)-based API recommendation approach to recommend an API sequence for a natural language query. The approach first retrieves similar programming questions in history based on the input natural language query, and then scores the results based on API documents via a scorer model. Finally, these results are used as samples for few-shot learning of LLM. To reduce the risk of encountering local optima, we also extract API seeds from the retrieved results to increase the search scope during the LLM generation process. The results show that our approach can achieve 48.41% ROUGE@10 on API sequence recommendation and the 82.61% MAP on API set recommendation, largely outperforming the state-of-the-art baselines.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
articleno = {44},
numpages = {21},
keywords = {API recommendation, deep learning, information retrieval, sequence generation, large language model}
}

@article{10.1145/3718088,
author = {Pinckney, Nathaniel and Batten, Christopher and Liu, Mingjie and Ren, Haoxing and Khailany, Brucek},
title = {Revisiting VerilogEval: A Year of Improvements in Large-Language Models for Hardware Code Generation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3718088},
doi = {10.1145/3718088},
abstract = {The application of large-language models (LLMs) to digital hardware code generation is an emerging field, with most LLMs primarily trained on natural language and software code. Hardware code like Verilog constitutes a small portion of training data, and few hardware benchmarks exist. The open-source VerilogEval benchmark, released in November 2023, provided a consistent evaluation framework for LLMs on code completion tasks. Since then, both commercial and open models have seen significant development. In this work, we evaluate new commercial and open models since VerilogEval’s original release—including GPT-4o, GPT-4 Turbo, Llama3.1 (8B/70B/405B), Llama3 70B, Mistral Large, DeepSeek Coder (33B and 6.7B), CodeGemma 7B, and RTL-Coder—against an improved VerilogEval benchmark suite. We find measurable improvements in state-of-the-art models: GPT-4o achieves a 63% pass rate on specification-to-RTL tasks. The recently released and open Llama3.1 405B achieves a 58% pass rate, almost matching GPT-4o, while the smaller domain-specific RTL-Coder 6.7B models achieve an impressive 34% pass rate. Additionally, we enhance VerilogEval’s infrastructure by automatically classifying failures, introducing in-context learning support, and extending the tasks to specification-to-RTL translation. We find that prompt engineering remains crucial for achieving good pass rates and varies widely with model and task. A benchmark infrastructure that allows for prompt engineering and failure analysis is essential for continued model development and deployment.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = feb,
keywords = {large language models, RTL code generation, benchmarks}
}

@inproceedings{10.1145/3649329.3657323,
author = {Koo, Jahyun and Park, Dahoon and Jung, Sangwoo and Kung, Jaeha},
title = {OPAL: Outlier-Preserved Microscaling Quantization Accelerator for Generative Large Language Models},
year = {2024},
isbn = {9798400706011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649329.3657323},
doi = {10.1145/3649329.3657323},
abstract = {To overcome the burden on the memory size and bandwidth due to ever-increasing size of large language models (LLMs), aggressive weight quantization has been recently studied, while lacking research on quantizing activations. In this paper, we present a hardware-software co-design method that results in an energy-efficient LLM accelerator, named OPAL, for generation tasks. First of all, a novel activation quantization method that leverages the microscaling data format while preserving several outliers per subtensor block (e.g., four out of 128 elements) is proposed. Second, on top of preserving outliers, mixed precision is utilized that sets 5-bit for inputs to sensitive layers in the decoder block of an LLM, while keeping inputs to less sensitive layers to 3-bit. Finally, we present the OPAL hardware architecture that consists of FP units for handling outliers and vectorized INT multipliers for dominant non-outlier related operations. In addition, OPAL uses log2-based approximation on softmax operations that only requires shift and subtraction to maximize power efficiency. As a result, we are able to improve the energy efficiency by 1.6~2.2\texttimes{}, and reduce the area by 2.4~3.1\texttimes{} with negligible accuracy loss, i.e., &lt;1 perplexity increase.},
booktitle = {Proceedings of the 61st ACM/IEEE Design Automation Conference},
articleno = {259},
numpages = {6},
location = {San Francisco, CA, USA},
series = {DAC '24}
}

@inproceedings{10.1145/3703790.3703792,
author = {Espinal, Wendy Yunuen Arevalo and Jimenez, Jaime and Corneo, Lorenzo},
title = {An eXtended Reality Data Transformation Framework for Internet of Things Devices Integration},
year = {2025},
isbn = {9798400712852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703790.3703792},
doi = {10.1145/3703790.3703792},
abstract = {The multidisciplinary nature of XR applications makes device and data integration a resource-intensive and time-consuming task, especially in the context of the Internet of Things (IoT).This paper presents Visualize Interactive Objects, VIO for short, a data transformation framework aimed at simplifying visualization and interaction of IoT devices and their data into XR applications. VIO comprises a software runtime&nbsp;(VRT) running on XR headsets, and a JSON-based syntax for defining VIO Descriptions (VDs). The VRT interprets VDs to facilitate visualization and interaction within the application. By raising the level of abstraction, VIO enhances interoperability among XR experiences and enables developers to integrate IoT data with minimal coding effort.A comprehensive evaluation demonstrated that VIO is lightweight, incurring in negligible overhead compared to native implementations. Ten Large Language Models (LLM) were used to generate VDs and native source-code from user intents. The results showed that LLMs have superior syntactical and semantical accuracy in generating VDs compared to native XR application development code, thus indicating that the task of creating VDs can be effectively automated using LLMs. Additionally, a user study with 12 participants found that VIO is developer-friendly and easily extensible.},
booktitle = {Proceedings of the 14th International Conference on the Internet of Things},
pages = {10–18},
numpages = {9},
keywords = {Extended Reality, Internet of Things, Data Transformation, Device and Data Integration, Generative AI},
location = {
},
series = {IoT '24}
}

@inproceedings{10.1145/3664647.3681464,
author = {Wang, Zhanyu and Wang, Longyue and Zhao, Zhen and Wu, Minghao and Lyu, Chenyang and Li, Huayang and Cai, Deng and Zhou, Luping and Shi, Shuming and Tu, Zhaopeng},
title = {GPT4Video: A Unified Multimodal Large Language Model for lnstruction-Followed Understanding and Safety-Aware Generation},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681464},
doi = {10.1145/3664647.3681464},
abstract = {Recent advances in Multimodal Large Language Models (MLLMs) have constituted a significant leap forward in the field, particularly in the processing of videos, which encompasses inherent challenges such as spatiotemporal relationships. However, existing MLLMs are predominantly focused on the comprehension of video inputs, with limited capabilities in generating video content. In this paper, we present GPT4Video, a unified framework that seamlessly and lightly integrates with LLMs, visual feature extractors, and stable diffusion generative models for cohesive video understanding and generation. Moreover, we explore a text-only finetuning approach to equip models for instruction-following and safeguarding in multimodal conversations, enhancing training efficiency and generalization capabilities. Additionally, we construct multi-turn and caption-interleaved datasets for finetuning and benchmarking MLLMs, which serve as solid resources for advancing this field. Through quantitative and qualitative assessments, GPT4Video demonstrates the following advantages: 1) The framework incorporates video generation ability without adding extra training parameters, ensuring seamless compatibility with various video generators. 2) The model achieves superior performances across a variety of benchmarks. For instance, it outperforms Valley by 11.8% on video question answering, and surpasses NExt-GPT by 2.3% on text-to-video generation. 3) As safety pioneers in open-source MLLMs, we developed finetuning and evaluation datasets, securing an F1 score exceeding 80% in blocking harmful content during understanding and generating videos. In general, GPT4Video shows potential to function as a real-life assistant, marked by its effectiveness, adaptability, and safety.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3907–3916},
numpages = {10},
keywords = {data construction, instruction-following, multimodal large language model, safeguarding, video understanding and generation},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3706599.3720284,
author = {Gadhvi, Rushiraj and Petkar, Soham and Desai, Priyansh Pankajkumar and Ramachandran, Shreyas and Siddharth, Siddharth},
title = {AdaptAI: A Personalized Solution to Sense Your Stress, Fix Your Mess, and Boost Productivity},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720284},
doi = {10.1145/3706599.3720284},
abstract = {Personalization is a critical yet often overlooked factor in boosting productivity and well-being in knowledge-intensive workplaces to better address individual preferences. Existing tools typically offer uniform guidance, whether auto-generating email responses or prompting break reminders, without accounting for individual behavioral patterns or stress triggers. We introduce AdaptAI, a multimodal AI solution combining egocentric vision and audio, heart and motion activities, and the agentic workflow of Large Language Models (LLMs) to deliver highly personalized productivity support and context-aware well-being interventions. AdaptAI not only automates peripheral tasks (e.g., drafting succinct document summaries, replying to emails, etc.) but also continuously monitors the user’s unique physiological and situational indicators to dynamically tailor interventions, such as micro-break suggestions or exercise prompts, at the exact point of need. In a preliminary study with 15 participants, AdaptAI demonstrated significant improvements in task throughput and user satisfaction by anticipating user stressors and streamlining daily workflows.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {60},
numpages = {12},
keywords = {workplace productivity, AI personalization, large language models, vision language models, multimodal sensing, context awareness},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641399.3641419,
author = {Sikand, Samarth and Phokela, Kanchanjot Kaur and Sharma, Vibhu Saujanya and Singi, Kapil and Kaulgud, Vikrant and Tung, Teresa and Sharma, Pragya and Burden, Adam P.},
title = {How much SPACE do metrics have in GenAI assisted software development?},
year = {2024},
isbn = {9798400717673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641399.3641419},
doi = {10.1145/3641399.3641419},
abstract = {Large Language Models (LLMs) are revolutionizing the way a developer creates software by replacing code with natural language prompts as primary drivers. While many initial assessments of such LLMs suggest that it helps with developer productivity, other research studies have also pointed out areas in the Software Development Life Cycle(SDLC) and developer experience where such tools fail miserably. Currently, there exist many studies dedicated to evaluation of LLM-based AI-assisted software tools but there lacks a standardization of studies and metrics which may prove to be a hindrance to adoption of metrics and reproducible studies. The primary objective of this survey is to assess the recent user studies and surveys, aimed at evaluating different aspects of developer’s experience of using code-based LLMs, and highlight any existing gaps among them. We have leveraged the SPACE framework to enumerate and categorise metrics from studies conducting some form of controlled user experiments. In Generative AI assisted SDLC, the developer’s experience should encompass the ability to perform the in-hand task efficiently and effectively, with minimal friction using these LLM tools. Our exploration has led to some critical insights regarding complete absence of user studies in Collaborative aspects of teams, bias towards certain LLM models &amp; metrics and lack of diversity in metrics within productivity dimensions. We also propose some recommendations to the research community which will help bring some conformity in the evaluation of such LLMs.},
booktitle = {Proceedings of the 17th Innovations in Software Engineering Conference},
articleno = {14},
numpages = {5},
keywords = {Developer Productivity, Generative AI, Metrics, SDLC, Software},
location = {Bangalore, India},
series = {ISEC '24}
}

@article{10.1145/3704263,
author = {Chen, Lei and Gao, Chen and Du, Xiaoyi and Luo, Hengliang and Jin, Depeng and Li, Yong and Wang, Meng},
title = {Enhancing ID-based Recommendation with Large Language Models},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3704263},
doi = {10.1145/3704263},
abstract = {Large Language Models (LLMs) have recently garnered significant attention in various domains, including recommendation systems. Recent research leverages the capabilities of LLMs to improve the performance and user modeling aspects of recommender systems. These studies primarily focus on utilizing LLMs to interpret textual data in recommendation tasks. However, it's worth noting that in ID-based recommendations, textual data is absent, and only ID data is available. The untapped potential of LLMs for ID data within the ID-based recommendation paradigm remains relatively unexplored. To this end, we introduce a pioneering approach called “LLM for ID-based Recommendation” (LLM4IDRec). This innovative approach integrates the capabilities of LLMs while exclusively relying on ID data, thus diverging from the previous reliance on textual data. The basic idea of LLM4IDRec is that by employing LLM to augment ID data, if augmented ID data can improve recommendation performance, it demonstrates the ability of LLM to interpret ID data effectively, exploring an innovative way for the integration of LLM in ID-based recommendation. Specifically, we first define a prompt template to enhance LLM's ability to comprehend ID data and the ID-based recommendation task. Next, during the process of generating training data using this prompt template, we develop two efficient methods to capture both the local and global structure of ID data. We feed this generated training data into the LLM and employ LoRA for fine-tuning LLM. Following the fine-tuning phase, we utilize the fine-tuned LLM to generate ID data that aligns with users’ preferences. We design two filtering strategies to eliminate invalid generated data. Thirdly, we can merge the original ID data with the generated ID data, creating augmented data. Finally, we input this augmented data into the existing ID-based recommendation models without any modifications to the recommendation model itself. We evaluate the effectiveness of our LLM4IDRec approach using three widely-used datasets. Our results demonstrate a notable improvement in recommendation performance, with our approach consistently outperforming existing methods in ID-based recommendation by solely augmenting input data.},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = nov,
keywords = {Large Language Model, ID-based recommendation, Data augmentation}
}

@inbook{10.1145/3658617.3697736,
author = {Chen, Lin and Chen, Ran and Hu, Shoubo and Yao, Xufeng and Tang, Zhentao and Kai, Shixiong and Xu, Siyuan and Yuan, Mingxuan and Hao, Jianye and Yu, Bei and Xu, Jiang},
title = {PCBAgent: An Agent-based Framework for High-Density Printed Circuit Board Placement},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697736},
abstract = {Recently, printed circuit board (PCB) placement has emerged as a significant challenge since the scale of PCB designs has rapidly enlarged. Furthermore, the presence of various types of constraints with differing tolerance priorities hampers the automation of PCB layout design, necessitating substantial manual effort. To address this problem, we introduce a novel agent-based framework that automatically generates PCB layouts meeting industrial constraints through user interactions. This framework includes two main agents: a reinforcement learning (RL)-based agent for layout inference and fine-tuning, and a large language model (LLM)-based agent for interactive optimization. Experimental results on 17 industrial tasks show that our framework outperforms other state-of-the-art methods.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {781–787},
numpages = {7}
}

@inproceedings{10.1145/3664647.3681659,
author = {Li, Yingxuan and Hinami, Ryota and Aizawa, Kiyoharu and Matsui, Yusuke},
title = {Zero-Shot Character Identification and Speaker Prediction in Comics via Iterative Multimodal Fusion},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681659},
doi = {10.1145/3664647.3681659},
abstract = {Recognizing characters and predicting speakers of dialogue are critical for comic processing tasks, such as voice generation or translation. However, because characters vary by comic title, supervised learning approaches like training character classifiers which require specific annotations for each comic title are infeasible. This motivates us to propose a novel zero-shot approach, allowing machines to identify characters and predict speaker names based solely on unannotated comic images. In spite of their importance in real-world applications, these task have largely remained unexplored due to challenges in story comprehension and multimodal integration. Recent large language models (LLMs) have shown great capability for text understanding and reasoning, while their application to multimodal content analysis is still an open problem. To address this problem, we propose an iterative multimodal framework, the first to employ multimodal information for both character identification and speaker prediction tasks. Our experiments demonstrate the effectiveness of the proposed framework, establishing a robust baseline for these tasks. Furthermore, since our method requires no training data or annotations, it can be used as-is on any comic series.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {7366–7374},
numpages = {9},
keywords = {character identification, comics understanding, multimodal content analysis, speaker prediction, zero-shot learning},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3638530.3654426,
author = {Vella Zarb, David and Parks, Geoff and Kipouros, Timoleon},
title = {Synergistic Utilization of LLMs for Program Synthesis},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3654426},
doi = {10.1145/3638530.3654426},
abstract = {Advances in Large Language Models (LLMs) have led them to be used as black boxes in several evolutionary algorithms for program synthesis. While these methods tend to be agnostic about which model is used, they only allow for using one. This paper suggests that using a combination of LLMs to seed population-based algorithms introduces more variation and leads to a wider variety of problems that can be solved, due to leveraging the strengths of component LLMs. We test this on the PSB2 suite, using the Search, Execute, Instruct, Debug and Rank (SEIDR) algorithm. In all cases examined, we find that using a combination of LLMs leads to more problems solved and better test pass rates compared to using the best individual model. We also find that the computational cost, as measured in terms of excess programs generated, is lowered.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {539–542},
numpages = {4},
keywords = {program synthesis, large language models, evolutionary algorithms},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{10.1145/3638529.3654178,
author = {Morris, Clint and Jurado, Michael and Zutty, Jason},
title = {LLM Guided Evolution - The Automation of Models Advancing Models},
year = {2024},
isbn = {9798400704949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638529.3654178},
doi = {10.1145/3638529.3654178},
abstract = {In the realm of machine learning, traditional model development and automated approaches like AutoML typically rely on layers of abstraction, such as tree-based or Cartesian genetic programming. Our study introduces "Guided Evolution" (GE), a novel framework that diverges from these methods by utilizing Large Language Models (LLMs) to directly modify code. GE leverages LLMs for a more intelligent, supervised evolutionary process, guiding mutations and crossovers. Our unique "Evolution of Thought" (EoT) technique further enhances GE by enabling LLMs to reflect on and learn from the outcomes of previous mutations. This results in a self-sustaining feedback loop that augments decision-making in model evolution. GE maintains genetic diversity, crucial for evolutionary algorithms, by leveraging LLMs' capability to generate diverse responses from expertly crafted prompts and modulate model temperature. This not only accelerates the evolution process but also injects expert like creativity and insight into the process. Our application of GE in evolving the ExquisiteNetV2 model demonstrates its efficacy: the LLM-driven GE autonomously produced variants with improved accuracy, increasing from 92.52% to 93.34%, without compromising model compactness. This underscores the potential of LLMs to accelerate the traditional model design pipeline, enabling models to autonomously evolve and enhance their own designs.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {377–384},
numpages = {8},
keywords = {large language models, automated machine learning, evolutionary algorithms},
location = {Melbourne, VIC, Australia},
series = {GECCO '24}
}

@inproceedings{10.1145/3698204.3716468,
author = {Ran, Kun and Alaofi, Marwah and Sanderson, Mark and Spina, Damiano},
title = {Two Heads Are Better Than One: Improving Search Effectiveness Through LLM-Generated Query Variants},
year = {2025},
isbn = {9798400712906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698204.3716468},
doi = {10.1145/3698204.3716468},
abstract = {User query quality impacts retrieval effectiveness. This study categorizes thousands of user queries spanning one hundred topics into three groups – low, medium, and high quality – based on NDCG@10 scores. The study investigates the impact of fusing search results of Large Language Model (LLM)-generated query variants with results retrieved from user queries drawn from the three groups, similar to a collaborative search approach where users with diverse queries collaborate in locating relevant information. The findings indicate that a traditional search system can be significantly improved by fusing results for low-quality queries, offering a promising solution for users who struggle to find relevant information, particularly in contexts where advanced search systems are impractical due to technical or resource constraints, or where access to query logs are unavailable.},
booktitle = {Proceedings of the 2025 ACM SIGIR Conference on Human Information Interaction and Retrieval},
pages = {333–341},
numpages = {9},
keywords = {Query Variants, Large Language Models, Ranking Fusion},
location = {
},
series = {CHIIR '25}
}

@inproceedings{10.1145/3677389.3702514,
author = {Balakireva, Lyudmila and Klein, Martin},
title = {Unlocking Scholarly Insights: Leveraging Machine Learning Approaches for Citation Analysis and Intent Classification.},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702514},
doi = {10.1145/3677389.3702514},
abstract = {Publicly funded organizations, notably institutions like the Los Alamos National Laboratory (LANL), are deeply vested in acquiring robust productivity metrics to gauge the entirety of their research output. This study explores the use of Large Language Models (LLMs), including BERT-based models, LLaMa-30b-instruct, and Mixtral-8x7b-instruct, for classifying URL-referenced resources (e.g., software, datasets) and determining authorship intent. We highlight the challenges of identifying resource types and the potential of BERT and LLMs to overcome them. Our analysis shows a growing number of URL citations, reflecting the increasing importance of digital resources. Our findings also reveal that LANL authors contribute substantially to accessible science, comprising about 10% of dataset and software mentions in LANL publications.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {26},
numpages = {5},
keywords = {large language models, BERT, citation classification},
location = {Hong Kong, China},
series = {JCDL '24}
}

@article{10.1145/3663485,
author = {Morales-Garc\'{\i}a, Juan and Llanes, Antonio and Arcas-T\'{u}nez, Francisco and Terroso-S\'{a}enz, Fernando},
title = {Developing Time Series Forecasting Models with Generative Large Language Models},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3663485},
doi = {10.1145/3663485},
abstract = {Nowadays, Generative Large Language Models (GLLMs) have made a significant impact in the field of Artificial Intelligence (AI). One of the domains extensively explored for these models is their ability as generators of functional source code for software projects. Nevertheless, their potential as assistants to write the code needed to generate and model Machine Learning (ML) or Deep Learning (DL) architectures has not been fully explored to date. For this reason, this work focuses on evaluating the extent to which different tools based on GLLMs, such as ChatGPT or Copilot, are able to correctly define the source code necessary to generate viable predictive models. The use case defined is the forecasting of a time series that reports the indoor temperature of a greenhouse. The results indicate that, while it is possible to achieve good accuracy metrics with simple predictive models generated by GLLMs, the composition of predictive models with complex architectures using GLLMs is still far from improving the accuracy of predictive models generated by human data scientists.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
keywords = {Deep Learning, Generative Large Language Models (GLLMs), ChatGPT, Copilot, Time series forecasting}
}

@inproceedings{10.1145/3613905.3650764,
author = {Englhardt, Zachary and Li, Richard and Nissanka, Dilini and Zhang, Zhihan and Narayanswamy, Girish and Breda, Joseph and Liu, Xin and Patel, Shwetak and Iyer, Vikram},
title = {Exploring and Characterizing Large Language Models for Embedded System Development and Debugging},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650764},
doi = {10.1145/3613905.3650764},
abstract = {Large language models (LLMs) have shown remarkable abilities to generate code. However, their ability to develop software for physical computing and embedded systems, which requires cross-domain hardware and software knowledge, has not been thoroughly studied. We observe through our experiments and a 15-user pilot study that even when LLMs fail to produce working code, they can generate helpful reasoning about embedded design tasks, as well as specific debugging suggestions for both novice and expert developers. These results highlight the potential to develop AI assistants to dramatically lower the barrier to entry for working with hardware. To evaluate the capabilities and limitations of LLMs, we develop an automated testbench to quantify LLM performance on embedded programming tasks and perform 450 trials. We leverage these findings to analyze how programmers interact with these tools including their productivity and sense of fulfillment and outline a human-AI collaborative workflow for developing and debugging embedded systems.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {150},
numpages = {9},
keywords = {Embedded Systems Development, GPT, Large Language Models},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3639478.3640024,
author = {Sapozhnikov, Arkadii and Olsthoorn, Mitchell and Panichella, Annibale and Kovalenko, Vladimir and Derakhshanfar, Pouria},
title = {TestSpark: IntelliJ IDEA's Ultimate Test Generation Companion},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3640024},
doi = {10.1145/3639478.3640024},
abstract = {Writing software tests is laborious and time-consuming. To address this, prior studies introduced various automated test-generation techniques. A well-explored research direction in this field is unit test generation, wherein artificial intelligence (AI) techniques create tests for a method/class under test. While many of these techniques have primarily found applications in a research context, existing tools (e.g., EvoSuite, Randoop, and AthenaTest) are not user-friendly and are tailored to a single technique. This paper introduces Test-Spark, a plugin for IntelliJ IDEA that enables users to generate unit tests with only a few clicks directly within their Integrated Development Environment (IDE). Furthermore, TestSpark also allows users to easily modify and run each generated test and integrate them into the project workflow. TestSpark leverages the advances of search-based test generation tools, and it introduces a technique to generate unit tests using Large Language Models (LLMs) by creating a feedback cycle between the IDE and the LLM. Since TestSpark is an open-source (https://github.com/JetBrains-Research/TestSpark), extendable, and well-documented tool, it is possible to add new test generation methods into the plugin with the minimum effort. This paper also explains our future studies related to TestSpark and our preliminary results. Demo video: https://youtu.be/0F4PrxWfiXo},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {30–34},
numpages = {5},
keywords = {unit test generation, intellij idea plugin, large language models},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3650212.3652115,
author = {Zeng, Zhengran and Wang, Yidong and Xie, Rui and Ye, Wei and Zhang, Shikun},
title = {CoderUJB: An Executable and Unified Java Benchmark for Practical Programming Scenarios},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3652115},
doi = {10.1145/3650212.3652115},
abstract = {In the evolving landscape of large language models (LLMs) tailored for software engineering, the need for benchmarks that accurately reflect real-world development scenarios is paramount. Current benchmarks are either too simplistic or fail to capture the multi-tasking nature of software development. To address this, we introduce CoderUJB, a new benchmark designed to evaluate LLMs across diverse Java programming tasks that are executable and reflective of actual development scenarios, acknowledging Java's prevalence in real-world software production. CoderUJB comprises 2,239 programming questions derived from 17 real open-source Java projects and spans five practical programming tasks. Our empirical study on this benchmark investigates the coding abilities of various open-source and closed-source LLMs, examining the effects of continued pre-training in specific programming languages code and instruction fine-tuning on their performance. The findings indicate that while LLMs exhibit strong potential, challenges remain, particularly in non-functional code generation (e.g., test generation and defect detection). Importantly, our results advise caution in the specific programming languages continued pre-training and instruction fine-tuning, as these techniques could hinder model performance on certain tasks, suggesting the need for more nuanced strategies. CoderUJB thus marks a significant step towards more realistic evaluations of programming capabilities in LLMs, and our study provides valuable insights for the future development of these models in software engineering.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {124–136},
numpages = {13},
keywords = {Benchmark, Code Generation, Large Language Models},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3627508.3638298,
author = {V\"{o}lker, Tom and Pfister, Jan and Koopmann, Tobias and Hotho, Andreas},
title = {From Chat to Publication Management: Organizing your related work using BibSonomy &amp; LLMs},
year = {2024},
isbn = {9798400704345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627508.3638298},
doi = {10.1145/3627508.3638298},
abstract = {The ever-growing corpus of scientific literature presents significant challenges for researchers with respect to discovery, management, and annotation of relevant publications. Traditional platforms like Semantic Scholar, BibSonomy, and Zotero offer tools for literature management, but largely require manual laborious and error-prone input of tags and metadata. Here, we introduce a novel retrieval augmented generation system that leverages chat-based large language models (LLMs) to streamline and enhance the process of publication management. It provides a unified chat-based interface, enabling intuitive interactions with various backends, including Semantic Scholar, BibSonomy, and the Zotero Webscraper. It supports two main use-cases: (1) Explorative Search &amp; Retrieval - leveraging LLMs to search for and retrieve both specific and general scientific publications, while addressing the challenges of content hallucination and data obsolescence; and (2) Cataloguing &amp; Management - aiding in the organization of personal publication libraries, in this case BibSonomy, by automating the addition of metadata and tags, while facilitating manual edits and updates. We compare our system to different LLM models in three different settings, including a user study, and we can show its advantages in different metrics.},
booktitle = {Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
pages = {386–390},
numpages = {5},
keywords = {Academic Search, ChatGPT, Publication Management, RAG},
location = {Sheffield, United Kingdom},
series = {CHIIR '24}
}

@article{10.1145/3654930,
author = {Li, Haoyang and Zhang, Jing and Liu, Hanbing and Fan, Ju and Zhang, Xiaokang and Zhu, Jun and Wei, Renjie and Pan, Hongyan and Li, Cuiping and Chen, Hong},
title = {CodeS: Towards Building Open-source Language Models for Text-to-SQL},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654930},
doi = {10.1145/3654930},
abstract = {Language models have shown promising performance on the task of translating natural language questions into SQL queries (Text-to-SQL). However, most of the state-of-the-art (SOTA) approaches rely on powerful yet closed-source large language models (LLMs), such as ChatGPT and GPT-4, which may have the limitations of unclear model architectures, data privacy risks, and expensive inference overheads. To address the limitations, we introduce CodeS, a series of pre-trained language models with parameters ranging from 1B to 15B, specifically designed for the text-to-SQL task. CodeS is a fully open-source language model, which achieves superior accuracy with much smaller parameter sizes. This paper studies the research challenges in building CodeS. To enhance the SQL generation abilities of CodeS, we adopt an incremental pre-training approach using a specifically curated SQL-centric corpus. Based on this, we address the challenges of schema linking and rapid domain adaptation through strategic prompt construction and a bi-directional data augmentation technique. We conduct comprehensive evaluations on multiple datasets, including the widely used Spider benchmark, the newly released BIRD benchmark, robustness-diagnostic benchmarks such as Spider-DK, Spider-Syn, Spider-Realistic, and Dr.Spider, as well as two real-world datasets created for financial and academic applications. The experimental results show that our CodeS achieves new SOTA accuracy and robustness on nearly all challenging text-to-SQL benchmarks.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {127},
numpages = {28},
keywords = {language model, natural language interface for databases, text-to-SQL}
}

@inproceedings{10.1145/3650212.3652135,
author = {Lu, You and Tian, Yifan and Bi, Yuyang and Chen, Bihuan and Peng, Xin},
title = {DiaVio: LLM-Empowered Diagnosis of Safety Violations in ADS Simulation Testing},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3652135},
doi = {10.1145/3650212.3652135},
abstract = {Simulation testing has been widely adopted by leading companies to ensure the safety of autonomous driving systems (ADSs). Anumber of scenario-based testing approaches have been developed to generate diverse driving scenarios for simulation testing, and demonstrated to be capable of finding safety violations. However, there is no automated way to diagnose whether these violations are caused by the ADS under test and which category these violations belong to. As a result, great effort is required to manually diagnose violations. 
 

 
To bridge this gap, we propose DiaVio to automatically diagnose safety violations in simulation testing by leveraging large language models (LLMs). It is built on top of a new domain specific language (DSL) of crash to align real-world accident reports described in natural language and violation scenarios in simulation testing. DiaVio fine-tunes a base LLM with real-world accident reports to learn diagnosis capability, and uses the fine-tuned LLM to diagnose violation scenarios in simulation testing. Our evaluation has demonstrated the effectiveness and efficiency of DiaVio in violation diagnosis.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {376–388},
numpages = {13},
keywords = {Automated Driving System, Large Language Models, Scenario-based Testing, Violation Diagnosis},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@article{10.1145/3736402,
author = {Meng, Chuan and Arabzadeh, Negar and Askari, Arian and Aliannejadi, Mohammad and de Rijke, Maarten},
title = {Query Performance Prediction using Relevance Judgments Generated by Large Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3736402},
doi = {10.1145/3736402},
abstract = {Query performance prediction (QPP) aims to estimate the retrieval quality of a search system for a query without human relevance judgments. Previous QPP methods typically return a single scalar value and do not require the predicted values to approximate a specific information retrieval (IR) evaluation measure, leading to certain drawbacks: (i) a single scalar is insufficient to accurately represent different IR evaluation measures, especially when metrics do not highly correlate, and (ii) a single scalar limits the interpretability of QPP methods because solely using a scalar is insufficient to explain QPP results. To address these issues, we propose a QPP framework using automatically generated relevance judgments (QPP-GenRE), which decomposes QPP into independent subtasks of predicting the relevance of each item in a ranked list to a given query. This allows us to predict any IR evaluation measure using the generated relevance judgments as pseudo-labels. This also allows us to interpret predicted IR evaluation measures, and identify, track and rectify errors in generated relevance judgments to improve QPP quality. We predict an item’s relevance by using open-source large language models (LLMs) to ensure scientific reproducibility.We face two main challenges: (i) excessive computational costs of judging an entire corpus for predicting a metric considering recall, and (ii) limited performance in prompting open-source LLMs in a zero-/few-shot manner. To solve the challenges, we devise an approximation strategy to predict an IR measure considering recall and propose to fine-tune open-source LLMs using human-labeled relevance judgments. Experiments on the TREC 2019–2022 deep learning tracks and CAsT-19–20 datasets show that QPP-GenRE achieves state-of-the-art QPP quality for both lexical and neural rankers.},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = may,
keywords = {Query performance prediction, Large language models, Relevance judgments, Relevance prediction, Re-ranking, Conversational search}
}

@inproceedings{10.1145/3689031.3696075,
author = {Sheng, Guangming and Zhang, Chi and Ye, Zilingfeng and Wu, Xibin and Zhang, Wang and Zhang, Ru and Peng, Yanghua and Lin, Haibin and Wu, Chuan},
title = {HybridFlow: A Flexible and Efficient RLHF Framework},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689031.3696075},
doi = {10.1145/3689031.3696075},
abstract = {Reinforcement Learning from Human Feedback (RLHF) is widely used in Large Language Model (LLM) alignment. Traditional RL can be modeled as a dataflow, where each node represents computation of a neural network (NN) and each edge denotes data dependencies between the NNs. RLHF complicates the dataflow by expanding each node into a distributed LLM training or generation program, and each edge into a many-to-many multicast. Traditional RL frameworks execute the dataflow using a single controller to instruct both intra-node computation and inter-node communication, which can be inefficient in RLHF due to large control dispatch overhead for distributed intra-node computation. Existing RLHF systems adopt a multi-controller paradigm, which can be inflexible due to nesting distributed computation and data communication. We propose HybridFlow, which combines single-controller and multi-controller paradigms in a hybrid manner to enable flexible representation and efficient execution of the RLHF data flow. We carefully design a set of hierarchical APIs that decouple and encapsulate computation and data dependencies in the complex RLHF dataflow, allowing efficient operation orchestration to implement RLHF algorithms and flexible mapping of the computation onto various devices. We further design a 3D-HybridEngine for efficient actor model resharding between training and generation phases, with zero memory redundancy and significantly reduced communication overhead. Our experimental results demonstrate 1.53x~20.57\texttimes{} throughput improvement when running various RLHF algorithms using HybridFlow, as compared with state-of-the-art baselines. HybridFlow source code is available at https://github.com/volcengine/verl},
booktitle = {Proceedings of the Twentieth European Conference on Computer Systems},
pages = {1279–1297},
numpages = {19},
keywords = {Distributed systems, Reinforcement Learning from Human Feedback},
location = {Rotterdam, Netherlands},
series = {EuroSys '25}
}

@article{10.1145/3704997,
author = {Renzullo, Joseph and Reiter, Pemma and Weimer, Westley and Forrest, Stephanie},
title = {Automated Program Repair: Emerging Trends Pose and Expose Problems for Benchmarks},
year = {2025},
issue_date = {August 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {8},
issn = {0360-0300},
url = {https://doi.org/10.1145/3704997},
doi = {10.1145/3704997},
abstract = {Machine learning (ML) pervades the field of Automated Program Repair (APR). Algorithms deploy neural machine translation and large language models (LLMs) to generate software patches, among other tasks. But, there are important differences between these applications of ML and earlier work, which complicates the task of ensuring that results are valid and likely to generalize. A challenge is that the most popular APR evaluation benchmarks were not designed with ML techniques in mind. This is especially true for LLMs, whose large and often poorly-disclosed training datasets may include problems on which they are evaluated.This article reviews work in APR published in the field’s top five venues since 2018, emphasizing emerging trends in the field, including the dramatic rise of ML models, including LLMs. ML-based articles are categorized along structural and functional dimensions, and a variety of issues are identified that these new methods raise. Importantly, data leakage and contamination concerns arise from the challenge of validating ML-based APR using existing benchmarks, which were designed before these techniques were popular. We discuss inconsistencies in evaluation design and performance reporting and offer pointers to solutions where they are available. Finally, we highlight promising new directions that the field is already taking.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {208},
numpages = {18},
keywords = {automated program repair, machine learning, benchmarks, patch quality}
}

@inproceedings{10.1145/3597503.3608134,
author = {Geng, Mingyang and Wang, Shangwen and Dong, Dezun and Wang, Haotian and Li, Ge and Jin, Zhi and Mao, Xiaoguang and Liao, Xiangke},
title = {Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3608134},
doi = {10.1145/3597503.3608134},
abstract = {Code comment generation aims at generating natural language descriptions for a code snippet to facilitate developers' program comprehension activities. Despite being studied for a long time, a bottleneck for existing approaches is that given a code snippet, they can only generate one comment while developers usually need to know information from diverse perspectives such as what is the functionality of this code snippet and how to use it. To tackle this limitation, this study empirically investigates the feasibility of utilizing large language models (LLMs) to generate comments that can fulfill developers' diverse intents. Our intuition is based on the facts that (1) the code and its pairwise comment are used during the pre-training process of LLMs to build the semantic connection between the natural language and programming language, and (2) comments in the real-world projects, which are collected for the pre-training, usually contain different developers' intents. We thus postulate that the LLMs can already understand the code from different perspectives after the pre-training. Indeed, experiments on two large-scale datasets demonstrate the rationale of our insights: by adopting the in-context learning paradigm and giving adequate prompts to the LLM (e.g., providing it with ten or more examples), the LLM can significantly outperform a state-of-the-art supervised learning approach on generating comments with multiple intents. Results also show that customized strategies for constructing the prompts and post-processing strategies for reranking the results can both boost the LLM's performances, which shed light on future research directions for using LLMs to achieve comment generation.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {39},
numpages = {13},
keywords = {code summarization, large language model, in-context learning},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3637528.3671918,
author = {Chen, Meng and Li, Zechen and Huang, Weiming and Gong, Yongshun and Yin, Yilong},
title = {Profiling Urban Streets: A Semi-Supervised Prediction Model Based on Street View Imagery and Spatial Topology},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671918},
doi = {10.1145/3637528.3671918},
abstract = {With the expansion and growth of cities, profiling urban areas with the advent of multi-modal urban datasets (e.g., points-of-interest and street view imagery) has become increasingly important in urban planing and management. Particularly, street view images have gained popularity for understanding the characteristics of urban areas due to its abundant visual information and inherent correlations with human activities. In this study, we define a street segment represented by multiple street view images as the minimum spatial unit for analysis and predict its functional and socioeconomic indicators, which presents several challenges in modeling spatial distributions of images on a street and the spatial topology (adjacency) of streets. Meanwhile, Large Language Models are capable of understanding imagery data based on its extraordinary knowledge base and unveil a remarkable opportunity for profiling streets with images. In view of the challenges and opportunity, we present a semi-supervised Urban Street Profiling Model (USPM) based on street view imagery and spatial adjacency of urban streets. Specifically, given a street with multiple images, we first employ a newly designed spatial context-based contrastive learning method to generate feature vectors of images and then apply the LSTM-based fusion method to encode multiple images on a street to yield the street visual representation; we then create the descriptions of street scenes for street view images based on the SPHINX (a large language model) and produce the street textual representation; finally, we build an urban street graph based on spatial topology (adjacency) and employ a semi-supervised graph learning algorithm to further encode the street representations for prediction. We conduct thorough experiments with real-world datasets to assess the proposed USPM. The experimental results demonstrate that USPM considerably outperforms baseline methods in two urban prediction tasks.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {319–328},
numpages = {10},
keywords = {large language model, street representation learning, street view imagery, urban street profiling},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3626772.3657951,
author = {Ma, Xueguang and Wang, Liang and Yang, Nan and Wei, Furu and Lin, Jimmy},
title = {Fine-Tuning LLaMA for Multi-Stage Text Retrieval},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657951},
doi = {10.1145/3626772.3657951},
abstract = {While large language models (LLMs) have shown impressive NLP capabilities, existing IR applications mainly focus on prompting LLMs to generate query expansions or generating permutations for listwise reranking. In this study, we leverage LLMs directly to serve as components in the widely used multi-stage text ranking pipeline. Specifically, we fine-tune the open-source LLaMA-2 model as a dense retriever (repLLaMA) and a pointwise reranker (rankLLaMA). This is performed for both passage and document retrieval tasks using the MS MARCO training data. Our study shows that finetuned LLM retrieval models outperform smaller models. They are more effective and exhibit greater generalizability, requiring only a straightforward training strategy. Moreover, our pipeline allows for the fine-tuning of LLMs at each stage of a multi-stage retrieval pipeline. This demonstrates the strong potential for optimizing LLMs to enhance a variety of retrieval tasks. Furthermore, as LLMs are naturally pre-trained with longer contexts, they can directly represent longer documents. This eliminates the need for heuristic segmenting and pooling strategies to rank long documents. On the MS MARCO and BEIR datasets, our repLLaMA-rankLLaMA pipeline demonstrates a high level of effectiveness.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2421–2425},
numpages = {5},
keywords = {dense retrieval, large language model, reranker},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3654777.3676358,
author = {Jennings, Nicholas and Wang, Han and Li, Isabel and Smith, James and Hartmann, Bjoern},
title = {What's the Game, then? Opportunities and Challenges for Runtime Behavior Generation},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676358},
doi = {10.1145/3654777.3676358},
abstract = {Procedural content generation (PCG), the process of algorithmically creating game components instead of manually, has been a common tool of game development for decades. Recent advances in large language models (LLMs) enable the generation of game behaviors based on player input at runtime. Such code generation brings with it the possibility of entirely new gameplay interactions that may be difficult to integrate with typical game development workflows. We explore these implications through GROMIT, a novel LLM-based runtime behavior generation system for Unity. When triggered by a player action, GROMIT generates a relevant behavior which is compiled without developer intervention and incorporated into the game. We create three demonstration scenarios with GROMIT to investigate how such a technology might be used in game development. In a system evaluation we find that our implementation is able to produce behaviors that result in significant downstream impacts to gameplay. We then conduct an interview study with n=13 game developers using GROMIT as a probe to elicit their current opinion on runtime behavior generation tools, and enumerate the specific themes curtailing the wider use of such tools. We find that the main themes of concern are quality considerations, community expectations, and fit with developer workflows, and that several of the subthemes are unique to runtime behavior generation specifically. We outline a future work agenda to address these concerns, including the need for additional guardrail systems for behavior generation.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {106},
numpages = {13},
keywords = {Generative AI, Human-AI interaction, Procedural Content Generation},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3704522.3704537,
author = {Lee, Hyun and Islam, Maminur and Yi, Chris and Chakraborttii, Chandranil (Nil)},
title = {Enhancing Graph Representation Learning with WalkLM for Effective Community Detection},
year = {2025},
isbn = {9798400711589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704522.3704537},
doi = {10.1145/3704522.3704537},
abstract = {Embeddings in deep neural networks are essential for processing high-dimensional and categorical data by converting it into compact, low-dimensional vectors. This conversion enables the model to capture complex semantic relationships and improves its generalization across diverse tasks. Although embeddings have demonstrated significant effectiveness in natural language processing and applications involving large language models (LLMs), their utility decreases when handling graph-based data. In this study, we address this challenge by enhancing WalkLM, a cutting-edge language model tailored for generating graph embeddings. We refine the random walk algorithm to better capture both local and global contexts within graphs. Additionally, we implement a k-means algorithm for community detection in these graphs. Our experiments across various benchmark datasets confirm the efficacy of our approach.},
booktitle = {Proceedings of the 11th International Conference on Networking, Systems, and Security},
pages = {41–47},
numpages = {7},
keywords = {Graph Clustering, Graph Embedding, Community Detection, Network, Machine Learning, LM(Language Model)},
location = {
},
series = {NSysS '24}
}

@inproceedings{10.5555/3709347.3743845,
author = {Tu, Songjun and Sun, Jingbo and Zhang, Qichao and Lan, Xiangyuan and Zhao, Dongbin},
title = {Online Preference-based Reinforcement Learning with Self-augmented Feedback from Large Language Model},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Preference-based reinforcement learning (PbRL) provides a powerful paradigm to avoid meticulous reward engineering by learning rewards based on human preferences. However, real-time human feedback is hard to obtain in online tasks. Most work suppose there is a ''scripted teacher'' that utilizes privileged predefined reward to provide preference feedback. In this paper, we propose a RL Self-augmented Large Language Model Feedback (RL-SaLLM-F) technique that does not rely on privileged information for online PbRL. RL-SaLLM-F leverages the reflective and discriminative capabilities of LLM to generate self-augmented trajectories and provide preference labels for reward learning. First, we identify a failure issue in LLM-based preference discrimination, specifically ''query ambiguity'', in online PbRL. Then LLM is employed to provide preference labels and generate self-augmented imagined trajectories that better achieve the task goal, thereby enhancing the quality and efficiency of feedback. Additionally, a double-check mechanism is introduced to mitigate randomness in the preference labels, improving the reliability of LLM feedback. The experiment across multiple tasks in the MetaWorld benchmark demonstrates the specific contributions of each proposed module in RL-SaLLM-F, and shows that self-augmented LLM feedback can effectively replace the impractical ''scripted teacher'' feedback. In summary, RL-SaLLM-F introduces a new direction of feedback acquisition in online PbRL that does not rely on any online privileged information, offering an efficient and lightweight solution with LLM-driven feedback.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {2069–2077},
numpages = {9},
keywords = {llm-driven feedback, online preference-based reinforcement learning, query ambiguity, self-augmented llm},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3650212.3680355,
author = {Zhang, Cen and Zheng, Yaowen and Bai, Mingqiang and Li, Yeting and Ma, Wei and Xie, Xiaofei and Li, Yuekang and Sun, Limin and Liu, Yang},
title = {How Effective Are They? Exploring Large Language Model Based Fuzz Driver Generation},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680355},
doi = {10.1145/3650212.3680355},
abstract = {Fuzz drivers are essential for library API fuzzing. However, automatically generating fuzz drivers is a complex task, as it demands the creation of high-quality, correct, and robust API usage code. An LLM-based (Large Language Model) approach for generating fuzz drivers is a promising area of research. Unlike traditional program analysis-based generators, this text-based approach is more generalized and capable of harnessing a variety of API usage information, resulting in code that is friendly for human readers. However, there is still a lack of understanding regarding the fundamental issues on this direction, such as its effectiveness and potential challenges.
 

 
To bridge this gap, we conducted the first in-depth study targeting the important issues of using LLMs to generate effective fuzz drivers. Our study features a curated dataset with 86 fuzz driver generation questions from 30 widely-used C projects. Six prompting strategies are designed and tested across five state-of-the-art LLMs with five different temperature settings. In total, our study evaluated 736,430 generated fuzz drivers, with 0.85 billion token costs ($8,000+ charged tokens). Additionally, we compared the LLM-generated drivers against those utilized in industry, conducting extensive fuzzing experiments (3.75 CPU-year). Our study uncovered that:
 

 
1) While LLM-based fuzz driver generation is a promising direction, it still encounters several obstacles towards practical applications;
 
2) LLMs face difficulties in generating effective fuzz drivers for APIs with intricate specifics. Three featured design choices of prompt strategies can be beneficial: issuing repeat queries, querying with examples, and employing an iterative querying process;
 
3) While LLM-generated drivers can yield fuzzing outcomes that are on par with those used in the industry, there are substantial opportunities for enhancement, such as extending contained API usage, or integrating semantic oracles to facilitate logical bug detection.
 

 
Our insights have been implemented to improve the OSS-Fuzz-Gen project, facilitating practical fuzz driver generation in industry.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1223–1235},
numpages = {13},
keywords = {Fuzz Driver Generation, Fuzz Testing, Large Language Model},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3626246.3654751,
author = {Giannakouris, Victor and Trummer, Immanuel},
title = {Demonstrating λ-Tune: Exploiting Large Language Models for Workload-Adaptive Database System Tuning},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3654751},
doi = {10.1145/3626246.3654751},
abstract = {We demonstrate λ-Tune, a tool that leverages Large Language Models (LLMs) for automated, workload-adaptive database system tuning. λ-Tune harnesses the ability of LLMs to process and comprehend arbitrary textual data in a zero-shot manner, employing a workload-adaptive optimization approach. Given a database system, the hardware specifications, and a set of queries, λ-Tune generates prompts to retrieve configuration recommendations for the tuning knobs and the physical design, tailored to the specific system and workload. Our framework utilizes a workload compression approach that extracts and includes in the prompt only the most insightful workload characteristics, while the prompt size can be adjusted by a user-defined token budget. Utilizing the zero-shot capabilities of LLMs, λ-Tune outperforms other LLM and machine learning-enhanced database tuning baselines, which rely on time-consuming tuning and training phases, as well as expensive hardware, such as GPUs. During demonstration, users will be able to experiment with λ-Tune to tune Postgres and MySQL, as well as explore and modify the configurations retrieved by the LLM in an interactive way through λ-Tune's user interface.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {508–511},
numpages = {4},
keywords = {database, large language model, tuning},
location = {Santiago AA, Chile},
series = {SIGMOD '24}
}

@inproceedings{10.1145/3640794.3669998,
author = {Sacar, Sayan and Munteanu, Cosmin and Sin, Jaisie and Wei, Christina and Sayago, Sergio and Zhao, Wei and Waycott, Jenny},
title = {Designing Age-Inclusive Interfaces: Emerging Mobile, Conversational, and Generative AI to Support Interactions across the Life Span},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640794.3669998},
doi = {10.1145/3640794.3669998},
abstract = {We are concurrently witnessing two significant shifts: voice and chat-based conversational user interfaces (CUIs) are becoming ubiquitous (especially more recently due to advances in generative AI and LLMs - large language models), and older people are becoming a very large demographic group (and increasingly adopting of mobile technology on which such interfaces are present). However, despite the recent increase in research activity, age-relevant and inter/cross-generational aspects continue to be underrepresented in both research and commercial product design. Therefore, the overarching aim of this workshop is to increase the momentum for research within the space of hands-free, mobile, and conversational interfaces that centers on age-relevant and inter- and cross-generational interaction. For this, we plan to create an interdisciplinary space that brings together researchers, designers, practitioners, and users, to discuss and share challenges, principles, and strategies for designing such interfaces across the life span. We thus welcome contributions of empirical studies, theories, design, and evaluation of hands-free, mobile, and conversational interfaces designed with aging in mind (e.g. older adults or inter/cross-generational). We particularly encourage contributions focused on leveraging recent advances in generative AI or LLMs. Through this, we aim to grow the community of CUI researchers across disciplinary boundaries (human-computer interaction, voice and language technologies, geronto-technologies, information studies, etc.) that are engaged in the shared goal of ensuring that the aging dimension is appropriately incorporated in mobile / conversational interaction design research.},
booktitle = {Proceedings of the 6th ACM Conference on Conversational User Interfaces},
articleno = {64},
numpages = {5},
location = {Luxembourg, Luxembourg},
series = {CUI '24}
}

@inproceedings{10.1145/3701716.3717529,
author = {Wang, Wenjie and Lin, Xinyu and Feng, Fuli and He, Xiangnan and Chua, Tat-Seng},
title = {Generative Recommendation: Towards Personalized Multimodal Content Generation},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717529},
doi = {10.1145/3701716.3717529},
abstract = {Traditional recommender systems primarily retrieve items from a pre-defined item corpus for personalized recommendations. However, this a retrieval-based paradigm faces two major constraints: 1) the existing item corpus with human-generated items may not adequately satisfy users' diverse information needs, and 2) users often rely on passive and noisy feedback (e.g., clicks) to refine the recommendations. To overcome the limitations, the rapid advancement of AI-Generated Content (AIGC) presents significant potential: 1) generative AI promotes the creation of personalized multimodal content as new items to satisfy users' information needs, and 2) large language models reduce the efforts of users to express information needs proactively in natural language. In this light, we propose a novel Generative Recommender paradigm named GeneRec with two objectives: 1) generating personalized multimodal content, and 2) integrating proactive user instructions to guide content generation. To achieve the objectives, GeneRec introduces an AI generator to personalize multimodal content generation and leverages user instructions to obtain users' information needs. Specifically, GeneRec first employs an instructor to pre-process users' instructions and traditional feedback (e.g., clicks) to extract generation guidance. Following the guidance, we develop the AI generator with an AI editor to edit existing items and an AI creator to create new items, respectively. Lastly, we study the feasibility of implementing the AI creator in the fashion domain, showing promising results. Furthermore, to ensure the trustworthiness of the generated items, we emphasize various trustworthiness checks such as fairness and safety checks.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2421–2425},
numpages = {5},
keywords = {generative recommender paradigm, personalized aigc, personalized multimodal content generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3610977.3634966,
author = {Kim, Callie Y. and Lee, Christine P. and Mutlu, Bilge},
title = {Understanding Large-Language Model (LLM)-powered Human-Robot Interaction},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610977.3634966},
doi = {10.1145/3610977.3634966},
abstract = {Large-language models (LLMs) hold significant promise in improving human-robot interaction, offering advanced conversational skills and versatility in managing diverse, open-ended user requests in various tasks and domains. Despite the potential to transform human-robot interaction, very little is known about the distinctive design requirements for utilizing LLMs in robots, which may differ from text and voice interaction and vary by task and context. To better understand these requirements, we conducted a user study (n = 32) comparing an LLM-powered social robot against text- and voice-based agents, analyzing task-based requirements in conversational tasks, including choose, generate, execute, and negotiate. Our findings show that LLM-powered robots elevate expectations for sophisticated non-verbal cues and excel in connection-building and deliberation, but fall short in logical communication and may induce anxiety. We provide design implications both for robots integrating LLMs and for fine-tuning LLMs for use with robots.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {371–380},
numpages = {10},
keywords = {human-robot interaction, large language models, social robots},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3670474.3685966,
author = {Vijayaraghavan, Prashanth and Nitsure, Apoorva and Mackin, Charles and Shi, Luyao and Ambrogio, Stefano and Haran, Arvind and Paruthi, Viresh and Elzein, Ali and Coops, Dan and Beymer, David and Baldwin, Tyler and Degan, Ehsan},
title = {Chain-of-Descriptions: Improving Code LLMs for VHDL Code Generation and Summarization},
year = {2024},
isbn = {9798400706998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670474.3685966},
doi = {10.1145/3670474.3685966},
abstract = {Large Language Models (LLMs) have become widely used across diverse NLP tasks and domains, demonstrating their adaptability and effectiveness. In the realm of Electronic Design Automation (EDA), LLMs show promise for tasks like Register-Transfer Level (RTL) code generation and summarization. However, despite the proliferation of LLMs for general code-related tasks, there's a dearth of research focused on evaluating and refining these models for hardware description languages (HDLs), notably VHDL. In this study, we evaluate the performance of existing code LLMs for VHDL code generation and summarization using various metrics and two datasets - VHDL-Eval and VHDL-Xform. The latter, an in-house dataset, aims to gauge LLMs' understanding of functionally equivalent code. Our findings reveal consistent underperformance of these models across different metrics, underscoring a significant gap in their suitability for this domain. To address this challenge, we propose Chain-of-Descriptions (CoDes), a novel approach to enhance the performance of LLMs for VHDL code generation and summarization tasks. CoDes involves generating a series of intermediate descriptive steps based on: (i) the problem statement for code generation, and (ii) the VHDL code for summarization. These steps are then integrated with the original input prompt (problem statement or code) and provided as input to the LLMs to generate the final output. Our experiments demonstrate that the CoDes approach significantly surpasses the standard prompting strategy across various metrics on both datasets. This method not only improves the quality of VHDL code generation and summarization but also serves as a framework for future research aimed at enhancing code LLMs for VHDL.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD},
articleno = {28},
numpages = {10},
keywords = {Chain-of-Descriptions, LLM, VHDL, VHDL Code Generation, VHDL Code Summarization, VHDL-Eval, VHDL-Xform},
location = {Salt Lake City, UT, USA},
series = {MLCAD '24}
}

@inproceedings{10.1145/3701716.3718385,
author = {Sood, Rishik and Anaissi, Ali and Huang, Weidong and Braytee, Ali},
title = {MemHateCaptioning: Enhancing Hate Speech Detection in Memes with Context-Aware Captioning and Chain-of-Thought},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3718385},
doi = {10.1145/3701716.3718385},
abstract = {Hate speech has become increasingly prevalent on social media, with memes presenting a unique challenge due to their multimodal nature, combining text, images, and often subtle cultural cues that spread hate online. Several hate speech detection models have recently been proposed to identify hate in multimodal memes. However, these methods may suffer from issues like context ambiguity, subtle visual cues, and multimodal complexity. Generating accurate captions from memes while considering the context, images, symbols, and text can help capture the intended meaning and, consequently, improve the accuracy of hate speech detection. This study introduces MemHateCaptioning, a framework designed to generate clear, human-like explanations to contextualize why a meme is flagged as hateful. MemHateCaptioning leverages recent advancements in vision-language models (VLMs) and large language models (LLMs), integrating ClipCap for image captioning, BLIP for language-image pretraining, and T5 for explanation generation. The framework incorporates Chain-of-Thought (CoT) prompting to enhance interpretability, enabling the model to break down complex reasoning step by step, which helps in comprehending the subtle interplay between text and images in hateful content. MemHateCaptioning is evaluated on the HatReD dataset and demonstrates strong performance, achieving higher BLEU and ROUGE-L scores compared to existing models. It also effectively reduces issues such as hallucinations and context misinterpretation by providing detailed, context-aware explanations.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2034–2041},
numpages = {8},
keywords = {ai captioning methods, hate speech detection, memes, multimodal models},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3643681,
author = {Thakur, Shailja and Ahmad, Baleegh and Pearce, Hammond and Tan, Benjamin and Dolan-Gavitt, Brendan and Karri, Ramesh and Garg, Siddharth},
title = {VeriGen: A Large Language Model for Verilog Code Generation},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {3},
issn = {1084-4309},
url = {https://doi.org/10.1145/3643681},
doi = {10.1145/3643681},
abstract = {In this study, we explore the capability of Large Language Models (LLMs) to automate hardware design by automatically completing partial Verilog code, a common language for designing and modeling digital systems. We fine-tune pre-existing LLMs on Verilog datasets compiled from GitHub and Verilog textbooks. We evaluate the functional correctness of the generated Verilog code using a specially designed test suite, featuring a custom problem set and testing benches. Here, our fine-tuned open-source CodeGen-16B model outperforms the commercial state-of-the-art GPT-3.5-turbo model with a 1.1% overall increase. Upon testing with a more diverse and complex problem set, we find that the fine-tuned model shows competitive performance against state-of-the-art gpt-3.5-turbo, excelling in certain scenarios. Notably, it demonstrates a 41% improvement in generating syntactically correct Verilog code across various problem categories compared to its pre-trained counterpart, highlighting the potential of smaller, in-house LLMs in hardware design automation. We release our training/evaluation scripts and LLM checkpoints as open-source contributions.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = apr,
articleno = {46},
numpages = {31},
keywords = {Transformers, verilog, GPT, large language models, EDA}
}

@inproceedings{10.1145/3649217.3653574,
author = {Denny, Paul and MacNeil, Stephen and Savelka, Jaromir and Porter, Leo and Luxton-Reilly, Andrew},
title = {Desirable Characteristics for AI Teaching Assistants in Programming Education},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653574},
doi = {10.1145/3649217.3653574},
abstract = {Providing timely and personalized feedback to large numbers of students is a long-standing challenge in programming courses. Relying on human teaching assistants (TAs) has been extensively studied, revealing a number of potential shortcomings. These include inequitable access for students with low confidence when needing support, as well as situations where TAs provide direct solutions without helping students to develop their own problem-solving skills. With the advent of powerful large language models (LLMs), digital teaching assistants configured for programming contexts have emerged as an appealing and scalable way to provide instant, equitable, round-the-clock support. Although digital TAs can provide a variety of help for programming tasks, from high-level problem solving advice to direct solution generation, the effectiveness of such tools depends on their ability to promote meaningful learning experiences. If students find the guardrails implemented in digital TAs too constraining, or if other expectations are not met, they may seek assistance in ways that do not help them learn. Thus, it is essential to identify the features that students believe make digital teaching assistants valuable. We deployed an LLM-powered digital assistant in an introductory programming course and collected student feedback (n=813) on the characteristics of the tool they perceived to be most important. Our results highlight that students value such tools for their ability to provide instant, engaging support, particularly during peak times such as before assessment deadlines. They also expressed a strong preference for features that enable them to retain autonomy in their learning journey, such as scaffolding that helps to guide them through problem-solving steps rather than simply being shown direct solutions.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {408–414},
numpages = {7},
keywords = {ai tutors, automated tutors, digital tas, feedback, llms},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626772.3657731,
author = {Wang, Fengyi and Zhu, Guanghui and Yuan, Chunfeng and Huang, Yihua},
title = {LLM-enhanced Cascaded Multi-level Learning on Temporal Heterogeneous Graphs},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657731},
doi = {10.1145/3626772.3657731},
abstract = {Learning on temporal heterogeneous graphs (THGs) has attracted substantial attention in applications of information retrieval. Such graphs are ubiquitous in real-world domains like recommender systems and social networks. However, the spatial heterogeneity, rich semantic information, and intricate evolution patterns of THGs make it still difficult to generate high-quality embeddings for graph nodes. In this paper, we focus on two valuable and understudied issues related to THG learning: (a) How to capture the specific evolutionary characteristics of diverse temporal heterogeneous graphs? (b) Due to the heterogeneous nature of the graph, how to capture the unique temporal patterns of different node types? We explore these questions and present our solution by proposing a new method named CasMLN (Cascaded Multi-level Learning Network) for THG learning. Through the multi-level learning structure and aggregation methods specifically designed for different levels, we obtain information of multiple levels and fuse them to improve embedding generation. Additionally, we pioneer the use of large language models (LLMs) in the THG field. By leveraging the universality and powerful capabilities of LLMs, our method introduces LLM-based external knowledge to effectively capture the implicit nature of graphs and node types, which helps to enhance type- and graph-level representations. We evaluate our method on several real-world THG datasets for different downstream tasks. Extensive experimental results show that CasMLN outperforms the state-of-the-art baselines in both accuracy and efficiency.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {512–521},
numpages = {10},
keywords = {graph neural network, large language models, representation learning, temporal heterogeneous graphs},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3691620.3695536,
author = {Chen, Mouxiang and Liu, Zhongxin and Tao, He and Hong, Yusu and Lo, David and Xia, Xin and Sun, Jianling},
title = {B4: Towards Optimal Assessment of Plausible Code Solutions with Plausible Tests},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695536},
doi = {10.1145/3691620.3695536},
abstract = {Selecting the best code solution from multiple generated ones is an essential task in code generation, which can be achieved by using some reliable validators (e.g., developer-written test cases) for assistance. Since reliable test cases are not always available and can be expensive to build in practice, researchers propose to automatically generate test cases to assess code solutions. However, when both code solutions and test cases are plausible and not reliable, selecting the best solution becomes challenging. Although some heuristic strategies have been proposed to tackle this problem, they lack a strong theoretical guarantee and it is still an open question whether an optimal selection strategy exists. Our work contributes in two ways. First, we show that within a Bayesian framework, the optimal selection strategy can be defined based on the posterior probability of the observed passing states between solutions and tests. The problem of identifying the best solution is then framed as an integer programming problem. Second, we propose an efficient approach for approximating this optimal (yet uncomputable) strategy, where the approximation error is bounded by the correctness of prior knowledge. We then incorporate effective prior knowledge to tailor code generation tasks. Both theoretical and empirical studies confirm that existing heuristics are limited in selecting the best solutions with plausible test cases. Our proposed approximated optimal strategy ℬ4 significantly surpasses existing heuristics in selecting code solutions generated by large language models (LLMs) with LLM-generated tests, achieving a relative performance improvement by up to 50% over the strongest heuristic and 246% over the random selection in the most challenging scenarios. Our code is publicly available at https://github.com/ZJU-CTAG/B4.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1693–1705},
numpages = {13},
keywords = {code generation, software engineering, large language models},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3630106.3662681,
author = {Lee, Yoonjoo and Son, Kihoon and Kim, Tae Soo and Kim, Jisu and Chung, John Joon Young and Adar, Eytan and Kim, Juho},
title = {One vs. Many: Comprehending Accurate Information from Multiple Erroneous and Inconsistent AI Generations},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3662681},
doi = {10.1145/3630106.3662681},
abstract = {As Large Language Models (LLMs) are nondeterministic, the same input can generate different outputs, some of which may be incorrect or hallucinated. If run again, the LLM may correct itself and produce the correct answer. Unfortunately, most LLM-powered systems resort to single results which, correct or not, users accept. Having the LLM produce multiple outputs may help identify disagreements or alternatives. However, it is not obvious how the user will interpret conflicts or inconsistencies. To this end, we investigate how users perceive the AI model and comprehend the generated information when they receive multiple, potentially inconsistent, outputs. Through a preliminary study, we identified five types of output inconsistencies. Based on these categories, we conducted a study (N = 252) in which participants were given one or more LLM-generated passages to an information-seeking question. We found that inconsistency within multiple LLM-generated outputs lowered the participants’ perceived AI capacity, while also increasing their comprehension of the given information. Specifically, we observed that this positive effect of inconsistencies was most significant for participants who read two passages, compared to those who read three. Based on these findings, we present design implications that, instead of regarding LLM output inconsistencies as a drawback, we can reveal the potential inconsistencies to transparently indicate the limitations of these models and promote critical LLM usage.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {2518–2531},
numpages = {14},
keywords = {Controlled Study, Inconsistency, Large Language Models, Reading Comprehension},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3657604.3664665,
author = {Koutcheme, Charles and Hellas, Arto},
title = {Propagating Large Language Models Programming Feedback},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664665},
doi = {10.1145/3657604.3664665},
abstract = {Large language models (LLMs) such as GPT-4 have emerged as promising tools for providing programming feedback. However, effective deployment of LLMs in massive classes and Massive Open Online Courses (MOOCs) raises financial concerns, calling for methods to minimize the number of calls to the APIs and systems serving such powerful models. In this article, we revisit the problem of 'propagating feedback' within the contemporary landscape of LLMs. Specifically, we explore feedback propagation as a way to reduce the cost of leveraging LLMs for providing programming feedback at scale. Our study investigates the effectiveness of this approach in the context of students requiring next-step hints for Python programming problems, presenting initial results that support the viability of the approach. We discuss our findings' implications and suggest directions for future research in optimizing feedback mechanisms for large-scale educational environments.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {366–370},
numpages = {5},
keywords = {computer science education, large language models, programming feedback},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3708557.3716331,
author = {Kovacs, Alexandra and Meteier, Quentin and Angelini, Leonardo and Mugellini, Elena and Abou Khaled, Omar},
title = {Explanation Modalities for a Recommender System Optimizing Energy Management in a Solar-Powered Smart Home},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716331},
doi = {10.1145/3708557.3716331},
abstract = {Due to the energy crisis, as well as economical and ecological concerns, home energy management became vital. Although photovoltaic systems are increasingly being adopted by homeowners, understanding how energy is managed to optimize their consumption remains a challenge. We enhance an existing Recommender System (RS) developed to provide daily recommendations for scheduling energy-intensive households activities during solar production peaks, to deliver explanations. This study’s aim is to identify the ideal approach to offer these explanations. Four explanation conditions were evaluated, covering diverse modalities: textual and hybrid (text + visual), with textual explanations generated using an Large Language Model (LLM) and provided in two lengths (short, long). An online questionnaire with 27 respondents was conducted to evaluate these conditions across four seasonal recommendations. Results revealed a preference for the hybrid explanations, suggesting the potential this modality might hold.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {43–47},
numpages = {5},
keywords = {explainable AI (xAI), recommender system, energy management, smart home, solar panels, explanation modality, amount of information},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3637528.3671837,
author = {Ning, Liang-bo and Wang, Shijie and Fan, Wenqi and Li, Qing and Xu, Xin and Chen, Hao and Huang, Feiran},
title = {CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671837},
doi = {10.1145/3637528.3671837},
abstract = {Recently, Large Language Model (LLM)-empowered recommender systems (RecSys) have brought significant advances in personalized user experience and have attracted considerable attention. Despite the impressive progress, the research question regarding the safety vulnerability of LLM-empowered RecSys still remains largely under-investigated. Given the security and privacy concerns, it is more practical to focus on attacking the black-box RecSys, where attackers can only observe the system's inputs and outputs. However, traditional attack approaches employing reinforcement learning (RL) agents are not effective for attacking LLM-empowered RecSys due to the limited capabilities in processing complex textual inputs, planning, and reasoning. On the other hand, LLMs provide unprecedented opportunities to serve as attack agents to attack RecSys because of their impressive capability in simulating human-like decision-making processes. Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our method first identifies the insertion position for maximum impact with minimal input modification. After that, the LLM agent is designed to generate adversarial perturbations to insert at target positions. To further improve the quality of generated perturbations, we utilize the prompt tuning technique to improve attacking strategies via feedback from the victim RecSys iteratively. Extensive experiments across three real-world datasets demonstrate the effectiveness of our proposed attacking method.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2284–2295},
numpages = {12},
keywords = {adversarial attacks, large language models, llm-empowered recommender systems, llms-based agent, recommender systems},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3613904.3641924,
author = {Szymanski, Annalisa and Wimer, Brianna L and Anuyah, Oghenemaro and Eicher-Miller, Heather A and Metoyer, Ronald A},
title = {Integrating Expertise in LLMs: Crafting a Customized Nutrition Assistant with Refined Template Instructions},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641924},
doi = {10.1145/3613904.3641924},
abstract = {Large Language Models (LLMs) have the potential to contribute to the fields of nutrition and dietetics in generating food product explanations that facilitate informed food selections. However, the extent to which these models offer effective and accurate information remains unverified. In collaboration with registered dietitians (RDs), we evaluate the strengths and weaknesses of LLMs in providing accurate and personalized nutrition information. Through a mixed-methods approach, RDs validated GPT-4 outputs at various levels of prompt specificity, which led to the development of design guidelines used to prompt LLMs for nutrition information. We tested these guidelines by creating a GPT prototype, The Food Product Nutrition Assistant, tailored for food product explanations. This prototype was refined and evaluated in focus groups with RDs. We find that the implementation of these dietitian-reviewed template instructions enhance the generation of detailed food product descriptions and tailored nutrition information.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {992},
numpages = {22},
keywords = {Artificial Intelligence, Food Recommendations, Large Language Models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3664646.3664771,
author = {Karanjai, Rabimba and Xu, Lei and Shi, Weidong},
title = {SolMover: Smart Contract Code Translation Based on Concepts},
year = {2024},
isbn = {9798400706851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664646.3664771},
doi = {10.1145/3664646.3664771},
abstract = {Large language models (LLMs) have showcased remarkable skills, rivaling or even exceeding human intelligence in certain areas. Their proficiency in translation is notable, as they may replicate the nuanced, preparatory steps of human translators for high-quality outcomes. Although there have been some notable work exploring using LLMs for code-to-code translation, there has not been
 
one for smart contracts, especially when the target language is unseen to the LLMs. In this work, we introduce our novel framework SolMover, which consists of two different LLMs working in tandem in a framework to understand coding concepts and then use that to translate code to an unseen language. We explore the human-like learning capability of LLMs with a detailed evaluation of the methodology to translate existing smart contracts written in Solidity to a low-resource one called Move. Specifically, we enable one LLM to understand coding rules for the new language to generate a planning task, for the second LLM to follow, which does not have planning capability but does have coding. Experiments show that SolMover brings a significant improvement over gpt-3.5-turbo-1106 and outperforms both Palm2 and Mixtral-8x7B-Instruct. Our further analysis shows that employing our bug mitigation technique even without the framework still improves code quality for all models},
booktitle = {Proceedings of the 1st ACM International Conference on AI-Powered Software},
pages = {112–121},
numpages = {10},
keywords = {Computing methodologies, Machine translation, Natural language generation},
location = {Porto de Galinhas, Brazil},
series = {AIware 2024}
}

@inproceedings{10.1145/3584371.3612956,
author = {Shi, Wenqi and Zhuang, Yuchen and Zhu, Yuanda and Iwinski, Henry and Wattenbarger, Michael and Wang, May Dongmei},
title = {Retrieval-Augmented Large Language Models for Adolescent Idiopathic Scoliosis Patients in Shared Decision-Making},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3612956},
doi = {10.1145/3584371.3612956},
abstract = {As health-related decision-making evolves, patients increasingly seek help from additional online resources such as "Dr. Google" and ChatGPT. Despite their potential, these tools encounter limitations, including the risk of potentially inaccurate information, a lack of specialized medical knowledge, the risk of generating unrealistic outputs (hallucinations), and significant computational demands. In this study, we develop and validate an innovative shared decisionmaking (SDM) tool, Chat-Orthopedist, for adolescent idiopathic scoliosis (AIS) patients and families to prepare a meaningful discussion with clinicians based on retrieval-augmented large language models. Firstly, we establish an external knowledge base with information on AIS disease and treatment options Secondly, we develop a retrieval-augmented ChatGPT to feed LLMs with AIS domain knowledge, providing accurate and comprehensible responses to patient inquiries. In addition, we perform a cyclical process of human-in-the-loop evaluations for system validation and improvement. ment. Chat-Orthopedist may optimize SDM workflow by enabling better interactive learning experiences, more effective clinical visits, and better-informed treatment decision-making.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {14},
numpages = {10},
keywords = {large language models, information retrieval, pediatric healthcare, shared decision-making, adolescent idiopathic scoliosis},
location = {Houston, TX, USA},
series = {BCB '23}
}

@inproceedings{10.1145/3640543.3645200,
author = {Khurana, Anjali and Subramonyam, Hariharan and Chilana, Parmit K},
title = {Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions for Software Help-Seeking},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645200},
doi = {10.1145/3640543.3645200},
abstract = {Large Language Model (LLM) assistants, such as ChatGPT, have emerged as potential alternatives to search methods for helping users navigate complex, feature-rich software. LLMs use vast training data from domain-specific texts, software manuals, and code repositories to mimic human-like interactions, offering tailored assistance, including step-by-step instructions. In this work, we investigated LLM-generated software guidance through a within-subject experiment with 16 participants and follow-up interviews. We compared a baseline LLM assistant with an LLM optimized for particular software contexts, SoftAIBot, which also offered guidelines for constructing appropriate prompts. We assessed task completion, perceived accuracy, relevance, and trust. Surprisingly, although SoftAIBot outperformed the baseline LLM, our results revealed no significant difference in LLM usage and user perceptions with or without prompt guidelines and the integration of domain context. Most users struggled to understand how the prompt’s text related to the LLM’s responses and often followed the LLM’s suggestions verbatim, even if they were incorrect. This resulted in difficulties when using the LLM’s advice for software tasks, leading to low task completion rates. Our detailed analysis also revealed that users remained unaware of inaccuracies in the LLM’s responses, indicating a gap between their lack of software expertise and their ability to evaluate the LLM’s assistance. With the growing push for designing domain-specific LLM assistants, we emphasize the importance of incorporating explainable, context-aware cues into LLMs to help users understand prompt-based interactions, identify biases, and maximize the utility of LLM assistants.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {288–303},
numpages = {16},
keywords = {feature-rich software, help-seeking, large language models, prompt-based interactions},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@inproceedings{10.1145/3663529.3663855,
author = {Sarda, Komal and Namrud, Zakeya and Litoiu, Marin and Shwartz, Larisa and Watts, Ian},
title = {Leveraging Large Language Models for the Auto-remediation of Microservice Applications: An Experimental Study},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663855},
doi = {10.1145/3663529.3663855},
abstract = {Runtime auto-remediation is crucial for ensuring the reliability and efficiency of distributed systems, especially within complex microservice-based applications. However, the complexity of modern microservice deployments often surpasses the capabilities of traditional manual remediation and existing autonomic computing methods. Our proposed solution harnesses large language models (LLMs) to generate and execute Ansible playbooks automatically to address issues within these complex environments. Ansible playbooks, a widely adopted markup language for IT task automation, facilitate critical actions such as addressing network failures, resource constraints, configuration errors, and application bugs prevalent in managing microservices. We apply in-context learning on pre-trained LLMs using our custom-made Ansible-based remediation dataset, equipping these models to comprehend diverse remediation tasks within microservice environments. Then, these tuned LLMs efficiently generate precise Ansible scripts tailored to specific issues encountered, surpassing current state-of-the-art techniques with high functional correctness (95.45%) and average correctness (98.86%).},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {358–369},
numpages = {12},
keywords = {Ansible, Auto-remediation, Autonomic computing, Cloud native applications, Code generation, Kubernetes, Large language models, Microservices, Prompt engineering, Real-time faults, Self-adaptive software},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3626772.3657675,
author = {Kamalloo, Ehsan and Upadhyay, Shivani and Lin, Jimmy},
title = {Towards Robust QA Evaluation via Open LLMs},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657675},
doi = {10.1145/3626772.3657675},
abstract = {Instruction-tuned large language models (LLMs) have been shown to be viable surrogates for the widely used, albeit overly rigid, lexical matching metrics in evaluating question answering (QA) models. However, these LLM-based evaluation methods are invariably based on proprietary LLMs. Despite their remarkable capabilities, proprietary LLMs are costly and subject to internal changes that can affect their output, which inhibits the reproducibility of their results and limits the widespread adoption of LLM-based evaluation. In this demo, we aim to use publicly available LLMs for standardizing LLM-based QA evaluation. However, open-source LLMs lag behind their proprietary counterparts. We overcome this gap by adopting chain-of-thought prompting with self-consistency to build a reliable evaluation framework. We demonstrate that our evaluation framework, based on 750M and 7B open LLMs, correlates competitively with human judgment, compared to most recent GPT-3 and GPT-4 models. Our codebase and data are available at https://github.com/castorini/qa-eval.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2811–2816},
numpages = {6},
keywords = {evaluation, large language models, question answering},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3626772.3657828,
author = {Zhao, Yuyue and Wu, Jiancan and Wang, Xiang and Tang, Wei and Wang, Dingxian and de Rijke, Maarten},
title = {Let Me Do It For You: Towards LLM Empowered Recommendation via Tool Learning},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657828},
doi = {10.1145/3626772.3657828},
abstract = {Conventional recommender systems (RSs) face challenges in precisely capturing users' fine-grained preferences. Large language models (LLMs) have shown capabilities in commonsense reasoning and leveraging external tools that may help address these challenges. However, existing LLM-based RSs suffer from hallucinations, misalignment between the semantic space of items and the behavior space of users, or overly simplistic control strategies (e.g., whether to rank or directly present existing results). To bridge these gap, we introduce ToolRec, a framework for LLM-empowered recommendations via tool learning that uses LLMs as surrogate users, thereby guiding the recommendation process and invoking external tools to generate a recommendation list that aligns closely with users' nuanced preferences.We formulate the recommendation process as a process aimed at exploring user interests in attribute granularity. The process factors in the nuances of the context and user preferences. The LLM then invokes external tools based on a user's attribute instructions and probes different segments of the item pool. We consider two types of attribute-oriented tools: rank tools and retrieval tools. Through the integration of LLMs, ToolRec enables conventional recommender systems to become external tools with a natural language interface. Extensive experiments verify the effectiveness of ToolRec, particularly in scenarios that are rich in semantic content.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1796–1806},
numpages = {11},
keywords = {large language models, recommender system, tool learning},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3649217.3653595,
author = {Cucuiat, Veronica and Waite, Jane},
title = {Feedback Literacy: Holistic Analysis of Secondary Educators' Views of LLM Explanations of Program Error Messages},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653595},
doi = {10.1145/3649217.3653595},
abstract = {The implications of using large language model (LLM) tools for learning to program at secondary school level are largely unknown, and yet there is pressure for teachers to engage with these. To start addressing this gap, we investigated: RQ1: What are secondary educators' views on the potential classroom use of LLM program error message explanations? RQ2: In what ways can a feedback literacy perspective support the analysis of educators' views of potential classroom use of LLM program error message explanations? The responses of eight expert secondary school educators were gathered during a semi-structured, activity-based interview and qualitatively analysed. Fifteen themes were derived from their commentary, of which ten corresponded to enhanced program error message (PEM) guidelines. Yet, all themes correlated to feedback literacy theory, providing a more holistic view. The analysis revealed that educators preferred LLM explanations to guide and develop understanding rather than tell, that students should be supported to make judgements and action LLM-generated feedback. Combining PEM guideline and feedback literacy findings, we suggest augmented IDEs should be designed with educators and students in mind, and teacher professional development (PD) is needed. Research is needed to compare our findings with a wider range of educators and investigate what feedback literacy means for resource design, PD, and classroom practice in secondary and undergraduate contexts.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {192–198},
numpages = {7},
keywords = {AI, IDE, K-12 education, ML, feedback literacy},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3627217.3627233,
author = {Balse, Rishabh and Kumar, Viraj and Prasad, Prajish and Warriem, Jayakrishnan Madathil},
title = {Evaluating the Quality of LLM-Generated Explanations for Logical Errors in CS1 Student Programs},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627233},
doi = {10.1145/3627217.3627233},
abstract = {When students in CS1 (Introductory Programming) write erroneous code, course staff can use automated tools to provide various types of helpful feedback. In this paper, we focus on syntactically correct student code containing logical errors. Tools that explain logical errors typically require course staff to invest greater effort than tools that detect such errors. To reduce this effort, prior work has investigated the use of Large Language Models (LLMs) such as GPT-3 to generate explanations. Unfortunately, these explanations can be incomplete or incorrect, and therefore unhelpful if presented to students directly. Nevertheless, LLM-generated explanations may be of adequate quality for Teaching Assistants (TAs) to efficiently craft helpful explanations on their basis. We evaluate the quality of explanations generated by an LLM (GPT-3.5-turbo) in two ways, for 30&nbsp;buggy student solutions across 6&nbsp;code-writing problems. First, in a study with 5&nbsp;undergraduate TAs, we compare TA perception of LLM-generated and peer-generated explanation quality. TAs were unaware which explanations were LLM-generated, but they found them to be comparable in quality to peer-generated explanations. Second, we performed a detailed manual analysis of LLM-generated explanations for all 30&nbsp;buggy solutions. We found at least one incorrect statement in 15/30 explanations (50%). However, in 28/30 cases (93%), the LLM-generated explanation correctly identified at least one logical error. Our results suggest that for large CS1 courses, TAs with adequate training to detect erroneous statements may be able to extract value from such explanations.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {49–54},
numpages = {6},
keywords = {Explanation, GPT-3.5-Turbo, Large language models (LLMs), Logical Errors, Python Programming},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@inproceedings{10.1145/3589335.3651910,
author = {Choi, Eun Cheol and Ferrara, Emilio},
title = {Automated Claim Matching with Large Language Models: Empowering Fact-Checkers in the Fight Against Misinformation},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651910},
doi = {10.1145/3589335.3651910},
abstract = {In today's digital era, the rapid spread of misinformation poses threats to public well-being and societal trust. As online misinformation proliferates, manual verification by fact checkers becomes increasingly challenging. We introduce FACT-GPT (Fact-checking Augmentation with Claim matching Task-oriented Generative Pre-trained Transformer), a framework designed to automate the claim matching phase of fact-checking using Large Language Models (LLMs). This framework identifies new social media content that either supports or contradicts claims previously debunked by fact-checkers. Our approach employs LLMs to generate a labeled dataset consisting of simulated social media posts. This data set serves as a training ground for fine-tuning more specialized LLMs. We evaluated FACT-GPT on an extensive dataset of social media content related to public health. The results indicate that our fine-tuned LLMs rival the performance of larger pre-trained LLMs in claim matching tasks, aligning closely with human annotations. This study achieves three key milestones: it provides an automated framework for enhanced fact-checking; demonstrates the potential of LLMs to complement human expertise; offers public resources, including datasets and codes, to further research and applications in the fact-checking domain.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1441–1449},
numpages = {9},
keywords = {augmented intelligence, claim matching, fact-checking, large language model, misinformation, textual entailment},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1145/3655103.3655110,
author = {Chen, Zhikai and Mao, Haitao and Li, Hang and Jin, Wei and Wen, Hongzhi and Wei, Xiaochi and Wang, Shuaiqiang and Yin, Dawei and Fan, Wenqi and Liu, Hui and Tang, Jiliang},
title = {Exploring the Potential of Large Language Models (LLMs)in Learning on Graphs},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
issn = {1931-0145},
url = {https://doi.org/10.1145/3655103.3655110},
doi = {10.1145/3655103.3655110},
abstract = {Learning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions through GNNs. The latter attempts to directly employ LLMs as standalone predictors. We conduct comprehensive and systematical studies on these two pipelines under various settings. From comprehensive empirical results, we make original observations and find new insights that open new possibilities and suggest promising directions to leverage LLMs for learning on graphs. Our codes and datasets are available at: https://github.com/CurryTang/Graph-LLM .},
journal = {SIGKDD Explor. Newsl.},
month = mar,
pages = {42–61},
numpages = {20}
}

@inproceedings{10.1145/3640457.3687114,
author = {Anelli, Vito Walter and Ferrara, Antonio and Musto, Cataldo and Narducci, Fedelucio and Ragone, Azzurra and Zanker, Markus},
title = {Sixth Knowledge-aware and Conversational Recommender Systems Workshop (KaRS)},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3687114},
doi = {10.1145/3640457.3687114},
abstract = {Recommender systems, though widely used, often struggle to engage users effectively. While deep learning methods have enhanced connections between users and items, they often neglect the user’s perspective. Knowledge-based approaches, utilizing knowledge graphs, offer semantic insights and address issues like knowledge graph embeddings, hybrid recommendation, and interpretable recommendation. More recently, neural-symbolic systems, combining data-driven and symbolic techniques, show promise in recommendation systems, especially when used with knowledge graphs. Moreover, content features become vital in conversational recommender systems, which demand multi-turn dialogues. Recent literature highlights increasing interest in this area, particularly with the emergence of Large Language Models (LLMs), which excel in understanding user queries and generating recommendations in natural language. Sixth Knowledge-aware and Conversational Recommender Systems (KaRS) Workshop aims to disseminate advancements and discuss about challenges and opportunities.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {1245–1249},
numpages = {5},
keywords = {conversational agents, knowledge graphs, large language models, natural language processing, neuro-symbolic, recommender systems},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3652037.3663893,
author = {Bird, Jordan J. and Wright, David and Sumich, Alexander and Lotfi, Ahmad},
title = {Generative AI in Psychological Therapy: Perspectives on Computational Linguistics and Large Language Models in Written Behaviour Monitoring},
year = {2024},
isbn = {9798400717604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652037.3663893},
doi = {10.1145/3652037.3663893},
abstract = {Technological intervention to support care areas that some people may not have access to is of paramount importance to promote sustainable development of good health and wellbeing. This study aims to explore the linguistic similarities and differences between human professionals and Generative Artificial Intelligence (AI) conversational agents in therapeutic dialogues. Initially, the MISTRAL-7B Large Language Model (LLM) is instructed to generate responses to patient queries to form a synthetic equivalent to a publicly available psychology dataset. A large set of linguistic features (e.g., text metrics, lexical diversity and richness, readability scores, sentiment, emotions, and named entities) is extracted and studied from both the expert and synthetically-generated text. The results suggest a significantly richer vocabulary in humans than the LLM approach. Similarly, the use of sentiment was significantly different between the two, suggesting a difference in the supportive or objective language used and that synthetic linguistic expressions of emotion may differ from those expressed by an intelligent being. However, no statistical significance was observed between human professionals and AI in the use of function words, pronouns and several named entities; possibly reflecting an increased proficiency of LLMs in modelling some language patterns, even in a specialised context (i.e., therapy). However, current findings do not support the similarity in sentimental nuance and emotional expression, which limits the effectiveness of contemporary LLMs as standalone agents. Further development is needed towards clinically validated algorithms.},
booktitle = {Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {322–328},
numpages = {7},
keywords = {AI, Computational Linguistics, Generative Artificial Intelligence, LLMs, Large Language Models, Psychology},
location = {Crete, Greece},
series = {PETRA '24}
}

@inproceedings{10.1145/3722237.3722266,
author = {Yang, Ye and Wen, Xiong and Maidin, Siti Sarah},
title = {Generative AI Tools in Higher Education Emerging Research: A Bibliometric analysis of co-citation and co-word analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722266},
doi = {10.1145/3722237.3722266},
abstract = {Artificial Intelligence (AI) is positively grasped as promising to disrupt the higher education system but it also poses a number of challenges. Although so many studies attempt to explore the matching of the possibility of this growing technology with the higher education system, ample research needs to be conducted to solve the challenges facing the renovation of higher education. With this in mind, our aim of bibliometric studies is to conduct a deep investigation into the increasingly developing scenario of Generative AI tools in higher education. We extracted data from the Web of Science database that is up-to-date till July 2024, comprising 934 relevant articles. Co-citation and co-word analyses revealed three main research clusters: advanced computationable methods, AI application in higher education, and user technology and adoption. The findings illustrated rapid diffusion of generative AI technologies with prominent emphasis on large-language models in pedagogical practices. Other critical themes center around developing AI-facilitated learning interventions, ethical challenges, and usage impact on learning outcomes. The results show that the field is inherently interdisciplinary, using ideas from educational technology, cognitive science, and AI. In addition, a rising trend is noted for the focus on academic honesty and users' involvement with AI devices. The results indicate the important implications of this study for teachers and policymakers alongside contributions to teaching and research that offer a guide to sustainable improvement across education. Future research would benefit from longitudinal studies drawing on an interdisciplinary approach to realize the long-term implications and address complex issues surrounding the integration of AI within universities.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {166–174},
numpages = {9},
keywords = {Generative AI, artificial intelligence, bibliometric, educational technology, higher education},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3661167.3661171,
author = {Vallecillos Ruiz, Fernando},
title = {Agent-Driven Automatic Software Improvement},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661171},
doi = {10.1145/3661167.3661171},
abstract = {With software maintenance accounting for 50% of the cost of developing software, enhancing code quality and reliability has become more critical than ever. In response to this challenge, this doctoral research proposal aims to explore innovative solutions by focusing on the deployment of agents powered by Large Language Models (LLMs) to perform software maintenance tasks. The iterative nature of agents, which allows for continuous learning and adaptation, can help surpass common challenges in code generation. One distinct challenge is the last-mile problems, errors at the final stage of producing functionally and contextually relevant code. Furthermore, this project aims to surpass the inherent limitations of current LLMs in source code through a collaborative framework where agents can correct and learn from each other’s errors. We aim to use the iterative feedback in these systems to further fine-tune the LLMs underlying the agents, becoming better aligned to the task of automated software improvement. Our main goal is to achieve a leap forward in the field of automatic software improvement by developing new tools and frameworks that can enhance the efficiency and reliability of software development.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {470–475},
numpages = {6},
keywords = {Automatic Maintenance, Automatic Software Improvement, LLM-based Agents, ML4Code, Multi-Agent Systems},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3701716.3715472,
author = {Gawin, Cole and Sun, Yidan and Kejriwal, Mayank},
title = {Navigating Semantic Relations: Challenges for Language Models in Abstract Common-Sense Reasoning},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715472},
doi = {10.1145/3701716.3715472},
abstract = {Large language models (LLMs) have achieved remarkable performance in generating human-like text and solving reasoning tasks of moderate complexity, such as question-answering and mathematical problem-solving. However, their capabilities in tasks requiring deeper cognitive skills, such as common-sense understanding and abstract reasoning, remain under-explored. In this paper, we systematically evaluate abstract common-sense reasoning in LLMs using the ConceptNet knowledge graph. We propose two prompting approaches: instruct prompting, where models predict plausible semantic relationships based on provided definitions, and few-shot prompting, where models identify relations using examples as guidance. Our experiments with the gpt-4o-mini model show that in instruct prompting, consistent performance is obtained when ranking multiple relations but with substantial decline when the model is restricted to predicting only one relation. In few-shot prompting, the model's accuracy improves significantly when selecting from five relations rather than the full set, although with notable bias toward certain relations. These results suggest significant gaps still, even in commercially used LLMs' abstract common-sense reasoning abilities, compared to human-level understanding. However, the findings also highlight the promise of careful prompt engineering, based on selective retrieval, for obtaining better performance.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {971–975},
numpages = {5},
keywords = {abstract common sense, conceptnet, llm prompting},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3691620.3695482,
author = {Wu, Yin and Xie, Xiaofei and Peng, Chenyang and Liu, Dijun and Wu, Hao and Fan, Ming and Liu, Ting and Wang, Haijun},
title = {AdvSCanner: Generating Adversarial Smart Contracts to Exploit Reentrancy Vulnerabilities Using LLM and Static Analysis},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695482},
doi = {10.1145/3691620.3695482},
abstract = {Smart contracts are prone to vulnerabilities, with reentrancy attacks posing significant risks due to their destructive potential. While various methods exist for detecting reentrancy vulnerabilities in smart contracts, such as static analysis, these approaches often suffer from high false positive rates and lack the ability to directly illustrate how vulnerabilities can be exploited in attacks.In this paper, we tackle the challenging task of generating ASCs for identified reentrancy vulnerabilities. To address this difficulty, we introduce AdvSCanner, a novel method that leverages the Large Language Model (LLM) and static analysis to automatically generate adversarial smart contracts (ASCs) designed to exploit reentrancy vulnerabilities in victim contracts. The basic idea of AdvSCanner is to extract attack flows associated with reentrancy vulnerabilities using static analysis and utilize them to guide LLM in generating ASCs. To mitigate the inherent inaccuracies in LLM outputs, AdvSCanner incorporates a self-reflection component, which collects compilation and attack-triggering feedback from the generated ASCs and refines the ASC generation if necessary. Experimental evaluations demonstrate the effectiveness of AdvSCanner, achieving a significantly higher success rate (76.41%) compared to baseline methods, which only achieve 6.92% and 18.97%, respectively. Furthermore, a case study illustrates that AdvSCanner can greatly reduce auditing time from 24 hours (without assistance) to approximately 3 hours when used during the auditing process.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1019–1031},
numpages = {13},
keywords = {reentrancy vulnerability, code generation, large language model, smart contract, static analysis},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3643991.3645072,
author = {Grewal, Balreet and Lu, Wentao and Nadi, Sarah and Bezemer, Cor-Paul},
title = {Analyzing Developer Use of ChatGPT Generated Code in Open Source GitHub Projects},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645072},
doi = {10.1145/3643991.3645072},
abstract = {The rapid development of large language models such as ChatGPT have made them particularly useful to developers in generating code snippets for their projects. To understand how ChatGPT's generated code is leveraged by developers, we conducted an empirical study of 3,044 ChatGPT-generated code snippets integrated within GitHub projects. A median of 54% of the generated lines of code is found in the project's code and this code typically remains unchanged once added. The modifications of the 76 code snippets that changed in a subsequent commit, consisted of minor functionality changes and code reorganizations that were made within a day. Our findings offer insights that help drive the development of AI-assisted programming tools. We highlight the importance of making changes in ChatGPT code before integrating it into a project.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {157–161},
numpages = {5},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3613904.3642360,
author = {He, Ziyao and Li, Shiyuan and Song, Yunpeng and Cai, Zhongmin},
title = {Towards Building Condition-Based Cross-Modality Intention-Aware Human-AI Cooperation under VR Environment},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642360},
doi = {10.1145/3613904.3642360},
abstract = {To address critical challenges in effectively identifying user intent and forming relevant information presentations and recommendations in VR environments, we propose an innovative condition-based multi-modal human-AI cooperation framework. It highlights the intent tuples (intent, condition, intent prompt, action prompt) and 2-Large-Language-Models (2-LLMs) architecture. This design, utilizes “condition” as the core to describe tasks, dynamically match user interactions with intentions, and empower generations of various tailored multi-modal AI responses. The architecture of 2-LLMs separates the roles of intent detection and action generation, decreasing the prompt length and helping with generating appropriate responses. We implemented a VR-based intelligent furniture purchasing system based on the proposed framework and conducted a three-phase comparative user study. The results conclusively demonstrate the system’s superiority in time efficiency and accuracy, intention conveyance improvements, effective product acquisitions, and user satisfaction and cooperation preference. Our framework provides a promising approach towards personalized and efficient user experiences in VR.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {955},
numpages = {13},
keywords = {Action Generation, Human-AI Cooperation, Intention Detection, Virtual Reality},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1109/SCW63240.2024.00238,
author = {Sollenberger, Zachariah and Patel, Jay and Munley, Christian and Jarmusch, Aaron and Chandrasekaran, Sunita},
title = {LLM4VV: Exploring LLM-as-a-Judge for Validation and Verification Testsuites},
year = {2025},
isbn = {9798350355543},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SCW63240.2024.00238},
doi = {10.1109/SCW63240.2024.00238},
abstract = {Large Language Models (LLM) continue to improve and are revolutionizing the landscape of software development. These large models have demonstrated potential to generate, debug, test, analyze, document, and even translate code. Thus they are a valuable tool in the software development cycle. If used correctly, such tools can often accelerate the development cycle. Though the tools are powerful and new, the community is cautious of training using biased or sensitive data, which can lead to biased, dangerous, or incorrect outputs along with the inadvertent release of confidential information. Additionally, the carbon footprints and the un-explainability of these "black box" models continue to raise questions about the reliability of LLMs.With these opportunities and these challenges ahead, this paper explores the idea of "judging" LLM-generated code to better understand and "open up" the un-explainable "black box" models used by LLMs. We probe into the black box of one such LLM that has generated the best compiler tests for the directive-based programming models OpenMP and OpenACC in our earlier research. We challenge DeepSeek's deepseek-coder-33B-instruct model with intentionally-erroneous code, and we also define relevant metrics and adopt an agent-based approach to evaluate the LLM and assess its capabilities as an LLM-as-a-judge. We also develop a pipeline-based approach to streamline the entire workflow. Finally, we make use of all of these strategies together to develop a more reliable method for automatically validating LLM-generated compiler tests. Based on our results, utilizing an agent-based prompting approach and setting up a validation pipeline structure drastically increased the quality of deepseek-coder-33B-instruct evaluation of tests which are used to validate compiler implementations of directive-based parallel programming models.},
booktitle = {Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {1885–1893},
numpages = {9},
location = {Atlanta, GA, USA},
series = {SC-W '24}
}

@inbook{10.1145/3658617.3697618,
author = {Huang, Shan and Li, Jinhao and Yu, Zhen and Ye, Jiancai and Xu, Jiaming and Xu, Ningyi and Dai, Guohao},
title = {LLSM: LLM-enhanced Logic Synthesis Model with EDA-guided CoT Prompting, Hybrid Embedding and AIG-tailored Acceleration},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697618},
abstract = {Machine learning-based methods have shown promising results in the field of Electronic Design Automation (EDA) like logic synthesis result prediction, enabling a shift-left in the overall EDA flow. Designers should fully optimize their Register Transfer Level (RTL) designs early because remedying low-quality RTL in downstream synthesis stages is extremely challenging. However, previous works mainly start modeling from the netlist level or layout level and apply Graph Neural Networks (GNNs) to make predictions.RTL captures the logic and scale information of circuits with uniform representation, making it suitable for a unified embedding approach. Since Large Language Models (LLMs) possess the ability to understand text modality, making them a potential method for understanding RTL and performing various EDA tasks. Therefore, we propose LLSM, the first LLM-enhanced logic synthesis model to extract information directly from RTL code. We also propose three novel approaches for LLSM in this paper. (1) EDA-guided Chain-of-Thought (CoT) prompting. We apply LLMs guided by circuit knowledge to summarize, analyze RTL code, and generate text with circuit information. (2) Text-circuit hybrid embedding. We train a small Language Model (LM) to encode the generated circuit information from LLM and fuse the embeddings of text and circuit modalities with weighted summation. (3) AIG-tailored acceleration library. We utilize an ELL2 format with zero padding tailored for And-Inverter-Graph (AIG) circuit representation and fuse the computation and format conversion. We also design a cacheable state strategy to avoid redundant computation for LM. We are the first to work with both LLM and GNN for the prediction of logic synthesis results and conduct extensive experiments on the OpenABC-D dataset. LLSM achieve up to 21.53% and 19.27% loss reduction in delay and area prediction respectively. It also achieves 1.34\texttimes{} and 6296.77\texttimes{} speedup on average compared to PyG implementation and Synopsis Design Compiler, respectively.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {974–980},
numpages = {7}
}

@inproceedings{10.1145/3685767.3685777,
author = {Abdalla, Hemn Barzan and Awlla, Ardalan Hussein and Kumar, Yulia and Cheraghy, Maryam},
title = {Big Data: Past, Present, and Future Insights},
year = {2024},
isbn = {9798400709609},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3685767.3685777},
doi = {10.1145/3685767.3685777},
abstract = {This paper presents a comprehensive analysis of the historical progression, current trends, and prospects of Big Data. It explores the technological advancements that have established Big Data as a critical element of contemporary analytics, its extensive impact across various sectors, and the ethical challenges it poses. Beginning with the early recognition of Big Data's potential in the 2000s, the paper traces the development of foundational technologies such as Hadoop and the subsequent diversification of tools and methods. It delves into the integration of advanced analytics and machine learning, the rise of cloud-based Big Data services, and the transformative effects on sectors including healthcare, finance, agriculture, and education. The study also examines ethical considerations such as privacy, bias, transparency, and regulatory compliance, emphasizing the need for robust governance frameworks. It investigates the potential of emerging technologies like AI, IoT, and quantum computing to enhance Big Data capabilities further. It highlights future directions, including decentralized data ecosystems, advanced analytical techniques, and enhanced data privacy measures. By providing a panoramic view of Big Data's development, this paper aims to showcase its potential to revolutionize decision-making processes, improve operational efficiency, and drive innovation across industries; it underscores the importance of balancing technological innovation with ethical responsibility to ensure positive societal advancement and global progress. To add a novelty to the discussion, an AI agent Big D was created to provide a relevant analysis of trends in Big Data. The agent uses a multimodal ChatGPT-4o Large Language Model (LLM) from OpenAI and provides its review based on uploaded files and LLM knowledge.},
booktitle = {Proceedings of the 2024 Asia Pacific Conference on Computing Technologies, Communications and Networking},
pages = {60–70},
numpages = {11},
location = {Chengdu, China},
series = {CTCNet '24}
}

@inproceedings{10.1145/3664647.3681695,
author = {Huang, Rongjie and Wang, Yongqi and Hu, Ruofan and Xu, Xiaoshan and Hong, Zhiqing and Yang, Dongchao and Cheng, Xize and Wang, Zehan and Jiang, Ziyue and Ye, Zhenhui and Liu, Luping and Zheng, Siqi and Zhao, Zhou},
title = {VoiceTuner: Self-Supervised Pre-training and Efficient Fine-tuning For Voice Generation},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681695},
doi = {10.1145/3664647.3681695},
abstract = {Voice large language models (LLMs) cast voice synthesis as a language modeling task in a discrete space, and have demonstrated significant progress to date. Despite the recent success, the current development of voice LLMs in low-resource applications is hampered by data scarcity and high computational cost. In this work, we propose VoiceTuner, with a self-supervised pre-training and efficient fine-tuning approach for low-resource voice generation. Specifically, 1) to mitigate data scarcity, we leverage large-scale unlabeled dataset and pre-train VoiceTuner-SSL without pre-defined applications, which can be fine-tuned in downstream tasks; 2) to further reduce the high training cost in complete fine-tuning, we introduce a multiscale transformer adapter to effectively update only around 1% parameters as a plug-and-play module. Experimental results demonstrate that VoiceTuner-SSL presents strong acoustic continuations, and VoiceTuner achieves state-of-the-art results in rich-resource TTS evaluation compared with competitive baseline models. Low-resource (1h, 10h, 30h) downstream applications including zero-shot TTS, instruction TTS, and singing voice synthesis present VoiceTuner's superior audio quality and style similarity with reduced data requirement and computational cost. Audio samples are available at https://VoiceTuner.github.io},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {10630–10639},
numpages = {10},
keywords = {efficient fine-tuning, large language models, speech synthesis},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3613905.3650839,
author = {Hou, Yuki and Tamoto, Haruki and Miyashita, Homei},
title = {"My agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650839},
doi = {10.1145/3613905.3650839},
abstract = {In this study, we propose a novel human-like memory architecture designed for enhancing the cognitive abilities of large language model (LLM)-based dialogue agents. Our proposed architecture enables agents to autonomously recall memories necessary for response generation, effectively addressing a limitation in the temporal cognition of LLMs. We adopt the human memory cue recall as a trigger for accurate and efficient memory recall. Moreover, we developed a mathematical model that dynamically quantifies memory consolidation, considering factors such as contextual relevance, elapsed time, and recall frequency. The agent stores memories retrieved from the user’s interaction history in a database that encapsulates each memory’s content and temporal context. Thus, this strategic storage allows agents to recall specific memories and understand their significance to the user in a temporal context, similar to how humans recognize and recall past experiences.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {7},
numpages = {7},
keywords = {Intelligent Agents, Large Language Models, Memory Retrieval Models, User Experience, User Interface},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3637528.3671485,
author = {Yan, Da and Hamed, Ahmed Abdeen and Chen, Jake Y. and Zaki, Mohammed J.},
title = {23rd International Workshop on Data Mining in Bioinformatics (BIOKDD 2024)},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671485},
doi = {10.1145/3637528.3671485},
abstract = {The goal of the 22nd International Workshop on Data Mining in Bioinformatics (BIOKDD 2023) is to encourage KDD researchers to solve the numerous problems and challenges in Bioinformatics using Data Mining technologies. Based on the organizers' expertise and communities, BIOKDD 2023 features the theme "Large-Scale Data-Driven Methods for Bioinformatics". This theme encourages the use of high-performance computing (HPC) to support the training of large machine learning models for problems in Bioinformatics and Computational Biology. The key goal is to accelerate the convergence between Data Mining and Bioinformatics communities to expedite discoveries in basic biology, medicine and healthcare.The goal of the 23rd International Workshop on Data Mining in Bioinformatics (BIOKDD 2024) is to encourage KDD researchers to solve the numerous problems and challenges in Bioinformatics using Data Mining technologies. Based on the organizers' expertise and communities, BIOKDD 2024 features the theme "Advancing Bioinformatics with LLMs and GenAI". This theme encourages the use of large language models and generative artificial intelligence to solve problems in Bioinformatics and Computational Biology. The key goal is to accelerate the convergence between Data Mining and Bioinformatics communities to expedite discoveries in basic biology, medicine and healthcare.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6747–6748},
numpages = {2},
keywords = {AI, bioinformatics, health informatics},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3657604.3664677,
author = {Barno, Erin and Albaladejo-Gonz\'{a}lez, Mariano and Reich, Justin},
title = {Scaling Generated Feedback for Novice Teachers by Sustaining Teacher Educators' Expertise: A Design to Train LLMs with Teacher Educator Endorsement of Generated Feedback},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664677},
doi = {10.1145/3657604.3664677},
abstract = {When using simulations to design and implement novice teacher practice, a teacher educator may be concerned about if what is technically possible in terms of generating feedback to novice teachers' responses is educationally purposeful to support their learning. This paper details the design of infrastructure to incorporate user feedback within the Teacher Moments platform that is generated by an AI agent, and how we designed to sustain and scale the expertise of mathematics teacher educators when training a large language model. To best support the learning of novice mathematics teacher users to enact ambitious and equitable mathematics teaching, this paper explains the research design of training a large language model by collaborating with mathematics teacher educators to edit or endorse generated feedback across multiple training cycles. This paper also describes the UI design to explore potential of hosting such processes all within the Teacher Moments platform.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {412–416},
numpages = {5},
keywords = {digital simulations, generative AI, natural language processing, professional learning, teacher education},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3626772.3657942,
author = {Rahmani, Hossein A. and Craswell, Nick and Yilmaz, Emine and Mitra, Bhaskar and Campos, Daniel},
title = {Synthetic Test Collections for Retrieval Evaluation},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657942},
doi = {10.1145/3626772.3657942},
abstract = {Constructing test collections in Information Retrieval (IR) is vital for evaluating search algorithms. Obtaining a diverse set of user queries for test collection construction can be challenging, and acquiring relevance judgments, which indicate the appropriateness of retrieved documents, is often costly and resource-intensive. Generating synthetic datasets using Large Language Models (LLMs) has recently gained significant attention in various applications. In information retrieval, while previous work exploited the capabilities of LLMs to generate synthetic queries or documents to augment training data and improve the performance of ranking models, using LLMs for constructing synthetic test collections is relatively unexplored. Previous studies demonstrate that LLMs have the potential to generate synthetic relevance judgments for use in the evaluation of information retrieval systems. In this paper, we comprehensively investigate whether it is possible to use LLMs to construct fully synthetic test collections by generating not only synthetic judgments but also synthetic queries. To qualify the efficacy of synthetic queries for examining system ordering, we analyze how these synthetic data are suitable for building a reliable and reusable test collection and the potential risks of bias such test collections may exhibit towards LLM-based models. Our comprehensive experiments indicate that test collections generated using LLMs can effectively and reliably evaluate system performance.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2647–2651},
numpages = {5},
keywords = {large language model, synthetic data generation, test collection},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3675094.3677545,
author = {Zhang, Shiquan and Ma, Ying and Fang, Le and Jia, Hong and D'Alfonso, Simon and Kostakos, Vassilis},
title = {Enabling On-Device LLMs Personalization with Smartphone Sensing},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3677545},
doi = {10.1145/3675094.3677545},
abstract = {This demo presents a novel end-to-end framework that combines on-device large language models (LLMs) with smartphone sensing technologies to achieve context-aware and personalized services. The framework addresses critical limitations of current personalization solutions via cloud LLMs, such as privacy concerns, latency and cost, and limited personal information. To achieve this, we innovatively proposed deploying LLMs on smartphones with multimodal sensor data through context-aware sensing and customized prompt engineering, ensuring privacy and enhancing personalization performance. A case study involving a university student demonstrated the capability of the framework to provide tailored recommendations. In addition, we show that the framework achieves the best trade-off in privacy, performance, latency, cost, battery and energy consumption between on-device and cloud LLMs. To the best of our knowledge, this is the first framework to provide on-device LLMs personalization with smartphone sensing. Future work will incorporate more diverse sensor data and involve extensive user studies to enhance personalization. Our proposed framework has the potential to substantially improve user experiences across domains including healthcare, productivity, and entertainment.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {186–190},
numpages = {5},
keywords = {end-to-end framework, llm, on-device, personalization, smartphone sensing},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3698383.3699622,
author = {Li, Xiaoyan and Jiang, Cuicui},
title = {Leveraging Prompt Tuning-Based Cognitive Attention to Enhance Logical Inference in Large Language Models},
year = {2024},
isbn = {9798400712951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698383.3699622},
doi = {10.1145/3698383.3699622},
abstract = {Large language models (LLMs) have demonstrated remarkable problem-solving abilities, but the impact of attention on their logical reasoning capabilities remains underexplored. This study investigates the intersection of cognitive neuroscience and LLMs, focusing on prompt fine-tuning techniques to analyze how humanlike cognitive abilities and disabilities affect the problem-solving performance of these models. Two GPT-4 based models were developed using prompt fine-tuning and retrieval-augmented generation (RAG). The models were evaluated using the Criteria Cognitive Aptitude Test (CCAT) dataset, which assesses cognitive abilities such as problem-solving, critical thinking, and information processing. Results showed that the prompt-tuned GPT-4 model achieved the highest accuracy (81.2%), while the model lacking attention performed poorly on questions requiring long-term inference. GPT-4's analysis highlighted the importance of attention in solving problems that demand long-term reference and identified the deficiencies in the attention-deficient model. This study sheds light on the mechanisms of problem-solving in the brain and the potential of AI to approximate human-like cognition, paving the way for future research at the intersection of cognitive neuroscience and artificial intelligence.},
booktitle = {Proceedings of the First ACM International Workshop on Resource-Efficient Mobile and Embedded LLM System in AIoT},
pages = {6–12},
numpages = {7},
keywords = {Attention ability, Cognitive function, Large language model, Logic Reasoning},
location = {Hangzhou, China},
series = {RMEL '24}
}

@inproceedings{10.1145/3696410.3714649,
author = {Quan, Lili and Xie, Xiaofei and Guo, Qianyu and Jiang, Lingxiao and Chen, Sen and Wang, Junjie and Li, Xiaohong},
title = {TensorJSFuzz: Effective Testing of Web-Based Deep Learning Frameworks via Input-Constraint Extraction},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714649},
doi = {10.1145/3696410.3714649},
abstract = {As web applications grow in popularity, developers are increasingly integrating deep learning (DL) models into these environments. Web-based DL frameworks (e.g., TensorFlow.js) are essential for building and deploying such applications. Therefore, ensuring the quality of these frameworks is critical. While extensive testing efforts have been made for native DL frameworks such as TensorFlow and PyTorch, web-based DL frameworks have not yet undergone systematic testing. A key challenge is generating syntactically and semantically valid inputs while designing effective test oracles for web environments. To address this, we introduce TensorJSFuzz, a novel method for testing web-based DL frameworks. To ensure input quality, TensorJSFuzz extracts constraints directly from the source code of DL operators. By leveraging Large Language Models (e.g., ChatGPT) to understand the code and extract input constraints, TensorJSFuzz performs type-aware random generation coupled with dependency-aware refinement to create high-quality test inputs. These inputs are then subjected to differential testing across various backends, including CPU, TensorFlow, Wasm, and WebGL. Our experimental results show that TensorJSFuzz outperforms all baselines in generating valid inputs and identifying bugs. In particular, TensorJSFuzz successfully detected 92 bugs, with 30 already confirmed or fixed by developers, demonstrating its effectiveness in improving the robustness of web-based DL frameworks.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {3405–3414},
numpages = {10},
keywords = {fuzzing, large language model, web-based deep learning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.5555/3721488.3721618,
author = {Martin-Ozimek, Antonio and Jayarathne, Isuru and Larb Mon, Su and Chew, Jouhyeong},
title = {Learning Nonverbal Cues in Multiparty Social Interactions for Robotic Facilitators},
year = {2025},
publisher = {IEEE Press},
abstract = {Conventional behavior cloning (BC) models often struggle to replicate the subtleties of human actions. Previous studies have attempted to address this issue through the development of a new BC technique: Implicit Behavior Cloning (IBC). This new technique consistently outperformed the conventional Mean Squared Error (MSE) BC models in a variety of tasks. Our goal is to replicate the performance of the IBC model by Florence [in Proceedings of the 5th Conference on Robot Learning, 164:158-168, 2022], for social interaction tasks using our custom dataset. While previous studies have explored the use of large language models (LLMs) for enhancing group conversations, they often overlook the significance of non-verbal cues, which constitute a substantial part of human communication. We propose using IBC to replicate nonverbal cues like gaze behaviors. The model is evaluated against various types of facilitator data and compared to an explicit, MSE BC model. Results show that the IBC model outperforms the MSE BC model across session types using the same metrics used in the previous IBC paper. Despite some metrics showing mixed results which are explainable for the custom dataset for social interaction, we successfully replicated the IBC model to generate nonverbal cues. Our contributions are (1) the replication and extension of the IBC model, and (2) a nonverbal cues generation model for social interaction. These advancements facilitate the integration of robots into the complex interactions between robots and humans, e.g., in the absence of a human facilitator.},
booktitle = {Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1042–1046},
numpages = {5},
keywords = {autonomous robots, generative ai, imitation learning, machine learning},
location = {Melbourne, Australia},
series = {HRI '25}
}

@proceedings{10.1145/3607827,
title = {LGM3A '23: Proceedings of the 1st Workshop on Large Generative Models Meet Multimodal Applications},
year = {2023},
isbn = {9798400702839},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the organizing committee, it is our distinct pleasure to extend a warm welcome to the LGM3A Workshop. As Chairs of this conference, we are delighted to bring together a community of scholars, researchers, and professionals from diverse backgrounds, all driven by a shared passion for advancing the frontiers of knowledge in our field.In recent years, the field of large language models has witnessed remarkable growth, with models like GPT, T5, RoBERTa, and BERT transforming our understanding of natural language processing. These models, trained on vast volumes of text data, have empowered us to decode the intricate structures and patterns of human language. Moreover, with the surge in multimodal data-comprising audio, visual, and text-we are now on the cusp of an exciting era where these large generative language models are poised to revolutionize multimodal applications.The workshop serves as a pivotal platform to delve into this dynamic intersection of language models and multimodal applications. In the era of BLIP, Flamingo, KOSMOS, PaLM-E, LLaVA, Visual ChatGPT, and the eagerly awaited GPT-4, we find ourselves at a juncture where large language models are enabling us to understand and generate responses with unprecedented accuracy and nuance across diverse modalities.},
location = {Ottawa ON, Canada}
}

@inproceedings{10.1145/3696410.3714798,
author = {Schwartz, Yuval and Ben-Shimol, Lavi and Mimran, Dudu and Elovici, Yuval and Shabtai, Asaf},
title = {LLMCloudHunter: Harnessing LLMs for Automated Extraction of Detection Rules from Cloud-Based CTI},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714798},
doi = {10.1145/3696410.3714798},
abstract = {As the number and sophistication of cyber attacks have increased, threat hunting has become a critical aspect of active security, enabling proactive detection and mitigation of threats before they cause significant harm. Open-source cyber threat intelligence (OSCTI) is a valuable resource for threat hunters, however, it often comes in unstructured formats that require further manual analysis. Previous studies aimed at automating OSCTI analysis are limited since (1) they failed to provide actionable outputs, (2) they did not take advantage of images present in OSCTI sources, and (3) they focused on on-premises environments, overlooking the growing importance of cloud environments. To address these gaps, we propose LLMCloudHunter, a novel framework that leverages large language models (LLMs) to automatically generate generic-signature detection rule candidates from textual and visual OSCTI data. We evaluated the quality of the rules generated by the proposed framework using 20 annotated real-world cloud threat reports. The results show that our framework achieved a precision of 83% and recall of 99% for the task of accurately extracting API calls made by the threat actor and a precision of 99% with a recall of 97% for IoCs. Additionally, 99.18% of the generated detection rule candidates were successfully compiled and converted into Splunk queries.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {1922–1941},
numpages = {20},
keywords = {cloud, cyber threat intelligence (cti), llm, sigma rules},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3652988.3673918,
author = {Zhang, Taiyu and Zhang, Xuesong and Cools, Robbe and Simeone, Adalberto},
title = {Focus Agent: LLM-Powered Virtual Focus Group},
year = {2024},
isbn = {9798400706257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652988.3673918},
doi = {10.1145/3652988.3673918},
abstract = {In the domain of Human-Computer Interaction, focus groups represent a widely utilised yet resource-intensive methodology, often demanding the expertise of skilled moderators and meticulous preparatory efforts. This study introduces the “Focus Agent,” a Large Language Model (LLM) powered framework that simulates both the focus group (for data collection) and acts as a moderator in a focus group setting with human participants. To assess the data quality derived from the Focus Agent, we ran five focus group sessions with a total of 23 human participants as well as deploying the Focus Agent to simulate these discussions with AI participants. Quantitative analysis indicates that Focus Agent can generate opinions similar to those of human participants. Furthermore, the research exposes some improvements associated with LLMs acting as moderators in focus group discussions that include human participants.},
booktitle = {Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents},
articleno = {10},
numpages = {10},
keywords = {Human-computer Interaction, Intelligent Virtual Agent, Multi Agent Simulation, Virtual Focus Group},
location = {GLASGOW, United Kingdom},
series = {IVA '24}
}

@article{10.1145/3736759,
author = {Liu, Lixin and Jiang, Aiwen and Chen, Yinuo and Liu, Changhong and Huang, Qi and Wang, Mingwen},
title = {Open-ended Autoregressive Visual Storytelling via Parameter Efficient Instruction Tuning},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3736759},
doi = {10.1145/3736759},
abstract = {Visual storytelling (VIST) involves generating coherent, creative, and vivid narrative for a collection of images. It remains an immense challenge within cross-modal domain. Traditional mainstream storytelling work were less proficient in handling long sequential relationships. Though large-scale visual-language pre-training (VLP) models demonstrated promising prospect on cross-modal tasks. So far they still were not particularly adept at handling tasks involving image sequences. Moreover, the reference descriptions in the available VIST benchmark dataset are short and simplistic, which constrains model’s potential capabilities. Current models struggle to produce truly rich and vivid narratives. Therefore, in this paper, we will address these deficiencies, and contribute from both dataset and innovative model aspects. Firstly, by leveraging large language model (LLM), we have constructed a new dataset VIST++ which can enrich vivid narratives for open-ended image sequences. The dataset has potential on providing beneficial support for future model learning. Secondly, we have proposed an innovative auto-regressive story generation model named ReStoryGen. It can be applied to image sequences of varying lengths in an open-ended way. We have performed extensive experiments and evaluations in terms of visual grounding, coherence and non-redundancy. The experiment results have convincingly demonstrated ReStoryGen achieves impressive outcomes through utilizing parameter-efficient instruction-tuning. Related source codes and models are distributed on Github https://github.com/lixinliu1995/story_gen.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = may,
keywords = {Visual Storytelling, Cross-Modal, Instruction-Tuning, BLIP-2, LoRA}
}

@inproceedings{10.1145/3640471.3680446,
author = {Sasaki, Iori and Arikawa, Masatoshi and Lu, Min and Utsumi, Tomihiro and Sato, Ryo},
title = {Geofence-to-Conversation: Hierarchical Geofencing for Augmenting City Walks with Large Language Models},
year = {2024},
isbn = {9798400705069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640471.3680446},
doi = {10.1145/3640471.3680446},
abstract = {This study presents a geofence-based service architecture for city-wide audio augmented reality, tailored for the era of large language models. Traditional geofencing mechanisms, which monitor user entry to geofences, struggle to provide continuous storytelling in areas with few points of interest, degrading the audio tour experiences for pedestrians. Our proposed geofencing architecture consistently incorporates complex and multilayered city features, enabling seamless audio tour experiences. Furthermore, this paper introduces prompt engineering for generating entertaining guide scripts for large language models, that is, the geofence-to-conversation technique. The mobile application developed for the actual field demonstrates the feasibility of our proposed architecture and highlights future challenges in enhancing users’ interaction with a city.},
booktitle = {Adjunct Proceedings of the 26th International Conference on Mobile Human-Computer Interaction},
articleno = {24},
numpages = {5},
location = {Melbourne, VIC, Australia},
series = {MobileHCI '24 Adjunct}
}

@inproceedings{10.1145/3616855.3635690,
author = {Xie, Yukang and Wang, Chengyu and Yan, Junbing and Zhou, Jiyong and Deng, Feiqi and Huang, Jun},
title = {Making Small Language Models Better Multi-task Learners with Mixture-of-Task-Adapters},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635690},
doi = {10.1145/3616855.3635690},
abstract = {Recently, Large Language Models (LLMs) have achieved amazing zero-shot learning performance over a variety of Natural Language Processing (NLP) tasks, especially for text generative tasks. Yet, the large size of LLMs often leads to the high computational cost of model training and online deployment. In our work, we present ALTER, a system that effectively builds the multi-tAsk Learners with mixTure-of-task-adaptERs upon small language models (with &lt;1B parameters) to address multiple NLP tasks simultaneously, capturing the commonalities and differences between tasks, in order to support domain-specific applications. Specifically, in ALTER, we propose the Mixture-of-Task-Adapters (MTA) module as an extension to the transformer architecture for the underlying model to capture the intra-task and inter-task knowledge. A two-stage training method is further proposed to optimize the collaboration between adapters at a small computational cost. Experimental results over a mixture of NLP tasks show that our proposed MTA architecture and the two-stage training method achieve good performance. Based on ALTER, we have also produced MTA-equipped language models for various domains.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {1094–1097},
numpages = {4},
keywords = {language model, multi-task learning, text generation},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3655038.3665950,
author = {Egersdoerfer, Chris and Sareen, Arnav and Bez, Jean Luca and Byna, Suren and Dai, Dong},
title = {ION: Navigating the HPC I/O Optimization Journey using Large Language Models},
year = {2024},
isbn = {9798400706301},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3655038.3665950},
doi = {10.1145/3655038.3665950},
abstract = {Effectively leveraging the complex software and hardware I/O stacks of HPC systems to deliver needed I/O performance has been a challenging task for domain scientists. To identify and address I/O issues in their applications, scientists largely rely on I/O experts to analyze the recorded I/O traces of their applications and provide insights into the potential issues. However, due to the limited number of I/O experts and the growing demand for data-intensive applications across the wide spectrum of sciences, inaccessibility has become a major bottleneck hindering scientists from maximizing their productivity. Inspired by the recent rapid progress of large language models (LLMs), in this work we propose IO Navigator (ION), an LLM-based framework that takes a recorded I/O trace of an application as input and leverages the in-context learning, chain-of-thought, and code generation capabilities of LLMs to comprehensively analyze the I/O trace and provide diagnosis of potential I/O issues. Similar to an I/O expert, ION provides detailed justifications for the diagnosis and an interactive interface for scientists to ask detailed questions about the diagnosis. We illustrate ION's applicability by assessing it on a set of controlled I/O traces generated with different I/O issues. We also demonstrate that ION can match state-of-the-art I/O optimization tools and provide more insightful and adaptive diagnoses for real applications. We believe ION, with its full capabilities, has the potential to become a powerful tool for scientists to navigate through complex I/O subsystems in the future.},
booktitle = {Proceedings of the 16th ACM Workshop on Hot Topics in Storage and File Systems},
pages = {86–92},
numpages = {7},
location = {Santa Clara, CA, USA},
series = {HotStorage '24}
}

@inproceedings{10.1145/3626772.3657995,
author = {Yang, Yiming},
title = {Representation Learning and Information Retrieval},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657995},
doi = {10.1145/3626772.3657995},
abstract = {How to best represent words, documents, queries, entities, relations, and other variables in information retrieval (IR) and related applications has been a fundamental research question for decades. Early IR systems relied on the independence assumptions about words and documents for simplicity and scalability, which were clearly sub-optimal from a semantic point of view. The rapid development of deep neural networks in the past decade has revolutionized the representation learning technologies for contextualized word embedding and graph-enhanced document embedding, leading to the new era of dense IR. This talk highlights such impactful shifts in representation learning for IR and related areas, the new challenges coming along and the remedies, including our recent work in large-scale dense IR [1, 9], in graph-based reasoning for knowledge-enhanced predictions [10], in self-refinement of large language models (LLMs) with retrieval augmented generation (RAG)[2,7] and iterative feedback [3,4], in principle-driven self-alignment of LLMs with minimum human supervision [6], etc. More generally, the power of such deep learning goes beyond IR enhancements, e.g., for significantly improving the state-of-the-art solvers for NP-Complete problems in classical computer science [5,8].},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1–2},
numpages = {2},
keywords = {ai-enhanced foundation models, deep representation learning, graph neural networks, retrieval augmented generation},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3652620.3676877,
author = {Ben Chaaben, Meriem},
title = {Software Modeling Assistance with Large Language Models},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3676877},
doi = {10.1145/3652620.3676877},
abstract = {Software modeling requires a challenging combination of expertise in both domain knowledge and modeling formalisms. Existing methods often fail to provide effective, general modeling assistance. This research introduces a novel approach using large language models (LLMs) to enhance software modeling. Utilizing few-shot prompt learning, our method supports various modeling activities without extensive training data. Initially focusing on static and behavioral formalisms like UML diagrams, we aim to extend this to other paradigms and integrate it into the Model-Driven Engineering (MDE) pipeline. Additionally, we aim to assess productivity, model quality, and accuracy when receiving real-time, context-aware suggestions during modeling tasks.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {188–191},
numpages = {4},
keywords = {modeling formalisms, generative AI, large language models, model-driven engineering, prompt learning, user study},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3580305.3599827,
author = {Drori, Iddo and Zhang, Sarah J. and Shuttleworth, Reece and Zhang, Sarah and Tyser, Keith and Chin, Zad and Lantigua, Pedro and Surbehera, Saisamrit and Hunter, Gregory and Austin, Derek and Tang, Leonard and Hicke, Yann and Simhon, Sage and Karnik, Sathwik and Granberry, Darnell and Udell, Madeleine},
title = {From Human Days to Machine Seconds: Automatically Answering and Generating Machine Learning Final Exams},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599827},
doi = {10.1145/3580305.3599827},
abstract = {A final exam in machine learning at a top institution such as MIT, Harvard, or Cornell typically takes faculty days to write, and students hours to solve. We demonstrate that large language models pass machine learning finals at a human level on finals available online and automatically generate new human-quality final exam questions in seconds. Previous work has developed program synthesis and few-shot learning methods to solve university-level problem set questions in mathematics and STEM courses. In this work, we develop and compare methods that solve final exams, which differ from problem sets in several ways: the questions are longer, have multiple parts, are more complicated, and span a broader set of topics. We curate a dataset and benchmark of questions from machine learning final exams available online and code for answering these questions and generating new questions. We show how to generate new questions from other questions and course notes. For reproducibility and future research on this final exam benchmark, we use automatic checkers for multiple-choice, numeric, and questions with expression answers. A student survey comparing the quality, appropriateness, and difficulty of machine-generated questions with human-written questions shows that across multiple aspects, machine-generated questions are indistinguishable from human-generated questions and are suitable for final exams. We perform ablation studies comparing zero-shot learning with few-shot learning and chain-of-thought prompting using GPT-3, OPT, Codex, and ChatGPT across machine learning topics and find that few-shot learning methods perform best. We highlight the transformative potential of language models to streamline the writing and solution of large-scale assessments, significantly reducing the workload from human days to mere machine seconds. Our results suggest that rather than banning large language models such as ChatGPT in class, instructors should teach students to harness them by asking students meta-questions about correctness, completeness, and originality of the responses generated, encouraging critical thinking in academic studies.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3947–3955},
numpages = {9},
keywords = {few-shot learning, large language models, machine learning, program synthesis, quantitative reasoning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3643796.3648451,
author = {Zharov, Yaroslav and Khudyakov, Yury and Fedotova, Evgeniia and Grigorenko, Evgeny and Bogomolov, Egor},
title = {Tool-augmented LLMs as a Universal Interface for IDEs},
year = {2024},
isbn = {9798400705809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643796.3648451},
doi = {10.1145/3643796.3648451},
abstract = {Modern-day Integrated Development Environments (IDEs) have come a long way from the early text editing utilities to the complex programs encompassing thousands of functions to help developers. However, with the increasing number of efficiency-enhancing tools incorporated, IDEs gradually became sophisticated software with a steep learning curve. The rise of the Large Language Models (LLMs) capable of both natural language dialogue and code generation leads to a discourse on the obsolescence of the concept of IDE. In this work, we offer a view on the place of the LLMs in the IDEs as the universal interface wrapping the IDE facilities. We envision a model that is able to perform complex actions involving multiple IDE features upon user command, stripping the user experience of the tedious work involved in searching through options and actions. For the practical part of the work, we engage with the works exploring the ability of LLMs to call for external tools to expedite a given task execution. We showcase a proof-of-concept of such a tool.},
booktitle = {Proceedings of the 1st ACM/IEEE Workshop on Integrated Development Environments},
pages = {40–42},
numpages = {3},
keywords = {IDE, LLM, ToolFormer},
location = {Lisbon, Portugal},
series = {IDE '24}
}

@inproceedings{10.1145/3696410.3714723,
author = {Wen, Bao and Gu, Jingjing and Han, Hao and Yu, Pengfei and Liu, Yang},
title = {Instruction Vulnerability Prediction for WebAssembly with Semantic Enhanced Code Property Graph},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714723},
doi = {10.1145/3696410.3714723},
abstract = {WebAssembly (Wasm) is a universal low-level bytecode designed to build modern web systems. Recent studies have shown that technologies such as voltage scaling and RowHammer attacks are expected to increase the likelihood of bit flips, which may cause unacceptable or catastrophic system failures. This raises concerns about the impact of bit flips on Wasm programs, which run as instructions in web systems, and it is an undeveloped topic since the features of Wasm differ from traditional programs. In this paper, we propose a novel paradigm, namely IVPSEG, to understand the error propagation of bit flips within Wasm programs. Specifically, we first use Large Language Models (LLMs) to automatically extract instruction embeddings containing semantic knowledge of each instruction's context. Then, we exploit these embeddings and program structure (control execution and data transfer) to construct a semantic enhanced code property graph, which implicates the potential path of error propagation. Based on this graph, we utilize graph neural networks and attention diffusion to optimize instruction embeddings by capturing different error propagation patterns for instruction vulnerability prediction. In particular, we build a Wasm compilation and fault generation system to simulate bit flips at Wasm runtime. Our experimental results with 14 benchmark programs and test cases show IVPSEG outperforms the state-of-the-art methods in terms of accuracy (average 13.06%ͽ ), F1-score (average 14.93%↑), and model robustness.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4134–4145},
numpages = {12},
keywords = {bit flips, error propagation, instruction vulnerability prediction, webassembly},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3650105.3652290,
author = {Abukhalaf, Seif and Hamdaqa, Mohammad and Khomh, Foutse},
title = {PathOCL: Path-Based Prompt Augmentation for OCL Generation with GPT-4},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650105.3652290},
doi = {10.1145/3650105.3652290},
abstract = {The rapid progress of AI-powered programming assistants, such as GitHub Copilot, has facilitated the development of software applications. These assistants rely on large language models (LLMs), which are foundation models (FMs) that support a wide range of tasks related to understanding and generating language. LLMs have demonstrated their ability to express UML model specifications using formal languages like the Object Constraint Language (OCL). However, the context size of the prompt is limited by the number of tokens an LLM can process. This limitation becomes significant as the size of UML class models increases. In this study, we introduce PathOCL, a novel path-based prompt augmentation technique designed to facilitate OCL generation. PathOCL addresses the limitations of LLMs, specifically their token processing limit and the challenges posed by large UML class models. PathOCL is based on the concept of chunking, which selectively augments the prompts with a subset of UML classes relevant to the English specification. Our findings demonstrate that PathOCL, compared to augmenting the complete UML class model (UML-Augmentation), generates a higher number of valid and correct OCL constraints using the GPT-4 model. Moreover, the average prompt size crafted using PathOCL significantly decreases when scaling the size of the UML class models.},
booktitle = {Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
pages = {108–118},
numpages = {11},
keywords = {object constraint language (OCL), simple path, prompt engineering, large language model (LLM), generative pre-trained transformer (GPT), foundation model (FM)},
location = {Lisbon, Portugal},
series = {FORGE '24}
}

@inproceedings{10.1145/3637528.3671965,
author = {Chen, Lin and Xu, Fengli and Li, Nian and Han, Zhenyu and Wang, Meng and Li, Yong and Hui, Pan},
title = {Large Language Model-driven Meta-structure Discovery in Heterogeneous Information Network},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671965},
doi = {10.1145/3637528.3671965},
abstract = {Heterogeneous information networks (HIN) have gained increasing popularity in recent years for capturing complex relations between diverse types of nodes. Meta-structures are proposed as a useful tool to identify the important patterns in HINs, but hand-crafted meta-structures pose significant challenges for scaling up, drawing wide research attention towards developing automatic search algorithms. Previous efforts primarily focused on searching for meta-structures with good empirical performance, overlooking the importance of human comprehensibility and generalizability. To address this challenge, we draw inspiration from the emergent reasoning abilities of large language models (LLMs). We propose ReStruct, a meta-structure search framework that integrates LLM reasoning into the evolutionary procedure. ReStruct uses a grammar translator to encode the meta-structures into natural language sentences, and leverages the reasoning power of LLMs to evaluate their semantic feasibility. Besides, ReStruct also employs performance-oriented evolutionary operations. These two competing forces allow ReStruct to jointly optimize the semantic explainability and empirical performance of meta-structures. Furthermore, ReStruct contains a differential LLM explainer to generate and refine natural language explanations for the discovered meta-structures by reasoning through the search history. Experiments on eight representative HIN datasets demonstrate that ReStruct achieves state-of-the-art performance in both recommendation and node classification tasks. Moreover, a survey study involving 73 graduate students shows that the discovered meta-structures and generated explanations by ReStruct are substantially more comprehensible. Our code and questionnaire are available at https://github.com/LinChen-65/ReStruct.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {307–318},
numpages = {12},
keywords = {graph neural networks, heterogeneous information networks, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inbook{10.1145/3676536.3676816,
author = {Yin, Yuxuan and Wang, Yu and Xu, Boxun and Li, Peng},
title = {ADO-LLM: Analog Design Bayesian Optimization with In-Context Learning of Large Language Models},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676816},
abstract = {Analog circuit design requires substantial human expertise and involvement, which is a significant roadblock to design productivity. Bayesian Optimization (BO), a popular machine-learning-based optimization strategy, has been leveraged to automate analog design given its applicability across various circuit topologies and technologies. Traditional BO methods employ black-box Gaussian Process surrogate models and optimized labeled data queries to find optimization solutions by trading off between exploration and exploitation. However, the search for the optimal design solution in BO can be expensive from both a computational and data usage point of view, particularly for high-dimensional optimization problems. This paper presents ADO-LLM, the first work integrating large language models (LLMs) with Bayesian Optimization for analog design optimization. ADO-LLM leverages the LLM's ability to infuse domain knowledge to rapidly generate viable design points to remedy BO's inefficiency in finding high-value design areas specifically under the limited design space coverage of the BO's probabilistic surrogate model. In the meantime, sampling of design points evaluated in the iterative BO process provides quality demonstrations for the LLM to generate high-quality design points while leveraging infused broad design knowledge. Furthermore, the diversity brought by BO's exploration enriches the contextual understanding of the LLM and allows it to more broadly search in the design space and prevent repetitive and redundant suggestions. We evaluate the proposed framework on two different types of analog circuits and demonstrate notable improvements in design efficiency and effectiveness.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {81},
numpages = {9}
}

@inproceedings{10.1145/3626772.3657935,
author = {Huly, Oz and Pogrebinsky, Idan and Carmel, David and Kurland, Oren and Maarek, Yoelle},
title = {Old IR Methods Meet RAG},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657935},
doi = {10.1145/3626772.3657935},
abstract = {Retrieval augmented generation (RAG) is an important approach to provide large language models (LLMs) with context pertaining to the text generation task: given a prompt, passages are retrieved from external corpora to ground the generation with more relevant and/or fresher data. Most previous studies used dense retrieval methods for applying RAG in question answering scenarios. However, recent work showed that traditional information retrieval methods (a.k.a. sparse methods) can do as well as or even better than dense retrieval ones. In particular, it was shown that Okapi BM25 outperforms dense retrieval methods, in terms of perplexity, for the fundamental text completion task in LLMs. We extend this study and show, using two popular LLMs, that a broad set of sparse retrieval methods achieve better results than all the dense retrieval methods we experimented with, for varying lengths of queries induced from the prompt. Furthermore, we found that Okapi BM25 is substantially outperformed by a term-proximity retrieval method (MRF), which is in turn outperformed by a pseudo-feedback-based bag-of-terms approach (relevance model). Additional exploration sheds some light on the effectiveness of lexical retrieval methods for RAG. Our findings call for further study of classical retrieval methods for RAG.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2559–2563},
numpages = {5},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3706598.3713448,
author = {Li, Jiahao Nick and Zhang, Zhuohao (Jerry) and Ma, Jiaju},
title = {OmniQuery: Contextually Augmenting Captured Multimodal Memories to Enable Personal Question Answering},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713448},
doi = {10.1145/3706598.3713448},
abstract = {People often capture memories through photos, screenshots, and videos. While existing AI-based tools enable querying this data using natural language, they only support retrieving individual pieces of information like certain objects in photos, and struggle with answering more complex queries that involve interpreting interconnected memories like sequential events. We conducted a one-month diary study to collect realistic user queries and generated a taxonomy of necessary contextual information for integrating with captured memories. We then introduce OmniQuery, a novel system that is able to answer complex personal memory-related questions that require extracting and inferring contextual information. OmniQuery augments individual captured memories through integrating scattered contextual information from multiple interconnected memories. Given a question, OmniQuery retrieves relevant augmented memories and uses a large language model (LLM) to generate answers with references. In human evaluations, we show the effectiveness of OmniQuery with an accuracy of 71.5%, outperforming a conventional RAG system by winning or tying for 74.5% of the time.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {635},
numpages = {20},
keywords = {personal memory, contextual augmentation, diary study, multimodal question answering, RAG},
location = {
},
series = {CHI '25}
}

@article{10.14778/3717755.3717772,
author = {Zhao, Fuheng and Deep, Shaleen and Psallidas, Fotis and Floratou, Avrilia and Agrawal, Divyakant and Abbadi, Amr El},
title = {Sphinteract: Resolving Ambiguities in NL2SQL through User Interaction},
year = {2025},
issue_date = {December 2024},
publisher = {VLDB Endowment},
volume = {18},
number = {4},
issn = {2150-8097},
url = {https://doi.org/10.14778/3717755.3717772},
doi = {10.14778/3717755.3717772},
abstract = {Translating natural language questions into SQL queries (NL2SQL) is a challenging task of great practical importance. Prior work has extensively studied how to address NL2SQL using Large Language Models (LLMs) with solutions ranging from careful prompt engineering, to fine-tuning existing LLMs, or even training custom models. However, a remaining challenging problem in NL2SQL is the inherent ambiguity in the natural language questions asked by users. In this paper, we introduce Sphinteract, a framework designed to assist LLMs in generating high-quality SQL answers that accurately reflect the user intent. Our key insight to resolve ambiguity is to take into account minimal user feedback interactively. We introduce the Summarize, Review, Ask (SRA) paradigm, which guides LLMs in identifying ambiguities in NL2SQL tasks and generates targeted questions for the user to answer. We propose three different methods of how to process user feedback and generate SQL queries based on user input. Our experiments on the challenging KaggleDBQA and BIRD benchmarks demonstrate that by means of asking clarification questions to the user, LLMs can efficiently incorporate the feedback, resulting in accuracy improvements of up to 42%.},
journal = {Proc. VLDB Endow.},
month = may,
pages = {1145–1158},
numpages = {14}
}

@inproceedings{10.1145/3581783.3612274,
author = {Liang, Kongming and Wang, Xinran and Zhang, Haiwen and Ma, Zhanyu and Guo, Jun},
title = {Hierarchical Visual Attribute Learning in the Wild},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612274},
doi = {10.1145/3581783.3612274},
abstract = {Observing objects' attributes at different levels of detail is a fundamental aspect of how humans perceive and understand the world around them. Existing studies focused on attribute prediction in a flat way, but they overlook the underlying attribute hierarchy, e.g., navy blue is a subcategory of blue. In recent years, large language models, e.g., ChatGPT, have emerged with the ability to perform an extensive range of natural language processing tasks like text generation and classification. The factual knowledge learned by LLM can assist us build the hierarchical relations of visual attributes in the wild. Based on that, we propose a model called the object-specific attribute relation net, which takes advantage of three types of relations among attributes - positive, negative, and hierarchical - to better facilitate attribute recognition in images. Guided by the extracted hierarchical relations, our model can predict attributes from coarse to fine. Additionally, we introduce several evaluation metrics for attribute hierarchy to comprehensively assess the model's ability to comprehend hierarchical relations. Our extensive experiments demonstrate that our proposed hierarchical annotation brings improvements to the model's understanding of hierarchical relations of attributes, and the object-specific attribute relation net can recognize visual attributes more accurately.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {3415–3423},
numpages = {9},
keywords = {attribute learning, hierarchical multi-label learning, large language model},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3630106.3658932,
author = {Mahomed, Yaaseen and Crawford, Charlie M. and Gautam, Sanjana and Friedler, Sorelle A. and Metaxa, Dana\"{e}},
title = {Auditing GPT's Content Moderation Guardrails: Can ChatGPT Write Your Favorite TV Show?},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658932},
doi = {10.1145/3630106.3658932},
abstract = {Large language models (LLMs) are increasingly appearing in consumer-facing products. To prevent problematic use, the organizations behind these systems have put content moderation guardrails in place that prevent the models from generating content they consider harmful. However, most of these enforcement standards and processes are opaque. Although they play a major role in the user experience of these tools, automated content moderation tools have received relatively less attention than other aspects of the models. This study undertakes an algorithm audit of OpenAI’s ChatGPT with the goal of better understanding its content moderation guardrails and their potential biases. To evaluate performance on a broad cultural range of content, we generate a dataset of 100 popular United States television shows with one to three synopses for each episode in the first season of each show (3,309 total synopses). We probe GPT’s content moderation endpoint (ME) to identify violating content both in the synopses themselves, and in GPT’s own outputs when asked to generate a script based on each synopsis, also comparing with ME outputs on 81 real scripts from the same TV shows (269,578 total ME outputs). Our findings show that a large number of GPT-generated and real scripts flag as content violations (about 18% of GPT scripts and 69% of real ones). Using metadata, we find that TV maturity ratings, as well as certain genres (Animation, Crime, Fantasy, and others) are statistically significantly related to a script’s likelihood of flagging. We conclude by discussing the implications of LLM self-censorship and directions for future research on their moderation procedures.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {660–686},
numpages = {27},
keywords = {AI system audit, content moderation, text generation},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3627673.3679077,
author = {Wallace, Joseph and Dogra, Tushar and Qiao, Wei and Wang, Yuan},
title = {Advertiser Content Understanding via LLMs for Google Ads Safety},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679077},
doi = {10.1145/3627673.3679077},
abstract = {Ads Content Safety at Google requires classifying billions of ads for Google Ads content policies. Consistent and accurate policy enforcement is important for advertiser experience and user safety and it is a challenging problem, so there is a lot of value for improving it for advertisers and users. Inconsistent policy enforcement causes increased policy friction and poor experience with good advertisers, and bad advertisers exploit the inconsistency by creating multiple similar ads in the hope that some will get through our defenses. This study proposes a method to understand advertiser's intent for content policy violations, using Large Language Models (LLMs). We focus on identifying good advertisers to reduce content over-flagging and improve advertiser experience, though the approach can easily be extended to classify bad advertisers too. We generate advertiser's content profile based on multiple signals from their ads, domains, targeting info, etc. We then use LLMs to classify the advertiser content profile, along with relying on any knowledge the LLM has of the advertiser, their products or brand, to understand whether they are likely to violate a certain policy or not. After minimal prompt tuning our method was able to reach 95% accuracy on a small test set.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5566–5567},
numpages = {2},
keywords = {content moderation, content understanding, large language model},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3597503.3639150,
author = {Ma, Zeyang and Chen, An Ran and Kim, Dong Jae and Chen, Tse-Hsun and Wang, Shaowei},
title = {LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639150},
doi = {10.1145/3597503.3639150},
abstract = {Logs are important in modern software development with runtime information. Log parsing is the first step in many log-based analyses, that involve extracting structured information from unstructured log data. Traditional log parsers face challenges in accurately parsing logs due to the diversity of log formats, which directly impacts the performance of downstream log-analysis tasks. In this paper, we explore the potential of using Large Language Models (LLMs) for log parsing and propose LLMParser, an LLM-based log parser based on generative LLMs and few-shot tuning. We leverage four LLMs, Flan-T5-small, Flan-T5-base, LLaMA-7B, and ChatGLM-6B in LLMParsers. Our evaluation of 16 open-source systems shows that LLMParser achieves statistically significantly higher parsing accuracy than state-of-the-art parsers (a 96% average parsing accuracy). We further conduct a comprehensive empirical analysis on the effect of training size, model size, and pre-training LLM on log parsing accuracy. We find that smaller LLMs may be more effective than more complex LLMs; for instance where Flan-T5-base achieves comparable results as LLaMA-7B with a shorter inference time. We also find that using LLMs pre-trained using logs from other systems does not always improve parsing accuracy. While using pre-trained Flan-T5-base shows an improvement in accuracy, pre-trained LLaMA results in a decrease (decrease by almost 55% in group accuracy). In short, our study provides empirical evidence for using LLMs for log parsing and highlights the limitations and future research direction of LLM-based log parsers.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {99},
numpages = {13},
keywords = {log parsing, log analysis, large language model},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3641234.3671031,
author = {Du, Jiachun and Zhong, Hanjin and Zhou, Liang and Li, Jianye},
title = {FactoryDecoder: Expertise-Free Digital Twin Generation and Modification Tool},
year = {2024},
isbn = {9798400705168},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641234.3671031},
doi = {10.1145/3641234.3671031},
abstract = {Digital twins are essential visualization applications in the manufacturing field. However, their development requires specialized 3D engineers, which often complicates modifications during the operation stage. To address this complexity, we introduce FactoryDecoder, a development tool for non-expert users in 3D engineering to generate and modify digital twins using natural language inputs. FactoryDecoder converts users' descriptions of production line into hierarchical asset codes, facilitating the automated layout and simplified modification of digital twins. Furthermore, if the system finds that the 3D asset library lacks appropriate device representations, it will automatically use a 3D mesh generator to create new ones. We evaluate the performance of large language models (LLMs) to optimize FactoryDecoder's capabilities. Preliminary user studies highlight FactoryDecoder's effectiveness.},
booktitle = {ACM SIGGRAPH 2024 Posters},
articleno = {55},
numpages = {2},
keywords = {Data visualization, Digital twin, Generative artificial intelligence, Large language model},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{10.1145/3613905.3650767,
author = {Nepal, Subigya and Pillai, Arvind and Campbell, William and Massachi, Talie and Choi, Eunsol Soul and Xu, Xuhai and Kuc, Joanna and Huckins, Jeremy F and Holden, Jason and Depp, Colin and Jacobson, Nicholas and Czerwinski, Mary P and Granholm, Eric and Campbell, Andrew},
title = {Contextual AI Journaling: Integrating LLM and Time Series Behavioral Sensing Technology to Promote Self-Reflection and Well-being using the MindScape App},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650767},
doi = {10.1145/3613905.3650767},
abstract = {MindScape aims to study the benefits of integrating time series behavioral patterns (e.g., conversational engagement, sleep, location) with Large Language Models (LLMs) to create a new form of contextual AI journaling, promoting self-reflection and well-being. We argue that integrating behavioral sensing in LLMs will likely lead to a new frontier in AI. In this Late-Breaking Work paper, we discuss the MindScape contextual journal App design that uses LLMs and behavioral sensing to generate contextual and personalized journaling prompts crafted to encourage self-reflection and emotional development. We also discuss the MindScape study of college students based on a preliminary user study and our upcoming study to assess the effectiveness of contextual AI journaling in promoting better well-being on college campuses. MindScape represents a new application class that embeds behavioral intelligence in AI.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {86},
numpages = {8},
keywords = {AI, Behavioral Sensing, Journaling, Large Language Models, Mental Health, Passive Sensing, Self-reflection, Smartphones, Well-being},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.5555/3635637.3662979,
author = {Liu, Jijia and Yu, Chao and Gao, Jiaxuan and Xie, Yuqing and Liao, Qingmin and Wu, Yi and Wang, Yu},
title = {LLM-Powered Hierarchical Language Agent for Real-time Human-AI Coordination},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {AI agents powered by Large Language Models (LLMs) have made significant advances, enabling them to assist humans in diverse complex tasks and leading to a revolution in human-AI coordination. LLM-powered agents typically require invoking LLM APIs and employing artificially designed complex prompts, which results in high inference latency. While this paradigm works well in scenarios with minimal interactive demands, such as code generation, it is unsuitable for highly interactive and real-time applications, such as gaming. Traditional gaming AI often employs small models or reactive policies, enabling fast inference but offering limited task completion and interaction abilities. In this work, we consider Overcooked as our testbed where players could communicate with natural language and cooperate to serve orders. We propose a Hierarchical Language Agent (HLA) for human-AI coordination that provides both strong reasoning abilities while keeping real-time execution. In particular, HLA adopts a hierarchical framework and comprises three modules: a proficient LLM, referred to as Slow Mind, for intention reasoning and language interaction, a lightweight LLM, referred to as Fast Mind, for generating macro actions, and a reactive policy, referred to as Executor, for transforming macro actions into atomic actions. Human studies show that HLA outperforms other baseline agents, including slow-mind-only agents and fast-mind-only agents, with stronger cooperation abilities, faster responses, and more consistent language communications.},
booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
pages = {1219–1228},
numpages = {10},
keywords = {hierarchical reasoning and planning, language agents, large language models, real-time human-ai coordination},
location = {Auckland, New Zealand},
series = {AAMAS '24}
}

@article{10.1145/3689736,
author = {Yang, Chenyuan and Deng, Yinlin and Lu, Runyu and Yao, Jiayi and Liu, Jiawei and Jabbarvand, Reyhaneh and Zhang, Lingming},
title = {WhiteFox: White-Box Compiler Fuzzing Empowered by Large Language Models},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3689736},
doi = {10.1145/3689736},
abstract = {Compiler correctness is crucial, as miscompilation can falsify program behaviors, leading to serious consequences over the software supply chain. In the literature, fuzzing has been extensively studied to uncover compiler defects. However, compiler fuzzing remains challenging: Existing arts focus on black- and grey-box fuzzing, which generates test programs without sufficient understanding of internal compiler behaviors. As such, they often fail to construct test programs to exercise intricate optimizations. Meanwhile, traditional white-box techniques, such as symbolic execution, are computationally inapplicable to the giant codebase of compiler systems. Recent advances demonstrate that Large Language Models (LLMs) excel in code generation/understanding tasks and even have achieved state-of-the-art performance in black-box fuzzing. Nonetheless, guiding LLMs with compiler source-code information remains a missing piece of research in compiler testing.
 
 
 
 
 
 
 

 
 
 
 
 
 
 
To this end, we propose WhiteFox, the first white-box compiler fuzzer using LLMs with source-code information to test compiler optimization, with a spotlight on detecting deep logic bugs in the emerging deep learning (DL) compilers. WhiteFox adopts a multi-agent framework: (i) an LLM-based analysis agent examines the low-level optimization source code and produces requirements on the high-level test programs that can trigger the optimization; (ii) an LLM-based generation agent produces test programs based on the summarized requirements. Additionally, optimization-triggering tests are also used as feedback to further enhance the test generation prompt on the fly. Our evaluation on the three most popular DL compilers (i.e., PyTorch Inductor, TensorFlow-XLA, and TensorFlow Lite) shows that WhiteFox can generate high-quality test programs to exercise deep optimizations requiring intricate conditions, practicing up to 8 times more optimizations than state-of-the-art fuzzers. To date, WhiteFox has found in total 101 bugs for the compilers under test, with 92 confirmed as previously unknown and 70 already fixed. Notably, WhiteFox has been recently acknowledged by the PyTorch team, and is in the process of being incorporated into its development workflow. Finally, beyond DL compilers, WhiteFox can also be adapted for compilers in different domains, such as LLVM, where WhiteFox has already found multiple bugs.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {296},
numpages = {27},
keywords = {Code Analysis, Fuzzing, Large Language Models, White-box Testing}
}

@inproceedings{10.1145/3650105.3652300,
author = {Wu, Yifan and Li, Ying and Yu, Siyu},
title = {Commit Message Generation via ChatGPT: How Far Are We?},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650105.3652300},
doi = {10.1145/3650105.3652300},
abstract = {Commit messages concisely describe code changes in natural language and are important for software maintenance. Various automatic commit message generation approaches have been proposed, such as retrieval-based, learning-based, and hybrid approaches. Recently, large language models have shown impressive performance in many natural language processing tasks. Among them, ChatGPT is the most popular one and has attracted wide attention from the software engineering community. ChatGPT demonstrates the ability of in-context learning (ICL), which allows ChatGPT to perform downstream tasks by learning from just a few demonstrations without explicit model tuning. However, it remains unclear how well ChatGPT performs in the commit message generation task via ICL. Therefore, in this paper, we conduct a preliminary evaluation of ChatGPT with ICL on commit message generation. Specifically, we first explore the impact of two key settings on the performance of ICL on commit message generation. Then, based on the best settings, we compare ChatGPT with several state-of-the-art approaches. The results show that a carefully-designed demonstration can lead to substantial improvements for ChatGPT on commit message generation. Furthermore, ChatGPT outperforms all the retrieval-based and learning-based approaches in terms of BLEU, METEOR, ROUGE-L, and Cider, and is comparable to hybrid approaches. Based on our findings, we outline several open challenges and opportunities for ChatGPT-based commit message generation.},
booktitle = {Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
pages = {124–129},
numpages = {6},
keywords = {commit message generation, large language model, in-context learning},
location = {Lisbon, Portugal},
series = {FORGE '24}
}

@inproceedings{10.1145/3639477.3639719,
author = {Di, Peng and Li, Jianguo and Yu, Hang and Jiang, Wei and Cai, Wenting and Cao, Yang and Chen, Chaoyu and Chen, Dajun and Chen, Hongwei and Chen, Liang and Fan, Gang and Gong, Jie and Gong, Zi and Hu, Wen and Guo, Tingting and Lei, Zhichao and Li, Ting and Li, Zheng and Liang, Ming and Liao, Cong and Liu, Bingchang and Liu, Jiachen and Liu, Zhiwei and Lu, Shaojun and Shen, Min and Wang, Guangpei and Wang, Huan and Wang, Zhi and Xu, Zhaogui and Yang, Jiawei and Ye, Qing and Zhang, Gehao and Zhang, Yu and Zhao, Zelin and Zheng, Xunjin and Zhou, Hailian and Zhu, Lifu and Zhu, Xianying},
title = {CodeFuse-13B: A Pretrained Multi-lingual Code Large Language Model},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639719},
doi = {10.1145/3639477.3639719},
abstract = {Code Large Language Models (Code LLMs) have gained significant attention in the industry due to their wide applications in the full lifecycle of software engineering. However, the effectiveness of existing models in understanding non-English inputs for multi-lingual code-related tasks is still far from well studied. This paper introduces CodeFuse-13B, an open-sourced pre-trained code LLM 2. It is specifically designed for code-related tasks with both English and Chinese prompts and supports over 40 programming languages. CodeFuse achieves its effectiveness by utilizing a high-quality pre-training dataset that is carefully filtered by program analyzers and optimized during the training process. Extensive experiments are conducted using real-world usage scenarios, the industry-standard benchmark HumanEval-x, and the specially designed CodefuseEval for Chinese prompts. To assess the effectiveness of CodeFuse, we actively collected valuable human feedback from the AntGroup's software development process where CodeFuse has been successfully deployed. The results demonstrate that CodeFuse-13B achieves a HumanEval pass@1 score of 37.10%, positioning it as one of the top multi-lingual code LLMs with similar parameter sizes. In practical scenarios, such as code generation, code translation, code comments, and testcase generation, CodeFuse performs better than other models when confronted with Chinese prompts.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {418–429},
numpages = {12},
keywords = {code large language models, multi-lingual, chinese prompts},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@article{10.1145/3712588,
author = {Liu, Yuanxing and Pei, Jiahuan and Zhang, Wei-Nan and Li, Ming and Che, Wanxiang and de Rijke, Maarten},
title = {Augmentation with Neighboring Information for Conversational Recommendation},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/3712588},
doi = {10.1145/3712588},
abstract = {Conversational recommender systems (CRSs) suggest items to users by understanding their needs and preferences from natural language conversations. While users can freely express preferences, modeling needs and preferences solely from users’ conversations is challenging due to the sparsity of the available information. Prior work introduces external resources to enrich information expressed in conversations. Obtaining such resources is challenging and not always effective. Can learning intrinsic relations among conversations and items enhance information without the use of external resources? Inspired by collaborative filtering, we propose to use so-called neighboring relations within training data, i.e., relations between conversations, items, and similar conversations and items, to enhance our algorithmic understanding of CRSs.We propose a neighboring relations enhanced conversational recommender system (NR-CRS) and study how neighboring relations improve CRSs from two angles: (i) We mine preference information from neighboring conversations to enhance the modeling of user representations and learning of user preferences. (ii) We generate negative samples based on neighboring items to extend the data available for training CRSs. Experiments on the ReDial dataset show that neighboring relations enhanced conversational recommender system (NR-CRS) outperforms the state-of-the-art baseline by 11.3–20.6% regarding recommendation performance while generating informative and diverse responses. We also assess the capabilities of large language models (i.e., Llama 2, Llama 3, and Chinese-Alpaca2) for CRSs. While the generated responses exhibit enhanced fluency and informativeness, recommending target items with LLMs remains challenging; we recommend that LLMs be used as a decoding base for NR-CRS to generate relevant and informative responses.},
journal = {ACM Trans. Inf. Syst.},
month = feb,
articleno = {62},
numpages = {49},
keywords = {Conversational recommendation, Neighboring relations}
}

@article{10.1145/3735640,
author = {Tang, Mingxin and Chen, Wei and Wu, Lizhou and Huang, Libo and Zeng, Kun},
title = {ChatDSE: A Zero-Shot Microarchitecture Design Space Explorer Powered by GPT4.0},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3735640},
doi = {10.1145/3735640},
abstract = {Design Space Exploration (DSE) aims at identifying Pareto optimal synthesis configurations. Previous works require microarchitecture samples with key labels, including power and clock cycles, to train their models. However, as the chip design space expands rapidly, the cost of sampling the design space has significantly increased, due to the growing number of samples and time-consuming Very Large Scale Integration (VLSI) implementation flow. Recent advancements in Large Language Models (LLMs) have demonstrated their remarkable power in zero-shot learning tasks, presenting an innovative strategy for accomplishing DSE. Hence, this article presents ChatDSE, a zero-shot framework for DSE that is powered by the advanced capabilities of the LLM GPT4.0. Firstly, this framework analyzes the nature of the target microarchitecture and generates a corresponding system context to provide the prior knowledge of the microarchitecture. Secondly, a proposed sampling algorithm, PriorDC, identifies the most representative samples with pseudo labels. One of these samples is chosen as a baseline, whose power and clock cycles labels are set as 1, and the remaining sample labels are obtained by chatting with GPT4.0. Finally, ChatDSE engages in a dialogue with GPT4.0 to estimate the power and clock cycles of designs within the space, ultimately identifying the Pareto optimal design set. In the DSE for the RISC-V Berkeley Out-of-Order Machine (BOOM), experimental results show that ChatDSE is capable of identifying optimal designs and accelerates the exploration process by 574 times when compared to the state-of-the-art DSE methodologies.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = may,
keywords = {Design space exploration, Zero-shot, Large language model, Pareto optimization, BOOM microarchitecture}
}

@inproceedings{10.1145/3700297.3700367,
author = {Wu, Weimei and Hu, Jianhua and Huang, Yingjie and Zeng, Wenying and Shao, Hui},
title = {Intelligent Teaching Platform Based on Large Models},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700367},
doi = {10.1145/3700297.3700367},
abstract = {Currently, most educational platforms suffer from limited resources, delayed updates, lack of personalized recommendations, monotonous teaching modes, poor interactivity, inadequate adaptability, and incomplete assessment methods. Focused on the innovative needs of the education sector, this article develops an intelligent teaching platform based on large language models. The platform aims to provide a comprehensive and multi-level educational solution for students and teachers, offering not only diverse and up-to-date teaching resources but also genuinely personalized instruction to create a highly interactive teaching environment. With core features like AI-powered real-time tutoring assistants, digital human video creation for lectures, and big data analysis of learning conditions, the platform significantly enhances teaching quality and learning experiences. It can timely and accurately answer various student inquiries, offering precise real-time solutions and personalized advice to help students better plan and execute their learning strategies. Teachers can easily upload background images and lecture scripts to effortlessly generate digital human teaching videos. Moreover, by closely monitoring student learning data, teachers can adjust their teaching strategies appropriately and continuously optimize teaching outcomes. As the digital transformation in education progresses, this platform is poised to become a key force in driving educational innovation and improving teaching quality, effectively promoting the efficient use and rational allocation of educational resources.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {409–415},
numpages = {7},
keywords = {AI real-time tutoring, Large language model, digital human teaching video, intelligent teaching platform, personalized learning},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3589334.3645378,
author = {Yan, Yibo and Wen, Haomin and Zhong, Siru and Chen, Wei and Chen, Haodong and Wen, Qingsong and Zimmermann, Roger and Liang, Yuxuan},
title = {UrbanCLIP: Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645378},
doi = {10.1145/3589334.3645378},
abstract = {Urban region profiling from web-sourced data is of utmost importance for urban computing. We are witnessing a blossom of LLMs for various fields, especially in multi-modal data research such as vision-language learning, where text modality serves as a supplement for images. As textual modality has rarely been introduced into modality combinations in urban region profiling, we aim to answer two fundamental questions: i) Can text modality enhance urban region profiling? ii) and if so, in what ways and which aspects? To answer the questions, we leverage the power of Large Language Models (LLMs) and introduce the first-ever LLM-enhanced framework that integrates the knowledge of text modality into urban imagery, named LLM-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining (UrbanCLIP ). Specifically, it first generates a detailed textual description for each satellite image by Image-to-Text LLMs. Then, the model is trained on image-text pairs, seamlessly unifying language supervision for urban visual representation learning, jointly with contrastive loss and language modeling loss. Results on urban indicator prediction in four major metropolises show its superior performance, with an average improvement of 6.1% on R2 compared to the state-of-the-art methods. Our code and dataset are available at https://github.com/StupidBuluchacha/UrbanCLIP.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4006–4017},
numpages = {12},
keywords = {language-image pretraining, spatio-temporal data, urban computing},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3706599.3720224,
author = {Tang, Xiao and Li, Zhuying and Sun, Xin and Xu, Xuhai and Zhang, Min-Ling},
title = {ZzzMate: A Self-Conscious Emotion-Aware Chatbot for Sleep Intervention},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720224},
doi = {10.1145/3706599.3720224},
abstract = {Empathy-driven design is increasingly recognized as a key element in behavior change interventions. However, self-conscious emotions such as guilt, shame, embarrassment, and pride are often overlooked. We introduce ZzzMate, an empathetic chatbot designed to detect and address these emotions to support healthy sleep routines. ZzzMate incorporates a novel emotion detection model that identifies self-conscious emotions from user interactions, which then informs a large language model (LLM) to generate empathetic responses. The system combines detected emotions with users’ sleep goals and empathy strategies to provide personalized interventions. In a comparative pilot study against a standard GPT, ZzzMate demonstrated better performance in emotional intelligence, self-efficacy and sleep adherence. This late-breaking-work presents our initial findings and system design of ZzzMate, laying the groundwork for future research in self-conscious emotion-aware health intervention technologies.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {610},
numpages = {7},
keywords = {Sleep, Self-conscious Emotions, Health, Behavioral Change, Chatbot, Empathetic Dialogue},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3696410.3714801,
author = {Zhu, Yun and Shi, Haizhou and Wang, Xiaotang and Liu, Yongchao and Wang, Yaoke and Peng, Boci and Hong, Chuntao and Tang, Siliang},
title = {GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714801},
doi = {10.1145/3696410.3714801},
abstract = {Recently, research on Text-Attributed Graphs (TAGs) has gained significant attention due to the prevalence of free-text node features in real-world applications and the advancements in Large Language Models (LLMs) that bolster TAG methodologies. However, current TAG approaches face two primary challenges: (i) Heavy reliance on label information and (ii) Limited cross-domain zero/few-shot transferability. These issues constrain the scaling of both data and model size, owing to high labor costs and scaling laws, complicating the development of graph foundation models with strong transferability. In this work, we propose the GraphCLIP framework to address these challenges by learning &lt;u&gt;graph&lt;/u&gt; foundation models with strong &lt;u&gt;c&lt;/u&gt;ross-domain zero/few-shot transferabi&lt;u&gt;li&lt;/u&gt;ty through a self-supervised contrastive graph-summary &lt;u&gt;p&lt;/u&gt;retraining method. Specifically, we generate and curate large-scale graph-summary pair data with the assistance of LLMs, and introduce a novel graph-summary pretraining method, combined with invariant learning, to enhance graph foundation models with strong cross-domain zero-shot transferability. For few-shot learning, we propose a novel graph prompt tuning technique aligned with our pretraining objective to mitigate catastrophic forgetting and minimize learning costs. Extensive experiments show the superiority of GraphCLIP in both zero-shot and few-shot settings, while evaluations across various downstream tasks confirm the versatility of GraphCLIP. Our code is available at: https://github.com/ZhuYun97/GraphCLIP.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {2183–2197},
numpages = {15},
keywords = {graph foundation model, graph representation learning, graph transformer, self-supervised learning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3706599.3706686,
author = {Arakawa, Riku and Yakura, Hiromu and Akuzawa, Kei and Kubo, Shizuma},
title = {AI for Meeting Minutes: Promises and Challenges in Designing Human-AI Collaboration on a Production SaaS Platform},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706686},
doi = {10.1145/3706599.3706686},
abstract = {Recent advances in AI technologies, including large language models, have enabled the widespread deployment of automated meeting minute generation at a commercial scale. However, many users continue to take minutes manually. To understand the factors behind this gap, we conducted a case study on a start-up company providing a commercial meeting analysis service. Through detailed observations of the development process over three years and workshops with their designers and developers, we identified key challenges, including discrepancies between user expectations and AI-generated summaries, as well as difficulties in balancing user interaction with automation. Importantly, our study sheds light on factors that have been less emphasized in previous HCI literature, such as the learning curve associated with adopting new technologies for an enterprise product. These insights spotlight the challenges in achieving an effective collaboration between rapidly evolving AI and users, suggesting the increasingly important role of HCI.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {654},
numpages = {6},
keywords = {Meeting minutes, Text summarization, Human-AI collaboration},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3613905.3636294,
author = {Muller, Michael and Kantosalo, Anna and Maher, Mary Lou and Martin, Charles Patrick and Walsh, Greg},
title = {GenAICHI 2024: Generative AI and HCI at CHI 2024},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636294},
doi = {10.1145/3613905.3636294},
abstract = {This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI), and - among other approaches - particularly to Large Language Models (LLMs) and Foundation Models (FMs). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together. Following successful workshops in 2022 and 2023, we convene the interdisciplinary research domain of generative AI and HCI. Participation in this invitational workshop is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {470},
numpages = {7},
keywords = {Bias, Design, Generative AI, Uncertainty.},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@article{10.1145/3643733,
author = {Jiang, Zhihan and Liu, Jinyang and Chen, Zhuangbin and Li, Yichen and Huang, Junjie and Huo, Yintong and He, Pinjia and Gu, Jiazhen and Lyu, Michael R.},
title = {LILAC: Log Parsing using LLMs with Adaptive Parsing Cache},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643733},
doi = {10.1145/3643733},
abstract = {Log parsing transforms log messages into structured formats, serving as the prerequisite step for various log analysis tasks. Although a variety of log parsing approaches have been proposed, their performance on complicated log data remains compromised due to the use of human-crafted rules or learning-based models with limited training data. The recent emergence of powerful large language models (LLMs) demonstrates their vast pre-trained knowledge related to code and logging, making it promising to apply LLMs for log parsing. However, their lack of specialized log parsing capabilities currently hinders their parsing accuracy. Moreover, the inherent inconsistent answers, as well as the substantial overhead, prevent the practical adoption of LLM-based log parsing. 
 

 
To address these challenges, we propose LILAC, the first practical Log parsIng framework using LLMs with Adaptive parsing Cache. To facilitate accurate and robust log parsing, LILAC leverages the in-context learning (ICL) capability of the LLM by performing a hierarchical candidate sampling algorithm and selecting high-quality demonstrations. Furthermore, LILAC incorporates a novel component, an adaptive parsing cache, to store and refine the templates generated by the LLM. It helps mitigate LLM's inefficiency issue by enabling rapid retrieval of previously processed log templates. In this process, LILAC adaptively updates the templates within the parsing cache to ensure the consistency of parsed results. The extensive evaluation on public large-scale datasets shows that LILAC outperforms state-of-the-art methods by 69.5% in terms of the average F1 score of template accuracy. In addition, LILAC reduces the query times to LLMs by several orders of magnitude, achieving a comparable efficiency to the fastest baseline.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {7},
numpages = {24},
keywords = {large language models, log analysis, log parsing}
}

@inproceedings{10.1145/3673791.3698416,
author = {Jang, Jisoo and Li, Wen-Syan},
title = {AU-RAG: Agent-based Universal Retrieval Augmented Generation},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673791.3698416},
doi = {10.1145/3673791.3698416},
abstract = {Retrieval Augmented Generation (RAG) has been effectively used to improve the accuracy of question-answering (Q&amp;A) systems powered by Large Language Models (LLMs) by integrating local knowledge and more up-to-date content. However, traditional RAG methods, including those with re-ranking mechanisms, face challenges when dealing with large, frequently updated data sources or when accessing sources exclusively via APIs, as they require pre-encoding all content into embedding vectors. To address these limitations, we introduce Agent-based Universal RAG (AU-RAG), a novel approach that augments data sources with descriptive metadata, allowing an agent to dynamically search through diverse data pools. This agent-driven system can learn from examples to retrieve and consolidate data from various sources on the fly, functioning as a more flexible and adaptive RAG. We demonstrate AU-RAG's functionality with a financial analysis example and evaluate its performance using a multi-source QA dataset. The results show that AU-RAG performs comparably to RAG with re-ranking in data retrieval tasks while also demonstrating an enhanced ability to intelligently learn and access new data sources from examples, making it a robust solution for dynamic and complex information environments.},
booktitle = {Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {2–11},
numpages = {10},
keywords = {agent, large language models, mediation, retrieval augmented generation},
location = {Tokyo, Japan},
series = {SIGIR-AP 2024}
}

@inproceedings{10.1145/3696410.3714895,
author = {Lin, Xuanrui and Jia, Chao and Ji, Junhui and Han, Hui and Naseem, Usman},
title = {Ask, Acquire, Understand: A Multimodal Agent-based Framework for Social Abuse Detection in Memes},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714895},
doi = {10.1145/3696410.3714895},
abstract = {Memes serve as a powerful medium of expression in the digital age, shaping cultural discourse and conveying ideas succinctly and engagingly. However, their potential for social abuse highlights the importance of developing effective methods to detect harmful content within memes. Recent studies on memes have focused on transforming images into textual captions using large language models (LLMs). However, these approaches often result in non-informative captions. Furthermore, previous methods have only been tested on limited datasets, providing insufficient evidence of their robustness. To address these limitations, we present a multimodal, agent-based framework designed to generate informative visual descriptions of memes by asking insightful questions to improve visual descriptions in zero-shot visual question-answering settings. Specifically, we leverage an LLM as agents with distinct roles and a large multimodal model (LMM) as a vision expert. These agents first analyze the images and then ask informative questions related to potential social abuse in memes to obtain high-quality answers about the images. Through continuous discussion guided by instructional prompts, the agents gather high-quality information while repeatedly acquiring image data from the LMM, which helps detect social abuse in memes. Results on a dataset of 6,626 memes across 5 tasks show our framework surpasses state-of-the-art methods, demonstrating strong generalizability and improved detection of social abuse in memes.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4734–4744},
numpages = {11},
keywords = {meme analysis, multimodal, social abuse},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3688804,
author = {Chen, Tao and Zhang, Enwei and Gao, Yuting and Li, Ke and Sun, Xing and Zhang, Yan and Li, Hui and Ji, Rongrong},
title = {MMICT: Boosting Multi-Modal Fine-Tuning with In-Context Examples},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3688804},
doi = {10.1145/3688804},
abstract = {Although In-Context Learning (ICL) brings remarkable performance gains to Large Language Models (LLMs), the improvements remain lower than fine-tuning on downstream tasks. This paper introduces Multi-Modal In-Context Tuning (MMICT), a novel multi-modal fine-tuning paradigm that boosts multi-modal fine-tuning by fully leveraging the promising ICL capability of multi-modal LLMs (MM-LLMs). We propose the Multi-Modal Hub (M-Hub), a unified module that captures various multi-modal features according to different inputs and objectives. Based on M-Hub, MMICT enables MM-LLMs to learn from in-context visual-guided textual features and subsequently generate outputs conditioned on the textual-guided visual features. Moreover, leveraging the flexibility of M-Hub, we design a variety of in-context demonstrations. Extensive experiments on a diverse range of downstream multi-modal tasks demonstrate that MMICT significantly outperforms traditional fine-tuning strategy and the vanilla ICT method that directly takes the concatenation of all information from different modalities as input. Our implementation is available at: https://github.com/KDEGroup/MMICT.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = aug,
keywords = {Multi-Modal Alignment, Text Generation, In-Context Tuning}
}

@article{10.1145/3715112,
author = {Betz, Stefanie and Penzenstadler, Birgit},
title = {With Great Power Comes Great Responsibility: The Role of Software Engineers},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715112},
doi = {10.1145/3715112},
abstract = {The landscape of Software Engineering evolves rapidly amidst digital transformation and the ascendancy of AI, leading to profound shifts in the role and responsibilities of Software Engineers. This evolution encompasses both immediate changes, such as the adoption of Large Language Model-based approaches to coding, and deeper shifts driven by the profound societal and environmental impacts of technology. Despite the urgency, there persists a lag in adapting to these evolving roles. This roadmap article proposes 10 research challenges to develop a new generation of Software Engineers equipped to navigate the technical and social complexities as well as ethical considerations inherent in their evolving profession. Furthermore, the challenges target role definition, integration of AI, education transformation, standards evolution, and impact assessment to equip future Software Engineers to skillfully and responsibly handle the obstacles within their transforming discipline.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {136},
numpages = {21},
keywords = {Sustainability, Responsibility, Roles, Ethics}
}

@inproceedings{10.1145/3691720.3691739,
author = {Dou, Juhua and Zhao, Xuhua},
title = {Design and Application of Online Teaching Resource Platform for College English Based on Retrieval-Augmented Generation},
year = {2024},
isbn = {9798400710230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691720.3691739},
doi = {10.1145/3691720.3691739},
abstract = {Aiming at the problems of inconvenient retrieval of teaching resources, untimely feedback, inaccurate questioning rate, and lack of learner privacy and security that exist in various online teaching resource platforms, it is proposed to construct a new college English teaching resource platform by utilizing the technology of Large Language Mode(LLM) and Retrieval-Augmented Generation(RAG). The platform builds a local large language model and a teaching resource repository for college English, which can intelligently identify learners' questions and queries, provide learners with real-time personalized interaction and accurate Q&amp;A services, reduce teachers' workload in delivering resources and answering questions in real time, greatly improve the efficiency of using the resource repository, and create an intelligent resource environment for teaching quality improvement.},
booktitle = {Proceedings of the 2nd International Conference on Educational Knowledge and Informatization},
pages = {111–115},
numpages = {5},
location = {Shanghai, China},
series = {EKI '24}
}

@inproceedings{10.1145/3623809.3623931,
author = {Cox, Samuel Rhys and Abdul, Ashraf and Ooi, Wei Tsang},
title = {Prompting a Large Language Model to Generate Diverse Motivational Messages: A Comparison with Human-Written Messages},
year = {2023},
isbn = {9798400708244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623809.3623931},
doi = {10.1145/3623809.3623931},
abstract = {Large language models (LLMs) are increasingly capable and prevalent, and can be used to produce creative content. The quality of content is influenced by the prompt used, with more specific prompts that incorporate examples generally producing better results. On from this, it could be seen that using instructions written for crowdsourcing tasks (that are specific and include examples to guide workers) could prove effective LLM prompts. To explore this, we used a previous crowdsourcing pipeline that gave examples to people to help them generate a collectively diverse corpus of motivational messages. We then used this same pipeline to generate messages using GPT-4, and compared the collective diversity of messages from: (1) crowd-writers, (2) GPT-4 using the pipeline, and (3 &amp; 4) two baseline GPT-4 prompts. We found that the LLM prompts using the crowdsourcing pipeline caused GPT-4 to produce more diverse messages than the two baseline prompts. We also discuss implications from messages generated by both human writers and LLMs.},
booktitle = {Proceedings of the 11th International Conference on Human-Agent Interaction},
pages = {378–380},
numpages = {3},
keywords = {Creativity, Crowdsourcing, Large Language Models, Prompt Engineering},
location = {Gothenburg, Sweden},
series = {HAI '23}
}

@inproceedings{10.1145/3640457.3688062,
author = {Shah, Jaidev and Luo, Gang and Liu, Jialin and Barapatre, Amey and Wu, Fan and Wang, Chuck and Li, Hongzhi},
title = {Analyzing User Preferences and Quality Improvement on Bing's WebPage Recommendation Experience with Large Language Models},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688062},
doi = {10.1145/3640457.3688062},
abstract = {Explore Further @ Bing (Web Recommendations) is a web-scale query independent webpage-to-webpage recommendation system with an index size of over 200 billion webpages. Due to the significant variability in webpage quality across the web and the reliance of our system on learning soleley user behavior (clicks), our production system was susceptible to serving clickbait and low-quality recommendations. Our team invested several months in developing and shipping several improvements that utilize LLM-generated recommendation quality labels to enhance our ranking stack to improve the nature of the recommendations we show to our users. Another key motivation behind our efforts was to go beyond merely surfacing relevant webpages, focusing instead on prioritizing more useful and authoritative content that delivers value to users based on their implied intent. We demonstrate how large language models (LLMs) offer a powerful tool for product teams to gain deeper insights into shifts in product experience and user behavior following significant improvements or changes to a production system. In this work, to enable our analysis, we also showcase the use of a small language model (SLM) to generate better-quality webpage text features and summaries at scale and describe our approach to mitigating position bias in user interaction logs."},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {751–754},
numpages = {4},
keywords = {Analysis, Clicks, LLM, Recommender Systems},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3589334.3645712,
author = {Zhao, Ziliang and Dou, Zhicheng},
title = {Generating Multi-turn Clarification for Web Information Seeking},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645712},
doi = {10.1145/3589334.3645712},
abstract = {Asking multi-turn clarifying questions has been applied in various conversational search systems to help recommend people, commodities, and images to users. However, its importance is still not emphasized in the Web search. In this paper, we make a step to extend the multi-turn clarification generation to Web search for clarifying users' ambiguous or faceted intents. Compared with other conversational search scenarios, Web search queries are more complicated, so clarification should be generated instead of being selected which is commonly applied in current studies. To this end, we first define the whole process of multi-turn Web search clarification composed of clarification candidate generation, optimal clarification selection, and document retrieval. Due to the lack of multi-turn open-domain clarification data, we first design a simple yet effective rule-based method to fit the above three components. After that, by utilizing the in-context learning and zero-shot instruction ability of large language models (LLMs), we implement clarification generation and selection by prompting LLMs with demonstrations and declarations, further improving the clarification effectiveness. To evaluate our proposed methods, we first measure whether our methods can improve the ability to retrieve documents. We also evaluate the quality of generated candidate facets. Experimental results show that, compared with existing single-turn methods for Web search clarification, our proposed framework is more suitable for open-domain Web search systems in asking multi-turn clarification questions to clarify users' ambiguous or faceted intents.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1539–1548},
numpages = {10},
keywords = {clarifying question, conversational search, search clarification},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.5555/3721488.3721714,
author = {Park, Cheonshu and Cho, Miyoung and Shin, Minjung and Ryu, Jeh-Kwang and Jang, Minsu},
title = {Adaptive Robot-mediated Assessment using LLM for Enhanced Survey Quality in Older Adults Care Programs},
year = {2025},
publisher = {IEEE Press},
abstract = {This study presents an adaptive human-robot interaction (HRI) system that evaluates older adult participants' satisfaction with personalized healthcare programs. By integrating the CLOi robot with a large language model (LLM), the system conducts satisfaction surveys that adapt in real-time to participant responses. The system was applied to evaluate healthcare programs that include physical health measurements, exercise assessments, and virtual reality (VR) experiences. The system utilizes the CLOi robot and Claude API to analyze response clarity in real-time, automatically generating contextually appropriate follow-up questions when responses are deemed ambiguous. This adaptive questioning strategy ensures comprehensive response quality before proceeding to subsequent survey items. We conducted a preliminary feasibility study with five older adult participants to evaluate our approach. The system leverages LLM prompts to analyze gaps between question intent and participant responses, generating targeted follow-up questions as needed. Results demonstrate that our LLM-enhanced robotic interview system effectively reduced response ambiguity through dynamic follow-up questioning, achieving an 85% response resolution rate. This adaptive approach improved the clarity and specificity of healthcare satisfaction assessments for older adults.},
booktitle = {Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1534–1538},
numpages = {5},
keywords = {adaptive robot-mediated assessment, human-robot interaction (hri), llm-based question generation},
location = {Melbourne, Australia},
series = {HRI '25}
}

@inproceedings{10.1145/3589334.3645365,
author = {Wang, Zheng and Gan, Bingzheng and Shi, Wei},
title = {Multimodal Query Suggestion with Multi-Agent Reinforcement Learning from Human Feedback},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645365},
doi = {10.1145/3589334.3645365},
abstract = {In the rapidly evolving landscape of information retrieval, search engines strive to provide more personalized and relevant results to users. Query suggestion systems play a crucial role in achieving this goal by assisting users in formulating effective queries. However, existing query suggestion systems mainly rely on textual inputs, potentially limiting user search experiences for querying images. In this paper, we introduce a novel Multimodal Query Suggestion (MMQS) task, which aims to generate query suggestions based on user query images to improve the intentionality and diversity of search results. We present the RL4Sugg framework, leveraging the power of Large Language Models (LLMs) with Multi-Agent Reinforcement Learning from Human Feedback to optimize the generation process. Through comprehensive experiments, we validate the effectiveness of RL4Sugg, demonstrating a 18% improvement compared to the best existing approach. Moreover, the MMQS has been transferred into real-world search engine products, which yield enhanced user engagement. Our research advances query suggestion systems and provides a new perspective on multimodal information retrieval.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1374–1385},
numpages = {12},
keywords = {multi-agent reinforcement learning from human feedback, multimodal query suggestion, vision-language pre-training},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3637528.3671897,
author = {Wu, Feijie and Li, Zitao and Li, Yaliang and Ding, Bolin and Gao, Jing},
title = {FedBiOT: LLM Local Fine-tuning in Federated Learning without Full Model},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671897},
doi = {10.1145/3637528.3671897},
abstract = {Large language models (LLMs) show amazing performance on many domain-specific tasks after fine-tuning with some appropriate data. However, many domain-specific data are privately distributed across multiple owners. Thus, this dilemma raises the interest in how to perform LLM fine-tuning in federated learning (FL). However, confronted with limited computation and communication capacities, FL clients struggle to fine-tune an LLM effectively. To this end, we introduce FedBiOT, a resource-efficient LLM fine-tuning approach to FL. Specifically, our method involves the server generating a compressed LLM and aligning its performance with the full model. Subsequently, the clients fine-tune a lightweight yet important part of the compressed model, referred to as an adapter. Notice that as the server has no access to the private data owned by the clients, the data used for alignment by the server has a different distribution from the one used for fine-tuning by clients. We formulate the problem into a bi-level optimization problem to minimize the negative effect of data discrepancy and derive the updating rules for the server and clients. We conduct extensive experiments on LLaMA-2, empirically showing that the adapter has exceptional performance when reintegrated into the global LLM. The results also indicate that the proposed FedBiOT significantly reduces resource consumption compared to existing benchmarks, all while achieving comparable performance levels.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3345–3355},
numpages = {11},
keywords = {federated learning, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3701716.3717539,
author = {Kanakaris, Nikos and Ping, Heng and Xiao, Xiongye and Ahmed, Nesreen K. and Luceri, Luca and Ferrara, Emilio and Bogdan, Paul},
title = {Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717539},
doi = {10.1145/3701716.3717539},
abstract = {Detecting organized political campaigns, commonly known as astroturf campaigns, is of paramount importance in fighting against disinformation on social media. Existing approaches for the identification of such organized actions employ techniques mostly from network science, graph machine learning and natural language processing. Their ultimate goal is to analyze the relationships and interactions (e.g. re-posting) among users and the textual similarities of their posts. Despite their effectiveness in recognizing astroturf campaigns, these methods face significant challenges, notably the class imbalance in available training datasets. To mitigate this issue, recent methods usually resort to data augmentation or increasing the number of positive samples, which may not always be feasible or sufficient in real-world settings. Following a different path, in this paper, we propose a novel framework for identifying astroturf campaigns based solely on large language models (LLMs), introducing a Balanced Retrieval-Augmented Generation (Balanced RAG) component. Our approach first gives both textual information concerning the posts (in our case tweets) and the user interactions of the social network as input to a language model. Then, through prompt engineering and the proposed Balanced RAG method, it effectively detects coordinated disinformation campaigns on 𝕏 (Twitter). The proposed framework does not require any training or fine-tuning of the language model. Instead, by strategically harnessing the strengths of prompt engineering and Balanced RAG, it facilitates LLMs to overcome the effects of class imbalance and effectively identify coordinated political campaigns. The experimental results demonstrate that by incorporating the proposed prompt engineering and Balanced RAG methods, our framework outperforms the traditional graph-based baselines, achieving 2\texttimes{}-3\texttimes{} improvements in terms of precision, recall and F1 scores.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2651–2660},
numpages = {10},
keywords = {class imbalance, disinformation spread, fake news detection, graph classification, graph-aware prompt engineering, large language models, organized disinformation campaign detection, prompt engineering, retrieval-augmented generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.5555/3721488.3721720,
author = {Ren, Qiaoqiao and Belpaeme, Tony},
title = {Touched by ChatGPT: Using an LLM to Drive Affective Tactile Interaction},
year = {2025},
publisher = {IEEE Press},
abstract = {Touch is a fundamental aspect of emotion-rich communication, playing a vital role in human interaction and offering significant potential in human-robot interaction. Previous research has demonstrated that a sparse representation of human touch can effectively convey social tactile signals. However, advances in human-robot tactile interaction remain limited, as many humanoid robots possess simplistic capabilities, such as only opening and closing their hands, restricting nuanced tactile expressions. In this study, we explore how a robot can use sparse representations of tactile vibrations to convey emotions to a person. To achieve this, we developed a wearable sleeve integrated with a 5x5 grid of vibration motors, enabling the robot to communicate diverse tactile emotions and gestures. Using chain prompts within a Large Language Model (LLM), we generated distinct 10-second vibration patterns corresponding to 10 emotions (e.g., happiness, sadness, fear) and 6 touch gestures (e.g., pat, rub, tap). Participants (N = 32) then rated each vibration stimulus based on perceived valence and arousal. People are accurate at recognising intended emotions, a result which aligns with earlier findings. These results highlight the LLM's ability to generate emotional haptic data and effectively convey emotions through tactile signals. By translating complex emotional and tactile expressions into vibratory patterns, this research demonstrates how LLMs can enhance physical interaction between humans and robots.},
booktitle = {Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1563–1567},
numpages = {5},
keywords = {affective computing, emotion classification, gesture classification, large language model., tactile interaction},
location = {Melbourne, Australia},
series = {HRI '25}
}

@article{10.1145/3695868,
author = {Li, Xinze and Wang, Hanbin and Liu, Zhenghao and Yu, Shi and Wang, Shuo and Yan, Yukun and Fu, Yukai and Gu, Yu and Yu, Ge},
title = {Building a Coding Assistant via the Retrieval-Augmented Language Model},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/3695868},
doi = {10.1145/3695868},
abstract = {Pretrained language models have shown strong effectiveness in code-related tasks, such as code retrieval, code generation, code summarization, and code completion tasks. In this article, we propose COde assistaNt viA retrieval-augmeNted language model (CONAN), which aims to build a code assistant by mimicking the knowledge-seeking behaviors of humans during coding. Specifically, it consists of a code structure-aware retriever (CONAN-R) and a dual-view code representation-based retrieval-augmented generation model (CONAN-G). CONAN-R pretrains CodeT5 using Code-Documentation Alignment and Masked Entity Prediction tasks to make language models code structure-aware and learn effective representations for code snippets and documentation. Then CONAN-G designs a dual-view code representation mechanism for implementing a retrieval-augmented code generation model. CONAN-G regards the code documentation descriptions as prompts, which help language models better understand the code semantics. Our experiments show that CONAN achieves convincing performance on different code generation tasks and significantly outperforms previous retrieval augmented code generation models. Our further analyses show that CONAN learns tailored representations for both code snippets and documentation by aligning code-documentation data pairs and capturing structural semantics by masking and predicting entities in the code data. Additionally, the retrieved code snippets and documentation provide necessary information from both program language and natural language to assist the code generation process. CONAN can also be used as an assistant for Large Language Models (LLMs), providing LLMs with external knowledge in shorter code document lengths to improve their effectiveness on various code tasks. It shows the ability of CONAN to extract necessary information and help filter out the noise from retrieved code documents.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
articleno = {39},
numpages = {25},
keywords = {Code Assistant, Code Generation, Code Retrieval, Retrieval Augmented Language Model}
}

@inproceedings{10.1145/3631802.3631830,
author = {Liffiton, Mark and Sheese, Brad E and Savelka, Jaromir and Denny, Paul},
title = {CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631830},
doi = {10.1145/3631802.3631830},
abstract = {Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students’ usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {8},
numpages = {11},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3653946.3653961,
author = {Jiang, Yingdi and Yao, Jiarui and Li, Fangfei and Zhang, Yan},
title = {Research on Engineering Management Question-answering System in the Communication Industry Based on Large Language Models and Knowledge Graphs},
year = {2024},
isbn = {9798400716553},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653946.3653961},
doi = {10.1145/3653946.3653961},
abstract = {In the engineering management of the communication industry, there are many issues, including low efficiency in information acquisition and limitations in the level of intelligence.Large language models, with their powerful text comprehension and generation capabilities, offer new perspectives for the development of this field.This study constructed a question-answering system using a combined approach of large language models and text knowledge bases. The system dynamically leverages abundant external knowledge and enhances the model's reasoning ability and interpretability through knowledge graphs. In response to five categories of issues in engineering management, experiments and in-depth analysis revealed that although large language models may lack granularity in addressing some complex problems, the question-answering system overall achieved intelligent assistance, improving the efficiency of collaborative engineering management.},
booktitle = {Proceedings of the 2024 7th International Conference on Machine Vision and Applications},
pages = {100–105},
numpages = {6},
keywords = {Engineering management, Keywords • Large language models, Knowledge graphs, Question-answering},
location = {Singapore, Singapore},
series = {ICMVA '24}
}

@article{10.1145/3652028,
author = {Spinner, Thilo and Kehlbeck, Rebecca and Sevastjanova, Rita and St\"{a}hle, Tobias and Keim, Daniel A. and Deussen, Oliver and El-Assady, Mennatallah},
title = {-generAItor: Tree-in-the-loop Text Generation for Language Model Explainability and Adaptation},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {2160-6455},
url = {https://doi.org/10.1145/3652028},
doi = {10.1145/3652028},
abstract = {Large language models (LLMs) are widely deployed in various downstream tasks, e.g., auto-completion, aided writing, or chat-based text generation. However, the considered output candidates of the underlying search algorithm are under-explored and under-explained. We tackle this shortcoming by proposing a tree-in-the-loop approach, where a visual representation of the beam search tree is the central component for analyzing, explaining, and adapting the generated outputs. To support these tasks, we present generAItor, a visual analytics technique, augmenting the central beam search tree with various task-specific widgets, providing targeted visualizations and interaction possibilities. Our approach allows interactions on multiple levels and offers an iterative pipeline that encompasses generating, exploring, and comparing output candidates, as well as fine-tuning the model based on adapted data. Our case study shows that our tool generates new insights in gender bias analysis beyond state-of-the-art template-based methods. Additionally, we demonstrate the applicability of our approach in a qualitative user study. Finally, we quantitatively evaluate the adaptability of the model to few samples, as occurring in text-generation use cases.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = jun,
articleno = {14},
numpages = {32},
keywords = {Large language models, beam search tree, natural language generation, explainability, language transformers, visual analytics}
}

@inproceedings{10.1145/3658644.3691377,
author = {Li, Wanpeng and Guo, Yuejun},
title = {Poster: Automated Dependency Mapping for Web API Security Testing Using Large Language Models},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3691377},
doi = {10.1145/3658644.3691377},
abstract = {Dependency extraction is crucial in web API security testing, as it helps identify the required API sequences to exploit a vulnerability. Traditional methods are generally rule-based and require extensive manual analysis of API specification documents by domain experts to formulate appropriate rules. This manual process is not only time-consuming and labor-intensive but also prone to missing dependencies and inaccuracies, which can compromise the effectiveness of security testing. In this paper, we explore the potential of large language models (LLMs) to automate dependency mapping in web APIs. By leveraging the capabilities of advanced LLMs such as GPT-3.5, Mistral-7B-Instruct, and Llama-3-8B-Instruct, which include understanding and generating natural language, we aim to streamline the dependency mapping process, reducing the need for manual analysis and enhancing accuracy. Our preliminary experiments demonstrate that this approach can effectively build dependency mappings, offering a a promising alternative to traditional rule-based approaches.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {5024–5026},
numpages = {3},
keywords = {api security testing, dependency mapping, large language model},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3660395.3660411,
author = {Wang, Shuyue and Cao, Peng and Yan, Xiaotong and Mu, Shanwei and Yu, Xuelian and Wang, Xuan},
title = {A Preliminary Attempt of Deploying AIGC in Autodriving Scenario Generation: Via LLM},
year = {2024},
isbn = {9798400716362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660395.3660411},
doi = {10.1145/3660395.3660411},
abstract = {With huge progress in Large Language Model (LLM) by Artificial-Intelligence-Generated-Content (AIGC), a technical demand from the industry of autodriving with respect to scenario generation needs sees a new possible solution. Thus a new powerful tools of computational modeling, and simulation is now at hand. In this paper, we explore the use of prompt engineering and the fine-tuning applied to open-source model. This paper studies the use about OpenSCENARIO. The theoretical descriptions comes with practical experiment in comparisons of prompt feedbacks and performance estimation of long conceptual Q&amp;A and code snippet generation.},
booktitle = {Proceedings of the 2023 3rd Guangdong-Hong Kong-Macao Greater Bay Area Artificial Intelligence and Big Data Forum},
pages = {86–91},
numpages = {6},
keywords = {AIGC, Autodriving, ChatGPT, LLM, Llama-2, OpenSCENARIO, code generation},
location = {Guangzhou, China},
series = {AIBDF '23}
}

@inproceedings{10.1145/3627673.3680082,
author = {Ujwal, Utkarsh and Surampudi, Sai Sri Harsha and Mitra, Sayantan and Saha, Tulika},
title = {"Reasoning before Responding": Towards Legal Long-form Question Answering with Interpretability},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680082},
doi = {10.1145/3627673.3680082},
abstract = {Long-Form Question Answering (LFQA) represents a growing interest in Legal Natural Language Processing (Legal-NLP) as many individuals encounter legal disputes at some point in their lives, but lack of knowledge about how to negotiate these complex situations might put them at risk. The endeavor to generate detailed answers to contextually rich legal questions has faced challenges, primarily due to the limited availability of specialized datasets involving intensive manual effort or incapability of existing LFQA models to produce informative responses. Addressing this, our research introduces a semi-synthetic dataset, Legal-LFQA (L2FQA) created by exploiting a large language model (LLM) and utilizing contexts derived from existing legal datasets. Additionally, we hypothesize that integrating legal reasoning into the answer generation process of the LLMs will help bolster both the quality and interpretability of the produced responses. We systematically analyze the quality of L2FQA using human evaluation and natural language inference based metrics. Next, we benchmark L2FQA on a wide range of general-purpose and domain-specific LLMs using fine-tuning and in-context learning (with zero, one and few shot) strategies. The efficacy of these techniques is gauged through several automated and human evaluations. Results indicate that incorporating legal reasoning into the answer generation process provides an avenue for improving the quality of responses in the context of Legal-LFQA task. By addressing the challenges faced in LFQA and emphasizing the potential of interpretability, this research contributes to the foundational work in enhancing question-answering systems within the legal domain.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4922–4930},
numpages = {9},
keywords = {interpretability, large language models, legal domain, long-form question answering},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3689218.3689235,
author = {Tang, Lisirui and Wang, Chengyu and Li, Gangmin and Liu, Peng},
title = {Fine-tuning of LLMs for HeXie Management Theory},
year = {2024},
isbn = {9798400718250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689218.3689235},
doi = {10.1145/3689218.3689235},
abstract = {HeXie Management Theory (HXMT) has been used in many applications. Those applications have demonstrated the effectiveness of the theory in responding to management challenges by integrating oriental and occidental wisdom. With its adoption’s complexity, dynamics, and flexibility, a revolutionary method needs to be developed to simplify it more broadly. Large Language Models (LLMs) have shown their compelling ability to generate human-like content with their chat-based paradigm. Many specifically trained LLMs have demonstrated success in their dedicated application domains. This paper reports the study of fine-tuning LLMs using a specialized dataset derived from the HeXie management theory. Two models were built on Baidu’s Qianfan platform and were adapted for Chinese text. Four criteria were used to evaluate the performances. This study provides an example of fine-tuning LLMs for a Chinese text-based specific theory and building a domain-specific intelligent agent using LLMs or HXMT, which is available at https://alex17swim.com/chat/},
booktitle = {Proceedings of the 2024 6th International Conference on Pattern Recognition and Intelligent Systems},
pages = {69–73},
numpages = {5},
keywords = {Fine-tune, HeXie Management Theory, Large Language Models, RAG},
location = {Hong Kong, Hong Kong},
series = {PRIS '24}
}

@inproceedings{10.1145/3696443.3708929,
author = {Taneja, Jubi and Laird, Avery and Yan, Cong and Musuvathi, Madan and Lahiri, Shuvendu K.},
title = {LLM-Vectorizer: LLM-Based Verified Loop Vectorizer},
year = {2025},
isbn = {9798400712753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696443.3708929},
doi = {10.1145/3696443.3708929},
abstract = {Vectorization is a powerful optimization technique that significantly boosts the performance of high performance computing applications operating on large data arrays. Despite decades of research on auto-vectorization, compilers frequently miss opportunities to vectorize code. On the other hand, writing vectorized code manually using compiler intrinsics is still a complex, error-prone task that demands deep knowledge of specific architecture and compilers.  In this paper, we evaluate the potential of large-language models (LLMs) to generate vectorized (Single Instruction Multiple Data) code from scalar programs that process individual array elements.   We propose a novel finite-state-machine multi-agents based approach that harnesses LLMs and test-based feedback to generate vectorized code.  Our findings indicate that LLMs are capable of producing high-performance vectorized code with run-time speedup ranging from 1.1x to 9.4x as compared to the state-of-the-art compilers such as Intel Compiler, GCC, and Clang.  To verify the correctness of vectorized code, we use Alive2, a leading bounded translation validation tool for LLVM IR. We describe a few domain-specific techniques to improve the scalability of Alive2 on our benchmark dataset. Overall, our approach is able to verify 38.2% of vectorizations as correct on the TSVC benchmark dataset.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {137–149},
numpages = {13},
keywords = {AI Agents, Large language model, Loop Vectorization, Translation Validation},
location = {Las Vegas, NV, USA},
series = {CGO '25}
}

@inproceedings{10.1145/3663529.3663829,
author = {Toslali, Mert and Snible, Edward and Chen, Jing and Cha, Alan and Singh, Sandeep and Kalantar, Michael and Parthasarathy, Srinivasan},
title = {AgraBOT: Accelerating Third-Party Security Risk Management in Enterprise Setting through Generative AI},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663829},
doi = {10.1145/3663529.3663829},
abstract = {In the contemporary business landscape, organizations often rely on third-party services for many functions, including IT services, cloud computing, and business processes. To identify potential security risks, organizations conduct rigorous assessments before engaging with third-party vendors, referred to as Third-Party Security Risk Management (TPSRM). Traditionally, TPSRM assessments are executed manually by human experts and involve scrutinizing various third-party documents such as System and Organization Controls Type 2 (SOC 2) reports and reviewing comprehensive questionnaires along with the security policy and procedures of vendors—a process that is time-intensive and inherently lacks scalability. 
 
 
 
AgraBOT, a Retrieval Augmented Generation (RAG) framework, can assist TPSRM assessors by expediting TPSRM assessments and reducing the time required from days to mere minutes. AgraBOT utilizes cutting-edge AI techniques, including information retrieval (IR), large language models (LLMs), multi-stage ranking, prompt engineering, and in-context learning to accurately generate relevant answers from third-party documents to conduct assessments. We evaluate AgraBOT on seven real TPSRM assessments, consisting of 373 question-answer pairs, and attain an F1 score of 0.85.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {74–79},
numpages = {6},
keywords = {AI, Document Understanding, LLM, RAG, TPSRM},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3706468.3706530,
author = {Thomas, Danielle R and Borchers, Conrad and Kakarla, Sanjit and Lin, Jionghao and Bhushan, Shambhavi and Guo, Boyuan and Gatz, Erin and Koedinger, Kenneth R},
title = {Does Multiple Choice Have a Future in the Age of Generative AI? A Posttest-only RCT},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706530},
doi = {10.1145/3706468.3706530},
abstract = {The role of multiple-choice questions (MCQs) as effective learning tools has been debated in past research. While MCQs are widely used due to their ease in grading, open response questions are increasingly used for instruction, given advances in large language models (LLMs) for automated grading. This study evaluates MCQs effectiveness relative to open-response questions, both individually and in combination, on learning. These activities are embedded within six tutor lessons on advocacy. Using a posttest-only randomized control design, we compare the performance of 234 tutors (790 lesson completions) across three conditions: MCQ only, open response only, and a combination of both. We find no significant learning differences across conditions at posttest, but tutors in the MCQ condition took significantly less time to complete instruction. These findings suggest that MCQs are as effective, and more efficient, than open response tasks for learning when practice time is limited. To further enhance efficiency, we autograded open responses using GPT-4o and GPT-4-turbo. GPT models demonstrate proficiency for purposes of low-stakes assessment, though further research is needed for broader use. This study contributes a dataset of lesson log data, human annotation rubrics, and LLM prompts to promote transparency and reproducibility.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {494–504},
numpages = {11},
keywords = {Tutoring, Generative AI, Human-AI tutoring, AI-assisted tutoring, Assessment},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3714334.3714380,
author = {Zhang, Zhixian and Yu, Xiaoting and Yang, Siqi and Bai, Yin and Wang, Yu and Yang, Shuo},
title = {Research on Methods of Large Language Models in the Field of Sensitive Data Governance},
year = {2025},
isbn = {9798400711237},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3714334.3714380},
doi = {10.1145/3714334.3714380},
abstract = {With the rapid advancement of big data and artificial intelligence technologies, the governance of sensitive data has become a critical and pressing issue. Traditional data de-identification approaches exhibit inefficiencies and a lack of flexibility when processing unstructured data. This paper introduces a sensitive data governance method based on Large Language Models, leveraging the natural language processing capabilities of LLMs to construct prompts that enable the identification of fields requiring de-identification and the selection of appropriate de-identification methods. Furthermore, it harnesses the LLMs to automatically generate Python processing code, thus circumventing the limitations of singular and inflexible built-in de-identification functionalities in big data platforms. The objective of this study is to reduce the technical barriers in sensitive data governance and to enhance the flexibility and efficiency of data processing. The paper provides a detailed exposition of the technical implementation of this method, encompassing multiple stages such as data identification, instruction processing, model invocation, result adjudication, and data caching, and discusses its advantages and potential value in practical applications.},
booktitle = {Proceedings of the 2024 2nd International Conference on Artificial Intelligence, Systems and Network Security},
pages = {271–276},
numpages = {6},
keywords = {Data models, Data privacy, Large Language Models, data de-identification, database},
location = {
},
series = {AISNS '24}
}

@inproceedings{10.1145/3674399.3674426,
author = {Dong, Dong and Liang, Yue},
title = {Grading Programming Assignments by Summarization},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674399.3674426},
doi = {10.1145/3674399.3674426},
abstract = {Grading programming assignments manually is a big burden for instructors who teach programming languages for university students due to complexity and subjectivity. The black test approach adopted by online judge systems can only outputs either an answer is correct or incorrect. This study proposes a Large Language Model (LLM) approach to automatically grade answers from students for programming assignments. A LLM mode formed by coder-decoder architecture is utilized to generate summarization from source code, then the summarization is compared to the textual assignment description by semantic similarity. Finally, the output is converted to five-score rating. CodeBERT and a Transformer model serve as coder and decoder respectively. The semantic similarity is computed by MiniLM-L6. The validation test shows that the accuracy of the suggested approach reaches 0.92.},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2024},
pages = {53–58},
numpages = {6},
keywords = {CodeBERT, automatic grading, programming assignment assessment, source code summarization},
location = {Changsha, China},
series = {ACM-TURC '24}
}

@inproceedings{10.1145/3688868.3689189,
author = {Zhou, Luping},
title = {Automated Medical Report Generation and Visual Question Answering},
year = {2024},
isbn = {9798400711954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3688868.3689189},
doi = {10.1145/3688868.3689189},
abstract = {The rapid growth of medical imaging data has far outpaced the availability of trained radiologists, significantly increasing their workload. To alleviate this burden, reduce diagnostic errors, and streamline clinical workflows, the need for automated medical diagnostic report generation has become more urgent than ever. However, this task is particularly challenging, as it requires the ability to capture and describe clinically significant fine-grained visual differences in highly similar medical images. Additionally, critical disease-related keywords can easily be overshadowed by the prevalence of similar phrases describing common image content. Moreover, generating comprehensive reports that detail both normal and pathological findings within images adds to the complexity.In this presentation, I will showcase our latest research on automated medical diagnostic report generation and medical visual question answering, highlighting how we have tackled these challenges. Our work has transitioned from traditional encoder-decoder models to cutting-edge approaches utilizing large language models (LLMs). I will also discuss the current limitations of these methods and propose potential future directions.Specifically, I will present two methods we developed before the advent of pretrained LLMs, which enhance fine-grained recognition for medical report generation from different angles. The first is a self-boosting framework designed to learn highly correlated image and text features, enabling the model to narrate even finer visual changes in the generated reports. The second method is inspired by the 'multi-expert joint diagnosis' scenario and introduces multiple learnable 'expert' tokens into the transformer architecture, with each expert focusing on distinct image regions. These complementary perspectives are then aggregated to produce a final, more accurate report. In addition to report generation, I will also present our efforts in improving medical visual question answering (VQA).Following this, I will introduce our recent work on integrating LLMs for medical report generation. I will outline two frameworks we developed: the first employs a frozen LLM for report generation, training only a lightweight visual alignment module to achieve state-of-the-art performance. The second framework goes a step further by integrating a knowledge graph to unlock disease-related knowledge within the LLM, thereby enhancing the clinical relevance of the generated reports. Additionally, I will share our latest investigation into GPT-4V's multimodal capabilities in chest X-ray analysis and discuss the limitations of current evaluation metrics for radiology report generation. To address these limitations, I will introduce our recently developed MRScore framework, which guides LLMs in radiology report evaluation to ensure alignment with human expert analysis.},
booktitle = {Proceedings of the 1st International Workshop on Multimedia Computing for Health and Medicine},
pages = {3–4},
numpages = {2},
keywords = {large language models, medical report generation, medical visual question answering},
location = {Melbourne VIC, Australia},
series = {MCHM'24}
}

@inproceedings{10.1145/3675249.3675298,
author = {Qi, Fei and Hou, Yingnan and Lin, Ning and Bao, Shanshan and Xu, Nuo},
title = {A Survey of Testing Techniques Based on Large Language Models},
year = {2024},
isbn = {9798400718267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675249.3675298},
doi = {10.1145/3675249.3675298},
abstract = {With the development of software testing technology, Large Language Model (LLM) driven testing method have gradually become an emerging trend in the field of software testing. This paper presents a comprehensive review of LLM-based testing techniques. The results of 19 studies using LLM to optimize testing techniques are analyzed from the perspective of software testing. This paper discusses in detail how to use LLM to optimize test techniques for generating automated test code and generating diverse input in software test tasks. It also summarizes the challenges and opportunities faced by this field. The above conclusions can identify the shortcomings of LLM-based software testing technology and the direction of future research.},
booktitle = {Proceedings of the 2024 International Conference on Computer and Multimedia Technology},
pages = {280–284},
numpages = {5},
keywords = {LLM, Pre-trained Large Language Model, Software Testing Techniques},
location = {Sanming, China},
series = {ICCMT '24}
}

@inproceedings{10.1145/3626772.3657849,
author = {Gienapp, Lukas and Scells, Harrisen and Deckers, Niklas and Bevendorff, Janek and Wang, Shuai and Kiesel, Johannes and Syed, Shahbaz and Fr\"{o}be, Maik and Zuccon, Guido and Stein, Benno and Hagen, Matthias and Potthast, Martin},
title = {Evaluating Generative Ad Hoc Information Retrieval},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657849},
doi = {10.1145/3626772.3657849},
abstract = {Recent advances in large language models have enabled the development of viable generative retrieval systems. Instead of a traditional document ranking, generative retrieval systems often directly return a grounded generated text as a response to a query. Quantifying the utility of the textual responses is essential for appropriately evaluating such generative ad hoc retrieval. Yet, the established evaluation methodology for ranking-based ad hoc retrieval is not suited for the reliable and reproducible evaluation of generated responses. To lay a foundation for developing new evaluation methods for generative retrieval systems, we survey the relevant literature from the fields of information retrieval and natural language processing, identify search tasks and system architectures in generative retrieval, develop a new user model, and study its operationalization.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1916–1929},
numpages = {14},
keywords = {ad hoc search, evaluation, generative information retrieval},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3690624.3709425,
author = {Yang, Qinchen and Hong, Zhiqing and Cao, Dongjiang and Wang, Haotian and Xie, Zejun and He, Tian and Liu, Yunhuai and Yang, Yu and Zhang, Desheng},
title = {AddrLLM: Address Rewriting via Large Language Model on Nationwide Logistics Data},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709425},
doi = {10.1145/3690624.3709425},
abstract = {Textual description of a physical location, commonly known as an address, plays an important role in location-based services(LBS) such as on-demand delivery and navigation. However, the prevalence of abnormal addresses, those containing inaccuracies that fail to pinpoint a location, have led to significant costs. Address rewriting has emerged as a solution to rectify these abnormal addresses. Despite the critical need, existing address rewriting methods are limited, typically tailored to correct specific error types, or frequently require retraining to process new address data effectively. In this study, we introduce AddrLLM, an innovative framework for address rewriting that is built upon a retrieval augmented large language model. AddrLLM overcomes aforementioned limitations through a meticulously designed Supervised Fine-Tuning module, an Address-centric Retrieval Augmented Generation module and a Bias-free Objective Alignment module. To the best of our knowledge, this study pioneers the application of LLM-based address rewriting approach to solve the issue of abnormal addresses. Through comprehensive offline testing with real-world data on a national scale and subsequent online deployment, AddrLLM has demonstrated superior performance in integration with existing logistics system. It has significantly decreased the rate of parcel re-routing by approximately 43%, underscoring its exceptional efficacy in real-world applications.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {2756–2767},
numpages = {12},
keywords = {address rewriting, large language models, query reformulation},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3672198.3673797,
author = {Li, Hanchen and Liu, Yuhan and Cheng, Yihua and Ray, Siddhant and Du, Kuntai and Jiang, Junchen},
title = {Eloquent: A More Robust Transmission Scheme for LLM Token Streaming},
year = {2024},
isbn = {9798400707131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672198.3673797},
doi = {10.1145/3672198.3673797},
abstract = {To render each generated token in real-time for users, the Large Language Model (LLM) server generates tokens one by one and streams each token (or group of a few tokens) through the network to the user right after generation, which we refer to as LLM token streaming. However, under unstable network conditions, the LLM token streaming experience could suffer greatly from stalls since one packet loss could block the rendering of later tokens even if the packets containing them arrive on time. With a measurement study, we show that current applications suffer from increased stalls under unstable networks.For this emerging token streaming problem in LLM Chatbots that differs from previous multimedia and text applications, we propose a novel transmission scheme, called Eloquent, which puts newly generated tokens as well as currently unacknowledged tokens in the next outgoing packet. This ensures that each packet contains some new tokens and, in the meantime, is independently rendered when received, avoiding the aforementioned stalls caused by missing packets. Through simulation under various networks, we show Eloquent reduces stall ratio (proportion of token rendering wait time) by 71.0% compared to the retransmission method commonly used by real chatbot applications and by 31.6% compared to the baseline packet duplication scheme. By tailoring Eloquent to fit the token-by-token generation of LLM, we enable the Chatbots to respond like an eloquent speaker for users to better enjoy pervasive AI.},
booktitle = {Proceedings of the 2024 SIGCOMM Workshop on Networks for AI Computing},
pages = {34–40},
numpages = {7},
keywords = {Large Language Models, Real-Time Communication, Token Streaming},
location = {Sydney, NSW, Australia},
series = {NAIC '24}
}

@inproceedings{10.1145/3600211.3604712,
author = {Rastogi, Charvi and Tulio Ribeiro, Marco and King, Nicholas and Nori, Harsha and Amershi, Saleema},
title = {Supporting Human-AI Collaboration in Auditing LLMs with LLMs},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604712},
doi = {10.1145/3600211.3604712},
abstract = {Large language models (LLMs) are increasingly becoming all-powerful and pervasive via deployment in sociotechnical systems. Yet these language models, be it for classification or generation, have been shown to be biased, behave irresponsibly, causing harm to people at scale. It is crucial to audit these language models rigorously before deployment. Existing auditing tools use either or both humans and AI to find failures. In this work, we draw upon literature in human-AI collaboration and sensemaking, and interview research experts in safe and fair AI, to build upon the auditing tool: AdaTest&nbsp;[36], which is powered by a generative LLM. Through the design process we highlight the importance of sensemaking and human-AI communication to leverage complementary strengths of humans and generative models in collaborative auditing. To evaluate the effectiveness of AdaTest++, the augmented tool, we conduct user studies with participants auditing two commercial language models: OpenAI’s GPT-3 and Azure’s sentiment analysis model. Qualitative analysis shows that AdaTest++ effectively leverages human strengths such as schematization, hypothesis testing. Further, with our tool, users identified a variety of failures modes, covering 26 different topics over 2 tasks, that have been shown in formal audits and also those previously under-reported.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {913–926},
numpages = {14},
keywords = {auditing, biases, generative models, language models},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

@article{10.1145/3732777,
author = {Yu, Guangba and Tan, Gou and Huang, Haojia and Zhang, Zhenyu and Chen, Pengfei and Natella, Roberto and Zheng, Zibin and Lyu, Michael R.},
title = {A Survey on Failure Analysis and Fault Injection in AI Systems},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3732777},
doi = {10.1145/3732777},
abstract = {The rapid advancement of Artificial Intelligence (AI) has led to its integration into various areas, especially with Large Language Models (LLMs) significantly enhancing capabilities in Artificial Intelligence Generated Content (AIGC). However, the complexity of AI systems has also exposed their vulnerabilities, necessitating robust methods for failure analysis (FA) and fault injection (FI) to ensure resilience and reliability. Despite the importance of these techniques, there lacks a comprehensive review of FA and FI methodologies in AI systems. This study fills this gap by presenting a detailed survey of existing FA and FI approaches across six layers of AI systems. We systematically analyze 142 studies to answer three research questions including (1) what are the prevalent failures in AI systems, (2) what types of faults can current FI tools simulate, (3) what gaps exist between the simulated faults and real-world failures. Our findings reveal a taxonomy of AI system failures, assess the capabilities of existing FI tools, and highlight discrepancies between real-world and simulated failures. Moreover, this survey contributes to the field by providing a framework for fault diagnosis, evaluating the state-of-the-art in FI, and identifying areas for improvement in FI techniques to enhance the resilience of AI systems.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Failure Analysis, Fault Injection, Chaos Engineering, AI system, MLOps, LLMOps}
}

@inproceedings{10.1145/3706598.3714122,
author = {Ju, Hyojin and Lee, Jungeun and Yang, Seungwon and Ok, Jungseul and Hwang, Inseok},
title = {Toward Affective Empathy via Personalized Analogy Generation: A Case Study on Microaggression},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714122},
doi = {10.1145/3706598.3714122},
abstract = {The importance of empathy cannot be overstated in modern societies where people of diverse backgrounds increasingly interact together. The HCI community has strived to foster affective empathy through immersive technologies. Many previous techniques are built upon a premise that presenting the same experience as-is may help evoke the same emotion, which however faces limitations in matters where the emotional responses largely differ across individuals. In this paper, we present a novel concept of generating a personalized experience based on a large language model (LLM) to facilitate affective empathy between individuals despite their differences. As a case study to showcase its effectiveness, we developed EmoSync, an LLM-based agent that generates personalized analogical microaggression situations, facilitating users to personally resonate with a specific microaggression situation of another person. EmoSync is designed and evaluated along a 3-phased user study with 100+ participants. We comprehensively discuss implications, limitations, and possible applications.Disclaimer: Readers may find content of a discriminative or stereotypical nature, which is inevitable given this work’s theme.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {379},
numpages = {31},
keywords = {Empathy, Personalized Analogy Generation, Microaggression, Large Language Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3626111.3628183,
author = {Mani, Sathiya Kumaran and Zhou, Yajie and Hsieh, Kevin and Segarra, Santiago and Eberl, Trevor and Azulai, Eliran and Frizler, Ido and Chandra, Ranveer and Kandula, Srikanth},
title = {Enhancing Network Management Using Code Generated by Large Language Models},
year = {2023},
isbn = {9798400704154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626111.3628183},
doi = {10.1145/3626111.3628183},
abstract = {Analyzing network topologies and communication graphs is essential in modern network management. However, the lack of a cohesive approach results in a steep learning curve, increased errors, and inefficiencies. In this paper, we present a novel approach that enables natural-language-based network management experiences, leveraging large language models (LLMs) to generate task-specific code from natural language queries. This method addresses the challenges of explainability, scalability, and privacy by allowing network operators to inspect the generated code, removing the need to share network data with LLMs, and focusing on application-specific requests combined with program synthesis techniques. We develop and evaluate a prototype system using benchmark applications, demonstrating high accuracy, cost-effectiveness, and potential for further improvements using complementary program synthesis techniques.},
booktitle = {Proceedings of the 22nd ACM Workshop on Hot Topics in Networks},
pages = {196–204},
numpages = {9},
keywords = {Communication graphs, Graph manipulation, Large language model, Natural language processing, Network lifecycle management, Network management, Program synthesis},
location = {Cambridge, MA, USA},
series = {HotNets '23}
}

@inproceedings{10.1145/3722565.3727197,
author = {Mulayim, Ozan Baris and Fierro, Gabe and Berg\'{e}s, Mario and Pritoni, Marco},
title = {Towards Zero-shot Question Answering in CPS-IoT: Large Language Models and Knowledge Graphs},
year = {2025},
isbn = {9798400716089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722565.3727197},
doi = {10.1145/3722565.3727197},
abstract = {Natural language provides an intuitive interface for querying data, yet its unstructured nature often makes precise retrieval of information challenging. Knowledge graphs (KGs), with their structured and relational representations, offer a powerful solution to structuring knowledge, while large language models (LLMs) are capable of interpreting user intent through language. This combination of KGs and LLMs has been explored extensively for Knowledge Graph Question Answering (KGQA), primarily for open-domain or encyclopedic knowledge. Domain-specific KGQA, instead, presents significant opportunities for Cyber-Physical Systems (CPS) and the Internet of Things (IoT), where the extraction of structured metadata is essential for automation and scalability of control and analytics applications.In this work, we evaluate and improve AutoKGQA, a domain-independent KGQA framework that utilizes LLMs to generate structured queries. Through a case study on KGs of sensor data from buildings, we assess its ability to retrieve time series identifiers, which are a requirement for extracting time series data from large sensory databases. Our results demonstrate that while AutoKGQA performs well in certain cases, its domain-agnostic approach leads to systematic failures particularly in complex queries requiring implicit knowledge. We show that domain-specific prompting significantly enhances query accuracy, allowing even smaller LLMs to perform on par with larger ones. These findings highlight the impact of domain-adapted prompting in KGQA (DA-KGQA) and suggest a path toward more efficient, scalable, and interpretable AI-driven metadata retrieval for CPS-IoT applications.},
booktitle = {Proceedings of the 2nd International Workshop on Foundation Models for Cyber-Physical Systems &amp; Internet of Things},
pages = {7–12},
numpages = {6},
keywords = {Knowledge Graphs, Large Language Models, Time series Extraction},
location = {Irvine, CA, USA},
series = {FMSys}
}

@inproceedings{10.1145/3589334.3645670,
author = {Sun, Hongda and Liu, Yuxuan and Wu, Chengwei and Yan, Haiyu and Tai, Cheng and Gao, Xin and Shang, Shuo and Yan, Rui},
title = {Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645670},
doi = {10.1145/3589334.3645670},
abstract = {Open-domain question answering (ODQA) has emerged as a pivotal research spotlight in information systems. Existing methods follow two main paradigms to collect evidence: (1) Theretrieve-then-read paradigm retrieves pertinent documents from an external corpus; and (2) thegenerate-then-read paradigm employs large language models (LLMs) to generate relevant documents. However, neither can fully address multifaceted requirements for evidence. To this end, we propose LLMQA, a generalized framework that formulates the ODQA process into three basic steps: query expansion, document selection, and answer generation, combining the superiority of both retrieval-based and generation-based evidence. Since LLMs exhibit their excellent capabilities to accomplish various tasks, we instruct LLMs to play multiple roles as generators, rerankers, and evaluators within our framework, integrating them to collaborate in the ODQA process. Furthermore, we introduce a novel prompt optimization algorithm to refine role-playing prompts and steer LLMs to produce higher-quality evidence and answers. Extensive experimental results on widely used benchmarks (NQ, WebQ, and TriviaQA) demonstrate that LLMQA achieves the best performance in terms of both answer accuracy and evidence quality, showcasing its potential for advancing ODQA research and applications.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4372–4382},
numpages = {11},
keywords = {prompt optimization, question answering, role-playing llms},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645336,
author = {Xu, Shicheng and Pang, Liang and Xu, Jun and Shen, Huawei and Cheng, Xueqi},
title = {List-aware Reranking-Truncation Joint Model for Search and Retrieval-augmented Generation},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645336},
doi = {10.1145/3589334.3645336},
abstract = {The results of information retrieval (IR) are usually presented in the form of a ranking list of candidate documents, such as web search for humans and retrieval-augmented generation for large language models (LLMs). List-aware retrieval aims to capture the list-level contextual features to return a better list, mainly including reranking and truncation. Reranking finely re-scores the documents in the list. Truncation dynamically determines the cut-off point of the ranked list to achieve the trade-off between overall relevance and avoiding misinformation from irrelevant documents. Previous studies treat them as two separate tasks and model them separately. However, the separation is not optimal. First, it is hard to share the contextual information of the ranking list between the two tasks. Second, the separate pipeline usually meets the error accumulation problem, where the small error from the reranking stage can largely affect the truncation stage. To solve these problems, we propose a Reranking-Truncation joint model (GenRT) that can perform the two tasks concurrently. GenRT integrates reranking and truncation via a generative paradigm based on an encoder-decoder architecture with novel loss functions for joint optimization to learn both tasks. Sharing parameters by the joint model is conducive to making full use of the common modeling information of the two tasks. Besides, the two tasks are performed concurrently and co-optimized to solve the error accumulation problem between separate stages. Experiments on public learning-to-rank benchmarks and open-domain Q&amp;A tasks show that our method achieves SOTA performance on both reranking and truncation tasks for web search and retrieval-augmented LLMs.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1330–1340},
numpages = {11},
keywords = {reranking, retrieval-augmented LLMs, truncation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3703412.3703434,
author = {Liu, Fengchen and Jung, Jordan and Feinstein, Wei and D'Ambrogia, Jeff and Jung, Gary},
title = {Aggregated Knowledge Model: Enhancing Domain-Specific QA with Fine-Tuned and Retrieval-Augmented Generation Models},
year = {2025},
isbn = {9798400711619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703412.3703434},
doi = {10.1145/3703412.3703434},
abstract = {This paper introduces a novel approach to enhancing closed-domain Question Answering (QA) systems, focusing on the specific needs of the Lawrence Berkeley National Laboratory (LBL) Science Information Technology (ScienceIT) domain. Utilizing a rich dataset derived from the ScienceIT documentation, our study embarks on a detailed comparison of two fine-tuned large language models and five retrieval-augmented generation (RAG) models. Through data processing techniques, we transform the documentation into structured context-question-answer triples, leveraging the latest Large Language Models (AWS Bedrock, GCP PaLM2, Meta LLaMA2, OpenAI GPT-4, Google Gemini-Pro) for data-driven insights. Additionally, we introduce the Aggregated Knowledge Model (AKM), which synthesizes responses from the seven models mentioned above using K-means clustering to select the most representative answers. The evaluation of these models across multiple metrics offers a comprehensive look into their effectiveness and suitability for the LBL ScienceIT environment. The results demonstrate the potential benefits of integrating fine-tuning and retrieval-augmented strategies, highlighting significant performance improvements achieved with the AKM. The insights gained from this study can be applied to develop specialized QA systems tailored to specific domains.},
booktitle = {Proceedings of the 4th International Conference on AI-ML Systems},
articleno = {22},
numpages = {7},
keywords = {Fine-tuning Language Models, Retrieval-Augmented Generation, Closed-Domain Question Answering, Domain-Specific Information Retrieval, Large Language Models, GCP PaLM, AWS Bedrock, Meta LLaMA, OpenAI GPT, Google Gemini-Pro, High Performance Computing},
location = {
},
series = {AIMLSystems '24}
}

@article{10.1145/3660811,
author = {Mai, Yubo and Gao, Zhipeng and Hu, Xing and Bao, Lingfeng and Liu, Yu and Sun, JianLing},
title = {Are Human Rules Necessary? Generating Reusable APIs with CoT Reasoning and In-Context Learning},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660811},
doi = {10.1145/3660811},
abstract = {Inspired by the great potential of Large Language Models (LLMs) for solving complex coding tasks, in this paper, we propose a novel approach, named Code2API, to automatically perform APIzation for Stack Overflow code snippets. Code2API does not require additional model training or any manual crafting rules and can be easily deployed on personal computers without relying on other external tools. Specifically, Code2API guides the LLMs through well-designed prompts to generate well-formed APIs for given code snippets. To elicit knowledge and logical reasoning from LLMs, we used chain-of-thought (CoT) reasoning and few-shot in-context learning, which can help the LLMs fully understand the APIzation task and solve it step by step in a manner similar to a developer. Our evaluations show that Code2API achieves a remarkable accuracy in identifying method parameters (65%) and return statements (66%) equivalent to human-generated ones, surpassing the current state-of-the-art approach, APIzator, by 15.0% and 16.5% respectively. Moreover, compared with APIzator, our user study demonstrates that Code2API exhibits superior performance in generating meaningful method names, even surpassing the human-level performance, and developers are more willing to use APIs generated by our approach, highlighting the applicability of our tool in practice. Finally, we successfully extend our framework to the Python dataset, achieving a comparable performance with Java, which verifies the generalizability of our tool.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {104},
numpages = {23},
keywords = {APIs, Chain-of-thought, In-context learning, Large language models, Stack Overflow}
}

@inproceedings{10.1145/3636555.3636850,
author = {Hutt, Stephen and DePiro, Allison and Wang, Joann and Rhodes, Sam and Baker, Ryan S and Hieb, Grayson and Sethuraman, Sheela and Ocumpaugh, Jaclyn and Mills, Caitlin},
title = {Feedback on Feedback: Comparing Classic Natural Language Processing and Generative AI to Evaluate Peer Feedback},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636850},
doi = {10.1145/3636555.3636850},
abstract = {Peer feedback can be a powerful tool as it presents learning opportunities for both the learner receiving feedback as well as the learner providing feedback. Despite its utility, it can be difficult to implement effectively, particularly for younger learners, who are often novices at providing feedback. It can be difficult for students to learn what constitutes “good” feedback – particularly in open-ended problem-solving contexts. To address this gap, we investigate both classical natural language processing techniques and large language models, specifically ChatGPT, as potential approaches to devise an automated detector of feedback quality (including both student progress towards goals and next steps needed). Our findings indicate that the classical detectors are highly accurate and, through feature analysis, we elucidate the pivotal elements influencing its decision process. We find that ChatGPT is less accurate than classical NLP but illustrate the potential of ChatGPT in evaluating feedback, by generating explanations for ratings, along with scores. We discuss how the detector can be used for automated feedback evaluation and to better scaffold peer feedback for younger learners.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {55–65},
numpages = {11},
keywords = {Generative AI, Language Analytics, Large Language Models, Natural Language Processing, Peer Feedback},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3675094.3678378,
author = {Choi, Youjin and Moon, JaeYoung and Kim, Kyung-Joong and Hong, Jin-Hyuk},
title = {Exploring the Potential of Generative AI in Song-Signing},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3678378},
doi = {10.1145/3675094.3678378},
abstract = {This study explores the potential of generative AI technology to support song-signing creation and proposes a design for an AI-based song-signing authoring tool. We identified the creative process, strategies, challenges, and requirements for an AI-assisted tool through focus group interviews with two song-signing creators. The findings suggest that generative AI can be applied to automate and streamline various aspects of the song-signing creation process, including music analysis, lyrics translation, and choreography generation. Based on these insights, we propose a design of an AI-based song-signing authoring tool incorporating large language models for sign language translation and recommendation, generative dance AI for sign language visualization, and customizable sign language avatars. The development of such tools has the potential to expand the participation of d/Deaf individuals in cultural and artistic activities and contribute to an inclusive cultural and creative ecosystem.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {816–820},
numpages = {5},
keywords = {cultural inclusivity, d/deaf individuals, generative ai, large language model (llm), song-signing},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@article{10.1145/3661143,
author = {Khanshan, Alireza and Van Gorp, Pieter and Markopoulos, Panos},
title = {Evaluation of Code Generation for Simulating Participant Behavior in Experience Sampling Method by Iterative In-Context Learning of a Large Language Model},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {EICS},
url = {https://doi.org/10.1145/3661143},
doi = {10.1145/3661143},
abstract = {The Experience Sampling Method (ESM) is commonly used to understand behaviors, thoughts, and feelings in the wild by collecting self-reports. Sustaining sufficient response rates, especially in long-running studies remains challenging. To avoid low response rates and dropouts, experimenters rely on their experience, proposed methodologies from earlier studies, trial and error, or the scarcely available participant behavior data from previous ESM protocols. This approach often fails in finding the acceptable study parameters, resulting in redesigning the protocol and repeating the experiment. Research has shown the potential of machine learning to personalize ESM protocols such that ESM prompts are delivered at opportune moments, leading to higher response rates. The corresponding training process is hindered due to the scarcity of open data in the ESM domain, causing a cold start, which could be mitigated by simulating participant behavior. Such simulations provide training data and insights for the experimenters to update their study design choices. Creating this simulation requires behavioral science, psychology, and programming expertise. Large language models (LLMs) have emerged as facilitators for information inquiry and programming, albeit random and occasionally unreliable. We aspire to assess the readiness of LLMs in an ESM use case. We conducted research using GPT-3.5 turbo-16k to tackle an ESM simulation problem. We explored several prompt design alternatives to generate ESM simulation programs, evaluated the output code in terms of semantics and syntax, and interviewed ESM practitioners. We found that engineering LLM-enabled ESM simulations have the potential to facilitate data generation, but they perpetuate trust and reliability challenges.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {255},
numpages = {19},
keywords = {Behavior Simulation, Experience Sampling Method, Large Language Model, Prompt Engineering}
}

@inproceedings{10.1145/3686038.3686652,
author = {Zeghouani, Omar and Ali, Zawar and Simson van Dijkhuizen, William and Hong, Jia Wei and Clos, Jeremie},
title = {Examining the Feasibility of AI-Generated Questions in Educational Settings},
year = {2024},
isbn = {9798400709890},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686038.3686652},
doi = {10.1145/3686038.3686652},
abstract = {Educators face ever-growing time constraints, leading to poor work-life balance and a negative impact on work quality. Through their language generation capabilities, large language models offer an interesting avenue to ease this academic workload, allowing both students and lecturers to generate educational content. In this work, we leverage the latest developments in automatic speech recognition, natural language generation, retrieval-augmented generation, and multimodal models to design the Augmented Lecture Integration Network (ALINet), a system capable of producing a diverse range of high-quality assessment questions from lecture content. We inform the design of our system through a series of automated experiments using public datasets and evaluate it with a user study conducted on students and educators. Our results indicate a generally positive perception of the system’s performance, particularly in generating natural and clear questions relevant to the taught content, demonstrating its potential as a valuable resource in educational settings. This project lays the foundation for future research in multimodal educational question generation and is available for reuse in our public repository.},
booktitle = {Proceedings of the Second International Symposium on Trustworthy Autonomous Systems},
articleno = {36},
numpages = {6},
keywords = {Educational Question Generation, Generative AI, Large Language Models},
location = {Austin, TX, USA},
series = {TAS '24}
}

@inproceedings{10.1145/3613904.3642393,
author = {Leong, Joanne and Pataranutaporn, Pat and Danry, Valdemar and Perteneder, Florian and Mao, Yaoli and Maes, Pattie},
title = {Putting Things into Context: Generative AI-Enabled Context Personalization for Vocabulary Learning Improves Learning Motivation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642393},
doi = {10.1145/3613904.3642393},
abstract = {Fostering students’ interests in learning is considered to have many positive downstream effects. Large language models have opened up new horizons for generating content tuned to one’s interests, yet it is unclear in what ways and to what extent this customization could have positive effects on learning. To explore this novel dimension, we conducted a between-subjects online study (n=272) featuring different variations of a generative AI vocabulary learning app that enables users to personalize their learning examples. Participants were randomly assigned to control (sentence sourced from pre-existing text) or experimental conditions (generated sentence or short story based on users’ text input). While we did not observe a difference in learning performance between the conditions, the analysis revealed that generative AI-driven context personalization positively affected learning motivation. We discuss how these results relate to previous findings and underscore their significance for the emerging field of using generative AI for personalized&nbsp;learning.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {677},
numpages = {15},
keywords = {education, generative artificial intelligence, learning, vocabulary},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3580305.3599568,
author = {Poon, Hoifung and Naumann, Tristan and Zhang, Sheng and Gonz\'{a}lez Hern\'{a}ndez, Javier},
title = {Precision Health in the Age of Large Language Models},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599568},
doi = {10.1145/3580305.3599568},
abstract = {Medicine today is imprecise. Among the top 20 drugs in the U.S., up to 80% of patients are non-responders. The goal of precision health is to provide the right intervention for the right people at the right time. The key to realize this dream is to develop a data-driven, learning system that can instantly incorporate new health information to optimize care delivery and accelerate biomedical discovery. In reality, however, the health ecosystem is mired in overwhelming unstructured data and excruciating manual processing. For example, in cancer, standard of care often fails, and clinical trials are the last hope. Yet less than 3% of patients could find a matching trial, whereas 40% of trial failures simply stem from insufficient recruitment. Discovery is painfully slow as a new drug may take billions of dollars and over a decade to develop.In this tutorial, we will explore how large language models (LLMs) can serve as a universal structuring tool to democratize biomedical knowledge work and usher in an intelligence revolution in precision health. We first review background for precision health and give a broad overview of the AI revolution that culminated in the development of large language models, highlighting key technical innovations and prominent trends such as consolidation of AI methods across modalities. We then give an in-depth review of biomedical LLMs and precision health applications, with a particular focus on scaling real-world evidence generation and drug discovery. To conclude, we discuss key technical challenges (e.g., bias, hallucination, cost), societal ramifications (e.g., privacy, regulation), as well as exciting research frontiers such as prompt programming, knowledge distillation, multi-modal learning, causal discovery.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5825–5826},
numpages = {2},
keywords = {artificial intelligence, large language model, machine learning, precision health},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.5555/3721488.3721591,
author = {Ito, Shunichiro and Kochigami, Kanae and Kanda, Takayuki},
title = {A Robot Dynamically Asking Questions in University Classes},
year = {2025},
publisher = {IEEE Press},
abstract = {We developed a robot that dynamically asks questions after listening to a lecture in university group classes to enhance students' learning. Based on interview results with ten professors, we designed our robot to let professors choose when a robot asks questions, ask various kinds of questions by letting professors choose question types, and ask questions dynamically without sharing them with professors in advance. The prepared question types include such as clarification questions, which are fact-based questions about a lecture, and thought-provoking questions, which activate students' critical thinking. We expanded them into eight sub-categories of questions that the most common types that are likely to emerge in classrooms. Leveraging large language models (LLMs), based on lecture transcripts, we developed a robot system that generates questions in the eight sub-categories and yields 0.93 classification accuracy toward human coding results. We also conducted a case study with our developed robot in four university lectures. In these lectures that involved our robot, the professors often asked reasoning questions and criticism questions, and the students showed engagement with the robot-professor dialogues. Interviews with 20 students revealed that the robot's questions contributed to the classes by helping the students reflect on the lectures and gain new perspectives. The professors also recognized some benefits of the robot, perceiving its presence as a question facilitator, a mood maker, a communication tool as well as a motivator to prepare more diligently for their own lectures.},
booktitle = {Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {839–848},
numpages = {10},
keywords = {education, group class, large language models, question, social robotics},
location = {Melbourne, Australia},
series = {HRI '25}
}

@inproceedings{10.1145/3584931.3607494,
author = {Richards Maldonado, Liam and Abouzied, Azza and Gleason, Nancy W.},
title = {ReaderQuizzer: Augmenting Research Papers with Just-In-Time Learning Questions to Facilitate Deeper Understanding},
year = {2023},
isbn = {9798400701290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584931.3607494},
doi = {10.1145/3584931.3607494},
abstract = {Academic reading is a key component of higher education, and serves as a basis for critical thinking, knowledge acquisition and effective communication. Research shows many students struggle with comprehension and analysis tasks with academic texts, despite the central importance of academic reading to success in higher education. Undergraduates and researchers need to internalize dense literature to scaffold their own work upon it. This reading task is time-consuming and difficult to do. Oftentimes, students struggle to actively and critically engage and as a result attain merely a cursory understanding of a paper’s contents, or worse, incorrectly interpret the text. How, then, can we provide a means to more easily digest a text while also facilitating meaningful, critical engagement and understanding? This paper locates itself within the broader field of augmented reading interfaces to implement an augmented reading interface that leverages the power of large language models (LLM) to intelligently generate and co-locate comprehension and analysis questions in an academic paper, thereby making the paper more digestible with the end goal of facilitating deeper understanding, and developing critical reading skills.},
booktitle = {Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {391–394},
numpages = {4},
keywords = {academic papers, augmented reading interfaces, reading comprehension},
location = {Minneapolis, MN, USA},
series = {CSCW '23 Companion}
}

@inproceedings{10.1145/3664647.3680661,
author = {Xu, Weiye and Wang, Min and Zhou, Wengang and Li, Houqiang},
title = {P-RAG: Progressive Retrieval Augmented Generation For Planning on Embodied Everyday Task},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680661},
doi = {10.1145/3664647.3680661},
abstract = {Embodied Everyday Task is a popular task in the embodied AI community, requiring agents to make a sequence of actions based on natural language instructions and visual observations. Traditional learning-based approaches face two challenges. Firstly, natural language instructions often lack explicit task planning. Secondly, extensive training is required to equip models with knowledge of the task environment. Previous works based on Large Language Model (LLM) either suffer from poor performance due to the lack of task-specific knowledge or rely on ground truth as few-shot samples. To address the above limitations, we propose a novel approach called Progressive Retrieval Augmented Generation (P-RAG), which not only effectively leverages the powerful language processing capabilities of LLMs but also progressively accumulates task-specific knowledge without ground-truth. Compared to the conventional RAG methods, which retrieve relevant information from the database in a one-shot manner to assist generation, P-RAG introduces an iterative approach to progressively update the database. In each iteration, P-RAG retrieves the latest database and obtains historical information from the previous interaction as experiential references for the current interaction. Moreover, we also introduce a more granular retrieval scheme that not only retrieves similar tasks but also incorporates retrieval of similar situations to provide more valuable reference experiences. Extensive experiments reveal that P-RAG achieves competitive results without utilizing ground truth and can even further improve performance through self-iterations.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {6969–6978},
numpages = {10},
keywords = {embodied ai, large language model, progressive method, retrieval augmented generation},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3597503.3639219,
author = {Du, Xueying and Liu, Mingwei and Wang, Kaixin and Wang, Hanlin and Liu, Junwei and Chen, Yixuan and Feng, Jiayi and Sha, Chaofeng and Peng, Xin and Lou, Yiling},
title = {Evaluating Large Language Models in Class-Level Code Generation},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639219},
doi = {10.1145/3597503.3639219},
abstract = {Recently, many large language models (LLMs) have been proposed, showing advanced proficiency in code generation. Meanwhile, many efforts have been dedicated to evaluating LLMs on code generation benchmarks such as HumanEval. Although being very helpful for comparing different LLMs, existing evaluation focuses on a simple code generation scenario (i.e., function-level or statement-level code generation), which mainly asks LLMs to generate one single code unit (e.g., a function or a statement) for the given natural language description. Such evaluation focuses on generating independent and often small-scale code units, thus leaving it unclear how LLMs perform in real-world software development scenarios.To fill this knowledge gap, we make the first attempt to evaluate LLMs in a more challenging code generation scenario, i.e., class-level code generation. Compared with existing code generation benchmarks, it better reflects real-world software development scenarios due to it comprising broader contextual dependencies and multiple, interdependent units of code. We first manually construct the first class-level code generation benchmark ClassEval of 100 class-level Python code generation tasks with approximately 500 person-hours. Based on the new benchmark ClassEval, we then perform the first study of 11 state-of-the-art LLMs on class-level code generation. Based on our results, we find that all LLMs perform much worse on class-level code generation compared to the method-level. While GPT models still dominate other LLMs on class-level code generation, the performance rankings of other models on method-level code generation no longer holds for class-level code generation. Besides, most models (except GPT models) perform better when generating the class method by method; and they have the limited ability of generating dependent code. Based on our findings, we call for software engineering (SE) researchers' expertise to build more LLM benchmarks based on practical and complicated software development scenarios.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {81},
numpages = {13},
keywords = {class-level code generation, large language model, benchmark},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3604237.3626867,
author = {Lakkaraju, Kausik and Jones, Sara E and Vuruma, Sai Krishna Revanth and Pallagani, Vishal and Muppasani, Bharath C and Srivastava, Biplav},
title = {LLMs for Financial Advisement: A Fairness and Efficacy Study in Personal Decision Making},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626867},
doi = {10.1145/3604237.3626867},
abstract = {As Large Language Model (LLM) based chatbots are becoming more accessible, users are relying on these chatbots for reliable and personalized recommendations in diverse domains, ranging from code generation to financial advisement. In this context, we set out to investigate how such systems perform in the personal finance domain, where financial inclusion has been an overarching stated aim of banks for decades. We test widely used LLM-based chatbots, ChatGPT and Bard, and compare their performance against SafeFinance, a rule-based chatbot built using the Rasa platform. The comparison is across two critical tasks: product discovery and multi-product interaction, where product refers to banking products like Credit Cards, Certificate of Deposits, and Checking Accounts. With this study, we provide interesting insights into the chatbots’ efficacy in financial advisement and their ability to provide fair treatment across different user groups. We find that both Bard and ChatGPT can make errors in retrieving basic online information, the responses they generate are inconsistent across different user groups, and they cannot be relied on for reasoning involving banking products. On the other hand, despite their limited generalization capabilities, rule-based chatbots like SafeFinance provide safe and reliable answers to users that can be traced back to their original source. Overall, although the outputs of the LLM-based chatbots are fluent and plausible, there are still critical gaps in providing consistent and reliable financial information.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {100–107},
numpages = {8},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@article{10.1145/3700597,
author = {Ke, Ping Fan and Ng, Ka Chung},
title = {Human-AI Synergy in Survey Development: Implications from Large Language Models in Business and Research},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3700597},
doi = {10.1145/3700597},
abstract = {This study examines the novel integration of Large Language Models (LLMs) into the survey development process in business and research through the development and evaluation of the Behavioral Research Assistant (BRASS) Bot. We first analyzed the traditional scale development process to identify tasks suitable for LLM integration, including both human-in-the-loop and automated LLM data collection methods. Following this analysis, we developed the details of BRASS Bot, incorporating design principles of falsifiability and reproducibility. We then conducted a comprehensive evaluation of the BRASS Bot across a diverse set of LLMs, including GPT, Claude, Gemini, and Llama, to assess its usability, validity, and reliability. We further demonstrated the practical utility of the BRASS Bot by conducting a user study and a predictive validity simulation. Our research presents both theoretical and practical implications. The augmentation approach of the BRASS Bot enriches the theoretical foundations of behavioral constructs by identifying previously overlooked patterns. Additionally, the BRASS Bot offers significant time and resource efficiency gains while enhancing scale validity. Our work lays the foundation for future research on the broader application of LLMs as both assistants and collaborators in survey analysis and behavioral research design and execution, highlighting their potential for a transformative impact on the field.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {9},
numpages = {39},
keywords = {Large Language Model, generative AI, scale development, behavioral research}
}

